{"step": 1192, "time": 120.2348747253418, "episode/length": 148.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.959731543624161, "episode/intrinsic_return": 0.0}
{"step": 1264, "time": 121.91556429862976, "episode/length": 157.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 1296, "time": 123.36893558502197, "episode/length": 161.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 1368, "time": 124.91194725036621, "episode/length": 170.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 1376, "time": 126.2669665813446, "episode/length": 171.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 1560, "time": 141.82050824165344, "eval_episode/length": 137.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9927536231884058}
{"step": 1560, "time": 143.39696621894836, "eval_episode/length": 147.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9932432432432432}
{"step": 1560, "time": 144.73193383216858, "eval_episode/length": 149.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.96}
{"step": 1560, "time": 146.5440320968628, "eval_episode/length": 173.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9770114942528736}
{"step": 1560, "time": 147.96648120880127, "eval_episode/length": 176.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9943502824858758}
{"step": 1560, "time": 149.6816704273224, "train_stats/sum_log_reward": 0.699999988079071, "train_stats/max_log_achievement_wake_up": 2.4, "train_stats/max_log_achievement_collect_sapling": 0.3333333333333333, "train_stats/max_log_achievement_place_plant": 0.3333333333333333, "train_stats/max_log_achievement_collect_wood": 1.0, "eval_stats/sum_log_reward": 0.8999999523162842, "eval_stats/max_log_achievement_collect_sapling": 0.6, "eval_stats/max_log_achievement_collect_wood": 0.0, "eval_stats/max_log_achievement_place_plant": 0.6, "eval_stats/max_log_achievement_wake_up": 1.6, "eval_stats/max_log_achievement_collect_drink": 5.0}
{"step": 1560, "time": 189.74037742614746, "eval_episode/length": 95.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9583333333333334}
{"step": 1560, "time": 194.15320706367493, "eval_episode/length": 142.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.972027972027972}
{"step": 1560, "time": 196.35035586357117, "eval_episode/length": 147.0, "eval_episode/score": 1.0999999791383743, "eval_episode/reward_rate": 0.9932432432432432}
{"step": 1560, "time": 198.50870776176453, "eval_episode/length": 149.0, "eval_episode/score": 2.0999999940395355, "eval_episode/reward_rate": 0.9933333333333333}
{"step": 1560, "time": 200.71738004684448, "eval_episode/length": 152.0, "eval_episode/score": 2.0999999940395355, "eval_episode/reward_rate": 0.9934640522875817}
{"step": 1560, "time": 202.6835114955902, "eval_episode/length": 154.0, "eval_episode/score": 1.1000000014901161, "eval_episode/reward_rate": 0.9935483870967742}
{"step": 1560, "time": 206.14142179489136, "eval_episode/length": 184.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9945945945945946}
{"step": 1560, "time": 213.65211272239685, "eval_episode/length": 151.0, "eval_episode/score": 2.100000001490116, "eval_episode/reward_rate": 0.993421052631579}
{"step": 1561, "time": 329.6705708503723, "eval_stats/sum_log_reward": 1.3499999474734068, "eval_stats/max_log_achievement_collect_drink": 1.375, "eval_stats/max_log_achievement_collect_sapling": 0.875, "eval_stats/max_log_achievement_collect_wood": 0.0, "eval_stats/max_log_achievement_place_plant": 0.5, "eval_stats/max_log_achievement_wake_up": 1.75, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 7.3349609375, "train/action_min": 0.0, "train/action_std": 4.901294231414795, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00039007156738080084, "train/actor_opt_grad_steps": 1.0, "train/actor_opt_loss": -2.3257412910461426, "train/adv_mag": 0.0, "train/adv_max": 0.0, "train/adv_mean": 0.0, "train/adv_min": 0.0, "train/adv_std": 0.0, "train/cont_avg": 0.9970703125, "train/cont_loss_mean": 0.663711667060852, "train/cont_loss_std": 0.29737892746925354, "train/cont_neg_acc": 0.6666666865348816, "train/cont_neg_loss": 0.7014727592468262, "train/cont_pos_acc": 0.5837414264678955, "train/cont_pos_loss": 0.6636006832122803, "train/cont_pred": 0.5361141562461853, "train/cont_rate": 0.9970703125, "train/dyn_loss_mean": 10.7698974609375, "train/dyn_loss_std": 0.48523521423339844, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 8.18502426147461, "train/extr_critic_critic_opt_grad_steps": 1.0, "train/extr_critic_critic_opt_loss": 33436.3203125, "train/extr_critic_mag": 0.0, "train/extr_critic_max": 0.0, "train/extr_critic_mean": 0.0, "train/extr_critic_min": 0.0, "train/extr_critic_std": 0.0, "train/extr_return_normed_mag": 0.0, "train/extr_return_normed_max": 0.0, "train/extr_return_normed_mean": 0.0, "train/extr_return_normed_min": 0.0, "train/extr_return_normed_std": 0.0, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.0, "train/extr_return_raw_max": 0.0, "train/extr_return_raw_mean": 0.0, "train/extr_return_raw_min": 0.0, "train/extr_return_raw_std": 0.0, "train/extr_reward_mag": 0.0, "train/extr_reward_max": 0.0, "train/extr_reward_mean": 0.0, "train/extr_reward_min": 0.0, "train/extr_reward_std": 0.0, "train/image_loss_mean": 3629.7255859375, "train/image_loss_std": 175.00990295410156, "train/model_loss_mean": 3642.392578125, "train/model_loss_std": 174.91238403320312, "train/model_opt_grad_norm": NaN, "train/model_opt_grad_steps": 0.0, "train/model_opt_loss": 36423924.0, "train/model_opt_model_opt_grad_overflow": 1.0, "train/model_opt_model_opt_grad_scale": 5000.0, "train/policy_entropy_mag": 2.7809205055236816, "train/policy_entropy_max": 2.7809205055236816, "train/policy_entropy_mean": 2.5692298412323, "train/policy_entropy_min": 1.841706395149231, "train/policy_entropy_std": 0.08938358724117279, "train/policy_logprob_mag": 5.488073348999023, "train/policy_logprob_max": -0.6058917045593262, "train/policy_logprob_mean": -2.568439245223999, "train/policy_logprob_min": -5.488073348999023, "train/policy_logprob_std": 0.681625485420227, "train/policy_randomness_mag": 0.9815428853034973, "train/policy_randomness_max": 0.9815428853034973, "train/policy_randomness_mean": 0.9068253040313721, "train/policy_randomness_min": 0.6500415205955505, "train/policy_randomness_std": 0.03154848515987396, "train/post_ent_mag": 106.27595520019531, "train/post_ent_max": 106.27595520019531, "train/post_ent_mean": 105.63536071777344, "train/post_ent_min": 104.88999938964844, "train/post_ent_std": 0.2423069179058075, "train/prior_ent_mag": 106.39314270019531, "train/prior_ent_max": 106.39314270019531, "train/prior_ent_mean": 105.57742309570312, "train/prior_ent_min": 104.72821044921875, "train/prior_ent_std": 0.2742423713207245, "train/rep_loss_mean": 10.7698974609375, "train/rep_loss_std": 0.48523521423339844, "train/reward_avg": 0.008593750186264515, "train/reward_loss_mean": 5.541262626647949, "train/reward_loss_std": 9.5367431640625e-07, "train/reward_max_data": 1.0, "train/reward_max_pred": 0.0, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 5.541263103485107, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 5.541263580322266, "train/reward_pred": 0.0, "train/reward_rate": 0.01171875, "train/params_agent/wm/model_opt": 181569923.0, "train/params_agent/task_behavior/critic/critic_opt": 9708799.0, "train/params_agent/task_behavior/ac/actor_opt": 9464849.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.6366405487060547, "report/cont_loss_std": 0.2754213809967041, "report/cont_neg_acc": 0.3333333432674408, "report/cont_neg_loss": 1.089364767074585, "report/cont_pos_acc": 0.6503427624702454, "report/cont_pos_loss": 0.6353102922439575, "report/cont_pred": 0.5484054088592529, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 10.887958526611328, "report/dyn_loss_std": 0.4923345446586609, "report/image_loss_mean": 3630.03564453125, "report/image_loss_std": 175.69578552246094, "report/model_loss_mean": 3642.746337890625, "report/model_loss_std": 175.5691680908203, "report/post_ent_mag": 106.27061462402344, "report/post_ent_max": 106.27061462402344, "report/post_ent_mean": 105.6318359375, "report/post_ent_min": 104.84214782714844, "report/post_ent_std": 0.2616924047470093, "report/prior_ent_mag": 106.290283203125, "report/prior_ent_max": 106.290283203125, "report/prior_ent_mean": 105.5479507446289, "report/prior_ent_min": 104.80589294433594, "report/prior_ent_std": 0.26603183150291443, "report/rep_loss_mean": 10.887958526611328, "report/rep_loss_std": 0.4923345446586609, "report/reward_avg": 0.008593750186264515, "report/reward_loss_mean": 5.541262626647949, "report/reward_loss_std": 9.5367431640625e-07, "report/reward_max_data": 1.0, "report/reward_max_pred": 0.0, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 5.541263103485107, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 5.541263580322266, "report/reward_pred": 0.0, "report/reward_rate": 0.01171875, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.6802648305892944, "eval/cont_loss_std": 0.2962716817855835, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.4875586926937103, "eval/cont_pos_acc": 0.575905978679657, "eval/cont_pos_loss": 0.6808310151100159, "eval/cont_pred": 0.5267549753189087, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 10.846240997314453, "eval/dyn_loss_std": 0.4815245270729065, "eval/image_loss_mean": 3648.959228515625, "eval/image_loss_std": 175.02825927734375, "eval/model_loss_mean": 3661.6884765625, "eval/model_loss_std": 174.91690063476562, "eval/post_ent_mag": 106.21415710449219, "eval/post_ent_max": 106.21415710449219, "eval/post_ent_mean": 105.59481811523438, "eval/post_ent_min": 104.8759765625, "eval/post_ent_std": 0.2513175904750824, "eval/prior_ent_mag": 106.21034240722656, "eval/prior_ent_max": 106.21034240722656, "eval/prior_ent_mean": 105.5369873046875, "eval/prior_ent_min": 104.54444122314453, "eval/prior_ent_std": 0.2732522785663605, "eval/rep_loss_mean": 10.846240997314453, "eval/rep_loss_std": 0.4815245270729065, "eval/reward_avg": 0.00634765625, "eval/reward_loss_mean": 5.541262626647949, "eval/reward_loss_std": 9.542561656417092e-07, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 5.541262626647949, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.541263580322266, "eval/reward_pred": 0.0, "eval/reward_rate": 0.009765625, "replay/size": 1057.0, "replay/inserts": 1057.0, "replay/samples": 112.0, "replay/insert_wait_avg": 1.7291549928028175e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.451087134225028e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 3416.0, "eval_replay/inserts": 3416.0, "eval_replay/samples": 112.0, "eval_replay/insert_wait_avg": 1.4817407594631651e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.260007313319615e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 223.60875344276428, "timer/env.step_count": 196.0, "timer/env.step_total": 21.838023900985718, "timer/env.step_frac": 0.09766175771189324, "timer/env.step_avg": 0.11141848929074345, "timer/env.step_min": 0.019637346267700195, "timer/env.step_max": 10.749443769454956, "timer/replay._sample_count": 112.0, "timer/replay._sample_total": 0.09591054916381836, "timer/replay._sample_frac": 0.00042892126398069643, "timer/replay._sample_avg": 0.000856344188962664, "timer/replay._sample_min": 0.0003745555877685547, "timer/replay._sample_max": 0.006407499313354492, "timer/agent.save_count": 1.0, "timer/agent.save_total": 9.111156225204468, "timer/agent.save_frac": 0.04074597297702209, "timer/agent.save_avg": 9.111156225204468, "timer/agent.save_min": 9.111156225204468, "timer/agent.save_max": 9.111156225204468, "timer/agent.policy_count": 296.0, "timer/agent.policy_total": 26.982482194900513, "timer/agent.policy_frac": 0.12066827339926586, "timer/agent.policy_avg": 0.09115703444223146, "timer/agent.policy_min": 0.010555505752563477, "timer/agent.policy_max": 19.58343529701233, "timer/dataset_train_count": 1.0, "timer/dataset_train_total": 3.457069396972656e-05, "timer/dataset_train_frac": 1.5460349130999204e-07, "timer/dataset_train_avg": 3.457069396972656e-05, "timer/dataset_train_min": 3.457069396972656e-05, "timer/dataset_train_max": 3.457069396972656e-05, "timer/agent.train_count": 1.0, "timer/agent.train_total": 90.38604688644409, "timer/agent.train_frac": 0.4042151547952689, "timer/agent.train_avg": 90.38604688644409, "timer/agent.train_min": 90.38604688644409, "timer/agent.train_max": 90.38604688644409, "timer/agent.report_count": 2.0, "timer/agent.report_total": 23.31477928161621, "timer/agent.report_frac": 0.10426595078525827, "timer/agent.report_avg": 11.657389640808105, "timer/agent.report_min": 0.24443697929382324, "timer/agent.report_max": 23.070342302322388, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 4.100799560546875e-05, "timer/dataset_eval_frac": 1.833917276228871e-07, "timer/dataset_eval_avg": 4.100799560546875e-05, "timer/dataset_eval_min": 4.100799560546875e-05, "timer/dataset_eval_max": 4.100799560546875e-05}
{"step": 1800, "time": 357.56310653686523, "episode/length": 224.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 2024, "time": 385.4400911331177, "episode/length": 94.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9894736842105263, "episode/intrinsic_return": 0.0}
{"step": 2072, "time": 392.5993824005127, "episode/length": 258.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9806949806949807, "episode/intrinsic_return": 0.0}
{"step": 2144, "time": 402.8010160923004, "episode/length": 267.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9888059701492538, "episode/intrinsic_return": 0.0}
{"step": 2408, "time": 435.97027921676636, "episode/length": 138.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9568345323741008, "episode/intrinsic_return": 0.0}
{"step": 2424, "time": 439.55891728401184, "episode/length": 153.0, "episode/score": 0.09999997913837433, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 2432, "time": 442.1333518028259, "episode/length": 132.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9924812030075187, "episode/intrinsic_return": 0.0}
{"step": 3104, "time": 522.7287812232971, "episode/length": 162.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 3168, "time": 531.9319941997528, "episode/length": 92.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.946236559139785, "episode/intrinsic_return": 0.0}
{"step": 3224, "time": 540.0528638362885, "episode/length": 230.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9826839826839827, "episode/intrinsic_return": 0.0}
{"step": 3264, "time": 546.7968504428864, "episode/length": 139.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 3600, "time": 587.4664030075073, "episode/length": 190.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 3672, "time": 597.4202835559845, "episode/length": 205.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 3768, "time": 610.2580480575562, "episode/length": 166.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 3880, "time": 624.8873000144958, "episode/length": 183.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 3880, "time": 624.8934800624847, "episode/length": 76.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.948051948051948, "episode/intrinsic_return": 0.0}
{"step": 4336, "time": 681.5984907150269, "episode/length": 145.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.0}
{"step": 4464, "time": 698.3233716487885, "episode/length": 169.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 4664, "time": 723.2946424484253, "episode/length": 132.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9924812030075187, "episode/intrinsic_return": 0.0}
{"step": 4880, "time": 750.2801988124847, "episode/length": 206.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 4968, "time": 762.1214754581451, "episode/length": 161.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 5032, "time": 771.0813462734222, "episode/length": 143.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 5192, "time": 791.2787933349609, "episode/length": 90.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.945054945054945, "episode/intrinsic_return": 0.0}
{"step": 5264, "time": 801.1576006412506, "episode/length": 172.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 5592, "time": 841.1473612785339, "episode/length": 88.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9438202247191011, "episode/intrinsic_return": 0.0}
{"step": 5640, "time": 848.4427106380463, "episode/length": 162.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 5984, "time": 890.3974330425262, "episode/length": 164.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9575757575757575, "episode/intrinsic_return": 0.0}
{"step": 6136, "time": 909.7546255588531, "episode/length": 295.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9966216216216216, "episode/intrinsic_return": 0.0}
{"step": 6184, "time": 917.047438621521, "episode/length": 143.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 6584, "time": 965.7057371139526, "episode/length": 173.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 6600, "time": 969.0819275379181, "episode/length": 203.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 6680, "time": 980.2000942230225, "episode/length": 176.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 7160, "time": 1038.211198091507, "episode/length": 189.0, "episode/score": 2.0999999940395355, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 7352, "time": 1062.307493686676, "episode/length": 151.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 7424, "time": 1072.2522866725922, "episode/length": 228.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9737991266375546, "episode/intrinsic_return": 0.0}
{"step": 7496, "time": 1082.1198964118958, "episode/length": 163.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 7552, "time": 1090.3174231052399, "episode/length": 195.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 7632, "time": 1101.2359685897827, "episode/length": 34.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 8056, "time": 1152.5303061008453, "episode/length": 183.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 8168, "time": 1167.1420993804932, "episode/length": 185.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 8488, "time": 1207.0434968471527, "episode/length": 116.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9572649572649573, "episode/intrinsic_return": 0.0}
{"step": 8712, "time": 1234.6277210712433, "episode/length": 193.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 8760, "time": 1241.8972373008728, "episode/length": 269.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 8808, "time": 1249.0026688575745, "episode/length": 172.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 8856, "time": 1256.113807439804, "episode/length": 169.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 9128, "time": 1289.5302410125732, "episode/length": 39.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 9216, "time": 1301.5348947048187, "episode/length": 197.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 9241, "time": 1306.8814630508423, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.200623830159505, "train/action_min": 0.0, "train/action_std": 2.9551176683356366, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04455831783798203, "train/actor_opt_grad_steps": 965.0, "train/actor_opt_loss": 152.78746342069158, "train/adv_mag": 1.8438658467979014, "train/adv_max": 1.8431506034782312, "train/adv_mean": 0.038281437373183146, "train/adv_min": -0.444030626900015, "train/adv_std": 0.16075885377483626, "train/cont_avg": 0.9947001139322916, "train/cont_loss_mean": 0.014734047010582193, "train/cont_loss_std": 0.14765276625181892, "train/cont_neg_acc": 0.46862505935132504, "train/cont_neg_loss": 1.694264662402323, "train/cont_pos_acc": 0.9971904077877601, "train/cont_pos_loss": 0.006517543266416699, "train/cont_pred": 0.9922681087628007, "train/cont_rate": 0.9947001139322916, "train/dyn_loss_mean": 5.249006633336346, "train/dyn_loss_std": 7.360147493891418, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 4.61451718552659, "train/extr_critic_critic_opt_grad_steps": 965.0, "train/extr_critic_critic_opt_loss": 21046.630142211914, "train/extr_critic_mag": 0.8816289069751898, "train/extr_critic_max": 0.8816289057334264, "train/extr_critic_mean": 0.30054885857530783, "train/extr_critic_min": -0.1317045825223128, "train/extr_critic_std": 0.31559773358585375, "train/extr_return_normed_mag": 2.283346163951351, "train/extr_return_normed_max": 2.2833301741705614, "train/extr_return_normed_mean": 0.27939566665659427, "train/extr_return_normed_min": -0.3146354770186935, "train/extr_return_normed_std": 0.2643566281539606, "train/extr_return_rate": 0.22803040700163515, "train/extr_return_raw_mag": 3.6177388611891423, "train/extr_return_raw_max": 3.617738859951108, "train/extr_return_raw_mean": 0.36010550255391965, "train/extr_return_raw_min": -0.6735895118895919, "train/extr_return_raw_std": 0.48550549474894306, "train/extr_reward_mag": 0.7996474162985882, "train/extr_reward_max": 0.7996474162985882, "train/extr_reward_mean": 0.012244703944134017, "train/extr_reward_min": -0.2504669241607189, "train/extr_reward_std": 0.08230570679379134, "train/image_loss_mean": 62.44941316048304, "train/image_loss_std": 33.92908404270808, "train/model_loss_mean": 65.8459014793237, "train/model_loss_std": 35.86517858505249, "train/model_opt_grad_norm": 235.39597138809285, "train/model_opt_grad_steps": 955.0, "train/model_opt_loss": 940.6506063938141, "train/model_opt_model_opt_grad_overflow": 0.005208333333333333, "train/model_opt_model_opt_grad_scale": 14.394124348958334, "train/policy_entropy_mag": 2.277371484786272, "train/policy_entropy_max": 2.277371484786272, "train/policy_entropy_mean": 0.7741405151706809, "train/policy_entropy_min": 0.4285293908712144, "train/policy_entropy_std": 0.3468555929478801, "train/policy_logprob_mag": 7.105055135985215, "train/policy_logprob_max": -0.19350214150714842, "train/policy_logprob_mean": -0.7750610287378853, "train/policy_logprob_min": -7.105055135985215, "train/policy_logprob_std": 1.03695542163526, "train/policy_randomness_mag": 0.8038121943051616, "train/policy_randomness_max": 0.8038121943051616, "train/policy_randomness_mean": 0.2732376269220064, "train/policy_randomness_min": 0.15125206932619525, "train/policy_randomness_std": 0.12242480300968357, "train/post_ent_mag": 49.61491813262304, "train/post_ent_max": 49.61491813262304, "train/post_ent_mean": 29.512515207131703, "train/post_ent_min": 14.580551445484161, "train/post_ent_std": 6.2112178592942655, "train/prior_ent_mag": 60.932352701822914, "train/prior_ent_max": 60.932352701822914, "train/prior_ent_mean": 35.714074701070786, "train/prior_ent_min": 18.338322187463444, "train/prior_ent_std": 7.334768638402845, "train/rep_loss_mean": 5.249006633336346, "train/rep_loss_std": 7.360147493891418, "train/reward_avg": 0.009243265779938762, "train/reward_loss_mean": 0.23234908265294507, "train/reward_loss_std": 0.5007798172300681, "train/reward_max_data": 1.0, "train/reward_max_pred": 0.821844382211566, "train/reward_neg_acc": 0.9957903635998567, "train/reward_neg_loss": 0.2063441524611941, "train/reward_pos_acc": 0.685233924848338, "train/reward_pos_loss": 2.1085036378353834, "train/reward_pred": 0.007941355530419969, "train/reward_rate": 0.014170328776041666, "train_stats/sum_log_reward": 1.7595744217012792, "train_stats/max_log_achievement_collect_drink": 5.9787234042553195, "train_stats/max_log_achievement_collect_sapling": 4.0, "train_stats/max_log_achievement_collect_wood": 0.2765957446808511, "train_stats/max_log_achievement_place_plant": 0.5106382978723404, "train_stats/max_log_achievement_wake_up": 1.7659574468085106, "train_stats/mean_log_entropy": 0.991974374556795, "train_stats/max_log_achievement_eat_cow": 0.1, "train_stats/max_log_achievement_defeat_zombie": 0.11428571428571428, "train_stats/max_log_achievement_defeat_skeleton": 0.058823529411764705, "train_stats/max_log_achievement_place_table": 0.058823529411764705, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.00781963486224413, "report/cont_loss_std": 0.22644029557704926, "report/cont_neg_acc": 0.7142857313156128, "report/cont_neg_loss": 1.1388781070709229, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 3.457110142335296e-05, "report/cont_pred": 0.9946475028991699, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 6.091917991638184, "report/dyn_loss_std": 6.142416000366211, "report/image_loss_mean": 18.220260620117188, "report/image_loss_std": 15.069252014160156, "report/model_loss_mean": 21.97403907775879, "report/model_loss_std": 17.177366256713867, "report/post_ent_mag": 47.837825775146484, "report/post_ent_max": 47.837825775146484, "report/post_ent_mean": 26.95758056640625, "report/post_ent_min": 11.055728912353516, "report/post_ent_std": 5.798973560333252, "report/prior_ent_mag": 59.982078552246094, "report/prior_ent_max": 59.982078552246094, "report/prior_ent_mean": 32.683494567871094, "report/prior_ent_min": 14.965527534484863, "report/prior_ent_std": 8.0357084274292, "report/rep_loss_mean": 6.091917991638184, "report/rep_loss_std": 6.142416000366211, "report/reward_avg": 0.01152343675494194, "report/reward_loss_mean": 0.09080943465232849, "report/reward_loss_std": 0.3689069449901581, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0011787414550781, "report/reward_neg_acc": 0.9950249195098877, "report/reward_neg_loss": 0.07073431462049484, "report/reward_pos_acc": 0.8947368264198303, "report/reward_pos_loss": 1.1526775360107422, "report/reward_pred": 0.00991660077124834, "report/reward_rate": 0.0185546875, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.01535556185990572, "eval/cont_loss_std": 0.2762579321861267, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.098862648010254, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0004187135782558471, "eval/cont_pred": 0.9996205568313599, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 12.185707092285156, "eval/dyn_loss_std": 10.668672561645508, "eval/image_loss_mean": 39.189422607421875, "eval/image_loss_std": 49.272239685058594, "eval/model_loss_mean": 46.659420013427734, "eval/model_loss_std": 51.52739334106445, "eval/post_ent_mag": 49.515586853027344, "eval/post_ent_max": 49.515586853027344, "eval/post_ent_mean": 27.445158004760742, "eval/post_ent_min": 9.392059326171875, "eval/post_ent_std": 7.330490589141846, "eval/prior_ent_mag": 59.982078552246094, "eval/prior_ent_max": 59.982078552246094, "eval/prior_ent_mean": 32.360103607177734, "eval/prior_ent_min": 12.558170318603516, "eval/prior_ent_std": 8.039416313171387, "eval/rep_loss_mean": 12.185707092285156, "eval/rep_loss_std": 10.668672561645508, "eval/reward_avg": 0.008203125558793545, "eval/reward_loss_mean": 0.14321663975715637, "eval/reward_loss_std": 0.7570979595184326, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.002302885055542, "eval/reward_neg_acc": 0.9990118741989136, "eval/reward_neg_loss": 0.12718036770820618, "eval/reward_pos_acc": 0.8333333730697632, "eval/reward_pos_loss": 1.495609998703003, "eval/reward_pred": 0.006770565174520016, "eval/reward_rate": 0.01171875, "replay/size": 8737.0, "replay/inserts": 7680.0, "replay/samples": 30720.0, "replay/insert_wait_avg": 1.7238470415274302e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 1.0123709216713906e-06, "replay/sample_wait_frac": 1.0, "eval_replay/size": 3416.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 9.238719940185547e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 977.202677488327, "timer/env.step_count": 960.0, "timer/env.step_total": 99.91938757896423, "timer/env.step_frac": 0.10225042345952619, "timer/env.step_avg": 0.10408269539475441, "timer/env.step_min": 0.023903369903564453, "timer/env.step_max": 3.2613494396209717, "timer/replay._sample_count": 30720.0, "timer/replay._sample_total": 15.99628758430481, "timer/replay._sample_frac": 0.016369467616911937, "timer/replay._sample_avg": 0.0005207124864682555, "timer/replay._sample_min": 0.0003380775451660156, "timer/replay._sample_max": 0.013768672943115234, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 960.0, "timer/agent.policy_total": 16.201691150665283, "timer/agent.policy_frac": 0.016579663076965748, "timer/agent.policy_avg": 0.016876761615276337, "timer/agent.policy_min": 0.009706735610961914, "timer/agent.policy_max": 0.0491485595703125, "timer/dataset_train_count": 1920.0, "timer/dataset_train_total": 0.30159950256347656, "timer/dataset_train_frac": 0.0003086355671258169, "timer/dataset_train_avg": 0.0001570830742518107, "timer/dataset_train_min": 8.845329284667969e-05, "timer/dataset_train_max": 0.001814126968383789, "timer/agent.train_count": 1920.0, "timer/agent.train_total": 857.8105499744415, "timer/agent.train_frac": 0.8778225538424073, "timer/agent.train_avg": 0.44677632811168827, "timer/agent.train_min": 0.43148088455200195, "timer/agent.train_max": 0.9461452960968018, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4714975357055664, "timer/agent.report_frac": 0.00048249717951801105, "timer/agent.report_avg": 0.2357487678527832, "timer/agent.report_min": 0.22959423065185547, "timer/agent.report_max": 0.24190330505371094, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0040740966796875e-05, "timer/dataset_eval_frac": 3.0741566369844217e-08, "timer/dataset_eval_avg": 3.0040740966796875e-05, "timer/dataset_eval_min": 3.0040740966796875e-05, "timer/dataset_eval_max": 3.0040740966796875e-05, "fps": 7.859069422106738}
{"step": 9296, "time": 1313.2706413269043, "episode/length": 154.0, "episode/score": 2.0999999791383743, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 9392, "time": 1326.5573117733002, "episode/length": 152.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 9416, "time": 1330.94886136055, "episode/length": 35.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 10088, "time": 1430.4069097042084, "eval_episode/length": 152.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9738562091503268}
{"step": 10088, "time": 1432.0381882190704, "eval_episode/length": 154.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9935483870967742}
{"step": 10088, "time": 1433.7224867343903, "eval_episode/length": 160.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.968944099378882}
{"step": 10088, "time": 1436.4429249763489, "eval_episode/length": 189.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 10088, "time": 1438.3523216247559, "eval_episode/length": 197.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9949494949494949}
{"step": 10088, "time": 1439.884830713272, "eval_episode/length": 198.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9949748743718593}
{"step": 10088, "time": 1442.1840941905975, "eval_episode/length": 218.0, "eval_episode/score": 1.0999999791383743, "eval_episode/reward_rate": 0.9954337899543378}
{"step": 10088, "time": 1444.7921323776245, "eval_episode/length": 246.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9959514170040485}
{"step": 10136, "time": 1450.4326841831207, "episode/length": 205.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 10160, "time": 1454.720822095871, "episode/length": 162.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 10280, "time": 1470.7495369911194, "episode/length": 195.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 10424, "time": 1489.016968011856, "episode/length": 140.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9716312056737588, "episode/intrinsic_return": 0.0}
{"step": 10536, "time": 1503.8216512203217, "episode/length": 221.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 10680, "time": 1522.553944349289, "episode/length": 160.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 10800, "time": 1538.114416360855, "episode/length": 172.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 10848, "time": 1545.3337061405182, "episode/length": 203.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 11288, "time": 1598.0569052696228, "episode/length": 143.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 11488, "time": 1622.897055864334, "episode/length": 132.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9924812030075187, "episode/intrinsic_return": 0.0}
{"step": 11584, "time": 1635.6777806282043, "episode/length": 177.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 11728, "time": 1654.0378687381744, "episode/length": 148.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 11736, "time": 1656.5513970851898, "episode/length": 181.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 11760, "time": 1660.9561088085175, "episode/length": 134.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9925925925925926, "episode/intrinsic_return": 0.0}
{"step": 11912, "time": 1680.1961653232574, "episode/length": 138.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.0}
{"step": 11936, "time": 1684.5227980613708, "episode/length": 135.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9632352941176471, "episode/intrinsic_return": 0.0}
{"step": 12048, "time": 1699.2531607151031, "episode/length": 39.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.875, "episode/intrinsic_return": 0.0}
{"step": 12192, "time": 1717.565135717392, "episode/length": 53.0, "episode/score": 2.100000023841858, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 12800, "time": 1790.1223301887512, "episode/length": 163.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 12928, "time": 1806.5858726501465, "episode/length": 167.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 12936, "time": 1808.9766471385956, "episode/length": 205.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 13128, "time": 1832.9848282337189, "episode/length": 173.0, "episode/score": 2.0999999940395355, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 13264, "time": 1850.5458359718323, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 13344, "time": 1861.4252967834473, "episode/length": 161.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 13368, "time": 1865.7725043296814, "episode/length": 178.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 13408, "time": 1872.0652902126312, "episode/length": 34.0, "episode/score": 2.1000000163912773, "episode/reward_rate": 0.9142857142857143, "episode/intrinsic_return": 0.0}
{"step": 13832, "time": 1923.141310453415, "episode/length": 204.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.0}
{"step": 14288, "time": 1977.9796478748322, "episode/length": 185.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 14360, "time": 1987.941870212555, "episode/length": 177.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 14560, "time": 2013.2435388565063, "episode/length": 203.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 14632, "time": 2023.1322183609009, "episode/length": 42.0, "episode/score": 1.0999999791383743, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 14688, "time": 2031.254043340683, "episode/length": 167.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 14728, "time": 2038.0089774131775, "episode/length": 182.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 14872, "time": 2056.371507883072, "episode/length": 182.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 15064, "time": 2080.2733039855957, "episode/length": 153.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 15248, "time": 2103.140310525894, "episode/length": 85.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9418604651162791, "episode/intrinsic_return": 0.0}
{"step": 15432, "time": 2126.0868742465973, "episode/length": 99.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 15592, "time": 2146.455448627472, "episode/length": 277.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9856115107913669, "episode/intrinsic_return": 0.0}
{"step": 15608, "time": 2149.8759541511536, "episode/length": 155.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 15816, "time": 2175.8157896995544, "episode/length": 70.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9154929577464789, "episode/intrinsic_return": 0.0}
{"step": 15824, "time": 2178.311364173889, "episode/length": 94.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9473684210526315, "episode/intrinsic_return": 0.0}
{"step": 16096, "time": 2211.6476759910583, "episode/length": 175.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9659090909090909, "episode/intrinsic_return": 0.0}
{"step": 16120, "time": 2216.05308842659, "episode/length": 36.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 16136, "time": 2219.464131832123, "episode/length": 175.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9659090909090909, "episode/intrinsic_return": 0.0}
{"step": 16544, "time": 2270.028160095215, "episode/length": 208.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 16608, "time": 2279.0828890800476, "episode/length": 63.0, "episode/score": -0.8999999910593033, "episode/reward_rate": 0.984375, "episode/intrinsic_return": 0.0}
{"step": 16825, "time": 2307.119985818863, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.075394887772817, "train/action_min": 0.0, "train/action_std": 3.722632785322805, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04926344137343149, "train/actor_opt_grad_steps": 2870.0, "train/actor_opt_loss": 36.466816716093234, "train/adv_mag": 1.1940507664882316, "train/adv_max": 1.187915326426269, "train/adv_mean": 0.013980161484728798, "train/adv_min": -0.558234674274606, "train/adv_std": 0.1044940417090421, "train/cont_avg": 0.9940321180555556, "train/cont_loss_mean": 0.0005889344283329914, "train/cont_loss_std": 0.015535374418827358, "train/cont_neg_acc": 0.9797451105067339, "train/cont_neg_loss": 0.06591450297262916, "train/cont_pos_acc": 0.9999636342285803, "train/cont_pos_loss": 0.00017758597464933546, "train/cont_pred": 0.9940577606675486, "train/cont_rate": 0.9940321180555556, "train/dyn_loss_mean": 5.620741748305225, "train/dyn_loss_std": 6.717269307091122, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.4257971370030964, "train/extr_critic_critic_opt_grad_steps": 2870.0, "train/extr_critic_critic_opt_loss": 16583.39525462963, "train/extr_critic_mag": 3.129478925119632, "train/extr_critic_max": 3.129478925119632, "train/extr_critic_mean": 0.9595301089778779, "train/extr_critic_min": -0.30342837553175667, "train/extr_critic_std": 0.9952197213652273, "train/extr_return_normed_mag": 2.0874142173736816, "train/extr_return_normed_max": 2.0874142173736816, "train/extr_return_normed_mean": 0.3961635698717107, "train/extr_return_normed_min": -0.2042103000576534, "train/extr_return_normed_std": 0.35572187074277767, "train/extr_return_rate": 0.5521732664928234, "train/extr_return_raw_mag": 6.118001573300235, "train/extr_return_raw_max": 6.118001573300235, "train/extr_return_raw_mean": 1.0017736831670085, "train/extr_return_raw_min": -0.8359934750688139, "train/extr_return_raw_std": 1.0869239212343933, "train/extr_reward_mag": 1.0047611206296891, "train/extr_reward_max": 1.0047611206296891, "train/extr_reward_mean": 0.019698136552636112, "train/extr_reward_min": -0.5445517610620569, "train/extr_reward_std": 0.13032596313921863, "train/image_loss_mean": 13.248869583089515, "train/image_loss_std": 14.136699363668129, "train/model_loss_mean": 16.67226434636999, "train/model_loss_std": 16.591776237285956, "train/model_opt_grad_norm": 111.2742060706729, "train/model_opt_grad_steps": 2860.0, "train/model_opt_loss": 905.7056855701264, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 54.66683201058201, "train/policy_entropy_mag": 2.3849663835353954, "train/policy_entropy_max": 2.3849663835353954, "train/policy_entropy_mean": 0.6824258766161702, "train/policy_entropy_min": 0.07941921343090673, "train/policy_entropy_std": 0.5285236633643902, "train/policy_logprob_mag": 7.437617708135535, "train/policy_logprob_max": -0.00946239535770719, "train/policy_logprob_mean": -0.6823602706666977, "train/policy_logprob_min": -7.437617708135535, "train/policy_logprob_std": 1.1971774845526963, "train/policy_randomness_mag": 0.8417884716911922, "train/policy_randomness_max": 0.8417884716911922, "train/policy_randomness_mean": 0.24086638638582178, "train/policy_randomness_min": 0.028031497080095863, "train/policy_randomness_std": 0.1865456599407095, "train/post_ent_mag": 42.93884955512153, "train/post_ent_max": 42.93884955512153, "train/post_ent_mean": 26.688530281107262, "train/post_ent_min": 11.999815426175557, "train/post_ent_std": 5.31121689932687, "train/prior_ent_mag": 61.0681085334253, "train/prior_ent_max": 61.0681085334253, "train/prior_ent_mean": 32.74517576025907, "train/prior_ent_min": 14.191410029375994, "train/prior_ent_std": 8.34199201745331, "train/rep_loss_mean": 5.620741748305225, "train/rep_loss_std": 6.717269307091122, "train/reward_avg": 0.01253100188705262, "train/reward_loss_mean": 0.05036077541964395, "train/reward_loss_std": 0.25791722173413273, "train/reward_max_data": 1.0, "train/reward_max_pred": 1.0025535058722925, "train/reward_neg_acc": 0.9952056448926371, "train/reward_neg_loss": 0.034253367144003434, "train/reward_pos_acc": 0.9529004081216439, "train/reward_pos_loss": 0.9356717114095334, "train/reward_pred": 0.012091964775223344, "train/reward_rate": 0.017903645833333332, "train_stats/sum_log_reward": 2.5693877108243046, "train_stats/max_log_achievement_collect_drink": 3.816326530612245, "train_stats/max_log_achievement_collect_sapling": 1.3673469387755102, "train_stats/max_log_achievement_collect_wood": 0.8571428571428571, "train_stats/max_log_achievement_defeat_skeleton": 0.04081632653061224, "train_stats/max_log_achievement_defeat_zombie": 0.10204081632653061, "train_stats/max_log_achievement_eat_cow": 0.061224489795918366, "train_stats/max_log_achievement_place_plant": 1.2040816326530612, "train_stats/max_log_achievement_place_table": 0.02040816326530612, "train_stats/max_log_achievement_wake_up": 2.0408163265306123, "train_stats/mean_log_entropy": 0.6861825281259964, "eval_stats/sum_log_reward": 2.0999999195337296, "eval_stats/max_log_achievement_collect_drink": 0.625, "eval_stats/max_log_achievement_collect_sapling": 2.0, "eval_stats/max_log_achievement_collect_wood": 0.125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_place_plant": 2.0, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 2.5, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 0.004218003246933222, "report/cont_loss_std": 0.12760324776172638, "report/cont_neg_acc": 0.875, "report/cont_neg_loss": 0.5376009941101074, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.813685412344057e-05, "report/cont_pred": 0.9933236837387085, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 6.229337692260742, "report/dyn_loss_std": 7.13038969039917, "report/image_loss_mean": 11.426935195922852, "report/image_loss_std": 11.508567810058594, "report/model_loss_mean": 15.22430419921875, "report/model_loss_std": 14.36340618133545, "report/post_ent_mag": 44.81523513793945, "report/post_ent_max": 44.81523513793945, "report/post_ent_mean": 26.762798309326172, "report/post_ent_min": 10.842948913574219, "report/post_ent_std": 6.170960903167725, "report/prior_ent_mag": 63.476356506347656, "report/prior_ent_max": 63.476356506347656, "report/prior_ent_mean": 33.799415588378906, "report/prior_ent_min": 13.484088897705078, "report/prior_ent_std": 9.675435066223145, "report/rep_loss_mean": 6.229337692260742, "report/rep_loss_std": 7.13038969039917, "report/reward_avg": 0.02177734300494194, "report/reward_loss_mean": 0.055547356605529785, "report/reward_loss_std": 0.2840990424156189, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0035429000854492, "report/reward_neg_acc": 0.9949849843978882, "report/reward_neg_loss": 0.03087417036294937, "report/reward_pos_acc": 0.9629629850387573, "report/reward_pos_loss": 0.9666275382041931, "report/reward_pred": 0.019722862169146538, "report/reward_rate": 0.0263671875, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.00896433088928461, "eval/cont_loss_std": 0.18684549629688263, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 3.0595908164978027, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 6.891977477607725e-07, "eval/cont_pred": 0.9996724128723145, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 15.170548439025879, "eval/dyn_loss_std": 10.791789054870605, "eval/image_loss_mean": 32.42074203491211, "eval/image_loss_std": 40.98933029174805, "eval/model_loss_mean": 41.606666564941406, "eval/model_loss_std": 43.484649658203125, "eval/post_ent_mag": 42.343841552734375, "eval/post_ent_max": 42.343841552734375, "eval/post_ent_mean": 27.142398834228516, "eval/post_ent_min": 10.876229286193848, "eval/post_ent_std": 6.306407451629639, "eval/prior_ent_mag": 63.476356506347656, "eval/prior_ent_max": 63.476356506347656, "eval/prior_ent_mean": 34.214969635009766, "eval/prior_ent_min": 13.542710304260254, "eval/prior_ent_std": 8.564616203308105, "eval/rep_loss_mean": 15.170548439025879, "eval/rep_loss_std": 10.791789054870605, "eval/reward_avg": 0.0064453124068677425, "eval/reward_loss_mean": 0.07462557405233383, "eval/reward_loss_std": 0.6764848828315735, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.003542423248291, "eval/reward_neg_acc": 0.9990138411521912, "eval/reward_neg_loss": 0.041046131402254105, "eval/reward_pos_acc": 0.6000000238418579, "eval/reward_pos_loss": 3.479581594467163, "eval/reward_pred": 0.003438417799770832, "eval/reward_rate": 0.009765625, "replay/size": 16321.0, "replay/inserts": 7584.0, "replay/samples": 30336.0, "replay/insert_wait_avg": 1.719889510029982e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.161306207190083e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 5392.0, "eval_replay/inserts": 1976.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1893177804676627e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0132789611816406e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2219948768616, "timer/env.step_count": 948.0, "timer/env.step_total": 103.01979851722717, "timer/env.step_frac": 0.10299693372560764, "timer/env.step_avg": 0.10867067354137887, "timer/env.step_min": 0.023062467575073242, "timer/env.step_max": 2.1108553409576416, "timer/replay._sample_count": 30336.0, "timer/replay._sample_total": 15.708406448364258, "timer/replay._sample_frac": 0.01570492003657462, "timer/replay._sample_avg": 0.0005178140311301509, "timer/replay._sample_min": 0.0003674030303955078, "timer/replay._sample_max": 0.022028207778930664, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1195.0, "timer/agent.policy_total": 19.621513605117798, "timer/agent.policy_frac": 0.01961715869638862, "timer/agent.policy_avg": 0.016419676657002343, "timer/agent.policy_min": 0.009447336196899414, "timer/agent.policy_max": 0.04631304740905762, "timer/dataset_train_count": 1896.0, "timer/dataset_train_total": 0.3707234859466553, "timer/dataset_train_frac": 0.0003706412054978809, "timer/dataset_train_avg": 0.0001955292647397971, "timer/dataset_train_min": 9.226799011230469e-05, "timer/dataset_train_max": 0.0841972827911377, "timer/agent.train_count": 1896.0, "timer/agent.train_total": 844.8053648471832, "timer/agent.train_frac": 0.8446178640084676, "timer/agent.train_avg": 0.4455724498139152, "timer/agent.train_min": 0.42177844047546387, "timer/agent.train_max": 0.8862721920013428, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4742417335510254, "timer/agent.report_frac": 0.0004741364776820468, "timer/agent.report_avg": 0.2371208667755127, "timer/agent.report_min": 0.23030495643615723, "timer/agent.report_max": 0.24393677711486816, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.218650817871094e-05, "timer/dataset_eval_frac": 3.2179364524645805e-08, "timer/dataset_eval_avg": 3.218650817871094e-05, "timer/dataset_eval_min": 3.218650817871094e-05, "timer/dataset_eval_max": 3.218650817871094e-05, "fps": 7.582219853099097}
{"step": 16912, "time": 2317.0657572746277, "episode/length": 162.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 16992, "time": 2327.834290266037, "episode/length": 146.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9659863945578231, "episode/intrinsic_return": 0.0}
{"step": 17056, "time": 2336.8124306201935, "episode/length": 182.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 17312, "time": 2368.043919801712, "episode/length": 148.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9865771812080537, "episode/intrinsic_return": 0.0}
{"step": 17672, "time": 2411.4341917037964, "episode/length": 279.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9857142857142858, "episode/intrinsic_return": 0.0}
{"step": 17864, "time": 2435.3614015579224, "episode/length": 156.0, "episode/score": 1.0999999791383743, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 17872, "time": 2438.224737882614, "episode/length": 216.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 17984, "time": 2453.2064113616943, "episode/length": 38.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 18216, "time": 2481.7800517082214, "episode/length": 208.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 18272, "time": 2489.7853615283966, "episode/length": 169.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 18360, "time": 2501.6460394859314, "episode/length": 162.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 18440, "time": 2512.866405725479, "episode/length": 180.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 19128, "time": 2596.3109579086304, "episode/length": 226.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 19336, "time": 2621.871762275696, "episode/length": 168.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 19376, "time": 2628.1235480308533, "episode/length": 187.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 19520, "time": 2646.4467647075653, "episode/length": 155.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 19520, "time": 2646.4531438350677, "episode/length": 134.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9925925925925926, "episode/intrinsic_return": 0.0}
{"step": 19728, "time": 2673.798758983612, "episode/length": 188.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 19768, "time": 2680.4717111587524, "episode/length": 175.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 20056, "time": 2716.000408411026, "episode/length": 35.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 20072, "time": 2733.693763256073, "eval_episode/length": 40.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.975609756097561}
{"step": 20072, "time": 2739.2393441200256, "eval_episode/length": 137.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9927536231884058}
{"step": 20072, "time": 2739.2473990917206, "eval_episode/length": 137.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9927536231884058}
{"step": 20072, "time": 2743.0338213443756, "eval_episode/length": 149.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9933333333333333}
{"step": 20072, "time": 2744.56568980217, "eval_episode/length": 151.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9671052631578947}
{"step": 20072, "time": 2747.695663690567, "eval_episode/length": 190.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9947643979057592}
{"step": 20072, "time": 2750.6311197280884, "eval_episode/length": 34.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 20072, "time": 2752.289207458496, "eval_episode/length": 190.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9947643979057592}
{"step": 20312, "time": 2780.1054272651672, "episode/length": 305.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9901960784313726, "episode/intrinsic_return": 0.0}
{"step": 20552, "time": 2809.7386870384216, "episode/length": 146.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 20824, "time": 2843.4583644866943, "episode/length": 211.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 20872, "time": 2850.4957778453827, "episode/length": 191.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 21040, "time": 2871.5575976371765, "episode/length": 163.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 21312, "time": 2904.833635568619, "episode/length": 60.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9180327868852459, "episode/intrinsic_return": 0.0}
{"step": 21328, "time": 2908.2706351280212, "episode/length": 225.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9778761061946902, "episode/intrinsic_return": 0.0}
{"step": 21352, "time": 2912.5399923324585, "episode/length": 38.0, "episode/score": -0.9000000283122063, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 21528, "time": 2934.6975440979004, "episode/length": 183.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 21640, "time": 2949.881858587265, "episode/length": 40.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 21752, "time": 2964.9815340042114, "episode/length": 278.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.989247311827957, "episode/intrinsic_return": 0.0}
{"step": 21856, "time": 2978.4811823368073, "episode/length": 192.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 21976, "time": 2994.2318279743195, "episode/length": 80.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9382716049382716, "episode/intrinsic_return": 0.0}
{"step": 22016, "time": 3000.978362083435, "episode/length": 182.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9672131147540983, "episode/intrinsic_return": 0.0}
{"step": 22544, "time": 3064.7082059383392, "episode/length": 208.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 22880, "time": 3105.296831846237, "episode/length": 168.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 23032, "time": 3124.268675327301, "episode/length": 173.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 23416, "time": 3170.439512491226, "episode/length": 174.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 23504, "time": 3182.152867794037, "episode/length": 190.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 23560, "time": 3190.278976917267, "episode/length": 225.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 24056, "time": 3249.5935537815094, "episode/length": 274.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9854545454545455, "episode/intrinsic_return": 0.0}
{"step": 24184, "time": 3266.0304267406464, "episode/length": 204.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 24256, "time": 3275.9448747634888, "episode/length": 171.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 24312, "time": 3284.080231189728, "episode/length": 100.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9603960396039604, "episode/intrinsic_return": 0.0}
{"step": 24376, "time": 3293.0393121242523, "episode/length": 167.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 24477, "time": 3307.175434589386, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.866255760192871, "train/action_min": 0.0, "train/action_std": 3.3725574550529323, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04518270833068527, "train/actor_opt_grad_steps": 4775.0, "train/actor_opt_loss": 8.909356740109311, "train/adv_mag": 0.7240539058111608, "train/adv_max": 0.7082166226270298, "train/adv_mean": 0.00762204157922497, "train/adv_min": -0.4942473058278362, "train/adv_std": 0.07737743652736147, "train/cont_avg": 0.9941507975260416, "train/cont_loss_mean": 0.0005461964551252881, "train/cont_loss_std": 0.014881232132625636, "train/cont_neg_acc": 0.9884403944015503, "train/cont_neg_loss": 0.05167221086382057, "train/cont_pos_acc": 0.9999334588646889, "train/cont_pos_loss": 0.00023915750117753376, "train/cont_pred": 0.9941035946831107, "train/cont_rate": 0.9941507975260416, "train/dyn_loss_mean": 6.12357568492492, "train/dyn_loss_std": 7.343350701034069, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.5271906154230237, "train/extr_critic_critic_opt_grad_steps": 4775.0, "train/extr_critic_critic_opt_loss": 16786.715021769207, "train/extr_critic_mag": 4.555574436982472, "train/extr_critic_max": 4.555574436982472, "train/extr_critic_mean": 1.3003190246721108, "train/extr_critic_min": -0.3898243935157855, "train/extr_critic_std": 1.335420200911661, "train/extr_return_normed_mag": 1.6741505997876327, "train/extr_return_normed_max": 1.6741505997876327, "train/extr_return_normed_mean": 0.39016561947452527, "train/extr_return_normed_min": -0.15899703378090635, "train/extr_return_normed_std": 0.34041455419113237, "train/extr_return_rate": 0.6508630028304955, "train/extr_return_raw_mag": 6.61939978102843, "train/extr_return_raw_max": 6.61939978102843, "train/extr_return_raw_mean": 1.3313975501805544, "train/extr_return_raw_min": -0.9239669262121121, "train/extr_return_raw_std": 1.401537099853158, "train/extr_reward_mag": 1.0049292488644521, "train/extr_reward_max": 1.0049292488644521, "train/extr_reward_mean": 0.02225564798815564, "train/extr_reward_min": -0.5998443079491457, "train/extr_reward_std": 0.1449030106111119, "train/image_loss_mean": 10.887527652084827, "train/image_loss_std": 13.19285569091638, "train/model_loss_mean": 14.606356809536615, "train/model_loss_std": 16.234706789255142, "train/model_opt_grad_norm": 88.68219017982483, "train/model_opt_grad_steps": 4765.0, "train/model_opt_loss": 2925.2193495432534, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 206.70572916666666, "train/policy_entropy_mag": 2.443376981963714, "train/policy_entropy_max": 2.443376981963714, "train/policy_entropy_mean": 0.6311431606300175, "train/policy_entropy_min": 0.07938323790828387, "train/policy_entropy_std": 0.5418472395588955, "train/policy_logprob_mag": 7.438260264694691, "train/policy_logprob_max": -0.009457265958189964, "train/policy_logprob_mean": -0.6305912599588434, "train/policy_logprob_min": -7.438260264694691, "train/policy_logprob_std": 1.1572802159935236, "train/policy_randomness_mag": 0.8624048493802547, "train/policy_randomness_max": 0.8624048493802547, "train/policy_randomness_mean": 0.22276584059000015, "train/policy_randomness_min": 0.028018799319397658, "train/policy_randomness_std": 0.19124829738090435, "train/post_ent_mag": 43.11269191900889, "train/post_ent_max": 43.11269191900889, "train/post_ent_mean": 27.221904933452606, "train/post_ent_min": 12.497700666387876, "train/post_ent_std": 5.543771716455619, "train/prior_ent_mag": 64.7310118675232, "train/prior_ent_max": 64.7310118675232, "train/prior_ent_mean": 33.81562282641729, "train/prior_ent_min": 14.358312686284384, "train/prior_ent_std": 9.126529082655907, "train/rep_loss_mean": 6.12357568492492, "train/rep_loss_std": 7.343350701034069, "train/reward_avg": 0.01470235176384449, "train/reward_loss_mean": 0.04413765917221705, "train/reward_loss_std": 0.22908143435294429, "train/reward_max_data": 1.0052083345750968, "train/reward_max_pred": 1.002988708515962, "train/reward_neg_acc": 0.9959456901997328, "train/reward_neg_loss": 0.027956496802895952, "train/reward_pos_acc": 0.9671800499781966, "train/reward_pos_loss": 0.8437336819867293, "train/reward_pred": 0.014259716435238564, "train/reward_rate": 0.019927978515625, "train_stats/sum_log_reward": 2.899999956289927, "train_stats/max_log_achievement_collect_drink": 6.888888888888889, "train_stats/max_log_achievement_collect_sapling": 1.2444444444444445, "train_stats/max_log_achievement_collect_wood": 1.2666666666666666, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.022222222222222223, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_place_plant": 1.2, "train_stats/max_log_achievement_place_table": 0.24444444444444444, "train_stats/max_log_achievement_wake_up": 2.2222222222222223, "train_stats/mean_log_entropy": 0.6879359788364834, "eval_stats/sum_log_reward": 2.4749999344348907, "eval_stats/max_log_achievement_collect_drink": 4.875, "eval_stats/max_log_achievement_collect_sapling": 1.375, "eval_stats/max_log_achievement_collect_wood": 0.75, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_place_plant": 1.375, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 1.5, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 6.269641744438559e-05, "report/cont_loss_std": 0.0013507372932508588, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 7.898574403952807e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 6.261649104999378e-05, "report/cont_pred": 0.9950562119483948, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 5.204103469848633, "report/dyn_loss_std": 7.028759002685547, "report/image_loss_mean": 6.6314697265625, "report/image_loss_std": 7.499740123748779, "report/model_loss_mean": 9.788297653198242, "report/model_loss_std": 10.68092155456543, "report/post_ent_mag": 40.13913345336914, "report/post_ent_max": 40.13913345336914, "report/post_ent_mean": 27.240182876586914, "report/post_ent_min": 13.194747924804688, "report/post_ent_std": 5.978855133056641, "report/prior_ent_mag": 66.56842041015625, "report/prior_ent_max": 66.56842041015625, "report/prior_ent_mean": 32.812252044677734, "report/prior_ent_min": 17.118633270263672, "report/prior_ent_std": 8.882294654846191, "report/rep_loss_mean": 5.204103469848633, "report/rep_loss_std": 7.028759002685547, "report/reward_avg": 0.012207030318677425, "report/reward_loss_mean": 0.034303367137908936, "report/reward_loss_std": 0.17005819082260132, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0020623207092285, "report/reward_neg_acc": 0.9970208406448364, "report/reward_neg_loss": 0.019831247627735138, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.8915635943412781, "report/reward_pred": 0.01067336555570364, "report/reward_rate": 0.0166015625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.0019156537018716335, "eval/cont_loss_std": 0.04576157405972481, "eval/cont_neg_acc": 0.6666666865348816, "eval/cont_neg_loss": 0.4478246569633484, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0006054414552636445, "eval/cont_pred": 0.9973289370536804, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 20.256839752197266, "eval/dyn_loss_std": 12.871626853942871, "eval/image_loss_mean": 25.29579734802246, "eval/image_loss_std": 28.798845291137695, "eval/model_loss_mean": 37.5345344543457, "eval/model_loss_std": 32.70492935180664, "eval/post_ent_mag": 44.07514190673828, "eval/post_ent_max": 44.07514190673828, "eval/post_ent_mean": 27.547073364257812, "eval/post_ent_min": 12.198373794555664, "eval/post_ent_std": 5.77921724319458, "eval/prior_ent_mag": 66.56842041015625, "eval/prior_ent_max": 66.56842041015625, "eval/prior_ent_mean": 35.21843719482422, "eval/prior_ent_min": 13.75050163269043, "eval/prior_ent_std": 8.851794242858887, "eval/rep_loss_mean": 20.256839752197266, "eval/rep_loss_std": 12.871626853942871, "eval/reward_avg": 9.765633149072528e-05, "eval/reward_loss_mean": 0.08271785080432892, "eval/reward_loss_std": 0.5832874774932861, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.000239372253418, "eval/reward_neg_acc": 0.999018669128418, "eval/reward_neg_loss": 0.0690629854798317, "eval/reward_pos_acc": 0.6000000238418579, "eval/reward_pos_loss": 2.865577459335327, "eval/reward_pred": -0.0026128566823899746, "eval/reward_rate": 0.0048828125, "replay/size": 23973.0, "replay/inserts": 7652.0, "replay/samples": 30608.0, "replay/insert_wait_avg": 1.722272004497905e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.092824096400515e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 7248.0, "eval_replay/inserts": 1856.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2339702967939706e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.044900894165, "timer/env.step_count": 956.0, "timer/env.step_total": 99.03223037719727, "timer/env.step_frac": 0.09902778394115112, "timer/env.step_avg": 0.10359019913932768, "timer/env.step_min": 0.023580074310302734, "timer/env.step_max": 3.1578919887542725, "timer/replay._sample_count": 30608.0, "timer/replay._sample_total": 16.047078132629395, "timer/replay._sample_frac": 0.01604635763682341, "timer/replay._sample_avg": 0.0005242772521115197, "timer/replay._sample_min": 0.00034689903259277344, "timer/replay._sample_max": 0.03107142448425293, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1188.0, "timer/agent.policy_total": 19.51250457763672, "timer/agent.policy_frac": 0.01951162848807099, "timer/agent.policy_avg": 0.016424667152892862, "timer/agent.policy_min": 0.009476661682128906, "timer/agent.policy_max": 0.06784582138061523, "timer/dataset_train_count": 1913.0, "timer/dataset_train_total": 0.29375743865966797, "timer/dataset_train_frac": 0.00029374424928021943, "timer/dataset_train_avg": 0.00015355851472016098, "timer/dataset_train_min": 8.916854858398438e-05, "timer/dataset_train_max": 0.0008139610290527344, "timer/agent.train_count": 1913.0, "timer/agent.train_total": 849.306919336319, "timer/agent.train_frac": 0.8492687864084227, "timer/agent.train_avg": 0.4439659797889801, "timer/agent.train_min": 0.4330151081085205, "timer/agent.train_max": 0.6333534717559814, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47388696670532227, "timer/agent.report_frac": 0.00047386568971214007, "timer/agent.report_avg": 0.23694348335266113, "timer/agent.report_min": 0.2294294834136963, "timer/agent.report_max": 0.24445748329162598, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.765655517578125e-05, "timer/dataset_eval_frac": 2.765531342747994e-08, "timer/dataset_eval_avg": 2.765655517578125e-05, "timer/dataset_eval_min": 2.765655517578125e-05, "timer/dataset_eval_max": 2.765655517578125e-05, "fps": 7.651556727132106}
{"step": 24688, "time": 3332.7246584892273, "episode/length": 416.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9784172661870504, "episode/intrinsic_return": 0.0}
{"step": 24968, "time": 3366.708538532257, "episode/length": 175.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 25064, "time": 3379.514859199524, "episode/length": 205.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 25320, "time": 3411.5024898052216, "episode/length": 141.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 25472, "time": 3430.8270189762115, "episode/length": 151.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9605263157894737, "episode/intrinsic_return": 0.0}
{"step": 25520, "time": 3438.0287318229675, "episode/length": 182.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 25672, "time": 3457.852277994156, "episode/length": 169.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9823529411764705, "episode/intrinsic_return": 0.0}
{"step": 25968, "time": 3493.94540643692, "episode/length": 198.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9597989949748744, "episode/intrinsic_return": 0.0}
{"step": 26040, "time": 3503.814216375351, "episode/length": 168.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 26184, "time": 3522.07444524765, "episode/length": 82.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9879518072289156, "episode/intrinsic_return": 0.0}
{"step": 26464, "time": 3555.942705154419, "episode/length": 174.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 26584, "time": 3571.3665153980255, "episode/length": 138.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9496402877697842, "episode/intrinsic_return": 0.0}
{"step": 26640, "time": 3579.281806707382, "episode/length": 164.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9636363636363636, "episode/intrinsic_return": 0.0}
{"step": 26784, "time": 3597.3728885650635, "episode/length": 226.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.973568281938326, "episode/intrinsic_return": 0.0}
{"step": 27008, "time": 3625.1031637191772, "episode/length": 166.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9580838323353293, "episode/intrinsic_return": 0.0}
{"step": 27448, "time": 3677.784861803055, "episode/length": 157.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 27512, "time": 3686.8144557476044, "episode/length": 183.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 27664, "time": 3706.082888841629, "episode/length": 211.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9716981132075472, "episode/intrinsic_return": 0.0}
{"step": 27728, "time": 3715.452371120453, "episode/length": 157.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 27992, "time": 3748.155039548874, "episode/length": 168.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 28008, "time": 3751.6374242305756, "episode/length": 177.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 28520, "time": 3812.437693119049, "episode/length": 216.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 28656, "time": 3829.5437321662903, "episode/length": 150.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 29176, "time": 3891.5520079135895, "episode/length": 188.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 29240, "time": 3900.688852071762, "episode/length": 278.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.982078853046595, "episode/intrinsic_return": 0.0}
{"step": 29312, "time": 3910.610338449478, "episode/length": 224.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 29368, "time": 3918.523547410965, "episode/length": 171.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 29384, "time": 3921.870895385742, "episode/length": 171.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9651162790697675, "episode/intrinsic_return": 0.0}
{"step": 29416, "time": 3927.0930004119873, "episode/length": 210.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 29824, "time": 3975.9896149635315, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 30056, "time": 4018.4486174583435, "eval_episode/length": 37.0, "eval_episode/score": 1.0999999716877937, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 30056, "time": 4021.416316986084, "eval_episode/length": 58.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9152542372881356}
{"step": 30056, "time": 4027.5228791236877, "eval_episode/length": 148.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9664429530201343}
{"step": 30056, "time": 4029.3735938072205, "eval_episode/length": 156.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9745222929936306}
{"step": 30056, "time": 4031.2844429016113, "eval_episode/length": 162.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9938650306748467}
{"step": 30056, "time": 4032.8031771183014, "eval_episode/length": 164.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.9757575757575757}
{"step": 30056, "time": 4036.0299270153046, "eval_episode/length": 148.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9932885906040269}
{"step": 30056, "time": 4037.6390945911407, "eval_episode/length": 209.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9809523809523809}
{"step": 30096, "time": 4042.266781806946, "episode/length": 179.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 30408, "time": 4079.841825246811, "episode/length": 127.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9609375, "episode/intrinsic_return": 0.0}
{"step": 30568, "time": 4100.028720140457, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 30648, "time": 4110.732655763626, "episode/length": 183.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 31000, "time": 4153.142480134964, "episode/length": 210.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 31056, "time": 4161.124538898468, "episode/length": 210.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 31296, "time": 4190.4840223789215, "episode/length": 234.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 31392, "time": 4203.03968334198, "episode/length": 195.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 31544, "time": 4222.265548467636, "episode/length": 141.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 31656, "time": 4236.741147041321, "episode/length": 81.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9878048780487805, "episode/intrinsic_return": 0.0}
{"step": 31696, "time": 4243.042113304138, "episode/length": 199.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 31888, "time": 4267.558332443237, "episode/length": 164.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 32201, "time": 4307.234669446945, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.5200287023356545, "train/action_min": 0.0, "train/action_std": 3.145165155588654, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0424673629953608, "train/actor_opt_grad_steps": 6700.0, "train/actor_opt_loss": -11.929458788774637, "train/adv_mag": 0.632782640234794, "train/adv_max": 0.6135829608366279, "train/adv_mean": 0.003070894889415898, "train/adv_min": -0.46015100821929894, "train/adv_std": 0.06686247277213501, "train/cont_avg": 0.9940293069948186, "train/cont_loss_mean": 0.00041378717588919865, "train/cont_loss_std": 0.012078395999129797, "train/cont_neg_acc": 0.9926967688792728, "train/cont_neg_loss": 0.039006305701946076, "train/cont_pos_acc": 0.9999541479688852, "train/cont_pos_loss": 0.00014697242080994067, "train/cont_pred": 0.9940225346100763, "train/cont_rate": 0.9940293069948186, "train/dyn_loss_mean": 6.109635029432069, "train/dyn_loss_std": 7.647709802024723, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.3893363701247181, "train/extr_critic_critic_opt_grad_steps": 6700.0, "train/extr_critic_critic_opt_loss": 16079.995906533355, "train/extr_critic_mag": 5.3305482617313995, "train/extr_critic_max": 5.3305482617313995, "train/extr_critic_mean": 1.2900608583435493, "train/extr_critic_min": -0.5001660220981262, "train/extr_critic_std": 1.4403711189877801, "train/extr_return_normed_mag": 1.6340379486429877, "train/extr_return_normed_max": 1.6340379486429877, "train/extr_return_normed_mean": 0.3709732820641809, "train/extr_return_normed_min": -0.15273750133310576, "train/extr_return_normed_std": 0.3367370613343975, "train/extr_return_rate": 0.6237333664004667, "train/extr_return_raw_mag": 6.874327296420082, "train/extr_return_raw_max": 6.874327296420082, "train/extr_return_raw_mean": 1.3036207028621218, "train/extr_return_raw_min": -1.0069775204584388, "train/extr_return_raw_std": 1.4854973282838733, "train/extr_reward_mag": 1.0058311205453823, "train/extr_reward_max": 1.0058311205453823, "train/extr_reward_mean": 0.023661092247022557, "train/extr_reward_min": -0.6369840678773395, "train/extr_reward_std": 0.15243044480140963, "train/image_loss_mean": 8.151739990155313, "train/image_loss_std": 11.065208543767584, "train/model_loss_mean": 11.86094041438918, "train/model_loss_std": 14.419738507641412, "train/model_opt_grad_norm": 77.25769189231754, "train/model_opt_grad_steps": 6689.704663212436, "train/model_opt_loss": 7091.939887012225, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 605.5699481865284, "train/policy_entropy_mag": 2.5307857854378657, "train/policy_entropy_max": 2.5307857854378657, "train/policy_entropy_mean": 0.5911112580583503, "train/policy_entropy_min": 0.07937658937175039, "train/policy_entropy_std": 0.5453657665400925, "train/policy_logprob_mag": 7.438359250676447, "train/policy_logprob_max": -0.00945607664961117, "train/policy_logprob_mean": -0.5908003955925066, "train/policy_logprob_min": -7.438359250676447, "train/policy_logprob_std": 1.130087100780072, "train/policy_randomness_mag": 0.893256322707537, "train/policy_randomness_max": 0.893256322707537, "train/policy_randomness_mean": 0.20863633529509906, "train/policy_randomness_min": 0.028016452663071414, "train/policy_randomness_std": 0.19249018470858045, "train/post_ent_mag": 43.09045706635312, "train/post_ent_max": 43.09045706635312, "train/post_ent_mean": 27.45782101092561, "train/post_ent_min": 13.414667890479528, "train/post_ent_std": 5.606586191938331, "train/prior_ent_mag": 66.54603572707101, "train/prior_ent_max": 66.54603572707101, "train/prior_ent_mean": 33.89487769566669, "train/prior_ent_min": 14.859420712130058, "train/prior_ent_std": 9.371101478220885, "train/rep_loss_mean": 6.109635029432069, "train/rep_loss_std": 7.647709802024723, "train/reward_avg": 0.01555264324620559, "train/reward_loss_mean": 0.04300566671966271, "train/reward_loss_std": 0.21269428320808115, "train/reward_max_data": 1.0031088090313531, "train/reward_max_pred": 1.0032467817395463, "train/reward_neg_acc": 0.9956216608304433, "train/reward_neg_loss": 0.026846945845555765, "train/reward_pos_acc": 0.9753854765793203, "train/reward_pos_loss": 0.798866036951233, "train/reward_pred": 0.01534684656617362, "train/reward_rate": 0.020948024611398965, "train_stats/sum_log_reward": 3.766666605359032, "train_stats/max_log_achievement_collect_drink": 1.4047619047619047, "train_stats/max_log_achievement_collect_sapling": 2.1904761904761907, "train_stats/max_log_achievement_collect_wood": 1.8333333333333333, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.11904761904761904, "train_stats/max_log_achievement_eat_cow": 0.07142857142857142, "train_stats/max_log_achievement_place_plant": 2.119047619047619, "train_stats/max_log_achievement_place_table": 0.42857142857142855, "train_stats/max_log_achievement_wake_up": 2.5238095238095237, "train_stats/mean_log_entropy": 0.5697259633314042, "train_stats/max_log_achievement_make_wood_pickaxe": 0.07142857142857142, "eval_stats/sum_log_reward": 3.0999999046325684, "eval_stats/max_log_achievement_collect_drink": 1.0, "eval_stats/max_log_achievement_collect_sapling": 2.0, "eval_stats/max_log_achievement_collect_wood": 2.125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.125, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_place_plant": 1.875, "eval_stats/max_log_achievement_place_table": 0.625, "eval_stats/max_log_achievement_wake_up": 2.0, "eval_stats/mean_log_entropy": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.125, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 1.3462079095916124e-06, "report/cont_loss_std": 2.1968729924992658e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.000305991037748754, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 7.500340757360391e-07, "report/cont_pred": 0.9980468153953552, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 6.519546985626221, "report/dyn_loss_std": 8.032670021057129, "report/image_loss_mean": 6.35623836517334, "report/image_loss_std": 7.62472677230835, "report/model_loss_mean": 10.293769836425781, "report/model_loss_std": 11.52053451538086, "report/post_ent_mag": 44.57372283935547, "report/post_ent_max": 44.57372283935547, "report/post_ent_mean": 27.050649642944336, "report/post_ent_min": 13.27280044555664, "report/post_ent_std": 5.938083171844482, "report/prior_ent_mag": 66.795166015625, "report/prior_ent_max": 66.795166015625, "report/prior_ent_mean": 33.06700134277344, "report/prior_ent_min": 13.300662994384766, "report/prior_ent_std": 10.011808395385742, "report/rep_loss_mean": 6.519546985626221, "report/rep_loss_std": 8.032670021057129, "report/reward_avg": 0.02031249925494194, "report/reward_loss_mean": 0.025801651179790497, "report/reward_loss_std": 0.14215996861457825, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.002500057220459, "report/reward_neg_acc": 0.9990009665489197, "report/reward_neg_loss": 0.00803952757269144, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7988402247428894, "report/reward_pred": 0.01875414326786995, "report/reward_rate": 0.0224609375, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.001990013523027301, "eval/cont_loss_std": 0.0591462180018425, "eval/cont_neg_acc": 0.800000011920929, "eval/cont_neg_loss": 0.3897787630558014, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 8.722290658624843e-05, "eval/cont_pred": 0.9959146976470947, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 21.818004608154297, "eval/dyn_loss_std": 12.654696464538574, "eval/image_loss_mean": 27.657588958740234, "eval/image_loss_std": 32.95359802246094, "eval/model_loss_mean": 40.84947204589844, "eval/model_loss_std": 36.01932907104492, "eval/post_ent_mag": 42.740882873535156, "eval/post_ent_max": 42.740882873535156, "eval/post_ent_mean": 27.0018367767334, "eval/post_ent_min": 13.492119789123535, "eval/post_ent_std": 5.372751712799072, "eval/prior_ent_mag": 66.795166015625, "eval/prior_ent_max": 66.795166015625, "eval/prior_ent_mean": 34.04716491699219, "eval/prior_ent_min": 13.363494873046875, "eval/prior_ent_std": 9.122066497802734, "eval/rep_loss_mean": 21.818004608154297, "eval/rep_loss_std": 12.654696464538574, "eval/reward_avg": 0.0022460934706032276, "eval/reward_loss_mean": 0.09909039735794067, "eval/reward_loss_std": 0.7149360179901123, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0003280639648438, "eval/reward_neg_acc": 0.9999999403953552, "eval/reward_neg_loss": 0.07723601907491684, "eval/reward_pos_acc": 0.5714285969734192, "eval/reward_pos_loss": 3.2742199897766113, "eval/reward_pred": -0.0005056004738435149, "eval/reward_rate": 0.0068359375, "replay/size": 31697.0, "replay/inserts": 7724.0, "replay/samples": 30896.0, "replay/insert_wait_avg": 1.5606169006726954e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.859725892883333e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 8928.0, "eval_replay/inserts": 1680.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1780432292393277e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.301568984985352e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0468928813934, "timer/env.step_count": 966.0, "timer/env.step_total": 93.01964116096497, "timer/env.step_frac": 0.09301527940649998, "timer/env.step_avg": 0.09629362439023288, "timer/env.step_min": 0.023505449295043945, "timer/env.step_max": 2.1739516258239746, "timer/replay._sample_count": 30896.0, "timer/replay._sample_total": 15.301398038864136, "timer/replay._sample_frac": 0.01530068054586606, "timer/replay._sample_avg": 0.0004952549857219101, "timer/replay._sample_min": 0.00034999847412109375, "timer/replay._sample_max": 0.03472542762756348, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1176.0, "timer/agent.policy_total": 18.994949340820312, "timer/agent.policy_frac": 0.018994058654680637, "timer/agent.policy_avg": 0.016152167806819995, "timer/agent.policy_min": 0.009400367736816406, "timer/agent.policy_max": 0.10872960090637207, "timer/dataset_train_count": 1931.0, "timer/dataset_train_total": 0.39160680770874023, "timer/dataset_train_frac": 0.0003915884449982339, "timer/dataset_train_avg": 0.00020280000399209747, "timer/dataset_train_min": 8.440017700195312e-05, "timer/dataset_train_max": 0.1147305965423584, "timer/agent.train_count": 1931.0, "timer/agent.train_total": 855.1317584514618, "timer/agent.train_frac": 0.8550916607396342, "timer/agent.train_avg": 0.44284399712659855, "timer/agent.train_min": 0.4302027225494385, "timer/agent.train_max": 0.9338955879211426, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4628102779388428, "timer/agent.report_frac": 0.0004627885764490171, "timer/agent.report_avg": 0.2314051389694214, "timer/agent.report_min": 0.2210526466369629, "timer/agent.report_max": 0.24175763130187988, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.4318695068359375e-05, "timer/dataset_eval_frac": 2.4317554748148792e-08, "timer/dataset_eval_avg": 2.4318695068359375e-05, "timer/dataset_eval_min": 2.4318695068359375e-05, "timer/dataset_eval_max": 2.4318695068359375e-05, "fps": 7.723537818251371}
{"step": 32424, "time": 4333.21639418602, "episode/length": 221.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 32768, "time": 4375.616020679474, "episode/length": 183.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 32800, "time": 4381.468109369278, "episode/length": 156.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 32848, "time": 4388.593923091888, "episode/length": 181.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 32960, "time": 4403.491512775421, "episode/length": 237.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 32992, "time": 4409.146127462387, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 33216, "time": 4436.796449184418, "episode/length": 189.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 33400, "time": 4459.835519075394, "episode/length": 188.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 33720, "time": 4499.050292491913, "episode/length": 39.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 33984, "time": 4531.470170736313, "episode/length": 141.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 34112, "time": 4548.284205913544, "episode/length": 167.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 34136, "time": 4553.195441484451, "episode/length": 166.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 34272, "time": 4571.067685842514, "episode/length": 159.0, "episode/score": 5.099999964237213, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 34456, "time": 4594.007390975952, "episode/length": 253.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9803149606299213, "episode/intrinsic_return": 0.0}
{"step": 34720, "time": 4626.381850719452, "episode/length": 219.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 34888, "time": 4647.652456283569, "episode/length": 208.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 35152, "time": 4681.204748392105, "episode/length": 178.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 35280, "time": 4698.197336196899, "episode/length": 161.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 35384, "time": 4711.907772779465, "episode/length": 158.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 35528, "time": 4730.847307682037, "episode/length": 156.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 35624, "time": 4743.450445652008, "episode/length": 185.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 35704, "time": 4754.406025648117, "episode/length": 155.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 35856, "time": 4773.716595172882, "episode/length": 58.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9322033898305084, "episode/intrinsic_return": 0.0}
{"step": 36064, "time": 4799.669195890427, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 36592, "time": 4862.947208881378, "episode/length": 212.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 36600, "time": 4865.337383985519, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 36792, "time": 4889.419486522675, "episode/length": 188.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 36952, "time": 4909.629249095917, "episode/length": 110.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.954954954954955, "episode/intrinsic_return": 0.0}
{"step": 37040, "time": 4921.48460149765, "episode/length": 176.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 37072, "time": 4926.644129514694, "episode/length": 192.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 37112, "time": 4933.005745410919, "episode/length": 156.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9617834394904459, "episode/intrinsic_return": 0.0}
{"step": 37184, "time": 4942.993677377701, "episode/length": 184.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 37192, "time": 4945.444359540939, "episode/length": 29.0, "episode/score": -0.8999999761581421, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 38008, "time": 5042.340603590012, "episode/length": 175.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 38184, "time": 5064.461794137955, "episode/length": 142.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.965034965034965, "episode/intrinsic_return": 0.0}
{"step": 38288, "time": 5078.127472400665, "episode/length": 186.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 38384, "time": 5090.90940785408, "episode/length": 158.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 38424, "time": 5097.1153955459595, "episode/length": 154.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 38584, "time": 5117.418356895447, "episode/length": 188.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 38608, "time": 5121.830590009689, "episode/length": 39.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 38672, "time": 5130.984876394272, "episode/length": 184.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 38792, "time": 5147.070050239563, "episode/length": 50.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 38912, "time": 5162.612134218216, "episode/length": 289.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9862068965517241, "episode/intrinsic_return": 0.0}
{"step": 39440, "time": 5226.134806871414, "episode/length": 178.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 39776, "time": 5267.154021978378, "episode/length": 198.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.0}
{"step": 39808, "time": 5272.394601821899, "episode/length": 172.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 40040, "time": 5319.2184154987335, "eval_episode/length": 136.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9562043795620438}
{"step": 40040, "time": 5320.985454082489, "eval_episode/length": 139.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9928571428571429}
{"step": 40040, "time": 5322.66366815567, "eval_episode/length": 141.0, "eval_episode/score": 4.099999971687794, "eval_episode/reward_rate": 0.9929577464788732}
{"step": 40040, "time": 5324.895078659058, "eval_episode/length": 158.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9937106918238994}
{"step": 40040, "time": 5326.977052927017, "eval_episode/length": 172.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9710982658959537}
{"step": 40040, "time": 5328.547065258026, "eval_episode/length": 174.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 40040, "time": 5330.007158756256, "eval_episode/length": 36.0, "eval_episode/score": 0.10000000149011612, "eval_episode/reward_rate": 0.972972972972973}
{"step": 40040, "time": 5332.862334728241, "eval_episode/length": 36.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.972972972972973}
{"step": 40041, "time": 5333.877863883972, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.799583279356664, "train/action_min": 0.0, "train/action_std": 3.3847665944877936, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04309091252293818, "train/actor_opt_grad_steps": 8645.0, "train/actor_opt_loss": -10.134304751309433, "train/adv_mag": 0.6371133797326867, "train/adv_max": 0.61327028380973, "train/adv_mean": 0.0041523909441765474, "train/adv_min": -0.4741868816164075, "train/adv_std": 0.06571246769127188, "train/cont_avg": 0.9941456074617347, "train/cont_loss_mean": 0.00034260218151443636, "train/cont_loss_std": 0.009930367399138676, "train/cont_neg_acc": 0.9922039090058743, "train/cont_neg_loss": 0.038863073805702864, "train/cont_pos_acc": 0.9999448012332527, "train/cont_pos_loss": 0.00016800708170827683, "train/cont_pred": 0.9941342272320572, "train/cont_rate": 0.9941456074617347, "train/dyn_loss_mean": 6.004895001041646, "train/dyn_loss_std": 7.779289520516688, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.3889089105080585, "train/extr_critic_critic_opt_grad_steps": 8645.0, "train/extr_critic_critic_opt_loss": 16305.882598254146, "train/extr_critic_mag": 5.778499987660622, "train/extr_critic_max": 5.778499987660622, "train/extr_critic_mean": 1.2167117264197798, "train/extr_critic_min": -0.5705115010543745, "train/extr_critic_std": 1.5126686223915644, "train/extr_return_normed_mag": 1.6620674911810427, "train/extr_return_normed_max": 1.6620674911810427, "train/extr_return_normed_mean": 0.35541569821688596, "train/extr_return_normed_min": -0.16620759428383744, "train/extr_return_normed_std": 0.3435042100597401, "train/extr_return_rate": 0.5527709404728851, "train/extr_return_raw_mag": 7.169057194067507, "train/extr_return_raw_max": 7.169057194067507, "train/extr_return_raw_mean": 1.235361400459494, "train/extr_return_raw_min": -1.1337643436023168, "train/extr_return_raw_std": 1.5624445184152953, "train/extr_reward_mag": 1.0071428989877507, "train/extr_reward_max": 1.0071428989877507, "train/extr_reward_mean": 0.025020707294116824, "train/extr_reward_min": -0.6588820954974817, "train/extr_reward_std": 0.15994942401136672, "train/image_loss_mean": 6.81294990072445, "train/image_loss_std": 9.943449611566505, "train/model_loss_mean": 10.460201827847229, "train/model_loss_std": 13.43147059606046, "train/model_opt_grad_norm": 73.04792515112429, "train/model_opt_grad_steps": 8633.275510204081, "train/model_opt_loss": 8274.726604850925, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 794.0051020408164, "train/policy_entropy_mag": 2.5377792934982146, "train/policy_entropy_max": 2.5377792934982146, "train/policy_entropy_mean": 0.635764871628917, "train/policy_entropy_min": 0.07937550263441338, "train/policy_entropy_std": 0.6383858256194056, "train/policy_logprob_mag": 7.438376747832006, "train/policy_logprob_max": -0.009455824019007233, "train/policy_logprob_mean": -0.6359510344206071, "train/policy_logprob_min": -7.438376747832006, "train/policy_logprob_std": 1.1766523274840142, "train/policy_randomness_mag": 0.8957247220131815, "train/policy_randomness_max": 0.8957247220131815, "train/policy_randomness_mean": 0.2243970992157654, "train/policy_randomness_min": 0.02801606916271302, "train/policy_randomness_std": 0.22532218261336795, "train/post_ent_mag": 43.07537462273422, "train/post_ent_max": 43.07537462273422, "train/post_ent_mean": 27.43759353793397, "train/post_ent_min": 13.70319304660875, "train/post_ent_std": 5.570435212582958, "train/prior_ent_mag": 67.61140776653679, "train/prior_ent_max": 67.61140776653679, "train/prior_ent_mean": 33.67047212561783, "train/prior_ent_min": 15.187179691937505, "train/prior_ent_std": 9.400648988023097, "train/rep_loss_mean": 6.004895001041646, "train/rep_loss_std": 7.779289520516688, "train/reward_avg": 0.017121731346397072, "train/reward_loss_mean": 0.04397231336607008, "train/reward_loss_std": 0.21670765384119384, "train/reward_max_data": 1.002551021016374, "train/reward_max_pred": 1.0039153433575922, "train/reward_neg_acc": 0.9956520929628488, "train/reward_neg_loss": 0.026359890597131178, "train/reward_pos_acc": 0.9732550467763629, "train/reward_pos_loss": 0.8095424731775206, "train/reward_pred": 0.01674969935770698, "train/reward_rate": 0.02247588488520408, "train_stats/sum_log_reward": 4.0565216641711155, "train_stats/max_log_achievement_collect_drink": 3.260869565217391, "train_stats/max_log_achievement_collect_sapling": 1.8478260869565217, "train_stats/max_log_achievement_collect_wood": 2.4347826086956523, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.06521739130434782, "train_stats/max_log_achievement_eat_cow": 0.043478260869565216, "train_stats/max_log_achievement_make_wood_pickaxe": 0.10869565217391304, "train_stats/max_log_achievement_make_wood_sword": 0.021739130434782608, "train_stats/max_log_achievement_place_plant": 1.8478260869565217, "train_stats/max_log_achievement_place_table": 0.9347826086956522, "train_stats/max_log_achievement_wake_up": 2.217391304347826, "train_stats/mean_log_entropy": 0.6339975848146107, "eval_stats/sum_log_reward": 3.224999975413084, "eval_stats/max_log_achievement_collect_drink": 2.625, "eval_stats/max_log_achievement_collect_sapling": 1.875, "eval_stats/max_log_achievement_collect_wood": 1.625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 1.875, "eval_stats/max_log_achievement_place_table": 0.5, "eval_stats/max_log_achievement_wake_up": 1.625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 5.340624284144724e-06, "report/cont_loss_std": 0.0001044518721755594, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00031110335839912295, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 4.14155420003226e-06, "report/cont_pred": 0.9960909485816956, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 5.437835693359375, "report/dyn_loss_std": 7.409029483795166, "report/image_loss_mean": 5.6081647872924805, "report/image_loss_std": 7.319141864776611, "report/model_loss_mean": 8.901143074035645, "report/model_loss_std": 10.742297172546387, "report/post_ent_mag": 41.947731018066406, "report/post_ent_max": 41.947731018066406, "report/post_ent_mean": 27.08234405517578, "report/post_ent_min": 14.32020378112793, "report/post_ent_std": 5.064769744873047, "report/prior_ent_mag": 67.6683578491211, "report/prior_ent_max": 67.6683578491211, "report/prior_ent_mean": 33.236167907714844, "report/prior_ent_min": 15.860433578491211, "report/prior_ent_std": 8.663084983825684, "report/rep_loss_mean": 5.437835693359375, "report/rep_loss_std": 7.409029483795166, "report/reward_avg": 0.01113281212747097, "report/reward_loss_mean": 0.03027215786278248, "report/reward_loss_std": 0.13802684843540192, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0046172142028809, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.020056037232279778, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6738879084587097, "report/reward_pred": 0.011573327705264091, "report/reward_rate": 0.015625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 2.4184733774745837e-05, "eval/cont_loss_std": 0.0004407509695738554, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.004118354059755802, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.2154850992374122e-05, "eval/cont_pred": 0.9970703125, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 22.093238830566406, "eval/dyn_loss_std": 14.566377639770508, "eval/image_loss_mean": 23.96651840209961, "eval/image_loss_std": 26.32625961303711, "eval/model_loss_mean": 37.35729217529297, "eval/model_loss_std": 32.37314224243164, "eval/post_ent_mag": 45.677757263183594, "eval/post_ent_max": 45.677757263183594, "eval/post_ent_mean": 27.08263397216797, "eval/post_ent_min": 14.606210708618164, "eval/post_ent_std": 5.49812650680542, "eval/prior_ent_mag": 67.6683578491211, "eval/prior_ent_max": 67.6683578491211, "eval/prior_ent_mean": 36.80124282836914, "eval/prior_ent_min": 15.421977996826172, "eval/prior_ent_std": 9.83931827545166, "eval/rep_loss_mean": 22.093238830566406, "eval/rep_loss_std": 14.566377639770508, "eval/reward_avg": 0.00439453125, "eval/reward_loss_mean": 0.1348080188035965, "eval/reward_loss_std": 0.8760769367218018, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0010194778442383, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.10857801884412766, "eval/reward_pos_acc": 0.6666666865348816, "eval/reward_pos_loss": 3.0929689407348633, "eval/reward_pred": 0.001779578858986497, "eval/reward_rate": 0.0087890625, "replay/size": 39537.0, "replay/inserts": 7840.0, "replay/samples": 31360.0, "replay/insert_wait_avg": 1.5486563955034529e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.667863855556565e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 10608.0, "eval_replay/inserts": 1680.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2753974823724657e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.748603820800781e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1026.6275985240936, "timer/env.step_count": 980.0, "timer/env.step_total": 98.8493173122406, "timer/env.step_frac": 0.09628546656484682, "timer/env.step_avg": 0.10086665031861286, "timer/env.step_min": 0.023375272750854492, "timer/env.step_max": 2.1428213119506836, "timer/replay._sample_count": 31360.0, "timer/replay._sample_total": 16.55481719970703, "timer/replay._sample_frac": 0.016125435575184872, "timer/replay._sample_avg": 0.000527895956623311, "timer/replay._sample_min": 0.0003707408905029297, "timer/replay._sample_max": 0.012006759643554688, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1190.0, "timer/agent.policy_total": 19.350306272506714, "timer/agent.policy_frac": 0.018848418160903928, "timer/agent.policy_avg": 0.016260761573535055, "timer/agent.policy_min": 0.009534597396850586, "timer/agent.policy_max": 0.04260659217834473, "timer/dataset_train_count": 1960.0, "timer/dataset_train_total": 0.30022287368774414, "timer/dataset_train_frac": 0.00029243600514865595, "timer/dataset_train_avg": 0.0001531749355549715, "timer/dataset_train_min": 9.560585021972656e-05, "timer/dataset_train_max": 0.0012359619140625, "timer/agent.train_count": 1960.0, "timer/agent.train_total": 876.5443952083588, "timer/agent.train_frac": 0.8538094986619312, "timer/agent.train_avg": 0.44721652816753, "timer/agent.train_min": 0.4338839054107666, "timer/agent.train_max": 0.9433438777923584, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4738445281982422, "timer/agent.report_frac": 0.00046155444182433177, "timer/agent.report_avg": 0.2369222640991211, "timer/agent.report_min": 0.2284078598022461, "timer/agent.report_max": 0.2454366683959961, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.86102294921875e-05, "timer/dataset_eval_frac": 2.7868167126344846e-08, "timer/dataset_eval_avg": 2.86102294921875e-05, "timer/dataset_eval_min": 2.86102294921875e-05, "timer/dataset_eval_max": 2.86102294921875e-05, "fps": 7.636555025270833}
{"step": 40120, "time": 5342.960520267487, "episode/length": 188.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 40216, "time": 5355.774734258652, "episode/length": 162.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 40280, "time": 5364.759741306305, "episode/length": 200.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 40808, "time": 5428.173907995224, "episode/length": 73.0, "episode/score": 2.100000023841858, "episode/reward_rate": 0.9864864864864865, "episode/intrinsic_return": 0.0}
{"step": 40832, "time": 5432.555798768997, "episode/length": 173.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 40912, "time": 5443.462474107742, "episode/length": 141.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 40968, "time": 5452.550043821335, "episode/length": 271.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9816176470588235, "episode/intrinsic_return": 0.0}
{"step": 40984, "time": 5455.905019760132, "episode/length": 146.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 41224, "time": 5485.535567998886, "episode/length": 38.0, "episode/score": 2.100000023841858, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 41448, "time": 5513.474400758743, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 41720, "time": 5546.866185426712, "episode/length": 179.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 41944, "time": 5574.523591518402, "episode/length": 141.0, "episode/score": 3.100000023841858, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 42040, "time": 5587.267524957657, "episode/length": 431.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 42312, "time": 5620.802747249603, "episode/length": 167.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 42512, "time": 5645.8829433918, "episode/length": 209.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 42640, "time": 5662.399426937103, "episode/length": 148.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 42688, "time": 5669.560116529465, "episode/length": 182.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 42728, "time": 5675.801739454269, "episode/length": 217.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 43152, "time": 5727.000777244568, "episode/length": 138.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9712230215827338, "episode/intrinsic_return": 0.0}
{"step": 43496, "time": 5768.757766246796, "episode/length": 193.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 43576, "time": 5779.644896745682, "episode/length": 157.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 43768, "time": 5803.744645833969, "episode/length": 140.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 43840, "time": 5813.651419878006, "episode/length": 264.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 43880, "time": 5819.877469062805, "episode/length": 170.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 43896, "time": 5823.215759515762, "episode/length": 150.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 44008, "time": 5837.822189331055, "episode/length": 13.0, "episode/score": 1.100000023841858, "episode/reward_rate": 0.9285714285714286, "episode/intrinsic_return": 0.0}
{"step": 44184, "time": 5859.844963788986, "episode/length": 181.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 44320, "time": 5877.237123012543, "episode/length": 145.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.958904109589041, "episode/intrinsic_return": 0.0}
{"step": 44656, "time": 5918.236168146133, "episode/length": 144.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 44928, "time": 5951.709141731262, "episode/length": 144.0, "episode/score": 5.100000038743019, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 44984, "time": 5959.742497205734, "episode/length": 142.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 44984, "time": 5959.749519109726, "episode/length": 121.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9508196721311475, "episode/intrinsic_return": 0.0}
{"step": 45168, "time": 5984.400156736374, "episode/length": 198.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 45432, "time": 6016.729422330856, "episode/length": 138.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.0}
{"step": 45592, "time": 6036.823795795441, "episode/length": 213.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 45752, "time": 6057.0542232990265, "episode/length": 39.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 46248, "time": 6116.498734474182, "episode/length": 198.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 46312, "time": 6125.450776815414, "episode/length": 165.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 46376, "time": 6134.461469173431, "episode/length": 273.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9854014598540146, "episode/intrinsic_return": 0.0}
{"step": 46504, "time": 6151.484888553619, "episode/length": 189.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 46536, "time": 6157.228479623795, "episode/length": 170.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 46800, "time": 6189.759567737579, "episode/length": 130.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9923664122137404, "episode/intrinsic_return": 0.0}
{"step": 46808, "time": 6192.364310503006, "episode/length": 234.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 47072, "time": 6224.858278036118, "episode/length": 32.0, "episode/score": -0.8999999910593033, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 47680, "time": 6297.176377296448, "episode/length": 178.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 47728, "time": 6304.238896608353, "episode/length": 176.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 47736, "time": 6306.754354000092, "episode/length": 267.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.996268656716418, "episode/intrinsic_return": 0.0}
{"step": 47949, "time": 6333.88218998909, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.069164295486992, "train/action_min": 0.0, "train/action_std": 3.7599973109772966, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04115773085032018, "train/actor_opt_grad_steps": 10610.0, "train/actor_opt_loss": -17.72344147024421, "train/adv_mag": 0.6423622767634803, "train/adv_max": 0.6058540882798016, "train/adv_mean": 0.0014245696158450023, "train/adv_min": -0.5060924957246344, "train/adv_std": 0.061772557022759154, "train/cont_avg": 0.9941901967005076, "train/cont_loss_mean": 0.00012567578795957682, "train/cont_loss_std": 0.003621376973963432, "train/cont_neg_acc": 0.999271137373788, "train/cont_neg_loss": 0.003532909446471886, "train/cont_pos_acc": 0.9999550659644422, "train/cont_pos_loss": 0.00010379894396430758, "train/cont_pred": 0.9941494201645633, "train/cont_rate": 0.9941901967005076, "train/dyn_loss_mean": 5.8556353840126, "train/dyn_loss_std": 7.905452970320804, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.2866562090549372, "train/extr_critic_critic_opt_grad_steps": 10610.0, "train/extr_critic_critic_opt_loss": 15864.079270106282, "train/extr_critic_mag": 6.218211980035463, "train/extr_critic_max": 6.218211980035463, "train/extr_critic_mean": 1.1120796515251778, "train/extr_critic_min": -0.6253114962940893, "train/extr_critic_std": 1.5162875113753498, "train/extr_return_normed_mag": 1.6695137520126886, "train/extr_return_normed_max": 1.6695137520126886, "train/extr_return_normed_mean": 0.33255406790578423, "train/extr_return_normed_min": -0.14959360581591044, "train/extr_return_normed_std": 0.3394072728259914, "train/extr_return_rate": 0.5116328544120499, "train/extr_return_raw_mag": 7.221901586213088, "train/extr_return_raw_max": 7.221901586213088, "train/extr_return_raw_mean": 1.1186596675572662, "train/extr_return_raw_min": -1.0850750292618263, "train/extr_return_raw_std": 1.5514957932046223, "train/extr_reward_mag": 1.005900121582341, "train/extr_reward_max": 1.005900121582341, "train/extr_reward_mean": 0.02447563941179193, "train/extr_reward_min": -0.6836869450390036, "train/extr_reward_std": 0.1601371616503309, "train/image_loss_mean": 5.916979038170751, "train/image_loss_std": 9.330423243759853, "train/model_loss_mean": 9.472653543888615, "train/model_loss_std": 12.951222543183922, "train/model_opt_grad_norm": 65.99320371017843, "train/model_opt_grad_steps": 10596.619289340102, "train/model_opt_loss": 8901.046958032599, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 932.741116751269, "train/policy_entropy_mag": 2.53171130485341, "train/policy_entropy_max": 2.53171130485341, "train/policy_entropy_mean": 0.6589631011643385, "train/policy_entropy_min": 0.07937524705973979, "train/policy_entropy_std": 0.6794021105403223, "train/policy_logprob_mag": 7.438380965121507, "train/policy_logprob_max": -0.009455708597744177, "train/policy_logprob_mean": -0.6589862643764709, "train/policy_logprob_min": -7.438380965121507, "train/policy_logprob_std": 1.1876710163155182, "train/policy_randomness_mag": 0.8935829915371037, "train/policy_randomness_max": 0.8935829915371037, "train/policy_randomness_mean": 0.23258505701111054, "train/policy_randomness_min": 0.028015978946374153, "train/policy_randomness_std": 0.2397991318993157, "train/post_ent_mag": 43.90388872175652, "train/post_ent_max": 43.90388872175652, "train/post_ent_mean": 27.866904011837722, "train/post_ent_min": 14.166827623009077, "train/post_ent_std": 5.666618448828682, "train/prior_ent_mag": 68.68998853809337, "train/prior_ent_max": 68.68998853809337, "train/prior_ent_mean": 33.87116453490282, "train/prior_ent_min": 15.690206092021187, "train/prior_ent_std": 9.50680422419824, "train/rep_loss_mean": 5.8556353840126, "train/rep_loss_std": 7.905452970320804, "train/reward_avg": 0.018165549509189454, "train/reward_loss_mean": 0.042167585910425576, "train/reward_loss_std": 0.20817141423975755, "train/reward_max_data": 1.0040609146737811, "train/reward_max_pred": 1.0037079335469279, "train/reward_neg_acc": 0.9961319586952325, "train/reward_neg_loss": 0.024211462556389233, "train/reward_pos_acc": 0.9780166778467634, "train/reward_pos_loss": 0.7881145667908761, "train/reward_pred": 0.01776538105199331, "train/reward_rate": 0.023482114530456854, "train_stats/sum_log_reward": 3.63191483375874, "train_stats/max_log_achievement_collect_drink": 3.978723404255319, "train_stats/max_log_achievement_collect_sapling": 2.0, "train_stats/max_log_achievement_collect_wood": 1.7659574468085106, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.06382978723404255, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.02127659574468085, "train_stats/max_log_achievement_make_wood_sword": 0.02127659574468085, "train_stats/max_log_achievement_place_plant": 1.9574468085106382, "train_stats/max_log_achievement_place_table": 0.5531914893617021, "train_stats/max_log_achievement_wake_up": 2.5319148936170213, "train_stats/mean_log_entropy": 0.608368787993776, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.00029103882843628526, "report/cont_loss_std": 0.00619468092918396, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0003429777571000159, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0002908351307269186, "report/cont_pred": 0.9958238005638123, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 7.214785575866699, "report/dyn_loss_std": 8.920218467712402, "report/image_loss_mean": 7.030462265014648, "report/image_loss_std": 11.796719551086426, "report/model_loss_mean": 11.40388298034668, "report/model_loss_std": 16.24273681640625, "report/post_ent_mag": 45.7236328125, "report/post_ent_max": 45.7236328125, "report/post_ent_mean": 27.77444839477539, "report/post_ent_min": 14.715543746948242, "report/post_ent_std": 5.67991828918457, "report/prior_ent_mag": 69.98587799072266, "report/prior_ent_max": 69.98587799072266, "report/prior_ent_mean": 34.27997589111328, "report/prior_ent_min": 17.669578552246094, "report/prior_ent_std": 10.36417007446289, "report/rep_loss_mean": 7.214785575866699, "report/rep_loss_std": 8.920218467712402, "report/reward_avg": 0.0166015625, "report/reward_loss_mean": 0.044257503002882004, "report/reward_loss_std": 0.22552645206451416, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0021262168884277, "report/reward_neg_acc": 0.9920159578323364, "report/reward_neg_loss": 0.030189061537384987, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.685011088848114, "report/reward_pred": 0.0177658312022686, "report/reward_rate": 0.021484375, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.0008866370772011578, "eval/cont_loss_std": 0.027584591880440712, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.006223821081221104, "eval/cont_pos_acc": 0.999020516872406, "eval/cont_pos_loss": 0.0008709548856131732, "eval/cont_pred": 0.9965096712112427, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 20.075977325439453, "eval/dyn_loss_std": 12.558967590332031, "eval/image_loss_mean": 25.648469924926758, "eval/image_loss_std": 28.770553588867188, "eval/model_loss_mean": 37.7723503112793, "eval/model_loss_std": 33.67749786376953, "eval/post_ent_mag": 45.975624084472656, "eval/post_ent_max": 45.975624084472656, "eval/post_ent_mean": 30.0148868560791, "eval/post_ent_min": 13.013307571411133, "eval/post_ent_std": 6.281081199645996, "eval/prior_ent_mag": 69.98587799072266, "eval/prior_ent_max": 69.98587799072266, "eval/prior_ent_mean": 39.05752944946289, "eval/prior_ent_min": 14.649534225463867, "eval/prior_ent_std": 9.938913345336914, "eval/rep_loss_mean": 20.075977325439453, "eval/rep_loss_std": 12.558967590332031, "eval/reward_avg": 0.009570312686264515, "eval/reward_loss_mean": 0.07740812003612518, "eval/reward_loss_std": 0.6708033084869385, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.000450849533081, "eval/reward_neg_acc": 0.9999999403953552, "eval/reward_neg_loss": 0.020695416256785393, "eval/reward_pos_acc": 0.46153849363327026, "eval/reward_pos_loss": 4.487911224365234, "eval/reward_pred": 0.0006748266750946641, "eval/reward_rate": 0.0126953125, "replay/size": 47445.0, "replay/inserts": 7908.0, "replay/samples": 31632.0, "replay/insert_wait_avg": 1.5788748822672897e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.736091970734121e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 10608.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 8.493661880493164e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 999.9930481910706, "timer/env.step_count": 988.0, "timer/env.step_total": 98.15665221214294, "timer/env.step_frac": 0.09815733458317799, "timer/env.step_avg": 0.09934883827139974, "timer/env.step_min": 0.02294015884399414, "timer/env.step_max": 3.244340181350708, "timer/replay._sample_count": 31632.0, "timer/replay._sample_total": 16.875545263290405, "timer/replay._sample_frac": 0.016875662579672216, "timer/replay._sample_avg": 0.0005334959934019475, "timer/replay._sample_min": 0.00037407875061035156, "timer/replay._sample_max": 0.028609275817871094, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 988.0, "timer/agent.policy_total": 16.11668086051941, "timer/agent.policy_frac": 0.016116792901384215, "timer/agent.policy_avg": 0.016312430020768633, "timer/agent.policy_min": 0.009884834289550781, "timer/agent.policy_max": 0.09047222137451172, "timer/dataset_train_count": 1977.0, "timer/dataset_train_total": 0.3015170097351074, "timer/dataset_train_frac": 0.0003015191058383198, "timer/dataset_train_avg": 0.00015251239743809176, "timer/dataset_train_min": 9.1552734375e-05, "timer/dataset_train_max": 0.0010745525360107422, "timer/agent.train_count": 1977.0, "timer/agent.train_total": 882.2327992916107, "timer/agent.train_frac": 0.8822389324480993, "timer/agent.train_avg": 0.44624825457339945, "timer/agent.train_min": 0.43561768531799316, "timer/agent.train_max": 0.9936633110046387, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47748613357543945, "timer/agent.report_frac": 0.0004774894529908825, "timer/agent.report_avg": 0.23874306678771973, "timer/agent.report_min": 0.23221540451049805, "timer/agent.report_max": 0.2452707290649414, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.6226043701171875e-05, "timer/dataset_eval_frac": 2.6226226020884112e-08, "timer/dataset_eval_avg": 2.6226043701171875e-05, "timer/dataset_eval_min": 2.6226043701171875e-05, "timer/dataset_eval_max": 2.6226043701171875e-05, "fps": 7.907943390846179}
{"step": 47960, "time": 6335.087050914764, "episode/length": 181.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9835164835164835, "episode/intrinsic_return": 0.0}
{"step": 48080, "time": 6350.655303478241, "episode/length": 192.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 48176, "time": 6363.3828003406525, "episode/length": 224.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 48248, "time": 6373.300655841827, "episode/length": 146.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 48800, "time": 6439.59886264801, "episode/length": 249.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 48816, "time": 6443.034177780151, "episode/length": 141.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 48880, "time": 6451.961347818375, "episode/length": 143.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 49024, "time": 6470.445663452148, "episode/length": 160.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 49408, "time": 6517.864680767059, "episode/length": 180.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9668508287292817, "episode/intrinsic_return": 0.0}
{"step": 49704, "time": 6553.907087087631, "episode/length": 181.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 49912, "time": 6579.657477140427, "episode/length": 228.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 50024, "time": 6594.277770519257, "episode/length": 142.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 50024, "time": 6608.5630168914795, "eval_episode/length": 54.0, "eval_episode/score": 3.100000001490116, "eval_episode/reward_rate": 0.9272727272727272}
{"step": 50024, "time": 6611.055338144302, "eval_episode/length": 75.0, "eval_episode/score": 4.100000016391277, "eval_episode/reward_rate": 0.9605263157894737}
{"step": 50024, "time": 6612.859971284866, "eval_episode/length": 82.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9397590361445783}
{"step": 50024, "time": 6616.076579332352, "eval_episode/length": 45.0, "eval_episode/score": 3.0999999940395355, "eval_episode/reward_rate": 0.9782608695652174}
{"step": 50024, "time": 6618.19863319397, "eval_episode/length": 135.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9926470588235294}
{"step": 50024, "time": 6620.096098899841, "eval_episode/length": 144.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.993103448275862}
{"step": 50024, "time": 6622.287632465363, "eval_episode/length": 160.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9627329192546584}
{"step": 50024, "time": 6623.911796808243, "eval_episode/length": 42.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9767441860465116}
{"step": 50112, "time": 6635.717282533646, "episode/length": 163.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 50128, "time": 6639.504458665848, "episode/length": 243.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 50136, "time": 6642.466407060623, "episode/length": 164.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 50552, "time": 6692.968022346497, "episode/length": 190.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 50840, "time": 6728.231274366379, "episode/length": 178.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 51208, "time": 6772.596208572388, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 51488, "time": 6806.629077196121, "episode/length": 222.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.0}
{"step": 51624, "time": 6823.906177997589, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 51656, "time": 6829.015443325043, "episode/length": 203.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 51968, "time": 6866.787184000015, "episode/length": 231.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.978448275862069, "episode/intrinsic_return": 0.0}
{"step": 52160, "time": 6890.529263019562, "episode/length": 164.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 52336, "time": 6912.532356023788, "episode/length": 140.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 52360, "time": 6916.785318613052, "episode/length": 278.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.974910394265233, "episode/intrinsic_return": 0.0}
{"step": 52408, "time": 6923.822610378265, "episode/length": 231.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 53000, "time": 6993.957186222076, "episode/length": 171.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 53040, "time": 7000.172564506531, "episode/length": 172.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 53064, "time": 7004.445767879486, "episode/length": 196.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 53472, "time": 7053.341288328171, "episode/length": 141.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 53600, "time": 7069.680638551712, "episode/length": 203.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 53720, "time": 7085.03576540947, "episode/length": 169.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9588235294117647, "episode/intrinsic_return": 0.0}
{"step": 53920, "time": 7109.7512810230255, "episode/length": 188.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 53976, "time": 7117.775633573532, "episode/length": 226.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 54200, "time": 7145.252698421478, "episode/length": 144.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 54264, "time": 7154.314037561417, "episode/length": 35.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.8888888888888888, "episode/intrinsic_return": 0.0}
{"step": 54272, "time": 7156.730329990387, "episode/length": 158.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 54400, "time": 7173.000196695328, "episode/length": 166.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9640718562874252, "episode/intrinsic_return": 0.0}
{"step": 54840, "time": 7225.589858055115, "episode/length": 139.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 54904, "time": 7234.481355190277, "episode/length": 178.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 54984, "time": 7245.2570724487305, "episode/length": 132.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9924812030075187, "episode/intrinsic_return": 0.0}
{"step": 55368, "time": 7291.457582235336, "episode/length": 136.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9927007299270073, "episode/intrinsic_return": 0.0}
{"step": 55384, "time": 7294.79042506218, "episode/length": 222.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9820627802690582, "episode/intrinsic_return": 0.0}
{"step": 55608, "time": 7322.333611488342, "episode/length": 150.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9536423841059603, "episode/intrinsic_return": 0.0}
{"step": 55656, "time": 7330.041483402252, "episode/length": 83.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9880952380952381, "episode/intrinsic_return": 0.0}
{"step": 55665, "time": 7333.931724309921, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.732242564463244, "train/action_min": 0.0, "train/action_std": 3.372159141332992, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04658473155659097, "train/actor_opt_grad_steps": 12560.0, "train/actor_opt_loss": -13.104948170521716, "train/adv_mag": 0.6364436388942244, "train/adv_max": 0.612239923038631, "train/adv_mean": 0.0028019461530388013, "train/adv_min": -0.49621267547261527, "train/adv_std": 0.06686048321618936, "train/cont_avg": 0.9943531411917098, "train/cont_loss_mean": 0.00014236275250048485, "train/cont_loss_std": 0.003909950978054251, "train/cont_neg_acc": 0.9993523316062176, "train/cont_neg_loss": 0.0037539802950479046, "train/cont_pos_acc": 0.9999694299203744, "train/cont_pos_loss": 0.00011962591545081043, "train/cont_pred": 0.9943261205223558, "train/cont_rate": 0.9943531411917098, "train/dyn_loss_mean": 5.844354636928578, "train/dyn_loss_std": 7.9648117673211765, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.3710914028740917, "train/extr_critic_critic_opt_grad_steps": 12560.0, "train/extr_critic_critic_opt_loss": 16260.920463285298, "train/extr_critic_mag": 5.9184954524657885, "train/extr_critic_max": 5.9184954524657885, "train/extr_critic_mean": 0.9423281063996448, "train/extr_critic_min": -0.6451914446341559, "train/extr_critic_std": 1.3461657694584348, "train/extr_return_normed_mag": 1.7442796187079632, "train/extr_return_normed_max": 1.7442796187079632, "train/extr_return_normed_mean": 0.3324497373764997, "train/extr_return_normed_min": -0.17047776399575984, "train/extr_return_normed_std": 0.336862422796111, "train/extr_return_rate": 0.4988467055590042, "train/extr_return_raw_mag": 6.7530369560953245, "train/extr_return_raw_max": 6.7530369560953245, "train/extr_return_raw_mean": 0.9538036754711922, "train/extr_return_raw_min": -1.1108909230775783, "train/extr_return_raw_std": 1.383703574615439, "train/extr_reward_mag": 1.006887747216101, "train/extr_reward_max": 1.006887747216101, "train/extr_reward_mean": 0.02392670979308341, "train/extr_reward_min": -0.672847004752085, "train/extr_reward_std": 0.15878925866259194, "train/image_loss_mean": 5.56225938500518, "train/image_loss_std": 9.38327564970817, "train/model_loss_mean": 9.110280738593383, "train/model_loss_std": 13.02336644879277, "train/model_opt_grad_norm": 63.46707028799106, "train/model_opt_grad_steps": 12545.056994818653, "train/model_opt_loss": 7329.341040418556, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 796.6321243523316, "train/policy_entropy_mag": 2.54952088168248, "train/policy_entropy_max": 2.54952088168248, "train/policy_entropy_mean": 0.6379252760212656, "train/policy_entropy_min": 0.07937516453507033, "train/policy_entropy_std": 0.67535480470855, "train/policy_logprob_mag": 7.438382277216936, "train/policy_logprob_max": -0.009455674110762195, "train/policy_logprob_mean": -0.6379028859842627, "train/policy_logprob_min": -7.438382277216936, "train/policy_logprob_std": 1.1730559891369676, "train/policy_randomness_mag": 0.8998689892378495, "train/policy_randomness_max": 0.8998689892378495, "train/policy_randomness_mean": 0.2251596274771221, "train/policy_randomness_min": 0.028015949739230113, "train/policy_randomness_std": 0.23837060763119416, "train/post_ent_mag": 44.7361194630361, "train/post_ent_max": 44.7361194630361, "train/post_ent_mean": 28.288124756491865, "train/post_ent_min": 14.635625325336358, "train/post_ent_std": 5.6546380532220235, "train/prior_ent_mag": 69.33342924760413, "train/prior_ent_max": 69.33342924760413, "train/prior_ent_mean": 34.21408683895447, "train/prior_ent_min": 16.30493318725744, "train/prior_ent_std": 9.453461748330705, "train/rep_loss_mean": 5.844354636928578, "train/rep_loss_std": 7.9648117673211765, "train/reward_avg": 0.018952902208608357, "train/reward_loss_mean": 0.04126622458350473, "train/reward_loss_std": 0.20371073326144193, "train/reward_max_data": 1.003626943869912, "train/reward_max_pred": 1.003423446818337, "train/reward_neg_acc": 0.9962754626348229, "train/reward_neg_loss": 0.02326022302297576, "train/reward_pos_acc": 0.9802705602324688, "train/reward_pos_loss": 0.7697323656452753, "train/reward_pred": 0.018721114438741318, "train/reward_rate": 0.024120587759067356, "train_stats/sum_log_reward": 3.922222157319387, "train_stats/max_log_achievement_collect_drink": 3.8, "train_stats/max_log_achievement_collect_sapling": 2.1333333333333333, "train_stats/max_log_achievement_collect_wood": 2.111111111111111, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.08888888888888889, "train_stats/max_log_achievement_eat_cow": 0.044444444444444446, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 2.088888888888889, "train_stats/max_log_achievement_place_table": 0.7333333333333333, "train_stats/max_log_achievement_wake_up": 2.8444444444444446, "train_stats/mean_log_entropy": 0.5901203417115741, "eval_stats/sum_log_reward": 3.5999999940395355, "eval_stats/max_log_achievement_collect_drink": 1.25, "eval_stats/max_log_achievement_collect_sapling": 1.875, "eval_stats/max_log_achievement_collect_wood": 1.375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.125, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 1.875, "eval_stats/max_log_achievement_place_table": 0.375, "eval_stats/max_log_achievement_wake_up": 1.25, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 7.319610449485481e-05, "report/cont_loss_std": 0.00215239473618567, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.008744047954678535, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 4.9216769184567966e-06, "report/cont_pred": 0.9922486543655396, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 5.389101028442383, "report/dyn_loss_std": 8.229410171508789, "report/image_loss_mean": 4.228927135467529, "report/image_loss_std": 7.018134593963623, "report/model_loss_mean": 7.50089168548584, "report/model_loss_std": 11.027568817138672, "report/post_ent_mag": 45.68156051635742, "report/post_ent_max": 45.68156051635742, "report/post_ent_mean": 27.805686950683594, "report/post_ent_min": 13.066272735595703, "report/post_ent_std": 5.888609409332275, "report/prior_ent_mag": 69.47673797607422, "report/prior_ent_max": 69.47673797607422, "report/prior_ent_mean": 33.44773864746094, "report/prior_ent_min": 16.025699615478516, "report/prior_ent_std": 10.036738395690918, "report/rep_loss_mean": 5.389101028442383, "report/rep_loss_std": 8.229410171508789, "report/reward_avg": 0.02167968824505806, "report/reward_loss_mean": 0.03843069076538086, "report/reward_loss_std": 0.16010279953479767, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0032711029052734, "report/reward_neg_acc": 1.0000001192092896, "report/reward_neg_loss": 0.020395005121827126, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6799858808517456, "report/reward_pred": 0.02140234410762787, "report/reward_rate": 0.02734375, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.000846406037453562, "eval/cont_loss_std": 0.02691478841006756, "eval/cont_neg_acc": 0.75, "eval/cont_neg_loss": 0.21617573499679565, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 1.9772735413425835e-06, "eval/cont_pred": 0.9966586828231812, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 21.893455505371094, "eval/dyn_loss_std": 12.727734565734863, "eval/image_loss_mean": 31.334636688232422, "eval/image_loss_std": 32.10392761230469, "eval/model_loss_mean": 44.59931945800781, "eval/model_loss_std": 36.52678680419922, "eval/post_ent_mag": 45.27707290649414, "eval/post_ent_max": 45.27707290649414, "eval/post_ent_mean": 30.29642677307129, "eval/post_ent_min": 14.220108032226562, "eval/post_ent_std": 6.779135227203369, "eval/prior_ent_mag": 69.47673797607422, "eval/prior_ent_max": 69.47673797607422, "eval/prior_ent_mean": 39.405723571777344, "eval/prior_ent_min": 14.01690673828125, "eval/prior_ent_std": 10.972070693969727, "eval/rep_loss_mean": 21.893455505371094, "eval/rep_loss_std": 12.727734565734863, "eval/reward_avg": 0.01376953162252903, "eval/reward_loss_mean": 0.12776273488998413, "eval/reward_loss_std": 1.0463523864746094, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0010244846343994, "eval/reward_neg_acc": 0.9990079998970032, "eval/reward_neg_loss": 0.03567258641123772, "eval/reward_pos_acc": 0.4375, "eval/reward_pos_loss": 5.929442882537842, "eval/reward_pred": 0.0049406131729483604, "eval/reward_rate": 0.015625, "replay/size": 55161.0, "replay/inserts": 7716.0, "replay/samples": 30864.0, "replay/insert_wait_avg": 1.5457038622312808e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.731377491375027e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 11928.0, "eval_replay/inserts": 1320.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2125029708399918e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.08970832824707e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.033459186554, "timer/env.step_count": 965.0, "timer/env.step_total": 95.56336092948914, "timer/env.step_frac": 0.09556016356414931, "timer/env.step_avg": 0.09902938956423744, "timer/env.step_min": 0.023245573043823242, "timer/env.step_max": 2.0436601638793945, "timer/replay._sample_count": 30864.0, "timer/replay._sample_total": 15.890300273895264, "timer/replay._sample_frac": 0.01588976861516287, "timer/replay._sample_avg": 0.0005148490239079595, "timer/replay._sample_min": 0.00036454200744628906, "timer/replay._sample_max": 0.01218271255493164, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1130.0, "timer/agent.policy_total": 17.883015155792236, "timer/agent.policy_frac": 0.017882416824671662, "timer/agent.policy_avg": 0.015825677129019677, "timer/agent.policy_min": 0.009550094604492188, "timer/agent.policy_max": 0.053195953369140625, "timer/dataset_train_count": 1929.0, "timer/dataset_train_total": 0.2790839672088623, "timer/dataset_train_frac": 0.00027907462959876806, "timer/dataset_train_avg": 0.0001446780545406233, "timer/dataset_train_min": 8.487701416015625e-05, "timer/dataset_train_max": 0.0006668567657470703, "timer/agent.train_count": 1929.0, "timer/agent.train_total": 856.3918843269348, "timer/agent.train_frac": 0.8563632311098271, "timer/agent.train_avg": 0.44395639415600563, "timer/agent.train_min": 0.4329237937927246, "timer/agent.train_max": 0.9262816905975342, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4752073287963867, "timer/agent.report_frac": 0.0004751914292777057, "timer/agent.report_avg": 0.23760366439819336, "timer/agent.report_min": 0.2317185401916504, "timer/agent.report_max": 0.24348878860473633, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.574920654296875e-05, "timer/dataset_eval_frac": 2.5748345024289127e-08, "timer/dataset_eval_avg": 2.574920654296875e-05, "timer/dataset_eval_min": 2.574920654296875e-05, "timer/dataset_eval_max": 2.574920654296875e-05, "fps": 7.715637573433142}
{"step": 55752, "time": 7343.963025808334, "episode/length": 45.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 55760, "time": 7346.38759636879, "episode/length": 186.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 56128, "time": 7390.650359153748, "episode/length": 152.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.0}
{"step": 56256, "time": 7407.000163316727, "episode/length": 256.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.980544747081712, "episode/intrinsic_return": 0.0}
{"step": 56280, "time": 7411.263858556747, "episode/length": 179.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 57120, "time": 7509.769404411316, "episode/length": 182.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 57184, "time": 7518.649774312973, "episode/length": 178.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 57208, "time": 7522.862803936005, "episode/length": 180.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 57264, "time": 7530.773885250092, "episode/length": 206.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 57472, "time": 7557.386265277863, "episode/length": 151.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 57592, "time": 7572.701511383057, "episode/length": 182.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 57840, "time": 7603.490092992783, "episode/length": 308.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9935275080906149, "episode/intrinsic_return": 0.0}
{"step": 57856, "time": 7606.9922747612, "episode/length": 196.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 58056, "time": 7631.848784446716, "episode/length": 98.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9494949494949495, "episode/intrinsic_return": 0.0}
{"step": 58080, "time": 7636.119030952454, "episode/length": 29.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8333333333333334, "episode/intrinsic_return": 0.0}
{"step": 58448, "time": 7680.362924814224, "episode/length": 157.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 58472, "time": 7684.606325149536, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 58704, "time": 7713.784243106842, "episode/length": 186.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 58880, "time": 7735.601589679718, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 58896, "time": 7738.956520080566, "episode/length": 177.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 59160, "time": 7771.394983053207, "episode/length": 134.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9925925925925926, "episode/intrinsic_return": 0.0}
{"step": 59208, "time": 7778.39417386055, "episode/length": 38.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 59328, "time": 7793.958424806595, "episode/length": 183.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 59376, "time": 7800.885904550552, "episode/length": 164.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 59824, "time": 7854.184313058853, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 59968, "time": 7872.381929159164, "episode/length": 189.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9631578947368421, "episode/intrinsic_return": 0.0}
{"step": 60008, "time": 7892.862656354904, "eval_episode/length": 41.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.8809523809523809}
{"step": 60008, "time": 7898.2955095767975, "eval_episode/length": 144.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.993103448275862}
{"step": 60008, "time": 7900.035903215408, "eval_episode/length": 146.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9931972789115646}
{"step": 60008, "time": 7901.990521430969, "eval_episode/length": 157.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9683544303797469}
{"step": 60008, "time": 7901.996948719025, "eval_episode/length": 157.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9683544303797469}
{"step": 60008, "time": 7906.162976264954, "eval_episode/length": 184.0, "eval_episode/score": 5.099999971687794, "eval_episode/reward_rate": 0.9945945945945946}
{"step": 60008, "time": 7909.039805173874, "eval_episode/length": 221.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9864864864864865}
{"step": 60008, "time": 7912.471342563629, "eval_episode/length": 227.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9956140350877193}
{"step": 60016, "time": 7913.394909620285, "episode/length": 163.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 60240, "time": 7941.301413059235, "episode/length": 134.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9925925925925926, "episode/intrinsic_return": 0.0}
{"step": 60528, "time": 7975.898051023483, "episode/length": 149.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 60600, "time": 7985.642084598541, "episode/length": 173.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 60656, "time": 7993.72497677803, "episode/length": 221.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 60976, "time": 8032.966376066208, "episode/length": 199.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 61240, "time": 8065.3576629161835, "episode/length": 176.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 61296, "time": 8073.32263302803, "episode/length": 165.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 61472, "time": 8095.322316646576, "episode/length": 153.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 61664, "time": 8119.157908678055, "episode/length": 205.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 61736, "time": 8129.404984474182, "episode/length": 150.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 61984, "time": 8159.610661506653, "episode/length": 172.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 62096, "time": 8174.111245393753, "episode/length": 179.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 62368, "time": 8207.083441734314, "episode/length": 47.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.8958333333333334, "episode/intrinsic_return": 0.0}
{"step": 62400, "time": 8212.394839763641, "episode/length": 144.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 62608, "time": 8238.483299970627, "episode/length": 203.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 62856, "time": 8268.6558303833, "episode/length": 139.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9571428571428572, "episode/intrinsic_return": 0.0}
{"step": 62912, "time": 8276.55801320076, "episode/length": 201.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 62952, "time": 8282.687068939209, "episode/length": 184.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 63096, "time": 8300.83955669403, "episode/length": 178.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 63365, "time": 8334.28052353859, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.875520221927623, "train/action_min": 0.0, "train/action_std": 3.525024037287025, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04706900008022785, "train/actor_opt_grad_steps": 14490.0, "train/actor_opt_loss": -15.151099237676112, "train/adv_mag": 0.6732149584305719, "train/adv_max": 0.6455852182417954, "train/adv_mean": 0.002640461444700565, "train/adv_min": -0.5164739988319614, "train/adv_std": 0.0681032557909044, "train/cont_avg": 0.9942317033678757, "train/cont_loss_mean": 0.0001032380366997282, "train/cont_loss_std": 0.0031069707823684007, "train/cont_neg_acc": 0.9953964151866695, "train/cont_neg_loss": 0.01072719773061567, "train/cont_pos_acc": 0.999994891912826, "train/cont_pos_loss": 3.3421270051424606e-05, "train/cont_pred": 0.9942384084271644, "train/cont_rate": 0.9942317033678757, "train/dyn_loss_mean": 5.801524246294881, "train/dyn_loss_std": 8.100721028184644, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.293227276344991, "train/extr_critic_critic_opt_grad_steps": 14490.0, "train/extr_critic_critic_opt_loss": 16155.86749615447, "train/extr_critic_mag": 5.737193614090045, "train/extr_critic_max": 5.737193614090045, "train/extr_critic_mean": 0.8303887836364885, "train/extr_critic_min": -0.6660604989590423, "train/extr_critic_std": 1.2991924150002434, "train/extr_return_normed_mag": 1.7823095667547513, "train/extr_return_normed_max": 1.7823095667547513, "train/extr_return_normed_mean": 0.31588394237305834, "train/extr_return_normed_min": -0.17616645428183164, "train/extr_return_normed_std": 0.33686138048690834, "train/extr_return_rate": 0.4481956604385623, "train/extr_return_raw_mag": 6.678170735354251, "train/extr_return_raw_max": 6.678170735354251, "train/extr_return_raw_mean": 0.8408889738080415, "train/extr_return_raw_min": -1.117834257338331, "train/extr_return_raw_std": 1.3408285688242145, "train/extr_reward_mag": 1.0057764745129205, "train/extr_reward_max": 1.0057764745129205, "train/extr_reward_mean": 0.023941966726739018, "train/extr_reward_min": -0.6843194609478965, "train/extr_reward_std": 0.15912527131601936, "train/image_loss_mean": 5.126084731650476, "train/image_loss_std": 8.68913444953879, "train/model_loss_mean": 8.649461753627797, "train/model_loss_std": 12.451538827135154, "train/model_opt_grad_norm": 57.81788349645743, "train/model_opt_grad_steps": 14473.523316062176, "train/model_opt_loss": 6554.903645411674, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 757.7720207253886, "train/policy_entropy_mag": 2.540375912127717, "train/policy_entropy_max": 2.540375912127717, "train/policy_entropy_mean": 0.6390168481540186, "train/policy_entropy_min": 0.07937512291991031, "train/policy_entropy_std": 0.6733836049860623, "train/policy_logprob_mag": 7.438382736759483, "train/policy_logprob_max": -0.009455669820887747, "train/policy_logprob_mean": -0.63917390484884, "train/policy_logprob_min": -7.438382736759483, "train/policy_logprob_std": 1.1771015114117163, "train/policy_randomness_mag": 0.8966412170563337, "train/policy_randomness_max": 0.8966412170563337, "train/policy_randomness_mean": 0.2255449041029332, "train/policy_randomness_min": 0.028015934992485097, "train/policy_randomness_std": 0.2376748617603371, "train/post_ent_mag": 45.30812989862471, "train/post_ent_max": 45.30812989862471, "train/post_ent_mean": 28.629267914925215, "train/post_ent_min": 14.941713259010116, "train/post_ent_std": 5.649137252353016, "train/prior_ent_mag": 70.00921089290955, "train/prior_ent_max": 70.00921089290955, "train/prior_ent_mean": 34.48581429713748, "train/prior_ent_min": 16.833892649319505, "train/prior_ent_std": 9.461934084719326, "train/rep_loss_mean": 5.801524246294881, "train/rep_loss_std": 8.100721028184644, "train/reward_avg": 0.01939311437067513, "train/reward_loss_mean": 0.042359241241000475, "train/reward_loss_std": 0.20312292510981386, "train/reward_max_data": 1.0062176180627063, "train/reward_max_pred": 1.0034264634927936, "train/reward_neg_acc": 0.9961200779583788, "train/reward_neg_loss": 0.02380980995671891, "train/reward_pos_acc": 0.9772297418796955, "train/reward_pos_loss": 0.7778843505394891, "train/reward_pred": 0.019044864355765013, "train/reward_rate": 0.02468223769430052, "train_stats/sum_log_reward": 3.8391303588514742, "train_stats/max_log_achievement_collect_drink": 2.652173913043478, "train_stats/max_log_achievement_collect_sapling": 1.7608695652173914, "train_stats/max_log_achievement_collect_wood": 3.347826086956522, "train_stats/max_log_achievement_defeat_skeleton": 0.021739130434782608, "train_stats/max_log_achievement_defeat_zombie": 0.021739130434782608, "train_stats/max_log_achievement_eat_cow": 0.021739130434782608, "train_stats/max_log_achievement_make_wood_pickaxe": 0.043478260869565216, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.7391304347826086, "train_stats/max_log_achievement_place_table": 1.326086956521739, "train_stats/max_log_achievement_wake_up": 2.4130434782608696, "train_stats/mean_log_entropy": 0.53826929823212, "eval_stats/sum_log_reward": 3.8499999940395355, "eval_stats/max_log_achievement_collect_drink": 2.75, "eval_stats/max_log_achievement_collect_sapling": 1.75, "eval_stats/max_log_achievement_collect_wood": 2.5, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.25, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 1.75, "eval_stats/max_log_achievement_place_table": 0.75, "eval_stats/max_log_achievement_wake_up": 2.375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.0005708690732717514, "report/cont_loss_std": 0.016788946464657784, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.10794036835432053, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 4.403141065267846e-05, "report/cont_pred": 0.995482325553894, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 6.660371780395508, "report/dyn_loss_std": 8.616007804870605, "report/image_loss_mean": 6.629793167114258, "report/image_loss_std": 11.629961967468262, "report/model_loss_mean": 10.67870807647705, "report/model_loss_std": 15.60517692565918, "report/post_ent_mag": 43.909942626953125, "report/post_ent_max": 43.909942626953125, "report/post_ent_mean": 28.792301177978516, "report/post_ent_min": 15.292272567749023, "report/post_ent_std": 5.606344699859619, "report/prior_ent_mag": 69.2411117553711, "report/prior_ent_max": 69.2411117553711, "report/prior_ent_mean": 35.20500183105469, "report/prior_ent_min": 16.986801147460938, "report/prior_ent_std": 9.307077407836914, "report/rep_loss_mean": 6.660371780395508, "report/rep_loss_std": 8.616007804870605, "report/reward_avg": 0.01826171949505806, "report/reward_loss_mean": 0.052120644599199295, "report/reward_loss_std": 0.3523508310317993, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.001540184020996, "report/reward_neg_acc": 0.9980000257492065, "report/reward_neg_loss": 0.02506108582019806, "report/reward_pos_acc": 0.9166666865348816, "report/reward_pos_loss": 1.1796025037765503, "report/reward_pred": 0.017150338739156723, "report/reward_rate": 0.0234375, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.006285505369305611, "eval/cont_loss_std": 0.20039230585098267, "eval/cont_neg_acc": 0.800000011920929, "eval/cont_neg_loss": 1.283665657043457, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.769369191606529e-05, "eval/cont_pred": 0.9960771799087524, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 21.071636199951172, "eval/dyn_loss_std": 12.58254337310791, "eval/image_loss_mean": 31.016008377075195, "eval/image_loss_std": 29.158544540405273, "eval/model_loss_mean": 43.75730895996094, "eval/model_loss_std": 34.24055480957031, "eval/post_ent_mag": 44.79717254638672, "eval/post_ent_max": 44.79717254638672, "eval/post_ent_mean": 29.461559295654297, "eval/post_ent_min": 14.08583927154541, "eval/post_ent_std": 6.256401538848877, "eval/prior_ent_mag": 69.2411117553711, "eval/prior_ent_max": 69.2411117553711, "eval/prior_ent_mean": 38.267845153808594, "eval/prior_ent_min": 13.489916801452637, "eval/prior_ent_std": 11.705338478088379, "eval/rep_loss_mean": 21.071636199951172, "eval/rep_loss_std": 12.58254337310791, "eval/reward_avg": 0.01943359524011612, "eval/reward_loss_mean": 0.09203491359949112, "eval/reward_loss_std": 0.6763854622840881, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0001916885375977, "eval/reward_neg_acc": 0.999000072479248, "eval/reward_neg_loss": 0.032092176377773285, "eval/reward_pos_acc": 0.75, "eval/reward_pos_loss": 2.589649200439453, "eval/reward_pred": 0.011195946484804153, "eval/reward_rate": 0.0234375, "replay/size": 62861.0, "replay/inserts": 7700.0, "replay/samples": 30800.0, "replay/insert_wait_avg": 1.530306679861886e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.452128769515397e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 14088.0, "eval_replay/inserts": 2160.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1021340334856952e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.791685104370117e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3330256938934, "timer/env.step_count": 962.0, "timer/env.step_total": 98.45054578781128, "timer/env.step_frac": 0.09841777014161843, "timer/env.step_avg": 0.10233944468587451, "timer/env.step_min": 0.023211956024169922, "timer/env.step_max": 2.110664129257202, "timer/replay._sample_count": 30800.0, "timer/replay._sample_total": 15.595193147659302, "timer/replay._sample_frac": 0.01559000127666634, "timer/replay._sample_avg": 0.0005063374398590683, "timer/replay._sample_min": 0.0003402233123779297, "timer/replay._sample_max": 0.011595964431762695, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1232.0, "timer/agent.policy_total": 19.314913272857666, "timer/agent.policy_frac": 0.01930848305189128, "timer/agent.policy_avg": 0.015677689344852003, "timer/agent.policy_min": 0.00924229621887207, "timer/agent.policy_max": 0.0705726146697998, "timer/dataset_train_count": 1925.0, "timer/dataset_train_total": 0.28468847274780273, "timer/dataset_train_frac": 0.00028459369573480297, "timer/dataset_train_avg": 0.00014789011571314428, "timer/dataset_train_min": 8.654594421386719e-05, "timer/dataset_train_max": 0.005424976348876953, "timer/agent.train_count": 1925.0, "timer/agent.train_total": 849.5503077507019, "timer/agent.train_frac": 0.8492674798589208, "timer/agent.train_avg": 0.4413248351951698, "timer/agent.train_min": 0.431427001953125, "timer/agent.train_max": 0.9328122138977051, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4719657897949219, "timer/agent.report_frac": 0.0004718086653867465, "timer/agent.report_avg": 0.23598289489746094, "timer/agent.report_min": 0.22883939743041992, "timer/agent.report_max": 0.24312639236450195, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.574920654296875e-05, "timer/dataset_eval_frac": 2.574063425038626e-08, "timer/dataset_eval_avg": 2.574920654296875e-05, "timer/dataset_eval_min": 2.574920654296875e-05, "timer/dataset_eval_max": 2.574920654296875e-05, "fps": 7.697326839105828}
{"step": 63672, "time": 8370.661068677902, "episode/length": 196.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 64040, "time": 8415.940933942795, "episode/length": 178.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 64160, "time": 8431.460464477539, "episode/length": 219.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9727272727272728, "episode/intrinsic_return": 0.0}
{"step": 64160, "time": 8431.470611333847, "episode/length": 223.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 64184, "time": 8437.442364692688, "episode/length": 165.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 64296, "time": 8452.098512887955, "episode/length": 149.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 64296, "time": 8452.10638165474, "episode/length": 167.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 64360, "time": 8462.789871692657, "episode/length": 180.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 65072, "time": 8547.672488212585, "episode/length": 174.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 65384, "time": 8585.726467847824, "episode/length": 149.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 65456, "time": 8595.672575473785, "episode/length": 136.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9927007299270073, "episode/intrinsic_return": 0.0}
{"step": 65560, "time": 8610.418506145477, "episode/length": 174.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9657142857142857, "episode/intrinsic_return": 0.0}
{"step": 65688, "time": 8626.882235765457, "episode/length": 173.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 65872, "time": 8649.784856319427, "episode/length": 213.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 66272, "time": 8698.078687429428, "episode/length": 101.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9509803921568627, "episode/intrinsic_return": 0.0}
{"step": 66576, "time": 8735.458168268204, "episode/length": 187.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 66688, "time": 8750.155843734741, "episode/length": 51.0, "episode/score": 2.100000023841858, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 66720, "time": 8755.38373374939, "episode/length": 166.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 67112, "time": 8802.72150182724, "episode/length": 383.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9765625, "episode/intrinsic_return": 0.0}
{"step": 67120, "time": 8805.165094137192, "episode/length": 194.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 67240, "time": 8820.697880268097, "episode/length": 193.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 67328, "time": 8832.52511048317, "episode/length": 181.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 67752, "time": 8883.333720445633, "episode/length": 52.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9056603773584906, "episode/intrinsic_return": 0.0}
{"step": 67752, "time": 8883.346188545227, "episode/length": 431.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 67808, "time": 8893.130401849747, "episode/length": 153.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 67960, "time": 8912.31673693657, "episode/length": 158.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 68456, "time": 8971.734651565552, "episode/length": 166.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 68512, "time": 8979.777396678925, "episode/length": 158.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 68544, "time": 8985.050718545914, "episode/length": 227.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9692982456140351, "episode/intrinsic_return": 0.0}
{"step": 69104, "time": 9052.341427326202, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 69168, "time": 9061.38303899765, "episode/length": 176.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9661016949152542, "episode/intrinsic_return": 0.0}
{"step": 69416, "time": 9092.628874063492, "episode/length": 200.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 69688, "time": 9126.124956130981, "episode/length": 321.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9875776397515528, "episode/intrinsic_return": 0.0}
{"step": 69824, "time": 9143.377017498016, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 69944, "time": 9158.9840426445, "episode/length": 178.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 69968, "time": 9163.348070383072, "episode/length": 250.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9800796812749004, "episode/intrinsic_return": 0.0}
{"step": 70096, "time": 9197.53883266449, "eval_episode/length": 135.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9926470588235294}
{"step": 70096, "time": 9199.4463057518, "eval_episode/length": 142.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.993006993006993}
{"step": 70096, "time": 9201.047523260117, "eval_episode/length": 145.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9931506849315068}
{"step": 70096, "time": 9202.905915021896, "eval_episode/length": 152.0, "eval_episode/score": 2.100000023841858, "eval_episode/reward_rate": 0.9934640522875817}
{"step": 70096, "time": 9205.151931762695, "eval_episode/length": 168.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9763313609467456}
{"step": 70096, "time": 9206.978131055832, "eval_episode/length": 176.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9943502824858758}
{"step": 70096, "time": 9208.84489107132, "eval_episode/length": 183.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9728260869565217}
{"step": 70096, "time": 9212.207011938095, "eval_episode/length": 224.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9955555555555555}
{"step": 70144, "time": 9218.65591287613, "episode/length": 199.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 70680, "time": 9282.9897813797, "episode/length": 157.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 70936, "time": 9314.24572968483, "episode/length": 138.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.0}
{"step": 70968, "time": 9319.453302145004, "episode/length": 232.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 71077, "time": 9334.45851445198, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.999330826991581, "train/action_min": 0.0, "train/action_std": 3.796417620515576, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04873495287421145, "train/actor_opt_grad_steps": 16420.0, "train/actor_opt_loss": -10.520569496049783, "train/adv_mag": 0.6616614692569397, "train/adv_max": 0.6450503020706572, "train/adv_mean": 0.004033695978651317, "train/adv_min": -0.4841312024877479, "train/adv_std": 0.06949732531769288, "train/cont_avg": 0.9940748461787565, "train/cont_loss_mean": 0.0002111102234803502, "train/cont_loss_std": 0.006108155687886936, "train/cont_neg_acc": 0.9950304315497838, "train/cont_neg_loss": 0.020029957260314896, "train/cont_pos_acc": 0.999974488285539, "train/cont_pos_loss": 6.0692543195140636e-05, "train/cont_pred": 0.9940814805154355, "train/cont_rate": 0.9940748461787565, "train/dyn_loss_mean": 6.007002269665812, "train/dyn_loss_std": 8.138466694194419, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.3190676857152752, "train/extr_critic_critic_opt_grad_steps": 16420.0, "train/extr_critic_critic_opt_loss": 16362.93757589864, "train/extr_critic_mag": 5.665970785012517, "train/extr_critic_max": 5.665970785012517, "train/extr_critic_mean": 0.8747253649593018, "train/extr_critic_min": -0.6720977552196522, "train/extr_critic_std": 1.313105136001666, "train/extr_return_normed_mag": 1.7465233574259467, "train/extr_return_normed_max": 1.7465233574259467, "train/extr_return_normed_mean": 0.32633144443208073, "train/extr_return_normed_min": -0.16895403319226646, "train/extr_return_normed_std": 0.34173880324462536, "train/extr_return_rate": 0.46790063473844773, "train/extr_return_raw_mag": 6.523787673890899, "train/extr_return_raw_max": 6.523787673890899, "train/extr_return_raw_mean": 0.8907206887717074, "train/extr_return_raw_min": -1.0728441733152756, "train/extr_return_raw_std": 1.3551420813397423, "train/extr_reward_mag": 1.0052744662823454, "train/extr_reward_max": 1.0052744662823454, "train/extr_reward_mean": 0.02546941972496905, "train/extr_reward_min": -0.6880571094819301, "train/extr_reward_std": 0.16427723607868727, "train/image_loss_mean": 5.255538706952426, "train/image_loss_std": 9.153415548986722, "train/model_loss_mean": 8.903009478909981, "train/model_loss_std": 12.935776750040796, "train/model_opt_grad_norm": 59.68064197480987, "train/model_opt_grad_steps": 16401.9792746114, "train/model_opt_loss": 7452.024064928756, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 841.9689119170985, "train/policy_entropy_mag": 2.5174261078315694, "train/policy_entropy_max": 2.5174261078315694, "train/policy_entropy_mean": 0.6357109962040897, "train/policy_entropy_min": 0.07937507644064068, "train/policy_entropy_std": 0.6564529541242926, "train/policy_logprob_mag": 7.438382939353508, "train/policy_logprob_max": -0.00945566062829964, "train/policy_logprob_mean": -0.635638598642201, "train/policy_logprob_min": -7.438382939353508, "train/policy_logprob_std": 1.1731690847811922, "train/policy_randomness_mag": 0.8885409418165375, "train/policy_randomness_max": 0.8885409418165375, "train/policy_randomness_mean": 0.22437808458051534, "train/policy_randomness_min": 0.02801591871122931, "train/policy_randomness_std": 0.23169908537457026, "train/post_ent_mag": 46.24253218655759, "train/post_ent_max": 46.24253218655759, "train/post_ent_mean": 29.12544199098577, "train/post_ent_min": 15.331828823979038, "train/post_ent_std": 5.6686116500222, "train/prior_ent_mag": 70.45504740976916, "train/prior_ent_max": 70.45504740976916, "train/prior_ent_mean": 35.170446484817745, "train/prior_ent_min": 17.14491126203784, "train/prior_ent_std": 9.494805039519473, "train/rep_loss_mean": 6.007002269665812, "train/rep_loss_std": 8.138466694194419, "train/reward_avg": 0.02031452395263191, "train/reward_loss_mean": 0.04305825936439124, "train/reward_loss_std": 0.20279616020967306, "train/reward_max_data": 1.0025906741927944, "train/reward_max_pred": 1.0032801325457084, "train/reward_neg_acc": 0.9959180021533076, "train/reward_neg_loss": 0.02410251088199143, "train/reward_pos_acc": 0.9800668896171095, "train/reward_pos_loss": 0.764219751938637, "train/reward_pred": 0.02008947777836897, "train/reward_rate": 0.025663860103626944, "train_stats/sum_log_reward": 4.34999994635582, "train_stats/max_log_achievement_collect_drink": 2.975, "train_stats/max_log_achievement_collect_sapling": 2.575, "train_stats/max_log_achievement_collect_wood": 2.8, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.1, "train_stats/max_log_achievement_eat_cow": 0.125, "train_stats/max_log_achievement_make_wood_pickaxe": 0.025, "train_stats/max_log_achievement_make_wood_sword": 0.025, "train_stats/max_log_achievement_place_plant": 2.5, "train_stats/max_log_achievement_place_table": 1.1, "train_stats/max_log_achievement_wake_up": 2.85, "train_stats/mean_log_entropy": 0.6101563174277544, "eval_stats/sum_log_reward": 3.8499999046325684, "eval_stats/max_log_achievement_collect_drink": 3.0, "eval_stats/max_log_achievement_collect_sapling": 1.5, "eval_stats/max_log_achievement_collect_wood": 2.375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 1.5, "eval_stats/max_log_achievement_place_table": 1.0, "eval_stats/max_log_achievement_wake_up": 2.75, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 2.366805165365804e-05, "report/cont_loss_std": 0.00018458996783010662, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.6226455045398325e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 2.371926893829368e-05, "report/cont_pred": 0.9931406378746033, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 6.030525207519531, "report/dyn_loss_std": 7.729966640472412, "report/image_loss_mean": 5.057260513305664, "report/image_loss_std": 5.999955177307129, "report/model_loss_mean": 8.727462768554688, "report/model_loss_std": 9.250325202941895, "report/post_ent_mag": 47.73955154418945, "report/post_ent_max": 47.73955154418945, "report/post_ent_mean": 29.136686325073242, "report/post_ent_min": 14.080592155456543, "report/post_ent_std": 6.045377254486084, "report/prior_ent_mag": 71.09043884277344, "report/prior_ent_max": 71.09043884277344, "report/prior_ent_mean": 35.631980895996094, "report/prior_ent_min": 16.525859832763672, "report/prior_ent_std": 9.915846824645996, "report/rep_loss_mean": 6.030525207519531, "report/rep_loss_std": 7.729966640472412, "report/reward_avg": 0.02119140699505806, "report/reward_loss_mean": 0.05186332017183304, "report/reward_loss_std": 0.1834031343460083, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0004193782806396, "report/reward_neg_acc": 0.9979899525642395, "report/reward_neg_loss": 0.033552635461091995, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6801092028617859, "report/reward_pred": 0.02180260233581066, "report/reward_rate": 0.0283203125, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.00020540280092973262, "eval/cont_loss_std": 0.006324332673102617, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.10126543045043945, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 7.63369826017879e-06, "eval/cont_pred": 0.998218297958374, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 22.483768463134766, "eval/dyn_loss_std": 13.231528282165527, "eval/image_loss_mean": 35.99642562866211, "eval/image_loss_std": 35.36835479736328, "eval/model_loss_mean": 49.610103607177734, "eval/model_loss_std": 40.45429611206055, "eval/post_ent_mag": 46.074859619140625, "eval/post_ent_max": 46.074859619140625, "eval/post_ent_mean": 30.167526245117188, "eval/post_ent_min": 18.900928497314453, "eval/post_ent_std": 5.912121295928955, "eval/prior_ent_mag": 71.09043884277344, "eval/prior_ent_max": 71.09043884277344, "eval/prior_ent_mean": 40.92939758300781, "eval/prior_ent_min": 18.894588470458984, "eval/prior_ent_std": 11.318021774291992, "eval/rep_loss_mean": 22.483768463134766, "eval/rep_loss_std": 13.231528282165527, "eval/reward_avg": 0.01513671875, "eval/reward_loss_mean": 0.12321043014526367, "eval/reward_loss_std": 0.9259812831878662, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9988247156143188, "eval/reward_neg_acc": 0.998009979724884, "eval/reward_neg_loss": 0.04484819620847702, "eval/reward_pos_acc": 0.5263158082962036, "eval/reward_pos_loss": 4.268160343170166, "eval/reward_pred": 0.008708616718649864, "eval/reward_rate": 0.0185546875, "replay/size": 70573.0, "replay/inserts": 7712.0, "replay/samples": 30848.0, "replay/insert_wait_avg": 1.5155593883941778e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.466811114821691e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 15888.0, "eval_replay/inserts": 1800.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2800428602430555e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.599592208862305e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1670722961426, "timer/env.step_count": 964.0, "timer/env.step_total": 88.46130466461182, "timer/env.step_frac": 0.08844652770014312, "timer/env.step_avg": 0.0917648388637052, "timer/env.step_min": 0.023126602172851562, "timer/env.step_max": 3.215369701385498, "timer/replay._sample_count": 30848.0, "timer/replay._sample_total": 15.868742942810059, "timer/replay._sample_frac": 0.015866092158362353, "timer/replay._sample_avg": 0.0005144172375132929, "timer/replay._sample_min": 0.00036215782165527344, "timer/replay._sample_max": 0.011649370193481445, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1189.0, "timer/agent.policy_total": 19.277682781219482, "timer/agent.policy_frac": 0.01927446255250392, "timer/agent.policy_avg": 0.016213358100268697, "timer/agent.policy_min": 0.009598016738891602, "timer/agent.policy_max": 0.0922553539276123, "timer/dataset_train_count": 1928.0, "timer/dataset_train_total": 0.32128047943115234, "timer/dataset_train_frac": 0.00032122681133020086, "timer/dataset_train_avg": 0.00016663925281698772, "timer/dataset_train_min": 8.940696716308594e-05, "timer/dataset_train_max": 0.03850960731506348, "timer/agent.train_count": 1928.0, "timer/agent.train_total": 860.1124842166901, "timer/agent.train_frac": 0.8599688072534513, "timer/agent.train_avg": 0.4461164337223496, "timer/agent.train_min": 0.4269871711730957, "timer/agent.train_max": 1.2432899475097656, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.46834588050842285, "timer/agent.report_frac": 0.00046826764595760345, "timer/agent.report_avg": 0.23417294025421143, "timer/agent.report_min": 0.22171545028686523, "timer/agent.report_max": 0.24663043022155762, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.2901763916015625e-05, "timer/dataset_eval_frac": 3.289626786100957e-08, "timer/dataset_eval_avg": 3.2901763916015625e-05, "timer/dataset_eval_min": 3.2901763916015625e-05, "timer/dataset_eval_max": 3.2901763916015625e-05, "fps": 7.710606935498006}
{"step": 71296, "time": 9359.827501296997, "episode/length": 143.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 71360, "time": 9368.730420351028, "episode/length": 273.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9817518248175182, "episode/intrinsic_return": 0.0}
{"step": 71448, "time": 9380.515865564346, "episode/length": 187.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 71896, "time": 9434.169847011566, "episode/length": 151.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 72032, "time": 9451.599861860275, "episode/length": 257.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9728682170542635, "episode/intrinsic_return": 0.0}
{"step": 72256, "time": 9479.336095809937, "episode/length": 320.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9968847352024922, "episode/intrinsic_return": 0.0}
{"step": 72336, "time": 9490.155292510986, "episode/length": 174.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 72544, "time": 9515.892733573914, "episode/length": 196.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 72592, "time": 9523.276124477386, "episode/length": 142.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 72992, "time": 9572.36591386795, "episode/length": 203.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 73136, "time": 9590.782339811325, "episode/length": 229.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9695652173913043, "episode/intrinsic_return": 0.0}
{"step": 73224, "time": 9602.53568315506, "episode/length": 148.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 73360, "time": 9619.957026004791, "episode/length": 182.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 73624, "time": 9652.390807151794, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 73904, "time": 9687.629750728607, "episode/length": 169.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 74048, "time": 9706.007253170013, "episode/length": 223.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 74232, "time": 9728.864881038666, "episode/length": 204.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9804878048780488, "episode/intrinsic_return": 0.0}
{"step": 74264, "time": 9734.133571863174, "episode/length": 158.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 74360, "time": 9746.774460792542, "episode/length": 141.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 74536, "time": 9769.536055803299, "episode/length": 174.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 74848, "time": 9807.397734165192, "episode/length": 185.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 74936, "time": 9819.073452472687, "episode/length": 163.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 75144, "time": 9844.857719421387, "episode/length": 36.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 75352, "time": 9870.659087181091, "episode/length": 162.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 75384, "time": 9875.814730167389, "episode/length": 143.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 75520, "time": 9893.179468870163, "episode/length": 144.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 75936, "time": 9943.084202051163, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 76016, "time": 9953.807561397552, "episode/length": 218.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 76208, "time": 9977.717886924744, "episode/length": 287.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9826388888888888, "episode/intrinsic_return": 0.0}
{"step": 76464, "time": 10009.042262554169, "episode/length": 164.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 76520, "time": 10017.494842290878, "episode/length": 145.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 76704, "time": 10040.439693689346, "episode/length": 220.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9819004524886877, "episode/intrinsic_return": 0.0}
{"step": 76816, "time": 10055.02838587761, "episode/length": 178.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 77008, "time": 10079.475822687149, "episode/length": 185.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 77480, "time": 10136.105365514755, "episode/length": 182.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 77880, "time": 10184.237987279892, "episode/length": 132.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9924812030075187, "episode/intrinsic_return": 0.0}
{"step": 77920, "time": 10190.377960681915, "episode/length": 181.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 77952, "time": 10195.595066308975, "episode/length": 217.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 78040, "time": 10207.932201862335, "episode/length": 166.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 78168, "time": 10224.225636005402, "episode/length": 278.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.982078853046595, "episode/intrinsic_return": 0.0}
{"step": 78728, "time": 10290.824654817581, "episode/length": 214.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 78856, "time": 10307.346831798553, "episode/length": 291.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9965753424657534, "episode/intrinsic_return": 0.0}
{"step": 79032, "time": 10329.31678366661, "episode/length": 37.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 79057, "time": 10334.667415618896, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.811965098932161, "train/action_min": 0.0, "train/action_std": 3.565914355330731, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04853955001088243, "train/actor_opt_grad_steps": 18380.0, "train/actor_opt_loss": -10.785233571189432, "train/adv_mag": 0.6730667518910451, "train/adv_max": 0.6351030175410324, "train/adv_mean": 0.0035919026261183548, "train/adv_min": -0.5155898539265197, "train/adv_std": 0.06836296941841667, "train/cont_avg": 0.9941553470477387, "train/cont_loss_mean": 0.00019176515001230194, "train/cont_loss_std": 0.005800541159203191, "train/cont_neg_acc": 0.9963243549520319, "train/cont_neg_loss": 0.02013065528701829, "train/cont_pos_acc": 0.9999851332837014, "train/cont_pos_loss": 5.3996750081560275e-05, "train/cont_pred": 0.9941647229482181, "train/cont_rate": 0.9941553470477387, "train/dyn_loss_mean": 5.8525444730442375, "train/dyn_loss_std": 8.217834343263252, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.2832888945862277, "train/extr_critic_critic_opt_grad_steps": 18380.0, "train/extr_critic_critic_opt_loss": 16113.911765860552, "train/extr_critic_mag": 5.796688106191818, "train/extr_critic_max": 5.796688106191818, "train/extr_critic_mean": 0.917982348994394, "train/extr_critic_min": -0.6480127926447883, "train/extr_critic_std": 1.3118622267066533, "train/extr_return_normed_mag": 1.757758831858036, "train/extr_return_normed_max": 1.757758831858036, "train/extr_return_normed_mean": 0.31873985608318944, "train/extr_return_normed_min": -0.17104910070722426, "train/extr_return_normed_std": 0.34103706082207474, "train/extr_return_rate": 0.4620370989169308, "train/extr_return_raw_mag": 6.622116884394507, "train/extr_return_raw_max": 6.622116884394507, "train/extr_return_raw_mean": 0.9321935293662488, "train/extr_return_raw_min": -1.0043087179337316, "train/extr_return_raw_std": 1.3487531201324272, "train/extr_reward_mag": 1.006185895833538, "train/extr_reward_max": 1.006185895833538, "train/extr_reward_mean": 0.02506065367014339, "train/extr_reward_min": -0.6825812264303466, "train/extr_reward_std": 0.1629326044764351, "train/image_loss_mean": 4.832847131556602, "train/image_loss_std": 8.790277615264433, "train/model_loss_mean": 8.387615287723253, "train/model_loss_std": 12.625439121495539, "train/model_opt_grad_norm": 57.0478400896542, "train/model_opt_grad_steps": 18360.8391959799, "train/model_opt_loss": 7488.849325975581, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 891.9597989949749, "train/policy_entropy_mag": 2.473996539810794, "train/policy_entropy_max": 2.473996539810794, "train/policy_entropy_mean": 0.6199702329971083, "train/policy_entropy_min": 0.07937505418182018, "train/policy_entropy_std": 0.6387366830703601, "train/policy_logprob_mag": 7.438383294110322, "train/policy_logprob_max": -0.00945566053591182, "train/policy_logprob_mean": -0.6199038457031825, "train/policy_logprob_min": -7.438383294110322, "train/policy_logprob_std": 1.1551729350832838, "train/policy_randomness_mag": 0.873212211096107, "train/policy_randomness_max": 0.873212211096107, "train/policy_randomness_mean": 0.21882228560783157, "train/policy_randomness_min": 0.028015910858410088, "train/policy_randomness_std": 0.22544601881623866, "train/post_ent_mag": 47.074693536039575, "train/post_ent_max": 47.074693536039575, "train/post_ent_mean": 29.508765072079758, "train/post_ent_min": 15.847922210118279, "train/post_ent_std": 5.674775574075516, "train/prior_ent_mag": 70.96145963429207, "train/prior_ent_max": 70.96145963429207, "train/prior_ent_mean": 35.38681156791035, "train/prior_ent_min": 17.72625115648586, "train/prior_ent_std": 9.463234201747568, "train/rep_loss_mean": 5.8525444730442375, "train/rep_loss_std": 8.217834343263252, "train/reward_avg": 0.020384638015667547, "train/reward_loss_mean": 0.043049713250380664, "train/reward_loss_std": 0.20645040505795023, "train/reward_max_data": 1.007537690239336, "train/reward_max_pred": 1.0034693934809622, "train/reward_neg_acc": 0.9957921573864156, "train/reward_neg_loss": 0.02357575603428498, "train/reward_pos_acc": 0.9780073755949585, "train/reward_pos_loss": 0.7867124233413582, "train/reward_pred": 0.020007228932750584, "train/reward_rate": 0.025626177763819095, "train_stats/sum_log_reward": 4.68139527564825, "train_stats/max_log_achievement_collect_drink": 3.5348837209302326, "train_stats/max_log_achievement_collect_sapling": 2.3255813953488373, "train_stats/max_log_achievement_collect_wood": 3.3488372093023258, "train_stats/max_log_achievement_defeat_skeleton": 0.023255813953488372, "train_stats/max_log_achievement_defeat_zombie": 0.09302325581395349, "train_stats/max_log_achievement_eat_cow": 0.06976744186046512, "train_stats/max_log_achievement_make_wood_pickaxe": 0.3488372093023256, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 2.2325581395348837, "train_stats/max_log_achievement_place_table": 1.186046511627907, "train_stats/max_log_achievement_wake_up": 2.9767441860465116, "train_stats/mean_log_entropy": 0.5915149121090423, "train_stats/max_log_achievement_collect_stone": 0.14705882352941177, "train_stats/max_log_achievement_place_stone": 0.029411764705882353, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 5.851403329870664e-06, "report/cont_loss_std": 7.4849980592262e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0011115517700091004, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 1.5153232197917532e-06, "report/cont_pred": 0.9960966110229492, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 5.38016414642334, "report/dyn_loss_std": 7.4290947914123535, "report/image_loss_mean": 3.7706727981567383, "report/image_loss_std": 8.162640571594238, "report/model_loss_mean": 7.038269996643066, "report/model_loss_std": 11.602198600769043, "report/post_ent_mag": 47.25298309326172, "report/post_ent_max": 47.25298309326172, "report/post_ent_mean": 28.85877227783203, "report/post_ent_min": 17.309785842895508, "report/post_ent_std": 5.570371627807617, "report/prior_ent_mag": 71.06529235839844, "report/prior_ent_max": 71.06529235839844, "report/prior_ent_mean": 35.05442810058594, "report/prior_ent_min": 18.642223358154297, "report/prior_ent_std": 9.705796241760254, "report/rep_loss_mean": 5.38016414642334, "report/rep_loss_std": 7.4290947914123535, "report/reward_avg": 0.02089843712747097, "report/reward_loss_mean": 0.03949275612831116, "report/reward_loss_std": 0.1665288209915161, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0014450550079346, "report/reward_neg_acc": 0.9979979991912842, "report/reward_neg_loss": 0.0215559471398592, "report/reward_pos_acc": 0.9599999785423279, "report/reward_pos_loss": 0.7562476992607117, "report/reward_pred": 0.02060972899198532, "report/reward_rate": 0.0244140625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 4.97652763442602e-05, "eval/cont_loss_std": 0.0014678735751658678, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.012663012370467186, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 3.015630340996722e-07, "eval/cont_pred": 0.9961419105529785, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 23.108261108398438, "eval/dyn_loss_std": 13.700182914733887, "eval/image_loss_mean": 41.1401481628418, "eval/image_loss_std": 40.03075408935547, "eval/model_loss_mean": 55.14402770996094, "eval/model_loss_std": 45.19780731201172, "eval/post_ent_mag": 44.71965026855469, "eval/post_ent_max": 44.71965026855469, "eval/post_ent_mean": 32.456581115722656, "eval/post_ent_min": 16.98082733154297, "eval/post_ent_std": 5.592777252197266, "eval/prior_ent_mag": 71.06529235839844, "eval/prior_ent_max": 71.06529235839844, "eval/prior_ent_mean": 43.54393005371094, "eval/prior_ent_min": 19.837181091308594, "eval/prior_ent_std": 10.368741989135742, "eval/rep_loss_mean": 23.108261108398438, "eval/rep_loss_std": 13.700182914733887, "eval/reward_avg": 0.01787109300494194, "eval/reward_loss_mean": 0.13887687027454376, "eval/reward_loss_std": 0.9851745963096619, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9979007244110107, "eval/reward_neg_acc": 0.9930139780044556, "eval/reward_neg_loss": 0.03069797344505787, "eval/reward_pos_acc": 0.40909093618392944, "eval/reward_pos_loss": 5.065934181213379, "eval/reward_pred": 0.008247577585279942, "eval/reward_rate": 0.021484375, "replay/size": 78553.0, "replay/inserts": 7980.0, "replay/samples": 31920.0, "replay/insert_wait_avg": 1.5423112644587543e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.511156244684282e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 15888.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 8.791685104370117e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1910171508789, "timer/env.step_count": 998.0, "timer/env.step_total": 93.04820775985718, "timer/env.step_frac": 0.09303043735076942, "timer/env.step_avg": 0.09323467711408535, "timer/env.step_min": 0.0236513614654541, "timer/env.step_max": 2.1138081550598145, "timer/replay._sample_count": 31920.0, "timer/replay._sample_total": 16.44160032272339, "timer/replay._sample_frac": 0.016438460294873027, "timer/replay._sample_avg": 0.0005150877294086275, "timer/replay._sample_min": 0.000370025634765625, "timer/replay._sample_max": 0.02863931655883789, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 998.0, "timer/agent.policy_total": 16.281558752059937, "timer/agent.policy_frac": 0.016278449289056016, "timer/agent.policy_avg": 0.016314187126312562, "timer/agent.policy_min": 0.009833335876464844, "timer/agent.policy_max": 0.05704998970031738, "timer/dataset_train_count": 1995.0, "timer/dataset_train_total": 0.29696130752563477, "timer/dataset_train_frac": 0.00029690459365607175, "timer/dataset_train_avg": 0.00014885278572713523, "timer/dataset_train_min": 9.059906005859375e-05, "timer/dataset_train_max": 0.0012125968933105469, "timer/agent.train_count": 1995.0, "timer/agent.train_total": 887.482531785965, "timer/agent.train_frac": 0.887313039777169, "timer/agent.train_avg": 0.4448533993914611, "timer/agent.train_min": 0.43149566650390625, "timer/agent.train_max": 0.9701623916625977, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47708630561828613, "timer/agent.report_frac": 0.0004769951913558504, "timer/agent.report_avg": 0.23854315280914307, "timer/agent.report_min": 0.23251652717590332, "timer/agent.report_max": 0.2445697784423828, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8371810913085938e-05, "timer/dataset_eval_frac": 2.836639244562026e-08, "timer/dataset_eval_avg": 2.8371810913085938e-05, "timer/dataset_eval_min": 2.8371810913085938e-05, "timer/dataset_eval_max": 2.8371810913085938e-05, "fps": 7.978368663603968}
{"step": 79112, "time": 10340.927926301956, "episode/length": 148.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 79128, "time": 10344.216680765152, "episode/length": 205.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 79184, "time": 10352.163434505463, "episode/length": 162.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 79424, "time": 10381.540199518204, "episode/length": 172.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 79536, "time": 10396.078377008438, "episode/length": 197.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 79552, "time": 10399.453891277313, "episode/length": 172.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9653179190751445, "episode/intrinsic_return": 0.0}
{"step": 79832, "time": 10433.893230676651, "episode/length": 34.0, "episode/score": 0.09999997168779373, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 80080, "time": 10482.997619628906, "eval_episode/length": 143.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9930555555555556}
{"step": 80080, "time": 10484.525036811829, "eval_episode/length": 144.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9655172413793104}
{"step": 80080, "time": 10486.61380815506, "eval_episode/length": 158.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9937106918238994}
{"step": 80080, "time": 10486.620933055878, "eval_episode/length": 158.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9622641509433962}
{"step": 80080, "time": 10490.195188760757, "eval_episode/length": 166.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9940119760479041}
{"step": 80080, "time": 10493.501577854156, "eval_episode/length": 42.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9767441860465116}
{"step": 80080, "time": 10495.711621284485, "eval_episode/length": 226.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9779735682819384}
{"step": 80080, "time": 10500.596192598343, "eval_episode/length": 305.0, "eval_episode/score": 6.099999979138374, "eval_episode/reward_rate": 0.9967320261437909}
{"step": 80304, "time": 10526.58220744133, "episode/length": 146.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 80464, "time": 10546.791405439377, "episode/length": 159.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 80632, "time": 10567.843406200409, "episode/length": 199.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 80648, "time": 10571.340067386627, "episode/length": 223.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 80768, "time": 10586.837641477585, "episode/length": 206.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9806763285024155, "episode/intrinsic_return": 0.0}
{"step": 81128, "time": 10630.91123008728, "episode/length": 61.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 81200, "time": 10640.724984645844, "episode/length": 207.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 81256, "time": 10649.254324674606, "episode/length": 228.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9781659388646288, "episode/intrinsic_return": 0.0}
{"step": 81296, "time": 10655.40760397911, "episode/length": 182.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 81504, "time": 10681.012748718262, "episode/length": 46.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 81808, "time": 10717.800844192505, "episode/length": 187.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 81912, "time": 10731.40949511528, "episode/length": 180.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 82096, "time": 10755.521225690842, "episode/length": 165.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 82144, "time": 10762.511768341064, "episode/length": 186.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 82608, "time": 10818.7540640831, "episode/length": 57.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 82688, "time": 10829.697640419006, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 82976, "time": 10864.571002721786, "episode/length": 145.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 82976, "time": 10864.579447507858, "episode/length": 214.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 83024, "time": 10873.442879676819, "episode/length": 138.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.0}
{"step": 83040, "time": 10876.793942213058, "episode/length": 229.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9826086956521739, "episode/intrinsic_return": 0.0}
{"step": 83048, "time": 10879.165202856064, "episode/length": 192.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 83568, "time": 10941.002696275711, "episode/length": 183.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 84008, "time": 10993.585443258286, "episode/length": 164.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 84152, "time": 11011.849420785904, "episode/length": 146.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 84192, "time": 11017.987449407578, "episode/length": 197.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 84232, "time": 11024.172375679016, "episode/length": 156.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 84296, "time": 11033.04542016983, "episode/length": 155.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 84536, "time": 11062.377928972244, "episode/length": 186.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9625668449197861, "episode/intrinsic_return": 0.0}
{"step": 84712, "time": 11084.302859067917, "episode/length": 210.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.981042654028436, "episode/intrinsic_return": 0.0}
{"step": 84824, "time": 11098.745169878006, "episode/length": 65.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9242424242424242, "episode/intrinsic_return": 0.0}
{"step": 84832, "time": 11101.135468482971, "episode/length": 157.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 85552, "time": 11186.87077999115, "episode/length": 164.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 85824, "time": 11220.303177595139, "episode/length": 208.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 85856, "time": 11225.451511383057, "episode/length": 142.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 85880, "time": 11229.758968114853, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 85920, "time": 11236.02086186409, "episode/length": 215.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 86216, "time": 11271.850537776947, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 86280, "time": 11280.907417535782, "episode/length": 283.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9964788732394366, "episode/intrinsic_return": 0.0}
{"step": 86312, "time": 11286.218063116074, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9621621621621622, "episode/intrinsic_return": 0.0}
{"step": 86709, "time": 11334.770515680313, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.810001712819044, "train/action_min": 0.0, "train/action_std": 3.558654478083106, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04856046039552589, "train/actor_opt_grad_steps": 20330.0, "train/actor_opt_loss": -9.682580751118236, "train/adv_mag": 0.6072435311934087, "train/adv_max": 0.578093796812427, "train/adv_mean": 0.00374742714147323, "train/adv_min": -0.487890136803632, "train/adv_std": 0.06565206414039847, "train/cont_avg": 0.9940485929319371, "train/cont_loss_mean": 0.0002352193878870907, "train/cont_loss_std": 0.0065822950057674405, "train/cont_neg_acc": 0.9928446777203944, "train/cont_neg_loss": 0.03223718245246812, "train/cont_pos_acc": 0.9999742554744501, "train/cont_pos_loss": 8.539350632802278e-05, "train/cont_pred": 0.994054646080077, "train/cont_rate": 0.9940485929319371, "train/dyn_loss_mean": 5.8317550938791, "train/dyn_loss_std": 8.194471908489447, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.2737238687994592, "train/extr_critic_critic_opt_grad_steps": 20330.0, "train/extr_critic_critic_opt_loss": 16150.451350826243, "train/extr_critic_mag": 5.972584639544262, "train/extr_critic_max": 5.972584639544262, "train/extr_critic_mean": 0.9977680042152005, "train/extr_critic_min": -0.6607133992679456, "train/extr_critic_std": 1.3665429466057821, "train/extr_return_normed_mag": 1.6916000555947188, "train/extr_return_normed_max": 1.6916000555947188, "train/extr_return_normed_mean": 0.31926410695957264, "train/extr_return_normed_min": -0.17043451094970652, "train/extr_return_normed_std": 0.3374323136519387, "train/extr_return_rate": 0.4805032038251767, "train/extr_return_raw_mag": 6.72872881864378, "train/extr_return_raw_max": 6.72872881864378, "train/extr_return_raw_mean": 1.013289485302271, "train/extr_return_raw_min": -1.0263300088687717, "train/extr_return_raw_std": 1.4053794170549403, "train/extr_reward_mag": 1.0069314497303588, "train/extr_reward_max": 1.0069314497303588, "train/extr_reward_mean": 0.02607640110599901, "train/extr_reward_min": -0.6988003441176489, "train/extr_reward_std": 0.1658059263026527, "train/image_loss_mean": 4.539987999731333, "train/image_loss_std": 8.249069599581015, "train/model_loss_mean": 8.082721468041704, "train/model_loss_std": 12.109596065201684, "train/model_opt_grad_norm": 52.173350049563105, "train/model_opt_grad_steps": 20309.93717277487, "train/model_opt_loss": 8828.568442459506, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1092.931937172775, "train/policy_entropy_mag": 2.46988074442479, "train/policy_entropy_max": 2.46988074442479, "train/policy_entropy_mean": 0.6025274637793996, "train/policy_entropy_min": 0.07937503106775085, "train/policy_entropy_std": 0.6214065500266889, "train/policy_logprob_mag": 7.438383409490136, "train/policy_logprob_max": -0.009455658183359975, "train/policy_logprob_mean": -0.6029167429626924, "train/policy_logprob_min": -7.438383409490136, "train/policy_logprob_std": 1.144377081806123, "train/policy_randomness_mag": 0.8717595148461027, "train/policy_randomness_max": 0.8717595148461027, "train/policy_randomness_mean": 0.21266575399493673, "train/policy_randomness_min": 0.028015902694997364, "train/policy_randomness_std": 0.2193292430870196, "train/post_ent_mag": 48.03311548682407, "train/post_ent_max": 48.03311548682407, "train/post_ent_mean": 30.21339067988371, "train/post_ent_min": 16.109212401025584, "train/post_ent_std": 5.711965271315649, "train/prior_ent_mag": 71.591385367029, "train/prior_ent_max": 71.591385367029, "train/prior_ent_mean": 36.0844577569612, "train/prior_ent_min": 18.2498683729721, "train/prior_ent_std": 9.446005381838814, "train/rep_loss_mean": 5.8317550938791, "train/rep_loss_std": 8.194471908489447, "train/reward_avg": 0.02093115996530387, "train/reward_loss_mean": 0.04344516600535802, "train/reward_loss_std": 0.20347219217978224, "train/reward_max_data": 1.0052356033425056, "train/reward_max_pred": 1.0034217191616277, "train/reward_neg_acc": 0.9958026050273037, "train/reward_neg_loss": 0.023820318744873812, "train/reward_pos_acc": 0.9809949588401156, "train/reward_pos_loss": 0.7693872988536096, "train/reward_pred": 0.020626646739611138, "train/reward_rate": 0.0263313972513089, "train_stats/sum_log_reward": 4.621739058876815, "train_stats/max_log_achievement_collect_drink": 3.3260869565217392, "train_stats/max_log_achievement_collect_sapling": 1.9782608695652173, "train_stats/max_log_achievement_collect_stone": 0.15217391304347827, "train_stats/max_log_achievement_collect_wood": 3.847826086956522, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.043478260869565216, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.43478260869565216, "train_stats/max_log_achievement_make_wood_sword": 0.021739130434782608, "train_stats/max_log_achievement_place_plant": 1.8478260869565217, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 1.1956521739130435, "train_stats/max_log_achievement_wake_up": 2.4565217391304346, "train_stats/mean_log_entropy": 0.515161654871443, "eval_stats/sum_log_reward": 4.349999904632568, "eval_stats/max_log_achievement_collect_drink": 2.625, "eval_stats/max_log_achievement_collect_sapling": 1.75, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 4.625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.625, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 1.75, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 1.625, "eval_stats/max_log_achievement_wake_up": 2.5, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 5.835405772813829e-06, "report/cont_loss_std": 4.797058500116691e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.000127072271425277, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 5.47917579751811e-06, "report/cont_pred": 0.9970653057098389, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 4.749114036560059, "report/dyn_loss_std": 7.23704719543457, "report/image_loss_mean": 3.951798677444458, "report/image_loss_std": 5.922313690185547, "report/model_loss_mean": 6.833932876586914, "report/model_loss_std": 9.227415084838867, "report/post_ent_mag": 49.01645278930664, "report/post_ent_max": 49.01645278930664, "report/post_ent_mean": 31.632047653198242, "report/post_ent_min": 16.635568618774414, "report/post_ent_std": 6.212660312652588, "report/prior_ent_mag": 72.78585815429688, "report/prior_ent_max": 72.78585815429688, "report/prior_ent_mean": 36.40988540649414, "report/prior_ent_min": 18.63588523864746, "report/prior_ent_std": 9.249974250793457, "report/rep_loss_mean": 4.749114036560059, "report/rep_loss_std": 7.23704719543457, "report/reward_avg": 0.02304687537252903, "report/reward_loss_mean": 0.0326605886220932, "report/reward_loss_std": 0.154476135969162, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.003495693206787, "report/reward_neg_acc": 0.9949849843978882, "report/reward_neg_loss": 0.014307352714240551, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7103708386421204, "report/reward_pred": 0.022658899426460266, "report/reward_rate": 0.0263671875, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 3.131585799565073e-06, "eval/cont_loss_std": 2.344686618016567e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00041313207475468516, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.329236394871259e-06, "eval/cont_pred": 0.9980453252792358, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 22.13239288330078, "eval/dyn_loss_std": 13.373262405395508, "eval/image_loss_mean": 27.778728485107422, "eval/image_loss_std": 32.340877532958984, "eval/model_loss_mean": 41.15477752685547, "eval/model_loss_std": 37.73998260498047, "eval/post_ent_mag": 49.238800048828125, "eval/post_ent_max": 49.238800048828125, "eval/post_ent_mean": 31.43368148803711, "eval/post_ent_min": 19.231502532958984, "eval/post_ent_std": 5.797973155975342, "eval/prior_ent_mag": 72.78585815429688, "eval/prior_ent_max": 72.78585815429688, "eval/prior_ent_mean": 42.63529968261719, "eval/prior_ent_min": 20.971424102783203, "eval/prior_ent_std": 10.894271850585938, "eval/rep_loss_mean": 22.13239288330078, "eval/rep_loss_std": 13.373262405395508, "eval/reward_avg": 0.01328125037252903, "eval/reward_loss_mean": 0.09661360830068588, "eval/reward_loss_std": 0.67165607213974, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.002262830734253, "eval/reward_neg_acc": 0.9990069270133972, "eval/reward_neg_loss": 0.06757769733667374, "eval/reward_pos_acc": 0.8235294222831726, "eval/reward_pos_loss": 1.8165639638900757, "eval/reward_pred": 0.010818114504218102, "eval/reward_rate": 0.0166015625, "replay/size": 86205.0, "replay/inserts": 7652.0, "replay/samples": 30608.0, "replay/insert_wait_avg": 1.547041203548194e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.597800642174074e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 18336.0, "eval_replay/inserts": 2448.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1793343849431457e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.450580596923828e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0932230949402, "timer/env.step_count": 956.0, "timer/env.step_total": 96.14827084541321, "timer/env.step_frac": 0.09613930844153488, "timer/env.step_avg": 0.10057350506842386, "timer/env.step_min": 0.023255109786987305, "timer/env.step_max": 3.248054027557373, "timer/replay._sample_count": 30608.0, "timer/replay._sample_total": 15.82405948638916, "timer/replay._sample_frac": 0.01582258445609621, "timer/replay._sample_avg": 0.0005169909659693269, "timer/replay._sample_min": 0.0003571510314941406, "timer/replay._sample_max": 0.022061586380004883, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1262.0, "timer/agent.policy_total": 20.408600568771362, "timer/agent.policy_frac": 0.02040669819320828, "timer/agent.policy_avg": 0.016171632780325962, "timer/agent.policy_min": 0.009723901748657227, "timer/agent.policy_max": 0.062290191650390625, "timer/dataset_train_count": 1913.0, "timer/dataset_train_total": 0.2885138988494873, "timer/dataset_train_frac": 0.00028848700519801273, "timer/dataset_train_avg": 0.0001508175111602129, "timer/dataset_train_min": 9.489059448242188e-05, "timer/dataset_train_max": 0.001218557357788086, "timer/agent.train_count": 1913.0, "timer/agent.train_total": 848.9631872177124, "timer/agent.train_frac": 0.8488840516191751, "timer/agent.train_avg": 0.44378629755238497, "timer/agent.train_min": 0.4343888759613037, "timer/agent.train_max": 0.9732184410095215, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4722862243652344, "timer/agent.report_frac": 0.0004722422004857437, "timer/agent.report_avg": 0.2361431121826172, "timer/agent.report_min": 0.22922730445861816, "timer/agent.report_max": 0.2430589199066162, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7894973754882812e-05, "timer/dataset_eval_frac": 2.7892373541496046e-08, "timer/dataset_eval_avg": 2.7894973754882812e-05, "timer/dataset_eval_min": 2.7894973754882812e-05, "timer/dataset_eval_max": 2.7894973754882812e-05, "fps": 7.651189485095201}
{"step": 86904, "time": 11357.382099866867, "episode/length": 168.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 86952, "time": 11364.433449745178, "episode/length": 136.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9927007299270073, "episode/intrinsic_return": 0.0}
{"step": 87152, "time": 11389.125306844711, "episode/length": 165.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 87632, "time": 11446.805434942245, "episode/length": 218.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 87720, "time": 11458.447044372559, "episode/length": 175.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9829545454545454, "episode/intrinsic_return": 0.0}
{"step": 87784, "time": 11467.383811235428, "episode/length": 187.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9840425531914894, "episode/intrinsic_return": 0.0}
{"step": 88032, "time": 11497.858926296234, "episode/length": 263.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9848484848484849, "episode/intrinsic_return": 0.0}
{"step": 88136, "time": 11511.540641784668, "episode/length": 239.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 88208, "time": 11521.423003911972, "episode/length": 52.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 88272, "time": 11530.42887187004, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 88432, "time": 11550.48098731041, "episode/length": 184.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 88784, "time": 11593.07131266594, "episode/length": 203.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 89336, "time": 11658.708357810974, "episode/length": 212.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 89448, "time": 11673.248591423035, "episode/length": 176.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 89456, "time": 11675.646160125732, "episode/length": 164.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9636363636363636, "episode/intrinsic_return": 0.0}
{"step": 89568, "time": 11690.196714639664, "episode/length": 230.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9783549783549783, "episode/intrinsic_return": 0.0}
{"step": 89696, "time": 11706.551748275757, "episode/length": 157.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 89872, "time": 11728.490924596786, "episode/length": 207.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 89920, "time": 11735.479471683502, "episode/length": 205.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 90064, "time": 11768.080425977707, "eval_episode/length": 43.0, "eval_episode/score": 1.1000000014901161, "eval_episode/reward_rate": 0.9772727272727273}
{"step": 90064, "time": 11773.769109249115, "eval_episode/length": 144.0, "eval_episode/score": 4.099999971687794, "eval_episode/reward_rate": 0.993103448275862}
{"step": 90064, "time": 11773.787584781647, "eval_episode/length": 144.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.993103448275862}
{"step": 90064, "time": 11776.839460849762, "eval_episode/length": 146.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9931972789115646}
{"step": 90064, "time": 11779.584113836288, "eval_episode/length": 176.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9717514124293786}
{"step": 90064, "time": 11781.26537513733, "eval_episode/length": 181.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.978021978021978}
{"step": 90064, "time": 11783.023611068726, "eval_episode/length": 143.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9930555555555556}
{"step": 90064, "time": 11788.13895201683, "eval_episode/length": 273.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9817518248175182}
{"step": 90072, "time": 11789.064707040787, "episode/length": 46.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 90424, "time": 11832.298792123795, "episode/length": 204.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 90688, "time": 11864.506781101227, "episode/length": 154.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 90792, "time": 11878.069707393646, "episode/length": 166.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9640718562874252, "episode/intrinsic_return": 0.0}
{"step": 90848, "time": 11886.06859922409, "episode/length": 188.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 91320, "time": 11942.439828395844, "episode/length": 218.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 91440, "time": 11958.118274450302, "episode/length": 170.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 91496, "time": 11966.155637979507, "episode/length": 202.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 91848, "time": 12008.469753742218, "episode/length": 144.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 91888, "time": 12014.668849945068, "episode/length": 182.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 91992, "time": 12028.21747303009, "episode/length": 149.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 92152, "time": 12048.293873548508, "episode/length": 103.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 92200, "time": 12055.385913848877, "episode/length": 168.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 92752, "time": 12120.927173614502, "episode/length": 156.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 92928, "time": 12142.71315073967, "episode/length": 185.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 92976, "time": 12149.80161690712, "episode/length": 140.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 93296, "time": 12188.41403889656, "episode/length": 162.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 93344, "time": 12196.081782579422, "episode/length": 427.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9789719626168224, "episode/intrinsic_return": 0.0}
{"step": 93744, "time": 12244.507252454758, "episode/length": 231.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.978448275862069, "episode/intrinsic_return": 0.0}
{"step": 93824, "time": 12255.333647966385, "episode/length": 208.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 93952, "time": 12271.788373947144, "episode/length": 218.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 93992, "time": 12277.963619470596, "episode/length": 154.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 94328, "time": 12318.760201931, "episode/length": 168.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 94445, "time": 12335.033836364746, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.687207723401256, "train/action_min": 0.0, "train/action_std": 3.3410589584370247, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.049346378457146824, "train/actor_opt_grad_steps": 22255.0, "train/actor_opt_loss": -11.858737814691416, "train/adv_mag": 0.6220667408299201, "train/adv_max": 0.5965371838549978, "train/adv_mean": 0.0033438632579924797, "train/adv_min": -0.47935203547330246, "train/adv_std": 0.06627350596269381, "train/cont_avg": 0.9941154558634021, "train/cont_loss_mean": 0.00019492324691048723, "train/cont_loss_std": 0.00540307366888096, "train/cont_neg_acc": 0.9928612355718908, "train/cont_neg_loss": 0.023133642550053936, "train/cont_pos_acc": 0.9999847919056096, "train/cont_pos_loss": 3.665153084091227e-05, "train/cont_pred": 0.9941414920325132, "train/cont_rate": 0.9941154558634021, "train/dyn_loss_mean": 5.9054009177021145, "train/dyn_loss_std": 8.282001532230181, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.2436335292673601, "train/extr_critic_critic_opt_grad_steps": 22255.0, "train/extr_critic_critic_opt_loss": 16264.683251449742, "train/extr_critic_mag": 6.01246252010778, "train/extr_critic_max": 6.01246252010778, "train/extr_critic_mean": 1.0489607038571662, "train/extr_critic_min": -0.6841774244898373, "train/extr_critic_std": 1.3691250774049268, "train/extr_return_normed_mag": 1.6825816754213314, "train/extr_return_normed_max": 1.6825816754213314, "train/extr_return_normed_mean": 0.3218444955256796, "train/extr_return_normed_min": -0.17226496031603863, "train/extr_return_normed_std": 0.3323412476894782, "train/extr_return_rate": 0.4984771255979833, "train/extr_return_raw_mag": 6.826967150894637, "train/extr_return_raw_max": 6.826967150894637, "train/extr_return_raw_mean": 1.0631385331915826, "train/extr_return_raw_min": -1.0295679821181543, "train/extr_return_raw_std": 1.4078636298474578, "train/extr_reward_mag": 1.0071465809320665, "train/extr_reward_max": 1.0071465809320665, "train/extr_reward_mean": 0.026973189017975453, "train/extr_reward_min": -0.6944980307952645, "train/extr_reward_std": 0.16578133050928412, "train/image_loss_mean": 4.46966570308528, "train/image_loss_std": 8.371939322383133, "train/model_loss_mean": 8.055294857811681, "train/model_loss_std": 12.264095638216157, "train/model_opt_grad_norm": 52.64518142975483, "train/model_opt_grad_steps": 22233.484536082473, "train/model_opt_loss": 10410.845343206347, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1288.659793814433, "train/policy_entropy_mag": 2.490489194073628, "train/policy_entropy_max": 2.490489194073628, "train/policy_entropy_mean": 0.5464380082395888, "train/policy_entropy_min": 0.07937502592187567, "train/policy_entropy_std": 0.5907954353954374, "train/policy_logprob_mag": 7.438383434236664, "train/policy_logprob_max": -0.009455658173783845, "train/policy_logprob_mean": -0.5458494983997542, "train/policy_logprob_min": -7.438383434236664, "train/policy_logprob_std": 1.1135611288326304, "train/policy_randomness_mag": 0.8790333928521147, "train/policy_randomness_max": 0.8790333928521147, "train/policy_randomness_mean": 0.1928686374395164, "train/policy_randomness_min": 0.02801590086412184, "train/policy_randomness_std": 0.20852486328365877, "train/post_ent_mag": 48.592811604136045, "train/post_ent_max": 48.592811604136045, "train/post_ent_mean": 30.733014863790924, "train/post_ent_min": 16.242271831355144, "train/post_ent_std": 5.628258744465936, "train/prior_ent_mag": 71.87308018477921, "train/prior_ent_max": 71.87308018477921, "train/prior_ent_mean": 36.65578991604834, "train/prior_ent_min": 18.686860703930414, "train/prior_ent_std": 9.337372081795918, "train/rep_loss_mean": 5.9054009177021145, "train/rep_loss_std": 8.282001532230181, "train/reward_avg": 0.021574480372682673, "train/reward_loss_mean": 0.04219372780782353, "train/reward_loss_std": 0.19911930064872368, "train/reward_max_data": 1.0036082482829536, "train/reward_max_pred": 1.0038873215311581, "train/reward_neg_acc": 0.9961077601639265, "train/reward_neg_loss": 0.02233194405232201, "train/reward_pos_acc": 0.9820680387855805, "train/reward_pos_loss": 0.7609312989048123, "train/reward_pred": 0.021296198095780674, "train/reward_rate": 0.02683533344072165, "train_stats/sum_log_reward": 4.742857092902774, "train_stats/max_log_achievement_collect_drink": 3.0476190476190474, "train_stats/max_log_achievement_collect_sapling": 2.4047619047619047, "train_stats/max_log_achievement_collect_stone": 0.21428571428571427, "train_stats/max_log_achievement_collect_wood": 4.0476190476190474, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.07142857142857142, "train_stats/max_log_achievement_eat_cow": 0.023809523809523808, "train_stats/max_log_achievement_make_wood_pickaxe": 0.7142857142857143, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 2.261904761904762, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 1.4285714285714286, "train_stats/max_log_achievement_wake_up": 2.380952380952381, "train_stats/mean_log_entropy": 0.47901062951201484, "train_stats/max_log_achievement_collect_coal": 0.02702702702702703, "eval_stats/sum_log_reward": 4.724999845027924, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 3.0, "eval_stats/max_log_achievement_collect_sapling": 2.375, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 3.125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.125, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.25, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.25, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 1.375, "eval_stats/max_log_achievement_wake_up": 1.875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.00012979279563296586, "report/cont_loss_std": 0.002940115286037326, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 3.1369123462354764e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.00013037289318162948, "report/cont_pred": 0.9940154552459717, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 5.7469868659973145, "report/dyn_loss_std": 8.26418399810791, "report/image_loss_mean": 3.6387264728546143, "report/image_loss_std": 5.99902868270874, "report/model_loss_mean": 7.127961158752441, "report/model_loss_std": 9.960711479187012, "report/post_ent_mag": 49.36402893066406, "report/post_ent_max": 49.36402893066406, "report/post_ent_mean": 31.081912994384766, "report/post_ent_min": 17.834444046020508, "report/post_ent_std": 5.677462577819824, "report/prior_ent_mag": 72.91268920898438, "report/prior_ent_max": 72.91268920898438, "report/prior_ent_mean": 36.78505325317383, "report/prior_ent_min": 20.012359619140625, "report/prior_ent_std": 9.56044864654541, "report/rep_loss_mean": 5.7469868659973145, "report/rep_loss_std": 8.26418399810791, "report/reward_avg": 0.02060546912252903, "report/reward_loss_mean": 0.040913064032793045, "report/reward_loss_std": 0.18430620431900024, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0006823539733887, "report/reward_neg_acc": 0.9949949979782104, "report/reward_neg_loss": 0.024684283882379532, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6894152164459229, "report/reward_pred": 0.021339522674679756, "report/reward_rate": 0.0244140625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.0003306184080429375, "eval/cont_loss_std": 0.007894473150372505, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.01941269263625145, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.00025578675558790565, "eval/cont_pred": 0.9959381818771362, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 19.719284057617188, "eval/dyn_loss_std": 13.097463607788086, "eval/image_loss_mean": 23.752038955688477, "eval/image_loss_std": 26.641942977905273, "eval/model_loss_mean": 35.79389190673828, "eval/model_loss_std": 32.1955451965332, "eval/post_ent_mag": 53.42695617675781, "eval/post_ent_max": 53.42695617675781, "eval/post_ent_mean": 32.50129699707031, "eval/post_ent_min": 19.23674774169922, "eval/post_ent_std": 5.673933506011963, "eval/prior_ent_mag": 72.91268920898438, "eval/prior_ent_max": 72.91268920898438, "eval/prior_ent_mean": 43.44014358520508, "eval/prior_ent_min": 20.922157287597656, "eval/prior_ent_std": 10.242619514465332, "eval/rep_loss_mean": 19.719284057617188, "eval/rep_loss_std": 13.097463607788086, "eval/reward_avg": 0.03437500074505806, "eval/reward_loss_mean": 0.20995202660560608, "eval/reward_loss_std": 1.1354542970657349, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.000976324081421, "eval/reward_neg_acc": 0.9969481229782104, "eval/reward_neg_loss": 0.09896386414766312, "eval/reward_pos_acc": 0.6829267740249634, "eval/reward_pos_loss": 2.8709607124328613, "eval/reward_pred": 0.021112903952598572, "eval/reward_rate": 0.0400390625, "replay/size": 93941.0, "replay/inserts": 7736.0, "replay/samples": 30944.0, "replay/insert_wait_avg": 1.522846281097002e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.617852680439047e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 20528.0, "eval_replay/inserts": 2192.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1651185307189497e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2497415542603, "timer/env.step_count": 967.0, "timer/env.step_total": 89.20358681678772, "timer/env.step_frac": 0.08918131453668436, "timer/env.step_avg": 0.09224776299564397, "timer/env.step_min": 0.02265334129333496, "timer/env.step_max": 2.037424087524414, "timer/replay._sample_count": 30944.0, "timer/replay._sample_total": 16.071113109588623, "timer/replay._sample_frac": 0.016067100486940558, "timer/replay._sample_avg": 0.0005193612044205217, "timer/replay._sample_min": 0.0003902912139892578, "timer/replay._sample_max": 0.01148223876953125, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1241.0, "timer/agent.policy_total": 19.922365427017212, "timer/agent.policy_frac": 0.019917391226775428, "timer/agent.policy_avg": 0.016053477378740702, "timer/agent.policy_min": 0.009450674057006836, "timer/agent.policy_max": 0.04702925682067871, "timer/dataset_train_count": 1934.0, "timer/dataset_train_total": 0.292072057723999, "timer/dataset_train_frac": 0.00029199913340657944, "timer/dataset_train_avg": 0.00015101967824405327, "timer/dataset_train_min": 9.489059448242188e-05, "timer/dataset_train_max": 0.0005564689636230469, "timer/agent.train_count": 1934.0, "timer/agent.train_total": 857.5389187335968, "timer/agent.train_frac": 0.8573248091032655, "timer/agent.train_avg": 0.4434017159946209, "timer/agent.train_min": 0.43314313888549805, "timer/agent.train_max": 0.933229923248291, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4745829105377197, "timer/agent.report_frac": 0.0004744644170567628, "timer/agent.report_avg": 0.23729145526885986, "timer/agent.report_min": 0.23003649711608887, "timer/agent.report_max": 0.24454641342163086, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.6226043701171875e-05, "timer/dataset_eval_frac": 2.6219495603587916e-08, "timer/dataset_eval_avg": 2.6226043701171875e-05, "timer/dataset_eval_min": 2.6226043701171875e-05, "timer/dataset_eval_max": 2.6226043701171875e-05, "fps": 7.733962724259022}
{"step": 94776, "time": 12373.505913734436, "episode/length": 184.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 94840, "time": 12382.454822063446, "episode/length": 238.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 94944, "time": 12395.977869987488, "episode/length": 149.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 94976, "time": 12401.33166718483, "episode/length": 203.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 95312, "time": 12441.761771202087, "episode/length": 164.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 95440, "time": 12458.137497663498, "episode/length": 138.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.0}
{"step": 95448, "time": 12460.677492380142, "episode/length": 202.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 95592, "time": 12478.859750032425, "episode/length": 204.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9804878048780488, "episode/intrinsic_return": 0.0}
{"step": 96000, "time": 12528.480133771896, "episode/length": 152.0, "episode/score": 3.100000023841858, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 96184, "time": 12551.847389698029, "episode/length": 167.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 96504, "time": 12590.626428365707, "episode/length": 194.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 96696, "time": 12614.57783150673, "episode/length": 172.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 96720, "time": 12618.847790241241, "episode/length": 159.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 96968, "time": 12649.257293462753, "episode/length": 189.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 97056, "time": 12661.06215596199, "episode/length": 41.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 97168, "time": 12675.59864449501, "episode/length": 196.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 97184, "time": 12679.015587806702, "episode/length": 275.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9818840579710145, "episode/intrinsic_return": 0.0}
{"step": 97368, "time": 12701.934876441956, "episode/length": 170.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 97768, "time": 12749.615924596786, "episode/length": 72.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9863013698630136, "episode/intrinsic_return": 0.0}
{"step": 97784, "time": 12753.00758433342, "episode/length": 51.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 97976, "time": 12776.727699041367, "episode/length": 183.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 98312, "time": 12818.1083278656, "episode/length": 156.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 98368, "time": 12826.15045452118, "episode/length": 272.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9853479853479854, "episode/intrinsic_return": 0.0}
{"step": 98368, "time": 12826.161353826523, "episode/length": 208.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 98416, "time": 12834.916756629944, "episode/length": 180.0, "episode/score": 5.099999964237213, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 99112, "time": 12917.32522392273, "episode/length": 165.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 99296, "time": 12940.210486888885, "episode/length": 190.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 99360, "time": 12949.259914636612, "episode/length": 172.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9595375722543352, "episode/intrinsic_return": 0.0}
{"step": 99400, "time": 12955.373337984085, "episode/length": 135.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9485294117647058, "episode/intrinsic_return": 0.0}
{"step": 99656, "time": 12986.62146449089, "episode/length": 160.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 99816, "time": 13006.93075466156, "episode/length": 180.0, "episode/score": 5.099999964237213, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 99848, "time": 13012.195699930191, "episode/length": 334.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.991044776119403, "episode/intrinsic_return": 0.0}
{"step": 99848, "time": 13012.212333202362, "episode/length": 178.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9664804469273743, "episode/intrinsic_return": 0.0}
{"step": 100048, "time": 13055.556396484375, "eval_episode/length": 52.0, "eval_episode/score": -0.9000000283122063, "eval_episode/reward_rate": 0.9811320754716981}
{"step": 100048, "time": 13061.531353473663, "eval_episode/length": 163.0, "eval_episode/score": 6.099999971687794, "eval_episode/reward_rate": 0.9939024390243902}
{"step": 100048, "time": 13063.101421117783, "eval_episode/length": 165.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9698795180722891}
{"step": 100048, "time": 13065.038813352585, "eval_episode/length": 175.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9772727272727273}
{"step": 100048, "time": 13066.857384681702, "eval_episode/length": 184.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.972972972972973}
{"step": 100048, "time": 13068.378645658493, "eval_episode/length": 185.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9731182795698925}
{"step": 100048, "time": 13069.999735832214, "eval_episode/length": 188.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9788359788359788}
{"step": 100048, "time": 13071.806444644928, "eval_episode/length": 29.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.8666666666666667}
{"step": 100536, "time": 13128.306804180145, "episode/length": 141.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 100560, "time": 13132.68925189972, "episode/length": 157.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9620253164556962, "episode/intrinsic_return": 0.0}
{"step": 100728, "time": 13153.690520524979, "episode/length": 201.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 100936, "time": 13179.219528198242, "episode/length": 159.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 101040, "time": 13192.82889342308, "episode/length": 148.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 101200, "time": 13212.994089365005, "episode/length": 229.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 101456, "time": 13244.337158679962, "episode/length": 204.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 101512, "time": 13252.349741220474, "episode/length": 207.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 102168, "time": 13329.857642889023, "episode/length": 200.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 102193, "time": 13335.290248155594, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.611474546126133, "train/action_min": 0.0, "train/action_std": 3.3362902754946693, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04828232621359084, "train/actor_opt_grad_steps": 24190.0, "train/actor_opt_loss": -13.946258499861305, "train/adv_mag": 0.6139917838449923, "train/adv_max": 0.5819798420747945, "train/adv_mean": 0.002625771282566508, "train/adv_min": -0.48858479313899816, "train/adv_std": 0.06424921125636818, "train/cont_avg": 0.9942924222797928, "train/cont_loss_mean": 0.00010591123840292519, "train/cont_loss_std": 0.0031162725953621127, "train/cont_neg_acc": 0.9992598079029142, "train/cont_neg_loss": 0.007009190063536388, "train/cont_pos_acc": 0.9999796408445724, "train/cont_pos_loss": 5.937336029875846e-05, "train/cont_pred": 0.9942671150123518, "train/cont_rate": 0.9942924222797928, "train/dyn_loss_mean": 5.875160538470807, "train/dyn_loss_std": 8.305599785839338, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.2411412439198073, "train/extr_critic_critic_opt_grad_steps": 24190.0, "train/extr_critic_critic_opt_loss": 16087.25015685719, "train/extr_critic_mag": 6.093539640693467, "train/extr_critic_max": 6.093539640693467, "train/extr_critic_mean": 1.015773542341173, "train/extr_critic_min": -0.6847469176653136, "train/extr_critic_std": 1.3753776142634258, "train/extr_return_normed_mag": 1.7096210959044145, "train/extr_return_normed_max": 1.7096210959044145, "train/extr_return_normed_mean": 0.3133325289568135, "train/extr_return_normed_min": -0.17378726867968555, "train/extr_return_normed_std": 0.3351459458393136, "train/extr_return_rate": 0.4766802518324531, "train/extr_return_raw_mag": 6.905080224565891, "train/extr_return_raw_max": 6.905080224565891, "train/extr_return_raw_mean": 1.0268234017599431, "train/extr_return_raw_min": -1.0243693429571359, "train/extr_return_raw_std": 1.4115627395674355, "train/extr_reward_mag": 1.0076691196372471, "train/extr_reward_max": 1.0076691196372471, "train/extr_reward_mean": 0.02601015579843305, "train/extr_reward_min": -0.6873230699430476, "train/extr_reward_std": 0.1637901983035661, "train/image_loss_mean": 4.263451030217304, "train/image_loss_std": 8.12710550906127, "train/model_loss_mean": 7.830347678821939, "train/model_loss_std": 12.027366638183594, "train/model_opt_grad_norm": 49.01543137940718, "train/model_opt_grad_steps": 24166.60621761658, "train/model_opt_loss": 10327.160960775584, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1321.2435233160622, "train/policy_entropy_mag": 2.4771532802384133, "train/policy_entropy_max": 2.4771532802384133, "train/policy_entropy_mean": 0.5393074900683962, "train/policy_entropy_min": 0.07937501822574151, "train/policy_entropy_std": 0.5970791118132636, "train/policy_logprob_mag": 7.438383547135586, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5396773231461875, "train/policy_logprob_min": -7.438383547135586, "train/policy_logprob_std": 1.1097211698793994, "train/policy_randomness_mag": 0.8743264029680756, "train/policy_randomness_max": 0.8743264029680756, "train/policy_randomness_mean": 0.19035187548923987, "train/policy_randomness_min": 0.028015898202830646, "train/policy_randomness_std": 0.21074272522345724, "train/post_ent_mag": 49.98484831894, "train/post_ent_max": 49.98484831894, "train/post_ent_mean": 31.596262897234507, "train/post_ent_min": 16.82623411089645, "train/post_ent_std": 5.85942930508154, "train/prior_ent_mag": 72.17393418544314, "train/prior_ent_max": 72.17393418544314, "train/prior_ent_mean": 37.46784959308842, "train/prior_ent_min": 19.31476664172553, "train/prior_ent_std": 9.278906760438119, "train/rep_loss_mean": 5.875160538470807, "train/rep_loss_std": 8.305599785839338, "train/reward_avg": 0.021395320538431406, "train/reward_loss_mean": 0.04169439683653839, "train/reward_loss_std": 0.19457049648533215, "train/reward_max_data": 1.0051813483855885, "train/reward_max_pred": 1.0044008351360578, "train/reward_neg_acc": 0.99597199160818, "train/reward_neg_loss": 0.022174130874285426, "train/reward_pos_acc": 0.9834923188303418, "train/reward_pos_loss": 0.7555933119101845, "train/reward_pred": 0.021115480475803267, "train/reward_rate": 0.026599943329015545, "train_stats/sum_log_reward": 4.766666561365128, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 3.5238095238095237, "train_stats/max_log_achievement_collect_sapling": 2.0714285714285716, "train_stats/max_log_achievement_collect_stone": 0.35714285714285715, "train_stats/max_log_achievement_collect_wood": 4.333333333333333, "train_stats/max_log_achievement_defeat_skeleton": 0.023809523809523808, "train_stats/max_log_achievement_defeat_zombie": 0.047619047619047616, "train_stats/max_log_achievement_eat_cow": 0.047619047619047616, "train_stats/max_log_achievement_make_wood_pickaxe": 0.5238095238095238, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.9761904761904763, "train_stats/max_log_achievement_place_stone": 0.047619047619047616, "train_stats/max_log_achievement_place_table": 1.5, "train_stats/max_log_achievement_wake_up": 2.4285714285714284, "train_stats/mean_log_entropy": 0.45511214896326974, "eval_stats/sum_log_reward": 4.474999979138374, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 3.0, "eval_stats/max_log_achievement_collect_sapling": 1.375, "eval_stats/max_log_achievement_collect_stone": 0.375, "eval_stats/max_log_achievement_collect_wood": 4.75, "eval_stats/max_log_achievement_defeat_skeleton": 0.125, "eval_stats/max_log_achievement_defeat_zombie": 0.125, "eval_stats/max_log_achievement_eat_cow": 0.25, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.5, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 1.125, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 1.375, "eval_stats/max_log_achievement_wake_up": 1.75, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 2.694169324968243e-06, "report/cont_loss_std": 3.734236815944314e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0006254874751903117, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 8.642182933726872e-07, "report/cont_pred": 0.9970712661743164, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 5.429025650024414, "report/dyn_loss_std": 7.668009281158447, "report/image_loss_mean": 3.308953046798706, "report/image_loss_std": 5.795731544494629, "report/model_loss_mean": 6.609064102172852, "report/model_loss_std": 9.664036750793457, "report/post_ent_mag": 48.42302703857422, "report/post_ent_max": 48.42302703857422, "report/post_ent_mean": 30.524028778076172, "report/post_ent_min": 17.353492736816406, "report/post_ent_std": 5.093406677246094, "report/prior_ent_mag": 72.68167114257812, "report/prior_ent_max": 72.68167114257812, "report/prior_ent_mean": 36.03364562988281, "report/prior_ent_min": 18.885334014892578, "report/prior_ent_std": 8.7612943649292, "report/rep_loss_mean": 5.429025650024414, "report/rep_loss_std": 7.668009281158447, "report/reward_avg": 0.02041015587747097, "report/reward_loss_mean": 0.042692434042692184, "report/reward_loss_std": 0.20955096185207367, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.002394199371338, "report/reward_neg_acc": 0.9969969987869263, "report/reward_neg_loss": 0.02281131222844124, "report/reward_pos_acc": 0.9599999785423279, "report/reward_pos_loss": 0.8371419906616211, "report/reward_pred": 0.019233515486121178, "report/reward_rate": 0.0244140625, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 3.314570858492516e-05, "eval/cont_loss_std": 0.0009983043419197202, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.016515614464879036, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 8.903945172278327e-07, "eval/cont_pred": 0.9980777502059937, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 23.491912841796875, "eval/dyn_loss_std": 13.989344596862793, "eval/image_loss_mean": 30.402990341186523, "eval/image_loss_std": 33.916866302490234, "eval/model_loss_mean": 44.66211700439453, "eval/model_loss_std": 39.54122543334961, "eval/post_ent_mag": 53.42149353027344, "eval/post_ent_max": 53.42149353027344, "eval/post_ent_mean": 31.756181716918945, "eval/post_ent_min": 18.056291580200195, "eval/post_ent_std": 5.488138675689697, "eval/prior_ent_mag": 72.68167114257812, "eval/prior_ent_max": 72.68167114257812, "eval/prior_ent_mean": 42.75093078613281, "eval/prior_ent_min": 19.550373077392578, "eval/prior_ent_std": 9.67953109741211, "eval/rep_loss_mean": 23.491912841796875, "eval/rep_loss_std": 13.989344596862793, "eval/reward_avg": 0.02568359300494194, "eval/reward_loss_mean": 0.16394422948360443, "eval/reward_loss_std": 0.9491915702819824, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.002234697341919, "eval/reward_neg_acc": 0.991959810256958, "eval/reward_neg_loss": 0.08909597992897034, "eval/reward_pos_acc": 0.6551724076271057, "eval/reward_pos_loss": 2.73201322555542, "eval/reward_pred": 0.019308684393763542, "eval/reward_rate": 0.0283203125, "replay/size": 101689.0, "replay/inserts": 7748.0, "replay/samples": 30992.0, "replay/insert_wait_avg": 1.5324578804642378e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.501815358695137e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 22096.0, "eval_replay/inserts": 1568.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1077036662977568e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.08970832824707e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2420296669006, "timer/env.step_count": 969.0, "timer/env.step_total": 89.67991590499878, "timer/env.step_frac": 0.08965821595685583, "timer/env.step_avg": 0.09254893282249615, "timer/env.step_min": 0.023070573806762695, "timer/env.step_max": 3.227200984954834, "timer/replay._sample_count": 30992.0, "timer/replay._sample_total": 15.75318717956543, "timer/replay._sample_frac": 0.015749375363492312, "timer/replay._sample_avg": 0.0005082985021800926, "timer/replay._sample_min": 0.0003809928894042969, "timer/replay._sample_max": 0.01159048080444336, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1165.0, "timer/agent.policy_total": 18.616214752197266, "timer/agent.policy_frac": 0.01861171016618529, "timer/agent.policy_avg": 0.015979583478280913, "timer/agent.policy_min": 0.009391069412231445, "timer/agent.policy_max": 0.057900190353393555, "timer/dataset_train_count": 1937.0, "timer/dataset_train_total": 0.2914600372314453, "timer/dataset_train_frac": 0.000291389512324839, "timer/dataset_train_avg": 0.00015046981787890826, "timer/dataset_train_min": 9.179115295410156e-05, "timer/dataset_train_max": 0.0006740093231201172, "timer/agent.train_count": 1937.0, "timer/agent.train_total": 858.7529780864716, "timer/agent.train_frac": 0.858545184681404, "timer/agent.train_avg": 0.4433417543038057, "timer/agent.train_min": 0.4319479465484619, "timer/agent.train_max": 0.9578464031219482, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4761013984680176, "timer/agent.report_frac": 0.000475986195687626, "timer/agent.report_avg": 0.2380506992340088, "timer/agent.report_min": 0.230010986328125, "timer/agent.report_max": 0.24609041213989258, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.5033950805664062e-05, "timer/dataset_eval_frac": 2.5027893312982297e-08, "timer/dataset_eval_avg": 2.5033950805664062e-05, "timer/dataset_eval_min": 2.5033950805664062e-05, "timer/dataset_eval_max": 2.5033950805664062e-05, "fps": 7.746021878839816}
{"step": 102208, "time": 13336.94533753395, "episode/length": 145.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 102328, "time": 13352.39576792717, "episode/length": 223.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 102376, "time": 13359.484234333038, "episode/length": 179.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 102584, "time": 13385.13316988945, "episode/length": 231.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 102672, "time": 13396.890852689743, "episode/length": 144.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9586206896551724, "episode/intrinsic_return": 0.0}
{"step": 102808, "time": 13414.13641667366, "episode/length": 200.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 103152, "time": 13455.552341461182, "episode/length": 211.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 103528, "time": 13500.841688394547, "episode/length": 149.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 103640, "time": 13515.476175785065, "episode/length": 183.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 103776, "time": 13532.69240307808, "episode/length": 137.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9565217391304348, "episode/intrinsic_return": 0.0}
{"step": 104088, "time": 13570.387908935547, "episode/length": 187.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 104096, "time": 13572.78566622734, "episode/length": 214.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 104120, "time": 13577.066704750061, "episode/length": 42.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 104176, "time": 13585.11739563942, "episode/length": 170.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 104304, "time": 13601.608276367188, "episode/length": 261.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9961832061068703, "episode/intrinsic_return": 0.0}
{"step": 104512, "time": 13627.159760951996, "episode/length": 169.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 105080, "time": 13694.54829621315, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 105144, "time": 13703.460488319397, "episode/length": 201.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 105448, "time": 13740.670851707458, "episode/length": 169.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 105496, "time": 13747.771204948425, "episode/length": 171.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 105520, "time": 13752.221285104752, "episode/length": 151.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 105752, "time": 13780.64942407608, "episode/length": 196.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 105800, "time": 13787.696245670319, "episode/length": 212.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 106360, "time": 13854.304558753967, "episode/length": 159.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 106408, "time": 13861.416106462479, "episode/length": 157.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 107024, "time": 13935.613359689713, "episode/length": 190.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 107056, "time": 13941.385489225388, "episode/length": 156.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 107136, "time": 13952.113496541977, "episode/length": 172.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 107216, "time": 13963.00637459755, "episode/length": 337.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9911242603550295, "episode/intrinsic_return": 0.0}
{"step": 107232, "time": 13966.277994632721, "episode/length": 222.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.0}
{"step": 107696, "time": 14022.044034481049, "episode/length": 160.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 107848, "time": 14041.031554460526, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 107896, "time": 14048.051324129105, "episode/length": 296.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9865319865319865, "episode/intrinsic_return": 0.0}
{"step": 108136, "time": 14077.518632411957, "episode/length": 134.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9925925925925926, "episode/intrinsic_return": 0.0}
{"step": 108336, "time": 14102.312346696854, "episode/length": 163.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 108528, "time": 14126.125907421112, "episode/length": 163.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 108880, "time": 14168.410875082016, "episode/length": 147.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 109336, "time": 14222.953280687332, "episode/length": 262.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9961977186311787, "episode/intrinsic_return": 0.0}
{"step": 109480, "time": 14241.336338996887, "episode/length": 167.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 109536, "time": 14249.319391489029, "episode/length": 210.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.981042654028436, "episode/intrinsic_return": 0.0}
{"step": 109536, "time": 14249.32629108429, "episode/length": 125.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9603174603174603, "episode/intrinsic_return": 0.0}
{"step": 109736, "time": 14275.681801319122, "episode/length": 229.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 110032, "time": 14325.920448064804, "eval_episode/length": 45.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9782608695652174}
{"step": 110032, "time": 14331.143327236176, "eval_episode/length": 137.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9927536231884058}
{"step": 110032, "time": 14333.005333423615, "eval_episode/length": 146.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9931972789115646}
{"step": 110032, "time": 14333.012839794159, "eval_episode/length": 146.0, "eval_episode/score": 5.0999999940395355, "eval_episode/reward_rate": 0.9931972789115646}
{"step": 110032, "time": 14337.008270263672, "eval_episode/length": 165.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9819277108433735}
{"step": 110032, "time": 14339.469344377518, "eval_episode/length": 184.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9621621621621622}
{"step": 110032, "time": 14340.97137260437, "eval_episode/length": 39.0, "eval_episode/score": 1.0999999940395355, "eval_episode/reward_rate": 0.975}
{"step": 110032, "time": 14343.757943153381, "eval_episode/length": 219.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9954545454545455}
{"step": 110032, "time": 14343.765805721283, "eval_episode/length": 173.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9770114942528736}
{"step": 110033, "time": 14344.780777931213, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.626451453384088, "train/action_min": 0.0, "train/action_std": 3.3316888310471358, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.05065570607287239, "train/actor_opt_grad_steps": 26135.0, "train/actor_opt_loss": -10.233120524103525, "train/adv_mag": 0.609684152870762, "train/adv_max": 0.5845836212440413, "train/adv_mean": 0.004252068271203565, "train/adv_min": -0.47577292152813505, "train/adv_std": 0.06740303926778082, "train/cont_avg": 0.9941505899234694, "train/cont_loss_mean": 0.00013876959369275827, "train/cont_loss_std": 0.0040774854104623105, "train/cont_neg_acc": 0.9956997094713912, "train/cont_neg_loss": 0.014045876040821598, "train/cont_pos_acc": 0.9999799339138732, "train/cont_pos_loss": 5.643024572936277e-05, "train/cont_pred": 0.9941457631636639, "train/cont_rate": 0.9941505899234694, "train/dyn_loss_mean": 6.030640222588364, "train/dyn_loss_std": 8.318591901234218, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.2740750373626242, "train/extr_critic_critic_opt_grad_steps": 26135.0, "train/extr_critic_critic_opt_loss": 16523.779331752234, "train/extr_critic_mag": 6.144399299913523, "train/extr_critic_max": 6.144399299913523, "train/extr_critic_mean": 1.0768167720157273, "train/extr_critic_min": -0.6689835196855117, "train/extr_critic_std": 1.3686243824812832, "train/extr_return_normed_mag": 1.700404558254748, "train/extr_return_normed_max": 1.700404558254748, "train/extr_return_normed_mean": 0.32489220562333965, "train/extr_return_normed_min": -0.17310256674429592, "train/extr_return_normed_std": 0.3351877219214731, "train/extr_return_rate": 0.515716372856072, "train/extr_return_raw_mag": 6.869816867672667, "train/extr_return_raw_max": 6.869816867672667, "train/extr_return_raw_mean": 1.0946615181711254, "train/extr_return_raw_min": -0.9965461030298349, "train/extr_return_raw_std": 1.4075502248442904, "train/extr_reward_mag": 1.008571056687102, "train/extr_reward_max": 1.008571056687102, "train/extr_reward_mean": 0.028403353597018486, "train/extr_reward_min": -0.7014034676308535, "train/extr_reward_std": 0.17004063820504411, "train/image_loss_mean": 4.42410714893925, "train/image_loss_std": 8.643032643259788, "train/model_loss_mean": 8.084994834296557, "train/model_loss_std": 12.508786921598473, "train/model_opt_grad_norm": 54.16787362585262, "train/model_opt_grad_steps": 26109.581632653062, "train/model_opt_loss": 7500.487069266183, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 937.5, "train/policy_entropy_mag": 2.464515362467085, "train/policy_entropy_max": 2.464515362467085, "train/policy_entropy_mean": 0.4926747548945096, "train/policy_entropy_min": 0.07937501519158179, "train/policy_entropy_std": 0.5603287694405537, "train/policy_logprob_mag": 7.438383640075217, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.49391464128786206, "train/policy_logprob_min": -7.438383640075217, "train/policy_logprob_std": 1.077730543455299, "train/policy_randomness_mag": 0.8698657702426521, "train/policy_randomness_max": 0.8698657702426521, "train/policy_randomness_mean": 0.17389256651608312, "train/policy_randomness_min": 0.0280158971151223, "train/policy_randomness_std": 0.19777146711641427, "train/post_ent_mag": 50.58270127432687, "train/post_ent_max": 50.58270127432687, "train/post_ent_mean": 32.21782891604365, "train/post_ent_min": 17.189439861141906, "train/post_ent_std": 5.833824598059362, "train/prior_ent_mag": 72.48960016211684, "train/prior_ent_max": 72.48960016211684, "train/prior_ent_mean": 38.23132668709268, "train/prior_ent_min": 19.925801476653742, "train/prior_ent_std": 9.165619791770467, "train/rep_loss_mean": 6.030640222588364, "train/rep_loss_std": 8.318591901234218, "train/reward_avg": 0.022031947533238908, "train/reward_loss_mean": 0.04236478689221703, "train/reward_loss_std": 0.19907771723763068, "train/reward_max_data": 1.0030612252196487, "train/reward_max_pred": 1.004157152102918, "train/reward_neg_acc": 0.9959992976212988, "train/reward_neg_loss": 0.021994755361039117, "train/reward_pos_acc": 0.9806287212639438, "train/reward_pos_loss": 0.767668643472146, "train/reward_pred": 0.021678084509960394, "train/reward_rate": 0.02732880261479592, "train_stats/sum_log_reward": 5.052380891073318, "train_stats/max_log_achievement_collect_coal": 0.047619047619047616, "train_stats/max_log_achievement_collect_drink": 3.9285714285714284, "train_stats/max_log_achievement_collect_sapling": 2.261904761904762, "train_stats/max_log_achievement_collect_stone": 0.40476190476190477, "train_stats/max_log_achievement_collect_wood": 4.642857142857143, "train_stats/max_log_achievement_defeat_skeleton": 0.023809523809523808, "train_stats/max_log_achievement_defeat_zombie": 0.07142857142857142, "train_stats/max_log_achievement_eat_cow": 0.023809523809523808, "train_stats/max_log_achievement_make_wood_pickaxe": 0.5476190476190477, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 2.142857142857143, "train_stats/max_log_achievement_place_stone": 0.023809523809523808, "train_stats/max_log_achievement_place_table": 1.7619047619047619, "train_stats/max_log_achievement_wake_up": 2.6666666666666665, "train_stats/mean_log_entropy": 0.45589919494731085, "eval_stats/sum_log_reward": 4.766666624281141, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 2.111111111111111, "eval_stats/max_log_achievement_collect_sapling": 1.6666666666666667, "eval_stats/max_log_achievement_collect_stone": 1.5555555555555556, "eval_stats/max_log_achievement_collect_wood": 5.333333333333333, "eval_stats/max_log_achievement_defeat_skeleton": 0.1111111111111111, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.7777777777777778, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 1.4444444444444444, "eval_stats/max_log_achievement_place_stone": 0.1111111111111111, "eval_stats/max_log_achievement_place_table": 2.0, "eval_stats/max_log_achievement_wake_up": 1.8888888888888888, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 1.6390675227739848e-05, "report/cont_loss_std": 0.0002167564380215481, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0002585644833743572, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.4963325156713836e-05, "report/cont_pred": 0.9941272735595703, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 5.410892486572266, "report/dyn_loss_std": 7.926030158996582, "report/image_loss_mean": 3.055556297302246, "report/image_loss_std": 4.8180766105651855, "report/model_loss_mean": 6.351459980010986, "report/model_loss_std": 8.5304594039917, "report/post_ent_mag": 53.304443359375, "report/post_ent_max": 53.304443359375, "report/post_ent_mean": 31.366939544677734, "report/post_ent_min": 16.53256607055664, "report/post_ent_std": 5.857959270477295, "report/prior_ent_mag": 72.18421173095703, "report/prior_ent_max": 72.18421173095703, "report/prior_ent_mean": 36.60802459716797, "report/prior_ent_min": 20.131114959716797, "report/prior_ent_std": 9.467617988586426, "report/rep_loss_mean": 5.410892486572266, "report/rep_loss_std": 7.926030158996582, "report/reward_avg": 0.02382812276482582, "report/reward_loss_mean": 0.04935160279273987, "report/reward_loss_std": 0.2929910719394684, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.001138687133789, "report/reward_neg_acc": 0.9959757924079895, "report/reward_neg_loss": 0.024238161742687225, "report/reward_pos_acc": 0.9666666984558105, "report/reward_pos_loss": 0.8814436197280884, "report/reward_pred": 0.023285653442144394, "report/reward_rate": 0.029296875, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.0076018827967345715, "eval/cont_loss_std": 0.2429361790418625, "eval/cont_neg_acc": 0.75, "eval/cont_neg_loss": 1.9449363946914673, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 4.49226490673027e-06, "eval/cont_pred": 0.9970673322677612, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 22.554611206054688, "eval/dyn_loss_std": 14.489449501037598, "eval/image_loss_mean": 29.79059410095215, "eval/image_loss_std": 32.85554122924805, "eval/model_loss_mean": 43.437007904052734, "eval/model_loss_std": 38.50376892089844, "eval/post_ent_mag": 48.70885467529297, "eval/post_ent_max": 48.70885467529297, "eval/post_ent_mean": 32.9329833984375, "eval/post_ent_min": 18.180667877197266, "eval/post_ent_std": 5.412792682647705, "eval/prior_ent_mag": 72.18421173095703, "eval/prior_ent_max": 72.18421173095703, "eval/prior_ent_mean": 43.1734733581543, "eval/prior_ent_min": 21.318029403686523, "eval/prior_ent_std": 9.297159194946289, "eval/rep_loss_mean": 22.554611206054688, "eval/rep_loss_std": 14.489449501037598, "eval/reward_avg": 0.01767577975988388, "eval/reward_loss_mean": 0.10604629665613174, "eval/reward_loss_std": 0.72117680311203, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.000596046447754, "eval/reward_neg_acc": 0.9940119981765747, "eval/reward_neg_loss": 0.046201176941394806, "eval/reward_pos_acc": 0.5454545617103577, "eval/reward_pos_loss": 2.8317196369171143, "eval/reward_pred": 0.011951621621847153, "eval/reward_rate": 0.021484375, "replay/size": 109529.0, "replay/inserts": 7840.0, "replay/samples": 31360.0, "replay/insert_wait_avg": 1.541479509703967e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.34969365353487e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 23856.0, "eval_replay/inserts": 1760.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1309981346130372e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.493661880493164e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1009.4731078147888, "timer/env.step_count": 980.0, "timer/env.step_total": 90.17792344093323, "timer/env.step_frac": 0.08933167485376782, "timer/env.step_avg": 0.09201828922544207, "timer/env.step_min": 0.02310347557067871, "timer/env.step_max": 3.1754531860351562, "timer/replay._sample_count": 31360.0, "timer/replay._sample_total": 15.601083278656006, "timer/replay._sample_frac": 0.01545467943413346, "timer/replay._sample_avg": 0.0004974835229163267, "timer/replay._sample_min": 0.0003795623779296875, "timer/replay._sample_max": 0.014909744262695312, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1200.0, "timer/agent.policy_total": 18.940613985061646, "timer/agent.policy_frac": 0.018762871282487634, "timer/agent.policy_avg": 0.015783844987551372, "timer/agent.policy_min": 0.009233236312866211, "timer/agent.policy_max": 0.06433367729187012, "timer/dataset_train_count": 1960.0, "timer/dataset_train_total": 0.3816554546356201, "timer/dataset_train_frac": 0.0003780739196329771, "timer/dataset_train_avg": 0.00019472217073245924, "timer/dataset_train_min": 9.250640869140625e-05, "timer/dataset_train_max": 0.08888769149780273, "timer/agent.train_count": 1960.0, "timer/agent.train_total": 868.3065886497498, "timer/agent.train_frac": 0.8601582171211842, "timer/agent.train_avg": 0.44301356563762745, "timer/agent.train_min": 0.4253425598144531, "timer/agent.train_max": 0.9513180255889893, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4758570194244385, "timer/agent.report_frac": 0.0004713914771385326, "timer/agent.report_avg": 0.23792850971221924, "timer/agent.report_min": 0.23156332969665527, "timer/agent.report_max": 0.2442936897277832, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.6464462280273438e-05, "timer/dataset_eval_frac": 2.6216114203934747e-08, "timer/dataset_eval_avg": 2.6464462280273438e-05, "timer/dataset_eval_min": 2.6464462280273438e-05, "timer/dataset_eval_max": 2.6464462280273438e-05, "fps": 7.766311082100895}
{"step": 110168, "time": 14360.335114955902, "episode/length": 228.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9781659388646288, "episode/intrinsic_return": 0.0}
{"step": 110424, "time": 14391.600198984146, "episode/length": 410.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9927007299270073, "episode/intrinsic_return": 0.0}
{"step": 110728, "time": 14428.710336446762, "episode/length": 230.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 110808, "time": 14439.48745417595, "episode/length": 165.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 110856, "time": 14446.67080450058, "episode/length": 164.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 110896, "time": 14453.405138015747, "episode/length": 194.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 110904, "time": 14456.304080963135, "episode/length": 170.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 111240, "time": 14497.8714864254, "episode/length": 187.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 112056, "time": 14594.402570962906, "episode/length": 165.0, "episode/score": 3.100000023841858, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 112088, "time": 14599.753858804703, "episode/length": 159.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 112128, "time": 14605.938971042633, "episode/length": 244.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 112160, "time": 14611.286739826202, "episode/length": 216.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 112600, "time": 14664.388590335846, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9588235294117647, "episode/intrinsic_return": 0.0}
{"step": 112600, "time": 14664.40412569046, "episode/length": 211.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 112672, "time": 14675.945679664612, "episode/length": 221.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9684684684684685, "episode/intrinsic_return": 0.0}
{"step": 113088, "time": 14725.962953805923, "episode/length": 278.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.985663082437276, "episode/intrinsic_return": 0.0}
{"step": 113296, "time": 14751.578547000885, "episode/length": 150.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 113368, "time": 14761.362539768219, "episode/length": 154.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9548387096774194, "episode/intrinsic_return": 0.0}
{"step": 113704, "time": 14801.91377902031, "episode/length": 128.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9922480620155039, "episode/intrinsic_return": 0.0}
{"step": 113784, "time": 14812.637391328812, "episode/length": 147.0, "episode/score": 6.1000000312924385, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 113880, "time": 14825.376408576965, "episode/length": 159.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 114248, "time": 14870.191459417343, "episode/length": 260.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9961685823754789, "episode/intrinsic_return": 0.0}
{"step": 114280, "time": 14875.44901919365, "episode/length": 148.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 114456, "time": 14897.479538917542, "episode/length": 144.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 114960, "time": 14958.782782793045, "episode/length": 198.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 115120, "time": 14978.876686096191, "episode/length": 166.0, "episode/score": 5.1000000312924385, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 115264, "time": 14997.399062395096, "episode/length": 194.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 115488, "time": 15025.464864253998, "episode/length": 428.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9790209790209791, "episode/intrinsic_return": 0.0}
{"step": 115568, "time": 15036.222364664078, "episode/length": 210.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.981042654028436, "episode/intrinsic_return": 0.0}
{"step": 115920, "time": 15079.089369297028, "episode/length": 208.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 116208, "time": 15113.976175785065, "episode/length": 240.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.983402489626556, "episode/intrinsic_return": 0.0}
{"step": 116400, "time": 15137.80861568451, "episode/length": 179.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 116464, "time": 15146.883905649185, "episode/length": 121.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9918032786885246, "episode/intrinsic_return": 0.0}
{"step": 116608, "time": 15165.832327127457, "episode/length": 268.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9851301115241635, "episode/intrinsic_return": 0.0}
{"step": 116608, "time": 15165.840788841248, "episode/length": 167.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 116832, "time": 15194.946521997452, "episode/length": 157.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 117016, "time": 15217.90281033516, "episode/length": 76.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.935064935064935, "episode/intrinsic_return": 0.0}
{"step": 117128, "time": 15232.511596441269, "episode/length": 150.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 117320, "time": 15256.26906299591, "episode/length": 88.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9438202247191011, "episode/intrinsic_return": 0.0}
{"step": 117504, "time": 15278.964570999146, "episode/length": 297.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9865771812080537, "episode/intrinsic_return": 0.0}
{"step": 117576, "time": 15288.99095082283, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9649122807017544, "episode/intrinsic_return": 0.0}
{"step": 117672, "time": 15301.681404590607, "episode/length": 132.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9624060150375939, "episode/intrinsic_return": 0.0}
{"step": 117944, "time": 15335.417166471481, "episode/length": 184.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 118005, "time": 15344.880782604218, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.82541015625, "train/action_min": 0.0, "train/action_std": 3.4695651268959047, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04856992261484265, "train/actor_opt_grad_steps": 28115.0, "train/actor_opt_loss": -10.699709354545922, "train/adv_mag": 0.5945242504775524, "train/adv_max": 0.561255432665348, "train/adv_mean": 0.003802518906559271, "train/adv_min": -0.4740970329940319, "train/adv_std": 0.06430181708186865, "train/cont_avg": 0.994208984375, "train/cont_loss_mean": 0.00011651837002517596, "train/cont_loss_std": 0.003361923284164732, "train/cont_neg_acc": 0.9963611114025116, "train/cont_neg_loss": 0.012935694281486576, "train/cont_pos_acc": 0.9999901726841927, "train/cont_pos_loss": 4.240621503548425e-05, "train/cont_pred": 0.9942093181610108, "train/cont_rate": 0.994208984375, "train/dyn_loss_mean": 5.951362981796264, "train/dyn_loss_std": 8.377610795497894, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.279460342526436, "train/extr_critic_critic_opt_grad_steps": 28115.0, "train/extr_critic_critic_opt_loss": 16376.6093359375, "train/extr_critic_mag": 6.489043521881103, "train/extr_critic_max": 6.489043521881103, "train/extr_critic_mean": 1.2068934369087219, "train/extr_critic_min": -0.6857361245155335, "train/extr_critic_std": 1.465312851667404, "train/extr_return_normed_mag": 1.674916735291481, "train/extr_return_normed_max": 1.674916735291481, "train/extr_return_normed_mean": 0.3343672725558281, "train/extr_return_normed_min": -0.16569272257387638, "train/extr_return_normed_std": 0.33652686640620233, "train/extr_return_rate": 0.5723310835659504, "train/extr_return_raw_mag": 7.213877758979797, "train/extr_return_raw_max": 7.213877758979797, "train/extr_return_raw_mean": 1.223845499455929, "train/extr_return_raw_min": -1.0095541882514953, "train/extr_return_raw_std": 1.5038658213615417, "train/extr_reward_mag": 1.0064103549718857, "train/extr_reward_max": 1.0064103549718857, "train/extr_reward_mean": 0.028624047851189972, "train/extr_reward_min": -0.6970753794908524, "train/extr_reward_std": 0.16997342094779014, "train/image_loss_mean": 4.382055505514145, "train/image_loss_std": 8.702648640871049, "train/model_loss_mean": 7.995631783008576, "train/model_loss_std": 12.615389132499695, "train/model_opt_grad_norm": 48.40301277160645, "train/model_opt_grad_steps": 28088.51, "train/model_opt_loss": 10091.786479492188, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1262.5, "train/policy_entropy_mag": 2.455737442970276, "train/policy_entropy_max": 2.455737442970276, "train/policy_entropy_mean": 0.5062849687039852, "train/policy_entropy_min": 0.07937501404434442, "train/policy_entropy_std": 0.5798721872270107, "train/policy_logprob_mag": 7.438383691310882, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5071760794520378, "train/policy_logprob_min": -7.438383691310882, "train/policy_logprob_std": 1.0864228835701943, "train/policy_randomness_mag": 0.8667675492167473, "train/policy_randomness_max": 0.8667675492167473, "train/policy_randomness_mean": 0.17869637794792653, "train/policy_randomness_min": 0.028015896771103145, "train/policy_randomness_std": 0.2046694365888834, "train/post_ent_mag": 51.19754146575928, "train/post_ent_max": 51.19754146575928, "train/post_ent_mean": 32.9181706237793, "train/post_ent_min": 17.251503829956054, "train/post_ent_std": 5.85973379611969, "train/prior_ent_mag": 72.70835361480712, "train/prior_ent_max": 72.70835361480712, "train/prior_ent_mean": 38.87372297286987, "train/prior_ent_min": 20.30514450550079, "train/prior_ent_std": 9.085998499393463, "train/rep_loss_mean": 5.951362981796264, "train/rep_loss_std": 8.377610795497894, "train/reward_avg": 0.02247167949564755, "train/reward_loss_mean": 0.04264197053387761, "train/reward_loss_std": 0.19544615976512433, "train/reward_max_data": 1.0055000013113022, "train/reward_max_pred": 1.0036903673410416, "train/reward_neg_acc": 0.9958949306607247, "train/reward_neg_loss": 0.02223969126585871, "train/reward_pos_acc": 0.9832979348301888, "train/reward_pos_loss": 0.7592621421813965, "train/reward_pred": 0.022158084716647864, "train/reward_rate": 0.0276171875, "train_stats/sum_log_reward": 5.379069760788319, "train_stats/max_log_achievement_collect_coal": 0.11627906976744186, "train_stats/max_log_achievement_collect_drink": 3.744186046511628, "train_stats/max_log_achievement_collect_sapling": 2.0930232558139537, "train_stats/max_log_achievement_collect_stone": 1.0930232558139534, "train_stats/max_log_achievement_collect_wood": 5.372093023255814, "train_stats/max_log_achievement_defeat_skeleton": 0.023255813953488372, "train_stats/max_log_achievement_defeat_zombie": 0.023255813953488372, "train_stats/max_log_achievement_eat_cow": 0.046511627906976744, "train_stats/max_log_achievement_make_wood_pickaxe": 0.7209302325581395, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.9767441860465116, "train_stats/max_log_achievement_place_stone": 0.09302325581395349, "train_stats/max_log_achievement_place_table": 2.1627906976744184, "train_stats/max_log_achievement_wake_up": 2.7209302325581395, "train_stats/mean_log_entropy": 0.4493617848601452, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 3.216014010831714e-05, "report/cont_loss_std": 0.00036550566437654197, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.002031678333878517, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.0375160602270626e-05, "report/cont_pred": 0.9941321611404419, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 5.25955057144165, "report/dyn_loss_std": 8.04560375213623, "report/image_loss_mean": 4.028160095214844, "report/image_loss_std": 7.773071765899658, "report/model_loss_mean": 7.219857215881348, "report/model_loss_std": 11.450763702392578, "report/post_ent_mag": 50.77494812011719, "report/post_ent_max": 50.77494812011719, "report/post_ent_mean": 34.002384185791016, "report/post_ent_min": 16.261085510253906, "report/post_ent_std": 6.372350692749023, "report/prior_ent_mag": 73.29935455322266, "report/prior_ent_max": 73.29935455322266, "report/prior_ent_mean": 39.63303756713867, "report/prior_ent_min": 20.885269165039062, "report/prior_ent_std": 9.144368171691895, "report/rep_loss_mean": 5.25955057144165, "report/rep_loss_std": 8.04560375213623, "report/reward_avg": 0.01630859449505806, "report/reward_loss_mean": 0.035934023559093475, "report/reward_loss_std": 0.1891143023967743, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.001218318939209, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.018654216080904007, "report/reward_pos_acc": 0.9545454978942871, "report/reward_pos_loss": 0.8229506611824036, "report/reward_pred": 0.015559591352939606, "report/reward_rate": 0.021484375, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.0029991217888891697, "eval/cont_loss_std": 0.09070610255002975, "eval/cont_neg_acc": 0.800000011920929, "eval/cont_neg_loss": 0.6101287007331848, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.0075538486707956e-05, "eval/cont_pred": 0.9961564540863037, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 20.48120880126953, "eval/dyn_loss_std": 13.456445693969727, "eval/image_loss_mean": 28.451154708862305, "eval/image_loss_std": 27.927000045776367, "eval/model_loss_mean": 40.886009216308594, "eval/model_loss_std": 32.9582633972168, "eval/post_ent_mag": 50.655277252197266, "eval/post_ent_max": 50.655277252197266, "eval/post_ent_mean": 33.26808166503906, "eval/post_ent_min": 16.64838981628418, "eval/post_ent_std": 5.554678440093994, "eval/prior_ent_mag": 73.29935455322266, "eval/prior_ent_max": 73.29935455322266, "eval/prior_ent_mean": 43.658111572265625, "eval/prior_ent_min": 21.205760955810547, "eval/prior_ent_std": 10.092360496520996, "eval/rep_loss_mean": 20.48120880126953, "eval/rep_loss_std": 13.456445693969727, "eval/reward_avg": 0.02207031100988388, "eval/reward_loss_mean": 0.14313215017318726, "eval/reward_loss_std": 1.0052070617675781, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0006046295166016, "eval/reward_neg_acc": 0.996990978717804, "eval/reward_neg_loss": 0.025535404682159424, "eval/reward_pos_acc": 0.5185185074806213, "eval/reward_pos_loss": 4.485500812530518, "eval/reward_pred": 0.008661231026053429, "eval/reward_rate": 0.0263671875, "replay/size": 117501.0, "replay/inserts": 7972.0, "replay/samples": 31888.0, "replay/insert_wait_avg": 1.5277690284526115e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.204969385073404e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 23856.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 6.556510925292969e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0920174121857, "timer/env.step_count": 996.0, "timer/env.step_total": 95.01154708862305, "timer/env.step_frac": 0.09500280517634034, "timer/env.step_avg": 0.09539311956689062, "timer/env.step_min": 0.023459911346435547, "timer/env.step_max": 3.237821340560913, "timer/replay._sample_count": 31888.0, "timer/replay._sample_total": 15.669774055480957, "timer/replay._sample_frac": 0.015668332296089806, "timer/replay._sample_avg": 0.0004914003404252684, "timer/replay._sample_min": 0.00036597251892089844, "timer/replay._sample_max": 0.010885953903198242, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 996.0, "timer/agent.policy_total": 15.830120325088501, "timer/agent.policy_frac": 0.015828663812406125, "timer/agent.policy_avg": 0.015893695105510544, "timer/agent.policy_min": 0.009523630142211914, "timer/agent.policy_max": 0.0534365177154541, "timer/dataset_train_count": 1993.0, "timer/dataset_train_total": 0.37659549713134766, "timer/dataset_train_frac": 0.0003765608469766784, "timer/dataset_train_avg": 0.00018895910543469525, "timer/dataset_train_min": 8.940696716308594e-05, "timer/dataset_train_max": 0.058110952377319336, "timer/agent.train_count": 1993.0, "timer/agent.train_total": 886.0938410758972, "timer/agent.train_frac": 0.8860123125157349, "timer/agent.train_avg": 0.444603031146963, "timer/agent.train_min": 0.42893362045288086, "timer/agent.train_max": 0.9616377353668213, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.471149206161499, "timer/agent.report_frac": 0.0004711058562197442, "timer/agent.report_avg": 0.2355746030807495, "timer/agent.report_min": 0.2292330265045166, "timer/agent.report_max": 0.24191617965698242, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.5987625122070312e-05, "timer/dataset_eval_frac": 2.5985234028080008e-08, "timer/dataset_eval_avg": 2.5987625122070312e-05, "timer/dataset_eval_min": 2.5987625122070312e-05, "timer/dataset_eval_max": 2.5987625122070312e-05, "fps": 7.971159331699157}
{"step": 118288, "time": 15377.634894609451, "episode/length": 158.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9622641509433962, "episode/intrinsic_return": 0.0}
{"step": 118576, "time": 15412.716097593307, "episode/length": 217.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 118584, "time": 15415.110389947891, "episode/length": 157.0, "episode/score": 2.0999999791383743, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 118672, "time": 15426.852289915085, "episode/length": 192.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 118904, "time": 15455.887486457825, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 118920, "time": 15459.288060188293, "episode/length": 176.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 119040, "time": 15474.889577150345, "episode/length": 56.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 119456, "time": 15525.023488998413, "episode/length": 188.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 119600, "time": 15543.392086267471, "episode/length": 240.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.0}
{"step": 119632, "time": 15548.828629732132, "episode/length": 167.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 120000, "time": 15593.433634281158, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 120016, "time": 15616.462924718857, "eval_episode/length": 140.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9929078014184397}
{"step": 120016, "time": 15618.250320196152, "eval_episode/length": 144.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9724137931034482}
{"step": 120016, "time": 15619.879583358765, "eval_episode/length": 146.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9931972789115646}
{"step": 120016, "time": 15621.454227209091, "eval_episode/length": 147.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9932432432432432}
{"step": 120016, "time": 15623.916709899902, "eval_episode/length": 168.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9644970414201184}
{"step": 120016, "time": 15626.238145589828, "eval_episode/length": 186.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9946524064171123}
{"step": 120016, "time": 15628.004346370697, "eval_episode/length": 46.0, "eval_episode/score": 3.0999999791383743, "eval_episode/reward_rate": 0.9787234042553191}
{"step": 120016, "time": 15629.592156171799, "eval_episode/length": 196.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9746192893401016}
{"step": 120152, "time": 15645.316436290741, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 120384, "time": 15673.709756851196, "episode/length": 167.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 120512, "time": 15690.133883237839, "episode/length": 44.0, "episode/score": 1.0999999940395355, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 120848, "time": 15730.948365926743, "episode/length": 173.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 120920, "time": 15741.312460660934, "episode/length": 249.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.996, "episode/intrinsic_return": 0.0}
{"step": 121048, "time": 15757.712030649185, "episode/length": 267.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9850746268656716, "episode/intrinsic_return": 0.0}
{"step": 121240, "time": 15781.622404813766, "episode/length": 200.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9701492537313433, "episode/intrinsic_return": 0.0}
{"step": 121296, "time": 15789.5981528759, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 121336, "time": 15795.83893418312, "episode/length": 216.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9723502304147466, "episode/intrinsic_return": 0.0}
{"step": 121904, "time": 15862.933202266693, "episode/length": 189.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 121984, "time": 15873.749512910843, "episode/length": 141.0, "episode/score": 3.1000000312924385, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 122152, "time": 15894.70673918724, "episode/length": 204.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 122184, "time": 15899.915324926376, "episode/length": 141.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 122280, "time": 15912.556599617004, "episode/length": 169.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 122536, "time": 15944.014336585999, "episode/length": 154.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 123000, "time": 16001.163539409637, "episode/length": 207.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 123192, "time": 16025.497281074524, "episode/length": 243.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 123304, "time": 16040.230407238007, "episode/length": 164.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 123576, "time": 16073.294978141785, "episode/length": 173.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 124016, "time": 16125.902126312256, "episode/length": 54.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9090909090909091, "episode/intrinsic_return": 0.0}
{"step": 124192, "time": 16147.8584420681, "episode/length": 238.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9832635983263598, "episode/intrinsic_return": 0.0}
{"step": 124296, "time": 16161.57970380783, "episode/length": 267.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9701492537313433, "episode/intrinsic_return": 0.0}
{"step": 124328, "time": 16166.827861309052, "episode/length": 302.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9867986798679867, "episode/intrinsic_return": 0.0}
{"step": 124384, "time": 16174.97754406929, "episode/length": 172.0, "episode/score": 8.1000000461936, "episode/reward_rate": 0.9653179190751445, "episode/intrinsic_return": 0.0}
{"step": 124512, "time": 16191.771669387817, "episode/length": 246.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.979757085020243, "episode/intrinsic_return": 0.0}
{"step": 124824, "time": 16229.349352836609, "episode/length": 203.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 124880, "time": 16237.315743684769, "episode/length": 196.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 125448, "time": 16304.920780658722, "episode/length": 156.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 125456, "time": 16307.8434278965, "episode/length": 144.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 125753, "time": 16345.16532421112, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.79922596037079, "train/action_min": 0.0, "train/action_std": 3.4397817979822505, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0483238658061917, "train/actor_opt_grad_steps": 30080.0, "train/actor_opt_loss": -11.6818545670707, "train/adv_mag": 0.5661980758368043, "train/adv_max": 0.5258816144009328, "train/adv_mean": 0.0031614424105114764, "train/adv_min": -0.4698770629927284, "train/adv_std": 0.06329211501954751, "train/cont_avg": 0.9940799060880829, "train/cont_loss_mean": 0.00013032610197210418, "train/cont_loss_std": 0.0036902763112315736, "train/cont_neg_acc": 0.9950345433437763, "train/cont_neg_loss": 0.0136472303963693, "train/cont_pos_acc": 0.9999898097675699, "train/cont_pos_loss": 4.122575421598581e-05, "train/cont_pred": 0.9940871951493575, "train/cont_rate": 0.9940799060880829, "train/dyn_loss_mean": 5.98932583467948, "train/dyn_loss_std": 8.393010302528817, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.2506878959700234, "train/extr_critic_critic_opt_grad_steps": 30080.0, "train/extr_critic_critic_opt_loss": 16358.369474579016, "train/extr_critic_mag": 6.527464760399853, "train/extr_critic_max": 6.527464760399853, "train/extr_critic_mean": 1.2544071668170276, "train/extr_critic_min": -0.6997372523490629, "train/extr_critic_std": 1.4707566975311912, "train/extr_return_normed_mag": 1.654564666624514, "train/extr_return_normed_max": 1.654564666624514, "train/extr_return_normed_mean": 0.3366605054992468, "train/extr_return_normed_min": -0.17406188665739614, "train/extr_return_normed_std": 0.33408051111537557, "train/extr_return_rate": 0.5861429618430262, "train/extr_return_raw_mag": 7.2094784400623695, "train/extr_return_raw_max": 7.2094784400623695, "train/extr_return_raw_mean": 1.268659051218181, "train/extr_return_raw_min": -1.0334043422511205, "train/extr_return_raw_std": 1.5059947992235885, "train/extr_reward_mag": 1.0107554808799466, "train/extr_reward_max": 1.0107554808799466, "train/extr_reward_mean": 0.02839512624560706, "train/extr_reward_min": -0.7058734560259883, "train/extr_reward_std": 0.17032205718786605, "train/image_loss_mean": 4.1757482209971535, "train/image_loss_std": 8.228634676167385, "train/model_loss_mean": 7.812447923452743, "train/model_loss_std": 12.173262882726798, "train/model_opt_grad_norm": 49.028125150216056, "train/model_opt_grad_steps": 30051.60621761658, "train/model_opt_loss": 10734.074145381315, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1386.0103626943005, "train/policy_entropy_mag": 2.4304531015880366, "train/policy_entropy_max": 2.4304531015880366, "train/policy_entropy_mean": 0.48791874520519235, "train/policy_entropy_min": 0.07937501409510875, "train/policy_entropy_std": 0.560475652236395, "train/policy_logprob_mag": 7.43838368796314, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.48737079383795745, "train/policy_logprob_min": -7.43838368796314, "train/policy_logprob_std": 1.0688415833705447, "train/policy_randomness_mag": 0.8578432853975444, "train/policy_randomness_max": 0.8578432853975444, "train/policy_randomness_mean": 0.17221390602656597, "train/policy_randomness_min": 0.02801589679378302, "train/policy_randomness_std": 0.19782331076310705, "train/post_ent_mag": 52.41736446637564, "train/post_ent_max": 52.41736446637564, "train/post_ent_mean": 33.691245340930365, "train/post_ent_min": 17.823126575489734, "train/post_ent_std": 6.035365919992714, "train/prior_ent_mag": 73.03499306792422, "train/prior_ent_max": 73.03499306792422, "train/prior_ent_mean": 39.66152110124499, "train/prior_ent_min": 20.720914539277864, "train/prior_ent_std": 9.024464782655548, "train/rep_loss_mean": 5.98932583467948, "train/rep_loss_std": 8.393010302528817, "train/reward_avg": 0.022278780617070785, "train/reward_loss_mean": 0.042973872833919034, "train/reward_loss_std": 0.19697897796340558, "train/reward_max_data": 1.0098445619326182, "train/reward_max_pred": 1.0063215191500174, "train/reward_neg_acc": 0.995634044081436, "train/reward_neg_loss": 0.022531724573532842, "train/reward_pos_acc": 0.9813417400103159, "train/reward_pos_loss": 0.7629366683836428, "train/reward_pred": 0.021911075452120655, "train/reward_rate": 0.02764228465025907, "train_stats/sum_log_reward": 5.075000017881393, "train_stats/max_log_achievement_collect_coal": 0.175, "train_stats/max_log_achievement_collect_drink": 3.175, "train_stats/max_log_achievement_collect_sapling": 1.625, "train_stats/max_log_achievement_collect_stone": 1.225, "train_stats/max_log_achievement_collect_wood": 5.625, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.025, "train_stats/max_log_achievement_eat_cow": 0.05, "train_stats/max_log_achievement_make_wood_pickaxe": 0.975, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.525, "train_stats/max_log_achievement_place_stone": 0.025, "train_stats/max_log_achievement_place_table": 2.0, "train_stats/max_log_achievement_wake_up": 2.525, "train_stats/mean_log_entropy": 0.43913935497403145, "eval_stats/sum_log_reward": 4.600000023841858, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 0.75, "eval_stats/max_log_achievement_collect_sapling": 2.625, "eval_stats/max_log_achievement_collect_stone": 0.125, "eval_stats/max_log_achievement_collect_wood": 4.25, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.125, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.375, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.625, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 1.625, "eval_stats/max_log_achievement_wake_up": 2.0, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 5.777395472250646e-06, "report/cont_loss_std": 9.938045695889741e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0004972474416717887, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 3.3658643587841652e-06, "report/cont_pred": 0.9951163530349731, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 7.675845146179199, "report/dyn_loss_std": 9.713958740234375, "report/image_loss_mean": 4.484982967376709, "report/image_loss_std": 9.694558143615723, "report/model_loss_mean": 9.130643844604492, "report/model_loss_std": 14.370443344116211, "report/post_ent_mag": 53.93795394897461, "report/post_ent_max": 53.93795394897461, "report/post_ent_mean": 34.736942291259766, "report/post_ent_min": 14.00895881652832, "report/post_ent_std": 5.427860260009766, "report/prior_ent_mag": 72.97090148925781, "report/prior_ent_max": 72.97090148925781, "report/prior_ent_mean": 41.66663360595703, "report/prior_ent_min": 22.894309997558594, "report/prior_ent_std": 8.918848991394043, "report/rep_loss_mean": 7.675845146179199, "report/rep_loss_std": 9.713958740234375, "report/reward_avg": 0.02275390550494194, "report/reward_loss_mean": 0.04014772176742554, "report/reward_loss_std": 0.17515693604946136, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.004655122756958, "report/reward_neg_acc": 0.9939759969711304, "report/reward_neg_loss": 0.021779518574476242, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6935310959815979, "report/reward_pred": 0.023045800626277924, "report/reward_rate": 0.02734375, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 4.0844348404789343e-05, "eval/cont_loss_std": 0.0012339461827650666, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.013934016227722168, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.2107796482373487e-08, "eval/cont_pred": 0.9971103668212891, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 21.40239906311035, "eval/dyn_loss_std": 13.758288383483887, "eval/image_loss_mean": 31.11412239074707, "eval/image_loss_std": 35.90462112426758, "eval/model_loss_mean": 44.06670379638672, "eval/model_loss_std": 41.164710998535156, "eval/post_ent_mag": 52.11494827270508, "eval/post_ent_max": 52.11494827270508, "eval/post_ent_mean": 35.13483428955078, "eval/post_ent_min": 20.398067474365234, "eval/post_ent_std": 6.031188488006592, "eval/prior_ent_mag": 72.97090148925781, "eval/prior_ent_max": 72.97090148925781, "eval/prior_ent_mean": 45.08329772949219, "eval/prior_ent_min": 24.791658401489258, "eval/prior_ent_std": 9.223737716674805, "eval/rep_loss_mean": 21.40239906311035, "eval/rep_loss_std": 13.758288383483887, "eval/reward_avg": 0.02031250111758709, "eval/reward_loss_mean": 0.11110325157642365, "eval/reward_loss_std": 0.8365978002548218, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0011866092681885, "eval/reward_neg_acc": 0.9970000386238098, "eval/reward_neg_loss": 0.028271382674574852, "eval/reward_pos_acc": 0.5833333730697632, "eval/reward_pos_loss": 3.562431812286377, "eval/reward_pred": 0.011606648564338684, "eval/reward_rate": 0.0234375, "replay/size": 125249.0, "replay/inserts": 7748.0, "replay/samples": 30992.0, "replay/insert_wait_avg": 1.5088560412578751e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.127556428136318e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 25432.0, "eval_replay/inserts": 1576.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.154121408607754e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.195638656616211e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2680776119232, "timer/env.step_count": 969.0, "timer/env.step_total": 88.74763226509094, "timer/env.step_frac": 0.08872384738796253, "timer/env.step_avg": 0.09158682380298343, "timer/env.step_min": 0.022862911224365234, "timer/env.step_max": 2.087193250656128, "timer/replay._sample_count": 30992.0, "timer/replay._sample_total": 15.129332780838013, "timer/replay._sample_frac": 0.015125278032423407, "timer/replay._sample_avg": 0.00048816897201981195, "timer/replay._sample_min": 0.00035834312438964844, "timer/replay._sample_max": 0.02226567268371582, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1166.0, "timer/agent.policy_total": 19.64161491394043, "timer/agent.policy_frac": 0.019636350847898238, "timer/agent.policy_avg": 0.0168452958095544, "timer/agent.policy_min": 0.00923776626586914, "timer/agent.policy_max": 0.10023665428161621, "timer/dataset_train_count": 1937.0, "timer/dataset_train_total": 0.28159666061401367, "timer/dataset_train_frac": 0.0002815211910854017, "timer/dataset_train_avg": 0.00014537772876304267, "timer/dataset_train_min": 8.749961853027344e-05, "timer/dataset_train_max": 0.0026667118072509766, "timer/agent.train_count": 1937.0, "timer/agent.train_total": 860.3555059432983, "timer/agent.train_frac": 0.8601249257072591, "timer/agent.train_avg": 0.44416907895885305, "timer/agent.train_min": 0.4297358989715576, "timer/agent.train_max": 0.9797325134277344, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4773988723754883, "timer/agent.report_frac": 0.0004772709267252114, "timer/agent.report_avg": 0.23869943618774414, "timer/agent.report_min": 0.23288583755493164, "timer/agent.report_max": 0.24451303482055664, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7179718017578125e-05, "timer/dataset_eval_frac": 2.717243369644264e-08, "timer/dataset_eval_avg": 2.7179718017578125e-05, "timer/dataset_eval_min": 2.7179718017578125e-05, "timer/dataset_eval_max": 2.7179718017578125e-05, "fps": 7.745815166225353}
{"step": 126000, "time": 16373.94825053215, "episode/length": 208.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9808612440191388, "episode/intrinsic_return": 0.0}
{"step": 126024, "time": 16378.236454486847, "episode/length": 204.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 126072, "time": 16385.211637735367, "episode/length": 155.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 126136, "time": 16394.109532117844, "episode/length": 156.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 126248, "time": 16408.42892885208, "episode/length": 278.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.985663082437276, "episode/intrinsic_return": 0.0}
{"step": 126376, "time": 16424.803832530975, "episode/length": 43.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 126536, "time": 16444.81478524208, "episode/length": 252.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9723320158102767, "episode/intrinsic_return": 0.0}
{"step": 126600, "time": 16453.89212679863, "episode/length": 143.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 127392, "time": 16547.26259279251, "episode/length": 241.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9958677685950413, "episode/intrinsic_return": 0.0}
{"step": 127696, "time": 16584.078238725662, "episode/length": 211.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 127784, "time": 16595.82998776436, "episode/length": 205.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 127872, "time": 16607.641735076904, "episode/length": 202.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 127992, "time": 16623.161898612976, "episode/length": 201.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9653465346534653, "episode/intrinsic_return": 0.0}
{"step": 128232, "time": 16652.837635040283, "episode/length": 211.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 128456, "time": 16680.62210869789, "episode/length": 297.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9798657718120806, "episode/intrinsic_return": 0.0}
{"step": 128632, "time": 16702.992179632187, "episode/length": 253.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9803149606299213, "episode/intrinsic_return": 0.0}
{"step": 128832, "time": 16727.83767437935, "episode/length": 141.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 129080, "time": 16758.320098638535, "episode/length": 210.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 129264, "time": 16781.38221693039, "episode/length": 184.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 129296, "time": 16786.575299024582, "episode/length": 162.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 129480, "time": 16809.418392896652, "episode/length": 155.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 129664, "time": 16832.602625370026, "episode/length": 49.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 129888, "time": 16860.236217975616, "episode/length": 156.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 129976, "time": 16872.0709233284, "episode/length": 142.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 130000, "time": 16894.89988565445, "eval_episode/length": 156.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9745222929936306}
{"step": 130000, "time": 16897.164536952972, "eval_episode/length": 171.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9651162790697675}
{"step": 130000, "time": 16899.396040201187, "eval_episode/length": 189.0, "eval_episode/score": 5.0999999940395355, "eval_episode/reward_rate": 0.9947368421052631}
{"step": 130000, "time": 16900.99798965454, "eval_episode/length": 190.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9790575916230366}
{"step": 130000, "time": 16902.805121421814, "eval_episode/length": 198.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9849246231155779}
{"step": 130000, "time": 16904.563378810883, "eval_episode/length": 203.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9950980392156863}
{"step": 130000, "time": 16906.14808154106, "eval_episode/length": 48.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.8979591836734694}
{"step": 130000, "time": 16908.30975294113, "eval_episode/length": 224.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9733333333333334}
{"step": 130072, "time": 16916.631320476532, "episode/length": 201.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 130592, "time": 16978.805594682693, "episode/length": 188.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 130640, "time": 16985.81930232048, "episode/length": 167.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9583333333333334, "episode/intrinsic_return": 0.0}
{"step": 131032, "time": 17033.209027290344, "episode/length": 48.0, "episode/score": 2.0999999940395355, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 131272, "time": 17064.19284772873, "episode/length": 424.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9788235294117648, "episode/intrinsic_return": 0.0}
{"step": 131408, "time": 17081.620738983154, "episode/length": 240.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.975103734439834, "episode/intrinsic_return": 0.0}
{"step": 131576, "time": 17102.773415327072, "episode/length": 199.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.97, "episode/intrinsic_return": 0.0}
{"step": 131712, "time": 17120.245082855225, "episode/length": 204.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.0}
{"step": 131736, "time": 17125.10558962822, "episode/length": 57.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9310344827586207, "episode/intrinsic_return": 0.0}
{"step": 131904, "time": 17146.780903577805, "episode/length": 279.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9964285714285714, "episode/intrinsic_return": 0.0}
{"step": 132080, "time": 17168.871103286743, "episode/length": 185.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 132296, "time": 17195.62965488434, "episode/length": 157.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 132792, "time": 17254.870137929916, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 132968, "time": 17277.073034524918, "episode/length": 384.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9766233766233766, "episode/intrinsic_return": 0.0}
{"step": 133032, "time": 17286.62849998474, "episode/length": 181.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 133192, "time": 17306.9213013649, "episode/length": 181.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 133328, "time": 17324.43764424324, "episode/length": 201.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 133489, "time": 17345.50956082344, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.83916984636759, "train/action_min": 0.0, "train/action_std": 3.46567178509899, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04743187751659413, "train/actor_opt_grad_steps": 32015.0, "train/actor_opt_loss": -12.243272010659433, "train/adv_mag": 0.5589068647205215, "train/adv_max": 0.5081845187034804, "train/adv_mean": 0.0030188694660405278, "train/adv_min": -0.4755243864102462, "train/adv_std": 0.0610493808677516, "train/cont_avg": 0.9946238724226805, "train/cont_loss_mean": 0.00018033477203334124, "train/cont_loss_std": 0.005503078316272403, "train/cont_neg_acc": 0.9957699238025036, "train/cont_neg_loss": 0.019211392853978077, "train/cont_pos_acc": 0.9999898635235029, "train/cont_pos_loss": 7.301763507579947e-05, "train/cont_pred": 0.9946295185801909, "train/cont_rate": 0.9946238724226805, "train/dyn_loss_mean": 6.033669865008482, "train/dyn_loss_std": 8.365085029110466, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.2195445627895827, "train/extr_critic_critic_opt_grad_steps": 32015.0, "train/extr_critic_critic_opt_loss": 16195.664032297036, "train/extr_critic_mag": 6.612024127822561, "train/extr_critic_max": 6.612024127822561, "train/extr_critic_mean": 1.2776825071610127, "train/extr_critic_min": -0.6650782233660983, "train/extr_critic_std": 1.4892121516552168, "train/extr_return_normed_mag": 1.6501882573992936, "train/extr_return_normed_max": 1.6501882573992936, "train/extr_return_normed_mean": 0.33216712915713026, "train/extr_return_normed_min": -0.15552541331301645, "train/extr_return_normed_std": 0.32831235552571486, "train/extr_return_rate": 0.5907455083635664, "train/extr_return_raw_mag": 7.412059289892924, "train/extr_return_raw_max": 7.412059289892924, "train/extr_return_raw_mean": 1.2916182033794443, "train/extr_return_raw_min": -0.9720630356945943, "train/extr_return_raw_std": 1.5246802832662445, "train/extr_reward_mag": 1.0166732404649872, "train/extr_reward_max": 1.0166732404649872, "train/extr_reward_mean": 0.02855670450197667, "train/extr_reward_min": -0.6588692013750371, "train/extr_reward_std": 0.16921080848605363, "train/image_loss_mean": 4.197321207252974, "train/image_loss_std": 8.361888433240123, "train/model_loss_mean": 7.860633493698749, "train/model_loss_std": 12.297204686194352, "train/model_opt_grad_norm": 49.88415430993149, "train/model_opt_grad_steps": 31984.654639175256, "train/model_opt_loss": 6059.358818762081, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 776.4175257731958, "train/policy_entropy_mag": 2.434822449979094, "train/policy_entropy_max": 2.434822449979094, "train/policy_entropy_mean": 0.5023522071309925, "train/policy_entropy_min": 0.07937501378587841, "train/policy_entropy_std": 0.5737510701430213, "train/policy_logprob_mag": 7.438383684944861, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5023694202764747, "train/policy_logprob_min": -7.438383684944861, "train/policy_logprob_std": 1.0778823577866112, "train/policy_randomness_mag": 0.859385475362699, "train/policy_randomness_max": 0.859385475362699, "train/policy_randomness_mean": 0.17730828305495153, "train/policy_randomness_min": 0.028015896697173415, "train/policy_randomness_std": 0.20250894966506466, "train/post_ent_mag": 52.909149681169964, "train/post_ent_max": 52.909149681169964, "train/post_ent_mean": 34.32573798268112, "train/post_ent_min": 18.042624444076694, "train/post_ent_std": 6.0000816202655285, "train/prior_ent_mag": 73.32691581962035, "train/prior_ent_max": 73.32691581962035, "train/prior_ent_mean": 40.33238664607412, "train/prior_ent_min": 21.34246290344553, "train/prior_ent_std": 8.869347609195513, "train/rep_loss_mean": 6.033669865008482, "train/rep_loss_std": 8.365085029110466, "train/reward_avg": 0.022532920933991056, "train/reward_loss_mean": 0.042930052961347644, "train/reward_loss_std": 0.20369648176831068, "train/reward_max_data": 1.0123711369701267, "train/reward_max_pred": 1.0078160873393422, "train/reward_neg_acc": 0.9959369369388855, "train/reward_neg_loss": 0.022307136729743677, "train/reward_pos_acc": 0.9784876271006987, "train/reward_pos_loss": 0.7753121865164373, "train/reward_pred": 0.022084200958788547, "train/reward_rate": 0.027479663337628867, "train_stats/sum_log_reward": 5.295121914002953, "train_stats/max_log_achievement_collect_coal": 0.0975609756097561, "train_stats/max_log_achievement_collect_drink": 3.024390243902439, "train_stats/max_log_achievement_collect_sapling": 2.048780487804878, "train_stats/max_log_achievement_collect_stone": 0.926829268292683, "train_stats/max_log_achievement_collect_wood": 5.951219512195122, "train_stats/max_log_achievement_defeat_skeleton": 0.04878048780487805, "train_stats/max_log_achievement_defeat_zombie": 0.024390243902439025, "train_stats/max_log_achievement_eat_cow": 0.04878048780487805, "train_stats/max_log_achievement_make_wood_pickaxe": 0.8780487804878049, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.951219512195122, "train_stats/max_log_achievement_place_stone": 0.1951219512195122, "train_stats/max_log_achievement_place_table": 2.048780487804878, "train_stats/max_log_achievement_wake_up": 2.731707317073171, "train_stats/mean_log_entropy": 0.4287942836924297, "eval_stats/sum_log_reward": 4.849999964237213, "eval_stats/max_log_achievement_collect_coal": 0.125, "eval_stats/max_log_achievement_collect_drink": 2.25, "eval_stats/max_log_achievement_collect_sapling": 2.25, "eval_stats/max_log_achievement_collect_stone": 0.25, "eval_stats/max_log_achievement_collect_wood": 6.875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.25, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.0, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.375, "eval_stats/max_log_achievement_wake_up": 2.375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 3.4306714951526374e-05, "report/cont_loss_std": 0.000832718622405082, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.004021340515464544, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 6.864009719720343e-06, "report/cont_pred": 0.9931843876838684, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 6.849728584289551, "report/dyn_loss_std": 8.483240127563477, "report/image_loss_mean": 6.674098491668701, "report/image_loss_std": 9.977193832397461, "report/model_loss_mean": 10.824987411499023, "report/model_loss_std": 13.667398452758789, "report/post_ent_mag": 53.999549865722656, "report/post_ent_max": 53.999549865722656, "report/post_ent_mean": 34.718727111816406, "report/post_ent_min": 17.19587516784668, "report/post_ent_std": 6.279545307159424, "report/prior_ent_mag": 74.14163208007812, "report/prior_ent_max": 74.14163208007812, "report/prior_ent_mean": 42.0350227355957, "report/prior_ent_min": 20.775909423828125, "report/prior_ent_std": 9.193946838378906, "report/rep_loss_mean": 6.849728584289551, "report/rep_loss_std": 8.483240127563477, "report/reward_avg": 0.02236328087747097, "report/reward_loss_mean": 0.04101774841547012, "report/reward_loss_std": 0.18121574819087982, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.006882905960083, "report/reward_neg_acc": 0.994979977607727, "report/reward_neg_loss": 0.02045520953834057, "report/reward_pos_acc": 0.9642857313156128, "report/reward_pos_loss": 0.7724568247795105, "report/reward_pred": 0.021625161170959473, "report/reward_rate": 0.02734375, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.0003378183173481375, "eval/cont_loss_std": 0.01056921947747469, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.1709635704755783, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 3.912752163159894e-06, "eval/cont_pred": 0.9983267784118652, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 23.24160385131836, "eval/dyn_loss_std": 13.637907981872559, "eval/image_loss_mean": 30.57859230041504, "eval/image_loss_std": 31.704364776611328, "eval/model_loss_mean": 44.668575286865234, "eval/model_loss_std": 37.29011154174805, "eval/post_ent_mag": 52.1290283203125, "eval/post_ent_max": 52.1290283203125, "eval/post_ent_mean": 34.43798065185547, "eval/post_ent_min": 22.657596588134766, "eval/post_ent_std": 5.231913089752197, "eval/prior_ent_mag": 74.14163208007812, "eval/prior_ent_max": 74.14163208007812, "eval/prior_ent_mean": 47.002540588378906, "eval/prior_ent_min": 22.98592758178711, "eval/prior_ent_std": 9.579134941101074, "eval/rep_loss_mean": 23.24160385131836, "eval/rep_loss_std": 13.637907981872559, "eval/reward_avg": 0.017578125, "eval/reward_loss_mean": 0.14468443393707275, "eval/reward_loss_std": 0.9994820952415466, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9994164705276489, "eval/reward_neg_acc": 0.989054799079895, "eval/reward_neg_loss": 0.06575146317481995, "eval/reward_pos_acc": 0.5263158082962036, "eval/reward_pos_loss": 4.319823265075684, "eval/reward_pred": 0.013135635294020176, "eval/reward_rate": 0.0185546875, "replay/size": 132985.0, "replay/inserts": 7736.0, "replay/samples": 30944.0, "replay/insert_wait_avg": 1.5364684387964448e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.346114188216958e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 27232.0, "eval_replay/inserts": 1800.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.165734397040473e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.493661880493164e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3311705589294, "timer/env.step_count": 967.0, "timer/env.step_total": 87.9857611656189, "timer/env.step_frac": 0.08795663251846621, "timer/env.step_avg": 0.09098837762732047, "timer/env.step_min": 0.02278757095336914, "timer/env.step_max": 2.025874137878418, "timer/replay._sample_count": 30944.0, "timer/replay._sample_total": 15.666404485702515, "timer/replay._sample_frac": 0.015661217951400033, "timer/replay._sample_avg": 0.0005062824614045538, "timer/replay._sample_min": 0.0003674030303955078, "timer/replay._sample_max": 0.029996395111083984, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1192.0, "timer/agent.policy_total": 19.022536039352417, "timer/agent.policy_frac": 0.019016238421045783, "timer/agent.policy_avg": 0.01595850338871847, "timer/agent.policy_min": 0.009505748748779297, "timer/agent.policy_max": 0.05489158630371094, "timer/dataset_train_count": 1934.0, "timer/dataset_train_total": 0.3336803913116455, "timer/dataset_train_frac": 0.00033356992277387844, "timer/dataset_train_avg": 0.00017253381143311557, "timer/dataset_train_min": 8.678436279296875e-05, "timer/dataset_train_max": 0.050057411193847656, "timer/agent.train_count": 1934.0, "timer/agent.train_total": 861.5419092178345, "timer/agent.train_frac": 0.861256686359631, "timer/agent.train_avg": 0.44547151459040046, "timer/agent.train_min": 0.4320838451385498, "timer/agent.train_max": 1.031982183456421, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4790616035461426, "timer/agent.report_frac": 0.0004789030049703136, "timer/agent.report_avg": 0.2395308017730713, "timer/agent.report_min": 0.23181366920471191, "timer/agent.report_max": 0.24724793434143066, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.314018249511719e-05, "timer/dataset_eval_frac": 3.312921107576833e-08, "timer/dataset_eval_avg": 3.314018249511719e-05, "timer/dataset_eval_min": 3.314018249511719e-05, "timer/dataset_eval_max": 3.314018249511719e-05, "fps": 7.733336613606185}
{"step": 133560, "time": 17353.7227435112, "episode/length": 157.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9810126582278481, "episode/intrinsic_return": 0.0}
{"step": 133576, "time": 17356.99635052681, "episode/length": 208.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 133576, "time": 17357.01470065117, "episode/length": 186.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9625668449197861, "episode/intrinsic_return": 0.0}
{"step": 134280, "time": 17442.306048631668, "episode/length": 163.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 134360, "time": 17453.191640138626, "episode/length": 165.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 134568, "time": 17479.12424135208, "episode/length": 154.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 134632, "time": 17488.710678100586, "episode/length": 179.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 134912, "time": 17522.92373776436, "episode/length": 264.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9962264150943396, "episode/intrinsic_return": 0.0}
{"step": 134912, "time": 17522.93510913849, "episode/length": 166.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 134952, "time": 17530.917437553406, "episode/length": 173.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 135064, "time": 17546.04411149025, "episode/length": 185.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 135080, "time": 17549.418559074402, "episode/length": 89.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9888888888888889, "episode/intrinsic_return": 0.0}
{"step": 135344, "time": 17581.683525562286, "episode/length": 48.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 135664, "time": 17620.76901102066, "episode/length": 172.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 135928, "time": 17654.059206962585, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9567901234567902, "episode/intrinsic_return": 0.0}
{"step": 136056, "time": 17670.520102500916, "episode/length": 142.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.965034965034965, "episode/intrinsic_return": 0.0}
{"step": 136160, "time": 17684.18207192421, "episode/length": 198.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.0}
{"step": 136184, "time": 17688.508620500565, "episode/length": 158.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 136576, "time": 17735.819714069366, "episode/length": 188.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 136744, "time": 17756.984935045242, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 137504, "time": 17847.316128253937, "episode/length": 229.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9739130434782609, "episode/intrinsic_return": 0.0}
{"step": 137512, "time": 17849.758055448532, "episode/length": 168.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 137552, "time": 17855.950756311417, "episode/length": 170.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 137552, "time": 17855.96097421646, "episode/length": 308.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9902912621359223, "episode/intrinsic_return": 0.0}
{"step": 137936, "time": 17904.151530265808, "episode/length": 148.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 137952, "time": 17907.538421154022, "episode/length": 236.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 138032, "time": 17918.36228442192, "episode/length": 262.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.973384030418251, "episode/intrinsic_return": 0.0}
{"step": 138720, "time": 18000.091295480728, "episode/length": 145.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9657534246575342, "episode/intrinsic_return": 0.0}
{"step": 138744, "time": 18004.318161010742, "episode/length": 153.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 138872, "time": 18020.895020246506, "episode/length": 170.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 138888, "time": 18024.229234933853, "episode/length": 288.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.986159169550173, "episode/intrinsic_return": 0.0}
{"step": 139000, "time": 18038.722506046295, "episode/length": 34.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 139008, "time": 18041.311984539032, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 139184, "time": 18063.253876686096, "episode/length": 155.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 139384, "time": 18089.384938955307, "episode/length": 178.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 140088, "time": 18192.022107601166, "eval_episode/length": 159.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9625}
{"step": 140088, "time": 18193.91383242607, "eval_episode/length": 170.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9766081871345029}
{"step": 140088, "time": 18193.92170238495, "eval_episode/length": 170.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9649122807017544}
{"step": 140088, "time": 18197.374654769897, "eval_episode/length": 177.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9719101123595506}
{"step": 140088, "time": 18199.23695731163, "eval_episode/length": 185.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9731182795698925}
{"step": 140088, "time": 18202.627796173096, "eval_episode/length": 230.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9956709956709957}
{"step": 140088, "time": 18205.968866825104, "eval_episode/length": 276.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9855595667870036}
{"step": 140088, "time": 18208.73881649971, "eval_episode/length": 127.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9609375}
{"step": 140120, "time": 18212.474503993988, "episode/length": 171.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 140416, "time": 18248.45347929001, "episode/length": 190.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9685863874345549, "episode/intrinsic_return": 0.0}
{"step": 140600, "time": 18271.565983057022, "episode/length": 198.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 140704, "time": 18285.816799879074, "episode/length": 189.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 140776, "time": 18295.618032455444, "episode/length": 221.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 140936, "time": 18316.112298727036, "episode/length": 193.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 140944, "time": 18318.62532019615, "episode/length": 258.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9845559845559846, "episode/intrinsic_return": 0.0}
{"step": 141128, "time": 18341.636509656906, "episode/length": 386.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 141141, "time": 18345.586449861526, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.692080832276669, "train/action_min": 0.0, "train/action_std": 3.370377504388699, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.047816750910425684, "train/actor_opt_grad_steps": 33940.0, "train/actor_opt_loss": -11.112104888176496, "train/adv_mag": 0.6027810938695338, "train/adv_max": 0.5606091813579279, "train/adv_mean": 0.002944573240620706, "train/adv_min": -0.47843520007832513, "train/adv_std": 0.062477595792078844, "train/cont_avg": 0.9945854466623036, "train/cont_loss_mean": 0.00013261610091040645, "train/cont_loss_std": 0.003948131772296205, "train/cont_neg_acc": 0.9958489159638969, "train/cont_neg_loss": 0.01241875651868351, "train/cont_pos_acc": 0.9999845673900625, "train/cont_pos_loss": 7.013676861995057e-05, "train/cont_pred": 0.9945795554765232, "train/cont_rate": 0.9945854466623036, "train/dyn_loss_mean": 6.144341286564373, "train/dyn_loss_std": 8.496760270982513, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.2231036736703045, "train/extr_critic_critic_opt_grad_steps": 33940.0, "train/extr_critic_critic_opt_loss": 16454.74219261289, "train/extr_critic_mag": 6.644226268948061, "train/extr_critic_max": 6.644226268948061, "train/extr_critic_mean": 1.2678099567977545, "train/extr_critic_min": -0.6640661736433419, "train/extr_critic_std": 1.4776354922049957, "train/extr_return_normed_mag": 1.6701774503548108, "train/extr_return_normed_max": 1.6701774503548108, "train/extr_return_normed_mean": 0.33007151434558846, "train/extr_return_normed_min": -0.15458725096355558, "train/extr_return_normed_std": 0.3266385194518803, "train/extr_return_rate": 0.5860564919354404, "train/extr_return_raw_mag": 7.485748063831429, "train/extr_return_raw_max": 7.485748063831429, "train/extr_return_raw_mean": 1.2814468881846723, "train/extr_return_raw_min": -0.9635280632847891, "train/extr_return_raw_std": 1.5127612124562888, "train/extr_reward_mag": 1.0135637677776876, "train/extr_reward_max": 1.0135637677776876, "train/extr_reward_mean": 0.029582832042732477, "train/extr_reward_min": -0.689229476514287, "train/extr_reward_std": 0.17179275101236025, "train/image_loss_mean": 4.242489282997491, "train/image_loss_std": 8.353771811380437, "train/model_loss_mean": 7.972280040461356, "train/model_loss_std": 12.35246002736516, "train/model_opt_grad_norm": 47.259708744069044, "train/model_opt_grad_steps": 33908.706806282724, "train/model_opt_loss": 9196.240881155923, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1155.1047120418848, "train/policy_entropy_mag": 2.412381867463676, "train/policy_entropy_max": 2.412381867463676, "train/policy_entropy_mean": 0.4643007551188244, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.530240884626099, "train/policy_logprob_mag": 7.438383778976521, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.4642087668960631, "train/policy_logprob_min": -7.438383778976521, "train/policy_logprob_std": 1.054399917263011, "train/policy_randomness_mag": 0.8514649340619591, "train/policy_randomness_max": 0.8514649340619591, "train/policy_randomness_mean": 0.16387779250038856, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.18715176306157835, "train/post_ent_mag": 53.766665952992064, "train/post_ent_max": 53.766665952992064, "train/post_ent_mean": 34.947803876786956, "train/post_ent_min": 18.229981352521488, "train/post_ent_std": 6.1241329277997245, "train/prior_ent_mag": 73.53663651231696, "train/prior_ent_max": 73.53663651231696, "train/prior_ent_mean": 41.04978890943278, "train/prior_ent_min": 22.004399883809516, "train/prior_ent_std": 8.812834822070537, "train/rep_loss_mean": 6.144341286564373, "train/rep_loss_std": 8.496760270982513, "train/reward_avg": 0.02267312238490238, "train/reward_loss_mean": 0.043053414477571765, "train/reward_loss_std": 0.1995105556558564, "train/reward_max_data": 1.0073298446795078, "train/reward_max_pred": 1.006728192274483, "train/reward_neg_acc": 0.9960990257912281, "train/reward_neg_loss": 0.02250910665186522, "train/reward_pos_acc": 0.9803591688890108, "train/reward_pos_loss": 0.7662349752106592, "train/reward_pred": 0.02233843520985848, "train/reward_rate": 0.02771187827225131, "train_stats/sum_log_reward": 5.472093007938806, "train_stats/max_log_achievement_collect_coal": 0.13953488372093023, "train_stats/max_log_achievement_collect_drink": 2.441860465116279, "train_stats/max_log_achievement_collect_sapling": 1.8372093023255813, "train_stats/max_log_achievement_collect_stone": 1.2790697674418605, "train_stats/max_log_achievement_collect_wood": 5.72093023255814, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.046511627906976744, "train_stats/max_log_achievement_make_wood_pickaxe": 0.813953488372093, "train_stats/max_log_achievement_make_wood_sword": 0.046511627906976744, "train_stats/max_log_achievement_place_plant": 1.697674418604651, "train_stats/max_log_achievement_place_stone": 0.6744186046511628, "train_stats/max_log_achievement_place_table": 2.046511627906977, "train_stats/max_log_achievement_wake_up": 2.4651162790697674, "train_stats/mean_log_entropy": 0.4204940823621528, "eval_stats/sum_log_reward": 5.100000023841858, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 6.625, "eval_stats/max_log_achievement_collect_sapling": 2.0, "eval_stats/max_log_achievement_collect_stone": 1.0, "eval_stats/max_log_achievement_collect_wood": 5.625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 1.875, "eval_stats/max_log_achievement_place_stone": 0.75, "eval_stats/max_log_achievement_place_table": 1.5, "eval_stats/max_log_achievement_wake_up": 2.5, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.002745490986853838, "report/cont_loss_std": 0.08006279170513153, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0006100095342844725, "report/cont_pos_acc": 0.9990166425704956, "report/cont_pos_loss": 0.002760189352557063, "report/cont_pred": 0.9920454621315002, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 6.441929340362549, "report/dyn_loss_std": 9.343276977539062, "report/image_loss_mean": 4.9474897384643555, "report/image_loss_std": 11.674188613891602, "report/model_loss_mean": 8.857980728149414, "report/model_loss_std": 16.15766716003418, "report/post_ent_mag": 53.05787658691406, "report/post_ent_max": 53.05787658691406, "report/post_ent_mean": 34.825416564941406, "report/post_ent_min": 19.359432220458984, "report/post_ent_std": 6.118051052093506, "report/prior_ent_mag": 73.87617492675781, "report/prior_ent_max": 73.87617492675781, "report/prior_ent_mean": 40.611961364746094, "report/prior_ent_min": 21.251325607299805, "report/prior_ent_std": 9.330582618713379, "report/rep_loss_mean": 6.441929340362549, "report/rep_loss_std": 9.343276977539062, "report/reward_avg": 0.02109374850988388, "report/reward_loss_mean": 0.04258812591433525, "report/reward_loss_std": 0.17586824297904968, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.007554531097412, "report/reward_neg_acc": 0.9989960789680481, "report/reward_neg_loss": 0.024861350655555725, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6731549501419067, "report/reward_pred": 0.021346881985664368, "report/reward_rate": 0.02734375, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.00022559647914022207, "eval/cont_loss_std": 0.006053165998309851, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0075397491455078125, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0001897075999295339, "eval/cont_pred": 0.9949818849563599, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 23.79452133178711, "eval/dyn_loss_std": 14.244948387145996, "eval/image_loss_mean": 37.902244567871094, "eval/image_loss_std": 41.67652130126953, "eval/model_loss_mean": 52.328617095947266, "eval/model_loss_std": 47.79153823852539, "eval/post_ent_mag": 46.18209457397461, "eval/post_ent_max": 46.18209457397461, "eval/post_ent_mean": 33.515228271484375, "eval/post_ent_min": 20.56378173828125, "eval/post_ent_std": 4.506044864654541, "eval/prior_ent_mag": 73.87617492675781, "eval/prior_ent_max": 73.87617492675781, "eval/prior_ent_mean": 46.09160614013672, "eval/prior_ent_min": 25.5089054107666, "eval/prior_ent_std": 8.969477653503418, "eval/rep_loss_mean": 23.79452133178711, "eval/rep_loss_std": 14.244948387145996, "eval/reward_avg": 0.01132812537252903, "eval/reward_loss_mean": 0.14943324029445648, "eval/reward_loss_std": 0.9407984018325806, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.001234531402588, "eval/reward_neg_acc": 0.9860973358154297, "eval/reward_neg_loss": 0.11661143600940704, "eval/reward_pos_acc": 0.8235294222831726, "eval/reward_pos_loss": 2.093642234802246, "eval/reward_pred": 0.013678890652954578, "eval/reward_rate": 0.0166015625, "replay/size": 140637.0, "replay/inserts": 7652.0, "replay/samples": 30608.0, "replay/insert_wait_avg": 1.5751765899737966e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.475584636355219e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 29680.0, "eval_replay/inserts": 2448.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1395005618824678e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1175870895385742e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0603580474854, "timer/env.step_count": 956.0, "timer/env.step_total": 91.7496235370636, "timer/env.step_frac": 0.0917440860431617, "timer/env.step_avg": 0.0959724095575979, "timer/env.step_min": 0.02269911766052246, "timer/env.step_max": 3.212210178375244, "timer/replay._sample_count": 30608.0, "timer/replay._sample_total": 15.826825857162476, "timer/replay._sample_frac": 0.01582587063851098, "timer/replay._sample_avg": 0.000517081346614038, "timer/replay._sample_min": 0.0003724098205566406, "timer/replay._sample_max": 0.02640080451965332, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1262.0, "timer/agent.policy_total": 20.415711402893066, "timer/agent.policy_frac": 0.02041447922478663, "timer/agent.policy_avg": 0.016177267355699736, "timer/agent.policy_min": 0.009465456008911133, "timer/agent.policy_max": 0.08275890350341797, "timer/dataset_train_count": 1913.0, "timer/dataset_train_total": 0.37651848793029785, "timer/dataset_train_frac": 0.00037649576338113366, "timer/dataset_train_avg": 0.00019682095553073595, "timer/dataset_train_min": 9.012222290039062e-05, "timer/dataset_train_max": 0.08961224555969238, "timer/agent.train_count": 1913.0, "timer/agent.train_total": 853.707850933075, "timer/agent.train_frac": 0.8536563259040199, "timer/agent.train_avg": 0.44626651904499476, "timer/agent.train_min": 0.42573094367980957, "timer/agent.train_max": 0.9201593399047852, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47580742835998535, "timer/agent.report_frac": 0.00047577871128593705, "timer/agent.report_avg": 0.23790371417999268, "timer/agent.report_min": 0.23194408416748047, "timer/agent.report_max": 0.24386334419250488, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.5272369384765625e-05, "timer/dataset_eval_frac": 2.5270844085958288e-08, "timer/dataset_eval_avg": 2.5272369384765625e-05, "timer/dataset_eval_min": 2.5272369384765625e-05, "timer/dataset_eval_max": 2.5272369384765625e-05, "fps": 7.651434520799456}
{"step": 141512, "time": 18388.821776390076, "episode/length": 173.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 141728, "time": 18415.621576070786, "episode/length": 163.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 141736, "time": 18418.025512456894, "episode/length": 119.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9916666666666667, "episode/intrinsic_return": 0.0}
{"step": 142072, "time": 18458.782982349396, "episode/length": 183.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 142232, "time": 18479.047529459, "episode/length": 160.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 142360, "time": 18495.531982421875, "episode/length": 206.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 143024, "time": 18574.71674799919, "episode/length": 188.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9682539682539683, "episode/intrinsic_return": 0.0}
{"step": 143064, "time": 18581.036053419113, "episode/length": 165.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 143344, "time": 18615.543120145798, "episode/length": 276.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9855595667870036, "episode/intrinsic_return": 0.0}
{"step": 143472, "time": 18631.93890953064, "episode/length": 316.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9968454258675079, "episode/intrinsic_return": 0.0}
{"step": 143744, "time": 18665.221007823944, "episode/length": 172.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 144088, "time": 18706.962997674942, "episode/length": 231.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.978448275862069, "episode/intrinsic_return": 0.0}
{"step": 144480, "time": 18754.702950000763, "episode/length": 181.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 144992, "time": 18815.894003391266, "episode/length": 407.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9779411764705882, "episode/intrinsic_return": 0.0}
{"step": 145096, "time": 18829.557702302933, "episode/length": 202.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 145152, "time": 18837.562746286392, "episode/length": 225.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9778761061946902, "episode/intrinsic_return": 0.0}
{"step": 145216, "time": 18846.59908723831, "episode/length": 268.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9888475836431226, "episode/intrinsic_return": 0.0}
{"step": 145320, "time": 18860.199386119843, "episode/length": 196.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 145528, "time": 18885.85027527809, "episode/length": 431.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 145616, "time": 18897.61083126068, "episode/length": 190.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 146432, "time": 18994.31625032425, "episode/length": 166.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 146728, "time": 19030.24849295616, "episode/length": 175.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9659090909090909, "episode/intrinsic_return": 0.0}
{"step": 146744, "time": 19033.5294611454, "episode/length": 151.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 146792, "time": 19040.561584949493, "episode/length": 204.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.0}
{"step": 146896, "time": 19054.169684171677, "episode/length": 209.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 147136, "time": 19083.862347126007, "episode/length": 189.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 147344, "time": 19109.54171872139, "episode/length": 357.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 147696, "time": 19153.709383010864, "episode/length": 157.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 147728, "time": 19158.922825336456, "episode/length": 341.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 147888, "time": 19178.929506778717, "episode/length": 144.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9517241379310345, "episode/intrinsic_return": 0.0}
{"step": 147920, "time": 19184.203112363815, "episode/length": 146.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 148096, "time": 19206.176537275314, "episode/length": 162.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 148416, "time": 19245.478403568268, "episode/length": 39.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 148752, "time": 19285.935304641724, "episode/length": 201.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 148952, "time": 19310.77906847, "episode/length": 256.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9844357976653697, "episode/intrinsic_return": 0.0}
{"step": 149096, "time": 19329.013581752777, "episode/length": 218.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 149221, "time": 19346.00540137291, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.6634461053527225, "train/action_min": 0.0, "train/action_std": 3.4424500748662665, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.048643306045248955, "train/actor_opt_grad_steps": 35905.0, "train/actor_opt_loss": -8.98335702733902, "train/adv_mag": 0.5578862450795599, "train/adv_max": 0.5161550297300415, "train/adv_mean": 0.00412843967788912, "train/adv_min": -0.4571350932416349, "train/adv_std": 0.06307026898801917, "train/cont_avg": 0.9945708926361386, "train/cont_loss_mean": 9.38138596955813e-05, "train/cont_loss_std": 0.002772168233554391, "train/cont_neg_acc": 0.9961103262877701, "train/cont_neg_loss": 0.007416914439252849, "train/cont_pos_acc": 0.9999902360510118, "train/cont_pos_loss": 5.7979213148225776e-05, "train/cont_pred": 0.9945727427407066, "train/cont_rate": 0.9945708926361386, "train/dyn_loss_mean": 6.132817192833023, "train/dyn_loss_std": 8.4923466385001, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.3038186557812266, "train/extr_critic_critic_opt_grad_steps": 35905.0, "train/extr_critic_critic_opt_loss": 16756.78981667698, "train/extr_critic_mag": 6.736283828716467, "train/extr_critic_max": 6.736283828716467, "train/extr_critic_mean": 1.442140785184237, "train/extr_critic_min": -0.6631127129686941, "train/extr_critic_std": 1.5319181745595272, "train/extr_return_normed_mag": 1.6272436256455902, "train/extr_return_normed_max": 1.6272436256455902, "train/extr_return_normed_mean": 0.35567533394487777, "train/extr_return_normed_min": -0.15133292121019695, "train/extr_return_normed_std": 0.32794104162419196, "train/extr_return_rate": 0.6377130735038531, "train/extr_return_raw_mag": 7.545054050955442, "train/extr_return_raw_max": 7.545054050955442, "train/extr_return_raw_mean": 1.4618766260619211, "train/extr_return_raw_min": -0.9641934916524604, "train/extr_return_raw_std": 1.5691210674767446, "train/extr_reward_mag": 1.0204366244892082, "train/extr_reward_max": 1.0204366244892082, "train/extr_reward_mean": 0.03159112607746726, "train/extr_reward_min": -0.6803036178692733, "train/extr_reward_std": 0.17675582828498124, "train/image_loss_mean": 4.176938388607289, "train/image_loss_std": 8.279943605460742, "train/model_loss_mean": 7.900479002754287, "train/model_loss_std": 12.274535273561384, "train/model_opt_grad_norm": 53.04400366603738, "train/model_opt_grad_steps": 35872.0198019802, "train/model_opt_loss": 10344.122043722928, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1311.881188118812, "train/policy_entropy_mag": 2.406757578991427, "train/policy_entropy_max": 2.406757578991427, "train/policy_entropy_mean": 0.4317181915930002, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.5007639760428136, "train/policy_logprob_mag": 7.438383803509249, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.43122698366642, "train/policy_logprob_min": -7.438383803509249, "train/policy_logprob_std": 1.0282330515951212, "train/policy_randomness_mag": 0.8494798089608108, "train/policy_randomness_max": 0.8494798089608108, "train/policy_randomness_mean": 0.15237757559902598, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.17674770884879745, "train/post_ent_mag": 54.277881546775895, "train/post_ent_max": 54.277881546775895, "train/post_ent_mean": 35.41384511890978, "train/post_ent_min": 18.51291011583687, "train/post_ent_std": 6.165357174259602, "train/prior_ent_mag": 73.76595295065701, "train/prior_ent_max": 73.76595295065701, "train/prior_ent_mean": 41.49476704739108, "train/prior_ent_min": 22.535999581365303, "train/prior_ent_std": 8.70892111381682, "train/rep_loss_mean": 6.132817192833023, "train/rep_loss_std": 8.4923466385001, "train/reward_avg": 0.023845528934777965, "train/reward_loss_mean": 0.043756512390209897, "train/reward_loss_std": 0.20147329782790477, "train/reward_max_data": 1.0113861413285283, "train/reward_max_pred": 1.0095087879955178, "train/reward_neg_acc": 0.9955449095456907, "train/reward_neg_loss": 0.022537410229278524, "train/reward_pos_acc": 0.9825921445199759, "train/reward_pos_loss": 0.7595935682258984, "train/reward_pred": 0.023630556920174472, "train/reward_rate": 0.028774752475247526, "train_stats/sum_log_reward": 5.516666677263048, "train_stats/max_log_achievement_collect_coal": 0.16666666666666666, "train_stats/max_log_achievement_collect_drink": 2.8333333333333335, "train_stats/max_log_achievement_collect_sapling": 1.5833333333333333, "train_stats/max_log_achievement_collect_stone": 3.1666666666666665, "train_stats/max_log_achievement_collect_wood": 6.166666666666667, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.1388888888888889, "train_stats/max_log_achievement_eat_cow": 0.05555555555555555, "train_stats/max_log_achievement_make_wood_pickaxe": 1.1388888888888888, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.4722222222222223, "train_stats/max_log_achievement_place_stone": 2.5833333333333335, "train_stats/max_log_achievement_place_table": 2.2222222222222223, "train_stats/max_log_achievement_wake_up": 3.0, "train_stats/mean_log_entropy": 0.4149991704357995, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 3.7941163100185804e-07, "report/cont_loss_std": 5.34778882865794e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 6.366198067553341e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 1.3124468978276127e-07, "report/cont_pred": 0.9960939884185791, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 5.3669233322143555, "report/dyn_loss_std": 7.928186416625977, "report/image_loss_mean": 2.91807222366333, "report/image_loss_std": 6.133738040924072, "report/model_loss_mean": 6.1752424240112305, "report/model_loss_std": 9.889304161071777, "report/post_ent_mag": 56.78493881225586, "report/post_ent_max": 56.78493881225586, "report/post_ent_mean": 35.00202941894531, "report/post_ent_min": 18.209396362304688, "report/post_ent_std": 6.100621223449707, "report/prior_ent_mag": 73.69773864746094, "report/prior_ent_max": 73.69773864746094, "report/prior_ent_mean": 40.412315368652344, "report/prior_ent_min": 24.215835571289062, "report/prior_ent_std": 8.444154739379883, "report/rep_loss_mean": 5.3669233322143555, "report/rep_loss_std": 7.928186416625977, "report/reward_avg": 0.02734375, "report/reward_loss_mean": 0.037016235291957855, "report/reward_loss_std": 0.14536181092262268, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0023491382598877, "report/reward_neg_acc": 0.9969788789749146, "report/reward_neg_loss": 0.017080048099160194, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6756173372268677, "report/reward_pred": 0.027545221149921417, "report/reward_rate": 0.0302734375, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.00013826502254232764, "eval/cont_loss_std": 0.004391961731016636, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.023562714457511902, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.0344081974599248e-07, "eval/cont_pred": 0.9942693114280701, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 19.861209869384766, "eval/dyn_loss_std": 13.473929405212402, "eval/image_loss_mean": 22.518314361572266, "eval/image_loss_std": 28.595504760742188, "eval/model_loss_mean": 34.565711975097656, "eval/model_loss_std": 33.9864616394043, "eval/post_ent_mag": 55.38710021972656, "eval/post_ent_max": 55.38710021972656, "eval/post_ent_mean": 35.02021026611328, "eval/post_ent_min": 21.969524383544922, "eval/post_ent_std": 6.024417877197266, "eval/prior_ent_mag": 73.69773864746094, "eval/prior_ent_max": 73.69773864746094, "eval/prior_ent_mean": 46.239498138427734, "eval/prior_ent_min": 24.117450714111328, "eval/prior_ent_std": 9.054293632507324, "eval/rep_loss_mean": 19.861209869384766, "eval/rep_loss_std": 13.473929405212402, "eval/reward_avg": 0.02919921837747097, "eval/reward_loss_mean": 0.13053159415721893, "eval/reward_loss_std": 0.8549569249153137, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0008234977722168, "eval/reward_neg_acc": 0.9939393401145935, "eval/reward_neg_loss": 0.0654527097940445, "eval/reward_pos_acc": 0.8235294222831726, "eval/reward_pos_loss": 2.02547550201416, "eval/reward_pred": 0.02265305072069168, "eval/reward_rate": 0.033203125, "replay/size": 148717.0, "replay/inserts": 8080.0, "replay/samples": 32320.0, "replay/insert_wait_avg": 1.5367080669591923e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.503914951097847e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 29680.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 8.195638656616211e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4111752510071, "timer/env.step_count": 1010.0, "timer/env.step_total": 81.83017182350159, "timer/env.step_frac": 0.08179653911100111, "timer/env.step_avg": 0.08101997210247681, "timer/env.step_min": 0.023060321807861328, "timer/env.step_max": 2.0391037464141846, "timer/replay._sample_count": 32320.0, "timer/replay._sample_total": 16.488856315612793, "timer/replay._sample_frac": 0.016482079292522572, "timer/replay._sample_avg": 0.0005101750097652473, "timer/replay._sample_min": 0.0003657341003417969, "timer/replay._sample_max": 0.026203393936157227, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1010.0, "timer/agent.policy_total": 16.28361439704895, "timer/agent.policy_frac": 0.01627692172967113, "timer/agent.policy_avg": 0.016122390492127672, "timer/agent.policy_min": 0.00988006591796875, "timer/agent.policy_max": 0.07068943977355957, "timer/dataset_train_count": 2020.0, "timer/dataset_train_total": 0.2951688766479492, "timer/dataset_train_frac": 0.0002950475603932455, "timer/dataset_train_avg": 0.000146123206261361, "timer/dataset_train_min": 8.821487426757812e-05, "timer/dataset_train_max": 0.0006163120269775391, "timer/agent.train_count": 2020.0, "timer/agent.train_total": 899.0188989639282, "timer/agent.train_frac": 0.898649396572725, "timer/agent.train_avg": 0.4450588608732318, "timer/agent.train_min": 0.4339442253112793, "timer/agent.train_max": 1.0517995357513428, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47358083724975586, "timer/agent.report_frac": 0.0004733861925632054, "timer/agent.report_avg": 0.23679041862487793, "timer/agent.report_min": 0.2310640811920166, "timer/agent.report_max": 0.24251675605773926, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8133392333984375e-05, "timer/dataset_eval_frac": 2.8121829333749292e-08, "timer/dataset_eval_avg": 2.8133392333984375e-05, "timer/dataset_eval_min": 2.8133392333984375e-05, "timer/dataset_eval_max": 2.8133392333984375e-05, "fps": 8.076564820334617}
{"step": 149248, "time": 19349.02538061142, "episode/length": 169.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 149256, "time": 19351.45622396469, "episode/length": 194.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9692307692307692, "episode/intrinsic_return": 0.0}
{"step": 149528, "time": 19384.398002147675, "episode/length": 200.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9800995024875622, "episode/intrinsic_return": 0.0}
{"step": 149656, "time": 19400.874361991882, "episode/length": 240.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.966804979253112, "episode/intrinsic_return": 0.0}
{"step": 150072, "time": 19470.35040307045, "eval_episode/length": 178.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9720670391061452}
{"step": 150072, "time": 19472.24646806717, "eval_episode/length": 185.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9731182795698925}
{"step": 150072, "time": 19473.930408477783, "eval_episode/length": 189.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 150072, "time": 19475.650024414062, "eval_episode/length": 195.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9795918367346939}
{"step": 150072, "time": 19477.518233537674, "eval_episode/length": 204.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9804878048780488}
{"step": 150072, "time": 19479.16489481926, "eval_episode/length": 206.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9903381642512077}
{"step": 150072, "time": 19481.143434524536, "eval_episode/length": 213.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9813084112149533}
{"step": 150072, "time": 19483.190799713135, "eval_episode/length": 227.0, "eval_episode/score": 5.099999979138374, "eval_episode/reward_rate": 0.9956140350877193}
{"step": 150280, "time": 19507.246490478516, "episode/length": 165.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 150304, "time": 19511.58464384079, "episode/length": 235.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 150528, "time": 19538.898146390915, "episode/length": 159.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 150736, "time": 19564.869095802307, "episode/length": 247.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9798387096774194, "episode/intrinsic_return": 0.0}
{"step": 150904, "time": 19586.076560020447, "episode/length": 205.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 151504, "time": 19657.70620584488, "episode/length": 152.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 151760, "time": 19689.014861106873, "episode/length": 262.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9695817490494296, "episode/intrinsic_return": 0.0}
{"step": 151800, "time": 19695.48345351219, "episode/length": 337.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 152048, "time": 19725.7724237442, "episode/length": 142.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 152056, "time": 19728.208566188812, "episode/length": 315.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9968354430379747, "episode/intrinsic_return": 0.0}
{"step": 152080, "time": 19732.53735089302, "episode/length": 193.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 152320, "time": 19761.85806131363, "episode/length": 251.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.996031746031746, "episode/intrinsic_return": 0.0}
{"step": 152472, "time": 19780.93998169899, "episode/length": 216.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 152720, "time": 19811.243739128113, "episode/length": 151.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 152864, "time": 19829.42956161499, "episode/length": 48.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 153232, "time": 19873.705327033997, "episode/length": 178.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9832402234636871, "episode/intrinsic_return": 0.0}
{"step": 153288, "time": 19881.68583202362, "episode/length": 154.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 153520, "time": 19910.048600673676, "episode/length": 149.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 153840, "time": 19948.51572394371, "episode/length": 139.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 154208, "time": 19992.64932513237, "episode/length": 268.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9962825278810409, "episode/intrinsic_return": 0.0}
{"step": 154240, "time": 19998.467400550842, "episode/length": 171.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 154352, "time": 20012.9918987751, "episode/length": 63.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.921875, "episode/intrinsic_return": 0.0}
{"step": 154488, "time": 20030.265335321426, "episode/length": 149.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9533333333333334, "episode/intrinsic_return": 0.0}
{"step": 154552, "time": 20039.094267845154, "episode/length": 164.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 155008, "time": 20093.421418190002, "episode/length": 405.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9778325123152709, "episode/intrinsic_return": 0.0}
{"step": 155104, "time": 20106.617002010345, "episode/length": 197.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 155376, "time": 20139.493638038635, "episode/length": 145.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 155392, "time": 20142.891738176346, "episode/length": 143.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 155448, "time": 20150.998769760132, "episode/length": 136.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9562043795620438, "episode/intrinsic_return": 0.0}
{"step": 155592, "time": 20169.28587961197, "episode/length": 438.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.979498861047836, "episode/intrinsic_return": 0.0}
{"step": 155736, "time": 20188.601899385452, "episode/length": 147.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 156200, "time": 20244.353095054626, "episode/length": 148.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 156672, "time": 20300.381562948227, "episode/length": 195.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 156760, "time": 20312.065766096115, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 157033, "time": 20346.24864602089, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.569074894831731, "train/action_min": 0.0, "train/action_std": 3.3856779881012744, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04885706746807465, "train/actor_opt_grad_steps": 37890.0, "train/actor_opt_loss": -9.746716716274237, "train/adv_mag": 0.5468418964972863, "train/adv_max": 0.5082513245252462, "train/adv_mean": 0.0039774354588212775, "train/adv_min": -0.45258900981683, "train/adv_std": 0.062107338641698547, "train/cont_avg": 0.9945262419871795, "train/cont_loss_mean": 0.00011359874431068652, "train/cont_loss_std": 0.003360038051435437, "train/cont_neg_acc": 0.9989743590354919, "train/cont_neg_loss": 0.008701568744954084, "train/cont_pos_acc": 0.9999848497219574, "train/cont_pos_loss": 7.164366992756827e-05, "train/cont_pred": 0.9945157313958193, "train/cont_rate": 0.9945262419871795, "train/dyn_loss_mean": 6.157082946483905, "train/dyn_loss_std": 8.5231289154444, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.2825255598777379, "train/extr_critic_critic_opt_grad_steps": 37890.0, "train/extr_critic_critic_opt_loss": 16851.347165464744, "train/extr_critic_mag": 6.99152893164219, "train/extr_critic_max": 6.99152893164219, "train/extr_critic_mean": 1.5639744073916704, "train/extr_critic_min": -0.6868308000075511, "train/extr_critic_std": 1.6288579256106646, "train/extr_return_normed_mag": 1.5858672031989465, "train/extr_return_normed_max": 1.5858672031989465, "train/extr_return_normed_mean": 0.36373458848549767, "train/extr_return_normed_min": -0.14358579661601628, "train/extr_return_normed_std": 0.33072036848618436, "train/extr_return_rate": 0.6440408342923873, "train/extr_return_raw_mag": 7.752873645684658, "train/extr_return_raw_max": 7.752873645684658, "train/extr_return_raw_mean": 1.584080840074099, "train/extr_return_raw_min": -0.9770437595171806, "train/extr_return_raw_std": 1.6703153463510367, "train/extr_reward_mag": 1.0191798686981202, "train/extr_reward_max": 1.0191798686981202, "train/extr_reward_mean": 0.030964807592905486, "train/extr_reward_min": -0.6869050643382928, "train/extr_reward_std": 0.17614048631527485, "train/image_loss_mean": 4.268331129123003, "train/image_loss_std": 8.81827335357666, "train/model_loss_mean": 8.006851907876822, "train/model_loss_std": 12.802679722125713, "train/model_opt_grad_norm": 46.19428415542994, "train/model_opt_grad_steps": 37855.18974358974, "train/model_opt_loss": 11177.998217147437, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1397.4358974358975, "train/policy_entropy_mag": 2.410333687219864, "train/policy_entropy_max": 2.410333687219864, "train/policy_entropy_mean": 0.44128181964923174, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.5211820441942948, "train/policy_logprob_mag": 7.438383845793895, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.4414783155306792, "train/policy_logprob_min": -7.438383845793895, "train/policy_logprob_std": 1.036603741462414, "train/policy_randomness_mag": 0.8507420182228088, "train/policy_randomness_max": 0.8507420182228088, "train/policy_randomness_mean": 0.15575311898421018, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.18395438989003499, "train/post_ent_mag": 55.179882949437854, "train/post_ent_max": 55.179882949437854, "train/post_ent_mean": 36.008619572566104, "train/post_ent_min": 18.80506362915039, "train/post_ent_std": 6.279029337565104, "train/prior_ent_mag": 73.92335083790314, "train/prior_ent_max": 73.92335083790314, "train/prior_ent_mean": 42.17267301510542, "train/prior_ent_min": 23.084956487019856, "train/prior_ent_std": 8.58875856644068, "train/rep_loss_mean": 6.157082946483905, "train/rep_loss_std": 8.5231289154444, "train/reward_avg": 0.023806089564011645, "train/reward_loss_mean": 0.04415739908432349, "train/reward_loss_std": 0.20490855937584854, "train/reward_max_data": 1.0087179507964696, "train/reward_max_pred": 1.0081310700147579, "train/reward_neg_acc": 0.9957192396506285, "train/reward_neg_loss": 0.022503094389461555, "train/reward_pos_acc": 0.9785717316162892, "train/reward_pos_loss": 0.7748545561081324, "train/reward_pred": 0.02334530388411039, "train/reward_rate": 0.02888621794871795, "train_stats/sum_log_reward": 5.889473764519942, "train_stats/max_log_achievement_collect_coal": 0.13157894736842105, "train_stats/max_log_achievement_collect_drink": 3.026315789473684, "train_stats/max_log_achievement_collect_sapling": 1.5526315789473684, "train_stats/max_log_achievement_collect_stone": 3.1578947368421053, "train_stats/max_log_achievement_collect_wood": 6.5, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.07894736842105263, "train_stats/max_log_achievement_make_wood_pickaxe": 1.394736842105263, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.5526315789473684, "train_stats/max_log_achievement_place_stone": 2.3947368421052633, "train_stats/max_log_achievement_place_table": 2.1052631578947367, "train_stats/max_log_achievement_wake_up": 2.5, "train_stats/mean_log_entropy": 0.41517818836789383, "eval_stats/sum_log_reward": 5.850000083446503, "eval_stats/max_log_achievement_collect_coal": 0.25, "eval_stats/max_log_achievement_collect_drink": 5.875, "eval_stats/max_log_achievement_collect_sapling": 1.0, "eval_stats/max_log_achievement_collect_stone": 2.75, "eval_stats/max_log_achievement_collect_wood": 6.875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.125, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.5, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 1.0, "eval_stats/max_log_achievement_place_stone": 1.625, "eval_stats/max_log_achievement_place_table": 2.125, "eval_stats/max_log_achievement_wake_up": 2.75, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 8.788480954535771e-06, "report/cont_loss_std": 3.897518035955727e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.4991864190960769e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 8.764152880758047e-06, "report/cont_pred": 0.9960850477218628, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 5.626721382141113, "report/dyn_loss_std": 8.020292282104492, "report/image_loss_mean": 3.956185817718506, "report/image_loss_std": 7.017058372497559, "report/model_loss_mean": 7.364048957824707, "report/model_loss_std": 10.801342964172363, "report/post_ent_mag": 53.638763427734375, "report/post_ent_max": 53.638763427734375, "report/post_ent_mean": 37.31850051879883, "report/post_ent_min": 20.85529327392578, "report/post_ent_std": 5.9240264892578125, "report/prior_ent_mag": 73.75566101074219, "report/prior_ent_max": 73.75566101074219, "report/prior_ent_mean": 43.02838134765625, "report/prior_ent_min": 27.843568801879883, "report/prior_ent_std": 8.212532997131348, "report/rep_loss_mean": 5.626721382141113, "report/rep_loss_std": 8.020292282104492, "report/reward_avg": 0.01904296875, "report/reward_loss_mean": 0.03182172402739525, "report/reward_loss_std": 0.14480522274971008, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0018129348754883, "report/reward_neg_acc": 0.9940059781074524, "report/reward_neg_loss": 0.014553731307387352, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7833547592163086, "report/reward_pred": 0.017400547862052917, "report/reward_rate": 0.0224609375, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 9.870441317616496e-06, "eval/cont_loss_std": 0.0001074256215360947, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 9.870441317616496e-06, "eval/cont_pred": 0.9999901056289673, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 25.508102416992188, "eval/dyn_loss_std": 13.730881690979004, "eval/image_loss_mean": 36.105560302734375, "eval/image_loss_std": 34.30149841308594, "eval/model_loss_mean": 51.494140625, "eval/model_loss_std": 40.08643341064453, "eval/post_ent_mag": 49.730690002441406, "eval/post_ent_max": 49.730690002441406, "eval/post_ent_mean": 35.36726760864258, "eval/post_ent_min": 20.42432403564453, "eval/post_ent_std": 4.9839887619018555, "eval/prior_ent_mag": 73.75566101074219, "eval/prior_ent_max": 73.75566101074219, "eval/prior_ent_mean": 49.35548400878906, "eval/prior_ent_min": 31.480764389038086, "eval/prior_ent_std": 7.465599536895752, "eval/rep_loss_mean": 25.508102416992188, "eval/rep_loss_std": 13.730881690979004, "eval/reward_avg": 0.02353515662252903, "eval/reward_loss_mean": 0.08370668441057205, "eval/reward_loss_std": 0.6631366014480591, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0000286102294922, "eval/reward_neg_acc": 0.9909909963607788, "eval/reward_neg_loss": 0.034445248544216156, "eval/reward_pos_acc": 0.7999999523162842, "eval/reward_pos_loss": 2.0521936416625977, "eval/reward_pred": 0.021563630551099777, "eval/reward_rate": 0.0244140625, "replay/size": 156529.0, "replay/inserts": 7812.0, "replay/samples": 31248.0, "replay/insert_wait_avg": 1.5125479749453964e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.464161788385707e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 31504.0, "eval_replay/inserts": 1824.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1286976044638116e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.301568984985352e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2264676094055, "timer/env.step_count": 977.0, "timer/env.step_total": 84.22986221313477, "timer/env.step_frac": 0.08421079119656633, "timer/env.step_avg": 0.0862127555917449, "timer/env.step_min": 0.023015737533569336, "timer/env.step_max": 2.135052442550659, "timer/replay._sample_count": 31248.0, "timer/replay._sample_total": 15.4503653049469, "timer/replay._sample_frac": 0.015446867089884249, "timer/replay._sample_avg": 0.0004944433341316852, "timer/replay._sample_min": 0.00036215782165527344, "timer/replay._sample_max": 0.026433229446411133, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1205.0, "timer/agent.policy_total": 18.96442198753357, "timer/agent.policy_frac": 0.01896012813264135, "timer/agent.policy_avg": 0.01573810953322288, "timer/agent.policy_min": 0.009296894073486328, "timer/agent.policy_max": 0.06626391410827637, "timer/dataset_train_count": 1953.0, "timer/dataset_train_total": 0.29253292083740234, "timer/dataset_train_frac": 0.00029246668660605593, "timer/dataset_train_avg": 0.00014978644180102527, "timer/dataset_train_min": 9.036064147949219e-05, "timer/dataset_train_max": 0.004257917404174805, "timer/agent.train_count": 1953.0, "timer/agent.train_total": 864.9915878772736, "timer/agent.train_frac": 0.8647957396534901, "timer/agent.train_avg": 0.4429040388516506, "timer/agent.train_min": 0.4293997287750244, "timer/agent.train_max": 0.922877311706543, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47510242462158203, "timer/agent.report_frac": 0.00047499485367259085, "timer/agent.report_avg": 0.23755121231079102, "timer/agent.report_min": 0.2317490577697754, "timer/agent.report_max": 0.24335336685180664, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 5.054473876953125e-05, "timer/dataset_eval_frac": 5.053329461510438e-08, "timer/dataset_eval_avg": 5.054473876953125e-05, "timer/dataset_eval_min": 5.054473876953125e-05, "timer/dataset_eval_max": 5.054473876953125e-05, "fps": 7.810126900856052}
{"step": 157096, "time": 20353.473965883255, "episode/length": 205.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 157152, "time": 20361.51933670044, "episode/length": 219.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 157528, "time": 20406.93552184105, "episode/length": 165.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 157672, "time": 20425.18236899376, "episode/length": 241.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9793388429752066, "episode/intrinsic_return": 0.0}
{"step": 157936, "time": 20457.360861301422, "episode/length": 430.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9791183294663574, "episode/intrinsic_return": 0.0}
{"step": 158128, "time": 20481.16760277748, "episode/length": 316.0, "episode/score": 9.100000031292439, "episode/reward_rate": 0.9842271293375394, "episode/intrinsic_return": 0.0}
{"step": 158272, "time": 20499.40082192421, "episode/length": 199.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 158328, "time": 20507.500151395798, "episode/length": 146.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9591836734693877, "episode/intrinsic_return": 0.0}
{"step": 158728, "time": 20555.74149608612, "episode/length": 149.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 158936, "time": 20581.365814208984, "episode/length": 271.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9852941176470589, "episode/intrinsic_return": 0.0}
{"step": 159120, "time": 20604.434582948685, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 159136, "time": 20607.86038184166, "episode/length": 107.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9444444444444444, "episode/intrinsic_return": 0.0}
{"step": 159160, "time": 20612.696445941925, "episode/length": 152.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 159288, "time": 20629.021361112595, "episode/length": 273.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9817518248175182, "episode/intrinsic_return": 0.0}
{"step": 159768, "time": 20686.265725135803, "episode/length": 179.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 159968, "time": 20710.90889286995, "episode/length": 154.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 160056, "time": 20742.66273164749, "eval_episode/length": 144.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.993103448275862}
{"step": 160056, "time": 20744.509552001953, "eval_episode/length": 152.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9673202614379085}
{"step": 160056, "time": 20746.38175868988, "eval_episode/length": 160.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.968944099378882}
{"step": 160056, "time": 20748.501271009445, "eval_episode/length": 173.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9770114942528736}
{"step": 160056, "time": 20750.17122578621, "eval_episode/length": 179.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9777777777777777}
{"step": 160056, "time": 20751.917610168457, "eval_episode/length": 187.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9840425531914894}
{"step": 160056, "time": 20753.39428949356, "eval_episode/length": 188.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9735449735449735}
{"step": 160056, "time": 20755.199940681458, "eval_episode/length": 51.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.9807692307692307}
{"step": 160080, "time": 20758.03086733818, "episode/length": 243.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9631147540983607, "episode/intrinsic_return": 0.0}
{"step": 160248, "time": 20779.510464191437, "episode/length": 138.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.0}
{"step": 160392, "time": 20797.729925632477, "episode/length": 52.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 160480, "time": 20809.547481060028, "episode/length": 148.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 160488, "time": 20811.993458747864, "episode/length": 193.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 160928, "time": 20864.82532310486, "episode/length": 220.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9819004524886877, "episode/intrinsic_return": 0.0}
{"step": 161192, "time": 20897.18291759491, "episode/length": 87.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9431818181818182, "episode/intrinsic_return": 0.0}
{"step": 161256, "time": 20906.13745880127, "episode/length": 146.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 161272, "time": 20909.43342924118, "episode/length": 187.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 161296, "time": 20913.856322050095, "episode/length": 45.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 161392, "time": 20927.202936172485, "episode/length": 283.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9859154929577465, "episode/intrinsic_return": 0.0}
{"step": 161424, "time": 20932.43498325348, "episode/length": 146.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9659863945578231, "episode/intrinsic_return": 0.0}
{"step": 161976, "time": 20998.18414592743, "episode/length": 197.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 162176, "time": 21023.13014650345, "episode/length": 211.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 162640, "time": 21079.064603090286, "episode/length": 170.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 162672, "time": 21084.158695220947, "episode/length": 176.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 162728, "time": 21092.180468797684, "episode/length": 162.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 162728, "time": 21092.213147878647, "episode/length": 191.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 163008, "time": 21127.84924697876, "episode/length": 213.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 163504, "time": 21187.24486207962, "episode/length": 165.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 163864, "time": 21232.271936178207, "episode/length": 44.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 163896, "time": 21237.550540208817, "episode/length": 145.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 163904, "time": 21239.994960546494, "episode/length": 240.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.979253112033195, "episode/intrinsic_return": 0.0}
{"step": 163944, "time": 21246.16690015793, "episode/length": 158.0, "episode/score": 4.099999964237213, "episode/reward_rate": 0.9622641509433962, "episode/intrinsic_return": 0.0}
{"step": 164384, "time": 21298.960609436035, "episode/length": 373.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9759358288770054, "episode/intrinsic_return": 0.0}
{"step": 164400, "time": 21302.41661643982, "episode/length": 173.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 164456, "time": 21310.48058462143, "episode/length": 226.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9823788546255506, "episode/intrinsic_return": 0.0}
{"step": 164696, "time": 21339.880173683167, "episode/length": 38.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 164729, "time": 21346.35333967209, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.385983165681671, "train/action_min": 0.0, "train/action_std": 3.082416609778923, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.045937794709452695, "train/actor_opt_grad_steps": 39830.0, "train/actor_opt_loss": -12.048080544252855, "train/adv_mag": 0.5168358262029954, "train/adv_max": 0.468662191240281, "train/adv_mean": 0.0024804041437904265, "train/adv_min": -0.4414886023868551, "train/adv_std": 0.05857991344184455, "train/cont_avg": 0.9942873623704663, "train/cont_loss_mean": 7.847641693391086e-05, "train/cont_loss_std": 0.0022459828106419226, "train/cont_neg_acc": 0.9983160622379322, "train/cont_neg_loss": 0.005817487766491533, "train/cont_pos_acc": 0.9999949085897732, "train/cont_pos_loss": 4.689932912152976e-05, "train/cont_pred": 0.9942963268472741, "train/cont_rate": 0.9942873623704663, "train/dyn_loss_mean": 6.119850593527364, "train/dyn_loss_std": 8.546854098226122, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1948557743136747, "train/extr_critic_critic_opt_grad_steps": 39830.0, "train/extr_critic_critic_opt_loss": 16597.452037119496, "train/extr_critic_mag": 7.348942887597751, "train/extr_critic_max": 7.348942887597751, "train/extr_critic_mean": 1.7636135168026148, "train/extr_critic_min": -0.6616465087999334, "train/extr_critic_std": 1.750205111627134, "train/extr_return_normed_mag": 1.542311563392995, "train/extr_return_normed_max": 1.542311563392995, "train/extr_return_normed_mean": 0.3738415062890769, "train/extr_return_normed_min": -0.13634450380434643, "train/extr_return_normed_std": 0.33210314933808976, "train/extr_return_rate": 0.6711534897898145, "train/extr_return_raw_mag": 8.051280651685488, "train/extr_return_raw_max": 8.051280651685488, "train/extr_return_raw_mean": 1.7769216336116889, "train/extr_return_raw_min": -0.9624883751795081, "train/extr_return_raw_std": 1.7832694282185846, "train/extr_reward_mag": 1.0216792642761388, "train/extr_reward_max": 1.0216792642761388, "train/extr_reward_mean": 0.032240040745065, "train/extr_reward_min": -0.6845435058514688, "train/extr_reward_std": 0.18019839488162895, "train/image_loss_mean": 4.0825722847577826, "train/image_loss_std": 8.398123064189377, "train/model_loss_mean": 7.798721096058584, "train/model_loss_std": 12.388927207709594, "train/model_opt_grad_norm": 47.87343000500931, "train/model_opt_grad_steps": 39793.502590673575, "train/model_opt_loss": 10614.30852291127, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1360.103626943005, "train/policy_entropy_mag": 2.407707615837532, "train/policy_entropy_max": 2.407707615837532, "train/policy_entropy_mean": 0.4176379292431273, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.5057423080805052, "train/policy_logprob_mag": 7.438383897969143, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.41747148466233763, "train/policy_logprob_min": -7.438383897969143, "train/policy_logprob_std": 1.0175259647591743, "train/policy_randomness_mag": 0.849815130542597, "train/policy_randomness_max": 0.849815130542597, "train/policy_randomness_mean": 0.1474078607605529, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.1785048410064816, "train/post_ent_mag": 55.24964823747546, "train/post_ent_max": 55.24964823747546, "train/post_ent_mean": 36.50078134092025, "train/post_ent_min": 18.661217145969214, "train/post_ent_std": 6.296728625816384, "train/prior_ent_mag": 74.11697648596888, "train/prior_ent_max": 74.11697648596888, "train/prior_ent_mean": 42.60846581730818, "train/prior_ent_min": 23.682534143714708, "train/prior_ent_std": 8.521696910956981, "train/rep_loss_mean": 6.119850593527364, "train/rep_loss_std": 8.546854098226122, "train/reward_avg": 0.02486793623532656, "train/reward_loss_mean": 0.04415996228899672, "train/reward_loss_std": 0.19890891189247834, "train/reward_max_data": 1.0119171012868535, "train/reward_max_pred": 1.0095098488071421, "train/reward_neg_acc": 0.9957634034552105, "train/reward_neg_loss": 0.02227441556848238, "train/reward_pos_acc": 0.9834443201055181, "train/reward_pos_loss": 0.7552550987876141, "train/reward_pred": 0.02453575844495253, "train/reward_rate": 0.029934423575129532, "train_stats/sum_log_reward": 5.78181820566004, "train_stats/max_log_achievement_collect_coal": 0.13636363636363635, "train_stats/max_log_achievement_collect_drink": 3.340909090909091, "train_stats/max_log_achievement_collect_sapling": 1.7272727272727273, "train_stats/max_log_achievement_collect_stone": 2.909090909090909, "train_stats/max_log_achievement_collect_wood": 6.954545454545454, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.09090909090909091, "train_stats/max_log_achievement_eat_cow": 0.022727272727272728, "train_stats/max_log_achievement_make_wood_pickaxe": 1.5681818181818181, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.7045454545454546, "train_stats/max_log_achievement_place_stone": 2.2045454545454546, "train_stats/max_log_achievement_place_table": 1.9772727272727273, "train_stats/max_log_achievement_wake_up": 2.0454545454545454, "train_stats/mean_log_entropy": 0.3681246814402667, "eval_stats/sum_log_reward": 4.8499999195337296, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 3.125, "eval_stats/max_log_achievement_collect_sapling": 0.875, "eval_stats/max_log_achievement_collect_stone": 3.125, "eval_stats/max_log_achievement_collect_wood": 5.625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.875, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 0.875, "eval_stats/max_log_achievement_place_stone": 2.25, "eval_stats/max_log_achievement_place_table": 1.75, "eval_stats/max_log_achievement_wake_up": 1.375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 1.2250362715349183e-06, "report/cont_loss_std": 3.090176687692292e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00020209192007314414, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.3942831717249646e-07, "report/cont_pred": 0.9951179623603821, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 5.361180305480957, "report/dyn_loss_std": 8.01530647277832, "report/image_loss_mean": 2.814763069152832, "report/image_loss_std": 5.601816654205322, "report/model_loss_mean": 6.068267822265625, "report/model_loss_std": 9.354507446289062, "report/post_ent_mag": 56.943519592285156, "report/post_ent_max": 56.943519592285156, "report/post_ent_mean": 37.748992919921875, "report/post_ent_min": 17.88067626953125, "report/post_ent_std": 7.22349214553833, "report/prior_ent_mag": 74.16127014160156, "report/prior_ent_max": 74.16127014160156, "report/prior_ent_mean": 42.98181915283203, "report/prior_ent_min": 21.694761276245117, "report/prior_ent_std": 8.377638816833496, "report/rep_loss_mean": 5.361180305480957, "report/rep_loss_std": 8.01530647277832, "report/reward_avg": 0.02236328274011612, "report/reward_loss_mean": 0.03679521381855011, "report/reward_loss_std": 0.18360979855060577, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0041754245758057, "report/reward_neg_acc": 0.9989960789680481, "report/reward_neg_loss": 0.018667642027139664, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6816189885139465, "report/reward_pred": 0.023075487464666367, "report/reward_rate": 0.02734375, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 1.995874043814183e-07, "eval/cont_loss_std": 9.496807820141839e-07, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.995874043814183e-07, "eval/cont_pred": 0.9999998807907104, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 21.333335876464844, "eval/dyn_loss_std": 13.174039840698242, "eval/image_loss_mean": 27.509166717529297, "eval/image_loss_std": 33.211238861083984, "eval/model_loss_mean": 40.406734466552734, "eval/model_loss_std": 38.02737808227539, "eval/post_ent_mag": 55.32387161254883, "eval/post_ent_max": 55.32387161254883, "eval/post_ent_mean": 35.98101806640625, "eval/post_ent_min": 23.393108367919922, "eval/post_ent_std": 5.757705211639404, "eval/prior_ent_mag": 74.16127014160156, "eval/prior_ent_max": 74.16127014160156, "eval/prior_ent_mean": 48.24519729614258, "eval/prior_ent_min": 27.958961486816406, "eval/prior_ent_std": 8.503640174865723, "eval/rep_loss_mean": 21.333335876464844, "eval/rep_loss_std": 13.174039840698242, "eval/reward_avg": 0.02314453199505806, "eval/reward_loss_mean": 0.09756788611412048, "eval/reward_loss_std": 0.7149276733398438, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0017695426940918, "eval/reward_neg_acc": 0.9889779686927795, "eval/reward_neg_loss": 0.03784051910042763, "eval/reward_pos_acc": 0.692307710647583, "eval/reward_pos_loss": 2.3901796340942383, "eval/reward_pred": 0.022806964814662933, "eval/reward_rate": 0.025390625, "replay/size": 164225.0, "replay/inserts": 7696.0, "replay/samples": 30784.0, "replay/insert_wait_avg": 1.57809802747318e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.256493746862589e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 33080.0, "eval_replay/inserts": 1576.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.5580412094968226e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.791685104370117e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.086455821991, "timer/env.step_count": 962.0, "timer/env.step_total": 94.42322516441345, "timer/env.step_frac": 0.09441506243258252, "timer/env.step_avg": 0.0981530407114485, "timer/env.step_min": 0.023183345794677734, "timer/env.step_max": 3.1289021968841553, "timer/replay._sample_count": 30784.0, "timer/replay._sample_total": 15.253330707550049, "timer/replay._sample_frac": 0.015252012082308457, "timer/replay._sample_avg": 0.0004954954101984813, "timer/replay._sample_min": 0.0003693103790283203, "timer/replay._sample_max": 0.027789831161499023, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1159.0, "timer/agent.policy_total": 19.603009700775146, "timer/agent.policy_frac": 0.019601315052970136, "timer/agent.policy_avg": 0.016913727092989772, "timer/agent.policy_min": 0.009265899658203125, "timer/agent.policy_max": 0.17836570739746094, "timer/dataset_train_count": 1924.0, "timer/dataset_train_total": 0.29204368591308594, "timer/dataset_train_frac": 0.00029201843921888675, "timer/dataset_train_avg": 0.00015178985754318397, "timer/dataset_train_min": 9.1552734375e-05, "timer/dataset_train_max": 0.0012202262878417969, "timer/agent.train_count": 1924.0, "timer/agent.train_total": 854.7057600021362, "timer/agent.train_frac": 0.854631872101134, "timer/agent.train_avg": 0.4442337629948733, "timer/agent.train_min": 0.4317798614501953, "timer/agent.train_max": 0.9756491184234619, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4749715328216553, "timer/agent.report_frac": 0.00047493047231728254, "timer/agent.report_avg": 0.23748576641082764, "timer/agent.report_min": 0.22865819931030273, "timer/agent.report_max": 0.24631333351135254, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.218650817871094e-05, "timer/dataset_eval_frac": 3.21837257082501e-08, "timer/dataset_eval_avg": 3.218650817871094e-05, "timer/dataset_eval_min": 3.218650817871094e-05, "timer/dataset_eval_max": 3.218650817871094e-05, "fps": 7.6952189368483985}
{"step": 165296, "time": 21412.83011341095, "episode/length": 320.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9906542056074766, "episode/intrinsic_return": 0.0}
{"step": 165360, "time": 21421.770874500275, "episode/length": 176.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 165648, "time": 21456.91785788536, "episode/length": 155.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 165816, "time": 21478.594487428665, "episode/length": 169.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 166208, "time": 21525.84812092781, "episode/length": 292.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9829351535836177, "episode/intrinsic_return": 0.0}
{"step": 166288, "time": 21536.69148516655, "episode/length": 198.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.0}
{"step": 166520, "time": 21565.30154967308, "episode/length": 152.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9607843137254902, "episode/intrinsic_return": 0.0}
{"step": 166744, "time": 21592.957112550735, "episode/length": 355.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9915730337078652, "episode/intrinsic_return": 0.0}
{"step": 166864, "time": 21608.48126721382, "episode/length": 42.0, "episode/score": 1.0999999940395355, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 166952, "time": 21620.441682577133, "episode/length": 198.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9698492462311558, "episode/intrinsic_return": 0.0}
{"step": 166976, "time": 21624.69157743454, "episode/length": 165.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 167304, "time": 21664.436302661896, "episode/length": 185.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 167488, "time": 21687.39883494377, "episode/length": 447.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9977678571428571, "episode/intrinsic_return": 0.0}
{"step": 167536, "time": 21694.5110142231, "episode/length": 165.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.963855421686747, "episode/intrinsic_return": 0.0}
{"step": 167624, "time": 21706.314834594727, "episode/length": 166.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 168040, "time": 21756.170923233032, "episode/length": 135.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.0}
{"step": 168312, "time": 21789.72470498085, "episode/length": 195.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 168360, "time": 21796.921648025513, "episode/length": 186.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9625668449197861, "episode/intrinsic_return": 0.0}
{"step": 168504, "time": 21815.02960038185, "episode/length": 149.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 168832, "time": 21854.682329177856, "episode/length": 167.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 168856, "time": 21858.980276584625, "episode/length": 164.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 168888, "time": 21864.312071084976, "episode/length": 238.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9832635983263598, "episode/intrinsic_return": 0.0}
{"step": 169240, "time": 21906.76917886734, "episode/length": 201.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 169328, "time": 21919.098219633102, "episode/length": 54.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 169656, "time": 21959.236865997314, "episode/length": 167.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 169792, "time": 21976.709969997406, "episode/length": 218.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 169896, "time": 21990.190132379532, "episode/length": 173.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 170040, "time": 22026.88836288452, "eval_episode/length": 158.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9685534591194969}
{"step": 170040, "time": 22028.725724697113, "eval_episode/length": 165.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9939759036144579}
{"step": 170040, "time": 22030.348053455353, "eval_episode/length": 167.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9702380952380952}
{"step": 170040, "time": 22032.39977145195, "eval_episode/length": 180.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.994475138121547}
{"step": 170040, "time": 22032.405868291855, "eval_episode/length": 180.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.994475138121547}
{"step": 170040, "time": 22036.89053750038, "eval_episode/length": 210.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.995260663507109}
{"step": 170040, "time": 22039.0499894619, "eval_episode/length": 224.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9955555555555555}
{"step": 170040, "time": 22041.203949213028, "eval_episode/length": 240.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.995850622406639}
{"step": 170152, "time": 22054.19648861885, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 170184, "time": 22059.40027666092, "episode/length": 227.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 170304, "time": 22074.868677854538, "episode/length": 180.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 170512, "time": 22100.64105796814, "episode/length": 44.0, "episode/score": 1.0999999940395355, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 170896, "time": 22146.862685918808, "episode/length": 195.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 170976, "time": 22157.76938533783, "episode/length": 147.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 171056, "time": 22168.73547554016, "episode/length": 144.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 171424, "time": 22213.726674556732, "episode/length": 45.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.8913043478260869, "episode/intrinsic_return": 0.0}
{"step": 171824, "time": 22262.136751174927, "episode/length": 105.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9622641509433962, "episode/intrinsic_return": 0.0}
{"step": 171832, "time": 22264.570994377136, "episode/length": 190.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 171976, "time": 22282.96090555191, "episode/length": 182.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 172072, "time": 22296.785058498383, "episode/length": 353.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9971751412429378, "episode/intrinsic_return": 0.0}
{"step": 172477, "time": 22346.4682533741, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.316405620771585, "train/action_min": 0.0, "train/action_std": 3.0094257740630317, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04618494527548859, "train/actor_opt_grad_steps": 41765.0, "train/actor_opt_loss": -12.565961908049804, "train/adv_mag": 0.5239666482222449, "train/adv_max": 0.4807948797326727, "train/adv_mean": 0.0023661247284986323, "train/adv_min": -0.4396417148641704, "train/adv_std": 0.05828157109544449, "train/cont_avg": 0.9943218427835051, "train/cont_loss_mean": 0.0001482914451715866, "train/cont_loss_std": 0.004342514151786042, "train/cont_neg_acc": 0.9959928826572969, "train/cont_neg_loss": 0.015737446065554415, "train/cont_pos_acc": 0.9999898626017816, "train/cont_pos_loss": 5.9259928565632686e-05, "train/cont_pred": 0.9943334659964768, "train/cont_rate": 0.9943218427835051, "train/dyn_loss_mean": 6.2804860282190065, "train/dyn_loss_std": 8.648621591096072, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.2208689740023662, "train/extr_critic_critic_opt_grad_steps": 41765.0, "train/extr_critic_critic_opt_loss": 16688.511814392717, "train/extr_critic_mag": 7.338483817798576, "train/extr_critic_max": 7.338483817798576, "train/extr_critic_mean": 1.6482590667365753, "train/extr_critic_min": -0.6733214597112125, "train/extr_critic_std": 1.7276357031360114, "train/extr_return_normed_mag": 1.5561409137912632, "train/extr_return_normed_max": 1.5561409137912632, "train/extr_return_normed_mean": 0.3571684405822115, "train/extr_return_normed_min": -0.1397623195092088, "train/extr_return_normed_std": 0.33098576532811236, "train/extr_return_rate": 0.6411864739103416, "train/extr_return_raw_mag": 8.036559591588286, "train/extr_return_raw_max": 8.036559591588286, "train/extr_return_raw_mean": 1.6608467578273458, "train/extr_return_raw_min": -0.982332640394722, "train/extr_return_raw_std": 1.7603748225674187, "train/extr_reward_mag": 1.0236807422539622, "train/extr_reward_max": 1.0236807422539622, "train/extr_reward_mean": 0.03261880121510668, "train/extr_reward_min": -0.6907820683164695, "train/extr_reward_std": 0.18123084083967603, "train/image_loss_mean": 4.246446334209638, "train/image_loss_std": 8.76500887600417, "train/model_loss_mean": 8.060381724662388, "train/model_loss_std": 12.817913281548883, "train/model_opt_grad_norm": 50.006476382619326, "train/model_opt_grad_steps": 41726.798969072166, "train/model_opt_loss": 11417.94945282297, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1430.4123711340205, "train/policy_entropy_mag": 2.4407755210227573, "train/policy_entropy_max": 2.4407755210227573, "train/policy_entropy_mean": 0.4199485364034004, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.5132911990291065, "train/policy_logprob_mag": 7.438383888952511, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.42064258471592186, "train/policy_logprob_min": -7.438383888952511, "train/policy_logprob_std": 1.0226317696350138, "train/policy_randomness_mag": 0.8614866487758676, "train/policy_randomness_max": 0.8614866487758676, "train/policy_randomness_mean": 0.14822340411009247, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.18116927000972413, "train/post_ent_mag": 56.07393569553021, "train/post_ent_max": 56.07393569553021, "train/post_ent_mean": 36.94143948112566, "train/post_ent_min": 18.970843585496095, "train/post_ent_std": 6.378113950650716, "train/prior_ent_mag": 74.18660885525733, "train/prior_ent_max": 74.18660885525733, "train/prior_ent_mean": 43.19280561466807, "train/prior_ent_min": 24.220468540781553, "train/prior_ent_std": 8.476663002033824, "train/rep_loss_mean": 6.2804860282190065, "train/rep_loss_std": 8.648621591096072, "train/reward_avg": 0.024802673807290874, "train/reward_loss_mean": 0.045495454615615695, "train/reward_loss_std": 0.20255119326649254, "train/reward_max_data": 1.0077319606063293, "train/reward_max_pred": 1.0088670819076067, "train/reward_neg_acc": 0.9952930079907486, "train/reward_neg_loss": 0.023339707529191504, "train/reward_pos_acc": 0.9811127717347489, "train/reward_pos_loss": 0.7625402322749502, "train/reward_pred": 0.02445259804059703, "train/reward_rate": 0.029966374033505154, "train_stats/sum_log_reward": 5.920512853524624, "train_stats/max_log_achievement_collect_coal": 0.1794871794871795, "train_stats/max_log_achievement_collect_drink": 3.1538461538461537, "train_stats/max_log_achievement_collect_sapling": 1.8205128205128205, "train_stats/max_log_achievement_collect_stone": 3.358974358974359, "train_stats/max_log_achievement_collect_wood": 6.3076923076923075, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.1282051282051282, "train_stats/max_log_achievement_eat_cow": 0.02564102564102564, "train_stats/max_log_achievement_make_wood_pickaxe": 1.0256410256410255, "train_stats/max_log_achievement_make_wood_sword": 0.02564102564102564, "train_stats/max_log_achievement_place_plant": 1.7692307692307692, "train_stats/max_log_achievement_place_stone": 2.5384615384615383, "train_stats/max_log_achievement_place_table": 2.230769230769231, "train_stats/max_log_achievement_wake_up": 2.0, "train_stats/mean_log_entropy": 0.35452603071163863, "eval_stats/sum_log_reward": 5.975000023841858, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 4.125, "eval_stats/max_log_achievement_collect_sapling": 1.25, "eval_stats/max_log_achievement_collect_stone": 3.0, "eval_stats/max_log_achievement_collect_wood": 7.375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.875, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 1.25, "eval_stats/max_log_achievement_place_stone": 1.875, "eval_stats/max_log_achievement_place_table": 2.25, "eval_stats/max_log_achievement_wake_up": 2.0, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 3.0986459023552015e-05, "report/cont_loss_std": 0.0007371031097136438, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0016238208627328277, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.1598440071102232e-05, "report/cont_pred": 0.9941288828849792, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 5.737971305847168, "report/dyn_loss_std": 8.001243591308594, "report/image_loss_mean": 3.84144926071167, "report/image_loss_std": 6.767515182495117, "report/model_loss_mean": 7.3245158195495605, "report/model_loss_std": 10.592937469482422, "report/post_ent_mag": 57.27552032470703, "report/post_ent_max": 57.27552032470703, "report/post_ent_mean": 37.69429016113281, "report/post_ent_min": 20.185867309570312, "report/post_ent_std": 6.258936405181885, "report/prior_ent_mag": 73.91693115234375, "report/prior_ent_max": 73.91693115234375, "report/prior_ent_mean": 43.45756149291992, "report/prior_ent_min": 27.420814514160156, "report/prior_ent_std": 7.688103199005127, "report/rep_loss_mean": 5.737971305847168, "report/rep_loss_std": 8.001243591308594, "report/reward_avg": 0.02431640587747097, "report/reward_loss_mean": 0.040252890437841415, "report/reward_loss_std": 0.1621643453836441, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.004072666168213, "report/reward_neg_acc": 0.9949647784233093, "report/reward_neg_loss": 0.020441466942429543, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6748575568199158, "report/reward_pred": 0.025170087814331055, "report/reward_rate": 0.0302734375, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.01441282220184803, "eval/cont_loss_std": 0.45803314447402954, "eval/cont_neg_acc": 0.6666666865348816, "eval/cont_neg_loss": 4.919244766235352, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 9.753994163475e-07, "eval/cont_pred": 0.9981339573860168, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 21.847389221191406, "eval/dyn_loss_std": 13.254837989807129, "eval/image_loss_mean": 29.634857177734375, "eval/image_loss_std": 31.829795837402344, "eval/model_loss_mean": 42.897117614746094, "eval/model_loss_std": 36.95439910888672, "eval/post_ent_mag": 58.775794982910156, "eval/post_ent_max": 58.775794982910156, "eval/post_ent_mean": 36.53015899658203, "eval/post_ent_min": 21.783079147338867, "eval/post_ent_std": 5.839391708374023, "eval/prior_ent_mag": 73.91693115234375, "eval/prior_ent_max": 73.91693115234375, "eval/prior_ent_mean": 49.95793151855469, "eval/prior_ent_min": 31.177589416503906, "eval/prior_ent_std": 7.844405174255371, "eval/rep_loss_mean": 21.847389221191406, "eval/rep_loss_std": 13.254837989807129, "eval/reward_avg": 0.02949218824505806, "eval/reward_loss_mean": 0.1394142210483551, "eval/reward_loss_std": 0.8739104270935059, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0056166648864746, "eval/reward_neg_acc": 0.9919273257255554, "eval/reward_neg_loss": 0.061459191143512726, "eval/reward_pos_acc": 0.7272726893424988, "eval/reward_pos_loss": 2.4804270267486572, "eval/reward_pred": 0.02147413231432438, "eval/reward_rate": 0.0322265625, "replay/size": 171973.0, "replay/inserts": 7748.0, "replay/samples": 30992.0, "replay/insert_wait_avg": 1.5599369448857265e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.415962514645916e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 35008.0, "eval_replay/inserts": 1928.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1789848201007764e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.493661880493164e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1038796901703, "timer/env.step_count": 968.0, "timer/env.step_total": 86.36800932884216, "timer/env.step_frac": 0.08635903837869198, "timer/env.step_avg": 0.0892231501331014, "timer/env.step_min": 0.023157358169555664, "timer/env.step_max": 2.059171438217163, "timer/replay._sample_count": 30992.0, "timer/replay._sample_total": 15.671860694885254, "timer/replay._sample_frac": 0.015670232875949205, "timer/replay._sample_avg": 0.0005056743900001695, "timer/replay._sample_min": 0.00038051605224609375, "timer/replay._sample_max": 0.03345656394958496, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1209.0, "timer/agent.policy_total": 19.264591693878174, "timer/agent.policy_frac": 0.01926259070192418, "timer/agent.policy_avg": 0.01593431901892322, "timer/agent.policy_min": 0.009606361389160156, "timer/agent.policy_max": 0.05736947059631348, "timer/dataset_train_count": 1937.0, "timer/dataset_train_total": 0.28736138343811035, "timer/dataset_train_frac": 0.00028733153552722363, "timer/dataset_train_avg": 0.00014835383760356755, "timer/dataset_train_min": 9.131431579589844e-05, "timer/dataset_train_max": 0.0007402896881103516, "timer/agent.train_count": 1937.0, "timer/agent.train_total": 862.2584209442139, "timer/agent.train_frac": 0.862168859110255, "timer/agent.train_avg": 0.4451514821601517, "timer/agent.train_min": 0.435089111328125, "timer/agent.train_max": 0.9537250995635986, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.472520112991333, "timer/agent.report_frac": 0.00047247103284682647, "timer/agent.report_avg": 0.2362600564956665, "timer/agent.report_min": 0.2285764217376709, "timer/agent.report_max": 0.2439436912536621, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.86102294921875e-05, "timer/dataset_eval_frac": 2.8607257779112785e-08, "timer/dataset_eval_avg": 2.86102294921875e-05, "timer/dataset_eval_min": 2.86102294921875e-05, "timer/dataset_eval_max": 2.86102294921875e-05, "fps": 7.747097125942705}
{"step": 172712, "time": 22373.72155380249, "episode/length": 315.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 172984, "time": 22406.931512117386, "episode/length": 260.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9731800766283525, "episode/intrinsic_return": 0.0}
{"step": 172992, "time": 22409.424929618835, "episode/length": 195.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 173088, "time": 22422.18950843811, "episode/length": 428.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9953379953379954, "episode/intrinsic_return": 0.0}
{"step": 173104, "time": 22425.641369104385, "episode/length": 158.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 173328, "time": 22453.22898387909, "episode/length": 168.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 173512, "time": 22476.08243870735, "episode/length": 179.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 173824, "time": 22514.271475076675, "episode/length": 104.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9904761904761905, "episode/intrinsic_return": 0.0}
{"step": 174192, "time": 22559.12320613861, "episode/length": 149.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 174192, "time": 22559.130724191666, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 174264, "time": 22570.661227941513, "episode/length": 146.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 174368, "time": 22584.227425336838, "episode/length": 317.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9968553459119497, "episode/intrinsic_return": 0.0}
{"step": 174448, "time": 22595.02462220192, "episode/length": 167.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 174808, "time": 22638.818321943283, "episode/length": 184.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 175368, "time": 22705.447336435318, "episode/length": 146.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 175464, "time": 22718.065847873688, "episode/length": 204.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 175640, "time": 22739.893244743347, "episode/length": 171.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 175984, "time": 22781.769010782242, "episode/length": 201.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 176000, "time": 22785.115087032318, "episode/length": 193.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 176040, "time": 22791.232981681824, "episode/length": 230.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 176440, "time": 22839.388435602188, "episode/length": 203.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 176568, "time": 22856.319622516632, "episode/length": 137.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9565217391304348, "episode/intrinsic_return": 0.0}
{"step": 176696, "time": 22872.707083940506, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 177208, "time": 22934.66811490059, "episode/length": 152.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9607843137254902, "episode/intrinsic_return": 0.0}
{"step": 177240, "time": 22939.865040302277, "episode/length": 465.0, "episode/score": 7.1000000312924385, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 177408, "time": 22960.903331279755, "episode/length": 220.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 177552, "time": 22979.05209994316, "episode/length": 188.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 177744, "time": 23003.015639066696, "episode/length": 217.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 178064, "time": 23042.252178907394, "episode/length": 202.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 178264, "time": 23067.156401634216, "episode/length": 195.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 178624, "time": 23110.860886096954, "episode/length": 176.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 178632, "time": 23113.211793899536, "episode/length": 173.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 178648, "time": 23116.658683776855, "episode/length": 259.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9961538461538462, "episode/intrinsic_return": 0.0}
{"step": 178768, "time": 23132.063591003418, "episode/length": 151.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 178904, "time": 23149.345537424088, "episode/length": 144.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 179192, "time": 23184.19754743576, "episode/length": 115.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9568965517241379, "episode/intrinsic_return": 0.0}
{"step": 179248, "time": 23192.206748485565, "episode/length": 59.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 179552, "time": 23228.908495426178, "episode/length": 185.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 179888, "time": 23269.925361394882, "episode/length": 156.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 179912, "time": 23274.233024597168, "episode/length": 160.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 179928, "time": 23277.71931695938, "episode/length": 314.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9936507936507937, "episode/intrinsic_return": 0.0}
{"step": 180024, "time": 23313.600119113922, "eval_episode/length": 148.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.959731543624161}
{"step": 180024, "time": 23315.47833585739, "eval_episode/length": 149.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9666666666666667}
{"step": 180024, "time": 23317.93340563774, "eval_episode/length": 160.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.968944099378882}
{"step": 180024, "time": 23320.189507484436, "eval_episode/length": 166.0, "eval_episode/score": 4.100000023841858, "eval_episode/reward_rate": 0.9940119760479041}
{"step": 180024, "time": 23323.198397397995, "eval_episode/length": 188.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9735449735449735}
{"step": 180024, "time": 23325.1839761734, "eval_episode/length": 191.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9947916666666666}
{"step": 180024, "time": 23328.21905183792, "eval_episode/length": 213.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9719626168224299}
{"step": 180024, "time": 23331.96023774147, "eval_episode/length": 37.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 180088, "time": 23339.48841881752, "episode/length": 179.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 180129, "time": 23346.49730014801, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.48146065117801, "train/action_min": 0.0, "train/action_std": 3.247309146751284, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.047000303201338384, "train/actor_opt_grad_steps": 43690.0, "train/actor_opt_loss": -10.742285859419999, "train/adv_mag": 0.5062907026076192, "train/adv_max": 0.458134354409123, "train/adv_mean": 0.0031908810968694877, "train/adv_min": -0.4272133776654748, "train/adv_std": 0.058491501684120185, "train/cont_avg": 0.9943400278141361, "train/cont_loss_mean": 0.0001775405413967339, "train/cont_loss_std": 0.005473259880345222, "train/cont_neg_acc": 0.9954333917008644, "train/cont_neg_loss": 0.02024420982156008, "train/cont_pos_acc": 0.9999794111201901, "train/cont_pos_loss": 6.206455835004055e-05, "train/cont_pred": 0.9943461053034398, "train/cont_rate": 0.9943400278141361, "train/dyn_loss_mean": 6.172682559927097, "train/dyn_loss_std": 8.601760369944946, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.2069881736296009, "train/extr_critic_critic_opt_grad_steps": 43690.0, "train/extr_critic_critic_opt_loss": 16530.9699361911, "train/extr_critic_mag": 7.420207433051464, "train/extr_critic_max": 7.420207433051464, "train/extr_critic_mean": 1.672580765804071, "train/extr_critic_min": -0.6581029898209098, "train/extr_critic_std": 1.7223525752571864, "train/extr_return_normed_mag": 1.56543309089401, "train/extr_return_normed_max": 1.56543309089401, "train/extr_return_normed_mean": 0.3620280989333597, "train/extr_return_normed_min": -0.13492813324116912, "train/extr_return_normed_std": 0.3290332116537693, "train/extr_return_rate": 0.65732169697422, "train/extr_return_raw_mag": 8.113854637944886, "train/extr_return_raw_max": 8.113854637944886, "train/extr_return_raw_mean": 1.689559108611801, "train/extr_return_raw_min": -0.9637777281057148, "train/extr_return_raw_std": 1.7568261448625495, "train/extr_reward_mag": 1.0216192487646771, "train/extr_reward_max": 1.0216192487646771, "train/extr_reward_mean": 0.03331749602001531, "train/extr_reward_min": -0.683362915253764, "train/extr_reward_std": 0.1818189758280809, "train/image_loss_mean": 4.034355840133747, "train/image_loss_std": 8.377345525781521, "train/model_loss_mean": 7.7831576257476005, "train/model_loss_std": 12.43996564255959, "train/model_opt_grad_norm": 49.05062412462736, "train/model_opt_grad_steps": 43650.1832460733, "train/model_opt_loss": 11162.533011391524, "train/model_opt_model_opt_grad_overflow": 0.005235602094240838, "train/model_opt_model_opt_grad_scale": 1420.1570680628272, "train/policy_entropy_mag": 2.446282100927143, "train/policy_entropy_max": 2.446282100927143, "train/policy_entropy_mean": 0.45522429977412, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.5573678036946901, "train/policy_logprob_mag": 7.438383971209301, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.4562079034238586, "train/policy_logprob_min": -7.438383971209301, "train/policy_logprob_std": 1.0506006460539334, "train/policy_randomness_mag": 0.8634302291570534, "train/policy_randomness_max": 0.8634302291570534, "train/policy_randomness_mean": 0.1606741993839204, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.19672637608350885, "train/post_ent_mag": 55.800643801065014, "train/post_ent_max": 55.800643801065014, "train/post_ent_mean": 37.21549053092277, "train/post_ent_min": 19.28552091808219, "train/post_ent_std": 6.242184212070485, "train/prior_ent_mag": 74.36224313306559, "train/prior_ent_max": 74.36224313306559, "train/prior_ent_mean": 43.355629646341214, "train/prior_ent_min": 24.5963899802163, "train/prior_ent_std": 8.323132749627398, "train/rep_loss_mean": 6.172682559927097, "train/rep_loss_std": 8.601760369944946, "train/reward_avg": 0.02494375796803317, "train/reward_loss_mean": 0.045014727577879166, "train/reward_loss_std": 0.20331222536676216, "train/reward_max_data": 1.0073298446795078, "train/reward_max_pred": 1.0076166809541394, "train/reward_neg_acc": 0.9957251885798589, "train/reward_neg_loss": 0.023178034710712458, "train/reward_pos_acc": 0.9845597450645807, "train/reward_pos_loss": 0.7537105695115334, "train/reward_pred": 0.024656394130857514, "train/reward_rate": 0.029961551047120418, "train_stats/sum_log_reward": 6.600000114667983, "train_stats/max_log_achievement_collect_coal": 0.16666666666666666, "train_stats/max_log_achievement_collect_drink": 2.6904761904761907, "train_stats/max_log_achievement_collect_sapling": 1.6428571428571428, "train_stats/max_log_achievement_collect_stone": 3.2142857142857144, "train_stats/max_log_achievement_collect_wood": 7.5476190476190474, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.047619047619047616, "train_stats/max_log_achievement_eat_cow": 0.11904761904761904, "train_stats/max_log_achievement_make_wood_pickaxe": 1.4523809523809523, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.5714285714285714, "train_stats/max_log_achievement_place_stone": 2.1666666666666665, "train_stats/max_log_achievement_place_table": 2.261904761904762, "train_stats/max_log_achievement_wake_up": 2.4761904761904763, "train_stats/mean_log_entropy": 0.4014375390751021, "eval_stats/sum_log_reward": 4.974999975413084, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 2.0, "eval_stats/max_log_achievement_collect_sapling": 1.625, "eval_stats/max_log_achievement_collect_stone": 4.25, "eval_stats/max_log_achievement_collect_wood": 4.125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.5, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 1.5, "eval_stats/max_log_achievement_place_stone": 3.375, "eval_stats/max_log_achievement_place_table": 1.375, "eval_stats/max_log_achievement_wake_up": 1.75, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 3.347185338498093e-05, "report/cont_loss_std": 0.0004640392435248941, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0027756812050938606, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.001645952987019e-05, "report/cont_pred": 0.9951108694076538, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 5.379593849182129, "report/dyn_loss_std": 7.931025505065918, "report/image_loss_mean": 3.6177406311035156, "report/image_loss_std": 6.541889190673828, "report/model_loss_mean": 6.871521949768066, "report/model_loss_std": 9.856217384338379, "report/post_ent_mag": 58.439414978027344, "report/post_ent_max": 58.439414978027344, "report/post_ent_mean": 38.32893753051758, "report/post_ent_min": 21.19643783569336, "report/post_ent_std": 6.992701530456543, "report/prior_ent_mag": 74.46209716796875, "report/prior_ent_max": 74.46209716796875, "report/prior_ent_mean": 43.697654724121094, "report/prior_ent_min": 22.607040405273438, "report/prior_ent_std": 8.680806159973145, "report/rep_loss_mean": 5.379593849182129, "report/rep_loss_std": 7.931025505065918, "report/reward_avg": 0.01416015625, "report/reward_loss_mean": 0.025991123169660568, "report/reward_loss_std": 0.12731631100177765, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.003758430480957, "report/reward_neg_acc": 0.998009979724884, "report/reward_neg_loss": 0.013705548830330372, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6758333444595337, "report/reward_pred": 0.01430024579167366, "report/reward_rate": 0.0185546875, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 1.5939400327624753e-05, "eval/cont_loss_std": 0.00018731961608864367, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0037968195974826813, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 8.54041900311131e-06, "eval/cont_pred": 0.9980457425117493, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 22.30316925048828, "eval/dyn_loss_std": 13.103318214416504, "eval/image_loss_mean": 29.446380615234375, "eval/image_loss_std": 31.26120376586914, "eval/model_loss_mean": 42.98508834838867, "eval/model_loss_std": 36.52657699584961, "eval/post_ent_mag": 56.409568786621094, "eval/post_ent_max": 56.409568786621094, "eval/post_ent_mean": 36.76227569580078, "eval/post_ent_min": 21.502758026123047, "eval/post_ent_std": 6.742958068847656, "eval/prior_ent_mag": 74.46209716796875, "eval/prior_ent_max": 74.46209716796875, "eval/prior_ent_mean": 49.9635009765625, "eval/prior_ent_min": 27.913204193115234, "eval/prior_ent_std": 8.132871627807617, "eval/rep_loss_mean": 22.30316925048828, "eval/rep_loss_std": 13.103318214416504, "eval/reward_avg": 0.02880859375, "eval/reward_loss_mean": 0.15679043531417847, "eval/reward_loss_std": 0.9340850114822388, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.003469705581665, "eval/reward_neg_acc": 0.9969727396965027, "eval/reward_neg_loss": 0.07542115449905396, "eval/reward_pos_acc": 0.7575757503509521, "eval/reward_pos_loss": 2.600334882736206, "eval/reward_pred": 0.02120724692940712, "eval/reward_rate": 0.0322265625, "replay/size": 179625.0, "replay/inserts": 7652.0, "replay/samples": 30608.0, "replay/insert_wait_avg": 1.5266329221431334e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.457435286861406e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 37024.0, "eval_replay/inserts": 2016.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.284101652720618e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0160732269287, "timer/env.step_count": 957.0, "timer/env.step_total": 89.88795208930969, "timer/env.step_frac": 0.08988650732307966, "timer/env.step_avg": 0.09392680469102371, "timer/env.step_min": 0.02288222312927246, "timer/env.step_max": 3.0946922302246094, "timer/replay._sample_count": 30608.0, "timer/replay._sample_total": 15.491764545440674, "timer/replay._sample_frac": 0.015491515546795821, "timer/replay._sample_avg": 0.0005061344924673509, "timer/replay._sample_min": 0.0003719329833984375, "timer/replay._sample_max": 0.011662721633911133, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1209.0, "timer/agent.policy_total": 19.63423204421997, "timer/agent.policy_frac": 0.01963391646382515, "timer/agent.policy_avg": 0.016240059589925533, "timer/agent.policy_min": 0.009831905364990234, "timer/agent.policy_max": 0.05567574501037598, "timer/dataset_train_count": 1913.0, "timer/dataset_train_total": 0.27784204483032227, "timer/dataset_train_frac": 0.0002778375790838643, "timer/dataset_train_avg": 0.00014523891522755998, "timer/dataset_train_min": 8.916854858398438e-05, "timer/dataset_train_max": 0.0007860660552978516, "timer/agent.train_count": 1913.0, "timer/agent.train_total": 850.2867314815521, "timer/agent.train_frac": 0.8502730648496294, "timer/agent.train_avg": 0.4444781659600377, "timer/agent.train_min": 0.4338114261627197, "timer/agent.train_max": 1.1288738250732422, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4741556644439697, "timer/agent.report_frac": 0.0004741480433548711, "timer/agent.report_avg": 0.23707783222198486, "timer/agent.report_min": 0.22980093955993652, "timer/agent.report_max": 0.2443547248840332, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7418136596679688e-05, "timer/dataset_eval_frac": 2.741769590583153e-08, "timer/dataset_eval_avg": 2.7418136596679688e-05, "timer/dataset_eval_min": 2.7418136596679688e-05, "timer/dataset_eval_max": 2.7418136596679688e-05, "fps": 7.6517684677736}
{"step": 180240, "time": 23360.502200126648, "episode/length": 166.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 180368, "time": 23376.845092773438, "episode/length": 146.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9591836734693877, "episode/intrinsic_return": 0.0}
{"step": 180528, "time": 23396.95675802231, "episode/length": 54.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 180656, "time": 23413.270723342896, "episode/length": 175.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 180744, "time": 23424.935453891754, "episode/length": 148.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9731543624161074, "episode/intrinsic_return": 0.0}
{"step": 181288, "time": 23489.641491413116, "episode/length": 169.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 181288, "time": 23489.6506588459, "episode/length": 171.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 181360, "time": 23501.2705013752, "episode/length": 183.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 181592, "time": 23529.70254302025, "episode/length": 168.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 181640, "time": 23536.782247543335, "episode/length": 158.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 181832, "time": 23560.666338205338, "episode/length": 58.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 182016, "time": 23583.636449098587, "episode/length": 169.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 182152, "time": 23601.192419290543, "episode/length": 175.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 182208, "time": 23609.20618700981, "episode/length": 209.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 182720, "time": 23670.63881802559, "episode/length": 178.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 182848, "time": 23687.757456064224, "episode/length": 150.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9536423841059603, "episode/intrinsic_return": 0.0}
{"step": 182888, "time": 23693.997609615326, "episode/length": 161.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 182928, "time": 23700.158502817154, "episode/length": 204.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 183216, "time": 23735.22079539299, "episode/length": 172.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 183424, "time": 23760.971849679947, "episode/length": 175.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 183512, "time": 23772.85838985443, "episode/length": 169.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 183624, "time": 23787.348845481873, "episode/length": 91.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9456521739130435, "episode/intrinsic_return": 0.0}
{"step": 183648, "time": 23791.729774475098, "episode/length": 179.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 184168, "time": 23853.830072641373, "episode/length": 180.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 184496, "time": 23894.250101089478, "episode/length": 205.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9660194174757282, "episode/intrinsic_return": 0.0}
{"step": 184632, "time": 23911.52301120758, "episode/length": 212.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9859154929577465, "episode/intrinsic_return": 0.0}
{"step": 184696, "time": 23920.578327417374, "episode/length": 158.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9622641509433962, "episode/intrinsic_return": 0.0}
{"step": 184944, "time": 23950.938754320145, "episode/length": 161.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 185400, "time": 24005.321464538574, "episode/length": 153.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 185432, "time": 24010.6571495533, "episode/length": 225.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 185776, "time": 24052.303040266037, "episode/length": 282.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9717314487632509, "episode/intrinsic_return": 0.0}
{"step": 186080, "time": 24089.342767715454, "episode/length": 180.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 186312, "time": 24118.554175376892, "episode/length": 226.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9823788546255506, "episode/intrinsic_return": 0.0}
{"step": 186376, "time": 24127.5378780365, "episode/length": 209.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.0}
{"step": 186408, "time": 24132.849903821945, "episode/length": 398.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9949874686716792, "episode/intrinsic_return": 0.0}
{"step": 186688, "time": 24167.221473693848, "episode/length": 217.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 186848, "time": 24187.54973602295, "episode/length": 180.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.988950276243094, "episode/intrinsic_return": 0.0}
{"step": 187000, "time": 24206.736667394638, "episode/length": 195.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9846938775510204, "episode/intrinsic_return": 0.0}
{"step": 187304, "time": 24243.752342939377, "episode/length": 190.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9685863874345549, "episode/intrinsic_return": 0.0}
{"step": 187384, "time": 24254.640228509903, "episode/length": 162.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 187624, "time": 24284.247282266617, "episode/length": 151.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 187768, "time": 24302.602175951004, "episode/length": 173.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 187776, "time": 24305.010330438614, "episode/length": 182.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 188113, "time": 24346.810838222504, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.479084264093907, "train/action_min": 0.0, "train/action_std": 3.1832580782061246, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04685483631401805, "train/actor_opt_grad_steps": 45640.0, "train/actor_opt_loss": -12.842504661637896, "train/adv_mag": 0.5280267534843043, "train/adv_max": 0.48336738857192607, "train/adv_mean": 0.0021327833664186277, "train/adv_min": -0.4399673302269461, "train/adv_std": 0.058273807205447004, "train/cont_avg": 0.9945430276381909, "train/cont_loss_mean": 7.011799304027751e-05, "train/cont_loss_std": 0.001935609827684752, "train/cont_neg_acc": 0.9981574544954539, "train/cont_neg_loss": 0.00744022318272827, "train/cont_pos_acc": 0.9999999841253961, "train/cont_pos_loss": 2.086252717580334e-05, "train/cont_pred": 0.9945480544962476, "train/cont_rate": 0.9945430276381909, "train/dyn_loss_mean": 6.175808362625352, "train/dyn_loss_std": 8.625908616799206, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.2048378808414517, "train/extr_critic_critic_opt_grad_steps": 45640.0, "train/extr_critic_critic_opt_loss": 16710.082507262876, "train/extr_critic_mag": 7.394209969582869, "train/extr_critic_max": 7.394209969582869, "train/extr_critic_mean": 1.604056066304595, "train/extr_critic_min": -0.6646390769948911, "train/extr_critic_std": 1.7065554390001536, "train/extr_return_normed_mag": 1.5616911673665645, "train/extr_return_normed_max": 1.5616911673665645, "train/extr_return_normed_mean": 0.34638581234007026, "train/extr_return_normed_min": -0.13124336178728085, "train/extr_return_normed_std": 0.32507670165306357, "train/extr_return_rate": 0.639127310196958, "train/extr_return_raw_mag": 8.11283220597847, "train/extr_return_raw_max": 8.11283220597847, "train/extr_return_raw_mean": 1.6154724611109825, "train/extr_return_raw_min": -0.9388102643453895, "train/extr_return_raw_std": 1.738644362694055, "train/extr_reward_mag": 1.0181030304587666, "train/extr_reward_max": 1.0181030304587666, "train/extr_reward_mean": 0.03316299908387302, "train/extr_reward_min": -0.6891156345156569, "train/extr_reward_std": 0.1817751680337005, "train/image_loss_mean": 4.006538711001525, "train/image_loss_std": 8.594035062358607, "train/model_loss_mean": 7.7563215739762965, "train/model_loss_std": 12.627535987738987, "train/model_opt_grad_norm": 46.02093963047967, "train/model_opt_grad_steps": 45598.4472361809, "train/model_opt_loss": 10982.055195410647, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1407.035175879397, "train/policy_entropy_mag": 2.432285700611134, "train/policy_entropy_max": 2.432285700611134, "train/policy_entropy_mean": 0.44861489669162424, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.551680142705764, "train/policy_logprob_mag": 7.438383996187143, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.4483318295910131, "train/policy_logprob_min": -7.438383996187143, "train/policy_logprob_std": 1.0429871534582358, "train/policy_randomness_mag": 0.8584901136369562, "train/policy_randomness_max": 0.8584901136369562, "train/policy_randomness_mean": 0.15834137175849933, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.19471888116855718, "train/post_ent_mag": 56.30017413805478, "train/post_ent_max": 56.30017413805478, "train/post_ent_mean": 37.760236653850306, "train/post_ent_min": 19.05097241138094, "train/post_ent_std": 6.413246859258144, "train/prior_ent_mag": 74.53581260796169, "train/prior_ent_max": 74.53581260796169, "train/prior_ent_mean": 43.89326634239312, "train/prior_ent_min": 24.836046774782726, "train/prior_ent_std": 8.238557640631594, "train/rep_loss_mean": 6.175808362625352, "train/rep_loss_std": 8.625908616799206, "train/reward_avg": 0.024689364602705044, "train/reward_loss_mean": 0.044227713372689395, "train/reward_loss_std": 0.20210591628773128, "train/reward_max_data": 1.0065326648740913, "train/reward_max_pred": 1.0073917756727593, "train/reward_neg_acc": 0.9953677723156148, "train/reward_neg_loss": 0.022589005534560537, "train/reward_pos_acc": 0.9843286530456351, "train/reward_pos_loss": 0.7555897137028488, "train/reward_pred": 0.02439004907749556, "train/reward_rate": 0.029606038002512564, "train_stats/sum_log_reward": 6.727907080983007, "train_stats/max_log_achievement_collect_coal": 0.09302325581395349, "train_stats/max_log_achievement_collect_drink": 3.302325581395349, "train_stats/max_log_achievement_collect_sapling": 1.6744186046511629, "train_stats/max_log_achievement_collect_stone": 3.6511627906976742, "train_stats/max_log_achievement_collect_wood": 8.534883720930232, "train_stats/max_log_achievement_defeat_skeleton": 0.023255813953488372, "train_stats/max_log_achievement_defeat_zombie": 0.046511627906976744, "train_stats/max_log_achievement_eat_cow": 0.046511627906976744, "train_stats/max_log_achievement_make_wood_pickaxe": 1.2093023255813953, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.5813953488372092, "train_stats/max_log_achievement_place_stone": 2.5813953488372094, "train_stats/max_log_achievement_place_table": 2.372093023255814, "train_stats/max_log_achievement_wake_up": 2.0, "train_stats/mean_log_entropy": 0.3457168163948281, "report/cont_avg": 0.9912109375, "report/cont_loss_mean": 3.951970938942395e-06, "report/cont_loss_std": 5.2400504500837997e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0001796634605852887, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.3939378479553852e-06, "report/cont_pred": 0.9912102222442627, "report/cont_rate": 0.9912109375, "report/dyn_loss_mean": 7.39614725112915, "report/dyn_loss_std": 9.510124206542969, "report/image_loss_mean": 4.823837757110596, "report/image_loss_std": 8.155613899230957, "report/model_loss_mean": 9.33903980255127, "report/model_loss_std": 12.256617546081543, "report/post_ent_mag": 57.40685272216797, "report/post_ent_max": 57.40685272216797, "report/post_ent_mean": 38.33244323730469, "report/post_ent_min": 19.81633758544922, "report/post_ent_std": 6.861783027648926, "report/prior_ent_mag": 74.68488311767578, "report/prior_ent_max": 74.68488311767578, "report/prior_ent_mean": 45.349727630615234, "report/prior_ent_min": 23.565427780151367, "report/prior_ent_std": 8.406106948852539, "report/rep_loss_mean": 7.39614725112915, "report/rep_loss_std": 9.510124206542969, "report/reward_avg": 0.04111327975988388, "report/reward_loss_mean": 0.0775100588798523, "report/reward_loss_std": 0.37940293550491333, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.005354642868042, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.029072659090161324, "report/reward_pos_acc": 0.9399999976158142, "report/reward_pos_loss": 1.0210707187652588, "report/reward_pred": 0.03757501393556595, "report/reward_rate": 0.048828125, "eval/cont_avg": 0.9921875, "eval/cont_loss_mean": 0.0014616439584642649, "eval/cont_loss_std": 0.04504336416721344, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.006809899117797613, "eval/cont_pos_acc": 0.999015748500824, "eval/cont_pos_loss": 0.0014195316471159458, "eval/cont_pred": 0.9914941191673279, "eval/cont_rate": 0.9921875, "eval/dyn_loss_mean": 20.331348419189453, "eval/dyn_loss_std": 13.448758125305176, "eval/image_loss_mean": 22.195823669433594, "eval/image_loss_std": 26.913034439086914, "eval/model_loss_mean": 34.56155776977539, "eval/model_loss_std": 32.26225662231445, "eval/post_ent_mag": 56.211387634277344, "eval/post_ent_max": 56.211387634277344, "eval/post_ent_mean": 37.60597229003906, "eval/post_ent_min": 20.631460189819336, "eval/post_ent_std": 6.810201168060303, "eval/prior_ent_mag": 74.68488311767578, "eval/prior_ent_max": 74.68488311767578, "eval/prior_ent_mean": 49.71657180786133, "eval/prior_ent_min": 31.1446590423584, "eval/prior_ent_std": 9.048188209533691, "eval/rep_loss_mean": 20.331348419189453, "eval/rep_loss_std": 13.448758125305176, "eval/reward_avg": 0.01689453050494194, "eval/reward_loss_mean": 0.16546526551246643, "eval/reward_loss_std": 0.9933299422264099, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.002918004989624, "eval/reward_neg_acc": 0.9979979991912842, "eval/reward_neg_loss": 0.10053227841854095, "eval/reward_pos_acc": 0.7199999690055847, "eval/reward_pos_loss": 2.760187864303589, "eval/reward_pred": 0.011697942391037941, "eval/reward_rate": 0.0244140625, "replay/size": 187609.0, "replay/inserts": 7984.0, "replay/samples": 31936.0, "replay/insert_wait_avg": 1.573222194740433e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.414372865566032e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 37024.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 8.195638656616211e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3027029037476, "timer/env.step_count": 998.0, "timer/env.step_total": 92.17429113388062, "timer/env.step_frac": 0.09214639815159024, "timer/env.step_avg": 0.09235900915218498, "timer/env.step_min": 0.023229360580444336, "timer/env.step_max": 3.233452320098877, "timer/replay._sample_count": 31936.0, "timer/replay._sample_total": 16.18748641014099, "timer/replay._sample_frac": 0.01618258789379539, "timer/replay._sample_avg": 0.0005068726957083227, "timer/replay._sample_min": 0.00036263465881347656, "timer/replay._sample_max": 0.010764360427856445, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 998.0, "timer/agent.policy_total": 16.0274600982666, "timer/agent.policy_frac": 0.01602261000769166, "timer/agent.policy_avg": 0.01605957925678016, "timer/agent.policy_min": 0.009834051132202148, "timer/agent.policy_max": 0.05414700508117676, "timer/dataset_train_count": 1996.0, "timer/dataset_train_total": 0.29544878005981445, "timer/dataset_train_frac": 0.0002953593739196799, "timer/dataset_train_avg": 0.0001480204308916906, "timer/dataset_train_min": 8.916854858398438e-05, "timer/dataset_train_max": 0.005321502685546875, "timer/agent.train_count": 1996.0, "timer/agent.train_total": 888.7690501213074, "timer/agent.train_frac": 0.8885000985614928, "timer/agent.train_avg": 0.44527507521107584, "timer/agent.train_min": 0.4333038330078125, "timer/agent.train_max": 0.9551792144775391, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47109436988830566, "timer/agent.report_frac": 0.00047095181140746747, "timer/agent.report_avg": 0.23554718494415283, "timer/agent.report_min": 0.22961926460266113, "timer/agent.report_max": 0.24147510528564453, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.6464462280273438e-05, "timer/dataset_eval_frac": 2.6456453834874756e-08, "timer/dataset_eval_avg": 2.6464462280273438e-05, "timer/dataset_eval_min": 2.6464462280273438e-05, "timer/dataset_eval_max": 2.6464462280273438e-05, "fps": 7.981478338214757}
{"step": 188408, "time": 24381.072074890137, "episode/length": 194.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 188472, "time": 24391.8286550045, "episode/length": 222.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 188592, "time": 24407.388947725296, "episode/length": 198.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.0}
{"step": 188792, "time": 24432.099543094635, "episode/length": 175.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9602272727272727, "episode/intrinsic_return": 0.0}
{"step": 188952, "time": 24452.061535835266, "episode/length": 165.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 188952, "time": 24452.068974733353, "episode/length": 205.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 189144, "time": 24477.721297979355, "episode/length": 170.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 189496, "time": 24520.21752333641, "episode/length": 215.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 189720, "time": 24547.72705435753, "episode/length": 155.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 189832, "time": 24562.341124534607, "episode/length": 177.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 189904, "time": 24572.224411010742, "episode/length": 118.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.957983193277311, "episode/intrinsic_return": 0.0}
{"step": 190008, "time": 24604.805693387985, "eval_episode/length": 146.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9931972789115646}
{"step": 190008, "time": 24607.177173376083, "eval_episode/length": 153.0, "eval_episode/score": 6.099999964237213, "eval_episode/reward_rate": 0.974025974025974}
{"step": 190008, "time": 24609.97400689125, "eval_episode/length": 169.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 190008, "time": 24612.68448829651, "eval_episode/length": 183.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9782608695652174}
{"step": 190008, "time": 24615.197331428528, "eval_episode/length": 195.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9948979591836735}
{"step": 190008, "time": 24617.79981970787, "eval_episode/length": 211.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9669811320754716}
{"step": 190008, "time": 24620.83097076416, "eval_episode/length": 233.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9786324786324786}
{"step": 190008, "time": 24625.518361091614, "eval_episode/length": 299.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9966666666666667}
{"step": 190048, "time": 24630.161143302917, "episode/length": 156.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 190208, "time": 24650.70411300659, "episode/length": 201.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 190696, "time": 24709.951102733612, "episode/length": 217.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 190896, "time": 24734.841914653778, "episode/length": 174.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 191016, "time": 24750.22269845009, "episode/length": 161.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 191312, "time": 24786.168107032776, "episode/length": 270.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.996309963099631, "episode/intrinsic_return": 0.0}
{"step": 191544, "time": 24814.686818361282, "episode/length": 166.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 191616, "time": 24825.291578769684, "episode/length": 195.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 191920, "time": 24862.32898569107, "episode/length": 251.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9801587301587301, "episode/intrinsic_return": 0.0}
{"step": 192048, "time": 24878.8067548275, "episode/length": 168.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 192248, "time": 24903.993379592896, "episode/length": 301.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9867549668874173, "episode/intrinsic_return": 0.0}
{"step": 192400, "time": 24923.30899310112, "episode/length": 172.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 192416, "time": 24926.732101917267, "episode/length": 45.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 192632, "time": 24953.295098781586, "episode/length": 164.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 192840, "time": 24979.075819969177, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 193472, "time": 25054.837846517563, "episode/length": 193.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 193664, "time": 25079.093195676804, "episode/length": 157.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 193808, "time": 25097.364722251892, "episode/length": 273.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9781021897810219, "episode/intrinsic_return": 0.0}
{"step": 193832, "time": 25101.60355758667, "episode/length": 366.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9836512261580381, "episode/intrinsic_return": 0.0}
{"step": 193880, "time": 25108.686665058136, "episode/length": 155.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 193928, "time": 25115.777470588684, "episode/length": 209.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 194248, "time": 25154.676986694336, "episode/length": 228.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.982532751091703, "episode/intrinsic_return": 0.0}
{"step": 194696, "time": 25208.394114255905, "episode/length": 231.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 194816, "time": 25223.883216381073, "episode/length": 143.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 195040, "time": 25251.460339784622, "episode/length": 150.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 195064, "time": 25255.692042589188, "episode/length": 198.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 195072, "time": 25258.10458111763, "episode/length": 148.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 195224, "time": 25277.24196767807, "episode/length": 50.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 195480, "time": 25308.81387734413, "episode/length": 208.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 195624, "time": 25327.158906698227, "episode/length": 211.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 195773, "time": 25346.938640594482, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.461434046427409, "train/action_min": 0.0, "train/action_std": 3.1891381653646627, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04740680150765305, "train/actor_opt_grad_steps": 47595.0, "train/actor_opt_loss": -12.298509824400147, "train/adv_mag": 0.514170404834052, "train/adv_max": 0.47242275237416226, "train/adv_mean": 0.0027512889087404346, "train/adv_min": -0.42753624621157843, "train/adv_std": 0.058537043805699795, "train/cont_avg": 0.994354248046875, "train/cont_loss_mean": 0.00024270619480937228, "train/cont_loss_std": 0.007377271446120659, "train/cont_neg_acc": 0.9932829048484564, "train/cont_neg_loss": 0.0366002136423352, "train/cont_pos_acc": 0.9999897371356686, "train/cont_pos_loss": 4.36882321300421e-05, "train/cont_pred": 0.994377737864852, "train/cont_rate": 0.994354248046875, "train/dyn_loss_mean": 6.172135134538014, "train/dyn_loss_std": 8.651342170933882, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.172208107697467, "train/extr_critic_critic_opt_grad_steps": 47595.0, "train/extr_critic_critic_opt_loss": 16565.709365844727, "train/extr_critic_mag": 7.418844235440095, "train/extr_critic_max": 7.418844235440095, "train/extr_critic_mean": 1.62985394988209, "train/extr_critic_min": -0.670539683351914, "train/extr_critic_std": 1.7315130829811096, "train/extr_return_normed_mag": 1.569572106624643, "train/extr_return_normed_max": 1.569572106624643, "train/extr_return_normed_mean": 0.3541996676164369, "train/extr_return_normed_min": -0.13526433849862465, "train/extr_return_normed_std": 0.33022237444917363, "train/extr_return_rate": 0.6416131259563068, "train/extr_return_raw_mag": 8.144665869573751, "train/extr_return_raw_max": 8.144665869573751, "train/extr_return_raw_mean": 1.6445787868772943, "train/extr_return_raw_min": -0.9725000451629361, "train/extr_return_raw_std": 1.766126827026407, "train/extr_reward_mag": 1.0175033584237099, "train/extr_reward_max": 1.0175033584237099, "train/extr_reward_mean": 0.034066213915745415, "train/extr_reward_min": -0.6773809610555569, "train/extr_reward_std": 0.1845829722005874, "train/image_loss_mean": 3.96924007187287, "train/image_loss_std": 8.582675762474537, "train/model_loss_mean": 7.717627229789893, "train/model_loss_std": 12.62776700903972, "train/model_opt_grad_norm": 47.91848157842954, "train/model_opt_grad_steps": 47551.708333333336, "train/model_opt_loss": 11092.743860880533, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1438.8020833333333, "train/policy_entropy_mag": 2.4436413484315076, "train/policy_entropy_max": 2.4436413484315076, "train/policy_entropy_mean": 0.44656452847023803, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.5521823327677945, "train/policy_logprob_mag": 7.438383994003137, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.44616719397405785, "train/policy_logprob_min": -7.438383994003137, "train/policy_logprob_std": 1.0410901413609583, "train/policy_randomness_mag": 0.8624981607620915, "train/policy_randomness_max": 0.8624981607620915, "train/policy_randomness_mean": 0.15761768146573255, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.1948961328404645, "train/post_ent_mag": 56.585402051607765, "train/post_ent_max": 56.585402051607765, "train/post_ent_mean": 38.11806627114614, "train/post_ent_min": 19.19813100496928, "train/post_ent_std": 6.475991060336431, "train/prior_ent_mag": 74.69201918443044, "train/prior_ent_max": 74.69201918443044, "train/prior_ent_mean": 44.286565045515694, "train/prior_ent_min": 24.75175577402115, "train/prior_ent_std": 8.249528107543787, "train/rep_loss_mean": 6.172135134538014, "train/rep_loss_std": 8.651342170933882, "train/reward_avg": 0.025747171821421944, "train/reward_loss_mean": 0.0448633336830729, "train/reward_loss_std": 0.19772505977501473, "train/reward_max_data": 1.0067708349476259, "train/reward_max_pred": 1.007848720997572, "train/reward_neg_acc": 0.9957450094322363, "train/reward_neg_loss": 0.022510185520028852, "train/reward_pos_acc": 0.9845320551345745, "train/reward_pos_loss": 0.7490779686098298, "train/reward_pred": 0.02544387614276881, "train/reward_rate": 0.030812581380208332, "train_stats/sum_log_reward": 6.587804922243444, "train_stats/max_log_achievement_collect_coal": 0.1951219512195122, "train_stats/max_log_achievement_collect_drink": 2.8536585365853657, "train_stats/max_log_achievement_collect_sapling": 1.6829268292682926, "train_stats/max_log_achievement_collect_stone": 5.2682926829268295, "train_stats/max_log_achievement_collect_wood": 6.682926829268292, "train_stats/max_log_achievement_defeat_skeleton": 0.07317073170731707, "train_stats/max_log_achievement_defeat_zombie": 0.07317073170731707, "train_stats/max_log_achievement_eat_cow": 0.07317073170731707, "train_stats/max_log_achievement_make_wood_pickaxe": 1.1219512195121952, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.6341463414634145, "train_stats/max_log_achievement_place_stone": 3.926829268292683, "train_stats/max_log_achievement_place_table": 2.073170731707317, "train_stats/max_log_achievement_wake_up": 2.0, "train_stats/mean_log_entropy": 0.3818067352219326, "eval_stats/sum_log_reward": 6.350000023841858, "eval_stats/max_log_achievement_collect_coal": 0.25, "eval_stats/max_log_achievement_collect_drink": 1.75, "eval_stats/max_log_achievement_collect_sapling": 1.375, "eval_stats/max_log_achievement_collect_stone": 5.125, "eval_stats/max_log_achievement_collect_wood": 7.0, "eval_stats/max_log_achievement_defeat_skeleton": 0.125, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.125, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 1.25, "eval_stats/max_log_achievement_place_stone": 2.75, "eval_stats/max_log_achievement_place_table": 1.875, "eval_stats/max_log_achievement_wake_up": 2.125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 1.360518581350334e-06, "report/cont_loss_std": 7.172151526901871e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 6.38110504951328e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 1.1156145092172665e-06, "report/cont_pred": 0.9960929155349731, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 6.438388347625732, "report/dyn_loss_std": 8.954863548278809, "report/image_loss_mean": 3.3901336193084717, "report/image_loss_std": 8.870746612548828, "report/model_loss_mean": 7.296053886413574, "report/model_loss_std": 13.272259712219238, "report/post_ent_mag": 53.568721771240234, "report/post_ent_max": 53.568721771240234, "report/post_ent_mean": 37.46797180175781, "report/post_ent_min": 20.04346466064453, "report/post_ent_std": 5.851649761199951, "report/prior_ent_mag": 75.22952270507812, "report/prior_ent_max": 75.22952270507812, "report/prior_ent_mean": 44.20936584472656, "report/prior_ent_min": 25.233989715576172, "report/prior_ent_std": 7.685248851776123, "report/rep_loss_mean": 6.438388347625732, "report/rep_loss_std": 8.954863548278809, "report/reward_avg": 0.03291015699505806, "report/reward_loss_mean": 0.042886145412921906, "report/reward_loss_std": 0.1945800632238388, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0029418468475342, "report/reward_neg_acc": 0.9979715943336487, "report/reward_neg_loss": 0.015883784741163254, "report/reward_pos_acc": 0.9736841917037964, "report/reward_pos_loss": 0.7435262799263, "report/reward_pred": 0.03203097730875015, "report/reward_rate": 0.037109375, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 9.140515430772211e-06, "eval/cont_loss_std": 0.00024824641877785325, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.002690910827368498, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.2606816426341538e-06, "eval/cont_pred": 0.9970769286155701, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 21.879894256591797, "eval/dyn_loss_std": 12.829876899719238, "eval/image_loss_mean": 25.68765640258789, "eval/image_loss_std": 25.564502716064453, "eval/model_loss_mean": 38.978240966796875, "eval/model_loss_std": 31.0107479095459, "eval/post_ent_mag": 56.229801177978516, "eval/post_ent_max": 56.229801177978516, "eval/post_ent_mean": 37.148460388183594, "eval/post_ent_min": 20.637794494628906, "eval/post_ent_std": 5.81760835647583, "eval/prior_ent_mag": 75.22952270507812, "eval/prior_ent_max": 75.22952270507812, "eval/prior_ent_mean": 50.291404724121094, "eval/prior_ent_min": 27.949153900146484, "eval/prior_ent_std": 7.511617660522461, "eval/rep_loss_mean": 21.879894256591797, "eval/rep_loss_std": 12.829876899719238, "eval/reward_avg": 0.02568359300494194, "eval/reward_loss_mean": 0.1626376509666443, "eval/reward_loss_std": 0.9966782331466675, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.002411127090454, "eval/reward_neg_acc": 0.9939637184143066, "eval/reward_neg_loss": 0.08096902072429657, "eval/reward_pos_acc": 0.7000000476837158, "eval/reward_pos_loss": 2.86859130859375, "eval/reward_pred": 0.018293112516403198, "eval/reward_rate": 0.029296875, "replay/size": 195269.0, "replay/inserts": 7660.0, "replay/samples": 30640.0, "replay/insert_wait_avg": 1.5505922681046528e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.515632141352322e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 39424.0, "eval_replay/inserts": 2400.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2507041295369467e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.493661880493164e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1125919818878, "timer/env.step_count": 957.0, "timer/env.step_total": 89.17886781692505, "timer/env.step_frac": 0.08916882812184419, "timer/env.step_avg": 0.09318585978780047, "timer/env.step_min": 0.023675918579101562, "timer/env.step_max": 3.2856359481811523, "timer/replay._sample_count": 30640.0, "timer/replay._sample_total": 15.656967163085938, "timer/replay._sample_frac": 0.015655204512583006, "timer/replay._sample_avg": 0.0005109976228161206, "timer/replay._sample_min": 0.0003902912139892578, "timer/replay._sample_max": 0.028998851776123047, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1257.0, "timer/agent.policy_total": 20.5189049243927, "timer/agent.policy_frac": 0.020516594920309033, "timer/agent.policy_avg": 0.016323711157034765, "timer/agent.policy_min": 0.009848833084106445, "timer/agent.policy_max": 0.10771989822387695, "timer/dataset_train_count": 1915.0, "timer/dataset_train_total": 0.2788219451904297, "timer/dataset_train_frac": 0.00027879055560924205, "timer/dataset_train_avg": 0.00014559892699239147, "timer/dataset_train_min": 8.821487426757812e-05, "timer/dataset_train_max": 0.0012280941009521484, "timer/agent.train_count": 1915.0, "timer/agent.train_total": 852.6773083209991, "timer/agent.train_frac": 0.852581314501079, "timer/agent.train_avg": 0.4452623019952998, "timer/agent.train_min": 0.43247294425964355, "timer/agent.train_max": 0.9890797138214111, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47286105155944824, "timer/agent.report_frac": 0.0004728078171902587, "timer/agent.report_avg": 0.23643052577972412, "timer/agent.report_min": 0.22982001304626465, "timer/agent.report_max": 0.2430410385131836, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7179718017578125e-05, "timer/dataset_eval_frac": 2.717665814377663e-08, "timer/dataset_eval_avg": 2.7179718017578125e-05, "timer/dataset_eval_min": 2.7179718017578125e-05, "timer/dataset_eval_max": 2.7179718017578125e-05, "fps": 7.659036514102457}
{"step": 196088, "time": 25383.56992840767, "episode/length": 57.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9137931034482759, "episode/intrinsic_return": 0.0}
{"step": 196088, "time": 25383.57794737816, "episode/length": 229.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9695652173913043, "episode/intrinsic_return": 0.0}
{"step": 196352, "time": 25417.60014486313, "episode/length": 163.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 196432, "time": 25429.073620796204, "episode/length": 150.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9602649006622517, "episode/intrinsic_return": 0.0}
{"step": 196736, "time": 25467.12242913246, "episode/length": 254.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 196840, "time": 25481.40266108513, "episode/length": 221.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9684684684684685, "episode/intrinsic_return": 0.0}
{"step": 196912, "time": 25491.24968123436, "episode/length": 178.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 196992, "time": 25501.894767045975, "episode/length": 239.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 197672, "time": 25582.647294044495, "episode/length": 197.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 197904, "time": 25611.15695977211, "episode/length": 226.0, "episode/score": 8.099999956786633, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 198112, "time": 25636.96021747589, "episode/length": 219.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9681818181818181, "episode/intrinsic_return": 0.0}
{"step": 198136, "time": 25641.268122196198, "episode/length": 57.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9137931034482759, "episode/intrinsic_return": 0.0}
{"step": 198184, "time": 25648.44636130333, "episode/length": 218.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 198272, "time": 25660.903530836105, "episode/length": 169.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 198632, "time": 25704.308217525482, "episode/length": 236.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 198808, "time": 25726.33944940567, "episode/length": 226.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9779735682819384, "episode/intrinsic_return": 0.0}
{"step": 199176, "time": 25770.59871864319, "episode/length": 158.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9622641509433962, "episode/intrinsic_return": 0.0}
{"step": 199424, "time": 25800.806702136993, "episode/length": 160.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 199576, "time": 25820.000468730927, "episode/length": 173.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 199616, "time": 25826.157829999924, "episode/length": 346.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9740634005763689, "episode/intrinsic_return": 0.0}
{"step": 199976, "time": 25869.66423225403, "episode/length": 167.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 200056, "time": 25880.559359312057, "episode/length": 155.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 200096, "time": 25907.512088775635, "eval_episode/length": 170.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9766081871345029}
{"step": 200096, "time": 25909.15709376335, "eval_episode/length": 173.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9712643678160919}
{"step": 200096, "time": 25911.047444820404, "eval_episode/length": 185.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.978494623655914}
{"step": 200096, "time": 25912.589824438095, "eval_episode/length": 187.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.973404255319149}
{"step": 200096, "time": 25914.261961460114, "eval_episode/length": 189.0, "eval_episode/score": 9.099999994039536, "eval_episode/reward_rate": 0.9947368421052631}
{"step": 200096, "time": 25915.957425117493, "eval_episode/length": 192.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9948186528497409}
{"step": 200096, "time": 25918.254103183746, "eval_episode/length": 39.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.875}
{"step": 200096, "time": 25920.637278079987, "eval_episode/length": 232.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9785407725321889}
{"step": 200168, "time": 25928.970684051514, "episode/length": 256.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9727626459143969, "episode/intrinsic_return": 0.0}
{"step": 200320, "time": 25948.137909650803, "episode/length": 255.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.98046875, "episode/intrinsic_return": 0.0}
{"step": 200632, "time": 25985.966479301453, "episode/length": 181.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 200912, "time": 26019.878353595734, "episode/length": 185.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9623655913978495, "episode/intrinsic_return": 0.0}
{"step": 201064, "time": 26039.047722816467, "episode/length": 185.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 201176, "time": 26053.554626703262, "episode/length": 194.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 201328, "time": 26072.67420744896, "episode/length": 168.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 201400, "time": 26082.603312253952, "episode/length": 167.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 201472, "time": 26092.395093917847, "episode/length": 162.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 201712, "time": 26121.763908147812, "episode/length": 173.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 202240, "time": 26184.387571811676, "episode/length": 200.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 202280, "time": 26190.61151242256, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 202536, "time": 26221.863530874252, "episode/length": 183.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 202584, "time": 26229.374225139618, "episode/length": 156.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 202728, "time": 26247.869338035583, "episode/length": 165.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.963855421686747, "episode/intrinsic_return": 0.0}
{"step": 202864, "time": 26265.151797533035, "episode/length": 40.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9024390243902439, "episode/intrinsic_return": 0.0}
{"step": 202936, "time": 26275.0049328804, "episode/length": 182.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 203528, "time": 26345.243042230606, "episode/length": 117.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9661016949152542, "episode/intrinsic_return": 0.0}
{"step": 203529, "time": 26347.830223083496, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.451424195594394, "train/action_min": 0.0, "train/action_std": 3.0931189723850525, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0476445890579027, "train/actor_opt_grad_steps": 49525.0, "train/actor_opt_loss": -11.02747715037969, "train/adv_mag": 0.5136674713228166, "train/adv_max": 0.4807553890439653, "train/adv_mean": 0.0029199362968976164, "train/adv_min": -0.4217875317199943, "train/adv_std": 0.058844654484815205, "train/cont_avg": 0.9944225193298969, "train/cont_loss_mean": 0.00015094222429775777, "train/cont_loss_std": 0.0045018797791893115, "train/cont_neg_acc": 0.9962874337569955, "train/cont_neg_loss": 0.01265099760905624, "train/cont_pos_acc": 0.999989870590033, "train/cont_pos_loss": 6.442074346991081e-05, "train/cont_pred": 0.9944373658022929, "train/cont_rate": 0.9944225193298969, "train/dyn_loss_mean": 6.265848848008618, "train/dyn_loss_std": 8.671722210559649, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1856362085366987, "train/extr_critic_critic_opt_grad_steps": 49525.0, "train/extr_critic_critic_opt_loss": 16635.434711259666, "train/extr_critic_mag": 7.513030782188337, "train/extr_critic_max": 7.513030782188337, "train/extr_critic_mean": 1.6590291605782264, "train/extr_critic_min": -0.657483287693299, "train/extr_critic_std": 1.7681717688275367, "train/extr_return_normed_mag": 1.5755908802612542, "train/extr_return_normed_max": 1.5755908802612542, "train/extr_return_normed_mean": 0.3532225530325752, "train/extr_return_normed_min": -0.12902447612015241, "train/extr_return_normed_std": 0.3317718584973788, "train/extr_return_rate": 0.6370453118663473, "train/extr_return_raw_mag": 8.318380884288512, "train/extr_return_raw_max": 8.318380884288512, "train/extr_return_raw_mean": 1.6748982465144284, "train/extr_return_raw_min": -0.9461646328881844, "train/extr_return_raw_std": 1.8033217443633325, "train/extr_reward_mag": 1.0216600858059126, "train/extr_reward_max": 1.0216600858059126, "train/extr_reward_mean": 0.03412353018894024, "train/extr_reward_min": -0.6772054120437386, "train/extr_reward_std": 0.18427318833845177, "train/image_loss_mean": 4.03638887036707, "train/image_loss_std": 8.7008492971204, "train/model_loss_mean": 7.842102861896004, "train/model_loss_std": 12.783607669712342, "train/model_opt_grad_norm": 44.0384446370233, "train/model_opt_grad_steps": 49480.28350515464, "train/model_opt_loss": 12749.545188667847, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1617.2680412371135, "train/policy_entropy_mag": 2.457704932419295, "train/policy_entropy_max": 2.457704932419295, "train/policy_entropy_mean": 0.4338743548417829, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.5357719410940543, "train/policy_logprob_mag": 7.438383957774369, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.43405639234277393, "train/policy_logprob_min": -7.438383957774369, "train/policy_logprob_std": 1.0325864513510281, "train/policy_randomness_mag": 0.8674619867629612, "train/policy_randomness_max": 0.8674619867629612, "train/policy_randomness_mean": 0.15313860704911123, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.1891039853397104, "train/post_ent_mag": 56.94823408618416, "train/post_ent_max": 56.94823408618416, "train/post_ent_mean": 38.42181050408747, "train/post_ent_min": 19.300054732057237, "train/post_ent_std": 6.524406607618037, "train/prior_ent_mag": 74.6692075827687, "train/prior_ent_max": 74.6692075827687, "train/prior_ent_mean": 44.653607319310765, "train/prior_ent_min": 25.297723514517557, "train/prior_ent_std": 8.236073112979378, "train/rep_loss_mean": 6.265848848008618, "train/rep_loss_std": 8.671722210559649, "train/reward_avg": 0.026396886882439408, "train/reward_loss_mean": 0.0460537769975736, "train/reward_loss_std": 0.20789014025754535, "train/reward_max_data": 1.010824744848861, "train/reward_max_pred": 1.0119031759881483, "train/reward_neg_acc": 0.9955569087844534, "train/reward_neg_loss": 0.022902720936660452, "train/reward_pos_acc": 0.9817548999466847, "train/reward_pos_loss": 0.7629091057580771, "train/reward_pred": 0.02599852663685673, "train/reward_rate": 0.03134060889175258, "train_stats/sum_log_reward": 6.575000065565109, "train_stats/max_log_achievement_collect_coal": 0.1, "train_stats/max_log_achievement_collect_drink": 4.2, "train_stats/max_log_achievement_collect_sapling": 1.575, "train_stats/max_log_achievement_collect_stone": 4.1, "train_stats/max_log_achievement_collect_wood": 6.275, "train_stats/max_log_achievement_defeat_skeleton": 0.025, "train_stats/max_log_achievement_defeat_zombie": 0.075, "train_stats/max_log_achievement_eat_cow": 0.075, "train_stats/max_log_achievement_make_wood_pickaxe": 0.975, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.5, "train_stats/max_log_achievement_place_stone": 3.05, "train_stats/max_log_achievement_place_table": 1.825, "train_stats/max_log_achievement_wake_up": 1.675, "train_stats/mean_log_entropy": 0.3545255057513714, "eval_stats/sum_log_reward": 6.475000217556953, "eval_stats/max_log_achievement_collect_coal": 0.125, "eval_stats/max_log_achievement_collect_drink": 2.125, "eval_stats/max_log_achievement_collect_sapling": 2.125, "eval_stats/max_log_achievement_collect_stone": 6.0, "eval_stats/max_log_achievement_collect_wood": 5.375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.125, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.0, "eval_stats/max_log_achievement_make_wood_sword": 0.125, "eval_stats/max_log_achievement_place_plant": 2.125, "eval_stats/max_log_achievement_place_stone": 5.0, "eval_stats/max_log_achievement_place_table": 1.5, "eval_stats/max_log_achievement_wake_up": 1.375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 3.3069600249291398e-06, "report/cont_loss_std": 3.7905756471445784e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0003375444211997092, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.3369950693231658e-06, "report/cont_pred": 0.9941412806510925, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 6.231339454650879, "report/dyn_loss_std": 8.155488014221191, "report/image_loss_mean": 4.441840171813965, "report/image_loss_std": 11.046159744262695, "report/model_loss_mean": 8.231616020202637, "report/model_loss_std": 14.396428108215332, "report/post_ent_mag": 57.938133239746094, "report/post_ent_max": 57.938133239746094, "report/post_ent_mean": 38.9482536315918, "report/post_ent_min": 20.188919067382812, "report/post_ent_std": 6.704781532287598, "report/prior_ent_mag": 74.62869262695312, "report/prior_ent_max": 74.62869262695312, "report/prior_ent_mean": 45.50065612792969, "report/prior_ent_min": 27.26299476623535, "report/prior_ent_std": 8.212162971496582, "report/rep_loss_mean": 6.231339454650879, "report/rep_loss_std": 8.155488014221191, "report/reward_avg": 0.03691406175494194, "report/reward_loss_mean": 0.05096881091594696, "report/reward_loss_std": 0.1903708279132843, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.00199556350708, "report/reward_neg_acc": 0.9959225058555603, "report/reward_neg_loss": 0.02356569841504097, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6761420369148254, "report/reward_pred": 0.03698212280869484, "report/reward_rate": 0.0419921875, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.0001350324891973287, "eval/cont_loss_std": 0.00314605375751853, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.02213498018682003, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 5.366818186303135e-06, "eval/cont_pred": 0.9942601919174194, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 21.869138717651367, "eval/dyn_loss_std": 13.09345817565918, "eval/image_loss_mean": 27.549238204956055, "eval/image_loss_std": 34.23127365112305, "eval/model_loss_mean": 40.82614517211914, "eval/model_loss_std": 38.82720184326172, "eval/post_ent_mag": 56.67809295654297, "eval/post_ent_max": 56.67809295654297, "eval/post_ent_mean": 36.55249786376953, "eval/post_ent_min": 22.80168914794922, "eval/post_ent_std": 6.002208709716797, "eval/prior_ent_mag": 74.62869262695312, "eval/prior_ent_max": 74.62869262695312, "eval/prior_ent_mean": 49.17705154418945, "eval/prior_ent_min": 30.922271728515625, "eval/prior_ent_std": 7.7467498779296875, "eval/rep_loss_mean": 21.869138717651367, "eval/rep_loss_std": 13.09345817565918, "eval/reward_avg": 0.03330077975988388, "eval/reward_loss_mean": 0.15528905391693115, "eval/reward_loss_std": 0.8901784420013428, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0017104148864746, "eval/reward_neg_acc": 0.9969543218612671, "eval/reward_neg_loss": 0.057223621755838394, "eval/reward_pos_acc": 0.6666666865348816, "eval/reward_pos_loss": 2.6320698261260986, "eval/reward_pred": 0.023126117885112762, "eval/reward_rate": 0.0380859375, "replay/size": 203025.0, "replay/inserts": 7756.0, "replay/samples": 31024.0, "replay/insert_wait_avg": 1.5839957403976811e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.43674764687281e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 41288.0, "eval_replay/inserts": 1864.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.196313825288044e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.046627044677734e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.8785727024078, "timer/env.step_count": 970.0, "timer/env.step_total": 87.7927873134613, "timer/env.step_frac": 0.08771572267394799, "timer/env.step_avg": 0.09050802815820753, "timer/env.step_min": 0.023107290267944336, "timer/env.step_max": 3.1920979022979736, "timer/replay._sample_count": 31024.0, "timer/replay._sample_total": 15.691833019256592, "timer/replay._sample_frac": 0.015678058704851762, "timer/replay._sample_avg": 0.0005057965774644337, "timer/replay._sample_min": 0.0003771781921386719, "timer/replay._sample_max": 0.02962517738342285, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1203.0, "timer/agent.policy_total": 20.523783445358276, "timer/agent.policy_frac": 0.0205057676376699, "timer/agent.policy_avg": 0.017060501617089174, "timer/agent.policy_min": 0.009427070617675781, "timer/agent.policy_max": 0.1298215389251709, "timer/dataset_train_count": 1939.0, "timer/dataset_train_total": 0.2931180000305176, "timer/dataset_train_frac": 0.00029286070061335063, "timer/dataset_train_avg": 0.00015116967510599153, "timer/dataset_train_min": 9.012222290039062e-05, "timer/dataset_train_max": 0.00124359130859375, "timer/agent.train_count": 1939.0, "timer/agent.train_total": 860.3195207118988, "timer/agent.train_frac": 0.8595643309547585, "timer/agent.train_avg": 0.44369237788133, "timer/agent.train_min": 0.4332289695739746, "timer/agent.train_max": 0.9670889377593994, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4756021499633789, "timer/agent.report_frac": 0.0004751846656875031, "timer/agent.report_avg": 0.23780107498168945, "timer/agent.report_min": 0.23008012771606445, "timer/agent.report_max": 0.24552202224731445, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9087066650390625e-05, "timer/dataset_eval_frac": 2.9061533979945747e-08, "timer/dataset_eval_avg": 2.9087066650390625e-05, "timer/dataset_eval_min": 2.9087066650390625e-05, "timer/dataset_eval_max": 2.9087066650390625e-05, "fps": 7.749084605842235}
{"step": 203560, "time": 26351.348251104355, "episode/length": 159.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9625, "episode/intrinsic_return": 0.0}
{"step": 203872, "time": 26388.988429307938, "episode/length": 116.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9914529914529915, "episode/intrinsic_return": 0.0}
{"step": 203920, "time": 26396.061753988266, "episode/length": 44.0, "episode/score": 2.0999999940395355, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 204120, "time": 26421.015238523483, "episode/length": 173.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 204160, "time": 26427.12435722351, "episode/length": 239.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9708333333333333, "episode/intrinsic_return": 0.0}
{"step": 204928, "time": 26518.995112895966, "episode/length": 468.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.997867803837953, "episode/intrinsic_return": 0.0}
{"step": 205064, "time": 26536.320680618286, "episode/length": 191.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 205400, "time": 26577.004737615585, "episode/length": 159.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.98125, "episode/intrinsic_return": 0.0}
{"step": 205416, "time": 26580.34024500847, "episode/length": 156.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 205432, "time": 26583.73000407219, "episode/length": 320.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9906542056074766, "episode/intrinsic_return": 0.0}
{"step": 205456, "time": 26588.147869348526, "episode/length": 467.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9978632478632479, "episode/intrinsic_return": 0.0}
{"step": 205688, "time": 26616.56619620323, "episode/length": 226.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.973568281938326, "episode/intrinsic_return": 0.0}
{"step": 205768, "time": 26627.458793878555, "episode/length": 230.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9826839826839827, "episode/intrinsic_return": 0.0}
{"step": 206400, "time": 26702.179806232452, "episode/length": 166.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9640718562874252, "episode/intrinsic_return": 0.0}
{"step": 206432, "time": 26707.36005783081, "episode/length": 121.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9918032786885246, "episode/intrinsic_return": 0.0}
{"step": 206456, "time": 26711.612763643265, "episode/length": 190.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 206824, "time": 26755.860968589783, "episode/length": 173.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 207008, "time": 26779.293204784393, "episode/length": 154.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 207016, "time": 26781.767599582672, "episode/length": 199.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 207208, "time": 26805.68916463852, "episode/length": 47.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.8958333333333334, "episode/intrinsic_return": 0.0}
{"step": 207216, "time": 26808.13257575035, "episode/length": 190.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 207328, "time": 26822.60380935669, "episode/length": 240.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.975103734439834, "episode/intrinsic_return": 0.0}
{"step": 207768, "time": 26875.04637503624, "episode/length": 163.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 207776, "time": 26877.437151432037, "episode/length": 171.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9651162790697675, "episode/intrinsic_return": 0.0}
{"step": 208160, "time": 26923.411660194397, "episode/length": 215.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9907407407407407, "episode/intrinsic_return": 0.0}
{"step": 208168, "time": 26925.817401885986, "episode/length": 144.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9724137931034482, "episode/intrinsic_return": 0.0}
{"step": 208488, "time": 26964.296345949173, "episode/length": 183.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 208864, "time": 27009.408534288406, "episode/length": 205.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 208864, "time": 27009.429990530014, "episode/length": 206.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 208864, "time": 27009.44135451317, "episode/length": 191.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 208872, "time": 27015.548411130905, "episode/length": 137.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9637681159420289, "episode/intrinsic_return": 0.0}
{"step": 209400, "time": 27078.447229862213, "episode/length": 154.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 209464, "time": 27087.331923007965, "episode/length": 161.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 209568, "time": 27101.04549050331, "episode/length": 86.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9885057471264368, "episode/intrinsic_return": 0.0}
{"step": 209808, "time": 27130.44207715988, "episode/length": 164.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 210000, "time": 27154.136126995087, "episode/length": 53.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9074074074074074, "episode/intrinsic_return": 0.0}
{"step": 210080, "time": 27179.105405330658, "eval_episode/length": 43.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9772727272727273}
{"step": 210080, "time": 27180.673615455627, "eval_episode/length": 46.0, "eval_episode/score": 3.100000001490116, "eval_episode/reward_rate": 0.9787234042553191}
{"step": 210080, "time": 27186.471708536148, "eval_episode/length": 151.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.993421052631579}
{"step": 210080, "time": 27188.56547999382, "eval_episode/length": 163.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9939024390243902}
{"step": 210080, "time": 27190.31586241722, "eval_episode/length": 167.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9940476190476191}
{"step": 210080, "time": 27194.146939754486, "eval_episode/length": 222.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9775784753363229}
{"step": 210080, "time": 27195.81245326996, "eval_episode/length": 180.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9723756906077348}
{"step": 210080, "time": 27197.51119351387, "eval_episode/length": 233.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9957264957264957}
{"step": 210168, "time": 27207.644083976746, "episode/length": 162.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 210432, "time": 27239.72865962982, "episode/length": 195.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9693877551020408, "episode/intrinsic_return": 0.0}
{"step": 210496, "time": 27248.730974435806, "episode/length": 203.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 210912, "time": 27298.646632671356, "episode/length": 188.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 211313, "time": 27348.068511724472, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.487610807123873, "train/action_min": 0.0, "train/action_std": 3.172516930963575, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04617759579619796, "train/actor_opt_grad_steps": 51465.0, "train/actor_opt_loss": -10.861926053530661, "train/adv_mag": 0.4920126216620514, "train/adv_max": 0.4703967454507179, "train/adv_mean": 0.003170735941201895, "train/adv_min": -0.39713713764837105, "train/adv_std": 0.05789765905704081, "train/cont_avg": 0.9945685003221649, "train/cont_loss_mean": 0.0001329105437570581, "train/cont_loss_std": 0.003991064746690699, "train/cont_neg_acc": 0.9951460484376887, "train/cont_neg_loss": 0.015471691393969129, "train/cont_pos_acc": 0.9999898635235029, "train/cont_pos_loss": 6.0331979634947566e-05, "train/cont_pred": 0.9945600929948473, "train/cont_rate": 0.9945685003221649, "train/dyn_loss_mean": 6.272210067080469, "train/dyn_loss_std": 8.610468957842011, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.213052333937478, "train/extr_critic_critic_opt_grad_steps": 51465.0, "train/extr_critic_critic_opt_loss": 16797.436150934278, "train/extr_critic_mag": 7.70397833942138, "train/extr_critic_max": 7.70397833942138, "train/extr_critic_mean": 1.6734611600944675, "train/extr_critic_min": -0.6550407778356493, "train/extr_critic_std": 1.8106773194578505, "train/extr_return_normed_mag": 1.5704786931116557, "train/extr_return_normed_max": 1.5704786931116557, "train/extr_return_normed_mean": 0.346822572046334, "train/extr_return_normed_min": -0.12924095592701557, "train/extr_return_normed_std": 0.3307092516999884, "train/extr_return_rate": 0.632995765080157, "train/extr_return_raw_mag": 8.517141494554343, "train/extr_return_raw_max": 8.517141494554343, "train/extr_return_raw_mean": 1.6911467479676316, "train/extr_return_raw_min": -0.9644466233007687, "train/extr_return_raw_std": 1.8447430508652913, "train/extr_reward_mag": 1.0216751860589097, "train/extr_reward_max": 1.0216751860589097, "train/extr_reward_mean": 0.03577133065531241, "train/extr_reward_min": -0.6784614453610686, "train/extr_reward_std": 0.1877912851338534, "train/image_loss_mean": 4.138748851019082, "train/image_loss_std": 8.74222342009397, "train/model_loss_mean": 7.947556154015138, "train/model_loss_std": 12.728830199880699, "train/model_opt_grad_norm": 47.522072408617156, "train/model_opt_grad_steps": 51418.67525773196, "train/model_opt_loss": 11233.088925076514, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1423.9690721649486, "train/policy_entropy_mag": 2.4696302389361193, "train/policy_entropy_max": 2.4696302389361193, "train/policy_entropy_mean": 0.4483231673228372, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.5612432306882033, "train/policy_logprob_mag": 7.438383997101145, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.44850611287293973, "train/policy_logprob_min": -7.438383997101145, "train/policy_logprob_std": 1.0449700229561205, "train/policy_randomness_mag": 0.8716710977947589, "train/policy_randomness_max": 0.8716710977947589, "train/policy_randomness_mean": 0.15823840499692357, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.19809423210387378, "train/post_ent_mag": 57.141766931592805, "train/post_ent_max": 57.141766931592805, "train/post_ent_mean": 38.92310901523865, "train/post_ent_min": 19.700052821759098, "train/post_ent_std": 6.520194456749356, "train/prior_ent_mag": 74.83080043989358, "train/prior_ent_max": 74.83080043989358, "train/prior_ent_mean": 45.161595609999196, "train/prior_ent_min": 25.68189396809057, "train/prior_ent_std": 8.061010284522146, "train/rep_loss_mean": 6.272210067080469, "train/rep_loss_std": 8.610468957842011, "train/reward_avg": 0.026127577212053475, "train/reward_loss_mean": 0.04534840379294354, "train/reward_loss_std": 0.20086979032638147, "train/reward_max_data": 1.0087628886871731, "train/reward_max_pred": 1.0087236307330967, "train/reward_neg_acc": 0.9953854228417898, "train/reward_neg_loss": 0.022725346486189776, "train/reward_pos_acc": 0.9842073726899845, "train/reward_pos_loss": 0.751154504485966, "train/reward_pred": 0.025817235823739897, "train/reward_rate": 0.031134221971649483, "train_stats/sum_log_reward": 6.900000023841858, "train_stats/max_log_achievement_collect_coal": 0.2, "train_stats/max_log_achievement_collect_drink": 3.225, "train_stats/max_log_achievement_collect_sapling": 1.5, "train_stats/max_log_achievement_collect_stone": 5.675, "train_stats/max_log_achievement_collect_wood": 7.15, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.075, "train_stats/max_log_achievement_eat_cow": 0.15, "train_stats/max_log_achievement_make_wood_pickaxe": 1.375, "train_stats/max_log_achievement_make_wood_sword": 0.025, "train_stats/max_log_achievement_place_plant": 1.45, "train_stats/max_log_achievement_place_stone": 4.6, "train_stats/max_log_achievement_place_table": 2.2, "train_stats/max_log_achievement_wake_up": 1.875, "train_stats/mean_log_entropy": 0.34416517838835714, "eval_stats/sum_log_reward": 5.85000005364418, "eval_stats/max_log_achievement_collect_coal": 0.125, "eval_stats/max_log_achievement_collect_drink": 2.375, "eval_stats/max_log_achievement_collect_sapling": 2.25, "eval_stats/max_log_achievement_collect_stone": 4.25, "eval_stats/max_log_achievement_collect_wood": 4.25, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.875, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.25, "eval_stats/max_log_achievement_place_stone": 2.0, "eval_stats/max_log_achievement_place_table": 1.375, "eval_stats/max_log_achievement_wake_up": 1.375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 3.330938795897964e-07, "report/cont_loss_std": 5.46094952369458e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 8.027614239836112e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 1.95917433387649e-08, "report/cont_pred": 0.9960940480232239, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 7.485739231109619, "report/dyn_loss_std": 8.59539794921875, "report/image_loss_mean": 3.171454429626465, "report/image_loss_std": 6.5715413093566895, "report/model_loss_mean": 7.716081619262695, "report/model_loss_std": 10.574114799499512, "report/post_ent_mag": 56.40338134765625, "report/post_ent_max": 56.40338134765625, "report/post_ent_mean": 37.487083435058594, "report/post_ent_min": 19.298593521118164, "report/post_ent_std": 5.99548864364624, "report/prior_ent_mag": 75.43630981445312, "report/prior_ent_max": 75.43630981445312, "report/prior_ent_mean": 45.594276428222656, "report/prior_ent_min": 24.31639862060547, "report/prior_ent_std": 8.066300392150879, "report/rep_loss_mean": 7.485739231109619, "report/rep_loss_std": 8.59539794921875, "report/reward_avg": 0.04082031175494194, "report/reward_loss_mean": 0.053183622658252716, "report/reward_loss_std": 0.20020271837711334, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.0260257720947266, "report/reward_neg_acc": 0.9979549646377563, "report/reward_neg_loss": 0.01985502615571022, "report/reward_pos_acc": 0.97826087474823, "report/reward_pos_loss": 0.7617784738540649, "report/reward_pred": 0.039121244102716446, "report/reward_rate": 0.044921875, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 1.8688485852180747e-06, "eval/cont_loss_std": 3.7073492421768606e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0004762844764627516, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 8.39525071683056e-09, "eval/cont_pred": 0.9960956573486328, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 21.001537322998047, "eval/dyn_loss_std": 13.669628143310547, "eval/image_loss_mean": 22.992528915405273, "eval/image_loss_std": 26.40294075012207, "eval/model_loss_mean": 35.73627471923828, "eval/model_loss_std": 31.695240020751953, "eval/post_ent_mag": 56.5283203125, "eval/post_ent_max": 56.5283203125, "eval/post_ent_mean": 37.066429138183594, "eval/post_ent_min": 18.0048828125, "eval/post_ent_std": 6.373147487640381, "eval/prior_ent_mag": 75.43630981445312, "eval/prior_ent_max": 75.43630981445312, "eval/prior_ent_mean": 50.68331527709961, "eval/prior_ent_min": 33.39666748046875, "eval/prior_ent_std": 7.658426284790039, "eval/rep_loss_mean": 21.001537322998047, "eval/rep_loss_std": 13.669628143310547, "eval/reward_avg": 0.02675781399011612, "eval/reward_loss_mean": 0.14282065629959106, "eval/reward_loss_std": 0.863684356212616, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0023224353790283, "eval/reward_neg_acc": 0.9909182786941528, "eval/reward_neg_loss": 0.09091878682374954, "eval/reward_pos_acc": 0.8484848141670227, "eval/reward_pos_loss": 1.7014496326446533, "eval/reward_pred": 0.027923766523599625, "eval/reward_rate": 0.0322265625, "replay/size": 210809.0, "replay/inserts": 7784.0, "replay/samples": 31136.0, "replay/insert_wait_avg": 1.5347124003677916e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.374849618400112e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 43160.0, "eval_replay/inserts": 1872.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1221720622136043e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.748603820800781e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2228577136993, "timer/env.step_count": 973.0, "timer/env.step_total": 86.8829083442688, "timer/env.step_frac": 0.08686355013208255, "timer/env.step_avg": 0.0892938420804407, "timer/env.step_min": 0.02302074432373047, "timer/env.step_max": 5.208736181259155, "timer/replay._sample_count": 31136.0, "timer/replay._sample_total": 15.346276760101318, "timer/replay._sample_frac": 0.015342857485960383, "timer/replay._sample_avg": 0.0004928788784719077, "timer/replay._sample_min": 0.00035953521728515625, "timer/replay._sample_max": 0.010717391967773438, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1207.0, "timer/agent.policy_total": 18.971089601516724, "timer/agent.policy_frac": 0.018966862689861613, "timer/agent.policy_avg": 0.015717555593634403, "timer/agent.policy_min": 0.009305953979492188, "timer/agent.policy_max": 0.062204837799072266, "timer/dataset_train_count": 1946.0, "timer/dataset_train_total": 0.2929558753967285, "timer/dataset_train_frac": 0.0002928906024666988, "timer/dataset_train_avg": 0.0001505425875625532, "timer/dataset_train_min": 9.322166442871094e-05, "timer/dataset_train_max": 0.000667572021484375, "timer/agent.train_count": 1946.0, "timer/agent.train_total": 862.2857506275177, "timer/agent.train_frac": 0.8620936264129405, "timer/agent.train_avg": 0.44310675777364733, "timer/agent.train_min": 0.43243885040283203, "timer/agent.train_max": 0.9744858741760254, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4757213592529297, "timer/agent.report_frac": 0.0004756153647001523, "timer/agent.report_avg": 0.23786067962646484, "timer/agent.report_min": 0.23149371147155762, "timer/agent.report_max": 0.24422764778137207, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7894973754882812e-05, "timer/dataset_eval_frac": 2.788875852991892e-08, "timer/dataset_eval_avg": 2.7894973754882812e-05, "timer/dataset_eval_min": 2.7894973754882812e-05, "timer/dataset_eval_max": 2.7894973754882812e-05, "fps": 7.78215382802865}
{"step": 211336, "time": 27350.65313768387, "episode/length": 166.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 211352, "time": 27353.927979707718, "episode/length": 446.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9798657718120806, "episode/intrinsic_return": 0.0}
{"step": 211664, "time": 27392.011766672134, "episode/length": 231.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 211904, "time": 27421.62665939331, "episode/length": 183.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 212192, "time": 27456.77133321762, "episode/length": 159.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 212192, "time": 27456.781809329987, "episode/length": 252.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9802371541501976, "episode/intrinsic_return": 0.0}
{"step": 212288, "time": 27471.22666501999, "episode/length": 223.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 212512, "time": 27498.68648290634, "episode/length": 146.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 212520, "time": 27501.185183286667, "episode/length": 145.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.0}
{"step": 212760, "time": 27530.556601047516, "episode/length": 411.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9927184466019418, "episode/intrinsic_return": 0.0}
{"step": 212816, "time": 27538.517187595367, "episode/length": 143.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9652777777777778, "episode/intrinsic_return": 0.0}
{"step": 213248, "time": 27591.544149160385, "episode/length": 167.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 213576, "time": 27631.16476583481, "episode/length": 172.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 213680, "time": 27644.89730167389, "episode/length": 173.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 213776, "time": 27657.645599126816, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 213776, "time": 27657.653558254242, "episode/length": 197.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 213904, "time": 27675.83522963524, "episode/length": 172.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 214184, "time": 27709.81465625763, "episode/length": 170.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 214224, "time": 27715.94608926773, "episode/length": 55.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 214400, "time": 27738.137939929962, "episode/length": 102.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9611650485436893, "episode/intrinsic_return": 0.0}
{"step": 214584, "time": 27761.84999036789, "episode/length": 166.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 214712, "time": 27778.206042289734, "episode/length": 65.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9393939393939394, "episode/intrinsic_return": 0.0}
{"step": 215064, "time": 27820.865057468414, "episode/length": 287.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9965277777777778, "episode/intrinsic_return": 0.0}
{"step": 215072, "time": 27823.271322965622, "episode/length": 173.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 215344, "time": 27856.42332959175, "episode/length": 195.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 215488, "time": 27874.743908405304, "episode/length": 135.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.0}
{"step": 215520, "time": 27879.921340465546, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 215632, "time": 27894.427543878555, "episode/length": 215.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 216408, "time": 27986.02087211609, "episode/length": 227.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 216568, "time": 28006.432252407074, "episode/length": 187.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 216600, "time": 28011.60849046707, "episode/length": 156.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 216648, "time": 28018.546145677567, "episode/length": 196.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9695431472081218, "episode/intrinsic_return": 0.0}
{"step": 216848, "time": 28043.271560192108, "episode/length": 266.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9812734082397003, "episode/intrinsic_return": 0.0}
{"step": 216920, "time": 28053.234603881836, "episode/length": 174.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 216944, "time": 28058.07382416725, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 217040, "time": 28071.39380288124, "episode/length": 78.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9367088607594937, "episode/intrinsic_return": 0.0}
{"step": 217104, "time": 28080.206900835037, "episode/length": 183.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 217432, "time": 28119.67749786377, "episode/length": 107.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9444444444444444, "episode/intrinsic_return": 0.0}
{"step": 217624, "time": 28143.446894407272, "episode/length": 127.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 217896, "time": 28176.333676815033, "episode/length": 155.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9551282051282052, "episode/intrinsic_return": 0.0}
{"step": 218120, "time": 28203.976003408432, "episode/length": 158.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 218256, "time": 28221.362230300903, "episode/length": 143.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 218504, "time": 28251.782965660095, "episode/length": 197.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 218528, "time": 28256.037214279175, "episode/length": 50.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 218736, "time": 28281.657679080963, "episode/length": 223.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 219048, "time": 28319.47545313835, "episode/length": 201.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 219120, "time": 28329.27547931671, "episode/length": 186.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 219261, "time": 28348.076756954193, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.611058834210113, "train/action_min": 0.0, "train/action_std": 3.226200531475508, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.045776404505923164, "train/actor_opt_grad_steps": 53430.0, "train/actor_opt_loss": -12.371747041785687, "train/adv_mag": 0.4878301542607983, "train/adv_max": 0.4580927873077105, "train/adv_mean": 0.0023628634212491764, "train/adv_min": -0.4128021774579532, "train/adv_std": 0.05688427201467543, "train/cont_avg": 0.9943565483668342, "train/cont_loss_mean": 0.00014105391880988734, "train/cont_loss_std": 0.004376945526269482, "train/cont_neg_acc": 0.9971240183921776, "train/cont_neg_loss": 0.009286248443482012, "train/cont_pos_acc": 0.9999654457796758, "train/cont_pos_loss": 8.324139452393609e-05, "train/cont_pred": 0.9943421024772989, "train/cont_rate": 0.9943565483668342, "train/dyn_loss_mean": 6.192438266984182, "train/dyn_loss_std": 8.64008430020893, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1800763622001187, "train/extr_critic_critic_opt_grad_steps": 53430.0, "train/extr_critic_critic_opt_loss": 16700.543125785174, "train/extr_critic_mag": 7.666973147560005, "train/extr_critic_max": 7.666973147560005, "train/extr_critic_mean": 1.6777688058177431, "train/extr_critic_min": -0.6752273659011228, "train/extr_critic_std": 1.8222568406531559, "train/extr_return_normed_mag": 1.560675180138056, "train/extr_return_normed_max": 1.560675180138056, "train/extr_return_normed_mean": 0.34541323002259333, "train/extr_return_normed_min": -0.1301325722480539, "train/extr_return_normed_std": 0.33206783414785584, "train/extr_return_rate": 0.6257361339863821, "train/extr_return_raw_mag": 8.476332096598256, "train/extr_return_raw_max": 8.476332096598256, "train/extr_return_raw_mean": 1.6909518529422318, "train/extr_return_raw_min": -0.9645503984024776, "train/extr_return_raw_std": 1.8542966662938871, "train/extr_reward_mag": 1.0206462402439596, "train/extr_reward_max": 1.0206462402439596, "train/extr_reward_mean": 0.035478387505340214, "train/extr_reward_min": -0.6921429987528815, "train/extr_reward_std": 0.187849623324284, "train/image_loss_mean": 3.8180749655967983, "train/image_loss_std": 8.149087683040293, "train/model_loss_mean": 7.579730350168506, "train/model_loss_std": 12.208299133645829, "train/model_opt_grad_norm": 46.521460374995094, "train/model_opt_grad_steps": 53382.0, "train/model_opt_loss": 10787.162747330402, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1419.5979899497488, "train/policy_entropy_mag": 2.439271632151388, "train/policy_entropy_max": 2.439271632151388, "train/policy_entropy_mean": 0.4493483164202628, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.5502464889581479, "train/policy_logprob_mag": 7.43838399139481, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.4498330393628259, "train/policy_logprob_min": -7.43838399139481, "train/policy_logprob_std": 1.0460969275565604, "train/policy_randomness_mag": 0.8609558397801078, "train/policy_randomness_max": 0.8609558397801078, "train/policy_randomness_mean": 0.1586002361534828, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.19421286401736676, "train/post_ent_mag": 57.531922134322734, "train/post_ent_max": 57.531922134322734, "train/post_ent_mean": 39.11700508462724, "train/post_ent_min": 19.255052417965988, "train/post_ent_std": 6.567362361217863, "train/prior_ent_mag": 74.9512031976901, "train/prior_ent_max": 74.9512031976901, "train/prior_ent_mean": 45.29202285843279, "train/prior_ent_min": 25.460463653257744, "train/prior_ent_std": 8.057784226671535, "train/rep_loss_mean": 6.192438266984182, "train/rep_loss_std": 8.64008430020893, "train/reward_avg": 0.026295049256415823, "train/reward_loss_mean": 0.046051433272472575, "train/reward_loss_std": 0.20178819960685232, "train/reward_max_data": 1.0095477409698257, "train/reward_max_pred": 1.0087126169971485, "train/reward_neg_acc": 0.9953735437824498, "train/reward_neg_loss": 0.02313790690790319, "train/reward_pos_acc": 0.9864101032515866, "train/reward_pos_loss": 0.7468247611319, "train/reward_pred": 0.02594940771521935, "train/reward_rate": 0.03155916300251256, "train_stats/sum_log_reward": 6.631914991013547, "train_stats/max_log_achievement_collect_coal": 0.19148936170212766, "train_stats/max_log_achievement_collect_drink": 2.702127659574468, "train_stats/max_log_achievement_collect_sapling": 1.6382978723404256, "train_stats/max_log_achievement_collect_stone": 4.595744680851064, "train_stats/max_log_achievement_collect_wood": 6.212765957446808, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.06382978723404255, "train_stats/max_log_achievement_eat_cow": 0.0851063829787234, "train_stats/max_log_achievement_make_wood_pickaxe": 1.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.5319148936170213, "train_stats/max_log_achievement_place_stone": 3.3404255319148937, "train_stats/max_log_achievement_place_table": 2.1702127659574466, "train_stats/max_log_achievement_wake_up": 1.8297872340425532, "train_stats/mean_log_entropy": 0.37007556950792353, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 1.8354883195570437e-06, "report/cont_loss_std": 1.6447927919216454e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 5.3843752539251e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.4259746876632562e-06, "report/cont_pred": 0.9921865463256836, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 7.010819911956787, "report/dyn_loss_std": 9.7989501953125, "report/image_loss_mean": 4.154696941375732, "report/image_loss_std": 11.207207679748535, "report/model_loss_mean": 8.414191246032715, "report/model_loss_std": 15.9850492477417, "report/post_ent_mag": 58.35950469970703, "report/post_ent_max": 58.35950469970703, "report/post_ent_mean": 38.716636657714844, "report/post_ent_min": 15.004505157470703, "report/post_ent_std": 6.383918762207031, "report/prior_ent_mag": 74.24848175048828, "report/prior_ent_max": 74.24848175048828, "report/prior_ent_mean": 45.80084228515625, "report/prior_ent_min": 24.82589340209961, "report/prior_ent_std": 7.782260417938232, "report/rep_loss_mean": 7.010819911956787, "report/rep_loss_std": 9.7989501953125, "report/reward_avg": 0.02529297024011612, "report/reward_loss_mean": 0.05300066992640495, "report/reward_loss_std": 0.31409627199172974, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0033526420593262, "report/reward_neg_acc": 0.9939515590667725, "report/reward_neg_loss": 0.032891593873500824, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6763819456100464, "report/reward_pred": 0.026303550228476524, "report/reward_rate": 0.03125, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.0027122674509882927, "eval/cont_loss_std": 0.06297281384468079, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0024358495138585567, "eval/cont_pos_acc": 0.9980372786521912, "eval/cont_pos_loss": 0.002713624155148864, "eval/cont_pred": 0.9936957359313965, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 20.214054107666016, "eval/dyn_loss_std": 13.596477508544922, "eval/image_loss_mean": 23.510229110717773, "eval/image_loss_std": 37.690330505371094, "eval/model_loss_mean": 35.81940460205078, "eval/model_loss_std": 42.84539794921875, "eval/post_ent_mag": 55.70891571044922, "eval/post_ent_max": 55.70891571044922, "eval/post_ent_mean": 38.030860900878906, "eval/post_ent_min": 20.685604095458984, "eval/post_ent_std": 6.134121894836426, "eval/prior_ent_mag": 74.24848175048828, "eval/prior_ent_max": 74.24848175048828, "eval/prior_ent_mean": 50.8321533203125, "eval/prior_ent_min": 30.526817321777344, "eval/prior_ent_std": 7.702866554260254, "eval/rep_loss_mean": 20.214054107666016, "eval/rep_loss_std": 13.596477508544922, "eval/reward_avg": 0.03476562350988388, "eval/reward_loss_mean": 0.17803147435188293, "eval/reward_loss_std": 1.0062769651412964, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.000905990600586, "eval/reward_neg_acc": 0.9898270964622498, "eval/reward_neg_loss": 0.08430276066064835, "eval/reward_pos_acc": 0.7804877758026123, "eval/reward_pos_loss": 2.42523455619812, "eval/reward_pred": 0.030476104468107224, "eval/reward_rate": 0.0400390625, "replay/size": 218757.0, "replay/inserts": 7948.0, "replay/samples": 31792.0, "replay/insert_wait_avg": 1.5285726642272672e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.425457854095751e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 43160.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 7.152557373046875e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 999.9975476264954, "timer/env.step_count": 993.0, "timer/env.step_total": 99.15947794914246, "timer/env.step_frac": 0.09915972112581527, "timer/env.step_avg": 0.09985848736066713, "timer/env.step_min": 0.022861003875732422, "timer/env.step_max": 3.3335866928100586, "timer/replay._sample_count": 31792.0, "timer/replay._sample_total": 15.739718914031982, "timer/replay._sample_frac": 0.01573975751379628, "timer/replay._sample_avg": 0.0004950842637780568, "timer/replay._sample_min": 0.0003669261932373047, "timer/replay._sample_max": 0.020374536514282227, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 993.0, "timer/agent.policy_total": 15.74955153465271, "timer/agent.policy_frac": 0.015749590158530325, "timer/agent.policy_avg": 0.015860575563597896, "timer/agent.policy_min": 0.009598970413208008, "timer/agent.policy_max": 0.056097984313964844, "timer/dataset_train_count": 1987.0, "timer/dataset_train_total": 0.299396276473999, "timer/dataset_train_frac": 0.0002993970107072955, "timer/dataset_train_avg": 0.00015067754226170057, "timer/dataset_train_min": 9.250640869140625e-05, "timer/dataset_train_max": 0.0006718635559082031, "timer/agent.train_count": 1987.0, "timer/agent.train_total": 881.9834272861481, "timer/agent.train_frac": 0.8819855902442411, "timer/agent.train_avg": 0.44387691358135284, "timer/agent.train_min": 0.43415379524230957, "timer/agent.train_max": 0.9297134876251221, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47513580322265625, "timer/agent.report_frac": 0.0004751369684359687, "timer/agent.report_avg": 0.23756790161132812, "timer/agent.report_min": 0.2315080165863037, "timer/agent.report_max": 0.24362778663635254, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.956390380859375e-05, "timer/dataset_eval_frac": 2.9563976310505945e-08, "timer/dataset_eval_avg": 2.956390380859375e-05, "timer/dataset_eval_min": 2.956390380859375e-05, "timer/dataset_eval_max": 2.956390380859375e-05, "fps": 7.947907402409762}
{"step": 219280, "time": 28350.19056367874, "episode/length": 279.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9964285714285714, "episode/intrinsic_return": 0.0}
{"step": 219512, "time": 28378.500380277634, "episode/length": 201.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 219904, "time": 28425.562838554382, "episode/length": 205.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 220064, "time": 28465.897548913956, "eval_episode/length": 158.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9748427672955975}
{"step": 220064, "time": 28467.66078019142, "eval_episode/length": 162.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9693251533742331}
{"step": 220064, "time": 28469.607642650604, "eval_episode/length": 168.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9704142011834319}
{"step": 220064, "time": 28471.23133945465, "eval_episode/length": 170.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9941520467836257}
{"step": 220064, "time": 28472.84419155121, "eval_episode/length": 174.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 220064, "time": 28474.625208854675, "eval_episode/length": 180.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9779005524861878}
{"step": 220064, "time": 28476.249388456345, "eval_episode/length": 185.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9731182795698925}
{"step": 220064, "time": 28478.086896181107, "eval_episode/length": 192.0, "eval_episode/score": 8.099999994039536, "eval_episode/reward_rate": 0.9948186528497409}
{"step": 220232, "time": 28497.55571746826, "episode/length": 212.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 220312, "time": 28508.280626535416, "episode/length": 196.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 220384, "time": 28518.206332683563, "episode/length": 157.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 220680, "time": 28554.781801700592, "episode/length": 203.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 220792, "time": 28569.224385738373, "episode/length": 159.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 220920, "time": 28585.785058021545, "episode/length": 204.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9804878048780488, "episode/intrinsic_return": 0.0}
{"step": 221112, "time": 28609.47020792961, "episode/length": 150.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 221432, "time": 28649.208506822586, "episode/length": 149.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 221736, "time": 28686.331775665283, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 221784, "time": 28693.6307220459, "episode/length": 409.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9878048780487805, "episode/intrinsic_return": 0.0}
{"step": 221992, "time": 28719.274165153503, "episode/length": 163.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 222448, "time": 28773.887689590454, "episode/length": 190.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 222520, "time": 28783.965784549713, "episode/length": 266.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9850187265917603, "episode/intrinsic_return": 0.0}
{"step": 222648, "time": 28800.309084415436, "episode/length": 191.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 222904, "time": 28832.35766339302, "episode/length": 56.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9122807017543859, "episode/intrinsic_return": 0.0}
{"step": 223032, "time": 28848.727738380432, "episode/length": 47.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.8958333333333334, "episode/intrinsic_return": 0.0}
{"step": 223112, "time": 28859.617587327957, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 223360, "time": 28889.9944088459, "episode/length": 170.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 223408, "time": 28897.041121006012, "episode/length": 326.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9877675840978594, "episode/intrinsic_return": 0.0}
{"step": 223616, "time": 28923.4077064991, "episode/length": 272.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9816849816849816, "episode/intrinsic_return": 0.0}
{"step": 223800, "time": 28946.279499292374, "episode/length": 95.0, "episode/score": 5.100000038743019, "episode/reward_rate": 0.9895833333333334, "episode/intrinsic_return": 0.0}
{"step": 223864, "time": 28955.307554244995, "episode/length": 167.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 224432, "time": 29023.521585941315, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 224528, "time": 29036.888832569122, "episode/length": 202.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 225048, "time": 29099.511350631714, "episode/length": 178.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 225048, "time": 29099.5211853981, "episode/length": 210.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 225080, "time": 29106.513902664185, "episode/length": 208.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 225216, "time": 29123.885894298553, "episode/length": 434.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9793103448275862, "episode/intrinsic_return": 0.0}
{"step": 225312, "time": 29136.582792520523, "episode/length": 188.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 225648, "time": 29177.87663793564, "episode/length": 222.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.0}
{"step": 225664, "time": 29181.37817621231, "episode/length": 141.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 226232, "time": 29248.82638812065, "episode/length": 147.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 226608, "time": 29294.00371837616, "episode/length": 161.0, "episode/score": 6.1000000312924385, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 226832, "time": 29322.410691022873, "episode/length": 299.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9766666666666667, "episode/intrinsic_return": 0.0}
{"step": 226888, "time": 29330.39150571823, "episode/length": 208.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9665071770334929, "episode/intrinsic_return": 0.0}
{"step": 226984, "time": 29343.06040740013, "episode/length": 237.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9747899159663865, "episode/intrinsic_return": 0.0}
{"step": 227008, "time": 29347.32681441307, "episode/length": 167.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 227009, "time": 29349.84087061882, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.622931411585857, "train/action_min": 0.0, "train/action_std": 3.174734685838837, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04707316489717395, "train/actor_opt_grad_steps": 55395.0, "train/actor_opt_loss": -11.509242177163202, "train/adv_mag": 0.4912332081303154, "train/adv_max": 0.45845988485002026, "train/adv_mean": 0.002774130438073249, "train/adv_min": -0.41100898169979605, "train/adv_std": 0.05843195457433917, "train/cont_avg": 0.9944376208118557, "train/cont_loss_mean": 0.0001179378567757458, "train/cont_loss_std": 0.0034577357644411323, "train/cont_neg_acc": 0.9979749635322807, "train/cont_neg_loss": 0.007955994537684261, "train/cont_pos_acc": 0.9999797365714594, "train/cont_pos_loss": 7.463579931228347e-05, "train/cont_pred": 0.9944316591184164, "train/cont_rate": 0.9944376208118557, "train/dyn_loss_mean": 6.270174228038984, "train/dyn_loss_std": 8.672881055124027, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1950049747511284, "train/extr_critic_critic_opt_grad_steps": 55395.0, "train/extr_critic_critic_opt_loss": 16806.056701030928, "train/extr_critic_mag": 7.64373169731848, "train/extr_critic_max": 7.64373169731848, "train/extr_critic_mean": 1.679013438753246, "train/extr_critic_min": -0.6426470605368467, "train/extr_critic_std": 1.8112389906165527, "train/extr_return_normed_mag": 1.5535085121380914, "train/extr_return_normed_max": 1.5535085121380914, "train/extr_return_normed_mean": 0.3450504116637191, "train/extr_return_normed_min": -0.1293658954235389, "train/extr_return_normed_std": 0.33095689332976785, "train/extr_return_rate": 0.6305583835262614, "train/extr_return_raw_mag": 8.432835082417911, "train/extr_return_raw_max": 8.432835082417911, "train/extr_return_raw_mean": 1.6944884602556523, "train/extr_return_raw_min": -0.9514932071732491, "train/extr_return_raw_std": 1.8457531431286605, "train/extr_reward_mag": 1.0235142044185364, "train/extr_reward_max": 1.0235142044185364, "train/extr_reward_mean": 0.036638408736085766, "train/extr_reward_min": -0.6744426427428255, "train/extr_reward_std": 0.19027466772450613, "train/image_loss_mean": 3.900571356114653, "train/image_loss_std": 8.313770159003662, "train/model_loss_mean": 7.710027790561165, "train/model_loss_std": 12.405108353526321, "train/model_opt_grad_norm": 45.21090063114756, "train/model_opt_grad_steps": 55345.345360824744, "train/model_opt_loss": 10705.381166438467, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1378.8659793814434, "train/policy_entropy_mag": 2.4449009895324707, "train/policy_entropy_max": 2.4449009895324707, "train/policy_entropy_mean": 0.44226852781379344, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.5425086061364597, "train/policy_logprob_mag": 7.438383974979833, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.44255744627456073, "train/policy_logprob_min": -7.438383974979833, "train/policy_logprob_std": 1.040819694393689, "train/policy_randomness_mag": 0.8629427570657632, "train/policy_randomness_max": 0.8629427570657632, "train/policy_randomness_mean": 0.1561013815406057, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.1914817322928881, "train/post_ent_mag": 57.477710527243076, "train/post_ent_max": 57.477710527243076, "train/post_ent_mean": 39.33075049488815, "train/post_ent_min": 19.59646876816897, "train/post_ent_std": 6.538232545262759, "train/prior_ent_mag": 74.93755895083713, "train/prior_ent_max": 74.93755895083713, "train/prior_ent_mean": 45.5514030456543, "train/prior_ent_min": 25.95496175707001, "train/prior_ent_std": 7.929854702703731, "train/rep_loss_mean": 6.270174228038984, "train/rep_loss_std": 8.672881055124027, "train/reward_avg": 0.027208339830994913, "train/reward_loss_mean": 0.04723403519307522, "train/reward_loss_std": 0.2088367862185252, "train/reward_max_data": 1.0082474246467512, "train/reward_max_pred": 1.0089241014313453, "train/reward_neg_acc": 0.9955366902130166, "train/reward_neg_loss": 0.023317359075833533, "train/reward_pos_acc": 0.9827970545930961, "train/reward_pos_loss": 0.7641555577823796, "train/reward_pred": 0.02675184029029663, "train/reward_rate": 0.03226179929123711, "train_stats/sum_log_reward": 6.850000077672303, "train_stats/max_log_achievement_collect_coal": 0.325, "train_stats/max_log_achievement_collect_drink": 2.825, "train_stats/max_log_achievement_collect_sapling": 1.45, "train_stats/max_log_achievement_collect_stone": 5.175, "train_stats/max_log_achievement_collect_wood": 7.575, "train_stats/max_log_achievement_defeat_skeleton": 0.05, "train_stats/max_log_achievement_defeat_zombie": 0.1, "train_stats/max_log_achievement_eat_cow": 0.075, "train_stats/max_log_achievement_make_wood_pickaxe": 1.425, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.4, "train_stats/max_log_achievement_place_stone": 3.775, "train_stats/max_log_achievement_place_table": 2.525, "train_stats/max_log_achievement_wake_up": 2.225, "train_stats/mean_log_entropy": 0.40320867486298084, "eval_stats/sum_log_reward": 5.975000023841858, "eval_stats/max_log_achievement_collect_coal": 0.125, "eval_stats/max_log_achievement_collect_drink": 2.25, "eval_stats/max_log_achievement_collect_sapling": 1.125, "eval_stats/max_log_achievement_collect_stone": 2.0, "eval_stats/max_log_achievement_collect_wood": 6.375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.25, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 0.875, "eval_stats/max_log_achievement_place_stone": 1.875, "eval_stats/max_log_achievement_place_table": 2.375, "eval_stats/max_log_achievement_wake_up": 1.875, "eval_stats/mean_log_entropy": 0.0, "train_stats/max_log_achievement_place_furnace": 0.1, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 3.7453387449204456e-06, "report/cont_loss_std": 2.789678364933934e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 2.710416811169125e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 3.653735348052578e-06, "report/cont_pred": 0.996090292930603, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 5.731139659881592, "report/dyn_loss_std": 8.02582836151123, "report/image_loss_mean": 3.621755838394165, "report/image_loss_std": 7.931949138641357, "report/model_loss_mean": 7.0994415283203125, "report/model_loss_std": 11.686258316040039, "report/post_ent_mag": 56.79300308227539, "report/post_ent_max": 56.79300308227539, "report/post_ent_mean": 40.08412170410156, "report/post_ent_min": 21.1258487701416, "report/post_ent_std": 6.778937339782715, "report/prior_ent_mag": 74.98773193359375, "report/prior_ent_max": 74.98773193359375, "report/prior_ent_mean": 46.13117599487305, "report/prior_ent_min": 29.10091781616211, "report/prior_ent_std": 7.956650257110596, "report/rep_loss_mean": 5.731139659881592, "report/rep_loss_std": 8.02582836151123, "report/reward_avg": 0.0185546875, "report/reward_loss_mean": 0.03899801895022392, "report/reward_loss_std": 0.15352089703083038, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0023539066314697, "report/reward_neg_acc": 0.9980000257492065, "report/reward_neg_loss": 0.02265114150941372, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7201181650161743, "report/reward_pred": 0.018659166991710663, "report/reward_rate": 0.0234375, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 6.641000072704628e-05, "eval/cont_loss_std": 0.001892664236947894, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.012227373197674751, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 6.738938736816635e-06, "eval/cont_pred": 0.9951684474945068, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 20.35831069946289, "eval/dyn_loss_std": 13.117061614990234, "eval/image_loss_mean": 26.292747497558594, "eval/image_loss_std": 30.178504943847656, "eval/model_loss_mean": 38.65688705444336, "eval/model_loss_std": 35.01923751831055, "eval/post_ent_mag": 54.87412643432617, "eval/post_ent_max": 54.87412643432617, "eval/post_ent_mean": 38.240257263183594, "eval/post_ent_min": 20.274919509887695, "eval/post_ent_std": 6.235491752624512, "eval/prior_ent_mag": 74.98773193359375, "eval/prior_ent_max": 74.98773193359375, "eval/prior_ent_mean": 51.42510223388672, "eval/prior_ent_min": 33.73139953613281, "eval/prior_ent_std": 7.3395891189575195, "eval/rep_loss_mean": 20.35831069946289, "eval/rep_loss_std": 13.117061614990234, "eval/reward_avg": 0.03828125074505806, "eval/reward_loss_mean": 0.1490878462791443, "eval/reward_loss_std": 0.8821309804916382, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.0029964447021484, "eval/reward_neg_acc": 0.9938837289810181, "eval/reward_neg_loss": 0.07108785212039948, "eval/reward_pos_acc": 0.8372092843055725, "eval/reward_pos_loss": 1.928576111793518, "eval/reward_pred": 0.032400380820035934, "eval/reward_rate": 0.0419921875, "replay/size": 226505.0, "replay/inserts": 7748.0, "replay/samples": 30992.0, "replay/insert_wait_avg": 1.5311039288018127e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.457658071522868e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 44704.0, "eval_replay/inserts": 1544.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1181275461621853e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.940696716308594e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1001.7213995456696, "timer/env.step_count": 969.0, "timer/env.step_total": 90.10685706138611, "timer/env.step_frac": 0.08995201370586078, "timer/env.step_avg": 0.0929895325710899, "timer/env.step_min": 0.023250341415405273, "timer/env.step_max": 3.297301769256592, "timer/replay._sample_count": 30992.0, "timer/replay._sample_total": 15.426098585128784, "timer/replay._sample_frac": 0.015399589738349692, "timer/replay._sample_avg": 0.0004977445335934687, "timer/replay._sample_min": 0.0003750324249267578, "timer/replay._sample_max": 0.011145830154418945, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1162.0, "timer/agent.policy_total": 18.464612245559692, "timer/agent.policy_frac": 0.018432881891047064, "timer/agent.policy_avg": 0.015890371984130545, "timer/agent.policy_min": 0.009364843368530273, "timer/agent.policy_max": 0.047101736068725586, "timer/dataset_train_count": 1937.0, "timer/dataset_train_total": 0.2963721752166748, "timer/dataset_train_frac": 0.00029586287699463575, "timer/dataset_train_avg": 0.00015300576934263027, "timer/dataset_train_min": 9.059906005859375e-05, "timer/dataset_train_max": 0.0007832050323486328, "timer/agent.train_count": 1937.0, "timer/agent.train_total": 860.6047995090485, "timer/agent.train_frac": 0.8591259005741272, "timer/agent.train_avg": 0.44429777981881696, "timer/agent.train_min": 0.4334850311279297, "timer/agent.train_max": 0.9324913024902344, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47637391090393066, "timer/agent.report_frac": 0.000475555290243365, "timer/agent.report_avg": 0.23818695545196533, "timer/agent.report_min": 0.23137116432189941, "timer/agent.report_max": 0.24500274658203125, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.6464462280273438e-05, "timer/dataset_eval_frac": 2.6418984652096267e-08, "timer/dataset_eval_avg": 2.6464462280273438e-05, "timer/dataset_eval_min": 2.6464462280273438e-05, "timer/dataset_eval_max": 2.6464462280273438e-05, "fps": 7.734573445733955}
{"step": 227104, "time": 29360.898597478867, "episode/length": 181.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 227888, "time": 29453.97043991089, "episode/length": 159.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 227912, "time": 29458.261736392975, "episode/length": 209.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 228304, "time": 29505.571308851242, "episode/length": 149.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 228320, "time": 29508.986117362976, "episode/length": 178.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 228448, "time": 29525.405671596527, "episode/length": 424.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9788235294117648, "episode/intrinsic_return": 0.0}
{"step": 228504, "time": 29533.5147023201, "episode/length": 189.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 229208, "time": 29617.25268626213, "episode/length": 161.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 229248, "time": 29623.949665546417, "episode/length": 279.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9785714285714285, "episode/intrinsic_return": 0.0}
{"step": 229408, "time": 29645.528274536133, "episode/length": 189.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 229616, "time": 29671.378868103027, "episode/length": 161.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9567901234567902, "episode/intrinsic_return": 0.0}
{"step": 229632, "time": 29674.8268699646, "episode/length": 165.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 229760, "time": 29691.4900329113, "episode/length": 163.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 230024, "time": 29723.611072063446, "episode/length": 398.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9774436090225563, "episode/intrinsic_return": 0.0}
{"step": 230032, "time": 29726.00901579857, "episode/length": 190.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 230048, "time": 29744.14426970482, "eval_episode/length": 59.0, "eval_episode/score": 3.0999999716877937, "eval_episode/reward_rate": 0.9833333333333333}
{"step": 230048, "time": 29749.479813814163, "eval_episode/length": 143.0, "eval_episode/score": 6.099999971687794, "eval_episode/reward_rate": 0.9930555555555556}
{"step": 230048, "time": 29751.6662504673, "eval_episode/length": 150.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9801324503311258}
{"step": 230048, "time": 29755.879195451736, "eval_episode/length": 196.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9847715736040609}
{"step": 230048, "time": 29758.364141702652, "eval_episode/length": 153.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9675324675324676}
{"step": 230048, "time": 29760.568450450897, "eval_episode/length": 229.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9782608695652174}
{"step": 230048, "time": 29762.50943851471, "eval_episode/length": 237.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9957983193277311}
{"step": 230048, "time": 29764.298712968826, "eval_episode/length": 244.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9795918367346939}
{"step": 230448, "time": 29810.766412973404, "episode/length": 154.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 230712, "time": 29843.347559452057, "episode/length": 162.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 230840, "time": 29859.65546154976, "episode/length": 150.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 230904, "time": 29868.73543024063, "episode/length": 206.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 231024, "time": 29884.160277605057, "episode/length": 175.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 231504, "time": 29941.50736427307, "episode/length": 217.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 231648, "time": 29959.81659579277, "episode/length": 201.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 232104, "time": 30014.463576078415, "episode/length": 206.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9710144927536232, "episode/intrinsic_return": 0.0}
{"step": 232136, "time": 30019.64315032959, "episode/length": 153.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 232176, "time": 30025.743768692017, "episode/length": 182.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9672131147540983, "episode/intrinsic_return": 0.0}
{"step": 232520, "time": 30067.24581027031, "episode/length": 186.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 232768, "time": 30097.475234746933, "episode/length": 240.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.970954356846473, "episode/intrinsic_return": 0.0}
{"step": 233072, "time": 30134.452659845352, "episode/length": 195.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 233520, "time": 30188.05551481247, "episode/length": 436.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9794050343249427, "episode/intrinsic_return": 0.0}
{"step": 233632, "time": 30202.600516557693, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 233776, "time": 30221.589084386826, "episode/length": 204.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 233952, "time": 30243.654136896133, "episode/length": 287.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9861111111111112, "episode/intrinsic_return": 0.0}
{"step": 234008, "time": 30251.864382267, "episode/length": 237.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9789915966386554, "episode/intrinsic_return": 0.0}
{"step": 234048, "time": 30258.03503704071, "episode/length": 121.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9508196721311475, "episode/intrinsic_return": 0.0}
{"step": 234136, "time": 30269.73127913475, "episode/length": 201.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 234809, "time": 30350.25445485115, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.537284968449519, "train/action_min": 0.0, "train/action_std": 3.072681014965742, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0468617529154588, "train/actor_opt_grad_steps": 57340.0, "train/actor_opt_loss": -11.392858039110134, "train/adv_mag": 0.4979898165433835, "train/adv_max": 0.46170018972494664, "train/adv_mean": 0.003002822105074115, "train/adv_min": -0.4163057654331892, "train/adv_std": 0.05833042426369129, "train/cont_avg": 0.9945813301282052, "train/cont_loss_mean": 9.739270154956359e-05, "train/cont_loss_std": 0.00286732521842215, "train/cont_neg_acc": 0.9955067163858659, "train/cont_neg_loss": 0.011773221658375358, "train/cont_pos_acc": 0.9999848946546896, "train/cont_pos_loss": 3.6483132950010236e-05, "train/cont_pred": 0.9945815523465474, "train/cont_rate": 0.9945813301282052, "train/dyn_loss_mean": 6.190724245707194, "train/dyn_loss_std": 8.617961976467035, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.17981136517647, "train/extr_critic_critic_opt_grad_steps": 57340.0, "train/extr_critic_critic_opt_loss": 16900.73552684295, "train/extr_critic_mag": 7.768774318695068, "train/extr_critic_max": 7.768774318695068, "train/extr_critic_mean": 1.7476085072908647, "train/extr_critic_min": -0.6466444180561945, "train/extr_critic_std": 1.8209129400742359, "train/extr_return_normed_mag": 1.5409516242834238, "train/extr_return_normed_max": 1.5409516242834238, "train/extr_return_normed_mean": 0.35077530741691587, "train/extr_return_normed_min": -0.125005622055286, "train/extr_return_normed_std": 0.32785585835958136, "train/extr_return_rate": 0.6525781617714809, "train/extr_return_raw_mag": 8.516551998334053, "train/extr_return_raw_max": 8.516551998334053, "train/extr_return_raw_mean": 1.7646327021794441, "train/extr_return_raw_min": -0.9346187976690439, "train/extr_return_raw_std": 1.8602587033540774, "train/extr_reward_mag": 1.0239162579560892, "train/extr_reward_max": 1.0239162579560892, "train/extr_reward_mean": 0.037386866549077705, "train/extr_reward_min": -0.683123751787039, "train/extr_reward_std": 0.19141166978157484, "train/image_loss_mean": 3.7963483358040833, "train/image_loss_std": 8.41174074075161, "train/model_loss_mean": 7.557613729819273, "train/model_loss_std": 12.455413559155586, "train/model_opt_grad_norm": 46.961752827962236, "train/model_opt_grad_steps": 57288.46666666667, "train/model_opt_loss": 9853.148585236378, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1301.2820512820513, "train/policy_entropy_mag": 2.4403699446947145, "train/policy_entropy_max": 2.4403699446947145, "train/policy_entropy_mean": 0.42298679856153637, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.5286486089229584, "train/policy_logprob_mag": 7.438384021856846, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.42215600304114514, "train/policy_logprob_min": -7.438384021856846, "train/policy_logprob_std": 1.025270098600632, "train/policy_randomness_mag": 0.8613434974963848, "train/policy_randomness_max": 0.8613434974963848, "train/policy_randomness_mean": 0.1492957781522702, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.18658976058165233, "train/post_ent_mag": 57.51328244331555, "train/post_ent_max": 57.51328244331555, "train/post_ent_mean": 39.55950115888547, "train/post_ent_min": 19.32926741869022, "train/post_ent_std": 6.525553903824243, "train/prior_ent_mag": 74.98583346635867, "train/prior_ent_max": 74.98583346635867, "train/prior_ent_mean": 45.74107292370918, "train/prior_ent_min": 26.282016685681466, "train/prior_ent_std": 7.85960011115441, "train/rep_loss_mean": 6.190724245707194, "train/rep_loss_std": 8.617961976467035, "train/reward_avg": 0.02762620171579795, "train/reward_loss_mean": 0.046733482535450885, "train/reward_loss_std": 0.20608669267250943, "train/reward_max_data": 1.0076923095262968, "train/reward_max_pred": 1.0086693017910688, "train/reward_neg_acc": 0.9953909632487175, "train/reward_neg_loss": 0.02262780692619391, "train/reward_pos_acc": 0.9808887383876703, "train/reward_pos_loss": 0.7642755862994072, "train/reward_pred": 0.027222604414400383, "train/reward_rate": 0.03266225961538462, "train_stats/sum_log_reward": 6.5000000613076345, "train_stats/max_log_achievement_collect_coal": 0.11428571428571428, "train_stats/max_log_achievement_collect_drink": 3.942857142857143, "train_stats/max_log_achievement_collect_sapling": 1.8285714285714285, "train_stats/max_log_achievement_collect_stone": 4.9714285714285715, "train_stats/max_log_achievement_collect_wood": 6.314285714285714, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.08571428571428572, "train_stats/max_log_achievement_eat_cow": 0.05714285714285714, "train_stats/max_log_achievement_make_wood_pickaxe": 1.0857142857142856, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 1.6571428571428573, "train_stats/max_log_achievement_place_stone": 4.0, "train_stats/max_log_achievement_place_table": 2.1714285714285713, "train_stats/max_log_achievement_wake_up": 2.6285714285714286, "train_stats/mean_log_entropy": 0.4187403231859207, "eval_stats/sum_log_reward": 6.224999904632568, "eval_stats/max_log_achievement_collect_coal": 0.125, "eval_stats/max_log_achievement_collect_drink": 3.875, "eval_stats/max_log_achievement_collect_sapling": 1.5, "eval_stats/max_log_achievement_collect_stone": 1.5, "eval_stats/max_log_achievement_collect_wood": 6.875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.25, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.125, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.375, "eval_stats/max_log_achievement_place_stone": 1.375, "eval_stats/max_log_achievement_place_table": 2.375, "eval_stats/max_log_achievement_wake_up": 1.875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 2.935920065283426e-06, "report/cont_loss_std": 5.595389666268602e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00032688610372133553, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.3463704817695543e-06, "report/cont_pred": 0.9951175451278687, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 5.813823699951172, "report/dyn_loss_std": 8.15550708770752, "report/image_loss_mean": 2.296067714691162, "report/image_loss_std": 4.676186561584473, "report/model_loss_mean": 5.8398542404174805, "report/model_loss_std": 8.830147743225098, "report/post_ent_mag": 54.24193572998047, "report/post_ent_max": 54.24193572998047, "report/post_ent_mean": 38.705936431884766, "report/post_ent_min": 18.791488647460938, "report/post_ent_std": 5.816038131713867, "report/prior_ent_mag": 75.2706298828125, "report/prior_ent_max": 75.2706298828125, "report/prior_ent_mean": 45.235321044921875, "report/prior_ent_min": 28.652915954589844, "report/prior_ent_std": 7.10204553604126, "report/rep_loss_mean": 5.813823699951172, "report/rep_loss_std": 8.15550708770752, "report/reward_avg": 0.04013671725988388, "report/reward_loss_mean": 0.05548916012048721, "report/reward_loss_std": 0.21177972853183746, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.001807689666748, "report/reward_neg_acc": 0.9959099888801575, "report/reward_neg_loss": 0.02305268868803978, "report/reward_pos_acc": 0.97826087474823, "report/reward_pos_loss": 0.7451167702674866, "report/reward_pred": 0.038854993879795074, "report/reward_rate": 0.044921875, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 8.321664495269943e-07, "eval/cont_loss_std": 7.755657861707732e-06, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 3.4578338272694964e-06, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 8.2445143334553e-07, "eval/cont_pred": 0.9970694780349731, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 21.70652198791504, "eval/dyn_loss_std": 12.811673164367676, "eval/image_loss_mean": 26.066394805908203, "eval/image_loss_std": 30.010692596435547, "eval/model_loss_mean": 39.25661087036133, "eval/model_loss_std": 35.349674224853516, "eval/post_ent_mag": 52.098052978515625, "eval/post_ent_max": 52.098052978515625, "eval/post_ent_mean": 36.64781951904297, "eval/post_ent_min": 20.38530731201172, "eval/post_ent_std": 5.673293113708496, "eval/prior_ent_mag": 75.2706298828125, "eval/prior_ent_max": 75.2706298828125, "eval/prior_ent_mean": 51.28177261352539, "eval/prior_ent_min": 34.598609924316406, "eval/prior_ent_std": 6.377959251403809, "eval/rep_loss_mean": 21.70652198791504, "eval/rep_loss_std": 12.811673164367676, "eval/reward_avg": 0.04570312798023224, "eval/reward_loss_mean": 0.16630086302757263, "eval/reward_loss_std": 0.9201659560203552, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.001826286315918, "eval/reward_neg_acc": 0.9928131699562073, "eval/reward_neg_loss": 0.08454439789056778, "eval/reward_pos_acc": 0.8399999737739563, "eval/reward_pos_loss": 1.7589166164398193, "eval/reward_pred": 0.040482297539711, "eval/reward_rate": 0.048828125, "replay/size": 234305.0, "replay/inserts": 7800.0, "replay/samples": 31200.0, "replay/insert_wait_avg": 1.544646727733123e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.52103634369679e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 46664.0, "eval_replay/inserts": 1960.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2253011975969587e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0728836059570312e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4242861270905, "timer/env.step_count": 975.0, "timer/env.step_total": 79.00290822982788, "timer/env.step_frac": 0.07896940260783676, "timer/env.step_avg": 0.0810286238254645, "timer/env.step_min": 0.022691011428833008, "timer/env.step_max": 1.9674668312072754, "timer/replay._sample_count": 31200.0, "timer/replay._sample_total": 15.870708465576172, "timer/replay._sample_frac": 0.015863977599960034, "timer/replay._sample_avg": 0.0005086765533838517, "timer/replay._sample_min": 0.0004062652587890625, "timer/replay._sample_max": 0.010872602462768555, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1220.0, "timer/agent.policy_total": 19.74094820022583, "timer/agent.policy_frac": 0.01973257594200188, "timer/agent.policy_avg": 0.01618110508215232, "timer/agent.policy_min": 0.009404182434082031, "timer/agent.policy_max": 0.0736093521118164, "timer/dataset_train_count": 1950.0, "timer/dataset_train_total": 0.3485746383666992, "timer/dataset_train_frac": 0.0003484268057067314, "timer/dataset_train_avg": 0.0001787562248034355, "timer/dataset_train_min": 9.34600830078125e-05, "timer/dataset_train_max": 0.05364346504211426, "timer/agent.train_count": 1950.0, "timer/agent.train_total": 867.4928510189056, "timer/agent.train_frac": 0.8671249419355882, "timer/agent.train_avg": 0.4448681287276439, "timer/agent.train_min": 0.424762487411499, "timer/agent.train_max": 0.9531505107879639, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4820592403411865, "timer/agent.report_frac": 0.0004818547960359565, "timer/agent.report_avg": 0.24102962017059326, "timer/agent.report_min": 0.23111581802368164, "timer/agent.report_max": 0.2509434223175049, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.86102294921875e-05, "timer/dataset_eval_frac": 2.8598095716913608e-08, "timer/dataset_eval_avg": 2.86102294921875e-05, "timer/dataset_eval_min": 2.86102294921875e-05, "timer/dataset_eval_max": 2.86102294921875e-05, "fps": 7.796579592509019}
{"step": 234856, "time": 30355.61665701866, "episode/length": 260.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9961685823754789, "episode/intrinsic_return": 0.0}
{"step": 235088, "time": 30384.187635183334, "episode/length": 181.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9835164835164835, "episode/intrinsic_return": 0.0}
{"step": 235120, "time": 30389.409845352173, "episode/length": 167.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 235160, "time": 30395.567779541016, "episode/length": 150.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 235376, "time": 30422.718700647354, "episode/length": 231.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.978448275862069, "episode/intrinsic_return": 0.0}
{"step": 235424, "time": 30430.422139644623, "episode/length": 171.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 235496, "time": 30440.75614142418, "episode/length": 169.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 235520, "time": 30445.414890050888, "episode/length": 188.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9682539682539683, "episode/intrinsic_return": 0.0}
{"step": 236312, "time": 30539.45290374756, "episode/length": 181.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 236584, "time": 30572.54107260704, "episode/length": 182.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 236624, "time": 30578.616899251938, "episode/length": 191.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 236720, "time": 30591.36746788025, "episode/length": 167.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 236856, "time": 30608.687704086304, "episode/length": 178.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 236952, "time": 30621.29098057747, "episode/length": 223.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 236960, "time": 30623.610043764114, "episode/length": 182.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 237424, "time": 30678.983627796173, "episode/length": 138.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9496402877697842, "episode/intrinsic_return": 0.0}
{"step": 237680, "time": 30711.379277944565, "episode/length": 269.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9888888888888889, "episode/intrinsic_return": 0.0}
{"step": 237984, "time": 30747.95583987236, "episode/length": 169.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 238064, "time": 30758.7616417408, "episode/length": 167.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 238152, "time": 30770.63127064705, "episode/length": 195.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 238160, "time": 30773.098930120468, "episode/length": 149.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 238712, "time": 30838.669021368027, "episode/length": 69.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9285714285714286, "episode/intrinsic_return": 0.0}
{"step": 238752, "time": 30844.83268761635, "episode/length": 236.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 238824, "time": 30854.804738998413, "episode/length": 174.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 238920, "time": 30867.711970329285, "episode/length": 245.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9796747967479674, "episode/intrinsic_return": 0.0}
{"step": 239584, "time": 30947.302182674408, "episode/length": 189.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9842105263157894, "episode/intrinsic_return": 0.0}
{"step": 239824, "time": 30976.810413837433, "episode/length": 267.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9850746268656716, "episode/intrinsic_return": 0.0}
{"step": 239944, "time": 30992.22277736664, "episode/length": 153.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 239976, "time": 30997.467191934586, "episode/length": 248.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 240032, "time": 31025.593845129013, "eval_episode/length": 172.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9710982658959537}
{"step": 240032, "time": 31027.467715263367, "eval_episode/length": 173.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9712643678160919}
{"step": 240032, "time": 31030.027680635452, "eval_episode/length": 184.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.972972972972973}
{"step": 240032, "time": 31030.036171913147, "eval_episode/length": 184.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9945945945945946}
{"step": 240032, "time": 31035.346142053604, "eval_episode/length": 210.0, "eval_episode/score": 7.100000023841858, "eval_episode/reward_rate": 0.995260663507109}
{"step": 240032, "time": 31038.363685131073, "eval_episode/length": 245.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9878048780487805}
{"step": 240032, "time": 31040.804644346237, "eval_episode/length": 253.0, "eval_episode/score": 9.100000023841858, "eval_episode/reward_rate": 0.9960629921259843}
{"step": 240032, "time": 31046.018707036972, "eval_episode/length": 318.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9905956112852664}
{"step": 240128, "time": 31057.155962705612, "episode/length": 245.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9796747967479674, "episode/intrinsic_return": 0.0}
{"step": 240128, "time": 31057.16244840622, "episode/length": 150.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9735099337748344, "episode/intrinsic_return": 0.0}
{"step": 240384, "time": 31090.165471553802, "episode/length": 194.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9641025641025641, "episode/intrinsic_return": 0.0}
{"step": 240632, "time": 31120.518045663834, "episode/length": 234.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9744680851063829, "episode/intrinsic_return": 0.0}
{"step": 241200, "time": 31187.94037461281, "episode/length": 201.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 241240, "time": 31194.13540148735, "episode/length": 161.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 241320, "time": 31204.918328523636, "episode/length": 186.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9625668449197861, "episode/intrinsic_return": 0.0}
{"step": 241696, "time": 31250.068432569504, "episode/length": 61.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9354838709677419, "episode/intrinsic_return": 0.0}
{"step": 241720, "time": 31254.309673547745, "episode/length": 198.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.0}
{"step": 241736, "time": 31257.59959936142, "episode/length": 168.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 242128, "time": 31304.91267800331, "episode/length": 249.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.976, "episode/intrinsic_return": 0.0}
{"step": 242328, "time": 31329.425830841064, "episode/length": 211.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 242489, "time": 31350.540071249008, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.510016441345215, "train/action_min": 0.0, "train/action_std": 3.0791283225019774, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04661521160354217, "train/actor_opt_grad_steps": 59275.0, "train/actor_opt_loss": -11.840334382043997, "train/adv_mag": 0.5047009061090648, "train/adv_max": 0.475812956225127, "train/adv_mean": 0.0029839368147198306, "train/adv_min": -0.40212051818768185, "train/adv_std": 0.05833228708555301, "train/cont_avg": 0.9946492513020834, "train/cont_loss_mean": 0.00017209521005575232, "train/cont_loss_std": 0.005299868462519323, "train/cont_neg_acc": 0.9937911489978433, "train/cont_neg_loss": 0.021738263550255727, "train/cont_pos_acc": 0.9999897588665286, "train/cont_pos_loss": 3.380172368083745e-05, "train/cont_pred": 0.9946765980372826, "train/cont_rate": 0.9946492513020834, "train/dyn_loss_mean": 6.180877509216468, "train/dyn_loss_std": 8.596023738384247, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.209927889207999, "train/extr_critic_critic_opt_grad_steps": 59275.0, "train/extr_critic_critic_opt_loss": 16854.345937093098, "train/extr_critic_mag": 7.850390320022901, "train/extr_critic_max": 7.850390320022901, "train/extr_critic_mean": 1.766835178559025, "train/extr_critic_min": -0.6369136261443297, "train/extr_critic_std": 1.865066650013129, "train/extr_return_normed_mag": 1.547626817598939, "train/extr_return_normed_max": 1.547626817598939, "train/extr_return_normed_mean": 0.34668758992726606, "train/extr_return_normed_min": -0.12482362605320911, "train/extr_return_normed_std": 0.3304810676878939, "train/extr_return_rate": 0.6381714198117455, "train/extr_return_raw_mag": 8.695916809141636, "train/extr_return_raw_max": 8.695916809141636, "train/extr_return_raw_mean": 1.783998648636043, "train/extr_return_raw_min": -0.9295714671413103, "train/extr_return_raw_std": 1.902030784636736, "train/extr_reward_mag": 1.0250082363684971, "train/extr_reward_max": 1.0250082363684971, "train/extr_reward_mean": 0.03736280860418143, "train/extr_reward_min": -0.6682897551606098, "train/extr_reward_std": 0.19163992869046828, "train/image_loss_mean": 3.7361483859519162, "train/image_loss_std": 8.091482616961002, "train/model_loss_mean": 7.4907650252183275, "train/model_loss_std": 12.099927758177122, "train/model_opt_grad_norm": 43.463979333639145, "train/model_opt_grad_steps": 59221.78125, "train/model_opt_loss": 11379.983993530273, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1516.9270833333333, "train/policy_entropy_mag": 2.448755686481794, "train/policy_entropy_max": 2.448755686481794, "train/policy_entropy_mean": 0.4435170901318391, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.5570174641907215, "train/policy_logprob_mag": 7.438384008904298, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.4436030945119758, "train/policy_logprob_min": -7.438384008904298, "train/policy_logprob_std": 1.0414604377001524, "train/policy_randomness_mag": 0.8643032964318991, "train/policy_randomness_max": 0.8643032964318991, "train/policy_randomness_mean": 0.15654206986073405, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.19660272162097195, "train/post_ent_mag": 57.90436943372091, "train/post_ent_max": 57.90436943372091, "train/post_ent_mean": 39.96701876322428, "train/post_ent_min": 19.20718441406886, "train/post_ent_std": 6.686032707492511, "train/prior_ent_mag": 75.00664122899373, "train/prior_ent_max": 75.00664122899373, "train/prior_ent_mean": 46.15500716368357, "train/prior_ent_min": 26.533921549717586, "train/prior_ent_std": 7.813788657387097, "train/rep_loss_mean": 6.180877509216468, "train/rep_loss_std": 8.596023738384247, "train/reward_avg": 0.027765909597898524, "train/reward_loss_mean": 0.04591803093596051, "train/reward_loss_std": 0.19841198398110768, "train/reward_max_data": 1.0088541687776644, "train/reward_max_pred": 1.0074243241300185, "train/reward_neg_acc": 0.995342482191821, "train/reward_neg_loss": 0.02211766432931957, "train/reward_pos_acc": 0.9833685187622905, "train/reward_pos_loss": 0.7535531887163719, "train/reward_pred": 0.027349776772704597, "train/reward_rate": 0.032633463541666664, "train_stats/sum_log_reward": 6.978048830497555, "train_stats/max_log_achievement_collect_coal": 0.17073170731707318, "train_stats/max_log_achievement_collect_drink": 2.8048780487804876, "train_stats/max_log_achievement_collect_sapling": 1.975609756097561, "train_stats/max_log_achievement_collect_stone": 4.2926829268292686, "train_stats/max_log_achievement_collect_wood": 6.926829268292683, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.04878048780487805, "train_stats/max_log_achievement_eat_cow": 0.024390243902439025, "train_stats/max_log_achievement_make_wood_pickaxe": 1.2439024390243902, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_furnace": 0.024390243902439025, "train_stats/max_log_achievement_place_plant": 1.853658536585366, "train_stats/max_log_achievement_place_stone": 2.7560975609756095, "train_stats/max_log_achievement_place_table": 2.317073170731707, "train_stats/max_log_achievement_wake_up": 1.8780487804878048, "train_stats/mean_log_entropy": 0.38849804314171393, "eval_stats/sum_log_reward": 7.225000083446503, "eval_stats/max_log_achievement_collect_coal": 0.125, "eval_stats/max_log_achievement_collect_drink": 1.5, "eval_stats/max_log_achievement_collect_sapling": 2.5, "eval_stats/max_log_achievement_collect_stone": 7.875, "eval_stats/max_log_achievement_collect_wood": 7.5, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.125, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.375, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 2.375, "eval_stats/max_log_achievement_place_stone": 6.75, "eval_stats/max_log_achievement_place_table": 2.5, "eval_stats/max_log_achievement_wake_up": 2.375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 7.209043815237237e-06, "report/cont_loss_std": 0.00016019839677028358, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 8.886810974217951e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 6.727752406732179e-06, "report/cont_pred": 0.9941345453262329, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 6.669651985168457, "report/dyn_loss_std": 8.302275657653809, "report/image_loss_mean": 3.1221046447753906, "report/image_loss_std": 6.51983118057251, "report/model_loss_mean": 7.171597480773926, "report/model_loss_std": 10.487524032592773, "report/post_ent_mag": 56.462738037109375, "report/post_ent_max": 56.462738037109375, "report/post_ent_mean": 39.33951950073242, "report/post_ent_min": 22.83803939819336, "report/post_ent_std": 6.357683181762695, "report/prior_ent_mag": 74.81462097167969, "report/prior_ent_max": 74.81462097167969, "report/prior_ent_mean": 46.298789978027344, "report/prior_ent_min": 26.18596076965332, "report/prior_ent_std": 7.9743332862854, "report/rep_loss_mean": 6.669651985168457, "report/rep_loss_std": 8.302275657653809, "report/reward_avg": 0.03398437425494194, "report/reward_loss_mean": 0.047694116830825806, "report/reward_loss_std": 0.20169369876384735, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0006229877471924, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.01844153366982937, "report/reward_pos_acc": 0.9743589758872986, "report/reward_pos_loss": 0.7865094542503357, "report/reward_pred": 0.0321052260696888, "report/reward_rate": 0.0380859375, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 8.733002323424444e-05, "eval/cont_loss_std": 0.001882822485640645, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00042848821613006294, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 8.632760000182316e-05, "eval/cont_pred": 0.9969872832298279, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 22.001150131225586, "eval/dyn_loss_std": 13.538468360900879, "eval/image_loss_mean": 31.826448440551758, "eval/image_loss_std": 39.53279495239258, "eval/model_loss_mean": 45.152042388916016, "eval/model_loss_std": 44.73091125488281, "eval/post_ent_mag": 54.69999694824219, "eval/post_ent_max": 54.69999694824219, "eval/post_ent_mean": 36.60247802734375, "eval/post_ent_min": 19.105819702148438, "eval/post_ent_std": 5.282408237457275, "eval/prior_ent_mag": 74.81462097167969, "eval/prior_ent_max": 74.81462097167969, "eval/prior_ent_mean": 49.64857482910156, "eval/prior_ent_min": 31.495330810546875, "eval/prior_ent_std": 6.839942932128906, "eval/rep_loss_mean": 22.001150131225586, "eval/rep_loss_std": 13.538468360900879, "eval/reward_avg": 0.02607421949505806, "eval/reward_loss_mean": 0.12481830269098282, "eval/reward_loss_std": 0.8297210335731506, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0075657367706299, "eval/reward_neg_acc": 0.9979878664016724, "eval/reward_neg_loss": 0.06403525918722153, "eval/reward_pos_acc": 0.8000000715255737, "eval/reward_pos_loss": 2.138763904571533, "eval/reward_pred": 0.021439746022224426, "eval/reward_rate": 0.029296875, "replay/size": 241985.0, "replay/inserts": 7680.0, "replay/samples": 30720.0, "replay/insert_wait_avg": 1.5449710190296174e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.47114730377992e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 49216.0, "eval_replay/inserts": 2552.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1626642699525648e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.748603820800781e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2722012996674, "timer/env.step_count": 960.0, "timer/env.step_total": 89.65352129936218, "timer/env.step_frac": 0.08962912413528451, "timer/env.step_avg": 0.09338908468683561, "timer/env.step_min": 0.023015975952148438, "timer/env.step_max": 3.411007881164551, "timer/replay._sample_count": 30720.0, "timer/replay._sample_total": 15.281641960144043, "timer/replay._sample_frac": 0.015277483409304383, "timer/replay._sample_avg": 0.0004974492825567722, "timer/replay._sample_min": 0.0003590583801269531, "timer/replay._sample_max": 0.010753631591796875, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1279.0, "timer/agent.policy_total": 20.697299242019653, "timer/agent.policy_frac": 0.02069166694338538, "timer/agent.policy_avg": 0.016182407538717476, "timer/agent.policy_min": 0.009366273880004883, "timer/agent.policy_max": 0.11890721321105957, "timer/dataset_train_count": 1920.0, "timer/dataset_train_total": 0.29807472229003906, "timer/dataset_train_frac": 0.00029799360804263727, "timer/dataset_train_avg": 0.00015524725119272869, "timer/dataset_train_min": 9.298324584960938e-05, "timer/dataset_train_max": 0.009301424026489258, "timer/agent.train_count": 1920.0, "timer/agent.train_total": 852.0239813327789, "timer/agent.train_frac": 0.8517921224100125, "timer/agent.train_avg": 0.44376249027748904, "timer/agent.train_min": 0.43253397941589355, "timer/agent.train_max": 1.2110278606414795, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.46193408966064453, "timer/agent.report_frac": 0.00046180838481809977, "timer/agent.report_avg": 0.23096704483032227, "timer/agent.report_min": 0.22037315368652344, "timer/agent.report_max": 0.2415609359741211, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.956390380859375e-05, "timer/dataset_eval_frac": 2.955585866545223e-08, "timer/dataset_eval_avg": 2.956390380859375e-05, "timer/dataset_eval_min": 2.956390380859375e-05, "timer/dataset_eval_max": 2.956390380859375e-05, "fps": 7.677804879914366}
{"step": 242584, "time": 31361.521847248077, "episode/length": 325.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9877300613496932, "episode/intrinsic_return": 0.0}
{"step": 242720, "time": 31378.852134227753, "episode/length": 184.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 243000, "time": 31412.805373191833, "episode/length": 162.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 243032, "time": 31417.97530388832, "episode/length": 163.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 243120, "time": 31429.624816179276, "episode/length": 172.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9653179190751445, "episode/intrinsic_return": 0.0}
{"step": 243528, "time": 31478.261569976807, "episode/length": 275.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9963768115942029, "episode/intrinsic_return": 0.0}
{"step": 243816, "time": 31513.04571533203, "episode/length": 185.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 244352, "time": 31576.504500865936, "episode/length": 153.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 244416, "time": 31585.508204221725, "episode/length": 176.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 244416, "time": 31585.51757121086, "episode/length": 285.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.986013986013986, "episode/intrinsic_return": 0.0}
{"step": 244560, "time": 31606.415227890015, "episode/length": 246.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9838056680161943, "episode/intrinsic_return": 0.0}
{"step": 244632, "time": 31616.24891424179, "episode/length": 238.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9707112970711297, "episode/intrinsic_return": 0.0}
{"step": 244928, "time": 31651.89306640625, "episode/length": 174.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 245048, "time": 31667.342002868652, "episode/length": 251.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 245304, "time": 31698.386867046356, "episode/length": 185.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 245808, "time": 31759.473556280136, "episode/length": 155.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 245896, "time": 31771.061980485916, "episode/length": 192.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 246000, "time": 31784.718332529068, "episode/length": 118.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9915966386554622, "episode/intrinsic_return": 0.0}
{"step": 246144, "time": 31803.53257703781, "episode/length": 215.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 246304, "time": 31823.604429006577, "episode/length": 208.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 246320, "time": 31826.967832565308, "episode/length": 237.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9789915966386554, "episode/intrinsic_return": 0.0}
{"step": 246384, "time": 31835.866324186325, "episode/length": 181.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 246784, "time": 31884.07455945015, "episode/length": 184.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 247216, "time": 31935.566974639893, "episode/length": 111.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9553571428571429, "episode/intrinsic_return": 0.0}
{"step": 247232, "time": 31938.907448768616, "episode/length": 166.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 247256, "time": 31943.215043067932, "episode/length": 180.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 247480, "time": 31970.84135699272, "episode/length": 184.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 247800, "time": 32009.60606622696, "episode/length": 176.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 247928, "time": 32026.0349445343, "episode/length": 222.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9820627802690582, "episode/intrinsic_return": 0.0}
{"step": 248448, "time": 32087.730219602585, "episode/length": 267.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.996268656716418, "episode/intrinsic_return": 0.0}
{"step": 248552, "time": 32101.1265501976, "episode/length": 93.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9468085106382979, "episode/intrinsic_return": 0.0}
{"step": 248688, "time": 32118.4377989769, "episode/length": 183.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 248720, "time": 32123.598777770996, "episode/length": 241.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9834710743801653, "episode/intrinsic_return": 0.0}
{"step": 248960, "time": 32152.85570192337, "episode/length": 50.0, "episode/score": 0.10000000149011612, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 249080, "time": 32168.178320884705, "episode/length": 230.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 249224, "time": 32186.273206710815, "episode/length": 161.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 249240, "time": 32189.650322198868, "episode/length": 247.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9798387096774194, "episode/intrinsic_return": 0.0}
{"step": 249368, "time": 32206.047083377838, "episode/length": 235.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9703389830508474, "episode/intrinsic_return": 0.0}
{"step": 250016, "time": 32297.394172668457, "eval_episode/length": 49.0, "eval_episode/score": 4.0999999940395355, "eval_episode/reward_rate": 0.98}
{"step": 250016, "time": 32302.473814725876, "eval_episode/length": 139.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9642857142857143}
{"step": 250016, "time": 32304.12361049652, "eval_episode/length": 142.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.965034965034965}
{"step": 250016, "time": 32307.062156915665, "eval_episode/length": 178.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.994413407821229}
{"step": 250016, "time": 32308.980568408966, "eval_episode/length": 188.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9735449735449735}
{"step": 250016, "time": 32311.103058338165, "eval_episode/length": 201.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9801980198019802}
{"step": 250016, "time": 32313.4732773304, "eval_episode/length": 224.0, "eval_episode/score": 9.099999971687794, "eval_episode/reward_rate": 0.9955555555555555}
{"step": 250016, "time": 32314.976876735687, "eval_episode/length": 225.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9734513274336283}
{"step": 250280, "time": 32345.48150587082, "episode/length": 194.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 250296, "time": 32348.8733458519, "episode/length": 166.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 250297, "time": 32352.02148270607, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.455984575320513, "train/action_min": 0.0, "train/action_std": 3.0648935183500634, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0458136016359696, "train/actor_opt_grad_steps": 61210.0, "train/actor_opt_loss": -12.423658654991632, "train/adv_mag": 0.48820099448546384, "train/adv_max": 0.45658333882307395, "train/adv_mean": 0.0027738453776412196, "train/adv_min": -0.4066725697272863, "train/adv_std": 0.05779294304740735, "train/cont_avg": 0.9947566105769231, "train/cont_loss_mean": 9.58490442160499e-05, "train/cont_loss_std": 0.0028856717638976264, "train/cont_neg_acc": 1.0, "train/cont_neg_loss": 0.0013382051120340924, "train/cont_pos_acc": 0.9999646911254296, "train/cont_pos_loss": 8.932638589060505e-05, "train/cont_pred": 0.9947239117744642, "train/cont_rate": 0.9947566105769231, "train/dyn_loss_mean": 6.357286120683719, "train/dyn_loss_std": 8.624153027167687, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1581834848110493, "train/extr_critic_critic_opt_grad_steps": 61210.0, "train/extr_critic_critic_opt_loss": 16887.016736778845, "train/extr_critic_mag": 7.880302908481696, "train/extr_critic_max": 7.880302908481696, "train/extr_critic_mean": 1.7887691561992352, "train/extr_critic_min": -0.6210071863272251, "train/extr_critic_std": 1.8798554365451519, "train/extr_return_normed_mag": 1.5336188310231917, "train/extr_return_normed_max": 1.5336188310231917, "train/extr_return_normed_mean": 0.34588643197829905, "train/extr_return_normed_min": -0.11922611624766619, "train/extr_return_normed_std": 0.329516685849581, "train/extr_return_rate": 0.6421050686102647, "train/extr_return_raw_mag": 8.720000274364764, "train/extr_return_raw_max": 8.720000274364764, "train/extr_return_raw_mean": 1.80491280739124, "train/extr_return_raw_min": -0.90315821934969, "train/extr_return_raw_std": 1.9185175204888367, "train/extr_reward_mag": 1.0316938339135586, "train/extr_reward_max": 1.0316938339135586, "train/extr_reward_mean": 0.03741087559133004, "train/extr_reward_min": -0.666802116540762, "train/extr_reward_std": 0.1910597345003715, "train/image_loss_mean": 3.889171854654948, "train/image_loss_std": 8.353373243869878, "train/model_loss_mean": 7.750634594452687, "train/model_loss_std": 12.382264535855024, "train/model_opt_grad_norm": 45.30871896988306, "train/model_opt_grad_steps": 61155.35897435898, "train/model_opt_loss": 11993.11086738782, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1544.871794871795, "train/policy_entropy_mag": 2.474192594870543, "train/policy_entropy_max": 2.474192594870543, "train/policy_entropy_mean": 0.43676494772617636, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.55861784861638, "train/policy_logprob_mag": 7.438383997403658, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.436562159886727, "train/policy_logprob_min": -7.438383997403658, "train/policy_logprob_std": 1.0363088506918687, "train/policy_randomness_mag": 0.8732814101072458, "train/policy_randomness_max": 0.8732814101072458, "train/policy_randomness_mean": 0.15415885891669837, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.19716758750952207, "train/post_ent_mag": 57.968459183130506, "train/post_ent_max": 57.968459183130506, "train/post_ent_mean": 40.08731888991136, "train/post_ent_min": 19.47539594601362, "train/post_ent_std": 6.596863044836582, "train/prior_ent_mag": 75.0813246506911, "train/prior_ent_max": 75.0813246506911, "train/prior_ent_mean": 46.41766545222356, "train/prior_ent_min": 26.784352649786534, "train/prior_ent_std": 7.765157318115234, "train/rep_loss_mean": 6.357286120683719, "train/rep_loss_std": 8.624153027167687, "train/reward_avg": 0.02797776426260288, "train/reward_loss_mean": 0.04699526254374247, "train/reward_loss_std": 0.20847238554404332, "train/reward_max_data": 1.0128205158771613, "train/reward_max_pred": 1.0110831969823593, "train/reward_neg_acc": 0.994789051092588, "train/reward_neg_loss": 0.02299391122487111, "train/reward_pos_acc": 0.9830770575083219, "train/reward_pos_loss": 0.7584589227651939, "train/reward_pred": 0.027702831314542355, "train/reward_rate": 0.032782451923076925, "train_stats/sum_log_reward": 7.0250001035630705, "train_stats/max_log_achievement_collect_coal": 0.2, "train_stats/max_log_achievement_collect_drink": 2.425, "train_stats/max_log_achievement_collect_sapling": 1.5, "train_stats/max_log_achievement_collect_stone": 5.05, "train_stats/max_log_achievement_collect_wood": 6.6, "train_stats/max_log_achievement_defeat_skeleton": 0.025, "train_stats/max_log_achievement_defeat_zombie": 0.225, "train_stats/max_log_achievement_eat_cow": 0.1, "train_stats/max_log_achievement_make_wood_pickaxe": 1.3, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 1.425, "train_stats/max_log_achievement_place_stone": 3.95, "train_stats/max_log_achievement_place_table": 2.2, "train_stats/max_log_achievement_wake_up": 1.7, "train_stats/mean_log_entropy": 0.4005451641976833, "eval_stats/sum_log_reward": 6.224999964237213, "eval_stats/max_log_achievement_collect_coal": 0.125, "eval_stats/max_log_achievement_collect_drink": 4.0, "eval_stats/max_log_achievement_collect_sapling": 1.5, "eval_stats/max_log_achievement_collect_stone": 3.125, "eval_stats/max_log_achievement_collect_wood": 7.5, "eval_stats/max_log_achievement_defeat_skeleton": 0.125, "eval_stats/max_log_achievement_defeat_zombie": 0.25, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.75, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.375, "eval_stats/max_log_achievement_place_stone": 2.75, "eval_stats/max_log_achievement_place_table": 2.375, "eval_stats/max_log_achievement_wake_up": 1.5, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 6.961432518437505e-06, "report/cont_loss_std": 9.907795902108774e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0008386379922740161, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.0596069134626305e-06, "report/cont_pred": 0.9941436052322388, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 5.995736122131348, "report/dyn_loss_std": 8.60859203338623, "report/image_loss_mean": 3.308610200881958, "report/image_loss_std": 8.47423267364502, "report/model_loss_mean": 6.947551727294922, "report/model_loss_std": 12.577974319458008, "report/post_ent_mag": 54.902339935302734, "report/post_ent_max": 54.902339935302734, "report/post_ent_mean": 39.61204147338867, "report/post_ent_min": 21.884017944335938, "report/post_ent_std": 6.525390148162842, "report/prior_ent_mag": 76.16520690917969, "report/prior_ent_max": 76.16520690917969, "report/prior_ent_mean": 45.64604949951172, "report/prior_ent_min": 22.191631317138672, "report/prior_ent_std": 7.920371055603027, "report/rep_loss_mean": 5.995736122131348, "report/rep_loss_std": 8.60859203338623, "report/reward_avg": 0.03046874888241291, "report/reward_loss_mean": 0.041492704302072525, "report/reward_loss_std": 0.161922425031662, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.004699468612671, "report/reward_neg_acc": 0.9969604015350342, "report/reward_neg_loss": 0.016754137352108955, "report/reward_pos_acc": 0.9999999403953552, "report/reward_pos_loss": 0.7014106512069702, "report/reward_pred": 0.031009795144200325, "report/reward_rate": 0.0361328125, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.0048231519758701324, "eval/cont_loss_std": 0.12539611756801605, "eval/cont_neg_acc": 0.800000011920929, "eval/cont_neg_loss": 0.8028430938720703, "eval/cont_pos_acc": 0.999018669128418, "eval/cont_pos_loss": 0.0009074503905139863, "eval/cont_pred": 0.9955611228942871, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 22.80843734741211, "eval/dyn_loss_std": 12.844846725463867, "eval/image_loss_mean": 30.423946380615234, "eval/image_loss_std": 30.076221466064453, "eval/model_loss_mean": 44.32649230957031, "eval/model_loss_std": 34.970829010009766, "eval/post_ent_mag": 54.49924850463867, "eval/post_ent_max": 54.49924850463867, "eval/post_ent_mean": 37.81797409057617, "eval/post_ent_min": 21.87190055847168, "eval/post_ent_std": 5.8154754638671875, "eval/prior_ent_mag": 76.16520690917969, "eval/prior_ent_max": 76.16520690917969, "eval/prior_ent_mean": 51.87980651855469, "eval/prior_ent_min": 31.654754638671875, "eval/prior_ent_std": 7.619963645935059, "eval/rep_loss_mean": 22.80843734741211, "eval/rep_loss_std": 12.844846725463867, "eval/reward_avg": 0.03701172024011612, "eval/reward_loss_mean": 0.21265873312950134, "eval/reward_loss_std": 1.2273634672164917, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0006413459777832, "eval/reward_neg_acc": 0.9989805817604065, "eval/reward_neg_loss": 0.07736682891845703, "eval/reward_pos_acc": 0.6511628031730652, "eval/reward_pos_loss": 3.299201488494873, "eval/reward_pred": 0.023256998509168625, "eval/reward_rate": 0.0419921875, "replay/size": 249793.0, "replay/inserts": 7808.0, "replay/samples": 31232.0, "replay/insert_wait_avg": 1.5540872929526157e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.426839505062729e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 51024.0, "eval_replay/inserts": 1808.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1253673418433266e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1001.4664211273193, "timer/env.step_count": 976.0, "timer/env.step_total": 88.72657132148743, "timer/env.step_frac": 0.08859665132018177, "timer/env.step_avg": 0.09090837225562236, "timer/env.step_min": 0.023246049880981445, "timer/env.step_max": 4.168698310852051, "timer/replay._sample_count": 31232.0, "timer/replay._sample_total": 15.564777851104736, "timer/replay._sample_frac": 0.015541986753369078, "timer/replay._sample_avg": 0.0004983599465645728, "timer/replay._sample_min": 0.00037217140197753906, "timer/replay._sample_max": 0.026302337646484375, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1202.0, "timer/agent.policy_total": 18.940154790878296, "timer/agent.policy_frac": 0.018912421216837165, "timer/agent.policy_avg": 0.01575720032518993, "timer/agent.policy_min": 0.009325504302978516, "timer/agent.policy_max": 0.0738370418548584, "timer/dataset_train_count": 1952.0, "timer/dataset_train_total": 0.3217604160308838, "timer/dataset_train_frac": 0.0003212892706564122, "timer/dataset_train_avg": 0.00016483627870434621, "timer/dataset_train_min": 9.322166442871094e-05, "timer/dataset_train_max": 0.02115654945373535, "timer/agent.train_count": 1952.0, "timer/agent.train_total": 862.0969817638397, "timer/agent.train_frac": 0.8608346356669694, "timer/agent.train_avg": 0.4416480439363933, "timer/agent.train_min": 0.43150949478149414, "timer/agent.train_max": 0.9660983085632324, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47832775115966797, "timer/agent.report_frac": 0.00047762734832509853, "timer/agent.report_avg": 0.23916387557983398, "timer/agent.report_min": 0.23208975791931152, "timer/agent.report_max": 0.24623799324035645, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0279159545898438e-05, "timer/dataset_eval_frac": 3.0234822563310846e-08, "timer/dataset_eval_avg": 3.0279159545898438e-05, "timer/dataset_eval_min": 3.0279159545898438e-05, "timer/dataset_eval_max": 3.0279159545898438e-05, "fps": 7.7964558508965425}
{"step": 250432, "time": 32367.62899494171, "episode/length": 247.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9798387096774194, "episode/intrinsic_return": 0.0}
{"step": 250616, "time": 32390.376671552658, "episode/length": 155.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 250616, "time": 32390.38501048088, "episode/length": 173.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 250648, "time": 32397.189949035645, "episode/length": 195.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 250712, "time": 32406.15959596634, "episode/length": 252.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9960474308300395, "episode/intrinsic_return": 0.0}
{"step": 250888, "time": 32428.114780426025, "episode/length": 205.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.970873786407767, "episode/intrinsic_return": 0.0}
{"step": 251640, "time": 32516.40807414055, "episode/length": 169.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 251840, "time": 32540.989124536514, "episode/length": 192.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 251904, "time": 32549.861315488815, "episode/length": 148.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.959731543624161, "episode/intrinsic_return": 0.0}
{"step": 251928, "time": 32554.161665678024, "episode/length": 163.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 251984, "time": 32562.164442539215, "episode/length": 193.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 252088, "time": 32575.570939064026, "episode/length": 179.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 252120, "time": 32581.354412794113, "episode/length": 153.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 252248, "time": 32597.913308382034, "episode/length": 203.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 252920, "time": 32677.54644012451, "episode/length": 159.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 253208, "time": 32712.442056894302, "episode/length": 162.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 253408, "time": 32736.96560692787, "episode/length": 184.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 253616, "time": 32762.53951215744, "episode/length": 190.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 253632, "time": 32765.838200092316, "episode/length": 188.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 253688, "time": 32773.91594910622, "episode/length": 212.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 254088, "time": 32822.62002444267, "episode/length": 229.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 254096, "time": 32825.01128435135, "episode/length": 281.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9893617021276596, "episode/intrinsic_return": 0.0}
{"step": 254176, "time": 32835.76042175293, "episode/length": 156.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 254520, "time": 32876.9080619812, "episode/length": 163.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 254768, "time": 32907.0600566864, "episode/length": 169.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 254912, "time": 32925.035276174545, "episode/length": 161.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 255016, "time": 32938.5651743412, "episode/length": 165.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 255440, "time": 32988.97837615013, "episode/length": 168.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9644970414201184, "episode/intrinsic_return": 0.0}
{"step": 255568, "time": 33005.184645175934, "episode/length": 241.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9834710743801653, "episode/intrinsic_return": 0.0}
{"step": 255784, "time": 33031.65802311897, "episode/length": 42.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9069767441860465, "episode/intrinsic_return": 0.0}
{"step": 255816, "time": 33036.81539225578, "episode/length": 214.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 255992, "time": 33058.60934925079, "episode/length": 183.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 256064, "time": 33068.47769641876, "episode/length": 161.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 256120, "time": 33076.478972911835, "episode/length": 150.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9735099337748344, "episode/intrinsic_return": 0.0}
{"step": 256144, "time": 33080.75659203529, "episode/length": 245.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.983739837398374, "episode/intrinsic_return": 0.0}
{"step": 256368, "time": 33108.069437503815, "episode/length": 46.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 256576, "time": 33133.56924653053, "episode/length": 56.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 256816, "time": 33162.80484294891, "episode/length": 155.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 257016, "time": 33187.29273676872, "episode/length": 149.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 257144, "time": 33203.540902376175, "episode/length": 169.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 257184, "time": 33209.71577334404, "episode/length": 270.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.981549815498155, "episode/intrinsic_return": 0.0}
{"step": 257608, "time": 33260.17371702194, "episode/length": 192.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 257832, "time": 33287.61165690422, "episode/length": 210.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 257928, "time": 33300.028395175934, "episode/length": 194.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 258056, "time": 33316.441208601, "episode/length": 154.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9612903225806452, "episode/intrinsic_return": 0.0}
{"step": 258296, "time": 33346.38863110542, "episode/length": 45.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 258325, "time": 33352.14814710617, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.516833556825249, "train/action_min": 0.0, "train/action_std": 3.125845996894647, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04766814304117243, "train/actor_opt_grad_steps": 63190.0, "train/actor_opt_loss": -13.546090996606432, "train/adv_mag": 0.517202570812026, "train/adv_max": 0.47314040444383576, "train/adv_mean": 0.002221108232469536, "train/adv_min": -0.44200215722197916, "train/adv_std": 0.05860775781433974, "train/cont_avg": 0.9943203902363185, "train/cont_loss_mean": 2.9257670015263063e-05, "train/cont_loss_std": 0.0008710192314864927, "train/cont_neg_acc": 1.0, "train/cont_neg_loss": 0.0011648535119771868, "train/cont_pos_acc": 0.9999950795031306, "train/cont_pos_loss": 2.249262218488376e-05, "train/cont_pred": 0.9943154477954503, "train/cont_rate": 0.9943203902363185, "train/dyn_loss_mean": 6.248573141904613, "train/dyn_loss_std": 8.702995715449699, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1685452357453494, "train/extr_critic_critic_opt_grad_steps": 63190.0, "train/extr_critic_critic_opt_loss": 16851.439302510884, "train/extr_critic_mag": 7.96212558366766, "train/extr_critic_max": 7.96212558366766, "train/extr_critic_mean": 1.830193851717669, "train/extr_critic_min": -0.643050387724122, "train/extr_critic_std": 1.9383690932496864, "train/extr_return_normed_mag": 1.5345296919049316, "train/extr_return_normed_max": 1.5345296919049316, "train/extr_return_normed_mean": 0.35394638050254895, "train/extr_return_normed_min": -0.12083979110367855, "train/extr_return_normed_std": 0.3364320415910797, "train/extr_return_rate": 0.6402561108567821, "train/extr_return_raw_mag": 8.769798696337647, "train/extr_return_raw_max": 8.769798696337647, "train/extr_return_raw_mean": 1.8432167519384355, "train/extr_return_raw_min": -0.9421490629514059, "train/extr_return_raw_std": 1.9739556448969675, "train/extr_reward_mag": 1.025047860928436, "train/extr_reward_max": 1.025047860928436, "train/extr_reward_mean": 0.039998324764012105, "train/extr_reward_min": -0.6929443244317278, "train/extr_reward_std": 0.1968532156440156, "train/image_loss_mean": 3.7949035084662746, "train/image_loss_std": 8.236165466593272, "train/model_loss_mean": 7.59231891916759, "train/model_loss_std": 12.325186240732373, "train/model_opt_grad_norm": 46.30275995814385, "train/model_opt_grad_steps": 63133.50746268657, "train/model_opt_loss": 9564.851977903452, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1262.4378109452737, "train/policy_entropy_mag": 2.489658237096682, "train/policy_entropy_max": 2.489658237096682, "train/policy_entropy_mean": 0.4408628421636363, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.5661388420643498, "train/policy_logprob_mag": 7.438384011017149, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.4407019781236032, "train/policy_logprob_min": -7.438384011017149, "train/policy_logprob_std": 1.0418242382172922, "train/policy_randomness_mag": 0.8787401033871209, "train/policy_randomness_max": 0.8787401033871209, "train/policy_randomness_mean": 0.15560523668924967, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.1998221682227073, "train/post_ent_mag": 58.11721982054449, "train/post_ent_max": 58.11721982054449, "train/post_ent_mean": 40.239984483861214, "train/post_ent_min": 19.329565479980772, "train/post_ent_std": 6.660519932039935, "train/prior_ent_mag": 75.1409683227539, "train/prior_ent_max": 75.1409683227539, "train/prior_ent_mean": 46.46891629043503, "train/prior_ent_min": 26.320080315888816, "train/prior_ent_std": 7.836764487461071, "train/rep_loss_mean": 6.248573141904613, "train/rep_loss_std": 8.702995715449699, "train/reward_avg": 0.029538829064932628, "train/reward_loss_mean": 0.048242300860027766, "train/reward_loss_std": 0.20582703067295588, "train/reward_max_data": 1.009950251128543, "train/reward_max_pred": 1.0089604480942684, "train/reward_neg_acc": 0.9949863493739076, "train/reward_neg_loss": 0.023205289969322692, "train/reward_pos_acc": 0.9842395079669668, "train/reward_pos_loss": 0.7468706553255148, "train/reward_pred": 0.029173859362652647, "train/reward_rate": 0.03461695429104478, "train_stats/sum_log_reward": 6.947826188543568, "train_stats/max_log_achievement_collect_coal": 0.17391304347826086, "train_stats/max_log_achievement_collect_drink": 2.347826086956522, "train_stats/max_log_achievement_collect_sapling": 1.7826086956521738, "train_stats/max_log_achievement_collect_stone": 5.391304347826087, "train_stats/max_log_achievement_collect_wood": 6.934782608695652, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.08695652173913043, "train_stats/max_log_achievement_eat_cow": 0.021739130434782608, "train_stats/max_log_achievement_make_wood_pickaxe": 1.2391304347826086, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 1.673913043478261, "train_stats/max_log_achievement_place_stone": 3.9130434782608696, "train_stats/max_log_achievement_place_table": 2.5434782608695654, "train_stats/max_log_achievement_wake_up": 1.3478260869565217, "train_stats/mean_log_entropy": 0.34609359535186185, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0625, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 7.646025323992944e-07, "report/cont_loss_std": 1.6615600543445908e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 2.739380761340726e-06, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 7.529633876401931e-07, "report/cont_pred": 0.9941399097442627, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 7.346610069274902, "report/dyn_loss_std": 9.633024215698242, "report/image_loss_mean": 5.989840507507324, "report/image_loss_std": 13.634992599487305, "report/model_loss_mean": 10.45954418182373, "report/model_loss_std": 18.020523071289062, "report/post_ent_mag": 59.258453369140625, "report/post_ent_max": 59.258453369140625, "report/post_ent_mean": 39.80699920654297, "report/post_ent_min": 21.02989959716797, "report/post_ent_std": 6.741580009460449, "report/prior_ent_mag": 75.28059387207031, "report/prior_ent_max": 75.28059387207031, "report/prior_ent_mean": 47.142723083496094, "report/prior_ent_min": 27.496402740478516, "report/prior_ent_std": 7.819214820861816, "report/rep_loss_mean": 7.346610069274902, "report/rep_loss_std": 9.633024215698242, "report/reward_avg": 0.02851562388241291, "report/reward_loss_mean": 0.06173703074455261, "report/reward_loss_std": 0.4043397605419159, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.005958080291748, "report/reward_neg_acc": 0.9939393401145935, "report/reward_neg_loss": 0.02704099379479885, "report/reward_pos_acc": 0.9117646813392639, "report/reward_pos_loss": 1.072003960609436, "report/reward_pred": 0.02754853293299675, "report/reward_rate": 0.033203125, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 4.7591955080861226e-05, "eval/cont_loss_std": 0.0015176133019849658, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.01619824580848217, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.3656166686359938e-07, "eval/cont_pred": 0.9971165060997009, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 19.54245376586914, "eval/dyn_loss_std": 13.567161560058594, "eval/image_loss_mean": 22.13326644897461, "eval/image_loss_std": 26.504274368286133, "eval/model_loss_mean": 33.970436096191406, "eval/model_loss_std": 31.779348373413086, "eval/post_ent_mag": 57.963497161865234, "eval/post_ent_max": 57.963497161865234, "eval/post_ent_mean": 38.84345245361328, "eval/post_ent_min": 20.184518814086914, "eval/post_ent_std": 7.501644134521484, "eval/prior_ent_mag": 75.28059387207031, "eval/prior_ent_max": 75.28059387207031, "eval/prior_ent_mean": 50.66908645629883, "eval/prior_ent_min": 32.71247100830078, "eval/prior_ent_std": 7.948875427246094, "eval/rep_loss_mean": 19.54245376586914, "eval/rep_loss_std": 13.567161560058594, "eval/reward_avg": 0.0302734375, "eval/reward_loss_mean": 0.11165264248847961, "eval/reward_loss_std": 0.7747222781181335, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0041289329528809, "eval/reward_neg_acc": 0.9959595203399658, "eval/reward_neg_loss": 0.03752026706933975, "eval/reward_pos_acc": 0.7647058963775635, "eval/reward_pos_loss": 2.2702128887176514, "eval/reward_pred": 0.023121703416109085, "eval/reward_rate": 0.033203125, "replay/size": 257821.0, "replay/inserts": 8028.0, "replay/samples": 32112.0, "replay/insert_wait_avg": 1.5300604378814773e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.396009827230365e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 51024.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1116232872009, "timer/env.step_count": 1003.0, "timer/env.step_total": 96.70758295059204, "timer/env.step_frac": 0.09669678933710446, "timer/env.step_avg": 0.09641832796669196, "timer/env.step_min": 0.0229794979095459, "timer/env.step_max": 3.1449389457702637, "timer/replay._sample_count": 32112.0, "timer/replay._sample_total": 15.931662559509277, "timer/replay._sample_frac": 0.015929884413446317, "timer/replay._sample_avg": 0.0004961280069603038, "timer/replay._sample_min": 0.00037169456481933594, "timer/replay._sample_max": 0.029877662658691406, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1003.0, "timer/agent.policy_total": 15.849875450134277, "timer/agent.policy_frac": 0.01584810643239838, "timer/agent.policy_avg": 0.01580246804599629, "timer/agent.policy_min": 0.009552717208862305, "timer/agent.policy_max": 0.09511446952819824, "timer/dataset_train_count": 2007.0, "timer/dataset_train_total": 0.3974461555480957, "timer/dataset_train_frac": 0.00039740179625325834, "timer/dataset_train_avg": 0.00019802997286900634, "timer/dataset_train_min": 9.250640869140625e-05, "timer/dataset_train_max": 0.09336352348327637, "timer/agent.train_count": 2007.0, "timer/agent.train_total": 884.3758041858673, "timer/agent.train_frac": 0.884277098269362, "timer/agent.train_avg": 0.4406456423447271, "timer/agent.train_min": 0.4273219108581543, "timer/agent.train_max": 0.9542350769042969, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4768376350402832, "timer/agent.report_frac": 0.0004767844147966174, "timer/agent.report_avg": 0.2384188175201416, "timer/agent.report_min": 0.23222064971923828, "timer/agent.report_max": 0.24461698532104492, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7894973754882812e-05, "timer/dataset_eval_frac": 2.7891860373741745e-08, "timer/dataset_eval_avg": 2.7894973754882812e-05, "timer/dataset_eval_min": 2.7894973754882812e-05, "timer/dataset_eval_max": 2.7894973754882812e-05, "fps": 8.026985461810353}
{"step": 258408, "time": 33361.64924740791, "episode/length": 152.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.0}
{"step": 258464, "time": 33369.602452754974, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9575757575757575, "episode/intrinsic_return": 0.0}
{"step": 258712, "time": 33400.182535648346, "episode/length": 266.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9812734082397003, "episode/intrinsic_return": 0.0}
{"step": 258728, "time": 33403.658541440964, "episode/length": 213.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9719626168224299, "episode/intrinsic_return": 0.0}
{"step": 259024, "time": 33439.57404208183, "episode/length": 148.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 259048, "time": 33443.82924199104, "episode/length": 179.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 259536, "time": 33502.0561234951, "episode/length": 140.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9574468085106383, "episode/intrinsic_return": 0.0}
{"step": 259592, "time": 33510.05511426926, "episode/length": 191.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 259864, "time": 33543.25765872002, "episode/length": 174.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 260000, "time": 33578.638971567154, "eval_episode/length": 147.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9594594594594594}
{"step": 260000, "time": 33581.130328178406, "eval_episode/length": 167.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9940476190476191}
{"step": 260000, "time": 33582.85774111748, "eval_episode/length": 172.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9653179190751445}
{"step": 260000, "time": 33584.588742733, "eval_episode/length": 179.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 260000, "time": 33588.085618019104, "eval_episode/length": 229.0, "eval_episode/score": 6.099999971687794, "eval_episode/reward_rate": 0.9956521739130435}
{"step": 260000, "time": 33590.52149295807, "eval_episode/length": 251.0, "eval_episode/score": 9.099999994039536, "eval_episode/reward_rate": 0.996031746031746}
{"step": 260000, "time": 33594.234637498856, "eval_episode/length": 158.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9685534591194969}
{"step": 260000, "time": 33596.47044801712, "eval_episode/length": 159.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.975}
{"step": 260024, "time": 33599.24008536339, "episode/length": 163.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 260288, "time": 33631.28066945076, "episode/length": 154.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 260312, "time": 33635.51573395729, "episode/length": 251.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9801587301587301, "episode/intrinsic_return": 0.0}
{"step": 260320, "time": 33637.88704109192, "episode/length": 198.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 260480, "time": 33658.31536602974, "episode/length": 181.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 260984, "time": 33718.9363052845, "episode/length": 173.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9540229885057471, "episode/intrinsic_return": 0.0}
{"step": 261064, "time": 33730.46013379097, "episode/length": 190.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9842931937172775, "episode/intrinsic_return": 0.0}
{"step": 261240, "time": 33752.964898109436, "episode/length": 171.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 261720, "time": 33810.93022489548, "episode/length": 175.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 261840, "time": 33826.50544857979, "episode/length": 193.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 261864, "time": 33830.81348490715, "episode/length": 192.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 262112, "time": 33861.248801231384, "episode/length": 260.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 262304, "time": 33886.22174191475, "episode/length": 154.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 262328, "time": 33891.0617184639, "episode/length": 167.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 262640, "time": 33929.21882915497, "episode/length": 174.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 262816, "time": 33951.190128088, "episode/length": 291.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9794520547945206, "episode/intrinsic_return": 0.0}
{"step": 262824, "time": 33953.70818018913, "episode/length": 137.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9637681159420289, "episode/intrinsic_return": 0.0}
{"step": 262864, "time": 33959.87437272072, "episode/length": 127.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.953125, "episode/intrinsic_return": 0.0}
{"step": 263288, "time": 34010.641542196274, "episode/length": 146.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 263288, "time": 34010.650235414505, "episode/length": 177.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 263568, "time": 34046.332993507385, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 263664, "time": 34058.944294929504, "episode/length": 166.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 264184, "time": 34121.16385316849, "episode/length": 164.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 264208, "time": 34125.537826538086, "episode/length": 172.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9826589595375722, "episode/intrinsic_return": 0.0}
{"step": 264384, "time": 34148.03536891937, "episode/length": 217.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9724770642201835, "episode/intrinsic_return": 0.0}
{"step": 264456, "time": 34157.96732926369, "episode/length": 98.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.98989898989899, "episode/intrinsic_return": 0.0}
{"step": 264528, "time": 34167.85346221924, "episode/length": 213.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 264576, "time": 34174.90963578224, "episode/length": 160.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9627329192546584, "episode/intrinsic_return": 0.0}
{"step": 264608, "time": 34180.24592065811, "episode/length": 52.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 265016, "time": 34229.46614718437, "episode/length": 180.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9668508287292817, "episode/intrinsic_return": 0.0}
{"step": 265272, "time": 34260.812639951706, "episode/length": 110.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9459459459459459, "episode/intrinsic_return": 0.0}
{"step": 265720, "time": 34314.63262295723, "episode/length": 303.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9967105263157895, "episode/intrinsic_return": 0.0}
{"step": 265736, "time": 34317.97851514816, "episode/length": 144.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 265744, "time": 34320.44739532471, "episode/length": 141.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 265997, "time": 34352.27660155296, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.557291666666667, "train/action_min": 0.0, "train/action_std": 3.2336063583691916, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0469240895860518, "train/actor_opt_grad_steps": 65155.0, "train/actor_opt_loss": -12.22355513938237, "train/adv_mag": 0.48597535273681086, "train/adv_max": 0.45673966438819963, "train/adv_mean": 0.002718891439937939, "train/adv_min": -0.39818626875057817, "train/adv_std": 0.05785045918310061, "train/cont_avg": 0.9944915771484375, "train/cont_loss_mean": 0.00013390432452438836, "train/cont_loss_std": 0.004027338407308401, "train/cont_neg_acc": 0.9965939158573747, "train/cont_neg_loss": 0.015235105549573783, "train/cont_pos_acc": 0.9999897688006362, "train/cont_pos_loss": 5.241025160572973e-05, "train/cont_pred": 0.9944976906602582, "train/cont_rate": 0.9944915771484375, "train/dyn_loss_mean": 6.3033663133780165, "train/dyn_loss_std": 8.734761337439219, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.2099147972961266, "train/extr_critic_critic_opt_grad_steps": 65155.0, "train/extr_critic_critic_opt_loss": 17112.598841349285, "train/extr_critic_mag": 8.074399506052336, "train/extr_critic_max": 8.074399506052336, "train/extr_critic_mean": 1.7610705103725195, "train/extr_critic_min": -0.6325692894558111, "train/extr_critic_std": 1.9353593612710636, "train/extr_return_normed_mag": 1.5305560336758692, "train/extr_return_normed_max": 1.5305560336758692, "train/extr_return_normed_mean": 0.340105058082069, "train/extr_return_normed_min": -0.12011415825691074, "train/extr_return_normed_std": 0.33286257398625213, "train/extr_return_rate": 0.6229634933794538, "train/extr_return_raw_mag": 8.816880901654562, "train/extr_return_raw_max": 8.816880901654562, "train/extr_return_raw_mean": 1.7771277104814847, "train/extr_return_raw_min": -0.9455635792886218, "train/extr_return_raw_std": 1.968802581851681, "train/extr_reward_mag": 1.0330821896592777, "train/extr_reward_max": 1.0330821896592777, "train/extr_reward_mean": 0.038971442729234695, "train/extr_reward_min": -0.6779101826250553, "train/extr_reward_std": 0.1948135371785611, "train/image_loss_mean": 3.907940451055765, "train/image_loss_std": 8.663226336240768, "train/model_loss_mean": 7.7376780559619265, "train/model_loss_std": 12.738716940085093, "train/model_opt_grad_norm": 45.31503703196844, "train/model_opt_grad_steps": 65096.552083333336, "train/model_opt_loss": 9869.879521687826, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1269.53125, "train/policy_entropy_mag": 2.481097118308147, "train/policy_entropy_max": 2.481097118308147, "train/policy_entropy_mean": 0.4501989165631433, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.58038335867847, "train/policy_logprob_mag": 7.438384028772513, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.4504789205578466, "train/policy_logprob_min": -7.438384028772513, "train/policy_logprob_std": 1.0496370662003756, "train/policy_randomness_mag": 0.8757184036076069, "train/policy_randomness_max": 0.8757184036076069, "train/policy_randomness_mean": 0.15890046088801077, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.20484985675041875, "train/post_ent_mag": 58.38242427508036, "train/post_ent_max": 58.38242427508036, "train/post_ent_mean": 40.48647904396057, "train/post_ent_min": 19.573472032944363, "train/post_ent_std": 6.668201910952727, "train/prior_ent_mag": 75.12908887863159, "train/prior_ent_max": 75.12908887863159, "train/prior_ent_mean": 46.76906442642212, "train/prior_ent_min": 27.275727262099583, "train/prior_ent_std": 7.7494184871514635, "train/rep_loss_mean": 6.3033663133780165, "train/rep_loss_std": 8.734761337439219, "train/reward_avg": 0.027743021385200944, "train/reward_loss_mean": 0.04758390875455613, "train/reward_loss_std": 0.20832652606380483, "train/reward_max_data": 1.011458336065213, "train/reward_max_pred": 1.0114101537813742, "train/reward_neg_acc": 0.9949266013378898, "train/reward_neg_loss": 0.023615319112044137, "train/reward_pos_acc": 0.9830248383805156, "train/reward_pos_loss": 0.7566915238276124, "train/reward_pred": 0.027427341357300367, "train/reward_rate": 0.0327301025390625, "train_stats/sum_log_reward": 7.146511709967325, "train_stats/max_log_achievement_collect_coal": 0.3023255813953488, "train_stats/max_log_achievement_collect_drink": 2.6744186046511627, "train_stats/max_log_achievement_collect_sapling": 1.744186046511628, "train_stats/max_log_achievement_collect_stone": 4.6976744186046515, "train_stats/max_log_achievement_collect_wood": 6.27906976744186, "train_stats/max_log_achievement_defeat_skeleton": 0.046511627906976744, "train_stats/max_log_achievement_defeat_zombie": 0.23255813953488372, "train_stats/max_log_achievement_eat_cow": 0.046511627906976744, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.2325581395348837, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 1.6046511627906976, "train_stats/max_log_achievement_place_stone": 3.9767441860465116, "train_stats/max_log_achievement_place_table": 2.2093023255813953, "train_stats/max_log_achievement_wake_up": 1.3255813953488371, "train_stats/mean_log_entropy": 0.325475504578546, "eval_stats/sum_log_reward": 7.225000083446503, "eval_stats/max_log_achievement_collect_coal": 0.125, "eval_stats/max_log_achievement_collect_drink": 0.875, "eval_stats/max_log_achievement_collect_sapling": 1.625, "eval_stats/max_log_achievement_collect_stone": 6.125, "eval_stats/max_log_achievement_collect_wood": 5.625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.375, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.125, "eval_stats/max_log_achievement_place_plant": 1.625, "eval_stats/max_log_achievement_place_stone": 5.25, "eval_stats/max_log_achievement_place_table": 1.625, "eval_stats/max_log_achievement_wake_up": 1.375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 2.2818403522251174e-05, "report/cont_loss_std": 0.0003469125949777663, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.442450320610078e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 2.287617462570779e-05, "report/cont_pred": 0.9931415319442749, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 7.041814804077148, "report/dyn_loss_std": 9.790802955627441, "report/image_loss_mean": 5.903645038604736, "report/image_loss_std": 12.905638694763184, "report/model_loss_mean": 10.191973686218262, "report/model_loss_std": 17.721994400024414, "report/post_ent_mag": 59.17747497558594, "report/post_ent_max": 59.17747497558594, "report/post_ent_mean": 41.26502227783203, "report/post_ent_min": 17.225248336791992, "report/post_ent_std": 6.857997894287109, "report/prior_ent_mag": 75.59545135498047, "report/prior_ent_max": 75.59545135498047, "report/prior_ent_mean": 48.40650939941406, "report/prior_ent_min": 26.80719757080078, "report/prior_ent_std": 8.042947769165039, "report/rep_loss_mean": 7.041814804077148, "report/rep_loss_std": 9.790802955627441, "report/reward_avg": 0.02822265401482582, "report/reward_loss_mean": 0.06321664154529572, "report/reward_loss_std": 0.29081758856773376, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0013766288757324, "report/reward_neg_acc": 0.9979757070541382, "report/reward_neg_loss": 0.026095842942595482, "report/reward_pos_acc": 0.8888888955116272, "report/reward_pos_loss": 1.0819764137268066, "report/reward_pred": 0.023751676082611084, "report/reward_rate": 0.03515625, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 6.252633284020703e-06, "eval/cont_loss_std": 4.6685679990332574e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 6.025768016115762e-06, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 6.253077572182519e-06, "eval/cont_pred": 0.9980406761169434, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 20.26093101501465, "eval/dyn_loss_std": 13.990925788879395, "eval/image_loss_mean": 23.388904571533203, "eval/image_loss_std": 30.323383331298828, "eval/model_loss_mean": 35.62098693847656, "eval/model_loss_std": 36.039703369140625, "eval/post_ent_mag": 55.52383804321289, "eval/post_ent_max": 55.52383804321289, "eval/post_ent_mean": 38.402366638183594, "eval/post_ent_min": 20.134052276611328, "eval/post_ent_std": 6.465345859527588, "eval/prior_ent_mag": 75.59545135498047, "eval/prior_ent_max": 75.59545135498047, "eval/prior_ent_mean": 51.17714309692383, "eval/prior_ent_min": 38.018035888671875, "eval/prior_ent_std": 6.048251152038574, "eval/rep_loss_mean": 20.26093101501465, "eval/rep_loss_std": 13.990925788879395, "eval/reward_avg": 0.02021484449505806, "eval/reward_loss_mean": 0.0755174532532692, "eval/reward_loss_std": 0.5935247540473938, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.000521183013916, "eval/reward_neg_acc": 0.9920079708099365, "eval/reward_neg_loss": 0.022436143830418587, "eval/reward_pos_acc": 0.695652186870575, "eval/reward_pos_loss": 2.3857083320617676, "eval/reward_pred": 0.015396376140415668, "eval/reward_rate": 0.0224609375, "replay/size": 265493.0, "replay/inserts": 7672.0, "replay/samples": 30688.0, "replay/insert_wait_avg": 1.4722160800778704e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.225975503016563e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 53648.0, "eval_replay/inserts": 2624.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0993240810022122e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.450580596923828e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1146125793457, "timer/env.step_count": 959.0, "timer/env.step_total": 92.8060610294342, "timer/env.step_frac": 0.09279542550636544, "timer/env.step_avg": 0.09677378626635474, "timer/env.step_min": 0.023141145706176758, "timer/env.step_max": 3.1447794437408447, "timer/replay._sample_count": 30688.0, "timer/replay._sample_total": 14.919053792953491, "timer/replay._sample_frac": 0.014917344077671762, "timer/replay._sample_avg": 0.0004861526913762217, "timer/replay._sample_min": 0.0003859996795654297, "timer/replay._sample_max": 0.010409832000732422, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1287.0, "timer/agent.policy_total": 20.173352003097534, "timer/agent.policy_frac": 0.020171040148158067, "timer/agent.policy_avg": 0.015674710181116967, "timer/agent.policy_min": 0.009306669235229492, "timer/agent.policy_max": 0.06754541397094727, "timer/dataset_train_count": 1918.0, "timer/dataset_train_total": 0.34302282333374023, "timer/dataset_train_frac": 0.0003429835131086298, "timer/dataset_train_avg": 0.00017884401633667374, "timer/dataset_train_min": 8.7738037109375e-05, "timer/dataset_train_max": 0.06354689598083496, "timer/agent.train_count": 1918.0, "timer/agent.train_total": 853.2705612182617, "timer/agent.train_frac": 0.8531727768856753, "timer/agent.train_avg": 0.4448751622618674, "timer/agent.train_min": 0.42432117462158203, "timer/agent.train_max": 0.9490611553192139, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4768705368041992, "timer/agent.report_frac": 0.0004768158877054363, "timer/agent.report_avg": 0.2384352684020996, "timer/agent.report_min": 0.23053956031799316, "timer/agent.report_max": 0.24633097648620605, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7418136596679688e-05, "timer/dataset_eval_frac": 2.7414994493448046e-08, "timer/dataset_eval_avg": 2.7418136596679688e-05, "timer/dataset_eval_min": 2.7418136596679688e-05, "timer/dataset_eval_max": 2.7418136596679688e-05, "fps": 7.671024753118204}
{"step": 266064, "time": 34359.99279332161, "episode/length": 200.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9800995024875622, "episode/intrinsic_return": 0.0}
{"step": 266128, "time": 34368.90235924721, "episode/length": 199.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 266176, "time": 34376.03998088837, "episode/length": 54.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 266312, "time": 34393.4430372715, "episode/length": 161.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 266688, "time": 34438.6799724102, "episode/length": 69.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9285714285714286, "episode/intrinsic_return": 0.0}
{"step": 266704, "time": 34442.41164183617, "episode/length": 178.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 266792, "time": 34454.290371418, "episode/length": 59.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 266848, "time": 34462.35548424721, "episode/length": 329.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.990909090909091, "episode/intrinsic_return": 0.0}
{"step": 266928, "time": 34473.31107878685, "episode/length": 147.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 267024, "time": 34486.12190890312, "episode/length": 39.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 267400, "time": 34531.81472301483, "episode/length": 166.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 267672, "time": 34564.934911966324, "episode/length": 186.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 268048, "time": 34610.23214554787, "episode/length": 169.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 268160, "time": 34624.80174732208, "episode/length": 153.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 268240, "time": 34635.599328279495, "episode/length": 180.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 268576, "time": 34676.578204631805, "episode/length": 193.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 268696, "time": 34692.10166335106, "episode/length": 161.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 268816, "time": 34707.56446027756, "episode/length": 245.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.983739837398374, "episode/intrinsic_return": 0.0}
{"step": 269160, "time": 34749.0287797451, "episode/length": 429.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9790697674418605, "episode/intrinsic_return": 0.0}
{"step": 269224, "time": 34758.15180039406, "episode/length": 146.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9523809523809523, "episode/intrinsic_return": 0.0}
{"step": 269848, "time": 34832.569222450256, "episode/length": 210.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 269864, "time": 34835.91254115105, "episode/length": 160.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 269944, "time": 34846.66158413887, "episode/length": 283.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9859154929577465, "episode/intrinsic_return": 0.0}
{"step": 270008, "time": 34855.5953810215, "episode/length": 220.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 270088, "time": 34884.954173088074, "eval_episode/length": 158.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9622641509433962}
{"step": 270088, "time": 34887.38258957863, "eval_episode/length": 178.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9720670391061452}
{"step": 270088, "time": 34889.065991163254, "eval_episode/length": 181.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.967032967032967}
{"step": 270088, "time": 34890.845645189285, "eval_episode/length": 187.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.973404255319149}
{"step": 270088, "time": 34892.54181480408, "eval_episode/length": 192.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9740932642487047}
{"step": 270088, "time": 34894.09219503403, "eval_episode/length": 193.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9742268041237113}
{"step": 270088, "time": 34895.91368889809, "eval_episode/length": 203.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9950980392156863}
{"step": 270088, "time": 34897.742428302765, "eval_episode/length": 213.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9766355140186916}
{"step": 270096, "time": 34898.676924943924, "episode/length": 174.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 270104, "time": 34901.25346779823, "episode/length": 160.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 270552, "time": 34956.152601480484, "episode/length": 173.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 270776, "time": 34983.70238947868, "episode/length": 193.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 271248, "time": 35040.60655713081, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 271272, "time": 35044.85967922211, "episode/length": 175.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 271288, "time": 35048.27314162254, "episode/length": 179.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 271320, "time": 35053.60854625702, "episode/length": 163.0, "episode/score": 10.100000016391277, "episode/reward_rate": 0.9817073170731707, "episode/intrinsic_return": 0.0}
{"step": 271584, "time": 35085.822424173355, "episode/length": 184.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 271624, "time": 35091.99154353142, "episode/length": 190.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 271720, "time": 35104.68973040581, "episode/length": 145.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 272600, "time": 35208.78567624092, "episode/length": 121.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9918032786885246, "episode/intrinsic_return": 0.0}
{"step": 272624, "time": 35213.171432733536, "episode/length": 171.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 272632, "time": 35215.52410387993, "episode/length": 231.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 272904, "time": 35248.739161491394, "episode/length": 164.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 273032, "time": 35265.20762872696, "episode/length": 213.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 273104, "time": 35275.007229328156, "episode/length": 226.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.973568281938326, "episode/intrinsic_return": 0.0}
{"step": 273200, "time": 35287.716854810715, "episode/length": 184.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9675675675675676, "episode/intrinsic_return": 0.0}
{"step": 273737, "time": 35352.63956975937, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.543712240426651, "train/action_min": 0.0, "train/action_std": 3.156607903347114, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.046563926350730686, "train/actor_opt_grad_steps": 67080.0, "train/actor_opt_loss": -11.699862296948778, "train/adv_mag": 0.488299771294075, "train/adv_max": 0.4531106925690112, "train/adv_mean": 0.0028618406441434856, "train/adv_min": -0.40785237807066327, "train/adv_std": 0.05758374251927119, "train/cont_avg": 0.9947731136658031, "train/cont_loss_mean": 7.239308775276782e-05, "train/cont_loss_std": 0.0021130513498775812, "train/cont_neg_acc": 0.9979274612634293, "train/cont_neg_loss": 0.0048450177613421535, "train/cont_pos_acc": 0.9999898023555933, "train/cont_pos_loss": 4.8391431521015194e-05, "train/cont_pred": 0.9947588913181286, "train/cont_rate": 0.9947731136658031, "train/dyn_loss_mean": 6.377480210417911, "train/dyn_loss_std": 8.797330087948339, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1531722795777988, "train/extr_critic_critic_opt_grad_steps": 67080.0, "train/extr_critic_critic_opt_loss": 16968.799622530765, "train/extr_critic_mag": 7.971303332037259, "train/extr_critic_max": 7.971303332037259, "train/extr_critic_mean": 1.7642114897466077, "train/extr_critic_min": -0.6281245403339208, "train/extr_critic_std": 1.880273856647274, "train/extr_return_normed_mag": 1.5410990980622683, "train/extr_return_normed_max": 1.5410990980622683, "train/extr_return_normed_mean": 0.34583832501129785, "train/extr_return_normed_min": -0.12471881033997462, "train/extr_return_normed_std": 0.3285112037405449, "train/extr_return_rate": 0.6393748983509182, "train/extr_return_raw_mag": 8.747455717986112, "train/extr_return_raw_max": 8.747455717986112, "train/extr_return_raw_mean": 1.780892186214269, "train/extr_return_raw_min": -0.9621480419228114, "train/extr_return_raw_std": 1.914904428269579, "train/extr_reward_mag": 1.0316760577068427, "train/extr_reward_max": 1.0316760577068427, "train/extr_reward_mean": 0.03948654298588556, "train/extr_reward_min": -0.6749253594195904, "train/extr_reward_std": 0.19580269338553433, "train/image_loss_mean": 3.8202239627047523, "train/image_loss_std": 8.47246998455858, "train/model_loss_mean": 7.693653618115835, "train/model_loss_std": 12.612776123797955, "train/model_opt_grad_norm": 43.43592125887698, "train/model_opt_grad_steps": 67019.89119170984, "train/model_opt_loss": 11444.188570170823, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1476.6839378238342, "train/policy_entropy_mag": 2.480938309832558, "train/policy_entropy_max": 2.480938309832558, "train/policy_entropy_mean": 0.4339560041773505, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.5692863240452011, "train/policy_logprob_mag": 7.438384014090108, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.43289003424693884, "train/policy_logprob_min": -7.438384014090108, "train/policy_logprob_std": 1.0350325280520583, "train/policy_randomness_mag": 0.8756623493575062, "train/policy_randomness_max": 0.8756623493575062, "train/policy_randomness_mean": 0.15316742481036508, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.20093309076338853, "train/post_ent_mag": 58.18762740693562, "train/post_ent_max": 58.18762740693562, "train/post_ent_mean": 40.55980737715805, "train/post_ent_min": 19.524255134898763, "train/post_ent_std": 6.66664797036759, "train/prior_ent_mag": 75.15714133465228, "train/prior_ent_max": 75.15714133465228, "train/prior_ent_mean": 46.91078510185597, "train/prior_ent_min": 27.24886692620312, "train/prior_ent_std": 7.694051935265101, "train/rep_loss_mean": 6.377480210417911, "train/rep_loss_std": 8.797330087948339, "train/reward_avg": 0.028381030972796092, "train/reward_loss_mean": 0.0468691898500209, "train/reward_loss_std": 0.20205978717210996, "train/reward_max_data": 1.0113989664482947, "train/reward_max_pred": 1.0101206401469176, "train/reward_neg_acc": 0.9948451009439063, "train/reward_neg_loss": 0.022649704010607046, "train/reward_pos_acc": 0.983238174507655, "train/reward_pos_loss": 0.7538484649954682, "train/reward_pred": 0.02808990676940414, "train/reward_rate": 0.03314746599740933, "train_stats/sum_log_reward": 6.671428686096554, "train_stats/max_log_achievement_collect_coal": 0.19047619047619047, "train_stats/max_log_achievement_collect_drink": 2.9285714285714284, "train_stats/max_log_achievement_collect_sapling": 1.9047619047619047, "train_stats/max_log_achievement_collect_stone": 3.9761904761904763, "train_stats/max_log_achievement_collect_wood": 5.761904761904762, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.23809523809523808, "train_stats/max_log_achievement_eat_cow": 0.11904761904761904, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.0952380952380953, "train_stats/max_log_achievement_make_wood_sword": 0.023809523809523808, "train_stats/max_log_achievement_place_furnace": 0.023809523809523808, "train_stats/max_log_achievement_place_plant": 1.6904761904761905, "train_stats/max_log_achievement_place_stone": 3.0952380952380953, "train_stats/max_log_achievement_place_table": 1.9523809523809523, "train_stats/max_log_achievement_wake_up": 1.6904761904761905, "train_stats/mean_log_entropy": 0.34690130076238085, "eval_stats/sum_log_reward": 7.600000083446503, "eval_stats/max_log_achievement_collect_coal": 0.625, "eval_stats/max_log_achievement_collect_drink": 4.625, "eval_stats/max_log_achievement_collect_sapling": 2.25, "eval_stats/max_log_achievement_collect_stone": 7.125, "eval_stats/max_log_achievement_collect_wood": 7.125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.125, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.25, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 2.125, "eval_stats/max_log_achievement_place_stone": 4.375, "eval_stats/max_log_achievement_place_table": 2.25, "eval_stats/max_log_achievement_wake_up": 1.5, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 1.3814527846989222e-05, "report/cont_loss_std": 0.00012540194438770413, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 8.955338125815615e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 1.3293217307364102e-05, "report/cont_pred": 0.9931515455245972, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 5.05604362487793, "report/dyn_loss_std": 7.646174430847168, "report/image_loss_mean": 4.164184093475342, "report/image_loss_std": 6.7407307624816895, "report/model_loss_mean": 7.2409820556640625, "report/model_loss_std": 9.819634437561035, "report/post_ent_mag": 60.32145309448242, "report/post_ent_max": 60.32145309448242, "report/post_ent_mean": 40.69542694091797, "report/post_ent_min": 22.01051902770996, "report/post_ent_std": 7.256759166717529, "report/prior_ent_mag": 74.92851257324219, "report/prior_ent_max": 74.92851257324219, "report/prior_ent_mean": 46.03961181640625, "report/prior_ent_min": 29.035110473632812, "report/prior_ent_std": 8.01160717010498, "report/rep_loss_mean": 5.05604362487793, "report/rep_loss_std": 7.646174430847168, "report/reward_avg": 0.02207031287252903, "report/reward_loss_mean": 0.04315797612071037, "report/reward_loss_std": 0.17606280744075775, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0029196739196777, "report/reward_neg_acc": 0.9929648041725159, "report/reward_neg_loss": 0.022356946021318436, "report/reward_pos_acc": 0.9655172228813171, "report/reward_pos_loss": 0.7568485736846924, "report/reward_pred": 0.02124853990972042, "report/reward_rate": 0.0283203125, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.0004911221913062036, "eval/cont_loss_std": 0.015383186750113964, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 2.300921914866194e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0004924976383335888, "eval/cont_pred": 0.996680498123169, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 20.600082397460938, "eval/dyn_loss_std": 13.46248722076416, "eval/image_loss_mean": 23.001033782958984, "eval/image_loss_std": 26.795902252197266, "eval/model_loss_mean": 35.45669174194336, "eval/model_loss_std": 32.03532028198242, "eval/post_ent_mag": 54.565773010253906, "eval/post_ent_max": 54.565773010253906, "eval/post_ent_mean": 38.57667541503906, "eval/post_ent_min": 20.38469696044922, "eval/post_ent_std": 6.185552597045898, "eval/prior_ent_mag": 74.92851257324219, "eval/prior_ent_max": 74.92851257324219, "eval/prior_ent_mean": 51.38390350341797, "eval/prior_ent_min": 28.20119857788086, "eval/prior_ent_std": 6.8106842041015625, "eval/rep_loss_mean": 20.600082397460938, "eval/rep_loss_std": 13.46248722076416, "eval/reward_avg": 0.02666015550494194, "eval/reward_loss_mean": 0.09512051939964294, "eval/reward_loss_std": 0.6663689017295837, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0005416870117188, "eval/reward_neg_acc": 0.9959717988967896, "eval/reward_neg_loss": 0.05390442907810211, "eval/reward_pos_acc": 0.9032257795333862, "eval/reward_pos_loss": 1.4153648614883423, "eval/reward_pred": 0.02554822713136673, "eval/reward_rate": 0.0302734375, "replay/size": 273233.0, "replay/inserts": 7740.0, "replay/samples": 30960.0, "replay/insert_wait_avg": 1.4989259015066064e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.185440038833815e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 55360.0, "eval_replay/inserts": 1712.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.11271287793311e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.493661880493164e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3513686656952, "timer/env.step_count": 968.0, "timer/env.step_total": 89.38619422912598, "timer/env.step_frac": 0.08935479775306601, "timer/env.step_avg": 0.09234110974083262, "timer/env.step_min": 0.022945404052734375, "timer/env.step_max": 1.9071011543273926, "timer/replay._sample_count": 30960.0, "timer/replay._sample_total": 15.15112590789795, "timer/replay._sample_frac": 0.01514580414690397, "timer/replay._sample_avg": 0.0004893774518054893, "timer/replay._sample_min": 0.00034737586975097656, "timer/replay._sample_max": 0.010555267333984375, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1182.0, "timer/agent.policy_total": 18.48337745666504, "timer/agent.policy_frac": 0.01847688525814568, "timer/agent.policy_avg": 0.01563737517484352, "timer/agent.policy_min": 0.009444236755371094, "timer/agent.policy_max": 0.055342674255371094, "timer/dataset_train_count": 1935.0, "timer/dataset_train_total": 0.2799360752105713, "timer/dataset_train_frac": 0.0002798377489940961, "timer/dataset_train_avg": 0.00014466980631037277, "timer/dataset_train_min": 8.821487426757812e-05, "timer/dataset_train_max": 0.0035867691040039062, "timer/agent.train_count": 1935.0, "timer/agent.train_total": 861.263870716095, "timer/agent.train_frac": 0.8609613558732666, "timer/agent.train_avg": 0.44509760760521705, "timer/agent.train_min": 0.43457579612731934, "timer/agent.train_max": 1.0942416191101074, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47467517852783203, "timer/agent.report_frac": 0.00047450845112649863, "timer/agent.report_avg": 0.23733758926391602, "timer/agent.report_min": 0.23173880577087402, "timer/agent.report_max": 0.242936372756958, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7418136596679688e-05, "timer/dataset_eval_frac": 2.740850610646036e-08, "timer/dataset_eval_avg": 2.7418136596679688e-05, "timer/dataset_eval_min": 2.7418136596679688e-05, "timer/dataset_eval_max": 2.7418136596679688e-05, "fps": 7.7371814000591925}
{"step": 273776, "time": 35357.053136110306, "episode/length": 312.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9904153354632588, "episode/intrinsic_return": 0.0}
{"step": 273912, "time": 35374.64194917679, "episode/length": 159.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 273944, "time": 35380.25450658798, "episode/length": 167.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 274288, "time": 35422.010779857635, "episode/length": 207.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 274536, "time": 35452.359896183014, "episode/length": 203.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 274560, "time": 35456.77727460861, "episode/length": 169.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 274632, "time": 35466.58127832413, "episode/length": 190.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 274920, "time": 35501.607674360275, "episode/length": 235.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9788135593220338, "episode/intrinsic_return": 0.0}
{"step": 275216, "time": 35537.590060949326, "episode/length": 162.0, "episode/score": 8.099999964237213, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 275408, "time": 35561.429602622986, "episode/length": 203.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 275424, "time": 35564.727353811264, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 275872, "time": 35618.074213027954, "episode/length": 154.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 275960, "time": 35629.891434669495, "episode/length": 208.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 276088, "time": 35646.28500413895, "episode/length": 190.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 276208, "time": 35662.1712911129, "episode/length": 99.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.99, "episode/intrinsic_return": 0.0}
{"step": 276240, "time": 35667.33945584297, "episode/length": 164.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9636363636363636, "episode/intrinsic_return": 0.0}
{"step": 276336, "time": 35679.97953557968, "episode/length": 224.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 276592, "time": 35711.23758196831, "episode/length": 145.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 277056, "time": 35766.59706616402, "episode/length": 229.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 277320, "time": 35798.71411919594, "episode/length": 169.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 277472, "time": 35817.907736063, "episode/length": 157.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 277496, "time": 35822.14816904068, "episode/length": 202.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 277728, "time": 35850.64572048187, "episode/length": 185.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 278088, "time": 35894.14922595024, "episode/length": 218.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 278264, "time": 35916.10914301872, "episode/length": 208.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9665071770334929, "episode/intrinsic_return": 0.0}
{"step": 278520, "time": 35947.59434580803, "episode/length": 182.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 279032, "time": 36010.0279071331, "episode/length": 213.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 279112, "time": 36020.81873226166, "episode/length": 172.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 279232, "time": 36036.302005529404, "episode/length": 216.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 279312, "time": 36047.13580584526, "episode/length": 402.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9875930521091811, "episode/intrinsic_return": 0.0}
{"step": 279608, "time": 36082.94530749321, "episode/length": 167.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 279696, "time": 36094.67952084541, "episode/length": 200.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 280072, "time": 36158.229716300964, "eval_episode/length": 146.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9931972789115646}
{"step": 280072, "time": 36160.36469960213, "eval_episode/length": 159.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.975}
{"step": 280072, "time": 36162.306232213974, "eval_episode/length": 169.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 280072, "time": 36164.87949633598, "eval_episode/length": 186.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9786096256684492}
{"step": 280072, "time": 36168.424768686295, "eval_episode/length": 203.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9950980392156863}
{"step": 280072, "time": 36170.284975767136, "eval_episode/length": 211.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9764150943396226}
{"step": 280072, "time": 36176.09779214859, "eval_episode/length": 169.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9647058823529412}
{"step": 280072, "time": 36178.093546152115, "eval_episode/length": 139.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9928571428571429}
{"step": 280528, "time": 36231.11930465698, "episode/length": 151.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 280568, "time": 36237.239784002304, "episode/length": 191.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 280624, "time": 36245.254212617874, "episode/length": 262.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9961977186311787, "episode/intrinsic_return": 0.0}
{"step": 280856, "time": 36274.42618274689, "episode/length": 422.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9976359338061466, "episode/intrinsic_return": 0.0}
{"step": 281112, "time": 36305.80369377136, "episode/length": 234.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9829787234042553, "episode/intrinsic_return": 0.0}
{"step": 281248, "time": 36323.347462415695, "episode/length": 193.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 281280, "time": 36328.52011656761, "episode/length": 208.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 281469, "time": 36352.91643714905, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.445820704642973, "train/action_min": 0.0, "train/action_std": 3.108688170428103, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.047643442614090876, "train/actor_opt_grad_steps": 69010.0, "train/actor_opt_loss": -13.793024607774816, "train/adv_mag": 0.5089964164044573, "train/adv_max": 0.48170184548654704, "train/adv_mean": 0.0021195487906926986, "train/adv_min": -0.40884649954311586, "train/adv_std": 0.05875947575417825, "train/cont_avg": 0.9946516758419689, "train/cont_loss_mean": 0.000143530538587765, "train/cont_loss_std": 0.004302495493484599, "train/cont_neg_acc": 0.9966321244758646, "train/cont_neg_loss": 0.021815739317758417, "train/cont_pos_acc": 0.9999847248428226, "train/cont_pos_loss": 3.791596734909754e-05, "train/cont_pred": 0.9946414133427675, "train/cont_rate": 0.9946516758419689, "train/dyn_loss_mean": 6.4048256799964705, "train/dyn_loss_std": 8.711265052538462, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1650468540315184, "train/extr_critic_critic_opt_grad_steps": 69010.0, "train/extr_critic_critic_opt_loss": 16976.157924829986, "train/extr_critic_mag": 7.829938006524595, "train/extr_critic_max": 7.829938006524595, "train/extr_critic_mean": 1.6961258618942814, "train/extr_critic_min": -0.6341996822950136, "train/extr_critic_std": 1.8296166213682896, "train/extr_return_normed_mag": 1.5393591606555208, "train/extr_return_normed_max": 1.5393591606555208, "train/extr_return_normed_mean": 0.34014747419196706, "train/extr_return_normed_min": -0.13201554509487795, "train/extr_return_normed_std": 0.327661283275624, "train/extr_return_rate": 0.6277033740683541, "train/extr_return_raw_mag": 8.514170278539313, "train/extr_return_raw_max": 8.514170278539313, "train/extr_return_raw_mean": 1.7082018259275762, "train/extr_return_raw_min": -0.9719755405589089, "train/extr_return_raw_std": 1.8596886513764377, "train/extr_reward_mag": 1.037236155623599, "train/extr_reward_max": 1.037236155623599, "train/extr_reward_mean": 0.038939325370550774, "train/extr_reward_min": -0.6913230240036169, "train/extr_reward_std": 0.19499496814500483, "train/image_loss_mean": 3.694370703376019, "train/image_loss_std": 8.362888396712782, "train/model_loss_mean": 7.585309661114154, "train/model_loss_std": 12.436585241031153, "train/model_opt_grad_norm": 45.04607314272866, "train/model_opt_grad_steps": 68948.1968911917, "train/model_opt_loss": 10369.56294527202, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1366.580310880829, "train/policy_entropy_mag": 2.49070210283902, "train/policy_entropy_max": 2.49070210283902, "train/policy_entropy_mean": 0.44014813924700485, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.5771184810702665, "train/policy_logprob_mag": 7.438384026443402, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.44031682780369574, "train/policy_logprob_min": -7.438384026443402, "train/policy_logprob_std": 1.0454470138475684, "train/policy_randomness_mag": 0.8791085410612235, "train/policy_randomness_max": 0.8791085410612235, "train/policy_randomness_mean": 0.15535297866312334, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.20369749890707936, "train/post_ent_mag": 58.33224050492203, "train/post_ent_max": 58.33224050492203, "train/post_ent_mean": 40.70138124851365, "train/post_ent_min": 19.688040728396086, "train/post_ent_std": 6.6803186619220005, "train/prior_ent_mag": 75.1516716517315, "train/prior_ent_max": 75.1516716517315, "train/prior_ent_mean": 47.108642518829186, "train/prior_ent_min": 27.175185593916346, "train/prior_ent_std": 7.588012070235811, "train/rep_loss_mean": 6.4048256799964705, "train/rep_loss_std": 8.711265052538462, "train/reward_avg": 0.028766090291614976, "train/reward_loss_mean": 0.047900075112213746, "train/reward_loss_std": 0.20945860862423102, "train/reward_max_data": 1.0129533709639713, "train/reward_max_pred": 1.0120520820271783, "train/reward_neg_acc": 0.9949105857567466, "train/reward_neg_loss": 0.02320803536362753, "train/reward_pos_acc": 0.9843917152424551, "train/reward_pos_loss": 0.7536673450099372, "train/reward_pred": 0.028401126573586094, "train/reward_rate": 0.03369899611398964, "train_stats/sum_log_reward": 7.20256416614239, "train_stats/max_log_achievement_collect_coal": 0.07692307692307693, "train_stats/max_log_achievement_collect_drink": 3.9743589743589745, "train_stats/max_log_achievement_collect_sapling": 2.0256410256410255, "train_stats/max_log_achievement_collect_stone": 4.333333333333333, "train_stats/max_log_achievement_collect_wood": 7.0256410256410255, "train_stats/max_log_achievement_defeat_skeleton": 0.02564102564102564, "train_stats/max_log_achievement_defeat_zombie": 0.20512820512820512, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.3333333333333333, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_furnace": 0.05128205128205128, "train_stats/max_log_achievement_place_plant": 1.8461538461538463, "train_stats/max_log_achievement_place_stone": 3.0256410256410255, "train_stats/max_log_achievement_place_table": 2.4615384615384617, "train_stats/max_log_achievement_wake_up": 2.1538461538461537, "train_stats/mean_log_entropy": 0.41177974946987933, "eval_stats/sum_log_reward": 6.7250001430511475, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 2.0, "eval_stats/max_log_achievement_collect_sapling": 1.5, "eval_stats/max_log_achievement_collect_stone": 4.0, "eval_stats/max_log_achievement_collect_wood": 6.625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.375, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.5, "eval_stats/max_log_achievement_place_stone": 2.375, "eval_stats/max_log_achievement_place_table": 1.875, "eval_stats/max_log_achievement_wake_up": 2.375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 3.4122278975701192e-06, "report/cont_loss_std": 2.5705763619043864e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 7.911137072369456e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.966063902931637e-06, "report/cont_pred": 0.9941381812095642, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 6.630406379699707, "report/dyn_loss_std": 8.589404106140137, "report/image_loss_mean": 4.213174819946289, "report/image_loss_std": 6.5500264167785645, "report/model_loss_mean": 8.236738204956055, "report/model_loss_std": 10.775599479675293, "report/post_ent_mag": 61.71298599243164, "report/post_ent_max": 61.71298599243164, "report/post_ent_mean": 42.38901138305664, "report/post_ent_min": 18.76959991455078, "report/post_ent_std": 7.5830535888671875, "report/prior_ent_mag": 75.0926513671875, "report/prior_ent_max": 75.0926513671875, "report/prior_ent_mean": 49.353904724121094, "report/prior_ent_min": 30.343231201171875, "report/prior_ent_std": 7.6273627281188965, "report/rep_loss_mean": 6.630406379699707, "report/rep_loss_std": 8.589404106140137, "report/reward_avg": 0.02451171725988388, "report/reward_loss_mean": 0.04531698673963547, "report/reward_loss_std": 0.17695185542106628, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0000479221343994, "report/reward_neg_acc": 0.9939576983451843, "report/reward_neg_loss": 0.022180497646331787, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7864309549331665, "report/reward_pred": 0.02302207425236702, "report/reward_rate": 0.0302734375, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.0006526217912323773, "eval/cont_loss_std": 0.02053919807076454, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.1661912053823471, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 3.450872327448451e-06, "eval/cont_pred": 0.996567964553833, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 17.630048751831055, "eval/dyn_loss_std": 12.851374626159668, "eval/image_loss_mean": 17.63113784790039, "eval/image_loss_std": 22.875349044799805, "eval/model_loss_mean": 28.347549438476562, "eval/model_loss_std": 27.81561851501465, "eval/post_ent_mag": 55.680702209472656, "eval/post_ent_max": 55.680702209472656, "eval/post_ent_mean": 38.07448959350586, "eval/post_ent_min": 20.571306228637695, "eval/post_ent_std": 5.994149208068848, "eval/prior_ent_mag": 75.0926513671875, "eval/prior_ent_max": 75.0926513671875, "eval/prior_ent_mean": 49.876983642578125, "eval/prior_ent_min": 32.12883758544922, "eval/prior_ent_std": 7.699540615081787, "eval/rep_loss_mean": 17.630048751831055, "eval/rep_loss_std": 12.851374626159668, "eval/reward_avg": 0.03466796875, "eval/reward_loss_mean": 0.13772892951965332, "eval/reward_loss_std": 0.902651309967041, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0011529922485352, "eval/reward_neg_acc": 0.9949238896369934, "eval/reward_neg_loss": 0.048525940626859665, "eval/reward_pos_acc": 0.692307710647583, "eval/reward_pos_loss": 2.390676498413086, "eval/reward_pred": 0.02671431191265583, "eval/reward_rate": 0.0380859375, "replay/size": 280965.0, "replay/inserts": 7732.0, "replay/samples": 30928.0, "replay/insert_wait_avg": 1.4937546853876089e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.250074025453587e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 57976.0, "eval_replay/inserts": 2616.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1446096846087628e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.046627044677734e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2623956203461, "timer/env.step_count": 966.0, "timer/env.step_total": 85.81314253807068, "timer/env.step_frac": 0.08579063145211092, "timer/env.step_avg": 0.08883348088827192, "timer/env.step_min": 0.022931575775146484, "timer/env.step_max": 1.9358699321746826, "timer/replay._sample_count": 30928.0, "timer/replay._sample_total": 15.197773694992065, "timer/replay._sample_frac": 0.015193786911849924, "timer/replay._sample_avg": 0.0004913920620470792, "timer/replay._sample_min": 0.00034928321838378906, "timer/replay._sample_max": 0.011689901351928711, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1293.0, "timer/agent.policy_total": 20.577461004257202, "timer/agent.policy_frac": 0.020572062985028446, "timer/agent.policy_avg": 0.01591450967073256, "timer/agent.policy_min": 0.009254693984985352, "timer/agent.policy_max": 0.1020050048828125, "timer/dataset_train_count": 1933.0, "timer/dataset_train_total": 0.27909231185913086, "timer/dataset_train_frac": 0.0002790190984696995, "timer/dataset_train_avg": 0.0001443829859591986, "timer/dataset_train_min": 8.749961853027344e-05, "timer/dataset_train_max": 0.0007960796356201172, "timer/agent.train_count": 1933.0, "timer/agent.train_total": 857.7504725456238, "timer/agent.train_frac": 0.8575254616201594, "timer/agent.train_avg": 0.44374054451403194, "timer/agent.train_min": 0.4317920207977295, "timer/agent.train_max": 0.9745352268218994, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4657902717590332, "timer/agent.report_frac": 0.0004656680824936519, "timer/agent.report_avg": 0.2328951358795166, "timer/agent.report_min": 0.22236895561218262, "timer/agent.report_max": 0.24342131614685059, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.147125244140625e-05, "timer/dataset_eval_frac": 3.146299668887213e-08, "timer/dataset_eval_avg": 3.147125244140625e-05, "timer/dataset_eval_min": 3.147125244140625e-05, "timer/dataset_eval_max": 3.147125244140625e-05, "fps": 7.729861712894102}
{"step": 281680, "time": 36377.65096497536, "episode/length": 49.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 281752, "time": 36388.14332842827, "episode/length": 62.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 281976, "time": 36415.845321178436, "episode/length": 357.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 282200, "time": 36443.682567596436, "episode/length": 196.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 282288, "time": 36455.48561549187, "episode/length": 219.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 282296, "time": 36457.91922521591, "episode/length": 179.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 282376, "time": 36468.74150466919, "episode/length": 225.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 282616, "time": 36498.26169657707, "episode/length": 187.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 282944, "time": 36538.04076051712, "episode/length": 148.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 283288, "time": 36580.19008350372, "episode/length": 83.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9880952380952381, "episode/intrinsic_return": 0.0}
{"step": 283392, "time": 36593.87715482712, "episode/length": 126.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9921259842519685, "episode/intrinsic_return": 0.0}
{"step": 283520, "time": 36610.44010734558, "episode/length": 152.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 283616, "time": 36623.1839029789, "episode/length": 176.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 283624, "time": 36625.491585969925, "episode/length": 205.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 283840, "time": 36652.370842695236, "episode/length": 193.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 284072, "time": 36680.98315382004, "episode/length": 298.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9765886287625418, "episode/intrinsic_return": 0.0}
{"step": 284808, "time": 36768.83421564102, "episode/length": 189.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 284848, "time": 36775.02639627457, "episode/length": 125.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9920634920634921, "episode/intrinsic_return": 0.0}
{"step": 284968, "time": 36790.67380809784, "episode/length": 168.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 284976, "time": 36793.151494026184, "episode/length": 253.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.984251968503937, "episode/intrinsic_return": 0.0}
{"step": 284984, "time": 36795.534927368164, "episode/length": 169.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 285080, "time": 36808.21289253235, "episode/length": 210.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9715639810426541, "episode/intrinsic_return": 0.0}
{"step": 285176, "time": 36820.9726626873, "episode/length": 206.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 285392, "time": 36847.694081783295, "episode/length": 164.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 285440, "time": 36854.92718720436, "episode/length": 57.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 286408, "time": 36969.69648241997, "episode/length": 194.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 286488, "time": 36980.621898174286, "episode/length": 187.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9680851063829787, "episode/intrinsic_return": 0.0}
{"step": 286496, "time": 36982.93348002434, "episode/length": 210.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.981042654028436, "episode/intrinsic_return": 0.0}
{"step": 286576, "time": 36993.70874643326, "episode/length": 186.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 286872, "time": 37031.1475982666, "episode/length": 211.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 286960, "time": 37042.99559020996, "episode/length": 195.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 287128, "time": 37064.16736602783, "episode/length": 89.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9555555555555556, "episode/intrinsic_return": 0.0}
{"step": 287144, "time": 37067.47072696686, "episode/length": 271.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9889705882352942, "episode/intrinsic_return": 0.0}
{"step": 287208, "time": 37076.51765489578, "episode/length": 41.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 288040, "time": 37175.69316291809, "episode/length": 193.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 288264, "time": 37203.602274656296, "episode/length": 210.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9715639810426541, "episode/intrinsic_return": 0.0}
{"step": 288320, "time": 37211.63518571854, "episode/length": 227.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9780701754385965, "episode/intrinsic_return": 0.0}
{"step": 288320, "time": 37211.64571595192, "episode/length": 359.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 288392, "time": 37223.2194879055, "episode/length": 155.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 288600, "time": 37249.30985784531, "episode/length": 173.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 288768, "time": 37270.57753396034, "episode/length": 225.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 289432, "time": 37350.007316827774, "episode/length": 173.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 289437, "time": 37352.96718335152, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.439379577636719, "train/action_min": 0.0, "train/action_std": 3.108864462375641, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04747482109814882, "train/actor_opt_grad_steps": 70975.0, "train/actor_opt_loss": -9.972913006581367, "train/adv_mag": 0.5105792209506035, "train/adv_max": 0.48117275550961497, "train/adv_mean": 0.00362435086169171, "train/adv_min": -0.4140374015271664, "train/adv_std": 0.059969510454684495, "train/cont_avg": 0.9944873046875, "train/cont_loss_mean": 0.00015670502102167915, "train/cont_loss_std": 0.004666725161376917, "train/cont_neg_acc": 0.9966468259692192, "train/cont_neg_loss": 0.01768099837986483, "train/cont_pos_acc": 0.9999950727820397, "train/cont_pos_loss": 4.4923565176659965e-05, "train/cont_pred": 0.9944901260733604, "train/cont_rate": 0.9944873046875, "train/dyn_loss_mean": 6.461398663520813, "train/dyn_loss_std": 8.763394906520844, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1637408015131951, "train/extr_critic_critic_opt_grad_steps": 70975.0, "train/extr_critic_critic_opt_loss": 17066.858291015626, "train/extr_critic_mag": 7.8252368783950805, "train/extr_critic_max": 7.8252368783950805, "train/extr_critic_mean": 1.7110347566008568, "train/extr_critic_min": -0.6218638294935226, "train/extr_critic_std": 1.8512780970335008, "train/extr_return_normed_mag": 1.5449007099866867, "train/extr_return_normed_max": 1.5449007099866867, "train/extr_return_normed_mean": 0.34208388201892376, "train/extr_return_normed_min": -0.12849822267889977, "train/extr_return_normed_std": 0.33293133199214936, "train/extr_return_rate": 0.6226933923363686, "train/extr_return_raw_mag": 8.558381836414338, "train/extr_return_raw_max": 8.558381836414338, "train/extr_return_raw_mean": 1.731596705019474, "train/extr_return_raw_min": -0.9396806880831718, "train/extr_return_raw_std": 1.8898219549655915, "train/extr_reward_mag": 1.0344523394107819, "train/extr_reward_max": 1.0344523394107819, "train/extr_reward_mean": 0.039108793986961245, "train/extr_reward_min": -0.6869184869527817, "train/extr_reward_std": 0.19509189322590828, "train/image_loss_mean": 3.7928287422657014, "train/image_loss_std": 8.652998337745666, "train/model_loss_mean": 7.717474341392517, "train/model_loss_std": 12.749911494255066, "train/model_opt_grad_norm": 45.04925112724304, "train/model_opt_grad_steps": 70911.405, "train/model_opt_loss": 10741.809438476563, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1381.25, "train/policy_entropy_mag": 2.4891819596290587, "train/policy_entropy_max": 2.4891819596290587, "train/policy_entropy_mean": 0.43971203833818434, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.5847682182490825, "train/policy_logprob_mag": 7.438384051322937, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.43926795467734336, "train/policy_logprob_min": -7.438384051322937, "train/policy_logprob_std": 1.0420213896036148, "train/policy_randomness_mag": 0.8785719954967499, "train/policy_randomness_max": 0.8785719954967499, "train/policy_randomness_mean": 0.15519905284047128, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.20639752030372618, "train/post_ent_mag": 58.41632318496704, "train/post_ent_max": 58.41632318496704, "train/post_ent_mean": 40.803307151794435, "train/post_ent_min": 19.75364052772522, "train/post_ent_std": 6.683770568370819, "train/prior_ent_mag": 75.3246028137207, "train/prior_ent_max": 75.3246028137207, "train/prior_ent_mean": 47.2485385131836, "train/prior_ent_min": 27.33699303627014, "train/prior_ent_std": 7.720099108219147, "train/rep_loss_mean": 6.461398663520813, "train/rep_loss_std": 8.763394906520844, "train/reward_avg": 0.027932128557004034, "train/reward_loss_mean": 0.04764967020601034, "train/reward_loss_std": 0.2093381180241704, "train/reward_max_data": 1.0150000035762787, "train/reward_max_pred": 1.0150541651248932, "train/reward_neg_acc": 0.9951682588458062, "train/reward_neg_loss": 0.023617096575908363, "train/reward_pos_acc": 0.9844207993149757, "train/reward_pos_loss": 0.756074076294899, "train/reward_pred": 0.027699693981558086, "train/reward_rate": 0.0329296875, "train_stats/sum_log_reward": 7.600000103314717, "train_stats/max_log_achievement_collect_coal": 0.5238095238095238, "train_stats/max_log_achievement_collect_drink": 3.0952380952380953, "train_stats/max_log_achievement_collect_sapling": 1.9523809523809523, "train_stats/max_log_achievement_collect_stone": 6.309523809523809, "train_stats/max_log_achievement_collect_wood": 6.214285714285714, "train_stats/max_log_achievement_defeat_skeleton": 0.047619047619047616, "train_stats/max_log_achievement_defeat_zombie": 0.2619047619047619, "train_stats/max_log_achievement_eat_cow": 0.047619047619047616, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.3095238095238095, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_furnace": 0.023809523809523808, "train_stats/max_log_achievement_place_plant": 1.8333333333333333, "train_stats/max_log_achievement_place_stone": 4.214285714285714, "train_stats/max_log_achievement_place_table": 1.9523809523809523, "train_stats/max_log_achievement_wake_up": 2.0476190476190474, "train_stats/mean_log_entropy": 0.38843624187367304, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.00032730266684666276, "report/cont_loss_std": 0.00892099179327488, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.004860781133174896, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.00030058278935030103, "report/cont_pred": 0.9939062595367432, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 5.6591715812683105, "report/dyn_loss_std": 8.413453102111816, "report/image_loss_mean": 3.6903457641601562, "report/image_loss_std": 11.170689582824707, "report/model_loss_mean": 7.142088413238525, "report/model_loss_std": 14.72327709197998, "report/post_ent_mag": 60.067665100097656, "report/post_ent_max": 60.067665100097656, "report/post_ent_mean": 42.56376266479492, "report/post_ent_min": 21.035947799682617, "report/post_ent_std": 6.962043285369873, "report/prior_ent_mag": 75.12098693847656, "report/prior_ent_max": 75.12098693847656, "report/prior_ent_mean": 48.1024055480957, "report/prior_ent_min": 26.188846588134766, "report/prior_ent_std": 7.680243492126465, "report/rep_loss_mean": 5.6591715812683105, "report/rep_loss_std": 8.413453102111816, "report/reward_avg": 0.02939452975988388, "report/reward_loss_mean": 0.055912718176841736, "report/reward_loss_std": 0.25453639030456543, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0035593509674072, "report/reward_neg_acc": 0.9969635605812073, "report/reward_neg_loss": 0.025575757026672363, "report/reward_pos_acc": 0.9166666865348816, "report/reward_pos_loss": 0.8884938359260559, "report/reward_pred": 0.02812155894935131, "report/reward_rate": 0.03515625, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.00028463639318943024, "eval/cont_loss_std": 0.008978024125099182, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0580807626247406, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.0440608093631454e-06, "eval/cont_pred": 0.9953631162643433, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 20.353404998779297, "eval/dyn_loss_std": 12.951193809509277, "eval/image_loss_mean": 27.07127571105957, "eval/image_loss_std": 31.716032028198242, "eval/model_loss_mean": 39.436927795410156, "eval/model_loss_std": 36.466835021972656, "eval/post_ent_mag": 58.688724517822266, "eval/post_ent_max": 58.688724517822266, "eval/post_ent_mean": 39.317657470703125, "eval/post_ent_min": 19.82596206665039, "eval/post_ent_std": 6.777866363525391, "eval/prior_ent_mag": 75.12098693847656, "eval/prior_ent_max": 75.12098693847656, "eval/prior_ent_mean": 52.387245178222656, "eval/prior_ent_min": 33.891693115234375, "eval/prior_ent_std": 6.719071865081787, "eval/rep_loss_mean": 20.353404998779297, "eval/rep_loss_std": 12.951193809509277, "eval/reward_avg": 0.04335937649011612, "eval/reward_loss_mean": 0.15332889556884766, "eval/reward_loss_std": 0.9368430376052856, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0012357234954834, "eval/reward_neg_acc": 0.9897541403770447, "eval/reward_neg_loss": 0.03698433190584183, "eval/reward_pos_acc": 0.7708333730697632, "eval/reward_pos_loss": 2.5190019607543945, "eval/reward_pred": 0.03403133898973465, "eval/reward_rate": 0.046875, "replay/size": 288933.0, "replay/inserts": 7968.0, "replay/samples": 31872.0, "replay/insert_wait_avg": 1.5247957294724554e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.235590951988496e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 57976.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 8.940696716308594e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0381331443787, "timer/env.step_count": 996.0, "timer/env.step_total": 89.81804370880127, "timer/env.step_frac": 0.08981461879497545, "timer/env.step_avg": 0.09017875874377637, "timer/env.step_min": 0.023164749145507812, "timer/env.step_max": 3.2281768321990967, "timer/replay._sample_count": 31872.0, "timer/replay._sample_total": 15.78218150138855, "timer/replay._sample_frac": 0.01578157970013132, "timer/replay._sample_avg": 0.0004951738673879439, "timer/replay._sample_min": 0.0003998279571533203, "timer/replay._sample_max": 0.023526668548583984, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 996.0, "timer/agent.policy_total": 16.057907104492188, "timer/agent.policy_frac": 0.016057294789351653, "timer/agent.policy_avg": 0.016122396691257215, "timer/agent.policy_min": 0.009843111038208008, "timer/agent.policy_max": 0.06906676292419434, "timer/dataset_train_count": 1992.0, "timer/dataset_train_total": 0.3559298515319824, "timer/dataset_train_frac": 0.0003559162793251162, "timer/dataset_train_avg": 0.00017867964434336466, "timer/dataset_train_min": 8.702278137207031e-05, "timer/dataset_train_max": 0.06825733184814453, "timer/agent.train_count": 1992.0, "timer/agent.train_total": 890.9418182373047, "timer/agent.train_frac": 0.8909078451198187, "timer/agent.train_avg": 0.4472599489143096, "timer/agent.train_min": 0.42742490768432617, "timer/agent.train_max": 1.0285966396331787, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4768712520599365, "timer/agent.report_frac": 0.0004768530681530412, "timer/agent.report_avg": 0.23843562602996826, "timer/agent.report_min": 0.23135161399841309, "timer/agent.report_max": 0.24551963806152344, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.86102294921875e-05, "timer/dataset_eval_frac": 2.8609138535777167e-08, "timer/dataset_eval_avg": 2.86102294921875e-05, "timer/dataset_eval_min": 2.86102294921875e-05, "timer/dataset_eval_max": 2.86102294921875e-05, "fps": 7.967570371265271}
{"step": 289672, "time": 37380.49293637276, "episode/length": 317.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9779874213836478, "episode/intrinsic_return": 0.0}
{"step": 289712, "time": 37386.601132154465, "episode/length": 173.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 289840, "time": 37403.23198056221, "episode/length": 189.0, "episode/score": 10.100000016391277, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 290040, "time": 37428.525924921036, "episode/length": 205.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 290056, "time": 37450.168592214584, "eval_episode/length": 93.0, "eval_episode/score": 5.100000023841858, "eval_episode/reward_rate": 0.9893617021276596}
{"step": 290056, "time": 37454.012803554535, "eval_episode/length": 150.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9602649006622517}
{"step": 290056, "time": 37455.75660467148, "eval_episode/length": 157.0, "eval_episode/score": 9.099999971687794, "eval_episode/reward_rate": 0.9936708860759493}
{"step": 290056, "time": 37457.75622344017, "eval_episode/length": 168.0, "eval_episode/score": 8.099999994039536, "eval_episode/reward_rate": 0.9940828402366864}
{"step": 290056, "time": 37459.898537158966, "eval_episode/length": 183.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9782608695652174}
{"step": 290056, "time": 37461.3850839138, "eval_episode/length": 184.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.972972972972973}
{"step": 290056, "time": 37464.108006477356, "eval_episode/length": 213.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9953271028037384}
{"step": 290056, "time": 37466.89094161987, "eval_episode/length": 151.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9671052631578947}
{"step": 290264, "time": 37491.198714494705, "episode/length": 207.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 290400, "time": 37508.556913375854, "episode/length": 44.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 290600, "time": 37533.48801326752, "episode/length": 145.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.958904109589041, "episode/intrinsic_return": 0.0}
{"step": 290752, "time": 37552.745023965836, "episode/length": 247.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9798387096774194, "episode/intrinsic_return": 0.0}
{"step": 291216, "time": 37608.95057249069, "episode/length": 192.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 291256, "time": 37615.06549572945, "episode/length": 192.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 291656, "time": 37663.23050427437, "episode/length": 423.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 291856, "time": 37688.00210952759, "episode/length": 251.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 292096, "time": 37717.523163318634, "episode/length": 167.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9583333333333334, "episode/intrinsic_return": 0.0}
{"step": 292288, "time": 37741.41822004318, "episode/length": 210.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.966824644549763, "episode/intrinsic_return": 0.0}
{"step": 292344, "time": 37749.480327129364, "episode/length": 140.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9645390070921985, "episode/intrinsic_return": 0.0}
{"step": 292560, "time": 37776.26499891281, "episode/length": 162.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9815950920245399, "episode/intrinsic_return": 0.0}
{"step": 292664, "time": 37789.994626522064, "episode/length": 299.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9766666666666667, "episode/intrinsic_return": 0.0}
{"step": 293160, "time": 37849.47752189636, "episode/length": 162.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 293392, "time": 37878.125277519226, "episode/length": 161.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 293584, "time": 37902.06910324097, "episode/length": 161.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 293624, "time": 37908.1885073185, "episode/length": 402.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9925558312655087, "episode/intrinsic_return": 0.0}
{"step": 293640, "time": 37911.58423089981, "episode/length": 247.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9758064516129032, "episode/intrinsic_return": 0.0}
{"step": 293800, "time": 37931.74131274223, "episode/length": 141.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9647887323943662, "episode/intrinsic_return": 0.0}
{"step": 294056, "time": 37963.03960490227, "episode/length": 213.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 294184, "time": 37979.44123697281, "episode/length": 202.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9704433497536946, "episode/intrinsic_return": 0.0}
{"step": 294288, "time": 37993.1217713356, "episode/length": 140.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9574468085106383, "episode/intrinsic_return": 0.0}
{"step": 294624, "time": 38034.0816552639, "episode/length": 153.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 294672, "time": 38041.152572631836, "episode/length": 135.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9558823529411765, "episode/intrinsic_return": 0.0}
{"step": 294856, "time": 38064.097626686096, "episode/length": 153.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 295008, "time": 38084.582225084305, "episode/length": 170.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 295216, "time": 38110.37430143356, "episode/length": 176.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 295464, "time": 38140.89566230774, "episode/length": 175.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9659090909090909, "episode/intrinsic_return": 0.0}
{"step": 295552, "time": 38152.543805122375, "episode/length": 170.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 295776, "time": 38180.212730169296, "episode/length": 185.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 296088, "time": 38218.144874572754, "episode/length": 182.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 296120, "time": 38223.44175195694, "episode/length": 180.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9668508287292817, "episode/intrinsic_return": 0.0}
{"step": 296312, "time": 38247.37512207031, "episode/length": 162.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 296984, "time": 38327.39166307449, "episode/length": 189.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 297185, "time": 38353.242058992386, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.471849510706768, "train/action_min": 0.0, "train/action_std": 3.1637991574144118, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04656600224462198, "train/actor_opt_grad_steps": 72940.0, "train/actor_opt_loss": -11.697959574701873, "train/adv_mag": 0.4895016941690692, "train/adv_max": 0.4612047259980533, "train/adv_mean": 0.0028683271018849744, "train/adv_min": -0.39798604330250636, "train/adv_std": 0.05843395241801603, "train/cont_avg": 0.9945251781088082, "train/cont_loss_mean": 0.00010344467962835737, "train/cont_loss_std": 0.0031464846026364912, "train/cont_neg_acc": 0.9963298795136764, "train/cont_neg_loss": 0.011230998216223661, "train/cont_pos_acc": 0.9999898032820904, "train/cont_pos_loss": 4.7394606952661674e-05, "train/cont_pred": 0.9945204128255498, "train/cont_rate": 0.9945251781088082, "train/dyn_loss_mean": 6.41159318765828, "train/dyn_loss_std": 8.693097932351067, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.145496142034086, "train/extr_critic_critic_opt_grad_steps": 72940.0, "train/extr_critic_critic_opt_loss": 16890.560430497084, "train/extr_critic_mag": 7.997793177866565, "train/extr_critic_max": 7.997793177866565, "train/extr_critic_mean": 1.8385872915001114, "train/extr_critic_min": -0.6174333095550537, "train/extr_critic_std": 1.9207823041807184, "train/extr_return_normed_mag": 1.5305143866514295, "train/extr_return_normed_max": 1.5305143866514295, "train/extr_return_normed_mean": 0.35214435799443045, "train/extr_return_normed_min": -0.12018493105478854, "train/extr_return_normed_std": 0.3346433896629304, "train/extr_return_rate": 0.642609192917384, "train/extr_return_raw_mag": 8.750896718217918, "train/extr_return_raw_max": 8.750896718217918, "train/extr_return_raw_mean": 1.855348681847666, "train/extr_return_raw_min": -0.9088959676922912, "train/extr_return_raw_std": 1.9582679487880648, "train/extr_reward_mag": 1.0357395898492843, "train/extr_reward_max": 1.0357395898492843, "train/extr_reward_mean": 0.04134900493479763, "train/extr_reward_min": -0.670279135975813, "train/extr_reward_std": 0.20032143214514836, "train/image_loss_mean": 3.7323234044208426, "train/image_loss_std": 8.453337239477918, "train/model_loss_mean": 7.628399554929585, "train/model_loss_std": 12.529967515579777, "train/model_opt_grad_norm": 43.75017016132673, "train/model_opt_grad_steps": 72874.81865284975, "train/model_opt_loss": 12267.227857836788, "train/model_opt_model_opt_grad_overflow": 0.0051813471502590676, "train/model_opt_model_opt_grad_scale": 1599.740932642487, "train/policy_entropy_mag": 2.4498069348112907, "train/policy_entropy_max": 2.4498069348112907, "train/policy_entropy_mean": 0.4469951545636271, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.5949138639195596, "train/policy_logprob_mag": 7.438384083268556, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.4475344518305724, "train/policy_logprob_min": -7.438384083268556, "train/policy_logprob_std": 1.0468942624917301, "train/policy_randomness_mag": 0.8646743408756553, "train/policy_randomness_max": 0.8646743408756553, "train/policy_randomness_mean": 0.15776967222517635, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.2099784878251466, "train/post_ent_mag": 58.491325477244324, "train/post_ent_max": 58.491325477244324, "train/post_ent_mean": 40.88710743405041, "train/post_ent_min": 19.473554102250333, "train/post_ent_std": 6.63680444480224, "train/prior_ent_mag": 75.2479572987927, "train/prior_ent_max": 75.2479572987927, "train/prior_ent_mean": 47.29386113221164, "train/prior_ent_min": 27.732028289162432, "train/prior_ent_std": 7.574859762438838, "train/rep_loss_mean": 6.41159318765828, "train/rep_loss_std": 8.693097932351067, "train/reward_avg": 0.03094691124025713, "train/reward_loss_mean": 0.049016758085378094, "train/reward_loss_std": 0.20993260645495795, "train/reward_max_data": 1.0139896406410889, "train/reward_max_pred": 1.0126380018619676, "train/reward_neg_acc": 0.9947810657901467, "train/reward_neg_loss": 0.022786577767813145, "train/reward_pos_acc": 0.9835789626744127, "train/reward_pos_loss": 0.7547388363996318, "train/reward_pred": 0.03050764408348601, "train/reward_rate": 0.03580897830310881, "train_stats/sum_log_reward": 7.1000000803094165, "train_stats/max_log_achievement_collect_coal": 0.23684210526315788, "train_stats/max_log_achievement_collect_drink": 4.473684210526316, "train_stats/max_log_achievement_collect_sapling": 2.1315789473684212, "train_stats/max_log_achievement_collect_stone": 3.736842105263158, "train_stats/max_log_achievement_collect_wood": 6.7368421052631575, "train_stats/max_log_achievement_defeat_skeleton": 0.02631578947368421, "train_stats/max_log_achievement_defeat_zombie": 0.2894736842105263, "train_stats/max_log_achievement_eat_cow": 0.02631578947368421, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.1578947368421053, "train_stats/max_log_achievement_make_wood_sword": 0.02631578947368421, "train_stats/max_log_achievement_place_furnace": 0.02631578947368421, "train_stats/max_log_achievement_place_plant": 1.894736842105263, "train_stats/max_log_achievement_place_stone": 3.026315789473684, "train_stats/max_log_achievement_place_table": 2.289473684210526, "train_stats/max_log_achievement_wake_up": 2.1052631578947367, "train_stats/mean_log_entropy": 0.386050404294541, "eval_stats/sum_log_reward": 7.100000202655792, "eval_stats/max_log_achievement_collect_coal": 0.125, "eval_stats/max_log_achievement_collect_drink": 3.5, "eval_stats/max_log_achievement_collect_sapling": 1.125, "eval_stats/max_log_achievement_collect_stone": 7.0, "eval_stats/max_log_achievement_collect_wood": 6.875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.125, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.75, "eval_stats/max_log_achievement_make_wood_sword": 0.125, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.125, "eval_stats/max_log_achievement_place_stone": 5.375, "eval_stats/max_log_achievement_place_table": 2.25, "eval_stats/max_log_achievement_wake_up": 1.625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 1.3164822121325415e-06, "report/cont_loss_std": 6.2805297602608334e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 5.019173113396391e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 1.1248146165598882e-06, "report/cont_pred": 0.9960929155349731, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 5.845439910888672, "report/dyn_loss_std": 8.064115524291992, "report/image_loss_mean": 2.950791835784912, "report/image_loss_std": 7.26718807220459, "report/model_loss_mean": 6.5155205726623535, "report/model_loss_std": 11.249343872070312, "report/post_ent_mag": 60.982933044433594, "report/post_ent_max": 60.982933044433594, "report/post_ent_mean": 41.048255920410156, "report/post_ent_min": 20.73624038696289, "report/post_ent_std": 6.780644416809082, "report/prior_ent_mag": 75.62919616699219, "report/prior_ent_max": 75.62919616699219, "report/prior_ent_mean": 47.33011245727539, "report/prior_ent_min": 27.378929138183594, "report/prior_ent_std": 7.422863960266113, "report/rep_loss_mean": 5.845439910888672, "report/rep_loss_std": 8.064115524291992, "report/reward_avg": 0.03994140774011612, "report/reward_loss_mean": 0.05746382474899292, "report/reward_loss_std": 0.22939501702785492, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.0761189460754395, "report/reward_neg_acc": 0.9907975196838379, "report/reward_neg_loss": 0.023910026997327805, "report/reward_pos_acc": 0.97826087474823, "report/reward_pos_loss": 0.7708466649055481, "report/reward_pred": 0.03869006782770157, "report/reward_rate": 0.044921875, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 5.853339098393917e-05, "eval/cont_loss_std": 0.0006988034001551569, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0011750569101423025, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 5.305486047291197e-05, "eval/cont_pred": 0.9950703978538513, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 20.897159576416016, "eval/dyn_loss_std": 11.818183898925781, "eval/image_loss_mean": 24.14850616455078, "eval/image_loss_std": 25.000125885009766, "eval/model_loss_mean": 36.88212585449219, "eval/model_loss_std": 29.225730895996094, "eval/post_ent_mag": 56.97503662109375, "eval/post_ent_max": 56.97503662109375, "eval/post_ent_mean": 39.11024856567383, "eval/post_ent_min": 22.781375885009766, "eval/post_ent_std": 6.211103916168213, "eval/prior_ent_mag": 75.62919616699219, "eval/prior_ent_max": 75.62919616699219, "eval/prior_ent_mean": 53.20714569091797, "eval/prior_ent_min": 34.020668029785156, "eval/prior_ent_std": 7.046222686767578, "eval/rep_loss_mean": 20.897159576416016, "eval/rep_loss_std": 11.818183898925781, "eval/reward_avg": 0.03896484151482582, "eval/reward_loss_mean": 0.19526158273220062, "eval/reward_loss_std": 1.0476828813552856, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.001150369644165, "eval/reward_neg_acc": 0.9928498864173889, "eval/reward_neg_loss": 0.07980078458786011, "eval/reward_pos_acc": 0.7111111283302307, "eval/reward_pos_loss": 2.7071754932403564, "eval/reward_pred": 0.028023522347211838, "eval/reward_rate": 0.0439453125, "replay/size": 296681.0, "replay/inserts": 7748.0, "replay/samples": 30992.0, "replay/insert_wait_avg": 1.5146103358231811e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.329417308951138e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 59944.0, "eval_replay/inserts": 1968.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1547794186972022e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.493661880493164e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2582588195801, "timer/env.step_count": 969.0, "timer/env.step_total": 81.82940459251404, "timer/env.step_frac": 0.08180827688349422, "timer/env.step_avg": 0.0844472699613148, "timer/env.step_min": 0.023324251174926758, "timer/env.step_max": 1.9795832633972168, "timer/replay._sample_count": 30992.0, "timer/replay._sample_total": 15.297749042510986, "timer/replay._sample_frac": 0.015293799283961016, "timer/replay._sample_avg": 0.0004936031570247479, "timer/replay._sample_min": 0.0003871917724609375, "timer/replay._sample_max": 0.01119852066040039, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1215.0, "timer/agent.policy_total": 19.508545398712158, "timer/agent.policy_frac": 0.019503508445643317, "timer/agent.policy_avg": 0.01605641596601824, "timer/agent.policy_min": 0.009327411651611328, "timer/agent.policy_max": 0.062319278717041016, "timer/dataset_train_count": 1937.0, "timer/dataset_train_total": 0.2858600616455078, "timer/dataset_train_frac": 0.0002857862548246846, "timer/dataset_train_avg": 0.00014757876182008663, "timer/dataset_train_min": 8.821487426757812e-05, "timer/dataset_train_max": 0.0008883476257324219, "timer/agent.train_count": 1937.0, "timer/agent.train_total": 865.2284812927246, "timer/agent.train_frac": 0.8650050861002576, "timer/agent.train_avg": 0.44668481223165957, "timer/agent.train_min": 0.4379696846008301, "timer/agent.train_max": 0.9811463356018066, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4762420654296875, "timer/agent.report_frac": 0.0004761191034720453, "timer/agent.report_avg": 0.23812103271484375, "timer/agent.report_min": 0.23241329193115234, "timer/agent.report_max": 0.24382877349853516, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0279159545898438e-05, "timer/dataset_eval_frac": 3.0271341704922616e-08, "timer/dataset_eval_avg": 3.0279159545898438e-05, "timer/dataset_eval_min": 3.0279159545898438e-05, "timer/dataset_eval_max": 3.0279159545898438e-05, "fps": 7.745894935065257}
{"step": 297192, "time": 38353.83115243912, "episode/length": 204.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 297208, "time": 38357.3591530323, "episode/length": 293.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9863945578231292, "episode/intrinsic_return": 0.0}
{"step": 297224, "time": 38360.78974914551, "episode/length": 250.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9760956175298805, "episode/intrinsic_return": 0.0}
{"step": 297336, "time": 38375.384507894516, "episode/length": 155.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 297432, "time": 38388.579134225845, "episode/length": 139.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9571428571428572, "episode/intrinsic_return": 0.0}
{"step": 298080, "time": 38465.64828133583, "episode/length": 244.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9836734693877551, "episode/intrinsic_return": 0.0}
{"step": 298568, "time": 38524.12978339195, "episode/length": 197.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9646464646464646, "episode/intrinsic_return": 0.0}
{"step": 298576, "time": 38526.49062371254, "episode/length": 172.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 298608, "time": 38531.62518262863, "episode/length": 174.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 298880, "time": 38564.66361784935, "episode/length": 206.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 298928, "time": 38571.750349998474, "episode/length": 198.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 299040, "time": 38586.28821659088, "episode/length": 119.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.95, "episode/intrinsic_return": 0.0}
{"step": 299168, "time": 38602.71920919418, "episode/length": 423.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 299848, "time": 38683.17040705681, "episode/length": 158.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 299872, "time": 38687.4427754879, "episode/length": 304.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9868852459016394, "episode/intrinsic_return": 0.0}
{"step": 299960, "time": 38699.18339252472, "episode/length": 168.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 300040, "time": 38728.73935842514, "eval_episode/length": 157.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9936708860759493}
{"step": 300040, "time": 38730.50571203232, "eval_episode/length": 163.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9939024390243902}
{"step": 300040, "time": 38732.35332989693, "eval_episode/length": 170.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9707602339181286}
{"step": 300040, "time": 38733.96731543541, "eval_episode/length": 172.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9884393063583815}
{"step": 300040, "time": 38735.77636265755, "eval_episode/length": 177.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9943820224719101}
{"step": 300040, "time": 38738.330488204956, "eval_episode/length": 201.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9752475247524752}
{"step": 300040, "time": 38739.87524271011, "eval_episode/length": 38.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 300040, "time": 38745.029469013214, "eval_episode/length": 289.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9896551724137931}
{"step": 300072, "time": 38748.70883107185, "episode/length": 187.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 300104, "time": 38753.916011571884, "episode/length": 146.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9659863945578231, "episode/intrinsic_return": 0.0}
{"step": 300368, "time": 38785.92750287056, "episode/length": 185.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 300696, "time": 38826.30910015106, "episode/length": 206.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9855072463768116, "episode/intrinsic_return": 0.0}
{"step": 301048, "time": 38868.64279818535, "episode/length": 234.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 301384, "time": 38909.19566655159, "episode/length": 188.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 301440, "time": 38917.13510107994, "episode/length": 166.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 301472, "time": 38922.459297180176, "episode/length": 174.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 301760, "time": 38957.52427101135, "episode/length": 238.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 301776, "time": 38960.84837412834, "episode/length": 226.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9779735682819384, "episode/intrinsic_return": 0.0}
{"step": 301976, "time": 38985.5728187561, "episode/length": 159.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 302024, "time": 38993.12964653969, "episode/length": 206.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 302368, "time": 39034.409346818924, "episode/length": 164.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 302728, "time": 39077.808314323425, "episode/length": 167.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 302888, "time": 39098.25478339195, "episode/length": 180.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9613259668508287, "episode/intrinsic_return": 0.0}
{"step": 302960, "time": 39108.27888703346, "episode/length": 185.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 303112, "time": 39128.639003276825, "episode/length": 166.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9820359281437125, "episode/intrinsic_return": 0.0}
{"step": 303440, "time": 39168.323640584946, "episode/length": 176.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 303664, "time": 39196.025819301605, "episode/length": 161.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 303744, "time": 39206.71701622009, "episode/length": 247.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9798387096774194, "episode/intrinsic_return": 0.0}
{"step": 304232, "time": 39264.926669836044, "episode/length": 187.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 304248, "time": 39268.799164533615, "episode/length": 283.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9894366197183099, "episode/intrinsic_return": 0.0}
{"step": 304472, "time": 39296.86487746239, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 304592, "time": 39312.50540685654, "episode/length": 203.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 304864, "time": 39345.790382385254, "episode/length": 139.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 304905, "time": 39353.25510716438, "train_stats/sum_log_reward": 7.490243981524212, "train_stats/max_log_achievement_collect_coal": 0.2682926829268293, "train_stats/max_log_achievement_collect_drink": 3.048780487804878, "train_stats/max_log_achievement_collect_sapling": 2.1951219512195124, "train_stats/max_log_achievement_collect_stone": 5.926829268292683, "train_stats/max_log_achievement_collect_wood": 6.902439024390244, "train_stats/max_log_achievement_defeat_skeleton": 0.04878048780487805, "train_stats/max_log_achievement_defeat_zombie": 0.24390243902439024, "train_stats/max_log_achievement_eat_cow": 0.0975609756097561, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.5121951219512195, "train_stats/max_log_achievement_make_wood_sword": 0.024390243902439025, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 2.024390243902439, "train_stats/max_log_achievement_place_stone": 4.7317073170731705, "train_stats/max_log_achievement_place_table": 2.4390243902439024, "train_stats/max_log_achievement_wake_up": 2.073170731707317, "train_stats/mean_log_entropy": 0.3932759165763855, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.809405549202558, "train/action_min": 0.0, "train/action_std": 3.5513448443437485, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04607151718954966, "train/actor_opt_grad_steps": 74870.0, "train/actor_opt_loss": -11.707094446384382, "train/adv_mag": 0.4916468542165707, "train/adv_max": 0.459698064957258, "train/adv_mean": 0.002984857021736087, "train/adv_min": -0.4000355071663239, "train/adv_std": 0.058224019724779176, "train/cont_avg": 0.9946213163860104, "train/cont_loss_mean": 5.8357610212455364e-05, "train/cont_loss_std": 0.0014950344705438148, "train/cont_neg_acc": 0.9994818654702735, "train/cont_neg_loss": 0.004833539888156474, "train/cont_pos_acc": 0.9999948733828846, "train/cont_pos_loss": 2.0451089009854955e-05, "train/cont_pred": 0.9946187246648759, "train/cont_rate": 0.9946213163860104, "train/dyn_loss_mean": 6.493719884151004, "train/dyn_loss_std": 8.80455712827376, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.134409175944452, "train/extr_critic_critic_opt_grad_steps": 74870.0, "train/extr_critic_critic_opt_loss": 16996.246635160296, "train/extr_critic_mag": 7.960442340435759, "train/extr_critic_max": 7.960442340435759, "train/extr_critic_mean": 1.7341078087455868, "train/extr_critic_min": -0.6096960219694543, "train/extr_critic_std": 1.855937852143006, "train/extr_return_normed_mag": 1.551609647088718, "train/extr_return_normed_max": 1.551609647088718, "train/extr_return_normed_mean": 0.33876436176695357, "train/extr_return_normed_min": -0.11642606560275963, "train/extr_return_normed_std": 0.3283225367415137, "train/extr_return_rate": 0.6285315123555574, "train/extr_return_raw_mag": 8.73871086051427, "train/extr_return_raw_max": 8.73871086051427, "train/extr_return_raw_mean": 1.7513038939144945, "train/extr_return_raw_min": -0.8704054720043518, "train/extr_return_raw_std": 1.8913942229562473, "train/extr_reward_mag": 1.034133219965999, "train/extr_reward_max": 1.034133219965999, "train/extr_reward_mean": 0.03956020801989217, "train/extr_reward_min": -0.6803814500107048, "train/extr_reward_std": 0.19522687553432938, "train/image_loss_mean": 3.7738390191231366, "train/image_loss_std": 8.498387895099857, "train/model_loss_mean": 7.717905694338942, "train/model_loss_std": 12.632793446278942, "train/model_opt_grad_norm": 44.63703159470632, "train/model_opt_grad_steps": 74803.46632124353, "train/model_opt_loss": 11255.400481703367, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1450.7772020725388, "train/policy_entropy_mag": 2.4311874135170575, "train/policy_entropy_max": 2.4311874135170575, "train/policy_entropy_mean": 0.4289888094126252, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.5419775454491531, "train/policy_logprob_mag": 7.438384048679332, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.4283305127077152, "train/policy_logprob_min": -7.438384048679332, "train/policy_logprob_std": 1.0354452491424244, "train/policy_randomness_mag": 0.8581024683201252, "train/policy_randomness_max": 0.8581024683201252, "train/policy_randomness_mean": 0.1514142234785569, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.19129428970072554, "train/post_ent_mag": 58.85481643676758, "train/post_ent_max": 58.85481643676758, "train/post_ent_mean": 41.234002068870424, "train/post_ent_min": 19.700234339027208, "train/post_ent_std": 6.7608702615135075, "train/prior_ent_mag": 75.37397560554464, "train/prior_ent_max": 75.37397560554464, "train/prior_ent_mean": 47.67681036835507, "train/prior_ent_min": 27.690484328591143, "train/prior_ent_std": 7.5869330692785395, "train/rep_loss_mean": 6.493719884151004, "train/rep_loss_std": 8.80455712827376, "train/reward_avg": 0.02923666199891215, "train/reward_loss_mean": 0.04777644074719804, "train/reward_loss_std": 0.20515954787867058, "train/reward_max_data": 1.0119171012868535, "train/reward_max_pred": 1.0110603997126761, "train/reward_neg_acc": 0.9948320039813383, "train/reward_neg_loss": 0.02289448031393203, "train/reward_pos_acc": 0.9853802230691663, "train/reward_pos_loss": 0.7514718165669416, "train/reward_pred": 0.02889305239765292, "train/reward_rate": 0.03406836949481865, "eval_stats/sum_log_reward": 6.350000023841858, "eval_stats/max_log_achievement_collect_coal": 0.5, "eval_stats/max_log_achievement_collect_drink": 4.5, "eval_stats/max_log_achievement_collect_sapling": 0.875, "eval_stats/max_log_achievement_collect_stone": 7.75, "eval_stats/max_log_achievement_collect_wood": 5.125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.875, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 0.875, "eval_stats/max_log_achievement_place_stone": 5.75, "eval_stats/max_log_achievement_place_table": 1.875, "eval_stats/max_log_achievement_wake_up": 1.25, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 7.767705028527416e-06, "report/cont_loss_std": 0.00018613341671880335, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.2228082596266177e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 7.745818948023953e-06, "report/cont_pred": 0.9951095581054688, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 6.5468597412109375, "report/dyn_loss_std": 9.088200569152832, "report/image_loss_mean": 4.5284037590026855, "report/image_loss_std": 9.039204597473145, "report/model_loss_mean": 8.490143775939941, "report/model_loss_std": 13.108529090881348, "report/post_ent_mag": 60.538230895996094, "report/post_ent_max": 60.538230895996094, "report/post_ent_mean": 41.81224060058594, "report/post_ent_min": 20.991214752197266, "report/post_ent_std": 7.100383758544922, "report/prior_ent_mag": 75.265625, "report/prior_ent_max": 75.265625, "report/prior_ent_mean": 48.683006286621094, "report/prior_ent_min": 29.04323387145996, "report/prior_ent_std": 7.450589656829834, "report/rep_loss_mean": 6.5468597412109375, "report/rep_loss_std": 9.088200569152832, "report/reward_avg": 0.01689453050494194, "report/reward_loss_mean": 0.033617258071899414, "report/reward_loss_std": 0.1740378439426422, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.001086711883545, "report/reward_neg_acc": 0.999002993106842, "report/reward_neg_loss": 0.020184947177767754, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.675169825553894, "report/reward_pred": 0.017382292076945305, "report/reward_rate": 0.0205078125, "eval/cont_avg": 0.9931640625, "eval/cont_loss_mean": 0.001274068490602076, "eval/cont_loss_std": 0.031567007303237915, "eval/cont_neg_acc": 0.8571429252624512, "eval/cont_neg_loss": 0.1758696734905243, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 7.232880307128653e-05, "eval/cont_pred": 0.9939237833023071, "eval/cont_rate": 0.9931640625, "eval/dyn_loss_mean": 21.229568481445312, "eval/dyn_loss_std": 12.740171432495117, "eval/image_loss_mean": 24.387042999267578, "eval/image_loss_std": 26.658077239990234, "eval/model_loss_mean": 37.306396484375, "eval/model_loss_std": 31.31334114074707, "eval/post_ent_mag": 58.29412078857422, "eval/post_ent_max": 58.29412078857422, "eval/post_ent_mean": 39.04496765136719, "eval/post_ent_min": 20.6551513671875, "eval/post_ent_std": 6.80526876449585, "eval/prior_ent_mag": 75.265625, "eval/prior_ent_max": 75.265625, "eval/prior_ent_mean": 52.85731887817383, "eval/prior_ent_min": 33.08604431152344, "eval/prior_ent_std": 6.5262250900268555, "eval/rep_loss_mean": 21.229568481445312, "eval/rep_loss_std": 12.740171432495117, "eval/reward_avg": 0.03994140774011612, "eval/reward_loss_mean": 0.18033915758132935, "eval/reward_loss_std": 0.9640995860099792, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0071871280670166, "eval/reward_neg_acc": 0.9959099888801575, "eval/reward_neg_loss": 0.08955295383930206, "eval/reward_pos_acc": 0.804347813129425, "eval/reward_pos_loss": 2.110532283782959, "eval/reward_pred": 0.03193090111017227, "eval/reward_rate": 0.044921875, "replay/size": 304401.0, "replay/inserts": 7720.0, "replay/samples": 30880.0, "replay/insert_wait_avg": 1.5552797465744414e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.477294595748032e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 62264.0, "eval_replay/inserts": 2320.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1575633081896552e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 999.9990408420563, "timer/env.step_count": 965.0, "timer/env.step_total": 89.37681365013123, "timer/env.step_frac": 0.08937689937669425, "timer/env.step_avg": 0.09261845974106862, "timer/env.step_min": 0.0229949951171875, "timer/env.step_max": 2.080038547515869, "timer/replay._sample_count": 30880.0, "timer/replay._sample_total": 15.436399936676025, "timer/replay._sample_frac": 0.015436414742635848, "timer/replay._sample_avg": 0.0004998834176384723, "timer/replay._sample_min": 0.0003731250762939453, "timer/replay._sample_max": 0.02513885498046875, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1255.0, "timer/agent.policy_total": 19.959735870361328, "timer/agent.policy_frac": 0.019959755014918906, "timer/agent.policy_avg": 0.01590417200825604, "timer/agent.policy_min": 0.009202718734741211, "timer/agent.policy_max": 0.06426215171813965, "timer/dataset_train_count": 1930.0, "timer/dataset_train_total": 0.28664493560791016, "timer/dataset_train_frac": 0.0002866452105459409, "timer/dataset_train_avg": 0.00014852069202482391, "timer/dataset_train_min": 9.179115295410156e-05, "timer/dataset_train_max": 0.000743865966796875, "timer/agent.train_count": 1930.0, "timer/agent.train_total": 856.7111921310425, "timer/agent.train_frac": 0.8567120138531761, "timer/agent.train_avg": 0.44389180939432255, "timer/agent.train_min": 0.4336411952972412, "timer/agent.train_max": 1.3704192638397217, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4792616367340088, "timer/agent.report_frac": 0.0004792620964220557, "timer/agent.report_avg": 0.2396308183670044, "timer/agent.report_min": 0.2322375774383545, "timer/agent.report_max": 0.2470240592956543, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.4809112548828125e-05, "timer/dataset_eval_frac": 3.4809145936296966e-08, "timer/dataset_eval_avg": 3.4809112548828125e-05, "timer/dataset_eval_min": 3.4809112548828125e-05, "timer/dataset_eval_max": 3.4809112548828125e-05, "fps": 7.7199007363399}
{"step": 305024, "time": 39366.98772192001, "episode/length": 197.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 305064, "time": 39373.15803408623, "episode/length": 271.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9816176470588235, "episode/intrinsic_return": 0.0}
{"step": 305080, "time": 39376.58466672897, "episode/length": 103.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9519230769230769, "episode/intrinsic_return": 0.0}
{"step": 305096, "time": 39379.946776628494, "episode/length": 178.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 305992, "time": 39485.97198653221, "episode/length": 140.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9574468085106383, "episode/intrinsic_return": 0.0}
{"step": 306080, "time": 39497.770644664764, "episode/length": 131.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9924242424242424, "episode/intrinsic_return": 0.0}
{"step": 306200, "time": 39513.28654241562, "episode/length": 200.0, "episode/score": 9.100000031292439, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 306360, "time": 39533.60770058632, "episode/length": 161.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 306536, "time": 39555.617731809616, "episode/length": 181.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 306872, "time": 39596.050820589066, "episode/length": 299.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 306880, "time": 39598.623505592346, "episode/length": 222.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9730941704035875, "episode/intrinsic_return": 0.0}
{"step": 307496, "time": 39671.8690302372, "episode/length": 161.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 307616, "time": 39687.33998918533, "episode/length": 422.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 307640, "time": 39691.63841819763, "episode/length": 194.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9692307692307692, "episode/intrinsic_return": 0.0}
{"step": 307656, "time": 39695.12461519241, "episode/length": 207.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 307808, "time": 39714.202511787415, "episode/length": 158.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 308040, "time": 39742.57444548607, "episode/length": 209.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 308248, "time": 39768.283452034, "episode/length": 170.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 308544, "time": 39804.25961923599, "episode/length": 115.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9913793103448276, "episode/intrinsic_return": 0.0}
{"step": 308960, "time": 39854.145245075226, "episode/length": 260.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9961685823754789, "episode/intrinsic_return": 0.0}
{"step": 309088, "time": 39870.461596250534, "episode/length": 198.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9698492462311558, "episode/intrinsic_return": 0.0}
{"step": 309112, "time": 39874.77934408188, "episode/length": 162.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 309192, "time": 39885.52729535103, "episode/length": 191.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9583333333333334, "episode/intrinsic_return": 0.0}
{"step": 309792, "time": 39956.73047375679, "episode/length": 192.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 310024, "time": 40003.89735579491, "eval_episode/length": 162.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9754601226993865}
{"step": 310024, "time": 40005.46098613739, "eval_episode/length": 163.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9939024390243902}
{"step": 310024, "time": 40007.55010700226, "eval_episode/length": 175.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9715909090909091}
{"step": 310024, "time": 40010.12482094765, "eval_episode/length": 201.0, "eval_episode/score": 5.099999971687794, "eval_episode/reward_rate": 0.995049504950495}
{"step": 310024, "time": 40011.73285460472, "eval_episode/length": 202.0, "eval_episode/score": 8.100000023841858, "eval_episode/reward_rate": 0.9950738916256158}
{"step": 310024, "time": 40013.43297290802, "eval_episode/length": 208.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9760765550239234}
{"step": 310024, "time": 40016.90334510803, "eval_episode/length": 254.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9764705882352941}
{"step": 310024, "time": 40019.35303878784, "eval_episode/length": 276.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9963898916967509}
{"step": 310168, "time": 40036.089324474335, "episode/length": 265.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9887218045112782, "episode/intrinsic_return": 0.0}
{"step": 310208, "time": 40042.17997980118, "episode/length": 207.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 310304, "time": 40054.78100657463, "episode/length": 148.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.959731543624161, "episode/intrinsic_return": 0.0}
{"step": 310360, "time": 40062.79964661598, "episode/length": 174.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9657142857142857, "episode/intrinsic_return": 0.0}
{"step": 310528, "time": 40083.84418320656, "episode/length": 166.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 310768, "time": 40113.17756104469, "episode/length": 209.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 311008, "time": 40142.73316669464, "episode/length": 420.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9786223277909739, "episode/intrinsic_return": 0.0}
{"step": 311024, "time": 40146.0321187973, "episode/length": 153.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 311688, "time": 40226.003851890564, "episode/length": 144.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 311752, "time": 40234.94892168045, "episode/length": 197.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 311808, "time": 40243.0413441658, "episode/length": 187.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9680851063829787, "episode/intrinsic_return": 0.0}
{"step": 312352, "time": 40307.747388362885, "episode/length": 165.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 312608, "time": 40339.037939071655, "episode/length": 299.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9866666666666667, "episode/intrinsic_return": 0.0}
{"step": 312664, "time": 40347.081627607346, "episode/length": 206.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 312697, "time": 40353.32722568512, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.767329915364583, "train/action_min": 0.0, "train/action_std": 3.5152969262538813, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04598461230022785, "train/actor_opt_grad_steps": 76810.0, "train/actor_opt_loss": -11.420535880174393, "train/adv_mag": 0.4879394436493898, "train/adv_max": 0.45139742890993756, "train/adv_mean": 0.0028779425512766464, "train/adv_min": -0.4104258777239384, "train/adv_std": 0.05771394184766672, "train/cont_avg": 0.9947566105769231, "train/cont_loss_mean": 7.804926108656801e-05, "train/cont_loss_std": 0.0023021235090047807, "train/cont_neg_acc": 0.9991452993490757, "train/cont_neg_loss": 0.00688400940216758, "train/cont_pos_acc": 0.9999899115317907, "train/cont_pos_loss": 4.1851036066676585e-05, "train/cont_pred": 0.9947468641476753, "train/cont_rate": 0.9947566105769231, "train/dyn_loss_mean": 6.443827453026405, "train/dyn_loss_std": 8.74811142163399, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.114372116785783, "train/extr_critic_critic_opt_grad_steps": 76810.0, "train/extr_critic_critic_opt_loss": 16884.97487479968, "train/extr_critic_mag": 7.947692582546137, "train/extr_critic_max": 7.947692582546137, "train/extr_critic_mean": 1.7190529823303222, "train/extr_critic_min": -0.5874140403209589, "train/extr_critic_std": 1.8508705475391485, "train/extr_return_normed_mag": 1.5436159922526433, "train/extr_return_normed_max": 1.5436159922526433, "train/extr_return_normed_mean": 0.33296195757694735, "train/extr_return_normed_min": -0.11998053877017437, "train/extr_return_normed_std": 0.3257021016799487, "train/extr_return_rate": 0.6325234031065916, "train/extr_return_raw_mag": 8.7496903468401, "train/extr_return_raw_max": 8.7496903468401, "train/extr_return_raw_mean": 1.7357096965496357, "train/extr_return_raw_min": -0.8880598893532387, "train/extr_return_raw_std": 1.8869514471445328, "train/extr_reward_mag": 1.0378476827572554, "train/extr_reward_max": 1.0378476827572554, "train/extr_reward_mean": 0.04032848528944529, "train/extr_reward_min": -0.6664320285503681, "train/extr_reward_std": 0.19737023772337497, "train/image_loss_mean": 3.694962813304021, "train/image_loss_std": 8.355745364458134, "train/model_loss_mean": 7.608299600161039, "train/model_loss_std": 12.41743986178667, "train/model_opt_grad_norm": 44.7306335351406, "train/model_opt_grad_steps": 76741.56923076924, "train/model_opt_loss": 9958.786135316506, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1307.6923076923076, "train/policy_entropy_mag": 2.422382106536474, "train/policy_entropy_max": 2.422382106536474, "train/policy_entropy_mean": 0.407131140660017, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.5228559831778209, "train/policy_logprob_mag": 7.438384065872584, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.4066628929896232, "train/policy_logprob_min": -7.438384065872584, "train/policy_logprob_std": 1.0169912735621134, "train/policy_randomness_mag": 0.854994580684564, "train/policy_randomness_max": 0.854994580684564, "train/policy_randomness_mean": 0.14369942584098913, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.18454521798934692, "train/post_ent_mag": 58.52759794577574, "train/post_ent_max": 58.52759794577574, "train/post_ent_mean": 41.15060845399514, "train/post_ent_min": 19.679857459435095, "train/post_ent_std": 6.7155646593142775, "train/prior_ent_mag": 75.39381017440405, "train/prior_ent_max": 75.39381017440405, "train/prior_ent_mean": 47.586863610683345, "train/prior_ent_min": 27.999077469263323, "train/prior_ent_std": 7.536482984591753, "train/rep_loss_mean": 6.443827453026405, "train/rep_loss_std": 8.74811142163399, "train/reward_avg": 0.029225260296311135, "train/reward_loss_mean": 0.04696230842516973, "train/reward_loss_std": 0.20094600633168833, "train/reward_max_data": 1.014871798417507, "train/reward_max_pred": 1.0128964687005066, "train/reward_neg_acc": 0.9951024999985328, "train/reward_neg_loss": 0.022356395497440527, "train/reward_pos_acc": 0.9838034932429974, "train/reward_pos_loss": 0.7476004050328181, "train/reward_pred": 0.028942032631200095, "train/reward_rate": 0.034009415064102565, "train_stats/sum_log_reward": 7.678947549117239, "train_stats/max_log_achievement_collect_coal": 0.2894736842105263, "train_stats/max_log_achievement_collect_drink": 3.789473684210526, "train_stats/max_log_achievement_collect_sapling": 1.868421052631579, "train_stats/max_log_achievement_collect_stone": 6.815789473684211, "train_stats/max_log_achievement_collect_wood": 6.131578947368421, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.15789473684210525, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.02631578947368421, "train_stats/max_log_achievement_make_wood_pickaxe": 1.1842105263157894, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_furnace": 0.13157894736842105, "train_stats/max_log_achievement_place_plant": 1.763157894736842, "train_stats/max_log_achievement_place_stone": 5.2368421052631575, "train_stats/max_log_achievement_place_table": 1.9210526315789473, "train_stats/max_log_achievement_wake_up": 2.1052631578947367, "train_stats/mean_log_entropy": 0.38395015816939504, "train_stats/max_log_achievement_make_stone_sword": 0.034482758620689655, "eval_stats/sum_log_reward": 7.350000202655792, "eval_stats/max_log_achievement_collect_coal": 0.375, "eval_stats/max_log_achievement_collect_drink": 3.875, "eval_stats/max_log_achievement_collect_sapling": 1.875, "eval_stats/max_log_achievement_collect_stone": 4.625, "eval_stats/max_log_achievement_collect_wood": 7.5, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.375, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.25, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.875, "eval_stats/max_log_achievement_place_stone": 3.875, "eval_stats/max_log_achievement_place_table": 2.5, "eval_stats/max_log_achievement_wake_up": 2.125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.00019706314196810126, "report/cont_loss_std": 0.004727660678327084, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.028486181050539017, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 2.3494967535953037e-06, "report/cont_pred": 0.9933457374572754, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 7.145605087280273, "report/dyn_loss_std": 9.567410469055176, "report/image_loss_mean": 4.180750846862793, "report/image_loss_std": 8.735755920410156, "report/model_loss_mean": 8.51552963256836, "report/model_loss_std": 13.189901351928711, "report/post_ent_mag": 60.79067611694336, "report/post_ent_max": 60.79067611694336, "report/post_ent_mean": 41.222740173339844, "report/post_ent_min": 20.440690994262695, "report/post_ent_std": 7.217857837677002, "report/prior_ent_mag": 75.40913391113281, "report/prior_ent_max": 75.40913391113281, "report/prior_ent_mean": 48.26051330566406, "report/prior_ent_min": 27.437143325805664, "report/prior_ent_std": 7.4784626960754395, "report/rep_loss_mean": 7.145605087280273, "report/rep_loss_std": 9.567410469055176, "report/reward_avg": 0.02783203125, "report/reward_loss_mean": 0.047218628227710724, "report/reward_loss_std": 0.23832429945468903, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.004181146621704, "report/reward_neg_acc": 0.9898886680603027, "report/reward_neg_loss": 0.02502390369772911, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6743780374526978, "report/reward_pred": 0.029556598514318466, "report/reward_rate": 0.0341796875, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 2.4450306227663532e-05, "eval/cont_loss_std": 0.0005046843434683979, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.008086309768259525, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 7.6218020694796e-07, "eval/cont_pred": 0.9970932006835938, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 20.051265716552734, "eval/dyn_loss_std": 13.006978034973145, "eval/image_loss_mean": 22.90352439880371, "eval/image_loss_std": 28.645042419433594, "eval/model_loss_mean": 35.0318717956543, "eval/model_loss_std": 33.385231018066406, "eval/post_ent_mag": 58.763702392578125, "eval/post_ent_max": 58.763702392578125, "eval/post_ent_mean": 39.28681182861328, "eval/post_ent_min": 19.288253784179688, "eval/post_ent_std": 7.16255521774292, "eval/prior_ent_mag": 75.40913391113281, "eval/prior_ent_max": 75.40913391113281, "eval/prior_ent_mean": 52.03471374511719, "eval/prior_ent_min": 34.67778396606445, "eval/prior_ent_std": 7.278784275054932, "eval/rep_loss_mean": 20.051265716552734, "eval/rep_loss_std": 13.006978034973145, "eval/reward_avg": 0.02685546875, "eval/reward_loss_mean": 0.09756310284137726, "eval/reward_loss_std": 0.6363800168037415, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0063502788543701, "eval/reward_neg_acc": 0.9889224767684937, "eval/reward_neg_loss": 0.040055498480796814, "eval/reward_pos_acc": 0.774193525314331, "eval/reward_pos_loss": 1.9396615028381348, "eval/reward_pred": 0.021463358774781227, "eval/reward_rate": 0.0302734375, "replay/size": 312193.0, "replay/inserts": 7792.0, "replay/samples": 31168.0, "replay/insert_wait_avg": 1.5343912328293192e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.441630720847442e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 64480.0, "eval_replay/inserts": 2216.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1428168534371826e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.08970832824707e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0533890724182, "timer/env.step_count": 974.0, "timer/env.step_total": 83.13894772529602, "timer/env.step_frac": 0.08313450925096116, "timer/env.step_avg": 0.08535826255163863, "timer/env.step_min": 0.022965192794799805, "timer/env.step_max": 1.6579358577728271, "timer/replay._sample_count": 31168.0, "timer/replay._sample_total": 15.591448068618774, "timer/replay._sample_frac": 0.015590615700108116, "timer/replay._sample_avg": 0.0005002389652405921, "timer/replay._sample_min": 0.0003695487976074219, "timer/replay._sample_max": 0.03722786903381348, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1251.0, "timer/agent.policy_total": 19.849721670150757, "timer/agent.policy_frac": 0.019848661968499517, "timer/agent.policy_avg": 0.015867083669185256, "timer/agent.policy_min": 0.00950169563293457, "timer/agent.policy_max": 0.06508851051330566, "timer/dataset_train_count": 1948.0, "timer/dataset_train_total": 0.37085866928100586, "timer/dataset_train_frac": 0.0003708388705376912, "timer/dataset_train_avg": 0.00019037919367608105, "timer/dataset_train_min": 9.036064147949219e-05, "timer/dataset_train_max": 0.08551335334777832, "timer/agent.train_count": 1948.0, "timer/agent.train_total": 863.9656076431274, "timer/agent.train_frac": 0.8639194837832442, "timer/agent.train_avg": 0.4435141723014001, "timer/agent.train_min": 0.42786073684692383, "timer/agent.train_max": 1.0120246410369873, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4761509895324707, "timer/agent.report_frac": 0.00047612556962995354, "timer/agent.report_avg": 0.23807549476623535, "timer/agent.report_min": 0.2321639060974121, "timer/agent.report_max": 0.2439870834350586, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8848648071289062e-05, "timer/dataset_eval_frac": 2.8847107950953614e-08, "timer/dataset_eval_avg": 2.8848648071289062e-05, "timer/dataset_eval_min": 2.8848648071289062e-05, "timer/dataset_eval_max": 2.8848648071289062e-05, "fps": 7.791464508460046}
{"step": 312768, "time": 40361.581632852554, "episode/length": 249.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.996, "episode/intrinsic_return": 0.0}
{"step": 313136, "time": 40405.91979289055, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 313376, "time": 40435.31745958328, "episode/length": 195.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 313832, "time": 40489.69756627083, "episode/length": 433.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9792626728110599, "episode/intrinsic_return": 0.0}
{"step": 314008, "time": 40511.80499315262, "episode/length": 174.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9657142857142857, "episode/intrinsic_return": 0.0}
{"step": 314280, "time": 40544.9529569149, "episode/length": 201.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 314368, "time": 40556.66758322716, "episode/length": 251.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 314408, "time": 40562.94515442848, "episode/length": 158.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 314416, "time": 40565.368500709534, "episode/length": 50.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 314536, "time": 40581.58960747719, "episode/length": 347.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 315032, "time": 40641.13881802559, "episode/length": 149.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 315128, "time": 40653.832030296326, "episode/length": 218.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 315960, "time": 40752.12137556076, "episode/length": 209.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 315984, "time": 40756.31156039238, "episode/length": 180.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 316056, "time": 40766.08240890503, "episode/length": 205.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 316152, "time": 40778.706333875656, "episode/length": 222.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.0}
{"step": 316200, "time": 40786.48335146904, "episode/length": 428.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9953379953379954, "episode/intrinsic_return": 0.0}
{"step": 316400, "time": 40811.857969522476, "episode/length": 247.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9758064516129032, "episode/intrinsic_return": 0.0}
{"step": 316984, "time": 40881.06997680664, "episode/length": 243.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 316984, "time": 40881.07864165306, "episode/length": 231.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 317408, "time": 40933.62046003342, "episode/length": 177.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 317448, "time": 40939.73447012901, "episode/length": 173.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 317696, "time": 40970.153341293335, "episode/length": 161.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9567901234567902, "episode/intrinsic_return": 0.0}
{"step": 317720, "time": 40974.49702501297, "episode/length": 219.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 317792, "time": 40984.49084877968, "episode/length": 204.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.0}
{"step": 317952, "time": 41004.605917453766, "episode/length": 120.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9586776859504132, "episode/intrinsic_return": 0.0}
{"step": 318000, "time": 41011.706043958664, "episode/length": 224.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 318160, "time": 41032.03025388718, "episode/length": 146.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9659863945578231, "episode/intrinsic_return": 0.0}
{"step": 318664, "time": 41091.99641776085, "episode/length": 156.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 318800, "time": 41109.32958817482, "episode/length": 168.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 318856, "time": 41117.323989868164, "episode/length": 144.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9517241379310345, "episode/intrinsic_return": 0.0}
{"step": 319224, "time": 41161.687782764435, "episode/length": 187.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 319368, "time": 41180.4659986496, "episode/length": 170.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 319480, "time": 41195.07844424248, "episode/length": 210.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 319768, "time": 41231.848860263824, "episode/length": 226.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.986784140969163, "episode/intrinsic_return": 0.0}
{"step": 320008, "time": 41281.93600654602, "eval_episode/length": 169.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 320008, "time": 41283.82335615158, "eval_episode/length": 179.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9611111111111111}
{"step": 320008, "time": 41285.44551420212, "eval_episode/length": 181.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9725274725274725}
{"step": 320008, "time": 41286.965598106384, "eval_episode/length": 184.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9675675675675676}
{"step": 320008, "time": 41289.03649735451, "eval_episode/length": 198.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9748743718592965}
{"step": 320008, "time": 41289.043690919876, "eval_episode/length": 198.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9748743718592965}
{"step": 320008, "time": 41293.40468597412, "eval_episode/length": 223.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9821428571428571}
{"step": 320008, "time": 41295.67054271698, "eval_episode/length": 55.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9821428571428571}
{"step": 320064, "time": 41302.15424108505, "episode/length": 174.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 320485, "time": 41353.32131910324, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.5648944561298075, "train/action_min": 0.0, "train/action_std": 3.1489839101449038, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04611917407466815, "train/actor_opt_grad_steps": 78760.0, "train/actor_opt_loss": -12.35818881530028, "train/adv_mag": 0.5030532395228361, "train/adv_max": 0.4782998792636089, "train/adv_mean": 0.0027515716346804254, "train/adv_min": -0.39911111562679974, "train/adv_std": 0.0586327884441767, "train/cont_avg": 0.9946113782051282, "train/cont_loss_mean": 0.00010853742967093729, "train/cont_loss_std": 0.0031918193061686068, "train/cont_neg_acc": 0.9987545792873089, "train/cont_neg_loss": 0.00508272014606122, "train/cont_pos_acc": 0.9999798505734174, "train/cont_pos_loss": 7.463904432006128e-05, "train/cont_pred": 0.9945931593577068, "train/cont_rate": 0.9946113782051282, "train/dyn_loss_mean": 6.465377240303235, "train/dyn_loss_std": 8.755576940683218, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1216213859044588, "train/extr_critic_critic_opt_grad_steps": 78760.0, "train/extr_critic_critic_opt_loss": 16764.84662459936, "train/extr_critic_mag": 7.905961435269087, "train/extr_critic_max": 7.905961435269087, "train/extr_critic_mean": 1.6952826408239512, "train/extr_critic_min": -0.6016604399069762, "train/extr_critic_std": 1.827493693278386, "train/extr_return_normed_mag": 1.5540323055707492, "train/extr_return_normed_max": 1.5540323055707492, "train/extr_return_normed_mean": 0.3344993449938603, "train/extr_return_normed_min": -0.12628721789671823, "train/extr_return_normed_std": 0.3276144941647848, "train/extr_return_rate": 0.6254253787872118, "train/extr_return_raw_mag": 8.647049825619428, "train/extr_return_raw_max": 8.647049825619428, "train/extr_return_raw_mean": 1.7109492989686819, "train/extr_return_raw_min": -0.9106571704913409, "train/extr_return_raw_std": 1.8639326480718759, "train/extr_reward_mag": 1.0402985144884158, "train/extr_reward_max": 1.0402985144884158, "train/extr_reward_mean": 0.03977894133482224, "train/extr_reward_min": -0.6835371298667712, "train/extr_reward_std": 0.1964213388852584, "train/image_loss_mean": 3.7481223705487374, "train/image_loss_std": 8.40960882871579, "train/model_loss_mean": 7.675286153646616, "train/model_loss_std": 12.492454401652019, "train/model_opt_grad_norm": 43.56877208611904, "train/model_opt_grad_steps": 78689.76923076923, "train/model_opt_loss": 10678.673665364584, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1391.025641025641, "train/policy_entropy_mag": 2.4318699531066112, "train/policy_entropy_max": 2.4318699531066112, "train/policy_entropy_mean": 0.4442118464372097, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.5758122902650099, "train/policy_logprob_mag": 7.438384043864715, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.4444718519846598, "train/policy_logprob_min": -7.438384043864715, "train/policy_logprob_std": 1.044634996010707, "train/policy_randomness_mag": 0.8583433744234916, "train/policy_randomness_max": 0.8583433744234916, "train/policy_randomness_mean": 0.1567872873865641, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.20323647016134017, "train/post_ent_mag": 58.73343918629182, "train/post_ent_max": 58.73343918629182, "train/post_ent_mean": 41.276785454383266, "train/post_ent_min": 19.39571479895176, "train/post_ent_std": 6.716184990222637, "train/prior_ent_mag": 75.31930944980719, "train/prior_ent_max": 75.31930944980719, "train/prior_ent_mean": 47.70279638828375, "train/prior_ent_min": 27.81684859838241, "train/prior_ent_std": 7.578431058541322, "train/rep_loss_mean": 6.465377240303235, "train/rep_loss_std": 8.755576940683218, "train/reward_avg": 0.029664963665298926, "train/reward_loss_mean": 0.04782894357847862, "train/reward_loss_std": 0.20357815462809342, "train/reward_max_data": 1.0138461571473343, "train/reward_max_pred": 1.0121723529620048, "train/reward_neg_acc": 0.9952940861384074, "train/reward_neg_loss": 0.022694219954502888, "train/reward_pos_acc": 0.9822351229496491, "train/reward_pos_loss": 0.7558406411073146, "train/reward_pred": 0.029260824816540267, "train/reward_rate": 0.03445012019230769, "train_stats/sum_log_reward": 7.322222352027893, "train_stats/max_log_achievement_collect_coal": 0.2777777777777778, "train_stats/max_log_achievement_collect_drink": 3.75, "train_stats/max_log_achievement_collect_sapling": 1.6111111111111112, "train_stats/max_log_achievement_collect_stone": 6.527777777777778, "train_stats/max_log_achievement_collect_wood": 7.25, "train_stats/max_log_achievement_defeat_skeleton": 0.027777777777777776, "train_stats/max_log_achievement_defeat_zombie": 0.25, "train_stats/max_log_achievement_eat_cow": 0.05555555555555555, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.3055555555555556, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_furnace": 0.027777777777777776, "train_stats/max_log_achievement_place_plant": 1.5277777777777777, "train_stats/max_log_achievement_place_stone": 4.666666666666667, "train_stats/max_log_achievement_place_table": 2.638888888888889, "train_stats/max_log_achievement_wake_up": 2.2777777777777777, "train_stats/mean_log_entropy": 0.3913536100751824, "eval_stats/sum_log_reward": 7.475000083446503, "eval_stats/max_log_achievement_collect_coal": 0.5, "eval_stats/max_log_achievement_collect_drink": 1.875, "eval_stats/max_log_achievement_collect_sapling": 2.875, "eval_stats/max_log_achievement_collect_stone": 6.375, "eval_stats/max_log_achievement_collect_wood": 6.5, "eval_stats/max_log_achievement_defeat_skeleton": 0.125, "eval_stats/max_log_achievement_defeat_zombie": 0.125, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.75, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 2.625, "eval_stats/max_log_achievement_place_stone": 5.75, "eval_stats/max_log_achievement_place_table": 1.75, "eval_stats/max_log_achievement_wake_up": 1.875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.00023041902750264853, "report/cont_loss_std": 0.007335349917411804, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 3.588465915527195e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.00023175797832664102, "report/cont_pred": 0.9929591417312622, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 5.48674201965332, "report/dyn_loss_std": 8.292614936828613, "report/image_loss_mean": 3.2407236099243164, "report/image_loss_std": 7.560572147369385, "report/model_loss_mean": 6.582756996154785, "report/model_loss_std": 11.022998809814453, "report/post_ent_mag": 56.617706298828125, "report/post_ent_max": 56.617706298828125, "report/post_ent_mean": 41.404117584228516, "report/post_ent_min": 20.179779052734375, "report/post_ent_std": 6.453697204589844, "report/prior_ent_mag": 75.2615737915039, "report/prior_ent_max": 75.2615737915039, "report/prior_ent_mean": 47.139869689941406, "report/prior_ent_min": 27.754823684692383, "report/prior_ent_std": 7.359658241271973, "report/rep_loss_mean": 5.48674201965332, "report/rep_loss_std": 8.292614936828613, "report/reward_avg": 0.02421874925494194, "report/reward_loss_mean": 0.04975814372301102, "report/reward_loss_std": 0.21863052248954773, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0006465911865234, "report/reward_neg_acc": 0.9949647784233093, "report/reward_neg_loss": 0.026544420048594475, "report/reward_pos_acc": 0.9677419066429138, "report/reward_pos_loss": 0.7933459877967834, "report/reward_pred": 0.0244021974503994, "report/reward_rate": 0.0302734375, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 2.6788254672283074e-06, "eval/cont_loss_std": 4.573559999698773e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00035333953564986587, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.6484804064020864e-06, "eval/cont_pred": 0.9970697164535522, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 19.951194763183594, "eval/dyn_loss_std": 14.259312629699707, "eval/image_loss_mean": 19.99993324279785, "eval/image_loss_std": 20.37893295288086, "eval/model_loss_mean": 32.11080551147461, "eval/model_loss_std": 26.428617477416992, "eval/post_ent_mag": 58.5098762512207, "eval/post_ent_max": 58.5098762512207, "eval/post_ent_mean": 39.10554504394531, "eval/post_ent_min": 20.102495193481445, "eval/post_ent_std": 6.764291286468506, "eval/prior_ent_mag": 75.2615737915039, "eval/prior_ent_max": 75.2615737915039, "eval/prior_ent_mean": 52.05215072631836, "eval/prior_ent_min": 31.28701400756836, "eval/prior_ent_std": 7.167626857757568, "eval/rep_loss_mean": 19.951194763183594, "eval/rep_loss_std": 14.259312629699707, "eval/reward_avg": 0.03046875074505806, "eval/reward_loss_mean": 0.14015017449855804, "eval/reward_loss_std": 0.9029295444488525, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0006320476531982, "eval/reward_neg_acc": 0.9919191002845764, "eval/reward_neg_loss": 0.04460591450333595, "eval/reward_pos_acc": 0.6764705777168274, "eval/reward_pos_loss": 2.9221737384796143, "eval/reward_pred": 0.02233400009572506, "eval/reward_rate": 0.033203125, "replay/size": 319981.0, "replay/inserts": 7788.0, "replay/samples": 31152.0, "replay/insert_wait_avg": 1.5356997434579841e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.468106872801544e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 66408.0, "eval_replay/inserts": 1928.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1523976860204673e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.08970832824707e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 999.9850227832794, "timer/env.step_count": 973.0, "timer/env.step_total": 82.48728108406067, "timer/env.step_frac": 0.08248851653244973, "timer/env.step_avg": 0.08477623955196369, "timer/env.step_min": 0.023395299911499023, "timer/env.step_max": 3.1687870025634766, "timer/replay._sample_count": 31152.0, "timer/replay._sample_total": 15.527731895446777, "timer/replay._sample_frac": 0.01552796446113574, "timer/replay._sample_avg": 0.0004984505616155232, "timer/replay._sample_min": 0.0003821849822998047, "timer/replay._sample_max": 0.011354446411132812, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1214.0, "timer/agent.policy_total": 20.686452388763428, "timer/agent.policy_frac": 0.020686762218884425, "timer/agent.policy_avg": 0.017039911358124736, "timer/agent.policy_min": 0.009369134902954102, "timer/agent.policy_max": 0.11884212493896484, "timer/dataset_train_count": 1947.0, "timer/dataset_train_total": 0.3129739761352539, "timer/dataset_train_frac": 0.00031297866368452883, "timer/dataset_train_avg": 0.00016074677767604208, "timer/dataset_train_min": 8.916854858398438e-05, "timer/dataset_train_max": 0.028101444244384766, "timer/agent.train_count": 1947.0, "timer/agent.train_total": 864.2775321006775, "timer/agent.train_frac": 0.8642904767664575, "timer/agent.train_avg": 0.4439021736521199, "timer/agent.train_min": 0.42762112617492676, "timer/agent.train_max": 0.9460527896881104, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4660038948059082, "timer/agent.report_frac": 0.0004660108743517675, "timer/agent.report_avg": 0.2330019474029541, "timer/agent.report_min": 0.22232961654663086, "timer/agent.report_max": 0.24367427825927734, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0040740966796875e-05, "timer/dataset_eval_frac": 3.004119090022353e-08, "timer/dataset_eval_avg": 3.0040740966796875e-05, "timer/dataset_eval_min": 3.0040740966796875e-05, "timer/dataset_eval_max": 3.0040740966796875e-05, "fps": 7.7880062852862535}
{"step": 320496, "time": 41354.513778448105, "episode/length": 204.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 320496, "time": 41354.52244925499, "episode/length": 291.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9828767123287672, "episode/intrinsic_return": 0.0}
{"step": 320616, "time": 41371.637741327286, "episode/length": 173.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 320720, "time": 41385.25345492363, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9644970414201184, "episode/intrinsic_return": 0.0}
{"step": 320760, "time": 41391.332928180695, "episode/length": 244.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 320864, "time": 41404.915212631226, "episode/length": 172.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 320920, "time": 41413.03236937523, "episode/length": 143.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 321528, "time": 41485.074810266495, "episode/length": 182.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 321664, "time": 41502.53164768219, "episode/length": 92.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.989247311827957, "episode/intrinsic_return": 0.0}
{"step": 321848, "time": 41525.412816524506, "episode/length": 168.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 322104, "time": 41556.80058097839, "episode/length": 185.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 322192, "time": 41569.24092411995, "episode/length": 178.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 322224, "time": 41574.83400654793, "episode/length": 187.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 322808, "time": 41644.15134477615, "episode/length": 288.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9965397923875432, "episode/intrinsic_return": 0.0}
{"step": 322840, "time": 41649.3562066555, "episode/length": 246.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9757085020242915, "episode/intrinsic_return": 0.0}
{"step": 323536, "time": 41732.2189142704, "episode/length": 210.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 323680, "time": 41750.52992558479, "episode/length": 196.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 323728, "time": 41757.60015749931, "episode/length": 191.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 323856, "time": 41773.847611665726, "episode/length": 273.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9890510948905109, "episode/intrinsic_return": 0.0}
{"step": 323944, "time": 41785.65577030182, "episode/length": 214.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9720930232558139, "episode/intrinsic_return": 0.0}
{"step": 324416, "time": 41842.62051200867, "episode/length": 200.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 324488, "time": 41852.599329948425, "episode/length": 205.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 324840, "time": 41895.32022738457, "episode/length": 413.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 324928, "time": 41907.014065265656, "episode/length": 149.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 325224, "time": 41942.91938781738, "episode/length": 192.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9689119170984456, "episode/intrinsic_return": 0.0}
{"step": 325224, "time": 41942.92746472359, "episode/length": 210.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 325488, "time": 41976.73444724083, "episode/length": 124.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 325496, "time": 41979.21678566933, "episode/length": 193.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9587628865979382, "episode/intrinsic_return": 0.0}
{"step": 325784, "time": 42014.36617279053, "episode/length": 240.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.979253112033195, "episode/intrinsic_return": 0.0}
{"step": 326040, "time": 42045.617595911026, "episode/length": 149.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 326112, "time": 42055.56523346901, "episode/length": 211.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 326192, "time": 42066.270147800446, "episode/length": 157.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 326496, "time": 42103.21292877197, "episode/length": 47.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 326520, "time": 42107.50677013397, "episode/length": 161.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 326872, "time": 42150.33709192276, "episode/length": 135.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9632352941176471, "episode/intrinsic_return": 0.0}
{"step": 326872, "time": 42150.346403837204, "episode/length": 171.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 326880, "time": 42155.433148384094, "episode/length": 173.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9597701149425287, "episode/intrinsic_return": 0.0}
{"step": 327112, "time": 42184.406229019165, "episode/length": 235.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 327496, "time": 42230.45464897156, "episode/length": 181.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 327680, "time": 42253.97439289093, "episode/length": 147.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9594594594594594, "episode/intrinsic_return": 0.0}
{"step": 327792, "time": 42269.12920498848, "episode/length": 199.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 328497, "time": 42353.57073831558, "train_stats/sum_log_reward": 7.4170733544884655, "train_stats/max_log_achievement_collect_coal": 0.1951219512195122, "train_stats/max_log_achievement_collect_drink": 2.951219512195122, "train_stats/max_log_achievement_collect_sapling": 1.951219512195122, "train_stats/max_log_achievement_collect_stone": 5.341463414634147, "train_stats/max_log_achievement_collect_wood": 6.2682926829268295, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.2682926829268293, "train_stats/max_log_achievement_eat_cow": 0.024390243902439025, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.146341463414634, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_furnace": 0.024390243902439025, "train_stats/max_log_achievement_place_plant": 1.7317073170731707, "train_stats/max_log_achievement_place_stone": 4.7317073170731705, "train_stats/max_log_achievement_place_table": 2.268292682926829, "train_stats/max_log_achievement_wake_up": 1.8048780487804879, "train_stats/mean_log_entropy": 0.35748450021918227, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.592404174804687, "train/action_min": 0.0, "train/action_std": 3.2395841443538664, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04747223660349846, "train/actor_opt_grad_steps": 80735.0, "train/actor_opt_loss": -12.78957820534706, "train/adv_mag": 0.5069793927669525, "train/adv_max": 0.47366617262363436, "train/adv_mean": 0.0024137220358943523, "train/adv_min": -0.4099253955483437, "train/adv_std": 0.05894398836418986, "train/cont_avg": 0.99462890625, "train/cont_loss_mean": 0.00010431209100964623, "train/cont_loss_std": 0.0031227131548526186, "train/cont_neg_acc": 0.997361111342907, "train/cont_neg_loss": 0.016625383324224002, "train/cont_pos_acc": 0.9999999815225601, "train/cont_pos_loss": 1.7767538994277742e-05, "train/cont_pred": 0.9946356320381164, "train/cont_rate": 0.99462890625, "train/dyn_loss_mean": 6.476296224594116, "train/dyn_loss_std": 8.743687469959259, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1456751999258996, "train/extr_critic_critic_opt_grad_steps": 80735.0, "train/extr_critic_critic_opt_loss": 16823.934516601563, "train/extr_critic_mag": 7.885218682289124, "train/extr_critic_max": 7.885218682289124, "train/extr_critic_mean": 1.670275557935238, "train/extr_critic_min": -0.6062893134355545, "train/extr_critic_std": 1.8275621622800826, "train/extr_return_normed_mag": 1.5539959329366684, "train/extr_return_normed_max": 1.5539959329366684, "train/extr_return_normed_mean": 0.3310806199163199, "train/extr_return_normed_min": -0.11930607970803976, "train/extr_return_normed_std": 0.3286390549689531, "train/extr_return_rate": 0.6208978195488453, "train/extr_return_raw_mag": 8.610539221763611, "train/extr_return_raw_max": 8.610539221763611, "train/extr_return_raw_mean": 1.6839551982283592, "train/extr_return_raw_min": -0.8673126274347305, "train/extr_return_raw_std": 1.8615870743989944, "train/extr_reward_mag": 1.0401183295249938, "train/extr_reward_max": 1.0401183295249938, "train/extr_reward_mean": 0.040272990046069025, "train/extr_reward_min": -0.6659830737113953, "train/extr_reward_std": 0.19718015991151333, "train/image_loss_mean": 3.821436893939972, "train/image_loss_std": 9.028311960697174, "train/model_loss_mean": 7.755414807796479, "train/model_loss_std": 13.094030756950378, "train/model_opt_grad_norm": 46.71422845274959, "train/model_opt_grad_steps": 80662.92, "train/model_opt_loss": 8902.435025634766, "train/model_opt_model_opt_grad_overflow": 0.005, "train/model_opt_model_opt_grad_scale": 1156.25, "train/policy_entropy_mag": 2.399087378978729, "train/policy_entropy_max": 2.399087378978729, "train/policy_entropy_mean": 0.45205454021692276, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.5726321446895599, "train/policy_logprob_mag": 7.438384070396423, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.4523739956319332, "train/policy_logprob_min": -7.438384070396423, "train/policy_logprob_std": 1.0493787994980812, "train/policy_randomness_mag": 0.8467725625634194, "train/policy_randomness_max": 0.8467725625634194, "train/policy_randomness_mean": 0.15955541554838418, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.20211401768028736, "train/post_ent_mag": 58.64614385604858, "train/post_ent_max": 58.64614385604858, "train/post_ent_mean": 41.4159330368042, "train/post_ent_min": 19.609519476890565, "train/post_ent_std": 6.705415947437286, "train/prior_ent_mag": 75.47053768157959, "train/prior_ent_max": 75.47053768157959, "train/prior_ent_mean": 47.85292028427124, "train/prior_ent_min": 28.094332218170166, "train/prior_ent_std": 7.542589740753174, "train/rep_loss_mean": 6.476296224594116, "train/rep_loss_std": 8.743687469959259, "train/reward_avg": 0.029959960696287452, "train/reward_loss_mean": 0.04809585258364677, "train/reward_loss_std": 0.20832511097192763, "train/reward_max_data": 1.0125000029802322, "train/reward_max_pred": 1.0130481588840485, "train/reward_neg_acc": 0.9951158532500267, "train/reward_neg_loss": 0.022872141753323375, "train/reward_pos_acc": 0.9847070309519768, "train/reward_pos_loss": 0.7508774492144584, "train/reward_pred": 0.029620116213336586, "train/reward_rate": 0.0347119140625, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 3.947791992686689e-05, "report/cont_loss_std": 0.00045487674651667476, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 2.1086600099806674e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 3.960449976148084e-05, "report/cont_pred": 0.9931249618530273, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 6.483522891998291, "report/dyn_loss_std": 8.941815376281738, "report/image_loss_mean": 2.6698668003082275, "report/image_loss_std": 8.719295501708984, "report/model_loss_mean": 6.606867790222168, "report/model_loss_std": 13.016600608825684, "report/post_ent_mag": 55.5743408203125, "report/post_ent_max": 55.5743408203125, "report/post_ent_mean": 40.28308868408203, "report/post_ent_min": 15.123332977294922, "report/post_ent_std": 6.2537689208984375, "report/prior_ent_mag": 75.78749084472656, "report/prior_ent_max": 75.78749084472656, "report/prior_ent_mean": 47.14329147338867, "report/prior_ent_min": 28.71268081665039, "report/prior_ent_std": 7.521282196044922, "report/rep_loss_mean": 6.483522891998291, "report/rep_loss_std": 8.941815376281738, "report/reward_avg": 0.02109374850988388, "report/reward_loss_mean": 0.04684792459011078, "report/reward_loss_std": 0.17507649958133698, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0006353855133057, "report/reward_neg_acc": 0.9939759969711304, "report/reward_neg_loss": 0.028062734752893448, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7150641083717346, "report/reward_pred": 0.02058132365345955, "report/reward_rate": 0.02734375, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.0005369489663280547, "eval/cont_loss_std": 0.012394504621624947, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.1053614541888237, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.259911889268551e-05, "eval/cont_pred": 0.9955400824546814, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 19.797536849975586, "eval/dyn_loss_std": 12.747902870178223, "eval/image_loss_mean": 18.283117294311523, "eval/image_loss_std": 20.982824325561523, "eval/model_loss_mean": 30.320816040039062, "eval/model_loss_std": 26.097368240356445, "eval/post_ent_mag": 52.515663146972656, "eval/post_ent_max": 52.515663146972656, "eval/post_ent_mean": 37.70450973510742, "eval/post_ent_min": 21.70890235900879, "eval/post_ent_std": 5.580341339111328, "eval/prior_ent_mag": 75.78749084472656, "eval/prior_ent_max": 75.78749084472656, "eval/prior_ent_mean": 50.608097076416016, "eval/prior_ent_min": 34.740509033203125, "eval/prior_ent_std": 6.477822303771973, "eval/rep_loss_mean": 19.797536849975586, "eval/rep_loss_std": 12.747902870178223, "eval/reward_avg": 0.04960937798023224, "eval/reward_loss_mean": 0.15863826870918274, "eval/reward_loss_std": 0.9681004881858826, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.000044822692871, "eval/reward_neg_acc": 0.9896801114082336, "eval/reward_neg_loss": 0.02938503958284855, "eval/reward_pos_acc": 0.7454545497894287, "eval/reward_pos_loss": 2.435845136642456, "eval/reward_pred": 0.036910735070705414, "eval/reward_rate": 0.0537109375, "replay/size": 327993.0, "replay/inserts": 8012.0, "replay/samples": 32048.0, "replay/insert_wait_avg": 1.5483221529247876e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.525272388429685e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 66408.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2356638908386, "timer/env.step_count": 1002.0, "timer/env.step_total": 91.88052701950073, "timer/env.step_frac": 0.09185887919862071, "timer/env.step_avg": 0.09169713275399274, "timer/env.step_min": 0.023237943649291992, "timer/env.step_max": 4.152095317840576, "timer/replay._sample_count": 32048.0, "timer/replay._sample_total": 15.85460615158081, "timer/replay._sample_frac": 0.015850870673724662, "timer/replay._sample_avg": 0.000494714370680879, "timer/replay._sample_min": 0.0003561973571777344, "timer/replay._sample_max": 0.010695934295654297, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1002.0, "timer/agent.policy_total": 16.01383948326111, "timer/agent.policy_frac": 0.016010066488699796, "timer/agent.policy_avg": 0.015981875731797515, "timer/agent.policy_min": 0.009793758392333984, "timer/agent.policy_max": 0.04634404182434082, "timer/dataset_train_count": 2003.0, "timer/dataset_train_total": 0.30248332023620605, "timer/dataset_train_frac": 0.00030241205263524556, "timer/dataset_train_avg": 0.00015101513741198506, "timer/dataset_train_min": 9.298324584960938e-05, "timer/dataset_train_max": 0.0007722377777099609, "timer/agent.train_count": 2003.0, "timer/agent.train_total": 889.2332763671875, "timer/agent.train_frac": 0.8890237655675458, "timer/agent.train_avg": 0.44395071211542064, "timer/agent.train_min": 0.4329409599304199, "timer/agent.train_max": 0.98215651512146, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4756653308868408, "timer/agent.report_frac": 0.00047555326015525165, "timer/agent.report_avg": 0.2378326654434204, "timer/agent.report_min": 0.2321321964263916, "timer/agent.report_max": 0.24353313446044922, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.5510787963867188e-05, "timer/dataset_eval_frac": 2.550477740878806e-08, "timer/dataset_eval_avg": 2.5510787963867188e-05, "timer/dataset_eval_min": 2.5510787963867188e-05, "timer/dataset_eval_max": 2.5510787963867188e-05, "fps": 8.009998846649781}
{"step": 328520, "time": 42356.10406899452, "episode/length": 104.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9904761904761905, "episode/intrinsic_return": 0.0}
{"step": 328592, "time": 42366.11964201927, "episode/length": 136.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9927007299270073, "episode/intrinsic_return": 0.0}
{"step": 328624, "time": 42371.8901014328, "episode/length": 218.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9680365296803652, "episode/intrinsic_return": 0.0}
{"step": 328880, "time": 42403.07568502426, "episode/length": 220.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 329112, "time": 42431.58110713959, "episode/length": 164.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 329160, "time": 42438.58492064476, "episode/length": 70.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9859154929577465, "episode/intrinsic_return": 0.0}
{"step": 329200, "time": 42444.66549324989, "episode/length": 290.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9828178694158075, "episode/intrinsic_return": 0.0}
{"step": 329296, "time": 42457.34784626961, "episode/length": 301.0, "episode/score": 8.100000031292439, "episode/reward_rate": 0.9966887417218543, "episode/intrinsic_return": 0.0}
{"step": 329880, "time": 42526.75514912605, "episode/length": 169.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9647058823529412, "episode/intrinsic_return": 0.0}
{"step": 329944, "time": 42536.48616242409, "episode/length": 427.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9789719626168224, "episode/intrinsic_return": 0.0}
{"step": 330096, "time": 42575.15932679176, "eval_episode/length": 163.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9939024390243902}
{"step": 330096, "time": 42576.92073774338, "eval_episode/length": 169.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9764705882352941}
{"step": 330096, "time": 42579.09889245033, "eval_episode/length": 184.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9783783783783784}
{"step": 330096, "time": 42581.45623636246, "eval_episode/length": 204.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.975609756097561}
{"step": 330096, "time": 42583.12775707245, "eval_episode/length": 207.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9759615384615384}
{"step": 330096, "time": 42585.32461977005, "eval_episode/length": 225.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9778761061946902}
{"step": 330096, "time": 42587.366466999054, "eval_episode/length": 238.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9832635983263598}
{"step": 330096, "time": 42593.41469860077, "eval_episode/length": 185.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.978494623655914}
{"step": 330104, "time": 42594.3605222702, "episode/length": 152.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 330128, "time": 42599.05245566368, "episode/length": 187.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9680851063829787, "episode/intrinsic_return": 0.0}
{"step": 330408, "time": 42633.58969497681, "episode/length": 155.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 330568, "time": 42654.24569272995, "episode/length": 170.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 330752, "time": 42677.16134977341, "episode/length": 204.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.0}
{"step": 330976, "time": 42705.31738734245, "episode/length": 209.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 331392, "time": 42754.91551375389, "episode/length": 180.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 331416, "time": 42759.306314468384, "episode/length": 191.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 331792, "time": 42804.38188147545, "episode/length": 207.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 331856, "time": 42813.20244193077, "episode/length": 218.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9680365296803652, "episode/intrinsic_return": 0.0}
{"step": 331976, "time": 42828.68498420715, "episode/length": 175.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9659090909090909, "episode/intrinsic_return": 0.0}
{"step": 331992, "time": 42831.98295688629, "episode/length": 197.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 332224, "time": 42860.39422082901, "episode/length": 155.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 332840, "time": 42933.432854413986, "episode/length": 180.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 332896, "time": 42941.93895339966, "episode/length": 267.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9850746268656716, "episode/intrinsic_return": 0.0}
{"step": 332928, "time": 42947.08449935913, "episode/length": 188.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 333096, "time": 42968.03706693649, "episode/length": 162.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9631901840490797, "episode/intrinsic_return": 0.0}
{"step": 333256, "time": 42988.07851648331, "episode/length": 51.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9038461538461539, "episode/intrinsic_return": 0.0}
{"step": 333272, "time": 42991.44118952751, "episode/length": 176.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 333296, "time": 42995.724370718, "episode/length": 164.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 333400, "time": 43009.4487092495, "episode/length": 146.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9659863945578231, "episode/intrinsic_return": 0.0}
{"step": 333576, "time": 43031.50066161156, "episode/length": 197.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 334144, "time": 43099.00814127922, "episode/length": 151.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 334488, "time": 43140.43545126915, "episode/length": 198.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9698492462311558, "episode/intrinsic_return": 0.0}
{"step": 334704, "time": 43166.973288059235, "episode/length": 175.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 334840, "time": 43184.327197790146, "episode/length": 195.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 334936, "time": 43196.91946339607, "episode/length": 229.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 334936, "time": 43196.92789340019, "episode/length": 209.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 335048, "time": 43213.067984342575, "episode/length": 205.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 335224, "time": 43234.942596912384, "episode/length": 47.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 336048, "time": 43333.43667984009, "episode/length": 308.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9967637540453075, "episode/intrinsic_return": 0.0}
{"step": 336152, "time": 43346.90158557892, "episode/length": 250.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9760956175298805, "episode/intrinsic_return": 0.0}
{"step": 336193, "time": 43353.92519688606, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.601366678873698, "train/action_min": 0.0, "train/action_std": 3.2436911339561143, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.047015070430158325, "train/actor_opt_grad_steps": 82695.0, "train/actor_opt_loss": -10.22870885146161, "train/adv_mag": 0.4903308027423918, "train/adv_max": 0.46899206734572846, "train/adv_mean": 0.0032162642509566317, "train/adv_min": -0.3954828647741427, "train/adv_std": 0.05895049470321586, "train/cont_avg": 0.9947357177734375, "train/cont_loss_mean": 7.609984961139589e-05, "train/cont_loss_std": 0.0021950109440359946, "train/cont_neg_acc": 0.9979431566767668, "train/cont_neg_loss": 0.008737481887959664, "train/cont_pos_acc": 0.9999897579352061, "train/cont_pos_loss": 2.8385987031624243e-05, "train/cont_pred": 0.9947303856412569, "train/cont_rate": 0.9947357177734375, "train/dyn_loss_mean": 6.498331355551879, "train/dyn_loss_std": 8.796977676451206, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1675030961632729, "train/extr_critic_critic_opt_grad_steps": 82695.0, "train/extr_critic_critic_opt_loss": 16898.24201456706, "train/extr_critic_mag": 7.901147807637851, "train/extr_critic_max": 7.901147807637851, "train/extr_critic_mean": 1.6989888145277898, "train/extr_critic_min": -0.5901709316919247, "train/extr_critic_std": 1.807034756988287, "train/extr_return_normed_mag": 1.5669352983434994, "train/extr_return_normed_max": 1.5669352983434994, "train/extr_return_normed_mean": 0.3347851683696111, "train/extr_return_normed_min": -0.12777844075268754, "train/extr_return_normed_std": 0.3266624263487756, "train/extr_return_rate": 0.6364695549321672, "train/extr_return_raw_mag": 8.666442433993021, "train/extr_return_raw_max": 8.666442433993021, "train/extr_return_raw_mean": 1.7171096398184698, "train/extr_return_raw_min": -0.8923109294846654, "train/extr_return_raw_std": 1.8425837078442175, "train/extr_reward_mag": 1.0355799173315365, "train/extr_reward_max": 1.0355799173315365, "train/extr_reward_mean": 0.040714166971156374, "train/extr_reward_min": -0.6855469519893328, "train/extr_reward_std": 0.19802976966214678, "train/image_loss_mean": 3.8291530882318816, "train/image_loss_std": 8.833779983222485, "train/model_loss_mean": 7.776268209020297, "train/model_loss_std": 12.911096272369226, "train/model_opt_grad_norm": 43.60126576821009, "train/model_opt_grad_steps": 82621.83854166667, "train/model_opt_loss": 11473.832490285238, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1490.8854166666667, "train/policy_entropy_mag": 2.3953635369737944, "train/policy_entropy_max": 2.3953635369737944, "train/policy_entropy_mean": 0.43852538087715703, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.5580204899112383, "train/policy_logprob_mag": 7.438384056091309, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.43781108129769564, "train/policy_logprob_min": -7.438384056091309, "train/policy_logprob_std": 1.0399177294845383, "train/policy_randomness_mag": 0.8454582110668222, "train/policy_randomness_max": 0.8454582110668222, "train/policy_randomness_mean": 0.1547802152344957, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.19695674550409117, "train/post_ent_mag": 58.66714012622833, "train/post_ent_max": 58.66714012622833, "train/post_ent_mean": 41.5224883556366, "train/post_ent_min": 19.907713770866394, "train/post_ent_std": 6.670569928983848, "train/prior_ent_mag": 75.49345791339874, "train/prior_ent_max": 75.49345791339874, "train/prior_ent_mean": 48.00815234581629, "train/prior_ent_min": 28.33055027325948, "train/prior_ent_std": 7.510925429562728, "train/rep_loss_mean": 6.498331355551879, "train/rep_loss_std": 8.796977676451206, "train/reward_avg": 0.030842081546628226, "train/reward_loss_mean": 0.048040193893636264, "train/reward_loss_std": 0.2050097699975595, "train/reward_max_data": 1.0119791695227225, "train/reward_max_pred": 1.0112874017407496, "train/reward_neg_acc": 0.9946937883893648, "train/reward_neg_loss": 0.022231375017630246, "train/reward_pos_acc": 0.985792076215148, "train/reward_pos_loss": 0.7466803289329013, "train/reward_pred": 0.03060426999096914, "train/reward_rate": 0.035578409830729164, "train_stats/sum_log_reward": 7.647619162287031, "train_stats/max_log_achievement_collect_coal": 0.2619047619047619, "train_stats/max_log_achievement_collect_drink": 3.7142857142857144, "train_stats/max_log_achievement_collect_sapling": 1.5714285714285714, "train_stats/max_log_achievement_collect_stone": 6.190476190476191, "train_stats/max_log_achievement_collect_wood": 5.119047619047619, "train_stats/max_log_achievement_defeat_skeleton": 0.047619047619047616, "train_stats/max_log_achievement_defeat_zombie": 0.23809523809523808, "train_stats/max_log_achievement_eat_cow": 0.07142857142857142, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.0476190476190477, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_furnace": 0.14285714285714285, "train_stats/max_log_achievement_place_plant": 1.4285714285714286, "train_stats/max_log_achievement_place_stone": 5.0, "train_stats/max_log_achievement_place_table": 1.7619047619047619, "train_stats/max_log_achievement_wake_up": 1.9523809523809523, "train_stats/mean_log_entropy": 0.394700115280492, "eval_stats/sum_log_reward": 7.6000001430511475, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 9.0, "eval_stats/max_log_achievement_collect_sapling": 1.875, "eval_stats/max_log_achievement_collect_stone": 4.0, "eval_stats/max_log_achievement_collect_wood": 7.375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.5, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.25, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.125, "eval_stats/max_log_achievement_place_plant": 1.875, "eval_stats/max_log_achievement_place_stone": 3.0, "eval_stats/max_log_achievement_place_table": 2.75, "eval_stats/max_log_achievement_wake_up": 2.0, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 9.439622772333678e-06, "report/cont_loss_std": 0.00023969635367393494, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.4272739008447388e-06, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 9.47893931879662e-06, "report/cont_pred": 0.995107889175415, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 6.034604072570801, "report/dyn_loss_std": 8.26645565032959, "report/image_loss_mean": 3.6823570728302, "report/image_loss_std": 8.788948059082031, "report/model_loss_mean": 7.348250389099121, "report/model_loss_std": 12.739571571350098, "report/post_ent_mag": 58.30824279785156, "report/post_ent_max": 58.30824279785156, "report/post_ent_mean": 41.490509033203125, "report/post_ent_min": 16.35504722595215, "report/post_ent_std": 6.5482988357543945, "report/prior_ent_mag": 75.88761901855469, "report/prior_ent_max": 75.88761901855469, "report/prior_ent_mean": 48.08966827392578, "report/prior_ent_min": 29.940387725830078, "report/prior_ent_std": 7.53673791885376, "report/rep_loss_mean": 6.034604072570801, "report/rep_loss_std": 8.26645565032959, "report/reward_avg": 0.03193359449505806, "report/reward_loss_mean": 0.04512181878089905, "report/reward_loss_std": 0.17167247831821442, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0041964054107666, "report/reward_neg_acc": 0.9969604015350342, "report/reward_neg_loss": 0.019828232005238533, "report/reward_pos_acc": 0.9999999403953552, "report/reward_pos_loss": 0.719845175743103, "report/reward_pred": 0.03130846843123436, "report/reward_rate": 0.0361328125, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 2.1578589439741336e-06, "eval/cont_loss_std": 4.009000986116007e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0001297482813242823, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.7829603393693105e-06, "eval/cont_pred": 0.9970690011978149, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 21.016616821289062, "eval/dyn_loss_std": 13.384696006774902, "eval/image_loss_mean": 25.035648345947266, "eval/image_loss_std": 26.98925018310547, "eval/model_loss_mean": 37.78697204589844, "eval/model_loss_std": 32.98711395263672, "eval/post_ent_mag": 57.754234313964844, "eval/post_ent_max": 57.754234313964844, "eval/post_ent_mean": 38.353485107421875, "eval/post_ent_min": 21.52871322631836, "eval/post_ent_std": 6.02117919921875, "eval/prior_ent_mag": 75.88761901855469, "eval/prior_ent_max": 75.88761901855469, "eval/prior_ent_mean": 51.92363739013672, "eval/prior_ent_min": 35.48320770263672, "eval/prior_ent_std": 6.700954437255859, "eval/rep_loss_mean": 21.016616821289062, "eval/rep_loss_std": 13.384696006774902, "eval/reward_avg": 0.04296875, "eval/reward_loss_mean": 0.1413486897945404, "eval/reward_loss_std": 0.8553973436355591, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0018234252929688, "eval/reward_neg_acc": 0.9877175092697144, "eval/reward_neg_loss": 0.0703684389591217, "eval/reward_pos_acc": 0.8936169743537903, "eval/reward_pos_loss": 1.61683189868927, "eval/reward_pred": 0.043656036257743835, "eval/reward_rate": 0.0458984375, "replay/size": 335689.0, "replay/inserts": 7696.0, "replay/samples": 30784.0, "replay/insert_wait_avg": 1.521312521302031e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.416348199586611e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 69208.0, "eval_replay/inserts": 2800.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1519874845232282e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.387731552124023e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3392934799194, "timer/env.step_count": 962.0, "timer/env.step_total": 92.00087976455688, "timer/env.step_frac": 0.09196967505346093, "timer/env.step_avg": 0.09563501015026703, "timer/env.step_min": 0.02298259735107422, "timer/env.step_max": 3.177873134613037, "timer/replay._sample_count": 30784.0, "timer/replay._sample_total": 15.192913293838501, "timer/replay._sample_frac": 0.015187760185832868, "timer/replay._sample_avg": 0.0004935327863123213, "timer/replay._sample_min": 0.0003638267517089844, "timer/replay._sample_max": 0.009766340255737305, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1312.0, "timer/agent.policy_total": 20.822423219680786, "timer/agent.policy_frac": 0.020815360703511913, "timer/agent.policy_avg": 0.0158707494052445, "timer/agent.policy_min": 0.00940561294555664, "timer/agent.policy_max": 0.054895639419555664, "timer/dataset_train_count": 1924.0, "timer/dataset_train_total": 0.2958540916442871, "timer/dataset_train_frac": 0.00029575374432717514, "timer/dataset_train_avg": 0.00015377031790243613, "timer/dataset_train_min": 9.441375732421875e-05, "timer/dataset_train_max": 0.0045948028564453125, "timer/agent.train_count": 1924.0, "timer/agent.train_total": 852.7827005386353, "timer/agent.train_frac": 0.8524934550676568, "timer/agent.train_avg": 0.4432342518392075, "timer/agent.train_min": 0.43231701850891113, "timer/agent.train_max": 0.9948720932006836, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47821807861328125, "timer/agent.report_frac": 0.0004780558773710521, "timer/agent.report_avg": 0.23910903930664062, "timer/agent.report_min": 0.23283886909484863, "timer/agent.report_max": 0.24537920951843262, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8371810913085938e-05, "timer/dataset_eval_frac": 2.836218780768654e-08, "timer/dataset_eval_avg": 2.8371810913085938e-05, "timer/dataset_eval_min": 2.8371810913085938e-05, "timer/dataset_eval_max": 2.8371810913085938e-05, "fps": 7.6932860974653225}
{"step": 336312, "time": 43367.675169467926, "episode/length": 157.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 336360, "time": 43374.753296136856, "episode/length": 233.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9786324786324786, "episode/intrinsic_return": 0.0}
{"step": 336368, "time": 43377.200382232666, "episode/length": 207.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 336384, "time": 43380.49906682968, "episode/length": 180.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 336816, "time": 43432.2660574913, "episode/length": 234.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 337416, "time": 43503.78198194504, "episode/length": 157.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 337488, "time": 43513.6257481575, "episode/length": 179.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 337552, "time": 43522.59960389137, "episode/length": 148.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 337576, "time": 43526.807624578476, "episode/length": 293.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9829931972789115, "episode/intrinsic_return": 0.0}
{"step": 337848, "time": 43560.12588381767, "episode/length": 182.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 337864, "time": 43563.38843417168, "episode/length": 193.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 338360, "time": 43622.723836898804, "episode/length": 248.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9799196787148594, "episode/intrinsic_return": 0.0}
{"step": 338688, "time": 43662.988676548004, "episode/length": 158.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 339008, "time": 43701.7412378788, "episode/length": 181.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 339288, "time": 43735.691098451614, "episode/length": 177.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 339480, "time": 43759.49652481079, "episode/length": 203.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 339952, "time": 43815.800438165665, "episode/length": 307.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9837662337662337, "episode/intrinsic_return": 0.0}
{"step": 340056, "time": 43829.24131608009, "episode/length": 170.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 340080, "time": 43850.870990514755, "eval_episode/length": 119.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9416666666666667}
{"step": 340080, "time": 43853.27936577797, "eval_episode/length": 140.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9574468085106383}
{"step": 340080, "time": 43855.341904878616, "eval_episode/length": 153.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9675324675324676}
{"step": 340080, "time": 43857.22162652016, "eval_episode/length": 164.0, "eval_episode/score": 6.099999979138374, "eval_episode/reward_rate": 0.9939393939393939}
{"step": 340080, "time": 43858.857625722885, "eval_episode/length": 170.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9707602339181286}
{"step": 340080, "time": 43862.07757997513, "eval_episode/length": 211.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9811320754716981}
{"step": 340080, "time": 43863.94033122063, "eval_episode/length": 216.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9815668202764977}
{"step": 340080, "time": 43867.62903404236, "eval_episode/length": 149.0, "eval_episode/score": 9.099999964237213, "eval_episode/reward_rate": 0.9666666666666667}
{"step": 340256, "time": 43888.08224415779, "episode/length": 429.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9790697674418605, "episode/intrinsic_return": 0.0}
{"step": 340288, "time": 43893.710488796234, "episode/length": 159.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 340472, "time": 43916.47008109093, "episode/length": 361.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9917127071823204, "episode/intrinsic_return": 0.0}
{"step": 340752, "time": 43950.53217339516, "episode/length": 298.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9832775919732442, "episode/intrinsic_return": 0.0}
{"step": 340952, "time": 43975.22864532471, "episode/length": 183.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 341352, "time": 44023.124804496765, "episode/length": 174.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 341464, "time": 44037.692796468735, "episode/length": 175.0, "episode/score": 9.1000000461936, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 341520, "time": 44045.659767627716, "episode/length": 278.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.996415770609319, "episode/intrinsic_return": 0.0}
{"step": 341616, "time": 44058.516615867615, "episode/length": 169.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 341720, "time": 44072.02470636368, "episode/length": 155.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 341800, "time": 44082.89370012283, "episode/length": 188.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 342024, "time": 44110.281147003174, "episode/length": 62.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9365079365079365, "episode/intrinsic_return": 0.0}
{"step": 342176, "time": 44129.36946439743, "episode/length": 177.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 342744, "time": 44196.95207762718, "episode/length": 140.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9574468085106383, "episode/intrinsic_return": 0.0}
{"step": 342992, "time": 44227.261598825455, "episode/length": 254.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.996078431372549, "episode/intrinsic_return": 0.0}
{"step": 343208, "time": 44254.4151930809, "episode/length": 231.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9741379310344828, "episode/intrinsic_return": 0.0}
{"step": 343216, "time": 44256.85740208626, "episode/length": 176.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 343256, "time": 44263.024295568466, "episode/length": 223.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.0}
{"step": 343296, "time": 44269.05840611458, "episode/length": 196.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 343664, "time": 44313.18091106415, "episode/length": 204.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 343864, "time": 44337.943544626236, "episode/length": 139.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 343977, "time": 44354.04909038544, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.536892465444711, "train/action_min": 0.0, "train/action_std": 3.1505783191094032, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04693948009457344, "train/actor_opt_grad_steps": 84630.0, "train/actor_opt_loss": -8.873466753114302, "train/adv_mag": 0.5046401648949355, "train/adv_max": 0.4741055211959741, "train/adv_mean": 0.0035104436366847763, "train/adv_min": -0.4086329280565947, "train/adv_std": 0.05885446512928376, "train/cont_avg": 0.9947215544871795, "train/cont_loss_mean": 0.00012601731981055545, "train/cont_loss_std": 0.0038758660578871776, "train/cont_neg_acc": 0.9963899068343334, "train/cont_neg_loss": 0.01728276260494521, "train/cont_pos_acc": 0.9999899038901696, "train/cont_pos_loss": 3.416749099943745e-05, "train/cont_pred": 0.9947259808198, "train/cont_rate": 0.9947215544871795, "train/dyn_loss_mean": 6.477094085399921, "train/dyn_loss_std": 8.73625302926088, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.2030450976811922, "train/extr_critic_critic_opt_grad_steps": 84630.0, "train/extr_critic_critic_opt_loss": 16903.635436698718, "train/extr_critic_mag": 8.002977757576184, "train/extr_critic_max": 8.002977757576184, "train/extr_critic_mean": 1.75721218647101, "train/extr_critic_min": -0.5955753198036781, "train/extr_critic_std": 1.81646132958241, "train/extr_return_normed_mag": 1.5661312158291156, "train/extr_return_normed_max": 1.5661312158291156, "train/extr_return_normed_mean": 0.34116468903345937, "train/extr_return_normed_min": -0.12781532322749115, "train/extr_return_normed_std": 0.3244889720128133, "train/extr_return_rate": 0.6595356242778974, "train/extr_return_raw_mag": 8.771744999518761, "train/extr_return_raw_max": 8.771744999518761, "train/extr_return_raw_mean": 1.7772375241304055, "train/extr_return_raw_min": -0.9003856072059044, "train/extr_return_raw_std": 1.8528393329718174, "train/extr_reward_mag": 1.0410930254520514, "train/extr_reward_max": 1.0410930254520514, "train/extr_reward_mean": 0.0416438640978856, "train/extr_reward_min": -0.6808757299031967, "train/extr_reward_std": 0.20000201624173383, "train/image_loss_mean": 3.747844806084266, "train/image_loss_std": 8.60197706467066, "train/model_loss_mean": 7.683523588914138, "train/model_loss_std": 12.668721986428285, "train/model_opt_grad_norm": 42.66052901439178, "train/model_opt_grad_steps": 84555.42564102563, "train/model_opt_loss": 10900.431555488782, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1416.6666666666667, "train/policy_entropy_mag": 2.425371491603362, "train/policy_entropy_max": 2.425371491603362, "train/policy_entropy_mean": 0.4165543333078042, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.5387719677044795, "train/policy_logprob_mag": 7.438384078099177, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.4162696818510691, "train/policy_logprob_min": -7.438384078099177, "train/policy_logprob_std": 1.0243571030787932, "train/policy_randomness_mag": 0.8560497042460319, "train/policy_randomness_max": 0.8560497042460319, "train/policy_randomness_mean": 0.14702539982704016, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.19016286226419302, "train/post_ent_mag": 58.83504928197616, "train/post_ent_max": 58.83504928197616, "train/post_ent_mean": 41.640380311623595, "train/post_ent_min": 19.698512292519595, "train/post_ent_std": 6.7185141587868715, "train/prior_ent_mag": 75.42717801607571, "train/prior_ent_max": 75.42717801607571, "train/prior_ent_mean": 48.11124476897411, "train/prior_ent_min": 28.49128192999424, "train/prior_ent_std": 7.469923146565756, "train/rep_loss_mean": 6.477094085399921, "train/rep_loss_std": 8.73625302926088, "train/reward_avg": 0.030845853251715502, "train/reward_loss_mean": 0.04929631578807647, "train/reward_loss_std": 0.2134053837030362, "train/reward_max_data": 1.0153846190525935, "train/reward_max_pred": 1.0142587398871397, "train/reward_neg_acc": 0.9948262822933686, "train/reward_neg_loss": 0.023016682673150147, "train/reward_pos_acc": 0.9822180906931559, "train/reward_pos_loss": 0.7610700506430406, "train/reward_pred": 0.03040708108112598, "train/reward_rate": 0.03559695512820513, "train_stats/sum_log_reward": 7.305128378745837, "train_stats/max_log_achievement_collect_coal": 0.20512820512820512, "train_stats/max_log_achievement_collect_drink": 3.4871794871794872, "train_stats/max_log_achievement_collect_sapling": 1.8205128205128205, "train_stats/max_log_achievement_collect_stone": 5.205128205128205, "train_stats/max_log_achievement_collect_wood": 5.384615384615385, "train_stats/max_log_achievement_defeat_skeleton": 0.05128205128205128, "train_stats/max_log_achievement_defeat_zombie": 0.2564102564102564, "train_stats/max_log_achievement_eat_cow": 0.07692307692307693, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.0769230769230769, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_furnace": 0.1282051282051282, "train_stats/max_log_achievement_place_plant": 1.641025641025641, "train_stats/max_log_achievement_place_stone": 3.5641025641025643, "train_stats/max_log_achievement_place_table": 1.9230769230769231, "train_stats/max_log_achievement_wake_up": 2.2051282051282053, "train_stats/mean_log_entropy": 0.36636958710658246, "eval_stats/sum_log_reward": 6.725000083446503, "eval_stats/max_log_achievement_collect_coal": 0.375, "eval_stats/max_log_achievement_collect_drink": 6.5, "eval_stats/max_log_achievement_collect_sapling": 2.625, "eval_stats/max_log_achievement_collect_stone": 2.375, "eval_stats/max_log_achievement_collect_wood": 4.625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.125, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.625, "eval_stats/max_log_achievement_make_wood_sword": 0.125, "eval_stats/max_log_achievement_place_furnace": 0.125, "eval_stats/max_log_achievement_place_plant": 2.5, "eval_stats/max_log_achievement_place_stone": 1.875, "eval_stats/max_log_achievement_place_table": 1.875, "eval_stats/max_log_achievement_wake_up": 1.625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 1.242087091668509e-05, "report/cont_loss_std": 0.00010913840378634632, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0005505960434675217, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 9.248915375792421e-06, "report/cont_pred": 0.9941346645355225, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 5.9937286376953125, "report/dyn_loss_std": 8.824674606323242, "report/image_loss_mean": 3.119555950164795, "report/image_loss_std": 6.046934127807617, "report/model_loss_mean": 6.758413791656494, "report/model_loss_std": 10.19211196899414, "report/post_ent_mag": 58.82344055175781, "report/post_ent_max": 58.82344055175781, "report/post_ent_mean": 41.89067840576172, "report/post_ent_min": 17.944225311279297, "report/post_ent_std": 6.609031677246094, "report/prior_ent_mag": 75.51155090332031, "report/prior_ent_max": 75.51155090332031, "report/prior_ent_mean": 48.12693405151367, "report/prior_ent_min": 30.197776794433594, "report/prior_ent_std": 7.378034591674805, "report/rep_loss_mean": 5.9937286376953125, "report/rep_loss_std": 8.824674606323242, "report/reward_avg": 0.02167968824505806, "report/reward_loss_mean": 0.04260832816362381, "report/reward_loss_std": 0.20645953714847565, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0000414848327637, "report/reward_neg_acc": 0.99698805809021, "report/reward_neg_loss": 0.020607413724064827, "report/reward_pos_acc": 0.9642857313156128, "report/reward_pos_loss": 0.8252123594284058, "report/reward_pred": 0.020792003720998764, "report/reward_rate": 0.02734375, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.005915247835218906, "eval/cont_loss_std": 0.1808861494064331, "eval/cont_neg_acc": 0.6666666865348816, "eval/cont_neg_loss": 1.9892505407333374, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 8.762290235608816e-05, "eval/cont_pred": 0.9981202483177185, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 20.54206085205078, "eval/dyn_loss_std": 12.977192878723145, "eval/image_loss_mean": 24.61383819580078, "eval/image_loss_std": 29.54006004333496, "eval/model_loss_mean": 37.10584259033203, "eval/model_loss_std": 34.27556228637695, "eval/post_ent_mag": 54.680049896240234, "eval/post_ent_max": 54.680049896240234, "eval/post_ent_mean": 38.09328842163086, "eval/post_ent_min": 20.650178909301758, "eval/post_ent_std": 6.2721991539001465, "eval/prior_ent_mag": 75.51155090332031, "eval/prior_ent_max": 75.51155090332031, "eval/prior_ent_mean": 51.59074401855469, "eval/prior_ent_min": 31.095163345336914, "eval/prior_ent_std": 6.857784748077393, "eval/rep_loss_mean": 20.54206085205078, "eval/rep_loss_std": 12.977192878723145, "eval/reward_avg": 0.03935546800494194, "eval/reward_loss_mean": 0.16085132956504822, "eval/reward_loss_std": 1.001639723777771, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9999216794967651, "eval/reward_neg_acc": 0.9928643703460693, "eval/reward_neg_loss": 0.04389388859272003, "eval/reward_pos_acc": 0.6744186282157898, "eval/reward_pos_loss": 2.8291127681732178, "eval/reward_pred": 0.024458691477775574, "eval/reward_rate": 0.0419921875, "replay/size": 343473.0, "replay/inserts": 7784.0, "replay/samples": 31136.0, "replay/insert_wait_avg": 1.5435030134461767e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.480903617647177e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 71368.0, "eval_replay/inserts": 2160.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1780747660884151e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.5367431640625e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1106870174408, "timer/env.step_count": 973.0, "timer/env.step_total": 85.99485087394714, "timer/env.step_frac": 0.08598533341384791, "timer/env.step_avg": 0.0883811416998429, "timer/env.step_min": 0.02310466766357422, "timer/env.step_max": 2.0854716300964355, "timer/replay._sample_count": 31136.0, "timer/replay._sample_total": 15.457739353179932, "timer/replay._sample_frac": 0.015456028571475875, "timer/replay._sample_avg": 0.000496458740788153, "timer/replay._sample_min": 0.0003829002380371094, "timer/replay._sample_max": 0.027198076248168945, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1243.0, "timer/agent.policy_total": 19.76843500137329, "timer/agent.policy_frac": 0.019766247134431984, "timer/agent.policy_avg": 0.01590380933336548, "timer/agent.policy_min": 0.009426355361938477, "timer/agent.policy_max": 0.04822349548339844, "timer/dataset_train_count": 1946.0, "timer/dataset_train_total": 0.2949182987213135, "timer/dataset_train_frac": 0.0002948856587072651, "timer/dataset_train_avg": 0.00015155102709214465, "timer/dataset_train_min": 9.250640869140625e-05, "timer/dataset_train_max": 0.0005888938903808594, "timer/agent.train_count": 1946.0, "timer/agent.train_total": 861.5425229072571, "timer/agent.train_frac": 0.8614471718891179, "timer/agent.train_avg": 0.4427248319153428, "timer/agent.train_min": 0.4323751926422119, "timer/agent.train_max": 0.5767829418182373, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47383952140808105, "timer/agent.report_frac": 0.0004737870793293681, "timer/agent.report_avg": 0.23691976070404053, "timer/agent.report_min": 0.2304372787475586, "timer/agent.report_max": 0.24340224266052246, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.5510787963867188e-05, "timer/dataset_eval_frac": 2.5507964563348684e-08, "timer/dataset_eval_avg": 2.5510787963867188e-05, "timer/dataset_eval_min": 2.5510787963867188e-05, "timer/dataset_eval_max": 2.5510787963867188e-05, "fps": 7.7830348084830145}
{"step": 343984, "time": 44354.62697196007, "episode/length": 225.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 344024, "time": 44360.95407342911, "episode/length": 128.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9922480620155039, "episode/intrinsic_return": 0.0}
{"step": 344456, "time": 44413.671620607376, "episode/length": 144.0, "episode/score": 8.099999964237213, "episode/reward_rate": 0.9586206896551724, "episode/intrinsic_return": 0.0}
{"step": 344544, "time": 44425.27081370354, "episode/length": 165.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 344704, "time": 44445.30565214157, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 344968, "time": 44477.4663002491, "episode/length": 117.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9576271186440678, "episode/intrinsic_return": 0.0}
{"step": 345072, "time": 44490.91805076599, "episode/length": 175.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 345208, "time": 44508.357524871826, "episode/length": 152.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 345376, "time": 44529.43041038513, "episode/length": 270.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.996309963099631, "episode/intrinsic_return": 0.0}
{"step": 345928, "time": 44595.31838154793, "episode/length": 183.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 346080, "time": 44614.72817349434, "episode/length": 191.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 346464, "time": 44661.099900722504, "episode/length": 324.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9846153846153847, "episode/intrinsic_return": 0.0}
{"step": 346512, "time": 44668.23860645294, "episode/length": 179.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 346528, "time": 44671.61239242554, "episode/length": 164.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 346848, "time": 44710.32587790489, "episode/length": 267.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.996268656716418, "episode/intrinsic_return": 0.0}
{"step": 346880, "time": 44715.545605659485, "episode/length": 238.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9790794979079498, "episode/intrinsic_return": 0.0}
{"step": 347448, "time": 44783.057934999466, "episode/length": 189.0, "episode/score": 11.099999941885471, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 347600, "time": 44802.29871726036, "episode/length": 189.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 347640, "time": 44808.461589574814, "episode/length": 146.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 348056, "time": 44858.22338271141, "episode/length": 51.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 348080, "time": 44862.68455052376, "episode/length": 195.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 348256, "time": 44885.18768143654, "episode/length": 171.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9651162790697675, "episode/intrinsic_return": 0.0}
{"step": 348376, "time": 44900.65108156204, "episode/length": 190.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 348392, "time": 44904.100836753845, "episode/length": 376.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9761273209549072, "episode/intrinsic_return": 0.0}
{"step": 348440, "time": 44911.29054427147, "episode/length": 44.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 348824, "time": 44957.50379061699, "episode/length": 171.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 349112, "time": 44992.39451622963, "episode/length": 188.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 349312, "time": 45017.15769672394, "episode/length": 116.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9914529914529915, "episode/intrinsic_return": 0.0}
{"step": 349552, "time": 45046.67953252792, "episode/length": 377.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 349648, "time": 45059.38587808609, "episode/length": 156.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 349952, "time": 45096.19499850273, "episode/length": 211.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9716981132075472, "episode/intrinsic_return": 0.0}
{"step": 350064, "time": 45129.34185743332, "eval_episode/length": 150.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9668874172185431}
{"step": 350064, "time": 45131.740427970886, "eval_episode/length": 170.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9941520467836257}
{"step": 350064, "time": 45131.74835348129, "eval_episode/length": 170.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9649122807017544}
{"step": 350064, "time": 45135.16917967796, "eval_episode/length": 178.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9720670391061452}
{"step": 350064, "time": 45137.32903218269, "eval_episode/length": 193.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.979381443298969}
{"step": 350064, "time": 45139.391949892044, "eval_episode/length": 207.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9615384615384616}
{"step": 350064, "time": 45141.31463217735, "eval_episode/length": 216.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9631336405529954}
{"step": 350064, "time": 45143.237545490265, "eval_episode/length": 225.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9823008849557522}
{"step": 350184, "time": 45157.11864089966, "episode/length": 169.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 350224, "time": 45163.422338724136, "episode/length": 138.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.0}
{"step": 350440, "time": 45190.08455848694, "episode/length": 249.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 350608, "time": 45211.26818680763, "episode/length": 119.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9583333333333334, "episode/intrinsic_return": 0.0}
{"step": 350712, "time": 45225.51063680649, "episode/length": 144.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 350832, "time": 45241.00247645378, "episode/length": 189.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 351224, "time": 45288.12579154968, "episode/length": 395.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9974747474747475, "episode/intrinsic_return": 0.0}
{"step": 351640, "time": 45338.04152226448, "episode/length": 181.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 351757, "time": 45354.2970893383, "train_stats/sum_log_reward": 7.817948903792944, "train_stats/max_log_achievement_collect_coal": 0.48717948717948717, "train_stats/max_log_achievement_collect_drink": 2.5641025641025643, "train_stats/max_log_achievement_collect_sapling": 1.6153846153846154, "train_stats/max_log_achievement_collect_stone": 7.282051282051282, "train_stats/max_log_achievement_collect_wood": 5.897435897435898, "train_stats/max_log_achievement_defeat_skeleton": 0.02564102564102564, "train_stats/max_log_achievement_defeat_zombie": 0.1794871794871795, "train_stats/max_log_achievement_eat_cow": 0.07692307692307693, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.1282051282051282, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_furnace": 0.46153846153846156, "train_stats/max_log_achievement_place_plant": 1.5897435897435896, "train_stats/max_log_achievement_place_stone": 3.923076923076923, "train_stats/max_log_achievement_place_table": 2.051282051282051, "train_stats/max_log_achievement_wake_up": 2.128205128205128, "train_stats/mean_log_entropy": 0.36786634761553544, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.4978515625, "train/action_min": 0.0, "train/action_std": 3.0767784803341596, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.048916456122428946, "train/actor_opt_grad_steps": 86580.0, "train/actor_opt_loss": -7.417905560011665, "train/adv_mag": 0.5044019182523092, "train/adv_max": 0.4741996922554114, "train/adv_mean": 0.004289024944591801, "train/adv_min": -0.41233485279939114, "train/adv_std": 0.06021356072563391, "train/cont_avg": 0.994686498397436, "train/cont_loss_mean": 6.387704083936231e-05, "train/cont_loss_std": 0.0017882906557116047, "train/cont_neg_acc": 0.9986121395091319, "train/cont_neg_loss": 0.007820992006433434, "train/cont_pos_acc": 0.999999984105428, "train/cont_pos_loss": 1.3737929870088896e-05, "train/cont_pred": 0.9946927116467402, "train/cont_rate": 0.994686498397436, "train/dyn_loss_mean": 6.466716913076548, "train/dyn_loss_std": 8.778337456629826, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.242671819527944, "train/extr_critic_critic_opt_grad_steps": 86580.0, "train/extr_critic_critic_opt_loss": 17206.79051983173, "train/extr_critic_mag": 8.080653205284705, "train/extr_critic_max": 8.080653205284705, "train/extr_critic_mean": 1.9803449829419455, "train/extr_critic_min": -0.5720631354894393, "train/extr_critic_std": 1.8273119247876681, "train/extr_return_normed_mag": 1.5411447017620772, "train/extr_return_normed_max": 1.5411447017620772, "train/extr_return_normed_mean": 0.3660084132200632, "train/extr_return_normed_min": -0.12483864254676379, "train/extr_return_normed_std": 0.31860284209251405, "train/extr_return_rate": 0.7427090397247902, "train/extr_return_raw_mag": 8.886450058374649, "train/extr_return_raw_max": 8.886450058374649, "train/extr_return_raw_mean": 2.0054235412524295, "train/extr_return_raw_min": -0.8705958212033297, "train/extr_return_raw_std": 1.8666037449469932, "train/extr_reward_mag": 1.035269095347478, "train/extr_reward_max": 1.035269095347478, "train/extr_reward_mean": 0.04175562970340252, "train/extr_reward_min": -0.6742354289079324, "train/extr_reward_std": 0.20052647254405878, "train/image_loss_mean": 3.7123102004711446, "train/image_loss_std": 8.580494704613319, "train/model_loss_mean": 7.64165902749086, "train/model_loss_std": 12.656164756188026, "train/model_opt_grad_norm": 42.71951436751928, "train/model_opt_grad_steps": 86504.13333333333, "train/model_opt_loss": 12499.200563401442, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1647.4358974358975, "train/policy_entropy_mag": 2.463888673293285, "train/policy_entropy_max": 2.463888673293285, "train/policy_entropy_mean": 0.4108529023635082, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.5386982775651492, "train/policy_logprob_mag": 7.438384097661728, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.41095905089989687, "train/policy_logprob_min": -7.438384097661728, "train/policy_logprob_std": 1.0217146729811644, "train/policy_randomness_mag": 0.8696445776866033, "train/policy_randomness_max": 0.8696445776866033, "train/policy_randomness_mean": 0.1450130438957459, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.19013685293686697, "train/post_ent_mag": 59.06810574653821, "train/post_ent_max": 59.06810574653821, "train/post_ent_mean": 41.7269889831543, "train/post_ent_min": 19.68210498614189, "train/post_ent_std": 6.765990528693566, "train/prior_ent_mag": 75.47515270526593, "train/prior_ent_max": 75.47515270526593, "train/prior_ent_mean": 48.16155557876978, "train/prior_ent_min": 28.276902937277768, "train/prior_ent_std": 7.488496494293213, "train/rep_loss_mean": 6.466716913076548, "train/rep_loss_std": 8.778337456629826, "train/reward_avg": 0.03095653035128728, "train/reward_loss_mean": 0.04925479670174611, "train/reward_loss_std": 0.20699134430824181, "train/reward_max_data": 1.009230771431556, "train/reward_max_pred": 1.0087328042739476, "train/reward_neg_acc": 0.9944415413416349, "train/reward_neg_loss": 0.02336842372106054, "train/reward_pos_acc": 0.9862111174143278, "train/reward_pos_loss": 0.7471793400935638, "train/reward_pred": 0.03069140895580252, "train/reward_rate": 0.03583733974358974, "eval_stats/sum_log_reward": 7.349999964237213, "eval_stats/max_log_achievement_collect_coal": 0.375, "eval_stats/max_log_achievement_collect_drink": 2.375, "eval_stats/max_log_achievement_collect_sapling": 1.375, "eval_stats/max_log_achievement_collect_stone": 7.75, "eval_stats/max_log_achievement_collect_wood": 6.125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.125, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.5, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.25, "eval_stats/max_log_achievement_place_plant": 1.25, "eval_stats/max_log_achievement_place_stone": 3.25, "eval_stats/max_log_achievement_place_table": 2.125, "eval_stats/max_log_achievement_wake_up": 2.125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 1.2649133168451954e-05, "report/cont_loss_std": 0.0003340590337757021, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0015559610910713673, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 2.0265345028747106e-06, "report/cont_pred": 0.9931726455688477, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 5.503027439117432, "report/dyn_loss_std": 8.265532493591309, "report/image_loss_mean": 3.5613670349121094, "report/image_loss_std": 6.294250011444092, "report/model_loss_mean": 6.917766571044922, "report/model_loss_std": 10.041380882263184, "report/post_ent_mag": 61.59772491455078, "report/post_ent_max": 61.59772491455078, "report/post_ent_mean": 42.21394348144531, "report/post_ent_min": 20.785280227661133, "report/post_ent_std": 6.612550258636475, "report/prior_ent_mag": 75.54103088378906, "report/prior_ent_max": 75.54103088378906, "report/prior_ent_mean": 47.76713562011719, "report/prior_ent_min": 30.00177764892578, "report/prior_ent_std": 7.652225017547607, "report/rep_loss_mean": 5.503027439117432, "report/rep_loss_std": 8.265532493591309, "report/reward_avg": 0.03652343899011612, "report/reward_loss_mean": 0.0545705184340477, "report/reward_loss_std": 0.283211350440979, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.002195119857788, "report/reward_neg_acc": 0.996941864490509, "report/reward_neg_loss": 0.02011454850435257, "report/reward_pos_acc": 0.9767441749572754, "report/reward_pos_loss": 0.8406473994255066, "report/reward_pred": 0.03489520400762558, "report/reward_rate": 0.0419921875, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 4.32252672908362e-05, "eval/cont_loss_std": 0.0008826754055917263, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.002199355512857437, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 3.0517230698023923e-05, "eval/cont_pred": 0.9941235780715942, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 21.12222671508789, "eval/dyn_loss_std": 14.298087120056152, "eval/image_loss_mean": 24.798656463623047, "eval/image_loss_std": 26.1838321685791, "eval/model_loss_mean": 37.611202239990234, "eval/model_loss_std": 31.973373413085938, "eval/post_ent_mag": 60.500728607177734, "eval/post_ent_max": 60.500728607177734, "eval/post_ent_mean": 38.523658752441406, "eval/post_ent_min": 22.66619110107422, "eval/post_ent_std": 7.1192474365234375, "eval/prior_ent_mag": 75.54103088378906, "eval/prior_ent_max": 75.54103088378906, "eval/prior_ent_mean": 51.68259811401367, "eval/prior_ent_min": 34.40061950683594, "eval/prior_ent_std": 6.871931076049805, "eval/rep_loss_mean": 21.12222671508789, "eval/rep_loss_std": 14.298087120056152, "eval/reward_avg": 0.02167968824505806, "eval/reward_loss_mean": 0.13916771113872528, "eval/reward_loss_std": 0.8538303971290588, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0005640983581543, "eval/reward_neg_acc": 0.995979905128479, "eval/reward_neg_loss": 0.07901264727115631, "eval/reward_pos_acc": 0.7586206793785095, "eval/reward_pos_loss": 2.2031090259552, "eval/reward_pred": 0.01741071790456772, "eval/reward_rate": 0.0283203125, "replay/size": 351253.0, "replay/inserts": 7780.0, "replay/samples": 31120.0, "replay/insert_wait_avg": 1.5311498568419627e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.437504805145655e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 73176.0, "eval_replay/inserts": 1808.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1541147147659707e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.685754776000977e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2317934036255, "timer/env.step_count": 972.0, "timer/env.step_total": 85.49829983711243, "timer/env.step_frac": 0.08547848648779266, "timer/env.step_avg": 0.08796121382418974, "timer/env.step_min": 0.023412227630615234, "timer/env.step_max": 2.0910372734069824, "timer/replay._sample_count": 31120.0, "timer/replay._sample_total": 15.43865704536438, "timer/replay._sample_frac": 0.015435079295799178, "timer/replay._sample_avg": 0.0004961008047996267, "timer/replay._sample_min": 0.00039267539978027344, "timer/replay._sample_max": 0.011287689208984375, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1198.0, "timer/agent.policy_total": 18.89165234565735, "timer/agent.policy_frac": 0.018887274400038956, "timer/agent.policy_avg": 0.015769325831099624, "timer/agent.policy_min": 0.009396076202392578, "timer/agent.policy_max": 0.05404949188232422, "timer/dataset_train_count": 1945.0, "timer/dataset_train_total": 0.3239567279815674, "timer/dataset_train_frac": 0.0003238816543505336, "timer/dataset_train_avg": 0.00016655872903936626, "timer/dataset_train_min": 9.322166442871094e-05, "timer/dataset_train_max": 0.03169417381286621, "timer/agent.train_count": 1945.0, "timer/agent.train_total": 863.5109312534332, "timer/agent.train_frac": 0.863310821499731, "timer/agent.train_avg": 0.4439644890763153, "timer/agent.train_min": 0.42167210578918457, "timer/agent.train_max": 0.9561491012573242, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47325563430786133, "timer/agent.report_frac": 0.0004731459621948725, "timer/agent.report_avg": 0.23662781715393066, "timer/agent.report_min": 0.2280747890472412, "timer/agent.report_max": 0.24518084526062012, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0994415283203125e-05, "timer/dataset_eval_frac": 3.098723264707892e-08, "timer/dataset_eval_avg": 3.0994415283203125e-05, "timer/dataset_eval_min": 3.0994415283203125e-05, "timer/dataset_eval_max": 3.0994415283203125e-05, "fps": 7.778085785669137}
{"step": 351800, "time": 45359.30652284622, "episode/length": 148.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 351912, "time": 45374.08234000206, "episode/length": 210.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9715639810426541, "episode/intrinsic_return": 0.0}
{"step": 351960, "time": 45381.13200426102, "episode/length": 189.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 351968, "time": 45383.56851387024, "episode/length": 251.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9801587301587301, "episode/intrinsic_return": 0.0}
{"step": 352696, "time": 45471.13606309891, "episode/length": 232.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 352952, "time": 45502.55728888512, "episode/length": 215.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 352976, "time": 45506.89147686958, "episode/length": 146.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 353176, "time": 45531.70309257507, "episode/length": 191.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 353304, "time": 45548.19598817825, "episode/length": 166.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 353672, "time": 45592.80320477486, "episode/length": 219.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 354000, "time": 45632.587870121, "episode/length": 130.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9618320610687023, "episode/intrinsic_return": 0.0}
{"step": 354080, "time": 45643.464215517044, "episode/length": 420.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9786223277909739, "episode/intrinsic_return": 0.0}
{"step": 354328, "time": 45673.85766410828, "episode/length": 143.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 354448, "time": 45689.21954417229, "episode/length": 218.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.0}
{"step": 354640, "time": 45713.163539648056, "episode/length": 207.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9711538461538461, "episode/intrinsic_return": 0.0}
{"step": 354704, "time": 45722.13245797157, "episode/length": 174.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 354976, "time": 45755.29831457138, "episode/length": 376.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9761273209549072, "episode/intrinsic_return": 0.0}
{"step": 355432, "time": 45809.891786813736, "episode/length": 56.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 355480, "time": 45817.00771403313, "episode/length": 184.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 355584, "time": 45830.66557049751, "episode/length": 187.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9680851063829787, "episode/intrinsic_return": 0.0}
{"step": 355584, "time": 45830.67317986488, "episode/length": 156.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 355928, "time": 45873.797582149506, "episode/length": 55.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9285714285714286, "episode/intrinsic_return": 0.0}
{"step": 355960, "time": 45879.05232858658, "episode/length": 285.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9965034965034965, "episode/intrinsic_return": 0.0}
{"step": 355976, "time": 45882.561779260635, "episode/length": 190.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 356056, "time": 45893.38314771652, "episode/length": 58.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 356136, "time": 45904.12298035622, "episode/length": 178.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 356440, "time": 45940.95173096657, "episode/length": 224.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.0}
{"step": 356992, "time": 46007.02483177185, "episode/length": 175.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 356992, "time": 46007.0315990448, "episode/length": 132.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9924812030075187, "episode/intrinsic_return": 0.0}
{"step": 357120, "time": 46025.15879678726, "episode/length": 142.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 357360, "time": 46054.60915565491, "episode/length": 162.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 357504, "time": 46073.05230855942, "episode/length": 170.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 358160, "time": 46150.97595858574, "episode/length": 214.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 358192, "time": 46156.12385225296, "episode/length": 278.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.996415770609319, "episode/intrinsic_return": 0.0}
{"step": 358344, "time": 46175.71848297119, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 358360, "time": 46179.055948257446, "episode/length": 154.0, "episode/score": 4.1000000312924385, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 358584, "time": 46206.70239043236, "episode/length": 198.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 358864, "time": 46240.90086221695, "episode/length": 169.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 358952, "time": 46252.670060396194, "episode/length": 439.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9795454545454545, "episode/intrinsic_return": 0.0}
{"step": 359408, "time": 46308.166843652725, "episode/length": 130.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9923664122137404, "episode/intrinsic_return": 0.0}
{"step": 359600, "time": 46332.09797000885, "episode/length": 175.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 359773, "time": 46354.69984602928, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.408301086425781, "train/action_min": 0.0, "train/action_std": 3.103209103345871, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.047883864119648935, "train/actor_opt_grad_steps": 88555.0, "train/actor_opt_loss": -9.470213205963374, "train/adv_mag": 0.4791251036524773, "train/adv_max": 0.44854735031723975, "train/adv_mean": 0.0034420066212533127, "train/adv_min": -0.39979034394025803, "train/adv_std": 0.058601355105638506, "train/cont_avg": 0.994580078125, "train/cont_loss_mean": 7.310412953742684e-05, "train/cont_loss_std": 0.002221064620500783, "train/cont_neg_acc": 0.9986607146263122, "train/cont_neg_loss": 0.0032140959598882545, "train/cont_pos_acc": 0.999985258281231, "train/cont_pos_loss": 5.319972530633876e-05, "train/cont_pred": 0.9945656114816666, "train/cont_rate": 0.994580078125, "train/dyn_loss_mean": 6.646532623767853, "train/dyn_loss_std": 8.797373995780944, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.2172630614042281, "train/extr_critic_critic_opt_grad_steps": 88555.0, "train/extr_critic_critic_opt_loss": 17055.413481445314, "train/extr_critic_mag": 8.433915781974793, "train/extr_critic_max": 8.433915781974793, "train/extr_critic_mean": 2.21126201570034, "train/extr_critic_min": -0.5660041785240173, "train/extr_critic_std": 1.9162280815839767, "train/extr_return_normed_mag": 1.5233900487422942, "train/extr_return_normed_max": 1.5233900487422942, "train/extr_return_normed_mean": 0.38226023815572263, "train/extr_return_normed_min": -0.11811364492401481, "train/extr_return_normed_std": 0.31682223826646805, "train/extr_return_rate": 0.7688356524705887, "train/extr_return_raw_mag": 9.27746105670929, "train/extr_return_raw_max": 9.27746105670929, "train/extr_return_raw_mean": 2.2324129378795625, "train/extr_return_raw_min": -0.8572376270592212, "train/extr_return_raw_std": 1.956777230501175, "train/extr_reward_mag": 1.0378485643863677, "train/extr_reward_max": 1.0378485643863677, "train/extr_reward_mean": 0.04171854076907039, "train/extr_reward_min": -0.6855405467748642, "train/extr_reward_std": 0.20010069720447063, "train/image_loss_mean": 3.7504052543640136, "train/image_loss_std": 8.70741928577423, "train/model_loss_mean": 7.78756338596344, "train/model_loss_std": 12.779979672431946, "train/model_opt_grad_norm": 39.9501277118472, "train/model_opt_grad_steps": 88476.485, "train/model_opt_loss": 7062.707770996094, "train/model_opt_model_opt_grad_overflow": 0.005, "train/model_opt_model_opt_grad_scale": 921.875, "train/policy_entropy_mag": 2.4418381226062773, "train/policy_entropy_max": 2.4418381226062773, "train/policy_entropy_mean": 0.40078848659992217, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.5296521937847137, "train/policy_logprob_mag": 7.43838410615921, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.40034293368458745, "train/policy_logprob_min": -7.43838410615921, "train/policy_logprob_std": 1.010649406015873, "train/policy_randomness_mag": 0.8618616983294487, "train/policy_randomness_max": 0.8618616983294487, "train/policy_randomness_mean": 0.14146074771881104, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.18694398246705532, "train/post_ent_mag": 58.823838024139405, "train/post_ent_max": 58.823838024139405, "train/post_ent_mean": 41.74395715713501, "train/post_ent_min": 19.8321150970459, "train/post_ent_std": 6.786565291881561, "train/prior_ent_mag": 75.48793395996094, "train/prior_ent_max": 75.48793395996094, "train/prior_ent_mean": 48.368183307647705, "train/prior_ent_min": 28.44791583061218, "train/prior_ent_std": 7.442101516723633, "train/rep_loss_mean": 6.646532623767853, "train/rep_loss_std": 8.797373995780944, "train/reward_avg": 0.03076074196025729, "train/reward_loss_mean": 0.04916548490524292, "train/reward_loss_std": 0.20508512504398824, "train/reward_max_data": 1.0150000035762787, "train/reward_max_pred": 1.0152226567268372, "train/reward_neg_acc": 0.9946177271008492, "train/reward_neg_loss": 0.023430550270713866, "train/reward_pos_acc": 0.9853924924135208, "train/reward_pos_loss": 0.7444929596781731, "train/reward_pred": 0.030467895213514565, "train/reward_rate": 0.0357421875, "train_stats/sum_log_reward": 7.5146343068378725, "train_stats/max_log_achievement_collect_coal": 0.4146341463414634, "train_stats/max_log_achievement_collect_drink": 3.5853658536585367, "train_stats/max_log_achievement_collect_sapling": 1.5609756097560976, "train_stats/max_log_achievement_collect_stone": 6.878048780487805, "train_stats/max_log_achievement_collect_wood": 5.317073170731708, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.14634146341463414, "train_stats/max_log_achievement_eat_cow": 0.024390243902439025, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.0975609756097562, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_furnace": 0.4878048780487805, "train_stats/max_log_achievement_place_plant": 1.4634146341463414, "train_stats/max_log_achievement_place_stone": 3.2439024390243905, "train_stats/max_log_achievement_place_table": 1.829268292682927, "train_stats/max_log_achievement_wake_up": 2.073170731707317, "train_stats/mean_log_entropy": 0.3566312328344438, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 1.4152409448797698e-06, "report/cont_loss_std": 2.2511996576213278e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 6.225374818313867e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.0566643595666392e-06, "report/cont_pred": 0.9941399693489075, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 5.823762893676758, "report/dyn_loss_std": 8.170525550842285, "report/image_loss_mean": 3.624737024307251, "report/image_loss_std": 6.2705230712890625, "report/model_loss_mean": 7.171165466308594, "report/model_loss_std": 9.970458030700684, "report/post_ent_mag": 59.423248291015625, "report/post_ent_max": 59.423248291015625, "report/post_ent_mean": 43.04892349243164, "report/post_ent_min": 16.823299407958984, "report/post_ent_std": 6.772421360015869, "report/prior_ent_mag": 75.12800598144531, "report/prior_ent_max": 75.12800598144531, "report/prior_ent_mean": 48.970909118652344, "report/prior_ent_min": 27.601776123046875, "report/prior_ent_std": 7.467015743255615, "report/rep_loss_mean": 5.823762893676758, "report/rep_loss_std": 8.170525550842285, "report/reward_avg": 0.03847656399011612, "report/reward_loss_mean": 0.052169475704431534, "report/reward_loss_std": 0.17546600103378296, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0011675357818604, "report/reward_neg_acc": 0.9948927760124207, "report/reward_neg_loss": 0.02227044105529785, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.702639639377594, "report/reward_pred": 0.03777344524860382, "report/reward_rate": 0.0439453125, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.0032707408536225557, "eval/cont_loss_std": 0.09806511551141739, "eval/cont_neg_acc": 0.800000011920929, "eval/cont_neg_loss": 0.6674474477767944, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.1777957297454122e-05, "eval/cont_pred": 0.9962254762649536, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 18.666549682617188, "eval/dyn_loss_std": 12.515724182128906, "eval/image_loss_mean": 18.140216827392578, "eval/image_loss_std": 19.5926570892334, "eval/model_loss_mean": 29.473562240600586, "eval/model_loss_std": 24.631797790527344, "eval/post_ent_mag": 60.37153625488281, "eval/post_ent_max": 60.37153625488281, "eval/post_ent_mean": 38.99625015258789, "eval/post_ent_min": 19.882949829101562, "eval/post_ent_std": 6.5825514793396, "eval/prior_ent_mag": 75.12800598144531, "eval/prior_ent_max": 75.12800598144531, "eval/prior_ent_mean": 51.64830017089844, "eval/prior_ent_min": 34.36852264404297, "eval/prior_ent_std": 7.249278545379639, "eval/rep_loss_mean": 18.666549682617188, "eval/rep_loss_std": 12.515724182128906, "eval/reward_avg": 0.03632812574505806, "eval/reward_loss_mean": 0.1301453709602356, "eval/reward_loss_std": 0.8464645743370056, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0006859302520752, "eval/reward_neg_acc": 0.9928717613220215, "eval/reward_neg_loss": 0.07898347824811935, "eval/reward_pos_acc": 0.9047619104385376, "eval/reward_pos_loss": 1.3263593912124634, "eval/reward_pred": 0.03591665253043175, "eval/reward_rate": 0.041015625, "replay/size": 359269.0, "replay/inserts": 8016.0, "replay/samples": 32064.0, "replay/insert_wait_avg": 1.5838655407081345e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.401087301220008e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 73176.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 8.046627044677734e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3913419246674, "timer/env.step_count": 1002.0, "timer/env.step_total": 89.55496311187744, "timer/env.step_frac": 0.08951993021009294, "timer/env.step_avg": 0.08937621069049645, "timer/env.step_min": 0.0230257511138916, "timer/env.step_max": 3.289113759994507, "timer/replay._sample_count": 32064.0, "timer/replay._sample_total": 15.97277545928955, "timer/replay._sample_frac": 0.01596652708784874, "timer/replay._sample_avg": 0.0004981529272483019, "timer/replay._sample_min": 0.00038051605224609375, "timer/replay._sample_max": 0.010960817337036133, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1002.0, "timer/agent.policy_total": 16.062071084976196, "timer/agent.policy_frac": 0.016055787782083504, "timer/agent.policy_avg": 0.016030011062850496, "timer/agent.policy_min": 0.009641885757446289, "timer/agent.policy_max": 0.06939888000488281, "timer/dataset_train_count": 2004.0, "timer/dataset_train_total": 0.3872370719909668, "timer/dataset_train_frac": 0.00038708558917148944, "timer/dataset_train_avg": 0.00019323207185177984, "timer/dataset_train_min": 9.036064147949219e-05, "timer/dataset_train_max": 0.0890967845916748, "timer/agent.train_count": 2004.0, "timer/agent.train_total": 891.5119385719299, "timer/agent.train_frac": 0.8911631890543327, "timer/agent.train_avg": 0.4448662368123403, "timer/agent.train_min": 0.42272305488586426, "timer/agent.train_max": 0.9598186016082764, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4698779582977295, "timer/agent.report_frac": 0.00046969414728612556, "timer/agent.report_avg": 0.23493897914886475, "timer/agent.report_min": 0.22866535186767578, "timer/agent.report_max": 0.2412126064300537, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.765655517578125e-05, "timer/dataset_eval_frac": 2.7645736240152184e-08, "timer/dataset_eval_avg": 2.765655517578125e-05, "timer/dataset_eval_min": 2.765655517578125e-05, "timer/dataset_eval_max": 2.765655517578125e-05, "fps": 8.012737495243439}
{"step": 359784, "time": 46355.87944149971, "episode/length": 149.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 359816, "time": 46361.29716324806, "episode/length": 206.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 359896, "time": 46372.13490200043, "episode/length": 193.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 360032, "time": 46389.32077932358, "episode/length": 145.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9657534246575342, "episode/intrinsic_return": 0.0}
{"step": 360048, "time": 46412.3361120224, "eval_episode/length": 137.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9927536231884058}
{"step": 360048, "time": 46414.696691036224, "eval_episode/length": 158.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9748427672955975}
{"step": 360048, "time": 46416.438606500626, "eval_episode/length": 166.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9760479041916168}
{"step": 360048, "time": 46418.60659074783, "eval_episode/length": 181.0, "eval_episode/score": 8.099999971687794, "eval_episode/reward_rate": 0.9945054945054945}
{"step": 360048, "time": 46420.33688831329, "eval_episode/length": 185.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9946236559139785}
{"step": 360048, "time": 46422.6441514492, "eval_episode/length": 206.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9951690821256038}
{"step": 360048, "time": 46422.65132308006, "eval_episode/length": 206.0, "eval_episode/score": 6.099999971687794, "eval_episode/reward_rate": 0.9951690821256038}
{"step": 360048, "time": 46430.43514919281, "eval_episode/length": 128.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9612403100775194}
{"step": 360232, "time": 46451.72887682915, "episode/length": 159.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 360416, "time": 46474.4753010273, "episode/length": 381.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9764397905759162, "episode/intrinsic_return": 0.0}
{"step": 361192, "time": 46567.95927357674, "episode/length": 222.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.0}
{"step": 361192, "time": 46567.97202658653, "episode/length": 144.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 361304, "time": 46584.37285017967, "episode/length": 185.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 361584, "time": 46618.945222854614, "episode/length": 210.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 361672, "time": 46630.887174367905, "episode/length": 179.0, "episode/score": 9.099999956786633, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 361872, "time": 46656.06136202812, "episode/length": 283.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9788732394366197, "episode/intrinsic_return": 0.0}
{"step": 361880, "time": 46658.47108221054, "episode/length": 261.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9885496183206107, "episode/intrinsic_return": 0.0}
{"step": 362560, "time": 46740.19080877304, "episode/length": 170.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 362568, "time": 46742.54612183571, "episode/length": 268.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9888475836431226, "episode/intrinsic_return": 0.0}
{"step": 362856, "time": 46777.41345500946, "episode/length": 193.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9690721649484536, "episode/intrinsic_return": 0.0}
{"step": 362920, "time": 46786.752024650574, "episode/length": 166.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 363112, "time": 46810.67536354065, "episode/length": 179.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 363128, "time": 46814.07467055321, "episode/length": 155.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 363400, "time": 46847.26193714142, "episode/length": 190.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 363704, "time": 46884.20205116272, "episode/length": 141.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 363896, "time": 46908.09175825119, "episode/length": 129.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9923076923076923, "episode/intrinsic_return": 0.0}
{"step": 363904, "time": 46910.48701500893, "episode/length": 167.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 364280, "time": 46955.749349594116, "episode/length": 169.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 364320, "time": 46962.09223508835, "episode/length": 148.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.959731543624161, "episode/intrinsic_return": 0.0}
{"step": 364392, "time": 46971.97623515129, "episode/length": 159.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.95625, "episode/intrinsic_return": 0.0}
{"step": 364712, "time": 47011.548828840256, "episode/length": 439.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9795454545454545, "episode/intrinsic_return": 0.0}
{"step": 364976, "time": 47044.44209527969, "episode/length": 134.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9925925925925926, "episode/intrinsic_return": 0.0}
{"step": 365256, "time": 47078.60514879227, "episode/length": 193.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 365296, "time": 47084.76533436775, "episode/length": 236.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9831223628691983, "episode/intrinsic_return": 0.0}
{"step": 365432, "time": 47102.09604525566, "episode/length": 190.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 365520, "time": 47113.81209349632, "episode/length": 149.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 365720, "time": 47138.47156524658, "episode/length": 165.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 366168, "time": 47192.266290426254, "episode/length": 235.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 366784, "time": 47265.7667658329, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 367024, "time": 47295.87570142746, "episode/length": 215.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 367080, "time": 47303.940467596054, "episode/length": 227.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 367104, "time": 47308.27066254616, "episode/length": 172.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9826589595375722, "episode/intrinsic_return": 0.0}
{"step": 367136, "time": 47313.41591525078, "episode/length": 269.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9740740740740741, "episode/intrinsic_return": 0.0}
{"step": 367176, "time": 47319.50603747368, "episode/length": 206.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9710144927536232, "episode/intrinsic_return": 0.0}
{"step": 367457, "time": 47354.70367479324, "train_stats/sum_log_reward": 8.050000154972077, "train_stats/max_log_achievement_collect_coal": 0.55, "train_stats/max_log_achievement_collect_drink": 3.0, "train_stats/max_log_achievement_collect_sapling": 1.775, "train_stats/max_log_achievement_collect_stone": 8.025, "train_stats/max_log_achievement_collect_wood": 6.8, "train_stats/max_log_achievement_defeat_skeleton": 0.025, "train_stats/max_log_achievement_defeat_zombie": 0.175, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.325, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_furnace": 0.475, "train_stats/max_log_achievement_place_plant": 1.675, "train_stats/max_log_achievement_place_stone": 3.5, "train_stats/max_log_achievement_place_table": 2.125, "train_stats/max_log_achievement_wake_up": 2.3, "train_stats/mean_log_entropy": 0.3688937794417143, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.46951166788737, "train/action_min": 0.0, "train/action_std": 3.126987903068463, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.044870892520217844, "train/actor_opt_grad_steps": 90515.0, "train/actor_opt_loss": -12.633172909263521, "train/adv_mag": 0.47003711403037113, "train/adv_max": 0.43529442076881725, "train/adv_mean": 0.0018733815369576707, "train/adv_min": -0.38218125731994707, "train/adv_std": 0.05570680758683011, "train/cont_avg": 0.9944966634114584, "train/cont_loss_mean": 0.00018419178761153177, "train/cont_loss_std": 0.005349262614034049, "train/cont_neg_acc": 0.9944963857765597, "train/cont_neg_loss": 0.022011277785382484, "train/cont_pos_acc": 0.9999897566934427, "train/cont_pos_loss": 3.560629305054963e-05, "train/cont_pred": 0.9945096038281918, "train/cont_rate": 0.9944966634114584, "train/dyn_loss_mean": 6.4868288859725, "train/dyn_loss_std": 8.815156218906244, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.188398432917893, "train/extr_critic_critic_opt_grad_steps": 90515.0, "train/extr_critic_critic_opt_loss": 16861.920501708984, "train/extr_critic_mag": 8.564341669281324, "train/extr_critic_max": 8.564341669281324, "train/extr_critic_mean": 2.0716822128742933, "train/extr_critic_min": -0.5771966160585483, "train/extr_critic_std": 1.9989764640728633, "train/extr_return_normed_mag": 1.5084056841830413, "train/extr_return_normed_max": 1.5084056841830413, "train/extr_return_normed_mean": 0.35517337126657367, "train/extr_return_normed_min": -0.11557576364915197, "train/extr_return_normed_std": 0.3228529939272751, "train/extr_return_rate": 0.7201640186831355, "train/extr_return_raw_mag": 9.334498104949793, "train/extr_return_raw_max": 9.334498104949793, "train/extr_return_raw_mean": 2.0834616124629974, "train/extr_return_raw_min": -0.8768747768675288, "train/extr_return_raw_std": 2.0301567247758308, "train/extr_reward_mag": 1.0421925447881222, "train/extr_reward_max": 1.0421925447881222, "train/extr_reward_mean": 0.04157792371309673, "train/extr_reward_min": -0.6827082385619482, "train/extr_reward_std": 0.20038472806724408, "train/image_loss_mean": 3.747799452394247, "train/image_loss_std": 8.484542056918144, "train/model_loss_mean": 7.689145644505818, "train/model_loss_std": 12.573220436771711, "train/model_opt_grad_norm": 43.821099231640495, "train/model_opt_grad_steps": 90435.0, "train/model_opt_loss": 6830.547106424968, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 890.2994791666666, "train/policy_entropy_mag": 2.450604412704706, "train/policy_entropy_max": 2.450604412704706, "train/policy_entropy_mean": 0.41186898403490585, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.5384437368872265, "train/policy_logprob_mag": 7.4383841107289, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.4120903199849029, "train/policy_logprob_min": -7.4383841107289, "train/policy_logprob_std": 1.0219974210485816, "train/policy_randomness_mag": 0.8649558148657283, "train/policy_randomness_max": 0.8649558148657283, "train/policy_randomness_mean": 0.14537167673309645, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.19004701070177057, "train/post_ent_mag": 59.03104786078135, "train/post_ent_max": 59.03104786078135, "train/post_ent_mean": 42.04532241821289, "train/post_ent_min": 19.779172937075298, "train/post_ent_std": 6.818653948605061, "train/prior_ent_mag": 75.48466165860494, "train/prior_ent_max": 75.48466165860494, "train/prior_ent_mean": 48.50917921463648, "train/prior_ent_min": 28.487848222255707, "train/prior_ent_std": 7.535939482351144, "train/rep_loss_mean": 6.4868288859725, "train/rep_loss_std": 8.815156218906244, "train/reward_avg": 0.0301635741100957, "train/reward_loss_mean": 0.04906473247683607, "train/reward_loss_std": 0.2067574663863828, "train/reward_max_data": 1.0166666706403096, "train/reward_max_pred": 1.0168740569303434, "train/reward_neg_acc": 0.9946411891529957, "train/reward_neg_loss": 0.023650850518606603, "train/reward_pos_acc": 0.9845239284137884, "train/reward_pos_loss": 0.7493788885573546, "train/reward_pred": 0.029927097076627735, "train/reward_rate": 0.035105387369791664, "eval_stats/sum_log_reward": 7.475000202655792, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 4.25, "eval_stats/max_log_achievement_collect_sapling": 1.125, "eval_stats/max_log_achievement_collect_stone": 7.25, "eval_stats/max_log_achievement_collect_wood": 4.5, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.125, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.125, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.125, "eval_stats/max_log_achievement_place_plant": 1.125, "eval_stats/max_log_achievement_place_stone": 3.375, "eval_stats/max_log_achievement_place_table": 1.375, "eval_stats/max_log_achievement_wake_up": 1.75, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 5.741824793403794e-07, "report/cont_loss_std": 6.576976375072263e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 6.382589344866574e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 3.261365293383278e-07, "report/cont_pred": 0.99609375, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 5.5465545654296875, "report/dyn_loss_std": 8.334412574768066, "report/image_loss_mean": 2.3043785095214844, "report/image_loss_std": 6.345462799072266, "report/model_loss_mean": 5.6850433349609375, "report/model_loss_std": 10.361027717590332, "report/post_ent_mag": 56.72923278808594, "report/post_ent_max": 56.72923278808594, "report/post_ent_mean": 41.863037109375, "report/post_ent_min": 20.36610221862793, "report/post_ent_std": 6.221076965332031, "report/prior_ent_mag": 75.6176528930664, "report/prior_ent_max": 75.6176528930664, "report/prior_ent_mean": 47.81473159790039, "report/prior_ent_min": 30.240158081054688, "report/prior_ent_std": 6.553770065307617, "report/rep_loss_mean": 5.5465545654296875, "report/rep_loss_std": 8.334412574768066, "report/reward_avg": 0.03886718675494194, "report/reward_loss_mean": 0.052731163799762726, "report/reward_loss_std": 0.21037672460079193, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.0772426128387451, "report/reward_neg_acc": 0.996941864490509, "report/reward_neg_loss": 0.02292638085782528, "report/reward_pos_acc": 0.9767441749572754, "report/reward_pos_loss": 0.7326960563659668, "report/reward_pred": 0.03854504972696304, "report/reward_rate": 0.0419921875, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.00016821666213218123, "eval/cont_loss_std": 0.004534737206995487, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.028500214219093323, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.2304344636504538e-06, "eval/cont_pred": 0.994296669960022, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 19.147533416748047, "eval/dyn_loss_std": 13.400482177734375, "eval/image_loss_mean": 20.57815170288086, "eval/image_loss_std": 30.33666229248047, "eval/model_loss_mean": 32.21320343017578, "eval/model_loss_std": 35.884178161621094, "eval/post_ent_mag": 57.572601318359375, "eval/post_ent_max": 57.572601318359375, "eval/post_ent_mean": 39.399391174316406, "eval/post_ent_min": 22.443178176879883, "eval/post_ent_std": 6.47923469543457, "eval/prior_ent_mag": 75.6176528930664, "eval/prior_ent_max": 75.6176528930664, "eval/prior_ent_mean": 52.25355529785156, "eval/prior_ent_min": 30.5101261138916, "eval/prior_ent_std": 7.974593162536621, "eval/rep_loss_mean": 19.147533416748047, "eval/rep_loss_std": 13.400482177734375, "eval/reward_avg": 0.03105468861758709, "eval/reward_loss_mean": 0.1463666558265686, "eval/reward_loss_std": 0.9393426775932312, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0012097358703613, "eval/reward_neg_acc": 0.9929077625274658, "eval/reward_neg_loss": 0.0644017681479454, "eval/reward_pos_acc": 0.8108108043670654, "eval/reward_pos_loss": 2.3328349590301514, "eval/reward_pred": 0.024478543549776077, "eval/reward_rate": 0.0361328125, "replay/size": 366953.0, "replay/inserts": 7684.0, "replay/samples": 30736.0, "replay/insert_wait_avg": 1.5075227855581097e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.44041895134135e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 75480.0, "eval_replay/inserts": 2304.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3440019554562039e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 999.987523317337, "timer/env.step_count": 961.0, "timer/env.step_total": 88.8039801120758, "timer/env.step_frac": 0.08880508810497895, "timer/env.step_avg": 0.0924078877336897, "timer/env.step_min": 0.023243188858032227, "timer/env.step_max": 3.2961032390594482, "timer/replay._sample_count": 30736.0, "timer/replay._sample_total": 15.393239498138428, "timer/replay._sample_frac": 0.01539343155709906, "timer/replay._sample_avg": 0.0005008211705536969, "timer/replay._sample_min": 0.00037550926208496094, "timer/replay._sample_max": 0.02581191062927246, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1249.0, "timer/agent.policy_total": 21.440008640289307, "timer/agent.policy_frac": 0.02144027614381096, "timer/agent.policy_avg": 0.01716573950383451, "timer/agent.policy_min": 0.009591102600097656, "timer/agent.policy_max": 0.12227225303649902, "timer/dataset_train_count": 1921.0, "timer/dataset_train_total": 0.28621578216552734, "timer/dataset_train_frac": 0.00028621935323356966, "timer/dataset_train_avg": 0.00014899311929491272, "timer/dataset_train_min": 8.96453857421875e-05, "timer/dataset_train_max": 0.0037088394165039062, "timer/agent.train_count": 1921.0, "timer/agent.train_total": 855.1332342624664, "timer/agent.train_frac": 0.8551439036215831, "timer/agent.train_avg": 0.4451500438638555, "timer/agent.train_min": 0.43265223503112793, "timer/agent.train_max": 1.089564323425293, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47287893295288086, "timer/agent.report_frac": 0.00047288483298687817, "timer/agent.report_avg": 0.23643946647644043, "timer/agent.report_min": 0.2293846607208252, "timer/agent.report_max": 0.24349427223205566, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.5987625122070312e-05, "timer/dataset_eval_frac": 2.5987949365467606e-08, "timer/dataset_eval_avg": 2.5987625122070312e-05, "timer/dataset_eval_min": 2.5987625122070312e-05, "timer/dataset_eval_max": 2.5987625122070312e-05, "fps": 7.6839960282079245}
{"step": 367592, "time": 47370.22900056839, "episode/length": 177.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9662921348314607, "episode/intrinsic_return": 0.0}
{"step": 367752, "time": 47390.21852064133, "episode/length": 90.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9560439560439561, "episode/intrinsic_return": 0.0}
{"step": 368160, "time": 47439.09746837616, "episode/length": 430.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9791183294663574, "episode/intrinsic_return": 0.0}
{"step": 368224, "time": 47448.18783187866, "episode/length": 135.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.0}
{"step": 368296, "time": 47458.320494413376, "episode/length": 188.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 368416, "time": 47474.25896668434, "episode/length": 166.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 368608, "time": 47498.01359319687, "episode/length": 178.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 368752, "time": 47517.61017251015, "episode/length": 144.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 368880, "time": 47533.97065973282, "episode/length": 81.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9878048780487805, "episode/intrinsic_return": 0.0}
{"step": 368944, "time": 47542.930451631546, "episode/length": 229.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9695652173913043, "episode/intrinsic_return": 0.0}
{"step": 368992, "time": 47550.07685184479, "episode/length": 154.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 369416, "time": 47600.92960309982, "episode/length": 156.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 369760, "time": 47642.54720664024, "episode/length": 42.0, "episode/score": 3.1000000163912773, "episode/reward_rate": 0.9302325581395349, "episode/intrinsic_return": 0.0}
{"step": 369848, "time": 47654.857860565186, "episode/length": 154.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 370032, "time": 47693.25771999359, "eval_episode/length": 85.0, "eval_episode/score": 5.100000023841858, "eval_episode/reward_rate": 0.9883720930232558}
{"step": 370032, "time": 47696.97627687454, "eval_episode/length": 141.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9577464788732394}
{"step": 370032, "time": 47698.98320865631, "eval_episode/length": 154.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9935483870967742}
{"step": 370032, "time": 47701.34632015228, "eval_episode/length": 172.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9710982658959537}
{"step": 370032, "time": 47703.15287876129, "eval_episode/length": 179.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 370032, "time": 47705.100511074066, "eval_episode/length": 191.0, "eval_episode/score": 9.099999994039536, "eval_episode/reward_rate": 0.9947916666666666}
{"step": 370032, "time": 47708.85322546959, "eval_episode/length": 70.0, "eval_episode/score": 5.100000023841858, "eval_episode/reward_rate": 0.9859154929577465}
{"step": 370032, "time": 47711.145591259, "eval_episode/length": 258.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9884169884169884}
{"step": 370384, "time": 47752.49358034134, "episode/length": 203.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 370392, "time": 47755.45001888275, "episode/length": 174.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 370456, "time": 47764.96929311752, "episode/length": 188.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 370528, "time": 47775.44009590149, "episode/length": 263.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9810606060606061, "episode/intrinsic_return": 0.0}
{"step": 370888, "time": 47818.786536216736, "episode/length": 250.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9721115537848606, "episode/intrinsic_return": 0.0}
{"step": 370984, "time": 47831.54086184502, "episode/length": 141.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 371384, "time": 47879.57049369812, "episode/length": 106.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9906542056074766, "episode/intrinsic_return": 0.0}
{"step": 371680, "time": 47915.54479956627, "episode/length": 422.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9976359338061466, "episode/intrinsic_return": 0.0}
{"step": 371680, "time": 47915.554730176926, "episode/length": 161.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 371808, "time": 47933.7066783905, "episode/length": 52.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 371888, "time": 47944.49705481529, "episode/length": 178.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 371912, "time": 47948.866774082184, "episode/length": 189.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.968421052631579, "episode/intrinsic_return": 0.0}
{"step": 372024, "time": 47964.04214835167, "episode/length": 141.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 372536, "time": 48025.11854958534, "episode/length": 106.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9906542056074766, "episode/intrinsic_return": 0.0}
{"step": 372616, "time": 48035.9003944397, "episode/length": 203.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9656862745098039, "episode/intrinsic_return": 0.0}
{"step": 373248, "time": 48111.10793042183, "episode/length": 152.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.0}
{"step": 373272, "time": 48115.49226689339, "episode/length": 438.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.979498861047836, "episode/intrinsic_return": 0.0}
{"step": 373272, "time": 48115.50134778023, "episode/length": 182.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 373304, "time": 48122.552162885666, "episode/length": 202.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9704433497536946, "episode/intrinsic_return": 0.0}
{"step": 373440, "time": 48139.96300673485, "episode/length": 102.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9902912621359223, "episode/intrinsic_return": 0.0}
{"step": 374000, "time": 48206.471066236496, "episode/length": 182.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 374184, "time": 48229.46893072128, "episode/length": 113.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9473684210526315, "episode/intrinsic_return": 0.0}
{"step": 374568, "time": 48276.67840266228, "episode/length": 164.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 374760, "time": 48300.57212495804, "episode/length": 358.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9944289693593314, "episode/intrinsic_return": 0.0}
{"step": 375160, "time": 48348.58164000511, "episode/length": 214.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 375189, "time": 48354.80816245079, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.4942778750404795, "train/action_min": 0.0, "train/action_std": 3.1322271947416, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0466011353030106, "train/actor_opt_grad_steps": 92440.0, "train/actor_opt_loss": -12.224473126502852, "train/adv_mag": 0.5000211179565272, "train/adv_max": 0.4579843946689151, "train/adv_mean": 0.0024421797010140103, "train/adv_min": -0.4133041822230878, "train/adv_std": 0.05838950387554465, "train/cont_avg": 0.9947427542098446, "train/cont_loss_mean": 6.202152104179223e-05, "train/cont_loss_std": 0.0017779830876221816, "train/cont_neg_acc": 0.9992598079029142, "train/cont_neg_loss": 0.004712861846995163, "train/cont_pos_acc": 0.9999949014866291, "train/cont_pos_loss": 3.0466144308024805e-05, "train/cont_pred": 0.9947334821360099, "train/cont_rate": 0.9947427542098446, "train/dyn_loss_mean": 6.707649579319929, "train/dyn_loss_std": 8.841737290120495, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1877862372546617, "train/extr_critic_critic_opt_grad_steps": 92440.0, "train/extr_critic_critic_opt_loss": 16953.94524166127, "train/extr_critic_mag": 8.44252624907024, "train/extr_critic_max": 8.44252624907024, "train/extr_critic_mean": 2.017841590500866, "train/extr_critic_min": -0.5631428746979471, "train/extr_critic_std": 1.947542351144583, "train/extr_return_normed_mag": 1.5371117381851909, "train/extr_return_normed_max": 1.5371117381851909, "train/extr_return_normed_mean": 0.3568709866370562, "train/extr_return_normed_min": -0.11531106531233985, "train/extr_return_normed_std": 0.3245929353749814, "train/extr_return_rate": 0.7233781678688959, "train/extr_return_raw_mag": 9.248140048486581, "train/extr_return_raw_max": 9.248140048486581, "train/extr_return_raw_mean": 2.032773103738696, "train/extr_return_raw_min": -0.8540799271875095, "train/extr_return_raw_std": 1.9845201141476014, "train/extr_reward_mag": 1.035841131457393, "train/extr_reward_max": 1.035841131457393, "train/extr_reward_mean": 0.04289117736326907, "train/extr_reward_min": -0.6779112087012572, "train/extr_reward_std": 0.2024214873814212, "train/image_loss_mean": 3.7877771916167107, "train/image_loss_std": 8.795283179209022, "train/model_loss_mean": 7.861597014214708, "train/model_loss_std": 12.878410077465631, "train/model_opt_grad_norm": 40.11504887286281, "train/model_opt_grad_steps": 92358.95854922279, "train/model_opt_loss": 11696.045655561853, "train/model_opt_model_opt_grad_overflow": 0.010362694300518135, "train/model_opt_model_opt_grad_scale": 1476.6839378238342, "train/policy_entropy_mag": 2.433897857221297, "train/policy_entropy_max": 2.433897857221297, "train/policy_entropy_mean": 0.4128169880629821, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.5371492024839233, "train/policy_logprob_mag": 7.438384061032626, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.41283950425800264, "train/policy_logprob_min": -7.438384061032626, "train/policy_logprob_std": 1.0231553961575959, "train/policy_randomness_mag": 0.859059133986735, "train/policy_randomness_max": 0.859059133986735, "train/policy_randomness_mean": 0.14570627944457099, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.1895900960876534, "train/post_ent_mag": 58.87085573660895, "train/post_ent_max": 58.87085573660895, "train/post_ent_mean": 41.94724143230853, "train/post_ent_min": 19.829224482719145, "train/post_ent_std": 6.764820145819471, "train/prior_ent_mag": 75.61891253377489, "train/prior_ent_max": 75.61891253377489, "train/prior_ent_mean": 48.63754096550027, "train/prior_ent_min": 28.746620899655042, "train/prior_ent_std": 7.423448453913081, "train/rep_loss_mean": 6.707649579319929, "train/rep_loss_std": 8.841737290120495, "train/reward_avg": 0.03157484575314688, "train/reward_loss_mean": 0.049168067284584664, "train/reward_loss_std": 0.21075521069795974, "train/reward_max_data": 1.0160621799953242, "train/reward_max_pred": 1.0137368063852576, "train/reward_neg_acc": 0.9950386063422564, "train/reward_neg_loss": 0.022834575802589636, "train/reward_pos_acc": 0.9848046179262467, "train/reward_pos_loss": 0.748723146211298, "train/reward_pred": 0.031169467118274362, "train/reward_rate": 0.0362744899611399, "train_stats/sum_log_reward": 7.484615374834109, "train_stats/max_log_achievement_collect_coal": 0.23076923076923078, "train_stats/max_log_achievement_collect_drink": 3.2051282051282053, "train_stats/max_log_achievement_collect_sapling": 1.5128205128205128, "train_stats/max_log_achievement_collect_stone": 7.0, "train_stats/max_log_achievement_collect_wood": 5.410256410256411, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.1282051282051282, "train_stats/max_log_achievement_eat_cow": 0.07692307692307693, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.0512820512820513, "train_stats/max_log_achievement_make_wood_sword": 0.05128205128205128, "train_stats/max_log_achievement_place_furnace": 0.4358974358974359, "train_stats/max_log_achievement_place_plant": 1.358974358974359, "train_stats/max_log_achievement_place_stone": 3.769230769230769, "train_stats/max_log_achievement_place_table": 1.794871794871795, "train_stats/max_log_achievement_wake_up": 2.1794871794871793, "train_stats/mean_log_entropy": 0.3653657218584648, "eval_stats/sum_log_reward": 6.225000083446503, "eval_stats/max_log_achievement_collect_coal": 0.25, "eval_stats/max_log_achievement_collect_drink": 1.875, "eval_stats/max_log_achievement_collect_sapling": 1.25, "eval_stats/max_log_achievement_collect_stone": 4.625, "eval_stats/max_log_achievement_collect_wood": 6.0, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.25, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.5, "eval_stats/max_log_achievement_place_plant": 1.25, "eval_stats/max_log_achievement_place_stone": 1.5, "eval_stats/max_log_achievement_place_table": 1.75, "eval_stats/max_log_achievement_wake_up": 1.75, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 6.703732196911005e-06, "report/cont_loss_std": 4.123360486119054e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 8.325704584422056e-06, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 6.6973711909668054e-06, "report/cont_pred": 0.9960871338844299, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 6.415672302246094, "report/dyn_loss_std": 9.351083755493164, "report/image_loss_mean": 2.7321858406066895, "report/image_loss_std": 6.679266452789307, "report/model_loss_mean": 6.625433444976807, "report/model_loss_std": 11.302823066711426, "report/post_ent_mag": 57.67711639404297, "report/post_ent_max": 57.67711639404297, "report/post_ent_mean": 41.60491180419922, "report/post_ent_min": 15.93173885345459, "report/post_ent_std": 6.594955921173096, "report/prior_ent_mag": 75.68887329101562, "report/prior_ent_max": 75.68887329101562, "report/prior_ent_mean": 47.587127685546875, "report/prior_ent_min": 29.577075958251953, "report/prior_ent_std": 7.176903247833252, "report/rep_loss_mean": 6.415672302246094, "report/rep_loss_std": 9.351083755493164, "report/reward_avg": 0.03554687649011612, "report/reward_loss_mean": 0.04383714497089386, "report/reward_loss_std": 0.15895451605319977, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.001823902130127, "report/reward_neg_acc": 0.9989838004112244, "report/reward_neg_loss": 0.018164001405239105, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6753965616226196, "report/reward_pred": 0.035613253712654114, "report/reward_rate": 0.0390625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 2.575891267042607e-05, "eval/cont_loss_std": 0.0003844567690975964, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00442717969417572, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.282623634324409e-05, "eval/cont_pred": 0.9970704317092896, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 20.72325897216797, "eval/dyn_loss_std": 12.697769165039062, "eval/image_loss_mean": 19.220413208007812, "eval/image_loss_std": 22.097124099731445, "eval/model_loss_mean": 31.80502700805664, "eval/model_loss_std": 26.96864891052246, "eval/post_ent_mag": 53.75627517700195, "eval/post_ent_max": 53.75627517700195, "eval/post_ent_mean": 38.734291076660156, "eval/post_ent_min": 19.95030403137207, "eval/post_ent_std": 6.334117412567139, "eval/prior_ent_mag": 75.68887329101562, "eval/prior_ent_max": 75.68887329101562, "eval/prior_ent_mean": 51.778587341308594, "eval/prior_ent_min": 33.53331756591797, "eval/prior_ent_std": 6.487087726593018, "eval/rep_loss_mean": 20.72325897216797, "eval/rep_loss_std": 12.697769165039062, "eval/reward_avg": 0.04052734375, "eval/reward_loss_mean": 0.15063494443893433, "eval/reward_loss_std": 0.8721610307693481, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0101051330566406, "eval/reward_neg_acc": 0.9856997132301331, "eval/reward_neg_loss": 0.07990211248397827, "eval/reward_pos_acc": 0.8444444537162781, "eval/reward_pos_loss": 1.689467430114746, "eval/reward_pred": 0.03976947069168091, "eval/reward_rate": 0.0439453125, "replay/size": 374685.0, "replay/inserts": 7732.0, "replay/samples": 30928.0, "replay/insert_wait_avg": 1.5151543871331448e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.496833554587091e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 77552.0, "eval_replay/inserts": 2072.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1468716109581435e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.685754776000977e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.086788892746, "timer/env.step_count": 966.0, "timer/env.step_total": 87.68501353263855, "timer/env.step_frac": 0.08767740410781719, "timer/env.step_avg": 0.0907712355410337, "timer/env.step_min": 0.02275848388671875, "timer/env.step_max": 3.3532440662384033, "timer/replay._sample_count": 30928.0, "timer/replay._sample_total": 15.385526657104492, "timer/replay._sample_frac": 0.015384191480160138, "timer/replay._sample_avg": 0.0004974627087785985, "timer/replay._sample_min": 0.00039887428283691406, "timer/replay._sample_max": 0.011307001113891602, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1225.0, "timer/agent.policy_total": 19.26781439781189, "timer/agent.policy_frac": 0.01926614231065326, "timer/agent.policy_avg": 0.015728828079846442, "timer/agent.policy_min": 0.009356021881103516, "timer/agent.policy_max": 0.0794060230255127, "timer/dataset_train_count": 1933.0, "timer/dataset_train_total": 0.2794473171234131, "timer/dataset_train_frac": 0.0002794230663048808, "timer/dataset_train_avg": 0.00014456664103642685, "timer/dataset_train_min": 8.559226989746094e-05, "timer/dataset_train_max": 0.0006129741668701172, "timer/agent.train_count": 1933.0, "timer/agent.train_total": 860.6823892593384, "timer/agent.train_frac": 0.8606076980701343, "timer/agent.train_avg": 0.4452573146711528, "timer/agent.train_min": 0.4359114170074463, "timer/agent.train_max": 1.5131521224975586, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4745666980743408, "timer/agent.report_frac": 0.000474525514530355, "timer/agent.report_avg": 0.2372833490371704, "timer/agent.report_min": 0.23002886772155762, "timer/agent.report_max": 0.2445378303527832, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.5987625122070312e-05, "timer/dataset_eval_frac": 2.598536988059078e-08, "timer/dataset_eval_avg": 2.5987625122070312e-05, "timer/dataset_eval_min": 2.5987625122070312e-05, "timer/dataset_eval_max": 2.5987625122070312e-05, "fps": 7.731208839830254}
{"step": 375344, "time": 48372.82000994682, "episode/length": 428.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9953379953379954, "episode/intrinsic_return": 0.0}
{"step": 375528, "time": 48395.68725013733, "episode/length": 167.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 375664, "time": 48412.94890117645, "episode/length": 207.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 375840, "time": 48435.01713490486, "episode/length": 61.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9516129032258065, "episode/intrinsic_return": 0.0}
{"step": 376320, "time": 48492.95667243004, "episode/length": 194.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 376352, "time": 48498.08544397354, "episode/length": 222.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.968609865470852, "episode/intrinsic_return": 0.0}
{"step": 376416, "time": 48507.05467867851, "episode/length": 392.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9974554707379135, "episode/intrinsic_return": 0.0}
{"step": 376728, "time": 48544.84146618843, "episode/length": 427.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9789719626168224, "episode/intrinsic_return": 0.0}
{"step": 376864, "time": 48563.30205798149, "episode/length": 212.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 377176, "time": 48600.945104599, "episode/length": 55.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 377288, "time": 48615.52159547806, "episode/length": 219.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 377304, "time": 48618.90090036392, "episode/length": 204.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.0}
{"step": 377424, "time": 48634.31195807457, "episode/length": 197.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 377824, "time": 48682.48856306076, "episode/length": 187.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 377832, "time": 48685.38832497597, "episode/length": 176.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 378072, "time": 48715.22973251343, "episode/length": 214.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 378280, "time": 48741.109162807465, "episode/length": 176.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 378520, "time": 48770.79384112358, "episode/length": 167.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 378728, "time": 48796.831889629364, "episode/length": 111.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9732142857142857, "episode/intrinsic_return": 0.0}
{"step": 378736, "time": 48799.242651462555, "episode/length": 163.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 379280, "time": 48864.0191514492, "episode/length": 150.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9602649006622517, "episode/intrinsic_return": 0.0}
{"step": 379640, "time": 48907.02061629295, "episode/length": 293.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9829931972789115, "episode/intrinsic_return": 0.0}
{"step": 379752, "time": 48921.461587667465, "episode/length": 305.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9836601307189542, "episode/intrinsic_return": 0.0}
{"step": 379880, "time": 48937.67846727371, "episode/length": 169.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 379888, "time": 48940.173899412155, "episode/length": 257.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9883720930232558, "episode/intrinsic_return": 0.0}
{"step": 380016, "time": 48971.80541038513, "eval_episode/length": 39.0, "eval_episode/score": 4.100000023841858, "eval_episode/reward_rate": 0.975}
{"step": 380016, "time": 48973.71125268936, "eval_episode/length": 49.0, "eval_episode/score": 2.100000001490116, "eval_episode/reward_rate": 0.94}
{"step": 380016, "time": 48978.55866384506, "eval_episode/length": 134.0, "eval_episode/score": 7.100000023841858, "eval_episode/reward_rate": 0.9925925925925926}
{"step": 380016, "time": 48980.90658164024, "eval_episode/length": 156.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9681528662420382}
{"step": 380016, "time": 48982.65716314316, "eval_episode/length": 166.0, "eval_episode/score": 6.099999979138374, "eval_episode/reward_rate": 0.9940119760479041}
{"step": 380016, "time": 48984.470655202866, "eval_episode/length": 174.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 380016, "time": 48986.077298641205, "eval_episode/length": 177.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9943820224719101}
{"step": 380016, "time": 48988.62860965729, "eval_episode/length": 165.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9759036144578314}
{"step": 380048, "time": 48992.31303572655, "episode/length": 163.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9634146341463414, "episode/intrinsic_return": 0.0}
{"step": 380336, "time": 49026.965079307556, "episode/length": 256.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9688715953307393, "episode/intrinsic_return": 0.0}
{"step": 380376, "time": 49033.03073501587, "episode/length": 205.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 380424, "time": 49040.15765285492, "episode/length": 67.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9264705882352942, "episode/intrinsic_return": 0.0}
{"step": 381168, "time": 49128.07504153252, "episode/length": 190.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 381208, "time": 49134.13160920143, "episode/length": 181.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 381224, "time": 49137.445576667786, "episode/length": 242.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9794238683127572, "episode/intrinsic_return": 0.0}
{"step": 381432, "time": 49163.20115733147, "episode/length": 192.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 381608, "time": 49185.28531289101, "episode/length": 47.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.8958333333333334, "episode/intrinsic_return": 0.0}
{"step": 381624, "time": 49188.64239883423, "episode/length": 196.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9644670050761421, "episode/intrinsic_return": 0.0}
{"step": 381624, "time": 49188.649017333984, "episode/length": 149.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 381968, "time": 49231.638543605804, "episode/length": 203.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 381976, "time": 49234.030623197556, "episode/length": 199.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 382576, "time": 49305.20677304268, "episode/length": 175.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 382985, "time": 49355.036271333694, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.464984287359775, "train/action_min": 0.0, "train/action_std": 3.021984654206496, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04592365383719787, "train/actor_opt_grad_steps": 94380.0, "train/actor_opt_loss": -10.241863483190537, "train/adv_mag": 0.4877890391227527, "train/adv_max": 0.4476940659376291, "train/adv_mean": 0.0035274863452053606, "train/adv_min": -0.40584231232985474, "train/adv_std": 0.058045665556803724, "train/cont_avg": 0.9947165464743589, "train/cont_loss_mean": 9.823477046579362e-05, "train/cont_loss_std": 0.0029548225738958186, "train/cont_neg_acc": 0.9987829324510908, "train/cont_neg_loss": 0.007469131030727591, "train/cont_pos_acc": 0.9999899115317907, "train/cont_pos_loss": 4.157593006024303e-05, "train/cont_pred": 0.9947041147794479, "train/cont_rate": 0.9947165464743589, "train/dyn_loss_mean": 6.496873192909437, "train/dyn_loss_std": 8.771693733410958, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1703449417383243, "train/extr_critic_critic_opt_grad_steps": 94380.0, "train/extr_critic_critic_opt_loss": 17070.62502003205, "train/extr_critic_mag": 8.50786691078773, "train/extr_critic_max": 8.50786691078773, "train/extr_critic_mean": 2.026700752820724, "train/extr_critic_min": -0.5515762102909577, "train/extr_critic_std": 1.9498595078786214, "train/extr_return_normed_mag": 1.530465072240585, "train/extr_return_normed_max": 1.530465072240585, "train/extr_return_normed_mean": 0.35499213590071754, "train/extr_return_normed_min": -0.11064802543857159, "train/extr_return_normed_std": 0.3212505812064195, "train/extr_return_rate": 0.7242291380197574, "train/extr_return_raw_mag": 9.319169455308181, "train/extr_return_raw_max": 9.319169455308181, "train/extr_return_raw_mean": 2.048508568910452, "train/extr_return_raw_min": -0.8320210595925649, "train/extr_return_raw_std": 1.9873327787105854, "train/extr_reward_mag": 1.0441695800194373, "train/extr_reward_max": 1.0441695800194373, "train/extr_reward_mean": 0.04280496467000399, "train/extr_reward_min": -0.6411930762804472, "train/extr_reward_std": 0.20251369292919452, "train/image_loss_mean": 3.707639191700862, "train/image_loss_std": 8.715256742330698, "train/model_loss_mean": 7.653906883337559, "train/model_loss_std": 12.792244324317345, "train/model_opt_grad_norm": 41.903312316307655, "train/model_opt_grad_steps": 94297.50256410257, "train/model_opt_loss": 11501.32204276843, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1500.0, "train/policy_entropy_mag": 2.432059003145267, "train/policy_entropy_max": 2.432059003145267, "train/policy_entropy_mean": 0.4111187688815288, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.540286966929069, "train/policy_logprob_mag": 7.438384100107046, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.4113069677964235, "train/policy_logprob_min": -7.438384100107046, "train/policy_logprob_std": 1.0220507820447287, "train/policy_randomness_mag": 0.8584100998364962, "train/policy_randomness_max": 0.8584100998364962, "train/policy_randomness_mean": 0.14510688330882635, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.19069758921097488, "train/post_ent_mag": 59.29281219091171, "train/post_ent_max": 59.29281219091171, "train/post_ent_mean": 42.105616329877805, "train/post_ent_min": 19.353392302684295, "train/post_ent_std": 6.792136216774965, "train/prior_ent_mag": 75.58557715782753, "train/prior_ent_max": 75.58557715782753, "train/prior_ent_mean": 48.602226316011865, "train/prior_ent_min": 29.190387970361954, "train/prior_ent_std": 7.469976554772793, "train/rep_loss_mean": 6.496873192909437, "train/rep_loss_std": 8.771693733410958, "train/reward_avg": 0.031091746544608702, "train/reward_loss_mean": 0.04804559259269482, "train/reward_loss_std": 0.19913355566752264, "train/reward_max_data": 1.0169230809578529, "train/reward_max_pred": 1.015394707215138, "train/reward_neg_acc": 0.9950485030810038, "train/reward_neg_loss": 0.022467962843485366, "train/reward_pos_acc": 0.9863411561036721, "train/reward_pos_loss": 0.7377316028643877, "train/reward_pred": 0.030816624046136172, "train/reward_rate": 0.03575220352564103, "train_stats/sum_log_reward": 7.920513006357046, "train_stats/max_log_achievement_collect_coal": 0.6923076923076923, "train_stats/max_log_achievement_collect_drink": 3.8461538461538463, "train_stats/max_log_achievement_collect_sapling": 1.2307692307692308, "train_stats/max_log_achievement_collect_stone": 8.794871794871796, "train_stats/max_log_achievement_collect_wood": 5.717948717948718, "train_stats/max_log_achievement_defeat_skeleton": 0.02564102564102564, "train_stats/max_log_achievement_defeat_zombie": 0.1282051282051282, "train_stats/max_log_achievement_eat_cow": 0.02564102564102564, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.205128205128205, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_furnace": 0.7692307692307693, "train_stats/max_log_achievement_place_plant": 1.1025641025641026, "train_stats/max_log_achievement_place_stone": 3.9743589743589745, "train_stats/max_log_achievement_place_table": 1.8974358974358974, "train_stats/max_log_achievement_wake_up": 2.1538461538461537, "train_stats/mean_log_entropy": 0.36340148632343, "eval_stats/sum_log_reward": 6.4749999940395355, "eval_stats/max_log_achievement_collect_coal": 0.25, "eval_stats/max_log_achievement_collect_drink": 2.375, "eval_stats/max_log_achievement_collect_sapling": 0.875, "eval_stats/max_log_achievement_collect_stone": 6.125, "eval_stats/max_log_achievement_collect_wood": 4.625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.125, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.25, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.125, "eval_stats/max_log_achievement_place_plant": 0.625, "eval_stats/max_log_achievement_place_stone": 3.25, "eval_stats/max_log_achievement_place_table": 1.125, "eval_stats/max_log_achievement_wake_up": 1.375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 2.3693561161053367e-05, "report/cont_loss_std": 0.0007305177277885377, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 8.505609002895653e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.32103921007365e-05, "report/cont_pred": 0.9921654462814331, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 6.374616622924805, "report/dyn_loss_std": 8.870482444763184, "report/image_loss_mean": 2.926295757293701, "report/image_loss_std": 8.026066780090332, "report/model_loss_mean": 6.800971984863281, "report/model_loss_std": 12.313766479492188, "report/post_ent_mag": 56.74929428100586, "report/post_ent_max": 56.74929428100586, "report/post_ent_mean": 41.70607376098633, "report/post_ent_min": 20.296972274780273, "report/post_ent_std": 6.410627365112305, "report/prior_ent_mag": 75.21102905273438, "report/prior_ent_max": 75.21102905273438, "report/prior_ent_mean": 48.37456130981445, "report/prior_ent_min": 29.31963348388672, "report/prior_ent_std": 7.358675956726074, "report/rep_loss_mean": 6.374616622924805, "report/rep_loss_std": 8.870482444763184, "report/reward_avg": 0.03447265550494194, "report/reward_loss_mean": 0.04988321661949158, "report/reward_loss_std": 0.18537336587905884, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0008580684661865, "report/reward_neg_acc": 0.9949083924293518, "report/reward_neg_loss": 0.02182326279580593, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7059516310691833, "report/reward_pred": 0.034450553357601166, "report/reward_rate": 0.041015625, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.006628753151744604, "eval/cont_loss_std": 0.2083272486925125, "eval/cont_neg_acc": 0.800000011920929, "eval/cont_neg_loss": 1.350744605064392, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 3.3483269362477586e-05, "eval/cont_pred": 0.9961388111114502, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 20.34748077392578, "eval/dyn_loss_std": 12.855595588684082, "eval/image_loss_mean": 19.600631713867188, "eval/image_loss_std": 20.858062744140625, "eval/model_loss_mean": 31.980974197387695, "eval/model_loss_std": 26.071386337280273, "eval/post_ent_mag": 57.038883209228516, "eval/post_ent_max": 57.038883209228516, "eval/post_ent_mean": 39.4983024597168, "eval/post_ent_min": 19.4931640625, "eval/post_ent_std": 6.895077705383301, "eval/prior_ent_mag": 75.21102905273438, "eval/prior_ent_max": 75.21102905273438, "eval/prior_ent_mean": 52.86768341064453, "eval/prior_ent_min": 33.77596664428711, "eval/prior_ent_std": 6.856152057647705, "eval/rep_loss_mean": 20.34748077392578, "eval/rep_loss_std": 12.855595588684082, "eval/reward_avg": 0.03095703013241291, "eval/reward_loss_mean": 0.1652221977710724, "eval/reward_loss_std": 0.9853076338768005, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0006465911865234, "eval/reward_neg_acc": 0.991894543170929, "eval/reward_neg_loss": 0.08866007626056671, "eval/reward_pos_acc": 0.7567567229270935, "eval/reward_pos_loss": 2.2075681686401367, "eval/reward_pred": 0.026566646993160248, "eval/reward_rate": 0.0361328125, "replay/size": 382481.0, "replay/inserts": 7796.0, "replay/samples": 31184.0, "replay/insert_wait_avg": 1.5536658637886967e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.521684136740546e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 79200.0, "eval_replay/inserts": 1648.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1172977466027713e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.493661880493164e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2173640727997, "timer/env.step_count": 975.0, "timer/env.step_total": 85.72273898124695, "timer/env.step_frac": 0.08570410998684454, "timer/env.step_avg": 0.08792075792948405, "timer/env.step_min": 0.023151159286499023, "timer/env.step_max": 3.2005443572998047, "timer/replay._sample_count": 31184.0, "timer/replay._sample_total": 15.527048110961914, "timer/replay._sample_frac": 0.01552367382199515, "timer/replay._sample_avg": 0.0004979171405516263, "timer/replay._sample_min": 0.00035309791564941406, "timer/replay._sample_max": 0.025293350219726562, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1181.0, "timer/agent.policy_total": 18.515881776809692, "timer/agent.policy_frac": 0.018511857963967555, "timer/agent.policy_avg": 0.015678138676384158, "timer/agent.policy_min": 0.009167909622192383, "timer/agent.policy_max": 0.06332755088806152, "timer/dataset_train_count": 1949.0, "timer/dataset_train_total": 0.2828860282897949, "timer/dataset_train_frac": 0.000282824552393199, "timer/dataset_train_avg": 0.00014514419101580036, "timer/dataset_train_min": 8.726119995117188e-05, "timer/dataset_train_max": 0.0009350776672363281, "timer/agent.train_count": 1949.0, "timer/agent.train_total": 863.8904247283936, "timer/agent.train_frac": 0.8637026867947039, "timer/agent.train_avg": 0.44324803731574836, "timer/agent.train_min": 0.431427001953125, "timer/agent.train_max": 0.9742650985717773, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4705078601837158, "timer/agent.report_frac": 0.0004704056109042618, "timer/agent.report_avg": 0.2352539300918579, "timer/agent.report_min": 0.22873210906982422, "timer/agent.report_max": 0.2417757511138916, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7894973754882812e-05, "timer/dataset_eval_frac": 2.7888911707448132e-08, "timer/dataset_eval_avg": 2.7894973754882812e-05, "timer/dataset_eval_min": 2.7894973754882812e-05, "timer/dataset_eval_max": 2.7894973754882812e-05, "fps": 7.794193539462466}
{"step": 383208, "time": 49380.784621715546, "episode/length": 221.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 383400, "time": 49404.823837041855, "episode/length": 223.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.0}
{"step": 383424, "time": 49408.979093790054, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 383488, "time": 49417.80221605301, "episode/length": 232.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9785407725321889, "episode/intrinsic_return": 0.0}
{"step": 383544, "time": 49425.76179456711, "episode/length": 291.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9828767123287672, "episode/intrinsic_return": 0.0}
{"step": 383800, "time": 49456.82635951042, "episode/length": 271.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9852941176470589, "episode/intrinsic_return": 0.0}
{"step": 383872, "time": 49466.61580467224, "episode/length": 236.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9831223628691983, "episode/intrinsic_return": 0.0}
{"step": 384360, "time": 49524.69960165024, "episode/length": 222.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9730941704035875, "episode/intrinsic_return": 0.0}
{"step": 384672, "time": 49562.2956840992, "episode/length": 155.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 384720, "time": 49569.403455257416, "episode/length": 153.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 384912, "time": 49593.26767587662, "episode/length": 188.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9682539682539683, "episode/intrinsic_return": 0.0}
{"step": 384952, "time": 49599.52261209488, "episode/length": 175.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 384960, "time": 49602.07174563408, "episode/length": 144.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9724137931034482, "episode/intrinsic_return": 0.0}
{"step": 385320, "time": 49646.76149106026, "episode/length": 180.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9668508287292817, "episode/intrinsic_return": 0.0}
{"step": 385344, "time": 49650.96379208565, "episode/length": 266.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9737827715355806, "episode/intrinsic_return": 0.0}
{"step": 385776, "time": 49702.39407634735, "episode/length": 56.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 385976, "time": 49727.10499501228, "episode/length": 201.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9603960396039604, "episode/intrinsic_return": 0.0}
{"step": 386288, "time": 49764.91953611374, "episode/length": 166.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9640718562874252, "episode/intrinsic_return": 0.0}
{"step": 386432, "time": 49783.135771512985, "episode/length": 189.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 386440, "time": 49785.4882004261, "episode/length": 214.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 386464, "time": 49789.79673075676, "episode/length": 187.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 386856, "time": 49837.138070344925, "episode/length": 109.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9363636363636364, "episode/intrinsic_return": 0.0}
{"step": 387096, "time": 49866.41006088257, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 387272, "time": 49888.85203886032, "episode/length": 324.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9846153846153847, "episode/intrinsic_return": 0.0}
{"step": 387616, "time": 49930.57613348961, "episode/length": 283.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9859154929577465, "episode/intrinsic_return": 0.0}
{"step": 387624, "time": 49933.471821308136, "episode/length": 147.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9594594594594594, "episode/intrinsic_return": 0.0}
{"step": 387664, "time": 49940.12570357323, "episode/length": 171.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 388128, "time": 49995.3234372139, "episode/length": 207.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 388784, "time": 50072.90507006645, "episode/length": 210.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 389320, "time": 50136.593276023865, "episode/length": 360.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9944598337950139, "episode/intrinsic_return": 0.0}
{"step": 389504, "time": 50159.57667851448, "episode/length": 330.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9848942598187311, "episode/intrinsic_return": 0.0}
{"step": 389512, "time": 50162.055454969406, "episode/length": 172.0, "episode/score": 9.1000000461936, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 389536, "time": 50166.38437914848, "episode/length": 233.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9786324786324786, "episode/intrinsic_return": 0.0}
{"step": 389592, "time": 50174.4229080677, "episode/length": 289.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9862068965517241, "episode/intrinsic_return": 0.0}
{"step": 389656, "time": 50183.37150335312, "episode/length": 253.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9960629921259843, "episode/intrinsic_return": 0.0}
{"step": 390000, "time": 50243.39378118515, "eval_episode/length": 142.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.993006993006993}
{"step": 390000, "time": 50245.24200630188, "eval_episode/length": 151.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 390000, "time": 50247.00677084923, "eval_episode/length": 157.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9683544303797469}
{"step": 390000, "time": 50248.93591237068, "eval_episode/length": 167.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9702380952380952}
{"step": 390000, "time": 50250.53246760368, "eval_episode/length": 171.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9767441860465116}
{"step": 390000, "time": 50252.28040242195, "eval_episode/length": 178.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9664804469273743}
{"step": 390000, "time": 50254.2507379055, "eval_episode/length": 190.0, "eval_episode/score": 7.099999964237213, "eval_episode/reward_rate": 0.9790575916230366}
{"step": 390000, "time": 50261.76495099068, "eval_episode/length": 301.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9900662251655629}
{"step": 390056, "time": 50268.227595329285, "episode/length": 68.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9855072463768116, "episode/intrinsic_return": 0.0}
{"step": 390248, "time": 50291.960785627365, "episode/length": 182.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 390768, "time": 50353.62321305275, "episode/length": 393.0, "episode/score": 12.099999979138374, "episode/reward_rate": 0.9974619289340102, "episode/intrinsic_return": 0.0}
{"step": 390769, "time": 50356.096902132034, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.436865547375802, "train/action_min": 0.0, "train/action_std": 3.0442461661803417, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.045879702193614764, "train/actor_opt_grad_steps": 96330.0, "train/actor_opt_loss": -9.067229541601279, "train/adv_mag": 0.4810227436897082, "train/adv_max": 0.43939278614826693, "train/adv_mean": 0.0031700084689780337, "train/adv_min": -0.40228769718072355, "train/adv_std": 0.057539380800265535, "train/cont_avg": 0.9947966746794872, "train/cont_loss_mean": 0.00015659996052039998, "train/cont_loss_std": 0.004869133112331908, "train/cont_neg_acc": 0.9941819297961699, "train/cont_neg_loss": 0.018277169654952675, "train/cont_pos_acc": 0.9999899048071641, "train/cont_pos_loss": 8.123211104361507e-05, "train/cont_pred": 0.9948042661715777, "train/cont_rate": 0.9947966746794872, "train/dyn_loss_mean": 6.672872112958859, "train/dyn_loss_std": 8.860136327988062, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.168269322774349, "train/extr_critic_critic_opt_grad_steps": 96330.0, "train/extr_critic_critic_opt_loss": 17124.117853565705, "train/extr_critic_mag": 8.626079520201072, "train/extr_critic_max": 8.626079520201072, "train/extr_critic_mean": 2.0964747954637577, "train/extr_critic_min": -0.5711467614540687, "train/extr_critic_std": 2.03532099540417, "train/extr_return_normed_mag": 1.5113623068882869, "train/extr_return_normed_max": 1.5113623068882869, "train/extr_return_normed_mean": 0.354293516660348, "train/extr_return_normed_min": -0.10882054523397715, "train/extr_return_normed_std": 0.3241194732678242, "train/extr_return_rate": 0.7095219404269487, "train/extr_return_raw_mag": 9.530774351266714, "train/extr_return_raw_max": 9.530774351266714, "train/extr_return_raw_mean": 2.11676313265776, "train/extr_return_raw_min": -0.8511354599243556, "train/extr_return_raw_std": 2.077151358433259, "train/extr_reward_mag": 1.0336828488569993, "train/extr_reward_max": 1.0336828488569993, "train/extr_reward_mean": 0.04264356324879023, "train/extr_reward_min": -0.6712590021964832, "train/extr_reward_std": 0.20193729996681214, "train/image_loss_mean": 3.8102875012617843, "train/image_loss_std": 8.669392099135962, "train/model_loss_mean": 7.86353408862383, "train/model_loss_std": 12.785122260069235, "train/model_opt_grad_norm": 41.783096802540314, "train/model_opt_grad_steps": 96245.80512820513, "train/model_opt_loss": 11304.300135216346, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1442.3076923076924, "train/policy_entropy_mag": 2.4460185295496233, "train/policy_entropy_max": 2.4460185295496233, "train/policy_entropy_mean": 0.4031274439432682, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.5388267423862066, "train/policy_logprob_mag": 7.438384109888322, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.4036315705531683, "train/policy_logprob_min": -7.438384109888322, "train/policy_logprob_std": 1.0157802065213521, "train/policy_randomness_mag": 0.8633371995045589, "train/policy_randomness_max": 0.8633371995045589, "train/policy_randomness_mean": 0.14228629687657723, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.1901821955656394, "train/post_ent_mag": 58.995359900058844, "train/post_ent_max": 58.995359900058844, "train/post_ent_mean": 42.05266371506911, "train/post_ent_min": 19.735178800729607, "train/post_ent_std": 6.75245302151411, "train/prior_ent_mag": 75.63869014642178, "train/prior_ent_max": 75.63869014642178, "train/prior_ent_mean": 48.692341026893025, "train/prior_ent_min": 29.071108099130484, "train/prior_ent_std": 7.464680815965702, "train/rep_loss_mean": 6.672872112958859, "train/rep_loss_std": 8.860136327988062, "train/reward_avg": 0.03108824106076589, "train/reward_loss_mean": 0.04936673447298698, "train/reward_loss_std": 0.20964584251244864, "train/reward_max_data": 1.009230771431556, "train/reward_max_pred": 1.0085560603019519, "train/reward_neg_acc": 0.994730893159524, "train/reward_neg_loss": 0.023280316481414515, "train/reward_pos_acc": 0.9852832876718961, "train/reward_pos_loss": 0.7522870134084653, "train/reward_pred": 0.03069967412127134, "train/reward_rate": 0.03584234775641026, "train_stats/sum_log_reward": 8.205263275849191, "train_stats/max_log_achievement_collect_coal": 0.8157894736842105, "train_stats/max_log_achievement_collect_drink": 3.789473684210526, "train_stats/max_log_achievement_collect_sapling": 1.5526315789473684, "train_stats/max_log_achievement_collect_stone": 8.68421052631579, "train_stats/max_log_achievement_collect_wood": 5.842105263157895, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.15789473684210525, "train_stats/max_log_achievement_eat_cow": 0.07894736842105263, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.236842105263158, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_furnace": 0.9210526315789473, "train_stats/max_log_achievement_place_plant": 1.4473684210526316, "train_stats/max_log_achievement_place_stone": 3.6578947368421053, "train_stats/max_log_achievement_place_table": 1.9473684210526316, "train_stats/max_log_achievement_wake_up": 2.026315789473684, "train_stats/mean_log_entropy": 0.369007723896127, "eval_stats/sum_log_reward": 7.600000202655792, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 2.25, "eval_stats/max_log_achievement_collect_sapling": 0.875, "eval_stats/max_log_achievement_collect_stone": 8.5, "eval_stats/max_log_achievement_collect_wood": 6.0, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.25, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.25, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.25, "eval_stats/max_log_achievement_place_plant": 0.875, "eval_stats/max_log_achievement_place_stone": 6.0, "eval_stats/max_log_achievement_place_table": 1.75, "eval_stats/max_log_achievement_wake_up": 1.5, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 9.230115210812073e-06, "report/cont_loss_std": 0.00013196858344599605, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 3.288883817731403e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 9.067272003449034e-06, "report/cont_pred": 0.9931553602218628, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 6.127042293548584, "report/dyn_loss_std": 8.643362998962402, "report/image_loss_mean": 3.143585681915283, "report/image_loss_std": 6.666712760925293, "report/model_loss_mean": 6.864709854125977, "report/model_loss_std": 10.899984359741211, "report/post_ent_mag": 58.962127685546875, "report/post_ent_max": 58.962127685546875, "report/post_ent_mean": 41.82303237915039, "report/post_ent_min": 21.244356155395508, "report/post_ent_std": 6.612180709838867, "report/prior_ent_mag": 75.98084259033203, "report/prior_ent_max": 75.98084259033203, "report/prior_ent_mean": 47.9753532409668, "report/prior_ent_min": 30.24637222290039, "report/prior_ent_std": 8.02049732208252, "report/rep_loss_mean": 6.127042293548584, "report/rep_loss_std": 8.643362998962402, "report/reward_avg": 0.03466796875, "report/reward_loss_mean": 0.044889695942401886, "report/reward_loss_std": 0.1600051075220108, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0041747093200684, "report/reward_neg_acc": 0.9939025044441223, "report/reward_neg_loss": 0.019321035593748093, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6738787889480591, "report/reward_pred": 0.034769635647535324, "report/reward_rate": 0.0390625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 4.568642907543108e-06, "eval/cont_loss_std": 7.608565647387877e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0006398864788934588, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 2.077200178973726e-06, "eval/cont_pred": 0.9960942268371582, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 19.747283935546875, "eval/dyn_loss_std": 13.003544807434082, "eval/image_loss_mean": 20.06433868408203, "eval/image_loss_std": 24.470556259155273, "eval/model_loss_mean": 32.091339111328125, "eval/model_loss_std": 29.436748504638672, "eval/post_ent_mag": 54.524051666259766, "eval/post_ent_max": 54.524051666259766, "eval/post_ent_mean": 39.11986541748047, "eval/post_ent_min": 22.2532958984375, "eval/post_ent_std": 5.762537002563477, "eval/prior_ent_mag": 75.98084259033203, "eval/prior_ent_max": 75.98084259033203, "eval/prior_ent_mean": 51.44005584716797, "eval/prior_ent_min": 35.046852111816406, "eval/prior_ent_std": 6.248228549957275, "eval/rep_loss_mean": 19.747283935546875, "eval/rep_loss_std": 13.003544807434082, "eval/reward_avg": 0.04990234225988388, "eval/reward_loss_mean": 0.17862816154956818, "eval/reward_loss_std": 1.0512210130691528, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0060138702392578, "eval/reward_neg_acc": 0.9896907806396484, "eval/reward_neg_loss": 0.047230225056409836, "eval/reward_pos_acc": 0.7407407760620117, "eval/reward_pos_loss": 2.5389246940612793, "eval/reward_pred": 0.03952018916606903, "eval/reward_rate": 0.052734375, "replay/size": 390265.0, "replay/inserts": 7784.0, "replay/samples": 31136.0, "replay/insert_wait_avg": 1.5166104758753683e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.435801952985428e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 81616.0, "eval_replay/inserts": 2416.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1615011076264034e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.940696716308594e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1001.0467569828033, "timer/env.step_count": 973.0, "timer/env.step_total": 84.28395128250122, "timer/env.step_frac": 0.08419581872133182, "timer/env.step_avg": 0.08662276596351616, "timer/env.step_min": 0.023375511169433594, "timer/env.step_max": 2.010566234588623, "timer/replay._sample_count": 31136.0, "timer/replay._sample_total": 15.44417405128479, "timer/replay._sample_frac": 0.015428024658742389, "timer/replay._sample_avg": 0.0004960230617704519, "timer/replay._sample_min": 0.000370025634765625, "timer/replay._sample_max": 0.022475242614746094, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1275.0, "timer/agent.policy_total": 21.44444513320923, "timer/agent.policy_frac": 0.021422021482636517, "timer/agent.policy_avg": 0.016819172653497434, "timer/agent.policy_min": 0.009408235549926758, "timer/agent.policy_max": 0.1562204360961914, "timer/dataset_train_count": 1946.0, "timer/dataset_train_total": 0.32242798805236816, "timer/dataset_train_frac": 0.0003220908372194118, "timer/dataset_train_avg": 0.0001656875580947421, "timer/dataset_train_min": 8.940696716308594e-05, "timer/dataset_train_max": 0.03565573692321777, "timer/agent.train_count": 1946.0, "timer/agent.train_total": 861.6900074481964, "timer/agent.train_frac": 0.860788970582519, "timer/agent.train_avg": 0.44280062047697655, "timer/agent.train_min": 0.42539453506469727, "timer/agent.train_max": 0.9794526100158691, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4647524356842041, "timer/agent.report_frac": 0.00046426646152372274, "timer/agent.report_avg": 0.23237621784210205, "timer/agent.report_min": 0.2221388816833496, "timer/agent.report_max": 0.2426135540008545, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.5510787963867188e-05, "timer/dataset_eval_frac": 2.5484112291375646e-08, "timer/dataset_eval_avg": 2.5510787963867188e-05, "timer/dataset_eval_min": 2.5510787963867188e-05, "timer/dataset_eval_max": 2.5510787963867188e-05, "fps": 7.775751932256697}
{"step": 390808, "time": 50360.500479221344, "episode/length": 151.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 391032, "time": 50388.00096964836, "episode/length": 186.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 391504, "time": 50444.30551075935, "episode/length": 180.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 391592, "time": 50456.03422808647, "episode/length": 241.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9793388429752066, "episode/intrinsic_return": 0.0}
{"step": 391968, "time": 50501.38688206673, "episode/length": 306.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.996742671009772, "episode/intrinsic_return": 0.0}
{"step": 392208, "time": 50530.65323138237, "episode/length": 360.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9889196675900277, "episode/intrinsic_return": 0.0}
{"step": 392384, "time": 50552.35246372223, "episode/length": 196.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 392536, "time": 50571.543419122696, "episode/length": 187.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 392848, "time": 50609.39117002487, "episode/length": 167.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 392960, "time": 50624.06983423233, "episode/length": 273.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9963503649635036, "episode/intrinsic_return": 0.0}
{"step": 393496, "time": 50689.8951151371, "episode/length": 190.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9685863874345549, "episode/intrinsic_return": 0.0}
{"step": 393760, "time": 50721.94989442825, "episode/length": 438.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.979498861047836, "episode/intrinsic_return": 0.0}
{"step": 393872, "time": 50736.448951005936, "episode/length": 207.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9855769230769231, "episode/intrinsic_return": 0.0}
{"step": 394112, "time": 50766.12659192085, "episode/length": 157.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 394272, "time": 50786.89813089371, "episode/length": 163.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 394416, "time": 50805.54044175148, "episode/length": 234.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 394432, "time": 50809.39156675339, "episode/length": 255.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9765625, "episode/intrinsic_return": 0.0}
{"step": 394512, "time": 50820.61744475365, "episode/length": 364.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.989041095890411, "episode/intrinsic_return": 0.0}
{"step": 394776, "time": 50852.67670059204, "episode/length": 159.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 395104, "time": 50892.195687532425, "episode/length": 85.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9883720930232558, "episode/intrinsic_return": 0.0}
{"step": 395160, "time": 50900.14803862572, "episode/length": 160.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 395856, "time": 50982.169083833694, "episode/length": 167.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 395944, "time": 50993.81154131889, "episode/length": 188.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9894179894179894, "episode/intrinsic_return": 0.0}
{"step": 396112, "time": 51014.829525470734, "episode/length": 166.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 396120, "time": 51017.40206694603, "episode/length": 230.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9783549783549783, "episode/intrinsic_return": 0.0}
{"step": 396144, "time": 51021.58691430092, "episode/length": 129.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9923076923076923, "episode/intrinsic_return": 0.0}
{"step": 396176, "time": 51026.7055015564, "episode/length": 301.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9867549668874173, "episode/intrinsic_return": 0.0}
{"step": 396384, "time": 51052.2534737587, "episode/length": 283.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 397128, "time": 51139.910331487656, "episode/length": 158.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 397320, "time": 51163.674674749374, "episode/length": 269.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9888888888888889, "episode/intrinsic_return": 0.0}
{"step": 397384, "time": 51172.67927336693, "episode/length": 157.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 397400, "time": 51176.05628275871, "episode/length": 181.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 397584, "time": 51198.96488404274, "episode/length": 183.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 397656, "time": 51208.702134370804, "episode/length": 158.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 397768, "time": 51223.14171361923, "episode/length": 202.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 397904, "time": 51240.320974349976, "episode/length": 215.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 398528, "time": 51314.32207632065, "episode/length": 140.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 398712, "time": 51337.306000471115, "episode/length": 197.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 398853, "time": 51356.329005002975, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.431158084680538, "train/action_min": 0.0, "train/action_std": 3.0844425151843837, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04504422399003317, "train/actor_opt_grad_steps": 98315.0, "train/actor_opt_loss": -12.135993761075015, "train/adv_mag": 0.46698102768104854, "train/adv_max": 0.43685732781887054, "train/adv_mean": 0.0026950941080103085, "train/adv_min": -0.39395782321986583, "train/adv_std": 0.05680974679860738, "train/cont_avg": 0.9947932781559405, "train/cont_loss_mean": 0.00012174133145731953, "train/cont_loss_std": 0.0035322858989657825, "train/cont_neg_acc": 0.9942872866545573, "train/cont_neg_loss": 0.01725477520740737, "train/cont_pos_acc": 0.9999902463785493, "train/cont_pos_loss": 4.65872518145181e-05, "train/cont_pred": 0.9947895404725972, "train/cont_rate": 0.9947932781559405, "train/dyn_loss_mean": 6.675574696890198, "train/dyn_loss_std": 8.871138570332292, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1415047498032598, "train/extr_critic_critic_opt_grad_steps": 98315.0, "train/extr_critic_critic_opt_loss": 17089.41284904858, "train/extr_critic_mag": 8.695637329970255, "train/extr_critic_max": 8.695637329970255, "train/extr_critic_mean": 2.1459262099596534, "train/extr_critic_min": -0.5600517687231007, "train/extr_critic_std": 2.036823276836093, "train/extr_return_normed_mag": 1.5016546426433148, "train/extr_return_normed_max": 1.5016546426433148, "train/extr_return_normed_mean": 0.359272227871536, "train/extr_return_normed_min": -0.1055971537301741, "train/extr_return_normed_std": 0.3211094356409394, "train/extr_return_rate": 0.7199924957044054, "train/extr_return_raw_mag": 9.54094925493297, "train/extr_return_raw_max": 9.54094925493297, "train/extr_return_raw_mean": 2.1633314655558897, "train/extr_return_raw_min": -0.8388646717118745, "train/extr_return_raw_std": 2.0735992293546697, "train/extr_reward_mag": 1.0389893538881056, "train/extr_reward_max": 1.0389893538881056, "train/extr_reward_mean": 0.04284532486212136, "train/extr_reward_min": -0.6589665035210034, "train/extr_reward_std": 0.20228852811131146, "train/image_loss_mean": 3.7229409170622874, "train/image_loss_std": 8.6908859380401, "train/model_loss_mean": 7.777954682265178, "train/model_loss_std": 12.842047275883136, "train/model_opt_grad_norm": 41.08032068875757, "train/model_opt_grad_steps": 98229.23762376238, "train/model_opt_loss": 12084.685397006497, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1553.2178217821781, "train/policy_entropy_mag": 2.458018654643899, "train/policy_entropy_max": 2.458018654643899, "train/policy_entropy_mean": 0.402456136328159, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.5445087830914129, "train/policy_logprob_mag": 7.438384122187548, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.4021796879201832, "train/policy_logprob_min": -7.438384122187548, "train/policy_logprob_std": 1.0145450514732022, "train/policy_randomness_mag": 0.8675727168522259, "train/policy_randomness_max": 0.8675727168522259, "train/policy_randomness_mean": 0.14204935401235477, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.19218770672779273, "train/post_ent_mag": 59.0041824567436, "train/post_ent_max": 59.0041824567436, "train/post_ent_mean": 42.01733851668858, "train/post_ent_min": 19.584951953132553, "train/post_ent_std": 6.721375899739785, "train/prior_ent_mag": 75.67054359511573, "train/prior_ent_max": 75.67054359511573, "train/prior_ent_mean": 48.65972314966787, "train/prior_ent_min": 29.02392847231119, "train/prior_ent_std": 7.45715860329052, "train/rep_loss_mean": 6.675574696890198, "train/rep_loss_std": 8.871138570332292, "train/reward_avg": 0.03177985746763868, "train/reward_loss_mean": 0.04954720888803206, "train/reward_loss_std": 0.21025579710408013, "train/reward_max_data": 1.0143564390664053, "train/reward_max_pred": 1.013444155749708, "train/reward_neg_acc": 0.9947639048689663, "train/reward_neg_loss": 0.02292846791483093, "train/reward_pos_acc": 0.9831386822285039, "train/reward_pos_loss": 0.7551248764047528, "train/reward_pred": 0.03132855010652306, "train/reward_rate": 0.03644221844059406, "train_stats/sum_log_reward": 8.547368589200472, "train_stats/max_log_achievement_collect_coal": 0.7105263157894737, "train_stats/max_log_achievement_collect_drink": 3.1052631578947367, "train_stats/max_log_achievement_collect_sapling": 1.6578947368421053, "train_stats/max_log_achievement_collect_stone": 10.921052631578947, "train_stats/max_log_achievement_collect_wood": 6.0, "train_stats/max_log_achievement_defeat_skeleton": 0.05263157894736842, "train_stats/max_log_achievement_defeat_zombie": 0.34210526315789475, "train_stats/max_log_achievement_eat_cow": 0.02631578947368421, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.236842105263158, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_furnace": 1.105263157894737, "train_stats/max_log_achievement_place_plant": 1.5263157894736843, "train_stats/max_log_achievement_place_stone": 4.342105263157895, "train_stats/max_log_achievement_place_table": 2.1315789473684212, "train_stats/max_log_achievement_wake_up": 1.9473684210526316, "train_stats/mean_log_entropy": 0.3490506340014307, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 2.34497019846458e-05, "report/cont_loss_std": 0.0005502511048689485, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0007530543953180313, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.130590655724518e-05, "report/cont_pred": 0.997051477432251, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 6.254012584686279, "report/dyn_loss_std": 9.194766998291016, "report/image_loss_mean": 4.049005508422852, "report/image_loss_std": 9.373068809509277, "report/model_loss_mean": 7.84643030166626, "report/model_loss_std": 13.691892623901367, "report/post_ent_mag": 58.62870788574219, "report/post_ent_max": 58.62870788574219, "report/post_ent_mean": 42.55335998535156, "report/post_ent_min": 19.388652801513672, "report/post_ent_std": 6.733974933624268, "report/prior_ent_mag": 75.77305603027344, "report/prior_ent_max": 75.77305603027344, "report/prior_ent_mean": 48.779842376708984, "report/prior_ent_min": 28.342880249023438, "report/prior_ent_std": 7.2431745529174805, "report/rep_loss_mean": 6.254012584686279, "report/rep_loss_std": 9.194766998291016, "report/reward_avg": 0.02626953274011612, "report/reward_loss_mean": 0.04499384015798569, "report/reward_loss_std": 0.18127772212028503, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0042123794555664, "report/reward_neg_acc": 0.9979858994483948, "report/reward_neg_loss": 0.023523053154349327, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7327516078948975, "report/reward_pred": 0.02585366927087307, "report/reward_rate": 0.0302734375, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.0030190597753971815, "eval/cont_loss_std": 0.09487499296665192, "eval/cont_neg_acc": 0.75, "eval/cont_neg_loss": 0.7615373730659485, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 4.4478187191998586e-05, "eval/cont_pred": 0.99698805809021, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 22.746990203857422, "eval/dyn_loss_std": 13.576212882995605, "eval/image_loss_mean": 22.961868286132812, "eval/image_loss_std": 25.43536376953125, "eval/model_loss_mean": 36.80739974975586, "eval/model_loss_std": 30.449451446533203, "eval/post_ent_mag": 56.025596618652344, "eval/post_ent_max": 56.025596618652344, "eval/post_ent_mean": 38.77265930175781, "eval/post_ent_min": 18.610157012939453, "eval/post_ent_std": 6.783045291900635, "eval/prior_ent_mag": 75.77305603027344, "eval/prior_ent_max": 75.77305603027344, "eval/prior_ent_mean": 53.56938934326172, "eval/prior_ent_min": 36.14038848876953, "eval/prior_ent_std": 5.845773696899414, "eval/rep_loss_mean": 22.746990203857422, "eval/rep_loss_std": 13.576212882995605, "eval/reward_avg": 0.04453124850988388, "eval/reward_loss_mean": 0.19431807100772858, "eval/reward_loss_std": 0.9329560399055481, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0262629985809326, "eval/reward_neg_acc": 0.9856410026550293, "eval/reward_neg_loss": 0.09354662150144577, "eval/reward_pos_acc": 0.7551020383834839, "eval/reward_pos_loss": 2.1994638442993164, "eval/reward_pred": 0.041098661720752716, "eval/reward_rate": 0.0478515625, "replay/size": 398349.0, "replay/inserts": 8084.0, "replay/samples": 32336.0, "replay/insert_wait_avg": 1.5140936434829311e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.295891649943658e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 81616.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 8.493661880493164e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2212889194489, "timer/env.step_count": 1010.0, "timer/env.step_total": 85.99286913871765, "timer/env.step_frac": 0.0859738440796604, "timer/env.step_avg": 0.08514145459278975, "timer/env.step_min": 0.02338266372680664, "timer/env.step_max": 2.09478497505188, "timer/replay._sample_count": 32336.0, "timer/replay._sample_total": 15.788265705108643, "timer/replay._sample_frac": 0.01578477270981194, "timer/replay._sample_avg": 0.0004882566088912866, "timer/replay._sample_min": 0.00034427642822265625, "timer/replay._sample_max": 0.012734651565551758, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1010.0, "timer/agent.policy_total": 16.04004168510437, "timer/agent.policy_frac": 0.01603649298689955, "timer/agent.policy_avg": 0.015881229391192447, "timer/agent.policy_min": 0.009459733963012695, "timer/agent.policy_max": 0.07213640213012695, "timer/dataset_train_count": 2021.0, "timer/dataset_train_total": 0.30025744438171387, "timer/dataset_train_frac": 0.0003001910154362797, "timer/dataset_train_avg": 0.0001485687503125749, "timer/dataset_train_min": 8.916854858398438e-05, "timer/dataset_train_max": 0.00107574462890625, "timer/agent.train_count": 2021.0, "timer/agent.train_total": 895.1193346977234, "timer/agent.train_frac": 0.8949212985305798, "timer/agent.train_avg": 0.442909121572352, "timer/agent.train_min": 0.431640625, "timer/agent.train_max": 0.95379638671875, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.476731538772583, "timer/agent.report_frac": 0.00047662606670530064, "timer/agent.report_avg": 0.2383657693862915, "timer/agent.report_min": 0.23060321807861328, "timer/agent.report_max": 0.24612832069396973, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7418136596679688e-05, "timer/dataset_eval_frac": 2.741207060919472e-08, "timer/dataset_eval_avg": 2.7418136596679688e-05, "timer/dataset_eval_min": 2.7418136596679688e-05, "timer/dataset_eval_max": 2.7418136596679688e-05, "fps": 8.082105055227343}
{"step": 398880, "time": 51359.36232852936, "episode/length": 152.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9607843137254902, "episode/intrinsic_return": 0.0}
{"step": 399080, "time": 51384.29353618622, "episode/length": 186.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 399192, "time": 51399.41272640228, "episode/length": 160.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 399208, "time": 51402.919187784195, "episode/length": 179.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 399416, "time": 51428.413450956345, "episode/length": 253.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9803149606299213, "episode/intrinsic_return": 0.0}
{"step": 400064, "time": 51505.35671329498, "episode/length": 168.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 400088, "time": 51523.851098775864, "eval_episode/length": 52.0, "eval_episode/score": 5.1000000312924385, "eval_episode/reward_rate": 0.9811320754716981}
{"step": 400088, "time": 51525.515719652176, "eval_episode/length": 55.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.9821428571428571}
{"step": 400088, "time": 51527.98141860962, "eval_episode/length": 79.0, "eval_episode/score": 7.100000023841858, "eval_episode/reward_rate": 0.9875}
{"step": 400088, "time": 51532.798622608185, "eval_episode/length": 158.0, "eval_episode/score": 7.099999971687794, "eval_episode/reward_rate": 0.9937106918238994}
{"step": 400088, "time": 51534.35981631279, "eval_episode/length": 162.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9693251533742331}
{"step": 400088, "time": 51539.951838970184, "eval_episode/length": 181.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.967032967032967}
{"step": 400088, "time": 51541.62259435654, "eval_episode/length": 210.0, "eval_episode/score": 10.099999994039536, "eval_episode/reward_rate": 0.995260663507109}
{"step": 400088, "time": 51545.23199391365, "eval_episode/length": 156.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9745222929936306}
{"step": 400144, "time": 51551.797811985016, "episode/length": 352.0, "episode/score": 10.100000016391277, "episode/reward_rate": 0.9971671388101983, "episode/intrinsic_return": 0.0}
{"step": 400336, "time": 51575.4478533268, "episode/length": 140.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9716312056737588, "episode/intrinsic_return": 0.0}
{"step": 400440, "time": 51589.00021767616, "episode/length": 155.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 400496, "time": 51597.01028871536, "episode/length": 201.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9603960396039604, "episode/intrinsic_return": 0.0}
{"step": 400552, "time": 51604.917214393616, "episode/length": 141.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9647887323943662, "episode/intrinsic_return": 0.0}
{"step": 400648, "time": 51617.78529500961, "episode/length": 195.0, "episode/score": 11.100000031292439, "episode/reward_rate": 0.9591836734693877, "episode/intrinsic_return": 0.0}
{"step": 400984, "time": 51658.71440243721, "episode/length": 306.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.996742671009772, "episode/intrinsic_return": 0.0}
{"step": 401224, "time": 51688.26424360275, "episode/length": 144.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9517241379310345, "episode/intrinsic_return": 0.0}
{"step": 401560, "time": 51730.03471636772, "episode/length": 176.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 401608, "time": 51737.12808704376, "episode/length": 145.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.0}
{"step": 401968, "time": 51780.3729493618, "episode/length": 183.0, "episode/score": 10.099999964237213, "episode/reward_rate": 0.967391304347826, "episode/intrinsic_return": 0.0}
{"step": 402048, "time": 51791.20673894882, "episode/length": 213.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9719626168224299, "episode/intrinsic_return": 0.0}
{"step": 402232, "time": 51814.06584191322, "episode/length": 155.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 402472, "time": 51843.37390398979, "episode/length": 113.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9912280701754386, "episode/intrinsic_return": 0.0}
{"step": 402496, "time": 51847.667182683945, "episode/length": 230.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 402568, "time": 51857.58175468445, "episode/length": 251.0, "episode/score": 11.100000031292439, "episode/reward_rate": 0.996031746031746, "episode/intrinsic_return": 0.0}
{"step": 402696, "time": 51873.85858821869, "episode/length": 135.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9632352941176471, "episode/intrinsic_return": 0.0}
{"step": 402704, "time": 51876.28220963478, "episode/length": 184.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 403304, "time": 51947.469631671906, "episode/length": 156.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9617834394904459, "episode/intrinsic_return": 0.0}
{"step": 403808, "time": 52007.74215388298, "episode/length": 137.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9565217391304348, "episode/intrinsic_return": 0.0}
{"step": 403840, "time": 52013.04200768471, "episode/length": 167.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 404104, "time": 52045.07229089737, "episode/length": 233.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9829059829059829, "episode/intrinsic_return": 0.0}
{"step": 404120, "time": 52048.39671611786, "episode/length": 205.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9660194174757282, "episode/intrinsic_return": 0.0}
{"step": 404168, "time": 52055.56182193756, "episode/length": 274.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9963636363636363, "episode/intrinsic_return": 0.0}
{"step": 404544, "time": 52100.8290617466, "episode/length": 230.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9826839826839827, "episode/intrinsic_return": 0.0}
{"step": 405352, "time": 52196.080716609955, "episode/length": 188.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 405360, "time": 52198.484437942505, "episode/length": 154.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 405440, "time": 52209.32634353638, "episode/length": 358.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9944289693593314, "episode/intrinsic_return": 0.0}
{"step": 405800, "time": 52252.65698337555, "episode/length": 203.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 405896, "time": 52265.42911052704, "episode/length": 323.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9969135802469136, "episode/intrinsic_return": 0.0}
{"step": 406008, "time": 52280.493243932724, "episode/length": 182.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 406384, "time": 52325.48344993591, "episode/length": 284.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 406584, "time": 52350.07652950287, "episode/length": 346.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9971181556195965, "episode/intrinsic_return": 0.0}
{"step": 406621, "time": 52356.73748087883, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.402100238603415, "train/action_min": 0.0, "train/action_std": 3.079163100301605, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.044771142207931, "train/actor_opt_grad_steps": 100295.0, "train/actor_opt_loss": -11.18196411143758, "train/adv_mag": 0.44538090508623224, "train/adv_max": 0.4196422244470144, "train/adv_mean": 0.002741499311342363, "train/adv_min": -0.3764233693634112, "train/adv_std": 0.05593618295472307, "train/cont_avg": 0.9946742106958762, "train/cont_loss_mean": 0.00013302761122057507, "train/cont_loss_std": 0.004089052691948925, "train/cont_neg_acc": 0.994968091089701, "train/cont_neg_loss": 0.024544906171658835, "train/cont_pos_acc": 0.9999999778786886, "train/cont_pos_loss": 1.850793791463636e-05, "train/cont_pred": 0.9946865150608968, "train/cont_rate": 0.9946742106958762, "train/dyn_loss_mean": 6.799080961758328, "train/dyn_loss_std": 8.957553000794244, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1697930048421485, "train/extr_critic_critic_opt_grad_steps": 100295.0, "train/extr_critic_critic_opt_loss": 17069.79708642075, "train/extr_critic_mag": 8.703871977697943, "train/extr_critic_max": 8.703871977697943, "train/extr_critic_mean": 2.058285073521211, "train/extr_critic_min": -0.5664036390707665, "train/extr_critic_std": 2.037239153975064, "train/extr_return_normed_mag": 1.5013327303620958, "train/extr_return_normed_max": 1.5013327303620958, "train/extr_return_normed_mean": 0.3494745990664689, "train/extr_return_normed_min": -0.10477763959734711, "train/extr_return_normed_std": 0.3224801185358431, "train/extr_return_rate": 0.6943510750827101, "train/extr_return_raw_mag": 9.488167895484217, "train/extr_return_raw_max": 9.488167895484217, "train/extr_return_raw_mean": 2.075949665811873, "train/extr_return_raw_min": -0.846572364421235, "train/extr_return_raw_std": 2.0747415460262104, "train/extr_reward_mag": 1.0477730392180766, "train/extr_reward_max": 1.0477730392180766, "train/extr_reward_mean": 0.04197787806468526, "train/extr_reward_min": -0.6598022764491052, "train/extr_reward_std": 0.20076741393386704, "train/image_loss_mean": 3.9255478984301853, "train/image_loss_std": 8.790635315413327, "train/model_loss_mean": 8.055560569173283, "train/model_loss_std": 12.965724596043223, "train/model_opt_grad_norm": 42.608891516616666, "train/model_opt_grad_steps": 100207.59793814433, "train/model_opt_loss": 11665.522840991463, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1449.7422680412371, "train/policy_entropy_mag": 2.465808224432247, "train/policy_entropy_max": 2.465808224432247, "train/policy_entropy_mean": 0.4163369227623202, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.5626262778166643, "train/policy_logprob_mag": 7.43838411999732, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.4171286652383116, "train/policy_logprob_min": -7.43838411999732, "train/policy_logprob_std": 1.0290799386722524, "train/policy_randomness_mag": 0.8703220938284373, "train/policy_randomness_max": 0.8703220938284373, "train/policy_randomness_mean": 0.14694866211604826, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.19858238592590252, "train/post_ent_mag": 59.28189043654609, "train/post_ent_max": 59.28189043654609, "train/post_ent_mean": 42.16840606374839, "train/post_ent_min": 19.53105908325038, "train/post_ent_std": 6.814335675583672, "train/prior_ent_mag": 75.66296378853394, "train/prior_ent_max": 75.66296378853394, "train/prior_ent_mean": 48.954520373000314, "train/prior_ent_min": 28.94077650050527, "train/prior_ent_std": 7.529719424001949, "train/rep_loss_mean": 6.799080961758328, "train/rep_loss_std": 8.957553000794244, "train/reward_avg": 0.03173324720665198, "train/reward_loss_mean": 0.05043106714321166, "train/reward_loss_std": 0.2152936821131362, "train/reward_max_data": 1.0159793852530803, "train/reward_max_pred": 1.0145358301929592, "train/reward_neg_acc": 0.9945442231045556, "train/reward_neg_loss": 0.023707097641086763, "train/reward_pos_acc": 0.9840659655861019, "train/reward_pos_loss": 0.754548345337209, "train/reward_pred": 0.03126454942850108, "train/reward_rate": 0.0365808231314433, "train_stats/sum_log_reward": 8.79230785369873, "train_stats/max_log_achievement_collect_coal": 0.46153846153846156, "train_stats/max_log_achievement_collect_drink": 4.128205128205129, "train_stats/max_log_achievement_collect_sapling": 1.3846153846153846, "train_stats/max_log_achievement_collect_stone": 9.846153846153847, "train_stats/max_log_achievement_collect_wood": 6.256410256410256, "train_stats/max_log_achievement_defeat_skeleton": 0.05128205128205128, "train_stats/max_log_achievement_defeat_zombie": 0.28205128205128205, "train_stats/max_log_achievement_eat_cow": 0.02564102564102564, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.4102564102564104, "train_stats/max_log_achievement_make_wood_sword": 0.02564102564102564, "train_stats/max_log_achievement_place_furnace": 0.9743589743589743, "train_stats/max_log_achievement_place_plant": 1.2820512820512822, "train_stats/max_log_achievement_place_stone": 4.17948717948718, "train_stats/max_log_achievement_place_table": 1.9743589743589745, "train_stats/max_log_achievement_wake_up": 1.5897435897435896, "train_stats/mean_log_entropy": 0.36111607383459043, "eval_stats/sum_log_reward": 7.100000023841858, "eval_stats/max_log_achievement_collect_coal": 0.25, "eval_stats/max_log_achievement_collect_drink": 2.75, "eval_stats/max_log_achievement_collect_sapling": 1.375, "eval_stats/max_log_achievement_collect_stone": 4.75, "eval_stats/max_log_achievement_collect_wood": 4.25, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.25, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.375, "eval_stats/max_log_achievement_place_plant": 1.0, "eval_stats/max_log_achievement_place_stone": 2.875, "eval_stats/max_log_achievement_place_table": 1.25, "eval_stats/max_log_achievement_wake_up": 1.0, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 1.3839331586495973e-05, "report/cont_loss_std": 0.0003431674849707633, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0004332109820097685, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 1.0952800039376598e-05, "report/cont_pred": 0.9931561946868896, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 6.411665439605713, "report/dyn_loss_std": 8.936568260192871, "report/image_loss_mean": 4.108023643493652, "report/image_loss_std": 8.429542541503906, "report/model_loss_mean": 8.005132675170898, "report/model_loss_std": 12.633024215698242, "report/post_ent_mag": 58.44612503051758, "report/post_ent_max": 58.44612503051758, "report/post_ent_mean": 42.778709411621094, "report/post_ent_min": 18.309249877929688, "report/post_ent_std": 7.226926326751709, "report/prior_ent_mag": 76.07614135742188, "report/prior_ent_max": 76.07614135742188, "report/prior_ent_mean": 49.104156494140625, "report/prior_ent_min": 29.933425903320312, "report/prior_ent_std": 7.09023904800415, "report/rep_loss_mean": 6.411665439605713, "report/rep_loss_std": 8.936568260192871, "report/reward_avg": 0.03603515774011612, "report/reward_loss_mean": 0.050096750259399414, "report/reward_loss_std": 0.19932563602924347, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.0996692180633545, "report/reward_neg_acc": 0.9979633688926697, "report/reward_neg_loss": 0.0234201792627573, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.673820436000824, "report/reward_pred": 0.03640322759747505, "report/reward_rate": 0.041015625, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 3.0019575660844566e-06, "eval/cont_loss_std": 6.352137279463932e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0012122035259380937, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 6.356139579111186e-07, "eval/cont_pred": 0.9980486631393433, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 20.329517364501953, "eval/dyn_loss_std": 12.94538402557373, "eval/image_loss_mean": 22.488248825073242, "eval/image_loss_std": 26.240537643432617, "eval/model_loss_mean": 34.82405090332031, "eval/model_loss_std": 31.255281448364258, "eval/post_ent_mag": 62.77970886230469, "eval/post_ent_max": 62.77970886230469, "eval/post_ent_mean": 39.99799728393555, "eval/post_ent_min": 19.100656509399414, "eval/post_ent_std": 7.193912982940674, "eval/prior_ent_mag": 76.07614135742188, "eval/prior_ent_max": 76.07614135742188, "eval/prior_ent_mean": 53.0966796875, "eval/prior_ent_min": 36.76885223388672, "eval/prior_ent_std": 6.115509033203125, "eval/rep_loss_mean": 20.329517364501953, "eval/rep_loss_std": 12.94538402557373, "eval/reward_avg": 0.03750000149011612, "eval/reward_loss_mean": 0.13808628916740417, "eval/reward_loss_std": 0.8540871143341064, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0024099349975586, "eval/reward_neg_acc": 0.9908443689346313, "eval/reward_neg_loss": 0.033585965633392334, "eval/reward_pos_acc": 0.6829267740249634, "eval/reward_pos_loss": 2.643545389175415, "eval/reward_pred": 0.029222367331385612, "eval/reward_rate": 0.0400390625, "replay/size": 406117.0, "replay/inserts": 7768.0, "replay/samples": 31072.0, "replay/insert_wait_avg": 1.5141175777855667e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.20105136828123e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 84144.0, "eval_replay/inserts": 2528.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1140975771071036e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.897615432739258e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3923733234406, "timer/env.step_count": 971.0, "timer/env.step_total": 86.42093348503113, "timer/env.step_frac": 0.08638703751601878, "timer/env.step_avg": 0.08900199123072207, "timer/env.step_min": 0.02353358268737793, "timer/env.step_max": 2.077711582183838, "timer/replay._sample_count": 31072.0, "timer/replay._sample_total": 14.956799030303955, "timer/replay._sample_frac": 0.014950932683158528, "timer/replay._sample_avg": 0.00048135939206693984, "timer/replay._sample_min": 0.0003886222839355469, "timer/replay._sample_max": 0.010679244995117188, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1287.0, "timer/agent.policy_total": 20.313312292099, "timer/agent.policy_frac": 0.02030534501639131, "timer/agent.policy_avg": 0.015783459434420357, "timer/agent.policy_min": 0.009362936019897461, "timer/agent.policy_max": 0.05972123146057129, "timer/dataset_train_count": 1942.0, "timer/dataset_train_total": 0.4307882785797119, "timer/dataset_train_frac": 0.00043061931504792886, "timer/dataset_train_avg": 0.00022182712594217915, "timer/dataset_train_min": 8.630752563476562e-05, "timer/dataset_train_max": 0.08392548561096191, "timer/agent.train_count": 1942.0, "timer/agent.train_total": 859.7240896224976, "timer/agent.train_frac": 0.8593868891326873, "timer/agent.train_avg": 0.442700355109422, "timer/agent.train_min": 0.41913533210754395, "timer/agent.train_max": 0.9686567783355713, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47397518157958984, "timer/agent.report_frac": 0.0004737892793054583, "timer/agent.report_avg": 0.23698759078979492, "timer/agent.report_min": 0.23069405555725098, "timer/agent.report_max": 0.24328112602233887, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.6226043701171875e-05, "timer/dataset_eval_frac": 2.621575733733891e-08, "timer/dataset_eval_avg": 2.6226043701171875e-05, "timer/dataset_eval_min": 2.6226043701171875e-05, "timer/dataset_eval_max": 2.6226043701171875e-05, "fps": 7.7648475485828605}
{"step": 406800, "time": 52377.41348838806, "episode/length": 179.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 406952, "time": 52396.65824484825, "episode/length": 188.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 407032, "time": 52407.34551310539, "episode/length": 55.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 407056, "time": 52411.63476061821, "episode/length": 212.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 407264, "time": 52437.1231508255, "episode/length": 182.0, "episode/score": 10.099999964237213, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 407520, "time": 52468.175809144974, "episode/length": 202.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 407520, "time": 52468.185144901276, "episode/length": 188.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9682539682539683, "episode/intrinsic_return": 0.0}
{"step": 407720, "time": 52494.63049983978, "episode/length": 166.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 407976, "time": 52525.757408857346, "episode/length": 56.0, "episode/score": 5.100000016391277, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 408296, "time": 52564.346381902695, "episode/length": 186.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 408368, "time": 52574.34493088722, "episode/length": 166.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 408392, "time": 52578.633407115936, "episode/length": 166.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9640718562874252, "episode/intrinsic_return": 0.0}
{"step": 408424, "time": 52583.90809035301, "episode/length": 183.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 408896, "time": 52640.1302921772, "episode/length": 171.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9651162790697675, "episode/intrinsic_return": 0.0}
{"step": 409520, "time": 52713.84470319748, "episode/length": 192.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 409552, "time": 52719.05742573738, "episode/length": 147.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 409592, "time": 52725.32482671738, "episode/length": 149.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 409872, "time": 52760.73276805878, "episode/length": 196.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 409928, "time": 52768.64680933952, "episode/length": 275.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 410072, "time": 52801.19077825546, "eval_episode/length": 50.0, "eval_episode/score": 3.0999999940395355, "eval_episode/reward_rate": 0.9803921568627451}
{"step": 410072, "time": 52806.57782101631, "eval_episode/length": 148.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9664429530201343}
{"step": 410072, "time": 52808.42421936989, "eval_episode/length": 153.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9935064935064936}
{"step": 410072, "time": 52810.139300107956, "eval_episode/length": 154.0, "eval_episode/score": 9.099999964237213, "eval_episode/reward_rate": 0.9741935483870968}
{"step": 410072, "time": 52811.88547062874, "eval_episode/length": 162.0, "eval_episode/score": 10.099999971687794, "eval_episode/reward_rate": 0.9938650306748467}
{"step": 410072, "time": 52813.54223179817, "eval_episode/length": 167.0, "eval_episode/score": 8.100000023841858, "eval_episode/reward_rate": 0.9940476190476191}
{"step": 410072, "time": 52815.14632153511, "eval_episode/length": 170.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9649122807017544}
{"step": 410072, "time": 52818.12662053108, "eval_episode/length": 157.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9746835443037974}
{"step": 410536, "time": 52871.80695939064, "episode/length": 204.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 410752, "time": 52898.409423828125, "episode/length": 144.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 410776, "time": 52902.79795527458, "episode/length": 438.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9931662870159453, "episode/intrinsic_return": 0.0}
{"step": 410920, "time": 52920.95362830162, "episode/length": 47.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.8958333333333334, "episode/intrinsic_return": 0.0}
{"step": 410952, "time": 52926.21382141113, "episode/length": 178.0, "episode/score": 8.099999964237213, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 411056, "time": 52940.37882208824, "episode/length": 187.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9680851063829787, "episode/intrinsic_return": 0.0}
{"step": 411376, "time": 52978.84804344177, "episode/length": 52.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 411384, "time": 52981.27260875702, "episode/length": 40.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 411528, "time": 52999.670753240585, "episode/length": 206.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 411624, "time": 53012.70227909088, "episode/length": 399.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9975, "episode/intrinsic_return": 0.0}
{"step": 412040, "time": 53062.39536142349, "episode/length": 263.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 412040, "time": 53062.402742385864, "episode/length": 157.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 412400, "time": 53107.24630141258, "episode/length": 205.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 412656, "time": 53138.37744474411, "episode/length": 140.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 412824, "time": 53159.36318588257, "episode/length": 97.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9897959183673469, "episode/intrinsic_return": 0.0}
{"step": 413104, "time": 53193.98075437546, "episode/length": 184.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 413336, "time": 53222.784829854965, "episode/length": 244.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 413400, "time": 53231.78258442879, "episode/length": 169.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 413592, "time": 53255.36893796921, "episode/length": 60.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 413592, "time": 53255.37918949127, "episode/length": 333.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 413840, "time": 53287.28179645538, "episode/length": 179.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9555555555555556, "episode/intrinsic_return": 0.0}
{"step": 414024, "time": 53310.20431423187, "episode/length": 170.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9532163742690059, "episode/intrinsic_return": 0.0}
{"step": 414144, "time": 53325.52993893623, "episode/length": 344.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.991304347826087, "episode/intrinsic_return": 0.0}
{"step": 414272, "time": 53341.89367246628, "episode/length": 180.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 414377, "time": 53356.973410367966, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.453385815177996, "train/action_min": 0.0, "train/action_std": 3.1598865543444132, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.044446120480286705, "train/actor_opt_grad_steps": 102235.0, "train/actor_opt_loss": -10.875387423393345, "train/adv_mag": 0.45922630472281545, "train/adv_max": 0.4308946997541742, "train/adv_mean": 0.002686105254893452, "train/adv_min": -0.3819375545093694, "train/adv_std": 0.0560868380725691, "train/cont_avg": 0.9946490415592784, "train/cont_loss_mean": 0.00017364947546969305, "train/cont_loss_std": 0.005300411378700644, "train/cont_neg_acc": 0.9957109964573322, "train/cont_neg_loss": 0.019671105607242733, "train/cont_pos_acc": 0.9999796914071152, "train/cont_pos_loss": 7.111724670703135e-05, "train/cont_pred": 0.99464720764111, "train/cont_rate": 0.9946490415592784, "train/dyn_loss_mean": 6.608968447164162, "train/dyn_loss_std": 8.906254065405463, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1690670279497952, "train/extr_critic_critic_opt_grad_steps": 102235.0, "train/extr_critic_critic_opt_loss": 16997.908439714884, "train/extr_critic_mag": 8.791759559788655, "train/extr_critic_max": 8.791759559788655, "train/extr_critic_mean": 2.1491730925963095, "train/extr_critic_min": -0.5826178438884696, "train/extr_critic_std": 2.0773033591889845, "train/extr_return_normed_mag": 1.4990336262073714, "train/extr_return_normed_max": 1.4990336262073714, "train/extr_return_normed_mean": 0.3584232165180531, "train/extr_return_normed_min": -0.10799783772606518, "train/extr_return_normed_std": 0.32400631689533743, "train/extr_return_rate": 0.7093797369101613, "train/extr_return_raw_mag": 9.60691061708116, "train/extr_return_raw_max": 9.60691061708116, "train/extr_return_raw_mean": 2.1667088626586284, "train/extr_return_raw_min": -0.8760687472279539, "train/extr_return_raw_std": 2.1137659273196743, "train/extr_reward_mag": 1.0399449916230035, "train/extr_reward_max": 1.0399449916230035, "train/extr_reward_mean": 0.043866619093286006, "train/extr_reward_min": -0.6862188307280394, "train/extr_reward_std": 0.20475947227060182, "train/image_loss_mean": 3.6885635379663446, "train/image_loss_std": 8.53933177535067, "train/model_loss_mean": 7.704312024657259, "train/model_loss_std": 12.70299662265581, "train/model_opt_grad_norm": 41.42244545454832, "train/model_opt_grad_steps": 102146.22164948453, "train/model_opt_loss": 13156.940480025773, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1713.9175257731958, "train/policy_entropy_mag": 2.490074278153095, "train/policy_entropy_max": 2.490074278153095, "train/policy_entropy_mean": 0.4347929303179082, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.5921023480363727, "train/policy_logprob_mag": 7.4383841003339315, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.4343562929593411, "train/policy_logprob_min": -7.4383841003339315, "train/policy_logprob_std": 1.041917975723129, "train/policy_randomness_mag": 0.878886946697825, "train/policy_randomness_max": 0.878886946697825, "train/policy_randomness_mean": 0.1534628237876081, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.20898614547301814, "train/post_ent_mag": 59.41911768175892, "train/post_ent_max": 59.41911768175892, "train/post_ent_mean": 42.455286537249066, "train/post_ent_min": 19.733375141301106, "train/post_ent_std": 6.843824919966078, "train/prior_ent_mag": 75.68198827369926, "train/prior_ent_max": 75.68198827369926, "train/prior_ent_mean": 49.02265489715891, "train/prior_ent_min": 29.458508638991525, "train/prior_ent_std": 7.427350798833001, "train/rep_loss_mean": 6.608968447164162, "train/rep_loss_std": 8.906254065405463, "train/reward_avg": 0.0325472171168736, "train/reward_loss_mean": 0.050193777951152665, "train/reward_loss_std": 0.21159266549901865, "train/reward_max_data": 1.0139175290913927, "train/reward_max_pred": 1.0136871737303192, "train/reward_neg_acc": 0.994761454690363, "train/reward_neg_loss": 0.023180835508290178, "train/reward_pos_acc": 0.9856824072980389, "train/reward_pos_loss": 0.7490693324619961, "train/reward_pred": 0.03224863761498295, "train/reward_rate": 0.037315761920103094, "train_stats/sum_log_reward": 7.51860481639241, "train_stats/max_log_achievement_collect_coal": 0.6046511627906976, "train_stats/max_log_achievement_collect_drink": 3.697674418604651, "train_stats/max_log_achievement_collect_sapling": 1.302325581395349, "train_stats/max_log_achievement_collect_stone": 7.8604651162790695, "train_stats/max_log_achievement_collect_wood": 6.511627906976744, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.4186046511627907, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.1627906976744187, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_furnace": 0.8372093023255814, "train_stats/max_log_achievement_place_plant": 1.2093023255813953, "train_stats/max_log_achievement_place_stone": 2.744186046511628, "train_stats/max_log_achievement_place_table": 2.2093023255813953, "train_stats/max_log_achievement_wake_up": 1.7674418604651163, "train_stats/mean_log_entropy": 0.33685820948245915, "eval_stats/sum_log_reward": 7.1000001430511475, "eval_stats/max_log_achievement_collect_coal": 0.25, "eval_stats/max_log_achievement_collect_drink": 1.875, "eval_stats/max_log_achievement_collect_sapling": 1.25, "eval_stats/max_log_achievement_collect_stone": 4.875, "eval_stats/max_log_achievement_collect_wood": 4.625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.125, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.75, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.375, "eval_stats/max_log_achievement_place_plant": 1.0, "eval_stats/max_log_achievement_place_stone": 2.25, "eval_stats/max_log_achievement_place_table": 1.5, "eval_stats/max_log_achievement_wake_up": 1.75, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 2.1404885046649724e-06, "report/cont_loss_std": 5.009914457332343e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0004260543209966272, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 6.044055567144824e-08, "report/cont_pred": 0.9951192140579224, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 6.0088090896606445, "report/dyn_loss_std": 8.684769630432129, "report/image_loss_mean": 2.4078328609466553, "report/image_loss_std": 6.190274715423584, "report/model_loss_mean": 6.046797752380371, "report/model_loss_std": 10.346142768859863, "report/post_ent_mag": 57.7360954284668, "report/post_ent_max": 57.7360954284668, "report/post_ent_mean": 41.78154754638672, "report/post_ent_min": 19.50177001953125, "report/post_ent_std": 6.845121383666992, "report/prior_ent_mag": 75.77719116210938, "report/prior_ent_max": 75.77719116210938, "report/prior_ent_mean": 48.0323486328125, "report/prior_ent_min": 28.434009552001953, "report/prior_ent_std": 7.496762752532959, "report/rep_loss_mean": 6.0088090896606445, "report/rep_loss_std": 8.684769630432129, "report/reward_avg": 0.02548828162252903, "report/reward_loss_mean": 0.033677417784929276, "report/reward_loss_std": 0.16564497351646423, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0002501010894775, "report/reward_neg_acc": 0.9989939332008362, "report/reward_neg_loss": 0.011958491057157516, "report/reward_pos_acc": 0.9666666984558105, "report/reward_pos_loss": 0.7532978653907776, "report/reward_pred": 0.02507311850786209, "report/reward_rate": 0.029296875, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 7.589190772705479e-06, "eval/cont_loss_std": 0.00020063509873580188, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0019308007322251797, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 4.7185210405586986e-08, "eval/cont_pred": 0.9961012601852417, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 19.37636947631836, "eval/dyn_loss_std": 12.497257232666016, "eval/image_loss_mean": 19.171390533447266, "eval/image_loss_std": 23.456445693969727, "eval/model_loss_mean": 30.91861915588379, "eval/model_loss_std": 28.059917449951172, "eval/post_ent_mag": 58.11703109741211, "eval/post_ent_max": 58.11703109741211, "eval/post_ent_mean": 39.795921325683594, "eval/post_ent_min": 18.628437042236328, "eval/post_ent_std": 6.626794815063477, "eval/prior_ent_mag": 75.77719116210938, "eval/prior_ent_max": 75.77719116210938, "eval/prior_ent_mean": 52.50527572631836, "eval/prior_ent_min": 33.648292541503906, "eval/prior_ent_std": 6.7277936935424805, "eval/rep_loss_mean": 19.37636947631836, "eval/rep_loss_std": 12.497257232666016, "eval/reward_avg": 0.02998046763241291, "eval/reward_loss_mean": 0.12139856070280075, "eval/reward_loss_std": 0.8232141733169556, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.0005764961242676, "eval/reward_neg_acc": 0.9959595203399658, "eval/reward_neg_loss": 0.033195555210113525, "eval/reward_pos_acc": 0.7058823704719543, "eval/reward_pos_loss": 2.689662456512451, "eval/reward_pred": 0.02079281583428383, "eval/reward_rate": 0.033203125, "replay/size": 413873.0, "replay/inserts": 7756.0, "replay/samples": 31024.0, "replay/insert_wait_avg": 1.5060393818879386e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.234940275572944e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 85816.0, "eval_replay/inserts": 1672.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1501700113834948e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2113902568817, "timer/env.step_count": 970.0, "timer/env.step_total": 92.27591133117676, "timer/env.step_frac": 0.09225640922513167, "timer/env.step_avg": 0.09512980549605851, "timer/env.step_min": 0.0231778621673584, "timer/env.step_max": 3.333524227142334, "timer/replay._sample_count": 31024.0, "timer/replay._sample_total": 14.903411388397217, "timer/replay._sample_frac": 0.014900261618266127, "timer/replay._sample_avg": 0.0004803832964284817, "timer/replay._sample_min": 0.00038623809814453125, "timer/replay._sample_max": 0.009520292282104492, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1179.0, "timer/agent.policy_total": 18.450586318969727, "timer/agent.policy_frac": 0.018446686869093853, "timer/agent.policy_avg": 0.015649352263757188, "timer/agent.policy_min": 0.009227991104125977, "timer/agent.policy_max": 0.06868362426757812, "timer/dataset_train_count": 1939.0, "timer/dataset_train_total": 0.34400463104248047, "timer/dataset_train_frac": 0.0003439319271840432, "timer/dataset_train_avg": 0.00017741342498322872, "timer/dataset_train_min": 8.630752563476562e-05, "timer/dataset_train_max": 0.03870725631713867, "timer/agent.train_count": 1939.0, "timer/agent.train_total": 858.1463487148285, "timer/agent.train_frac": 0.8579649832766181, "timer/agent.train_avg": 0.4425716084140425, "timer/agent.train_min": 0.4313976764678955, "timer/agent.train_max": 0.9907739162445068, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4737987518310547, "timer/agent.report_frac": 0.0004736986165588158, "timer/agent.report_avg": 0.23689937591552734, "timer/agent.report_min": 0.23051977157592773, "timer/agent.report_max": 0.24327898025512695, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.47955322265625e-05, "timer/dataset_eval_frac": 2.4790291800410638e-08, "timer/dataset_eval_avg": 2.47955322265625e-05, "timer/dataset_eval_min": 2.47955322265625e-05, "timer/dataset_eval_max": 2.47955322265625e-05, "fps": 7.754242001889282}
{"step": 414840, "time": 53410.62376689911, "episode/length": 179.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 415080, "time": 53439.95268511772, "episode/length": 185.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 415296, "time": 53466.64213514328, "episode/length": 181.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 415448, "time": 53485.739629268646, "episode/length": 263.0, "episode/score": 10.100000016391277, "episode/reward_rate": 0.9962121212121212, "episode/intrinsic_return": 0.0}
{"step": 415560, "time": 53500.28973698616, "episode/length": 176.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 415640, "time": 53511.16134309769, "episode/length": 170.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 415888, "time": 53542.24908065796, "episode/length": 232.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9785407725321889, "episode/intrinsic_return": 0.0}
{"step": 416080, "time": 53566.06019592285, "episode/length": 154.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9548387096774194, "episode/intrinsic_return": 0.0}
{"step": 416232, "time": 53585.77154016495, "episode/length": 42.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 416408, "time": 53607.76555252075, "episode/length": 165.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 416784, "time": 53653.21979427338, "episode/length": 398.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9974937343358395, "episode/intrinsic_return": 0.0}
{"step": 416952, "time": 53674.759889125824, "episode/length": 187.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 417064, "time": 53689.22567152977, "episode/length": 177.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 417456, "time": 53736.42994761467, "episode/length": 269.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9962962962962963, "episode/intrinsic_return": 0.0}
{"step": 417576, "time": 53751.77142453194, "episode/length": 186.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 417616, "time": 53757.92651128769, "episode/length": 150.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 417728, "time": 53772.39596700668, "episode/length": 117.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9491525423728814, "episode/intrinsic_return": 0.0}
{"step": 418144, "time": 53823.15732336044, "episode/length": 148.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9798657718120806, "episode/intrinsic_return": 0.0}
{"step": 418360, "time": 53849.74092459679, "episode/length": 265.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9962406015037594, "episode/intrinsic_return": 0.0}
{"step": 418520, "time": 53869.88751745224, "episode/length": 369.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9891891891891892, "episode/intrinsic_return": 0.0}
{"step": 418560, "time": 53876.02718448639, "episode/length": 186.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9679144385026738, "episode/intrinsic_return": 0.0}
{"step": 418736, "time": 53897.94967985153, "episode/length": 139.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 419000, "time": 53929.96054840088, "episode/length": 192.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 419000, "time": 53929.9692773819, "episode/length": 177.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 419528, "time": 53994.11020207405, "episode/length": 224.0, "episode/score": 9.099999964237213, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 419856, "time": 54033.65854096413, "episode/length": 166.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 419864, "time": 54036.58747148514, "episode/length": 162.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 419872, "time": 54039.366161584854, "episode/length": 215.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 419936, "time": 54048.94847822189, "episode/length": 196.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9695431472081218, "episode/intrinsic_return": 0.0}
{"step": 420056, "time": 54079.409757852554, "eval_episode/length": 55.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9821428571428571}
{"step": 420056, "time": 54085.20311331749, "eval_episode/length": 164.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9696969696969697}
{"step": 420056, "time": 54086.91671323776, "eval_episode/length": 170.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9766081871345029}
{"step": 420056, "time": 54089.03118491173, "eval_episode/length": 184.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9783783783783784}
{"step": 420056, "time": 54090.71039390564, "eval_episode/length": 133.0, "eval_episode/score": 8.100000023841858, "eval_episode/reward_rate": 0.9925373134328358}
{"step": 420056, "time": 54092.3726978302, "eval_episode/length": 195.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9744897959183674}
{"step": 420056, "time": 54094.662264585495, "eval_episode/length": 216.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9723502304147466}
{"step": 420056, "time": 54097.70059633255, "eval_episode/length": 256.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.980544747081712}
{"step": 420464, "time": 54145.33253455162, "episode/length": 182.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 420560, "time": 54158.001935720444, "episode/length": 194.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 421104, "time": 54223.02605295181, "episode/length": 196.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 421280, "time": 54244.88347411156, "episode/length": 317.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9968553459119497, "episode/intrinsic_return": 0.0}
{"step": 421392, "time": 54259.34015059471, "episode/length": 191.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 421480, "time": 54270.97552919388, "episode/length": 192.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 421656, "time": 54292.89260458946, "episode/length": 223.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 421672, "time": 54296.26322603226, "episode/length": 138.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9640287769784173, "episode/intrinsic_return": 0.0}
{"step": 422177, "time": 54357.0709195137, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.428005120693109, "train/action_min": 0.0, "train/action_std": 3.0709484381553454, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04440872384569584, "train/actor_opt_grad_steps": 104180.0, "train/actor_opt_loss": -11.505978725735957, "train/adv_mag": 0.462844440417412, "train/adv_max": 0.4335231675551488, "train/adv_mean": 0.0027505144678751747, "train/adv_min": -0.3940013940517719, "train/adv_std": 0.05593428567816049, "train/cont_avg": 0.9946965144230769, "train/cont_loss_mean": 8.90220573789217e-05, "train/cont_loss_std": 0.00272892099118018, "train/cont_neg_acc": 0.9972649574279785, "train/cont_neg_loss": 0.011501590269369607, "train/cont_pos_acc": 0.9999899369019728, "train/cont_pos_loss": 4.1665473347562415e-05, "train/cont_pred": 0.9946922925802377, "train/cont_rate": 0.9946965144230769, "train/dyn_loss_mean": 6.694305620438013, "train/dyn_loss_std": 8.910978975051489, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.109185483211126, "train/extr_critic_critic_opt_grad_steps": 104180.0, "train/extr_critic_critic_opt_loss": 16853.98171073718, "train/extr_critic_mag": 8.651820217034755, "train/extr_critic_max": 8.651820217034755, "train/extr_critic_mean": 2.035212222123757, "train/extr_critic_min": -0.5807442714006473, "train/extr_critic_std": 2.0417293138993093, "train/extr_return_normed_mag": 1.4993771785344834, "train/extr_return_normed_max": 1.4993771785344834, "train/extr_return_normed_mean": 0.34646683556911273, "train/extr_return_normed_min": -0.11467765344259066, "train/extr_return_normed_std": 0.3240736878835238, "train/extr_return_rate": 0.6912971131312542, "train/extr_return_raw_mag": 9.434042930603027, "train/extr_return_raw_max": 9.434042930603027, "train/extr_return_raw_mean": 2.052800567333515, "train/extr_return_raw_min": -0.8993520048948435, "train/extr_return_raw_std": 2.074861559501061, "train/extr_reward_mag": 1.047402219283275, "train/extr_reward_max": 1.047402219283275, "train/extr_reward_mean": 0.042950509431270455, "train/extr_reward_min": -0.6919583186125144, "train/extr_reward_std": 0.2026049879881052, "train/image_loss_mean": 3.779452013969421, "train/image_loss_std": 8.532656997289413, "train/model_loss_mean": 7.846063491625664, "train/model_loss_std": 12.700722904694386, "train/model_opt_grad_norm": 43.0996369922284, "train/model_opt_grad_steps": 104089.33846153846, "train/model_opt_loss": 12826.935188802083, "train/model_opt_model_opt_grad_overflow": 0.005128205128205128, "train/model_opt_model_opt_grad_scale": 1634.6153846153845, "train/policy_entropy_mag": 2.4781826398311515, "train/policy_entropy_max": 2.4781826398311515, "train/policy_entropy_mean": 0.41489344590749494, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.5657795493419354, "train/policy_logprob_mag": 7.438384114778959, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.4151862797064659, "train/policy_logprob_min": -7.438384114778959, "train/policy_logprob_std": 1.0287044402880547, "train/policy_randomness_mag": 0.8746897199215034, "train/policy_randomness_max": 0.8746897199215034, "train/policy_randomness_mean": 0.14643917970168285, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.19969535309534805, "train/post_ent_mag": 59.374350112523786, "train/post_ent_max": 59.374350112523786, "train/post_ent_mean": 42.38563701923077, "train/post_ent_min": 19.637522888183593, "train/post_ent_std": 6.809818289830134, "train/prior_ent_mag": 75.76177806365185, "train/prior_ent_max": 75.76177806365185, "train/prior_ent_mean": 49.08668707823142, "train/prior_ent_min": 29.350740246895032, "train/prior_ent_std": 7.42480036906707, "train/rep_loss_mean": 6.694305620438013, "train/rep_loss_std": 8.910978975051489, "train/reward_avg": 0.031989182570041755, "train/reward_loss_mean": 0.04993913889122315, "train/reward_loss_std": 0.2121144997767913, "train/reward_max_data": 1.0184615428631123, "train/reward_max_pred": 1.0161737631528804, "train/reward_neg_acc": 0.9947638832605802, "train/reward_neg_loss": 0.023107482970525058, "train/reward_pos_acc": 0.9839714942834317, "train/reward_pos_loss": 0.7554685977789072, "train/reward_pred": 0.03154986685094161, "train/reward_rate": 0.03673878205128205, "train_stats/sum_log_reward": 8.451351513733735, "train_stats/max_log_achievement_collect_coal": 0.6486486486486487, "train_stats/max_log_achievement_collect_drink": 3.3783783783783785, "train_stats/max_log_achievement_collect_sapling": 1.7027027027027026, "train_stats/max_log_achievement_collect_stone": 9.783783783783784, "train_stats/max_log_achievement_collect_wood": 5.513513513513513, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.24324324324324326, "train_stats/max_log_achievement_eat_cow": 0.16216216216216217, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.2162162162162162, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_furnace": 1.0, "train_stats/max_log_achievement_place_plant": 1.5675675675675675, "train_stats/max_log_achievement_place_stone": 3.5945945945945947, "train_stats/max_log_achievement_place_table": 1.7837837837837838, "train_stats/max_log_achievement_wake_up": 2.135135135135135, "train_stats/mean_log_entropy": 0.37148665858281626, "eval_stats/sum_log_reward": 7.3500001430511475, "eval_stats/max_log_achievement_collect_coal": 0.5, "eval_stats/max_log_achievement_collect_drink": 3.625, "eval_stats/max_log_achievement_collect_sapling": 1.125, "eval_stats/max_log_achievement_collect_stone": 7.0, "eval_stats/max_log_achievement_collect_wood": 4.875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.125, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.875, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.375, "eval_stats/max_log_achievement_place_plant": 1.125, "eval_stats/max_log_achievement_place_stone": 3.0, "eval_stats/max_log_achievement_place_table": 1.625, "eval_stats/max_log_achievement_wake_up": 1.75, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 6.20740138401743e-06, "report/cont_loss_std": 5.40011387784034e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 7.964922406245023e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 5.629119186778553e-06, "report/cont_pred": 0.9921825528144836, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 5.862765789031982, "report/dyn_loss_std": 8.369488716125488, "report/image_loss_mean": 3.2214608192443848, "report/image_loss_std": 6.06980037689209, "report/model_loss_mean": 6.794175148010254, "report/model_loss_std": 9.99362564086914, "report/post_ent_mag": 60.43166732788086, "report/post_ent_max": 60.43166732788086, "report/post_ent_mean": 42.61281204223633, "report/post_ent_min": 22.105716705322266, "report/post_ent_std": 7.348603248596191, "report/prior_ent_mag": 75.41438293457031, "report/prior_ent_max": 75.41438293457031, "report/prior_ent_mean": 48.6099853515625, "report/prior_ent_min": 28.06247329711914, "report/prior_ent_std": 7.7790632247924805, "report/rep_loss_mean": 5.862765789031982, "report/rep_loss_std": 8.369488716125488, "report/reward_avg": 0.02802734449505806, "report/reward_loss_mean": 0.055047955363988876, "report/reward_loss_std": 0.19597157835960388, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.0574443340301514, "report/reward_neg_acc": 0.991894543170929, "report/reward_neg_loss": 0.02958478219807148, "report/reward_pos_acc": 0.9729729294776917, "report/reward_pos_loss": 0.7342951893806458, "report/reward_pred": 0.02704833447933197, "report/reward_rate": 0.0361328125, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 2.834004226315301e-05, "eval/cont_loss_std": 0.0006831932114437222, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0007017046445980668, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.636149656609632e-05, "eval/cont_pred": 0.9970463514328003, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 20.75855255126953, "eval/dyn_loss_std": 13.215225219726562, "eval/image_loss_mean": 22.48424530029297, "eval/image_loss_std": 28.365100860595703, "eval/model_loss_mean": 35.097068786621094, "eval/model_loss_std": 33.58667755126953, "eval/post_ent_mag": 57.10667419433594, "eval/post_ent_max": 57.10667419433594, "eval/post_ent_mean": 39.04853057861328, "eval/post_ent_min": 20.382549285888672, "eval/post_ent_std": 6.516695499420166, "eval/prior_ent_mag": 75.41438293457031, "eval/prior_ent_max": 75.41438293457031, "eval/prior_ent_mean": 52.69610595703125, "eval/prior_ent_min": 36.36183166503906, "eval/prior_ent_std": 6.740618705749512, "eval/rep_loss_mean": 20.75855255126953, "eval/rep_loss_std": 13.215225219726562, "eval/reward_avg": 0.04091797024011612, "eval/reward_loss_mean": 0.15766268968582153, "eval/reward_loss_std": 0.8775822520256042, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0030016899108887, "eval/reward_neg_acc": 0.9887754917144775, "eval/reward_neg_loss": 0.08096472173929214, "eval/reward_pos_acc": 0.8409091234207153, "eval/reward_pos_loss": 1.8659354448318481, "eval/reward_pred": 0.03641325235366821, "eval/reward_rate": 0.04296875, "replay/size": 421673.0, "replay/inserts": 7800.0, "replay/samples": 31200.0, "replay/insert_wait_avg": 1.500844955444336e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.195867905249962e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 87872.0, "eval_replay/inserts": 2056.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0922493173918372e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.046627044677734e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0924410820007, "timer/env.step_count": 975.0, "timer/env.step_total": 84.77112650871277, "timer/env.step_frac": 0.08476329089838817, "timer/env.step_avg": 0.0869447451371413, "timer/env.step_min": 0.023372173309326172, "timer/env.step_max": 2.961824893951416, "timer/replay._sample_count": 31200.0, "timer/replay._sample_total": 15.019644021987915, "timer/replay._sample_frac": 0.015018255718179562, "timer/replay._sample_avg": 0.000481398846858587, "timer/replay._sample_min": 0.0003688335418701172, "timer/replay._sample_max": 0.008307933807373047, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1232.0, "timer/agent.policy_total": 19.27030897140503, "timer/agent.policy_frac": 0.019268527767849607, "timer/agent.policy_avg": 0.015641484554711874, "timer/agent.policy_min": 0.009184837341308594, "timer/agent.policy_max": 0.084381103515625, "timer/dataset_train_count": 1950.0, "timer/dataset_train_total": 0.28982067108154297, "timer/dataset_train_frac": 0.00028979388222151323, "timer/dataset_train_avg": 0.00014862598517002203, "timer/dataset_train_min": 9.107589721679688e-05, "timer/dataset_train_max": 0.0004892349243164062, "timer/agent.train_count": 1950.0, "timer/agent.train_total": 864.2142720222473, "timer/agent.train_frac": 0.864134390504195, "timer/agent.train_avg": 0.443186806165255, "timer/agent.train_min": 0.43175458908081055, "timer/agent.train_max": 0.9895710945129395, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47413015365600586, "timer/agent.report_frac": 0.0004740863286028281, "timer/agent.report_avg": 0.23706507682800293, "timer/agent.report_min": 0.2291252613067627, "timer/agent.report_max": 0.24500489234924316, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.765655517578125e-05, "timer/dataset_eval_frac": 2.7653998810209586e-08, "timer/dataset_eval_avg": 2.765655517578125e-05, "timer/dataset_eval_min": 2.765655517578125e-05, "timer/dataset_eval_max": 2.765655517578125e-05, "fps": 7.799175041340681}
{"step": 422608, "time": 54406.95729994774, "episode/length": 187.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 422840, "time": 54435.61250638962, "episode/length": 180.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 422896, "time": 54443.553533792496, "episode/length": 201.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 423072, "time": 54465.5562813282, "episode/length": 174.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 423120, "time": 54472.690630197525, "episode/length": 405.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9901477832512315, "episode/intrinsic_return": 0.0}
{"step": 423232, "time": 54487.16842675209, "episode/length": 345.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 423392, "time": 54507.230328798294, "episode/length": 216.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 423856, "time": 54562.590079307556, "episode/length": 155.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 423936, "time": 54573.20067071915, "episode/length": 306.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.996742671009772, "episode/intrinsic_return": 0.0}
{"step": 424136, "time": 54597.81318426132, "episode/length": 154.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 424424, "time": 54632.854155540466, "episode/length": 168.0, "episode/score": 11.100000016391277, "episode/reward_rate": 0.9822485207100592, "episode/intrinsic_return": 0.0}
{"step": 424544, "time": 54648.270411491394, "episode/length": 177.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 424816, "time": 54681.21016216278, "episode/length": 197.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 425136, "time": 54719.936851263046, "episode/length": 159.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 425536, "time": 54767.79173731804, "episode/length": 199.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 425808, "time": 54800.864832401276, "episode/length": 172.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 425864, "time": 54808.89438009262, "episode/length": 164.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 426160, "time": 54845.76585316658, "episode/length": 414.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9783132530120482, "episode/intrinsic_return": 0.0}
{"step": 426352, "time": 54869.62218642235, "episode/length": 276.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9819494584837545, "episode/intrinsic_return": 0.0}
{"step": 426832, "time": 54927.029917001724, "episode/length": 429.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9976744186046511, "episode/intrinsic_return": 0.0}
{"step": 426984, "time": 54946.49716949463, "episode/length": 270.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.974169741697417, "episode/intrinsic_return": 0.0}
{"step": 427136, "time": 54965.651636600494, "episode/length": 249.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 427312, "time": 54987.58980035782, "episode/length": 187.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 427416, "time": 55001.36241340637, "episode/length": 156.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9617834394904459, "episode/intrinsic_return": 0.0}
{"step": 427608, "time": 55025.06919670105, "episode/length": 217.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 427672, "time": 55033.99749112129, "episode/length": 44.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9111111111111111, "episode/intrinsic_return": 0.0}
{"step": 427800, "time": 55050.24380731583, "episode/length": 180.0, "episode/score": 10.100000016391277, "episode/reward_rate": 0.9834254143646409, "episode/intrinsic_return": 0.0}
{"step": 428368, "time": 55117.68371462822, "episode/length": 153.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 428800, "time": 55169.310067892075, "episode/length": 226.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9691629955947136, "episode/intrinsic_return": 0.0}
{"step": 428992, "time": 55193.19864606857, "episode/length": 269.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 428992, "time": 55193.21020460129, "episode/length": 431.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 429256, "time": 55227.10056877136, "episode/length": 205.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 430016, "time": 55316.77156162262, "episode/length": 205.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 430040, "time": 55340.08882546425, "eval_episode/length": 164.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9696969696969697}
{"step": 430040, "time": 55341.90975499153, "eval_episode/length": 173.0, "eval_episode/score": 9.100000023841858, "eval_episode/reward_rate": 0.9942528735632183}
{"step": 430040, "time": 55343.441877126694, "eval_episode/length": 176.0, "eval_episode/score": 10.099999964237213, "eval_episode/reward_rate": 0.9717514124293786}
{"step": 430040, "time": 55345.04909539223, "eval_episode/length": 179.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 430040, "time": 55346.61789560318, "eval_episode/length": 180.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9723756906077348}
{"step": 430040, "time": 55352.26115369797, "eval_episode/length": 240.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.995850622406639}
{"step": 430040, "time": 55354.09415245056, "eval_episode/length": 248.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9678714859437751}
{"step": 430040, "time": 55355.73943257332, "eval_episode/length": 252.0, "eval_episode/score": 10.100000023841858, "eval_episode/reward_rate": 0.9960474308300395}
{"step": 430045, "time": 55357.18566894531, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.524467971724302, "train/action_min": 0.0, "train/action_std": 3.2079141539365508, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04485313426041361, "train/actor_opt_grad_steps": 106140.0, "train/actor_opt_loss": -11.32901459136212, "train/adv_mag": 0.46973874181660297, "train/adv_max": 0.43932265043258667, "train/adv_mean": 0.0028674385035157898, "train/adv_min": -0.3876585034549539, "train/adv_std": 0.05585585035345881, "train/cont_avg": 0.9947106995558376, "train/cont_loss_mean": 9.21669180323178e-05, "train/cont_loss_std": 0.0025399635279464393, "train/cont_neg_acc": 0.9971799212058788, "train/cont_neg_loss": 0.006109845685400822, "train/cont_pos_acc": 0.99997503866399, "train/cont_pos_loss": 5.2227664789347384e-05, "train/cont_pred": 0.9946938680513256, "train/cont_rate": 0.9947106995558376, "train/dyn_loss_mean": 6.768503455341165, "train/dyn_loss_std": 8.894737943174876, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1279622867022674, "train/extr_critic_critic_opt_grad_steps": 106140.0, "train/extr_critic_critic_opt_loss": 16965.74896890863, "train/extr_critic_mag": 8.762358137798794, "train/extr_critic_max": 8.762358137798794, "train/extr_critic_mean": 2.0918760620397965, "train/extr_critic_min": -0.5671997493898808, "train/extr_critic_std": 2.0699959188548442, "train/extr_return_normed_mag": 1.503101423912242, "train/extr_return_normed_max": 1.503101423912242, "train/extr_return_normed_mean": 0.35061955353632795, "train/extr_return_normed_min": -0.10707632550582062, "train/extr_return_normed_std": 0.3240105822909302, "train/extr_return_rate": 0.6976837170910715, "train/extr_return_raw_mag": 9.61198355582765, "train/extr_return_raw_max": 9.61198355582765, "train/extr_return_raw_mean": 2.110502459071009, "train/extr_return_raw_min": -0.8690169297801662, "train/extr_return_raw_std": 2.1099031062295595, "train/extr_reward_mag": 1.0527643806438156, "train/extr_reward_max": 1.0527643806438156, "train/extr_reward_mean": 0.043010050364708535, "train/extr_reward_min": -0.6751005746386378, "train/extr_reward_std": 0.2031553172066732, "train/image_loss_mean": 3.789809444834133, "train/image_loss_std": 8.681839364434257, "train/model_loss_mean": 7.901784393388002, "train/model_loss_std": 12.8346162979978, "train/model_opt_grad_norm": 40.10622186225078, "train/model_opt_grad_steps": 106047.23350253807, "train/model_opt_loss": 10231.061302843433, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1294.4162436548224, "train/policy_entropy_mag": 2.4575803316184106, "train/policy_entropy_max": 2.4575803316184106, "train/policy_entropy_mean": 0.4271443852313279, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.5731336180933841, "train/policy_logprob_mag": 7.438384121444625, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.42742326129511526, "train/policy_logprob_min": -7.438384121444625, "train/policy_logprob_std": 1.0359742974266788, "train/policy_randomness_mag": 0.8674180071971138, "train/policy_randomness_max": 0.8674180071971138, "train/policy_randomness_mean": 0.15076322327864353, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.20229101767243468, "train/post_ent_mag": 59.19117401820149, "train/post_ent_max": 59.19117401820149, "train/post_ent_mean": 42.44037959297297, "train/post_ent_min": 19.599732432873722, "train/post_ent_std": 6.825548213145455, "train/prior_ent_mag": 75.78443211589368, "train/prior_ent_max": 75.78443211589368, "train/prior_ent_mean": 49.19168408389019, "train/prior_ent_min": 29.56690915102886, "train/prior_ent_std": 7.394353251771879, "train/rep_loss_mean": 6.768503455341165, "train/rep_loss_std": 8.894737943174876, "train/reward_avg": 0.03227960380257538, "train/reward_loss_mean": 0.05078075640849051, "train/reward_loss_std": 0.20896158159384268, "train/reward_max_data": 1.0147208156924563, "train/reward_max_pred": 1.0148833620971836, "train/reward_neg_acc": 0.9941078596913875, "train/reward_neg_loss": 0.02412448302478657, "train/reward_pos_acc": 0.9866912074500535, "train/reward_pos_loss": 0.7414839673163321, "train/reward_pred": 0.03198250832726356, "train/reward_rate": 0.0371738182106599, "train_stats/sum_log_reward": 8.675757812731193, "train_stats/max_log_achievement_collect_coal": 0.6363636363636364, "train_stats/max_log_achievement_collect_drink": 4.484848484848484, "train_stats/max_log_achievement_collect_sapling": 1.393939393939394, "train_stats/max_log_achievement_collect_stone": 11.151515151515152, "train_stats/max_log_achievement_collect_wood": 5.7272727272727275, "train_stats/max_log_achievement_defeat_skeleton": 0.030303030303030304, "train_stats/max_log_achievement_defeat_zombie": 0.2727272727272727, "train_stats/max_log_achievement_eat_cow": 0.030303030303030304, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.2121212121212122, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_furnace": 1.3333333333333333, "train_stats/max_log_achievement_place_plant": 1.393939393939394, "train_stats/max_log_achievement_place_stone": 3.5757575757575757, "train_stats/max_log_achievement_place_table": 1.9090909090909092, "train_stats/max_log_achievement_wake_up": 2.6363636363636362, "train_stats/mean_log_entropy": 0.4276007508689707, "eval_stats/sum_log_reward": 8.850000202655792, "eval_stats/max_log_achievement_collect_coal": 0.75, "eval_stats/max_log_achievement_collect_drink": 2.375, "eval_stats/max_log_achievement_collect_sapling": 1.375, "eval_stats/max_log_achievement_collect_stone": 10.875, "eval_stats/max_log_achievement_collect_wood": 6.0, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.5, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.125, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 1.0, "eval_stats/max_log_achievement_place_plant": 1.375, "eval_stats/max_log_achievement_place_stone": 3.5, "eval_stats/max_log_achievement_place_table": 2.0, "eval_stats/max_log_achievement_wake_up": 2.0, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 7.792144970153458e-06, "report/cont_loss_std": 0.0001923120580613613, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 3.774036667891778e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 7.674700100324117e-06, "report/cont_pred": 0.9960863590240479, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 5.9295220375061035, "report/dyn_loss_std": 8.131768226623535, "report/image_loss_mean": 3.4841973781585693, "report/image_loss_std": 5.881275177001953, "report/model_loss_mean": 7.0955610275268555, "report/model_loss_std": 9.447121620178223, "report/post_ent_mag": 56.70885467529297, "report/post_ent_max": 56.70885467529297, "report/post_ent_mean": 42.492637634277344, "report/post_ent_min": 22.474960327148438, "report/post_ent_std": 6.530744552612305, "report/prior_ent_mag": 75.40668487548828, "report/prior_ent_max": 75.40668487548828, "report/prior_ent_mean": 48.42438888549805, "report/prior_ent_min": 29.956558227539062, "report/prior_ent_std": 6.821324348449707, "report/rep_loss_mean": 5.9295220375061035, "report/rep_loss_std": 8.131768226623535, "report/reward_avg": 0.03603515774011612, "report/reward_loss_mean": 0.05364251136779785, "report/reward_loss_std": 0.18062059581279755, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0042102336883545, "report/reward_neg_acc": 0.9898167252540588, "report/reward_neg_loss": 0.025842422619462013, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.703635036945343, "report/reward_pred": 0.03544741868972778, "report/reward_rate": 0.041015625, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.0124471141025424, "eval/cont_loss_std": 0.37942829728126526, "eval/cont_neg_acc": 0.800000011920929, "eval/cont_neg_loss": 2.549058675765991, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 5.401944918048684e-07, "eval/cont_pred": 0.9965407848358154, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 20.020668029785156, "eval/dyn_loss_std": 13.120732307434082, "eval/image_loss_mean": 18.939376831054688, "eval/image_loss_std": 20.380859375, "eval/model_loss_mean": 31.158836364746094, "eval/model_loss_std": 25.70025634765625, "eval/post_ent_mag": 56.817081451416016, "eval/post_ent_max": 56.817081451416016, "eval/post_ent_mean": 40.09122085571289, "eval/post_ent_min": 18.790708541870117, "eval/post_ent_std": 6.955620288848877, "eval/prior_ent_mag": 75.40668487548828, "eval/prior_ent_max": 75.40668487548828, "eval/prior_ent_mean": 53.33528137207031, "eval/prior_ent_min": 34.457496643066406, "eval/prior_ent_std": 6.349834442138672, "eval/rep_loss_mean": 20.020668029785156, "eval/rep_loss_std": 13.120732307434082, "eval/reward_avg": 0.03574218600988388, "eval/reward_loss_mean": 0.19461286067962646, "eval/reward_loss_std": 1.0663658380508423, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0782089233398438, "eval/reward_neg_acc": 0.986761748790741, "eval/reward_neg_loss": 0.08404161781072617, "eval/reward_pos_acc": 0.738095223903656, "eval/reward_pos_loss": 2.779873847961426, "eval/reward_pred": 0.0337146520614624, "eval/reward_rate": 0.041015625, "replay/size": 429541.0, "replay/inserts": 7868.0, "replay/samples": 31472.0, "replay/insert_wait_avg": 1.4931463504358784e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.228464660877253e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 89896.0, "eval_replay/inserts": 2024.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1124629748197412e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.450580596923828e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1008172035217, "timer/env.step_count": 983.0, "timer/env.step_total": 75.42252254486084, "timer/env.step_frac": 0.07541491942358074, "timer/env.step_avg": 0.0767268794962979, "timer/env.step_min": 0.023257970809936523, "timer/env.step_max": 3.2558798789978027, "timer/replay._sample_count": 31472.0, "timer/replay._sample_total": 15.290838718414307, "timer/replay._sample_frac": 0.015289297294217291, "timer/replay._sample_avg": 0.0004858553227762553, "timer/replay._sample_min": 0.0003800392150878906, "timer/replay._sample_max": 0.024280786514282227, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1236.0, "timer/agent.policy_total": 20.967028856277466, "timer/agent.policy_frac": 0.02096491523215169, "timer/agent.policy_avg": 0.016963615579512512, "timer/agent.policy_min": 0.009418725967407227, "timer/agent.policy_max": 0.11498880386352539, "timer/dataset_train_count": 1967.0, "timer/dataset_train_total": 0.28968048095703125, "timer/dataset_train_frac": 0.00028965127912507335, "timer/dataset_train_avg": 0.000147270198758023, "timer/dataset_train_min": 8.821487426757812e-05, "timer/dataset_train_max": 0.0007326602935791016, "timer/agent.train_count": 1967.0, "timer/agent.train_total": 871.268492937088, "timer/agent.train_frac": 0.8711806629388883, "timer/agent.train_avg": 0.44294280271331365, "timer/agent.train_min": 0.4315612316131592, "timer/agent.train_max": 0.9467029571533203, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4614989757537842, "timer/agent.report_frac": 0.00046145245340787337, "timer/agent.report_avg": 0.2307494878768921, "timer/agent.report_min": 0.21976876258850098, "timer/agent.report_max": 0.2417302131652832, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 4.172325134277344e-05, "timer/dataset_eval_frac": 4.1719045345288126e-08, "timer/dataset_eval_avg": 4.172325134277344e-05, "timer/dataset_eval_min": 4.172325134277344e-05, "timer/dataset_eval_max": 4.172325134277344e-05, "fps": 7.8670985641237445}
{"step": 430080, "time": 55361.17783856392, "episode/length": 159.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 430176, "time": 55373.74143266678, "episode/length": 296.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9966329966329966, "episode/intrinsic_return": 0.0}
{"step": 430176, "time": 55373.7513988018, "episode/length": 344.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9855072463768116, "episode/intrinsic_return": 0.0}
{"step": 430576, "time": 55423.68792510033, "episode/length": 49.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.92, "episode/intrinsic_return": 0.0}
{"step": 430640, "time": 55433.069652080536, "episode/length": 172.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 430776, "time": 55450.36556839943, "episode/length": 222.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.0}
{"step": 430784, "time": 55452.764999866486, "episode/length": 223.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.0}
{"step": 431256, "time": 55509.3811109066, "episode/length": 447.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 431280, "time": 55513.89931297302, "episode/length": 62.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 431744, "time": 55569.12928724289, "episode/length": 195.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 431792, "time": 55576.29244351387, "episode/length": 63.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.984375, "episode/intrinsic_return": 0.0}
{"step": 431824, "time": 55581.62041950226, "episode/length": 217.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 432016, "time": 55605.35059213638, "episode/length": 171.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 432088, "time": 55615.09960126877, "episode/length": 188.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 432152, "time": 55624.43482375145, "episode/length": 50.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 432160, "time": 55627.16010951996, "episode/length": 171.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 432208, "time": 55634.27915215492, "episode/length": 273.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9890510948905109, "episode/intrinsic_return": 0.0}
{"step": 432568, "time": 55677.455428123474, "episode/length": 92.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.956989247311828, "episode/intrinsic_return": 0.0}
{"step": 432640, "time": 55687.284652233124, "episode/length": 172.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 433032, "time": 55734.29480457306, "episode/length": 57.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9137931034482759, "episode/intrinsic_return": 0.0}
{"step": 433248, "time": 55760.84929013252, "episode/length": 129.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9923076923076923, "episode/intrinsic_return": 0.0}
{"step": 433360, "time": 55775.33108830452, "episode/length": 158.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 433408, "time": 55782.53425145149, "episode/length": 173.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 433848, "time": 55834.91960692406, "episode/length": 210.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 433864, "time": 55838.29547595978, "episode/length": 258.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9806949806949807, "episode/intrinsic_return": 0.0}
{"step": 434336, "time": 55895.938041210175, "episode/length": 272.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9853479853479854, "episode/intrinsic_return": 0.0}
{"step": 434504, "time": 55916.933217048645, "episode/length": 183.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 434520, "time": 55920.3123755455, "episode/length": 234.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 435032, "time": 55981.53017759323, "episode/length": 208.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9808612440191388, "episode/intrinsic_return": 0.0}
{"step": 435344, "time": 56019.31069993973, "episode/length": 261.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9770992366412213, "episode/intrinsic_return": 0.0}
{"step": 435512, "time": 56040.39140725136, "episode/length": 207.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 435520, "time": 56043.2651758194, "episode/length": 206.0, "episode/score": 8.100000038743019, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 435544, "time": 56047.89271569252, "episode/length": 266.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9812734082397003, "episode/intrinsic_return": 0.0}
{"step": 435944, "time": 56095.6446223259, "episode/length": 177.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 435984, "time": 56101.834656238556, "episode/length": 184.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 436328, "time": 56143.13894891739, "episode/length": 161.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 436896, "time": 56210.67884683609, "episode/length": 172.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 436920, "time": 56215.45096898079, "episode/length": 116.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9487179487179487, "episode/intrinsic_return": 0.0}
{"step": 437256, "time": 56255.94345474243, "episode/length": 163.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 437304, "time": 56263.121867895126, "episode/length": 222.0, "episode/score": 9.099999964237213, "episode/reward_rate": 0.9820627802690582, "episode/intrinsic_return": 0.0}
{"step": 437304, "time": 56263.1330974102, "episode/length": 370.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9919137466307277, "episode/intrinsic_return": 0.0}
{"step": 437584, "time": 56298.69381523132, "episode/length": 279.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 437768, "time": 56321.620326042175, "episode/length": 277.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9892086330935251, "episode/intrinsic_return": 0.0}
{"step": 437984, "time": 56348.08602643013, "episode/length": 206.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 438032, "time": 56355.27325129509, "episode/length": 138.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.0}
{"step": 438033, "time": 56357.7291533947, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.47535191828282, "train/action_min": 0.0, "train/action_std": 3.1367197755593152, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0442017976512861, "train/actor_opt_grad_steps": 108120.0, "train/actor_opt_loss": -11.882946834305123, "train/adv_mag": 0.46328628602339395, "train/adv_max": 0.43141575599435583, "train/adv_mean": 0.002612884227042586, "train/adv_min": -0.38528790867807877, "train/adv_std": 0.05479614608850911, "train/cont_avg": 0.9946215452261307, "train/cont_loss_mean": 0.00015463130707548005, "train/cont_loss_std": 0.004695927793037315, "train/cont_neg_acc": 0.9957645373727808, "train/cont_neg_loss": 0.02019161877106812, "train/cont_pos_acc": 0.9999901146145921, "train/cont_pos_loss": 4.241537055301206e-05, "train/cont_pred": 0.9946259128388448, "train/cont_rate": 0.9946215452261307, "train/dyn_loss_mean": 6.766157452185549, "train/dyn_loss_std": 8.904082799077633, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1032004901512185, "train/extr_critic_critic_opt_grad_steps": 108120.0, "train/extr_critic_critic_opt_loss": 16903.911029758165, "train/extr_critic_mag": 8.868247386798188, "train/extr_critic_max": 8.868247386798188, "train/extr_critic_mean": 2.0584536383499454, "train/extr_critic_min": -0.5840880894780758, "train/extr_critic_std": 2.0775400034746334, "train/extr_return_normed_mag": 1.5143814997457379, "train/extr_return_normed_max": 1.5143814997457379, "train/extr_return_normed_mean": 0.344726299520713, "train/extr_return_normed_min": -0.11159355517233437, "train/extr_return_normed_std": 0.32384642666608243, "train/extr_return_rate": 0.6909809811929961, "train/extr_return_raw_mag": 9.706545331370291, "train/extr_return_raw_max": 9.706545331370291, "train/extr_return_raw_mean": 2.0754843489009533, "train/extr_return_raw_min": -0.9019675380620525, "train/extr_return_raw_std": 2.113081074839261, "train/extr_reward_mag": 1.0511104509459068, "train/extr_reward_max": 1.0511104509459068, "train/extr_reward_mean": 0.04318764604553206, "train/extr_reward_min": -0.693122500151246, "train/extr_reward_std": 0.20339387176024853, "train/image_loss_mean": 3.7585771754758444, "train/image_loss_std": 8.644390710035161, "train/model_loss_mean": 7.868650460363034, "train/model_loss_std": 12.782511342110945, "train/model_opt_grad_norm": 41.10682390682661, "train/model_opt_grad_steps": 108025.44221105527, "train/model_opt_loss": 10932.751371604114, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1394.4723618090452, "train/policy_entropy_mag": 2.487720931594695, "train/policy_entropy_max": 2.487720931594695, "train/policy_entropy_mean": 0.434720988998461, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.5946421160470301, "train/policy_logprob_mag": 7.438384077656808, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.4348272320313669, "train/policy_logprob_min": -7.438384077656808, "train/policy_logprob_std": 1.042991515679575, "train/policy_randomness_mag": 0.8780563174180649, "train/policy_randomness_max": 0.8780563174180649, "train/policy_randomness_mean": 0.15343743135881185, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.20988257401552632, "train/post_ent_mag": 59.34348262614341, "train/post_ent_max": 59.34348262614341, "train/post_ent_mean": 42.41080334917385, "train/post_ent_min": 19.795216675379766, "train/post_ent_std": 6.807374894319468, "train/prior_ent_mag": 75.82941417598245, "train/prior_ent_max": 75.82941417598245, "train/prior_ent_mean": 49.16470954166585, "train/prior_ent_min": 29.23835227237874, "train/prior_ent_std": 7.405151302491001, "train/rep_loss_mean": 6.766157452185549, "train/rep_loss_std": 8.904082799077633, "train/reward_avg": 0.03278747243553999, "train/reward_loss_mean": 0.05022421601841498, "train/reward_loss_std": 0.20974174703485401, "train/reward_max_data": 1.0185929692570288, "train/reward_max_pred": 1.015866952924872, "train/reward_neg_acc": 0.994875237869857, "train/reward_neg_loss": 0.023190236086465754, "train/reward_pos_acc": 0.9846099171806221, "train/reward_pos_loss": 0.7444058075622099, "train/reward_pred": 0.032460893785122354, "train/reward_rate": 0.037560851130653265, "train_stats/sum_log_reward": 8.188889079623753, "train_stats/max_log_achievement_collect_coal": 0.7777777777777778, "train_stats/max_log_achievement_collect_drink": 3.6, "train_stats/max_log_achievement_collect_sapling": 1.2666666666666666, "train_stats/max_log_achievement_collect_stone": 11.71111111111111, "train_stats/max_log_achievement_collect_wood": 5.666666666666667, "train_stats/max_log_achievement_defeat_skeleton": 0.044444444444444446, "train_stats/max_log_achievement_defeat_zombie": 0.17777777777777778, "train_stats/max_log_achievement_eat_cow": 0.022222222222222223, "train_stats/max_log_achievement_make_stone_pickaxe": 0.022222222222222223, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.0888888888888888, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_furnace": 1.4, "train_stats/max_log_achievement_place_plant": 1.2222222222222223, "train_stats/max_log_achievement_place_stone": 3.422222222222222, "train_stats/max_log_achievement_place_table": 1.8666666666666667, "train_stats/max_log_achievement_wake_up": 1.6666666666666667, "train_stats/mean_log_entropy": 0.36072477565871347, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 9.152670827461407e-06, "report/cont_loss_std": 0.00013378543371800333, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00015997847367543727, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 8.412603165197652e-06, "report/cont_pred": 0.9951096773147583, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 5.853509902954102, "report/dyn_loss_std": 8.639293670654297, "report/image_loss_mean": 3.2409353256225586, "report/image_loss_std": 7.301255702972412, "report/model_loss_mean": 6.796894550323486, "report/model_loss_std": 11.21436882019043, "report/post_ent_mag": 58.36264419555664, "report/post_ent_max": 58.36264419555664, "report/post_ent_mean": 43.42420196533203, "report/post_ent_min": 19.298030853271484, "report/post_ent_std": 6.8936591148376465, "report/prior_ent_mag": 75.52098846435547, "report/prior_ent_max": 75.52098846435547, "report/prior_ent_mean": 49.46349334716797, "report/prior_ent_min": 31.761032104492188, "report/prior_ent_std": 7.5637431144714355, "report/rep_loss_mean": 5.853509902954102, "report/rep_loss_std": 8.639293670654297, "report/reward_avg": 0.03056640736758709, "report/reward_loss_mean": 0.04384395107626915, "report/reward_loss_std": 0.18656794726848602, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.0007076263427734, "report/reward_neg_acc": 0.996966540813446, "report/reward_neg_loss": 0.018444286659359932, "report/reward_pos_acc": 0.9714285731315613, "report/reward_pos_loss": 0.7615658640861511, "report/reward_pred": 0.029771272093057632, "report/reward_rate": 0.0341796875, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.00012103979679523036, "eval/cont_loss_std": 0.003061312949284911, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00038547441363334656, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.00011974227527389303, "eval/cont_pred": 0.9950045347213745, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 21.41997528076172, "eval/dyn_loss_std": 12.69019603729248, "eval/image_loss_mean": 17.40180206298828, "eval/image_loss_std": 21.02859115600586, "eval/model_loss_mean": 30.38068962097168, "eval/model_loss_std": 25.4337158203125, "eval/post_ent_mag": 55.06983184814453, "eval/post_ent_max": 55.06983184814453, "eval/post_ent_mean": 38.342254638671875, "eval/post_ent_min": 20.845287322998047, "eval/post_ent_std": 6.748147010803223, "eval/prior_ent_mag": 75.52098846435547, "eval/prior_ent_max": 75.52098846435547, "eval/prior_ent_mean": 52.327301025390625, "eval/prior_ent_min": 35.43842315673828, "eval/prior_ent_std": 6.866013526916504, "eval/rep_loss_mean": 21.41997528076172, "eval/rep_loss_std": 12.69019603729248, "eval/reward_avg": 0.04326171800494194, "eval/reward_loss_mean": 0.12678298354148865, "eval/reward_loss_std": 0.7878876328468323, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0009102821350098, "eval/reward_neg_acc": 0.9917948246002197, "eval/reward_neg_loss": 0.04387954622507095, "eval/reward_pos_acc": 0.8571428656578064, "eval/reward_pos_loss": 1.7763923406600952, "eval/reward_pred": 0.039634428918361664, "eval/reward_rate": 0.0478515625, "replay/size": 437529.0, "replay/inserts": 7988.0, "replay/samples": 31952.0, "replay/insert_wait_avg": 1.4893699420590847e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.369172650692041e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 89896.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 7.599592208862305e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.5324468612671, "timer/env.step_count": 999.0, "timer/env.step_total": 97.09279799461365, "timer/env.step_frac": 0.09704112875019678, "timer/env.step_avg": 0.09718998798259625, "timer/env.step_min": 0.023117780685424805, "timer/env.step_max": 3.12272310256958, "timer/replay._sample_count": 31952.0, "timer/replay._sample_total": 15.51348066329956, "timer/replay._sample_frac": 0.015505224954939063, "timer/replay._sample_avg": 0.00048552455756445796, "timer/replay._sample_min": 0.0003991127014160156, "timer/replay._sample_max": 0.01096343994140625, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 999.0, "timer/agent.policy_total": 15.9219651222229, "timer/agent.policy_frac": 0.015913492033337952, "timer/agent.policy_avg": 0.015937903025248147, "timer/agent.policy_min": 0.009775876998901367, "timer/agent.policy_max": 0.07172799110412598, "timer/dataset_train_count": 1997.0, "timer/dataset_train_total": 0.29271912574768066, "timer/dataset_train_frac": 0.0002925633513095541, "timer/dataset_train_avg": 0.00014657943202187314, "timer/dataset_train_min": 8.726119995117188e-05, "timer/dataset_train_max": 0.0010685920715332031, "timer/agent.train_count": 1997.0, "timer/agent.train_total": 884.3725287914276, "timer/agent.train_frac": 0.8839018980001694, "timer/agent.train_avg": 0.4428505402060228, "timer/agent.train_min": 0.43201684951782227, "timer/agent.train_max": 0.9544334411621094, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47551941871643066, "timer/agent.report_frac": 0.0004752663646323164, "timer/agent.report_avg": 0.23775970935821533, "timer/agent.report_min": 0.22993159294128418, "timer/agent.report_max": 0.24558782577514648, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.6464462280273438e-05, "timer/dataset_eval_frac": 2.64503788590706e-08, "timer/dataset_eval_avg": 2.6464462280273438e-05, "timer/dataset_eval_min": 2.6464462280273438e-05, "timer/dataset_eval_max": 2.6464462280273438e-05, "fps": 7.983631910804478}
{"step": 438512, "time": 56413.039625406265, "episode/length": 150.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 438656, "time": 56431.210290431976, "episode/length": 168.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 439008, "time": 56473.62300300598, "episode/length": 263.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 439216, "time": 56499.614453077316, "episode/length": 203.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 439472, "time": 56531.83549594879, "episode/length": 212.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 439640, "time": 56553.2518184185, "episode/length": 140.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 439824, "time": 56576.09397029877, "episode/length": 320.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9875389408099688, "episode/intrinsic_return": 0.0}
{"step": 440024, "time": 56614.81347298622, "eval_episode/length": 40.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.975609756097561}
{"step": 440024, "time": 56618.907130002975, "eval_episode/length": 87.0, "eval_episode/score": 8.100000023841858, "eval_episode/reward_rate": 0.9886363636363636}
{"step": 440024, "time": 56624.13245987892, "eval_episode/length": 155.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.967948717948718}
{"step": 440024, "time": 56626.31456780434, "eval_episode/length": 160.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9627329192546584}
{"step": 440024, "time": 56629.939277648926, "eval_episode/length": 195.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9642857142857143}
{"step": 440024, "time": 56631.96892571449, "eval_episode/length": 196.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9949238578680203}
{"step": 440024, "time": 56634.99797129631, "eval_episode/length": 217.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9954128440366973}
{"step": 440024, "time": 56637.748388290405, "eval_episode/length": 236.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9789029535864979}
{"step": 440192, "time": 56657.489203453064, "episode/length": 275.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9963768115942029, "episode/intrinsic_return": 0.0}
{"step": 440360, "time": 56678.51683783531, "episode/length": 168.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 440744, "time": 56724.598073244095, "episode/length": 190.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 441160, "time": 56774.35254383087, "episode/length": 390.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9974424552429667, "episode/intrinsic_return": 0.0}
{"step": 441208, "time": 56781.456862449646, "episode/length": 195.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 441288, "time": 56792.21028447151, "episode/length": 226.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9779735682819384, "episode/intrinsic_return": 0.0}
{"step": 441320, "time": 56797.42609286308, "episode/length": 332.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.990990990990991, "episode/intrinsic_return": 0.0}
{"step": 441400, "time": 56808.184711933136, "episode/length": 150.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9602649006622517, "episode/intrinsic_return": 0.0}
{"step": 441568, "time": 56829.123832941055, "episode/length": 150.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 441776, "time": 56854.92949938774, "episode/length": 243.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 442408, "time": 56931.731544971466, "episode/length": 207.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 442616, "time": 56957.376937389374, "episode/length": 181.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 442656, "time": 56963.52290177345, "episode/length": 170.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 442816, "time": 56983.66062045097, "episode/length": 176.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9661016949152542, "episode/intrinsic_return": 0.0}
{"step": 442952, "time": 57000.965371608734, "episode/length": 146.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 443200, "time": 57031.259186029434, "episode/length": 234.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9702127659574468, "episode/intrinsic_return": 0.0}
{"step": 443384, "time": 57054.15758371353, "episode/length": 226.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9779735682819384, "episode/intrinsic_return": 0.0}
{"step": 443848, "time": 57109.55703687668, "episode/length": 329.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9848484848484849, "episode/intrinsic_return": 0.0}
{"step": 444104, "time": 57140.83473443985, "episode/length": 211.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 444152, "time": 57147.83187747002, "episode/length": 191.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 444184, "time": 57152.95439982414, "episode/length": 170.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 444192, "time": 57155.307475566864, "episode/length": 42.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 444208, "time": 57158.65450048447, "episode/length": 156.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 444496, "time": 57193.537480831146, "episode/length": 229.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 445320, "time": 57291.01892733574, "episode/length": 264.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9849056603773585, "episode/intrinsic_return": 0.0}
{"step": 445328, "time": 57293.468349695206, "episode/length": 242.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9958847736625515, "episode/intrinsic_return": 0.0}
{"step": 445432, "time": 57307.05586767197, "episode/length": 159.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 445480, "time": 57314.13681650162, "episode/length": 171.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 445496, "time": 57317.503726005554, "episode/length": 162.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 445696, "time": 57342.21846961975, "episode/length": 188.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 445813, "time": 57358.069717645645, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.466523625300481, "train/action_min": 0.0, "train/action_std": 3.091084603774242, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04459807926263565, "train/actor_opt_grad_steps": 110090.0, "train/actor_opt_loss": -10.552636930613946, "train/adv_mag": 0.47784377489334495, "train/adv_max": 0.4453265440769685, "train/adv_mean": 0.0030946887886481515, "train/adv_min": -0.38874502319556015, "train/adv_std": 0.055867445335174216, "train/cont_avg": 0.9947315705128205, "train/cont_loss_mean": 0.00013747192238286907, "train/cont_loss_std": 0.004173120693314722, "train/cont_neg_acc": 0.9965750920466888, "train/cont_neg_loss": 0.015568680060704746, "train/cont_pos_acc": 0.9999798551583902, "train/cont_pos_loss": 4.688653772041617e-05, "train/cont_pred": 0.994721062366779, "train/cont_rate": 0.9947315705128205, "train/dyn_loss_mean": 6.711848329886412, "train/dyn_loss_std": 8.912106330578144, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1592908730873694, "train/extr_critic_critic_opt_grad_steps": 110090.0, "train/extr_critic_critic_opt_loss": 16966.989603365386, "train/extr_critic_mag": 8.76399347843268, "train/extr_critic_max": 8.76399347843268, "train/extr_critic_mean": 2.041203143657782, "train/extr_critic_min": -0.5601375854932344, "train/extr_critic_std": 2.0527942241766515, "train/extr_return_normed_mag": 1.5089515227537889, "train/extr_return_normed_max": 1.5089515227537889, "train/extr_return_normed_mean": 0.346724710556177, "train/extr_return_normed_min": -0.10192367799389057, "train/extr_return_normed_std": 0.3234966782423166, "train/extr_return_rate": 0.6907542427380879, "train/extr_return_raw_mag": 9.567735882294484, "train/extr_return_raw_max": 9.567735882294484, "train/extr_return_raw_mean": 2.0611865691649607, "train/extr_return_raw_min": -0.8364893020727695, "train/extr_return_raw_std": 2.089686273305844, "train/extr_reward_mag": 1.0498336070623153, "train/extr_reward_max": 1.0498336070623153, "train/extr_reward_mean": 0.04343530700947994, "train/extr_reward_min": -0.7012163596275526, "train/extr_reward_std": 0.20404680187885577, "train/image_loss_mean": 3.8394183745751014, "train/image_loss_std": 8.801827350029578, "train/model_loss_mean": 7.917537716107491, "train/model_loss_std": 12.930684070098094, "train/model_opt_grad_norm": 39.75329471490322, "train/model_opt_grad_steps": 109994.16923076923, "train/model_opt_loss": 14717.868244190706, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1858.974358974359, "train/policy_entropy_mag": 2.5393400705777682, "train/policy_entropy_max": 2.5393400705777682, "train/policy_entropy_mean": 0.4519800228950305, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6197555016248654, "train/policy_logprob_mag": 7.438384141677465, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.4523327534015362, "train/policy_logprob_min": -7.438384141677465, "train/policy_logprob_std": 1.059381945622273, "train/policy_randomness_mag": 0.8962756095788418, "train/policy_randomness_max": 0.8962756095788418, "train/policy_randomness_mean": 0.15952911354028262, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.21874649738654112, "train/post_ent_mag": 59.177379764654695, "train/post_ent_max": 59.177379764654695, "train/post_ent_mean": 42.52344076694586, "train/post_ent_min": 19.586763484661397, "train/post_ent_std": 6.77904397768852, "train/prior_ent_mag": 75.82679212521285, "train/prior_ent_max": 75.82679212521285, "train/prior_ent_mean": 49.221892664982725, "train/prior_ent_min": 29.24723269144694, "train/prior_ent_std": 7.456207228929569, "train/rep_loss_mean": 6.711848329886412, "train/rep_loss_std": 8.912106330578144, "train/reward_avg": 0.032373297209732046, "train/reward_loss_mean": 0.05087286739204174, "train/reward_loss_std": 0.21318064202100803, "train/reward_max_data": 1.0164102603227665, "train/reward_max_pred": 1.016485240520575, "train/reward_neg_acc": 0.9945613986406571, "train/reward_neg_loss": 0.023611505525425458, "train/reward_pos_acc": 0.9824794509471991, "train/reward_pos_loss": 0.7585155535966922, "train/reward_pred": 0.0319209033002456, "train/reward_rate": 0.03717447916666667, "train_stats/sum_log_reward": 8.154054190661457, "train_stats/max_log_achievement_collect_coal": 0.5135135135135135, "train_stats/max_log_achievement_collect_drink": 4.216216216216216, "train_stats/max_log_achievement_collect_sapling": 1.8108108108108107, "train_stats/max_log_achievement_collect_stone": 9.297297297297296, "train_stats/max_log_achievement_collect_wood": 6.243243243243243, "train_stats/max_log_achievement_defeat_skeleton": 0.08108108108108109, "train_stats/max_log_achievement_defeat_zombie": 0.24324324324324326, "train_stats/max_log_achievement_eat_cow": 0.08108108108108109, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.2702702702702702, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_furnace": 1.135135135135135, "train_stats/max_log_achievement_place_plant": 1.7027027027027026, "train_stats/max_log_achievement_place_stone": 3.2432432432432434, "train_stats/max_log_achievement_place_table": 2.2432432432432434, "train_stats/max_log_achievement_wake_up": 2.324324324324324, "train_stats/mean_log_entropy": 0.39220159198786764, "eval_stats/sum_log_reward": 7.725000262260437, "eval_stats/max_log_achievement_collect_coal": 0.125, "eval_stats/max_log_achievement_collect_drink": 2.375, "eval_stats/max_log_achievement_collect_sapling": 1.125, "eval_stats/max_log_achievement_collect_stone": 8.375, "eval_stats/max_log_achievement_collect_wood": 5.625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.25, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.625, "eval_stats/max_log_achievement_place_plant": 1.125, "eval_stats/max_log_achievement_place_stone": 2.125, "eval_stats/max_log_achievement_place_table": 1.875, "eval_stats/max_log_achievement_wake_up": 1.125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.00017424029647372663, "report/cont_loss_std": 0.00504011707380414, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0006419088458642364, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.00017194554675370455, "report/cont_pred": 0.9949612617492676, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 7.020947456359863, "report/dyn_loss_std": 8.825470924377441, "report/image_loss_mean": 2.835462808609009, "report/image_loss_std": 6.596085071563721, "report/model_loss_mean": 7.094104766845703, "report/model_loss_std": 10.6965970993042, "report/post_ent_mag": 56.49900817871094, "report/post_ent_max": 56.49900817871094, "report/post_ent_mean": 40.623870849609375, "report/post_ent_min": 19.594572067260742, "report/post_ent_std": 6.226755619049072, "report/prior_ent_mag": 75.96728515625, "report/prior_ent_max": 75.96728515625, "report/prior_ent_mean": 47.6116943359375, "report/prior_ent_min": 26.465404510498047, "report/prior_ent_std": 7.365573406219482, "report/rep_loss_mean": 7.020947456359863, "report/rep_loss_std": 8.825470924377441, "report/reward_avg": 0.04326171800494194, "report/reward_loss_mean": 0.04589955508708954, "report/reward_loss_std": 0.16772422194480896, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0018231868743896, "report/reward_neg_acc": 0.9999999403953552, "report/reward_neg_loss": 0.014301963150501251, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6746271848678589, "report/reward_pred": 0.043344687670469284, "report/reward_rate": 0.0478515625, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.0004907893599011004, "eval/cont_loss_std": 0.015395987778902054, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00033709697891026735, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0004915434983558953, "eval/cont_pred": 0.9947310090065002, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 18.689960479736328, "eval/dyn_loss_std": 12.863956451416016, "eval/image_loss_mean": 19.164710998535156, "eval/image_loss_std": 23.936792373657227, "eval/model_loss_mean": 30.53327178955078, "eval/model_loss_std": 29.191829681396484, "eval/post_ent_mag": 55.87993621826172, "eval/post_ent_max": 55.87993621826172, "eval/post_ent_mean": 39.878753662109375, "eval/post_ent_min": 19.66896629333496, "eval/post_ent_std": 6.567530155181885, "eval/prior_ent_mag": 75.96728515625, "eval/prior_ent_max": 75.96728515625, "eval/prior_ent_mean": 52.47471237182617, "eval/prior_ent_min": 32.334815979003906, "eval/prior_ent_std": 7.237781047821045, "eval/rep_loss_mean": 18.689960479736328, "eval/rep_loss_std": 12.863956451416016, "eval/reward_avg": 0.046875, "eval/reward_loss_mean": 0.1540926694869995, "eval/reward_loss_std": 0.8589439392089844, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.0724120140075684, "eval/reward_neg_acc": 0.9927909970283508, "eval/reward_neg_loss": 0.05049583688378334, "eval/reward_pos_acc": 0.8301886916160583, "eval/reward_pos_loss": 2.052065134048462, "eval/reward_pred": 0.034443121403455734, "eval/reward_rate": 0.0517578125, "replay/size": 445309.0, "replay/inserts": 7780.0, "replay/samples": 31120.0, "replay/insert_wait_avg": 1.5150918445734254e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.282185983535257e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 91792.0, "eval_replay/inserts": 1896.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2315778289666156e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.046627044677734e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3210208415985, "timer/env.step_count": 972.0, "timer/env.step_total": 83.56131386756897, "timer/env.step_frac": 0.08353449755286205, "timer/env.step_avg": 0.08596842990490634, "timer/env.step_min": 0.02342534065246582, "timer/env.step_max": 2.1717827320098877, "timer/replay._sample_count": 31120.0, "timer/replay._sample_total": 15.2301766872406, "timer/replay._sample_frac": 0.015225289052135504, "timer/replay._sample_avg": 0.0004894015645000193, "timer/replay._sample_min": 0.0003771781921386719, "timer/replay._sample_max": 0.023437023162841797, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1209.0, "timer/agent.policy_total": 19.455039978027344, "timer/agent.policy_frac": 0.019448796509003944, "timer/agent.policy_avg": 0.016091844481412196, "timer/agent.policy_min": 0.00969243049621582, "timer/agent.policy_max": 0.07074832916259766, "timer/dataset_train_count": 1945.0, "timer/dataset_train_total": 0.2915346622467041, "timer/dataset_train_frac": 0.00029144110357835697, "timer/dataset_train_avg": 0.0001498892865021615, "timer/dataset_train_min": 8.96453857421875e-05, "timer/dataset_train_max": 0.004889011383056641, "timer/agent.train_count": 1945.0, "timer/agent.train_total": 861.2565364837646, "timer/agent.train_frac": 0.860980143913366, "timer/agent.train_avg": 0.44280541721530314, "timer/agent.train_min": 0.43160462379455566, "timer/agent.train_max": 0.9719583988189697, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.46987223625183105, "timer/agent.report_frac": 0.00046972144587795845, "timer/agent.report_avg": 0.23493611812591553, "timer/agent.report_min": 0.22932124137878418, "timer/agent.report_max": 0.24055099487304688, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9087066650390625e-05, "timer/dataset_eval_frac": 2.907773209236256e-08, "timer/dataset_eval_avg": 2.9087066650390625e-05, "timer/dataset_eval_min": 2.9087066650390625e-05, "timer/dataset_eval_max": 2.9087066650390625e-05, "fps": 7.777391256335234}
{"step": 446000, "time": 57379.70490384102, "episode/length": 187.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 446152, "time": 57398.75204730034, "episode/length": 242.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9794238683127572, "episode/intrinsic_return": 0.0}
{"step": 446688, "time": 57462.49018931389, "episode/length": 170.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9590643274853801, "episode/intrinsic_return": 0.0}
{"step": 446920, "time": 57490.930057287216, "episode/length": 198.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9698492462311558, "episode/intrinsic_return": 0.0}
{"step": 446944, "time": 57495.28586554527, "episode/length": 155.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 447368, "time": 57546.15196251869, "episode/length": 170.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 447392, "time": 57550.59937906265, "episode/length": 236.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9789029535864979, "episode/intrinsic_return": 0.0}
{"step": 447704, "time": 57588.30166244507, "episode/length": 283.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9823943661971831, "episode/intrinsic_return": 0.0}
{"step": 447712, "time": 57590.9592089653, "episode/length": 278.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.982078853046595, "episode/intrinsic_return": 0.0}
{"step": 447832, "time": 57606.29064869881, "episode/length": 209.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 447832, "time": 57606.29738903046, "episode/length": 142.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.965034965034965, "episode/intrinsic_return": 0.0}
{"step": 448232, "time": 57656.14300251007, "episode/length": 163.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 448888, "time": 57733.701041936874, "episode/length": 131.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.946969696969697, "episode/intrinsic_return": 0.0}
{"step": 449224, "time": 57774.0792889595, "episode/length": 228.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9694323144104804, "episode/intrinsic_return": 0.0}
{"step": 449264, "time": 57780.13846158981, "episode/length": 193.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 449280, "time": 57783.620020866394, "episode/length": 238.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9790794979079498, "episode/intrinsic_return": 0.0}
{"step": 449528, "time": 57813.934975385666, "episode/length": 211.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 449576, "time": 57821.14825105667, "episode/length": 167.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 449616, "time": 57827.24082517624, "episode/length": 333.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9820359281437125, "episode/intrinsic_return": 0.0}
{"step": 449696, "time": 57838.08419561386, "episode/length": 248.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 450008, "time": 57897.16326880455, "eval_episode/length": 165.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.963855421686747}
{"step": 450008, "time": 57899.42863202095, "eval_episode/length": 171.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9709302325581395}
{"step": 450008, "time": 57901.52503466606, "eval_episode/length": 173.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9712643678160919}
{"step": 450008, "time": 57903.50467967987, "eval_episode/length": 174.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9942857142857143}
{"step": 450008, "time": 57905.74442887306, "eval_episode/length": 183.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9945652173913043}
{"step": 450008, "time": 57908.91556620598, "eval_episode/length": 210.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.976303317535545}
{"step": 450008, "time": 57911.624084711075, "eval_episode/length": 232.0, "eval_episode/score": 10.099999971687794, "eval_episode/reward_rate": 0.9957081545064378}
{"step": 450008, "time": 57915.14067173004, "eval_episode/length": 99.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.99}
{"step": 450520, "time": 57974.39084529877, "episode/length": 161.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 450552, "time": 57979.542281627655, "episode/length": 127.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9921875, "episode/intrinsic_return": 0.0}
{"step": 450616, "time": 57989.65192294121, "episode/length": 129.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9923076923076923, "episode/intrinsic_return": 0.0}
{"step": 450696, "time": 58000.43751955032, "episode/length": 134.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 451128, "time": 58051.98455476761, "episode/length": 279.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9892857142857143, "episode/intrinsic_return": 0.0}
{"step": 451192, "time": 58060.88109612465, "episode/length": 186.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 451368, "time": 58082.72402596474, "episode/length": 260.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9808429118773946, "episode/intrinsic_return": 0.0}
{"step": 451760, "time": 58129.79739880562, "episode/length": 142.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.965034965034965, "episode/intrinsic_return": 0.0}
{"step": 452016, "time": 58161.280913591385, "episode/length": 182.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 452184, "time": 58183.07173538208, "episode/length": 364.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9917808219178083, "episode/intrinsic_return": 0.0}
{"step": 452672, "time": 58241.6400885582, "episode/length": 60.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 452752, "time": 58252.43707084656, "episode/length": 194.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 452792, "time": 58258.54681634903, "episode/length": 261.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9809160305343512, "episode/intrinsic_return": 0.0}
{"step": 452912, "time": 58274.05689287186, "episode/length": 143.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 452952, "time": 58280.67807531357, "episode/length": 303.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9835526315789473, "episode/intrinsic_return": 0.0}
{"step": 452952, "time": 58280.68539595604, "episode/length": 116.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9572649572649573, "episode/intrinsic_return": 0.0}
{"step": 453280, "time": 58322.87866234779, "episode/length": 238.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9748953974895398, "episode/intrinsic_return": 0.0}
{"step": 453336, "time": 58330.90259242058, "episode/length": 275.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9818840579710145, "episode/intrinsic_return": 0.0}
{"step": 453553, "time": 58358.23878407478, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.485897716462921, "train/action_min": 0.0, "train/action_std": 3.16017796338531, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04464874034409696, "train/actor_opt_grad_steps": 112030.0, "train/actor_opt_loss": -12.050828673447352, "train/adv_mag": 0.4571361733224108, "train/adv_max": 0.42254458638052866, "train/adv_mean": 0.0026064165010819484, "train/adv_min": -0.39146919201075103, "train/adv_std": 0.055494848986209364, "train/cont_avg": 0.9944998785621761, "train/cont_loss_mean": 0.0001046190824238229, "train/cont_loss_std": 0.0029159421124427, "train/cont_neg_acc": 0.9939263101686467, "train/cont_neg_loss": 0.014848398653312856, "train/cont_pos_acc": 0.9999949079721085, "train/cont_pos_loss": 3.7377422803903784e-05, "train/cont_pred": 0.9944943155649413, "train/cont_rate": 0.9944998785621761, "train/dyn_loss_mean": 6.800221551885259, "train/dyn_loss_std": 8.94706719156374, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1283283273790785, "train/extr_critic_critic_opt_grad_steps": 112030.0, "train/extr_critic_critic_opt_loss": 16911.785105650906, "train/extr_critic_mag": 8.970057413368027, "train/extr_critic_max": 8.970057413368027, "train/extr_critic_mean": 2.1752919594858593, "train/extr_critic_min": -0.5754576328504889, "train/extr_critic_std": 2.1251382315097076, "train/extr_return_normed_mag": 1.5093788797991263, "train/extr_return_normed_max": 1.5093788797991263, "train/extr_return_normed_mean": 0.3597733190022602, "train/extr_return_normed_min": -0.09890409167180407, "train/extr_return_normed_std": 0.3245002584136212, "train/extr_return_rate": 0.7125617701154916, "train/extr_return_raw_mag": 9.854224980803968, "train/extr_return_raw_max": 9.854224980803968, "train/extr_return_raw_mean": 2.1926403144480653, "train/extr_return_raw_min": -0.8635901391815027, "train/extr_return_raw_std": 2.1626470601620453, "train/extr_reward_mag": 1.0440999670967537, "train/extr_reward_max": 1.0440999670967537, "train/extr_reward_mean": 0.04498952441882593, "train/extr_reward_min": -0.6834080410744859, "train/extr_reward_std": 0.20751872349897196, "train/image_loss_mean": 3.764545326405856, "train/image_loss_std": 8.788110656441802, "train/model_loss_mean": 7.895650295395925, "train/model_loss_std": 12.936760176031083, "train/model_opt_grad_norm": 41.24042065279471, "train/model_opt_grad_steps": 111932.8031088083, "train/model_opt_loss": 11587.449681731703, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1476.6839378238342, "train/policy_entropy_mag": 2.551095423920785, "train/policy_entropy_max": 2.551095423920785, "train/policy_entropy_mean": 0.45426098238001217, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6276841543499052, "train/policy_logprob_mag": 7.438384135152392, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.4540945371815578, "train/policy_logprob_min": -7.438384135152392, "train/policy_logprob_std": 1.0613936315546382, "train/policy_randomness_mag": 0.9004247330630999, "train/policy_randomness_max": 0.9004247330630999, "train/policy_randomness_mean": 0.16033419225500037, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.22154496146916108, "train/post_ent_mag": 59.26406229839424, "train/post_ent_max": 59.26406229839424, "train/post_ent_mean": 42.49328779309525, "train/post_ent_min": 19.725187815532784, "train/post_ent_std": 6.768328503623527, "train/prior_ent_mag": 75.83798810731561, "train/prior_ent_max": 75.83798810731561, "train/prior_ent_mean": 49.274287485705756, "train/prior_ent_min": 29.28470258762182, "train/prior_ent_std": 7.4320150138182965, "train/rep_loss_mean": 6.800221551885259, "train/rep_loss_std": 8.94706719156374, "train/reward_avg": 0.033616519248392915, "train/reward_loss_mean": 0.05086742299053953, "train/reward_loss_std": 0.21040341659531075, "train/reward_max_data": 1.0150259103182067, "train/reward_max_pred": 1.0141212958746006, "train/reward_neg_acc": 0.9948089768231841, "train/reward_neg_loss": 0.022841660286555637, "train/reward_pos_acc": 0.9833000938509412, "train/reward_pos_loss": 0.752530918837829, "train/reward_pred": 0.03308174209041917, "train/reward_rate": 0.038414831606217614, "train_stats/sum_log_reward": 8.126316007814909, "train_stats/max_log_achievement_collect_coal": 0.6578947368421053, "train_stats/max_log_achievement_collect_drink": 3.973684210526316, "train_stats/max_log_achievement_collect_sapling": 1.368421052631579, "train_stats/max_log_achievement_collect_stone": 11.5, "train_stats/max_log_achievement_collect_wood": 5.368421052631579, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.2631578947368421, "train_stats/max_log_achievement_eat_cow": 0.07894736842105263, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.9736842105263158, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_furnace": 1.7105263157894737, "train_stats/max_log_achievement_place_plant": 1.263157894736842, "train_stats/max_log_achievement_place_stone": 3.1315789473684212, "train_stats/max_log_achievement_place_table": 1.9210526315789473, "train_stats/max_log_achievement_wake_up": 2.3947368421052633, "train_stats/mean_log_entropy": 0.4229229296508588, "eval_stats/sum_log_reward": 7.6000001430511475, "eval_stats/max_log_achievement_collect_coal": 0.625, "eval_stats/max_log_achievement_collect_drink": 3.375, "eval_stats/max_log_achievement_collect_sapling": 0.75, "eval_stats/max_log_achievement_collect_stone": 13.875, "eval_stats/max_log_achievement_collect_wood": 5.5, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.25, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.125, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 2.0, "eval_stats/max_log_achievement_place_plant": 0.75, "eval_stats/max_log_achievement_place_stone": 3.125, "eval_stats/max_log_achievement_place_table": 2.125, "eval_stats/max_log_achievement_wake_up": 2.0, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 2.1013298464822583e-05, "report/cont_loss_std": 0.0003483043401502073, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0013353483518585563, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.066420281858882e-05, "report/cont_pred": 0.9921872615814209, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 6.416864395141602, "report/dyn_loss_std": 8.776068687438965, "report/image_loss_mean": 4.739195823669434, "report/image_loss_std": 7.110388278961182, "report/model_loss_mean": 8.643041610717773, "report/model_loss_std": 10.902615547180176, "report/post_ent_mag": 59.74162292480469, "report/post_ent_max": 59.74162292480469, "report/post_ent_mean": 43.83852767944336, "report/post_ent_min": 17.971363067626953, "report/post_ent_std": 7.58691930770874, "report/prior_ent_mag": 75.64179229736328, "report/prior_ent_max": 75.64179229736328, "report/prior_ent_mean": 50.25074768066406, "report/prior_ent_min": 29.77899169921875, "report/prior_ent_std": 8.280402183532715, "report/rep_loss_mean": 6.416864395141602, "report/rep_loss_std": 8.776068687438965, "report/reward_avg": 0.02685546688735485, "report/reward_loss_mean": 0.05370531231164932, "report/reward_loss_std": 0.2713843286037445, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0006368160247803, "report/reward_neg_acc": 0.9878910183906555, "report/reward_neg_loss": 0.026384901255369186, "report/reward_pos_acc": 0.9696969389915466, "report/reward_pos_loss": 0.8741455078125, "report/reward_pred": 0.026838233694434166, "report/reward_rate": 0.0322265625, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 1.645587690290995e-05, "eval/cont_loss_std": 0.0002736430906224996, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 6.394823139999062e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.6362937458325177e-05, "eval/cont_pred": 0.9980306625366211, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 19.977737426757812, "eval/dyn_loss_std": 12.637292861938477, "eval/image_loss_mean": 21.32624626159668, "eval/image_loss_std": 26.958133697509766, "eval/model_loss_mean": 33.4519157409668, "eval/model_loss_std": 31.953824996948242, "eval/post_ent_mag": 56.176666259765625, "eval/post_ent_max": 56.176666259765625, "eval/post_ent_mean": 39.851287841796875, "eval/post_ent_min": 20.20810890197754, "eval/post_ent_std": 6.918362617492676, "eval/prior_ent_mag": 75.64179229736328, "eval/prior_ent_max": 75.64179229736328, "eval/prior_ent_mean": 53.144737243652344, "eval/prior_ent_min": 33.16390609741211, "eval/prior_ent_std": 6.3495635986328125, "eval/rep_loss_mean": 19.977737426757812, "eval/rep_loss_std": 12.637292861938477, "eval/reward_avg": 0.03212890401482582, "eval/reward_loss_mean": 0.13901260495185852, "eval/reward_loss_std": 0.8546566367149353, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0001022815704346, "eval/reward_neg_acc": 0.9939271211624146, "eval/reward_neg_loss": 0.0640379935503006, "eval/reward_pos_acc": 0.8055555820465088, "eval/reward_pos_loss": 2.1966488361358643, "eval/reward_pred": 0.02348950132727623, "eval/reward_rate": 0.03515625, "replay/size": 453049.0, "replay/inserts": 7740.0, "replay/samples": 30960.0, "replay/insert_wait_avg": 1.5111240613676165e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.362097732780516e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 94064.0, "eval_replay/inserts": 2272.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.199858289369395e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.599592208862305e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1557731628418, "timer/env.step_count": 968.0, "timer/env.step_total": 85.51653957366943, "timer/env.step_frac": 0.08550322046658419, "timer/env.step_avg": 0.0883435326174271, "timer/env.step_min": 0.02307891845703125, "timer/env.step_max": 4.069617033004761, "timer/replay._sample_count": 30960.0, "timer/replay._sample_total": 15.073371171951294, "timer/replay._sample_frac": 0.01507102351095173, "timer/replay._sample_avg": 0.0004868659939260754, "timer/replay._sample_min": 0.0003337860107421875, "timer/replay._sample_max": 0.010470867156982422, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1252.0, "timer/agent.policy_total": 20.08411979675293, "timer/agent.policy_frac": 0.020080991717160147, "timer/agent.policy_avg": 0.01604162923063333, "timer/agent.policy_min": 0.009623050689697266, "timer/agent.policy_max": 0.08317852020263672, "timer/dataset_train_count": 1935.0, "timer/dataset_train_total": 0.3124117851257324, "timer/dataset_train_frac": 0.00031236312733343255, "timer/dataset_train_avg": 0.00016145311892802708, "timer/dataset_train_min": 8.988380432128906e-05, "timer/dataset_train_max": 0.023452281951904297, "timer/agent.train_count": 1935.0, "timer/agent.train_total": 857.2858130931854, "timer/agent.train_frac": 0.8571522917696593, "timer/agent.train_avg": 0.44304176387244726, "timer/agent.train_min": 0.4247558116912842, "timer/agent.train_max": 0.9937353134155273, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.473482608795166, "timer/agent.report_frac": 0.00047340886439904125, "timer/agent.report_avg": 0.236741304397583, "timer/agent.report_min": 0.2305009365081787, "timer/agent.report_max": 0.2429816722869873, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9802322387695312e-05, "timer/dataset_eval_frac": 2.9797680708725964e-08, "timer/dataset_eval_avg": 2.9802322387695312e-05, "timer/dataset_eval_min": 2.9802322387695312e-05, "timer/dataset_eval_max": 2.9802322387695312e-05, "fps": 7.738674470738413}
{"step": 453840, "time": 58391.35221147537, "episode/length": 62.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 454184, "time": 58432.5411632061, "episode/length": 178.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 454288, "time": 58446.039875268936, "episode/length": 166.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 454296, "time": 58448.5148024559, "episode/length": 172.0, "episode/score": 6.1000000461936, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 454576, "time": 58482.52924513817, "episode/length": 222.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.968609865470852, "episode/intrinsic_return": 0.0}
{"step": 454768, "time": 58506.433410167694, "episode/length": 226.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 454936, "time": 58527.933423519135, "episode/length": 206.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 455352, "time": 58577.71090388298, "episode/length": 188.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 455600, "time": 58607.720754146576, "episode/length": 365.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 456040, "time": 58660.307540655136, "episode/length": 218.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 456104, "time": 58669.63497662544, "episode/length": 190.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 456160, "time": 58677.56092429161, "episode/length": 173.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 456320, "time": 58697.66080355644, "episode/length": 266.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9850187265917603, "episode/intrinsic_return": 0.0}
{"step": 456408, "time": 58709.25244617462, "episode/length": 183.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 456592, "time": 58731.89583683014, "episode/length": 286.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 457064, "time": 58787.839982271194, "episode/length": 119.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9916666666666667, "episode/intrinsic_return": 0.0}
{"step": 457360, "time": 58823.62823319435, "episode/length": 164.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 457368, "time": 58826.58372139931, "episode/length": 251.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 457560, "time": 58850.71173262596, "episode/length": 143.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9583333333333334, "episode/intrinsic_return": 0.0}
{"step": 457632, "time": 58861.84255814552, "episode/length": 253.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9724409448818898, "episode/intrinsic_return": 0.0}
{"step": 457872, "time": 58890.98955464363, "episode/length": 193.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 458080, "time": 58916.51794075966, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 458136, "time": 58924.53894114494, "episode/length": 71.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9861111111111112, "episode/intrinsic_return": 0.0}
{"step": 458616, "time": 58981.53653025627, "episode/length": 306.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9804560260586319, "episode/intrinsic_return": 0.0}
{"step": 458984, "time": 59027.3063480854, "episode/length": 201.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 459088, "time": 59040.824704647064, "episode/length": 252.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9841897233201581, "episode/intrinsic_return": 0.0}
{"step": 459192, "time": 59054.497941970825, "episode/length": 228.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9737991266375546, "episode/intrinsic_return": 0.0}
{"step": 459408, "time": 59080.9134619236, "episode/length": 191.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9635416666666666, "episode/intrinsic_return": 0.0}
{"step": 459688, "time": 59114.763879776, "episode/length": 200.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 459736, "time": 59121.69959068298, "episode/length": 139.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 460032, "time": 59157.38776445389, "episode/length": 299.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9966666666666667, "episode/intrinsic_return": 0.0}
{"step": 460096, "time": 59180.20721578598, "eval_episode/length": 46.0, "eval_episode/score": 6.100000023841858, "eval_episode/reward_rate": 0.9787234042553191}
{"step": 460096, "time": 59182.0970928669, "eval_episode/length": 56.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9824561403508771}
{"step": 460096, "time": 59187.935505628586, "eval_episode/length": 163.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9573170731707317}
{"step": 460096, "time": 59187.94388961792, "eval_episode/length": 163.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9695121951219512}
{"step": 460096, "time": 59193.54605126381, "eval_episode/length": 203.0, "eval_episode/score": 9.100000023841858, "eval_episode/reward_rate": 0.9950980392156863}
{"step": 460096, "time": 59195.25591182709, "eval_episode/length": 209.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9761904761904762}
{"step": 460096, "time": 59200.38593029976, "eval_episode/length": 249.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.984}
{"step": 460096, "time": 59203.039632081985, "eval_episode/length": 160.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9937888198757764}
{"step": 460656, "time": 59267.980229854584, "episode/length": 208.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 460872, "time": 59294.535287857056, "episode/length": 182.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9672131147540983, "episode/intrinsic_return": 0.0}
{"step": 460976, "time": 59307.872841119766, "episode/length": 235.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9788135593220338, "episode/intrinsic_return": 0.0}
{"step": 460992, "time": 59311.21220755577, "episode/length": 156.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9617834394904459, "episode/intrinsic_return": 0.0}
{"step": 461240, "time": 59341.434611558914, "episode/length": 193.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 461365, "time": 59358.30773615837, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.404577761280294, "train/action_min": 0.0, "train/action_std": 3.06900582508165, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04399357645829417, "train/actor_opt_grad_steps": 113975.0, "train/actor_opt_loss": -10.78884428321403, "train/adv_mag": 0.44275716114409114, "train/adv_max": 0.4179505906542953, "train/adv_mean": 0.002675797472093387, "train/adv_min": -0.37314216701351866, "train/adv_std": 0.05469578582489369, "train/cont_avg": 0.9947086256377551, "train/cont_loss_mean": 8.880422067218136e-05, "train/cont_loss_std": 0.0026184209178442257, "train/cont_neg_acc": 0.9956997088631805, "train/cont_neg_loss": 0.019543371500754355, "train/cont_pos_acc": 0.9999999826659962, "train/cont_pos_loss": 2.6111977531945277e-05, "train/cont_pred": 0.994703756911414, "train/cont_rate": 0.9947086256377551, "train/dyn_loss_mean": 6.863226725130665, "train/dyn_loss_std": 8.931260274381053, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.111112464751516, "train/extr_critic_critic_opt_grad_steps": 113975.0, "train/extr_critic_critic_opt_loss": 16950.699089205995, "train/extr_critic_mag": 9.006766805843432, "train/extr_critic_max": 9.006766805843432, "train/extr_critic_mean": 2.1242104203117136, "train/extr_critic_min": -0.5673664802191208, "train/extr_critic_std": 2.1229528815162424, "train/extr_return_normed_mag": 1.5044685285918566, "train/extr_return_normed_max": 1.5044685285918566, "train/extr_return_normed_mean": 0.3518078045881524, "train/extr_return_normed_min": -0.09533254041963694, "train/extr_return_normed_std": 0.32318891554462664, "train/extr_return_rate": 0.6976546257430193, "train/extr_return_raw_mag": 9.835884624597977, "train/extr_return_raw_max": 9.835884624597977, "train/extr_return_raw_mean": 2.142086643345502, "train/extr_return_raw_min": -0.8425066414840368, "train/extr_return_raw_std": 2.157589072475628, "train/extr_reward_mag": 1.0438472166353343, "train/extr_reward_max": 1.0438472166353343, "train/extr_reward_mean": 0.044638162041653176, "train/extr_reward_min": -0.6798753245752684, "train/extr_reward_std": 0.20636288464373473, "train/image_loss_mean": 3.8022402014051164, "train/image_loss_std": 8.613371995030617, "train/model_loss_mean": 7.971520479844541, "train/model_loss_std": 12.789280696791046, "train/model_opt_grad_norm": 41.210822903380105, "train/model_opt_grad_steps": 113876.29591836735, "train/model_opt_loss": 12637.932315748565, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1594.3877551020407, "train/policy_entropy_mag": 2.5487220907697874, "train/policy_entropy_max": 2.5487220907697874, "train/policy_entropy_mean": 0.4346676853542425, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.5980412593605567, "train/policy_logprob_mag": 7.43838413150943, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.43423133860437235, "train/policy_logprob_min": -7.43838413150943, "train/policy_logprob_std": 1.0453488756807483, "train/policy_randomness_mag": 0.899587052513142, "train/policy_randomness_max": 0.899587052513142, "train/policy_randomness_mean": 0.15341861732304096, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.21108232218087936, "train/post_ent_mag": 59.06810055946817, "train/post_ent_max": 59.06810055946817, "train/post_ent_mean": 42.538972465359436, "train/post_ent_min": 19.877448247403514, "train/post_ent_std": 6.76940515819861, "train/prior_ent_mag": 75.77073420310506, "train/prior_ent_max": 75.77073420310506, "train/prior_ent_mean": 49.38526585637307, "train/prior_ent_min": 29.720567790829406, "train/prior_ent_std": 7.362373753469818, "train/rep_loss_mean": 6.863226725130665, "train/rep_loss_std": 8.931260274381053, "train/reward_avg": 0.03294901922820326, "train/reward_loss_mean": 0.05125553521080589, "train/reward_loss_std": 0.2113789447716304, "train/reward_max_data": 1.0173469429113426, "train/reward_max_pred": 1.0163655098603697, "train/reward_neg_acc": 0.9941310976841011, "train/reward_neg_loss": 0.023866676568642865, "train/reward_pos_acc": 0.9857982281519442, "train/reward_pos_loss": 0.7511319265681871, "train/reward_pred": 0.032555251025917886, "train/reward_rate": 0.037697305484693876, "train_stats/sum_log_reward": 8.127777894337973, "train_stats/max_log_achievement_collect_coal": 0.5, "train_stats/max_log_achievement_collect_drink": 4.027777777777778, "train_stats/max_log_achievement_collect_sapling": 1.3055555555555556, "train_stats/max_log_achievement_collect_stone": 10.055555555555555, "train_stats/max_log_achievement_collect_wood": 5.583333333333333, "train_stats/max_log_achievement_defeat_skeleton": 0.027777777777777776, "train_stats/max_log_achievement_defeat_zombie": 0.25, "train_stats/max_log_achievement_eat_cow": 0.027777777777777776, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.0277777777777777, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_furnace": 1.3055555555555556, "train_stats/max_log_achievement_place_plant": 1.2222222222222223, "train_stats/max_log_achievement_place_stone": 3.111111111111111, "train_stats/max_log_achievement_place_table": 2.0, "train_stats/max_log_achievement_wake_up": 1.9722222222222223, "train_stats/mean_log_entropy": 0.42472606814569897, "eval_stats/sum_log_reward": 7.225000202655792, "eval_stats/max_log_achievement_collect_coal": 0.25, "eval_stats/max_log_achievement_collect_drink": 4.75, "eval_stats/max_log_achievement_collect_sapling": 1.0, "eval_stats/max_log_achievement_collect_stone": 7.875, "eval_stats/max_log_achievement_collect_wood": 5.0, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.375, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.875, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 1.0, "eval_stats/max_log_achievement_place_plant": 0.875, "eval_stats/max_log_achievement_place_stone": 2.25, "eval_stats/max_log_achievement_place_table": 1.875, "eval_stats/max_log_achievement_wake_up": 1.625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 1.8511291273171082e-06, "report/cont_loss_std": 2.2097996406955644e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.4107422430242877e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 1.8030650608125143e-06, "report/cont_pred": 0.9960920810699463, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 5.9953460693359375, "report/dyn_loss_std": 8.346277236938477, "report/image_loss_mean": 3.169520378112793, "report/image_loss_std": 6.216800689697266, "report/model_loss_mean": 6.814296722412109, "report/model_loss_std": 10.310876846313477, "report/post_ent_mag": 58.08055114746094, "report/post_ent_max": 58.08055114746094, "report/post_ent_mean": 43.43678283691406, "report/post_ent_min": 20.869525909423828, "report/post_ent_std": 6.599052906036377, "report/prior_ent_mag": 75.70184326171875, "report/prior_ent_max": 75.70184326171875, "report/prior_ent_mean": 49.774925231933594, "report/prior_ent_min": 30.523860931396484, "report/prior_ent_std": 7.163313865661621, "report/rep_loss_mean": 5.9953460693359375, "report/rep_loss_std": 8.346277236938477, "report/reward_avg": 0.04374999925494194, "report/reward_loss_mean": 0.04756687581539154, "report/reward_loss_std": 0.17113910615444183, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0032844543457031, "report/reward_neg_acc": 0.9989754557609558, "report/reward_neg_loss": 0.016617627814412117, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6768683791160583, "report/reward_pred": 0.04408150538802147, "report/reward_rate": 0.046875, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.002105817198753357, "eval/cont_loss_std": 0.06697212159633636, "eval/cont_neg_acc": 0.75, "eval/cont_neg_loss": 0.5366363525390625, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 9.619013326300774e-06, "eval/cont_pred": 0.9969487190246582, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 20.639015197753906, "eval/dyn_loss_std": 12.57840633392334, "eval/image_loss_mean": 18.015230178833008, "eval/image_loss_std": 20.997085571289062, "eval/model_loss_mean": 30.558664321899414, "eval/model_loss_std": 25.827119827270508, "eval/post_ent_mag": 57.56938934326172, "eval/post_ent_max": 57.56938934326172, "eval/post_ent_mean": 39.04766845703125, "eval/post_ent_min": 20.49837875366211, "eval/post_ent_std": 6.340251445770264, "eval/prior_ent_mag": 75.70184326171875, "eval/prior_ent_max": 75.70184326171875, "eval/prior_ent_mean": 52.034149169921875, "eval/prior_ent_min": 33.796302795410156, "eval/prior_ent_std": 6.056196689605713, "eval/rep_loss_mean": 20.639015197753906, "eval/rep_loss_std": 12.57840633392334, "eval/reward_avg": 0.03564453125, "eval/reward_loss_mean": 0.15791752934455872, "eval/reward_loss_std": 0.9227805733680725, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0012109279632568, "eval/reward_neg_acc": 0.9898374676704407, "eval/reward_neg_loss": 0.05685989558696747, "eval/reward_pos_acc": 0.699999988079071, "eval/reward_pos_loss": 2.643934965133667, "eval/reward_pred": 0.02821091189980507, "eval/reward_rate": 0.0390625, "replay/size": 460861.0, "replay/inserts": 7812.0, "replay/samples": 31248.0, "replay/insert_wait_avg": 1.5318668383057767e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.381759053673185e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 96664.0, "eval_replay/inserts": 2600.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1333135458139272e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.152557373046875e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.053941488266, "timer/env.step_count": 976.0, "timer/env.step_total": 82.05786895751953, "timer/env.step_frac": 0.08205344287269363, "timer/env.step_avg": 0.0840756854072946, "timer/env.step_min": 0.02313089370727539, "timer/env.step_max": 2.0731258392333984, "timer/replay._sample_count": 31248.0, "timer/replay._sample_total": 15.357535123825073, "timer/replay._sample_frac": 0.015356706760207563, "timer/replay._sample_avg": 0.0004914725782074076, "timer/replay._sample_min": 0.0004050731658935547, "timer/replay._sample_max": 0.030920028686523438, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1301.0, "timer/agent.policy_total": 20.601836442947388, "timer/agent.policy_frac": 0.020600725209170247, "timer/agent.policy_avg": 0.015835385428860406, "timer/agent.policy_min": 0.009104013442993164, "timer/agent.policy_max": 0.07626724243164062, "timer/dataset_train_count": 1953.0, "timer/dataset_train_total": 0.29512548446655273, "timer/dataset_train_frac": 0.00029510956581737103, "timer/dataset_train_avg": 0.00015111391933771262, "timer/dataset_train_min": 9.322166442871094e-05, "timer/dataset_train_max": 0.0012161731719970703, "timer/agent.train_count": 1953.0, "timer/agent.train_total": 862.5112054347992, "timer/agent.train_frac": 0.8624646828062318, "timer/agent.train_avg": 0.44163400175872974, "timer/agent.train_min": 0.42905402183532715, "timer/agent.train_max": 1.7014307975769043, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4717113971710205, "timer/agent.report_frac": 0.00047168595372868225, "timer/agent.report_avg": 0.23585569858551025, "timer/agent.report_min": 0.2285597324371338, "timer/agent.report_max": 0.24315166473388672, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7418136596679688e-05, "timer/dataset_eval_frac": 2.7416657701359996e-08, "timer/dataset_eval_avg": 2.7418136596679688e-05, "timer/dataset_eval_min": 2.7418136596679688e-05, "timer/dataset_eval_max": 2.7418136596679688e-05, "fps": 7.811464906876504}
{"step": 461408, "time": 59363.21832203865, "episode/length": 408.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9975550122249389, "episode/intrinsic_return": 0.0}
{"step": 461800, "time": 59410.636415958405, "episode/length": 325.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9846625766871165, "episode/intrinsic_return": 0.0}
{"step": 462136, "time": 59451.19155335426, "episode/length": 184.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 462176, "time": 59457.26011586189, "episode/length": 149.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 462288, "time": 59471.84760212898, "episode/length": 281.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 462448, "time": 59491.92225456238, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 462808, "time": 59535.32722377777, "episode/length": 241.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9834710743801653, "episode/intrinsic_return": 0.0}
{"step": 463128, "time": 59574.24981069565, "episode/length": 165.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 463696, "time": 59642.08092093468, "episode/length": 175.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 463832, "time": 59659.51912641525, "episode/length": 206.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 464112, "time": 59693.625217199326, "episode/length": 34.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.8571428571428571, "episode/intrinsic_return": 0.0}
{"step": 464224, "time": 59708.17239546776, "episode/length": 260.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9961685823754789, "episode/intrinsic_return": 0.0}
{"step": 464664, "time": 59760.973016023636, "episode/length": 276.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9855595667870036, "episode/intrinsic_return": 0.0}
{"step": 464672, "time": 59763.363517045975, "episode/length": 232.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9785407725321889, "episode/intrinsic_return": 0.0}
{"step": 464848, "time": 59785.31103396416, "episode/length": 450.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9800443458980045, "episode/intrinsic_return": 0.0}
{"step": 464960, "time": 59799.839128017426, "episode/length": 443.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9977477477477478, "episode/intrinsic_return": 0.0}
{"step": 465016, "time": 59807.96119880676, "episode/length": 42.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 465448, "time": 59860.00303411484, "episode/length": 218.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 465520, "time": 59869.86382675171, "episode/length": 175.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 465896, "time": 59915.08561491966, "episode/length": 153.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 466048, "time": 59934.285120010376, "episode/length": 227.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9868421052631579, "episode/intrinsic_return": 0.0}
{"step": 466120, "time": 59944.14902591705, "episode/length": 373.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9973262032085561, "episode/intrinsic_return": 0.0}
{"step": 466552, "time": 59996.06276869774, "episode/length": 191.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 466584, "time": 60001.32607936859, "episode/length": 216.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 466720, "time": 60018.789167165756, "episode/length": 149.0, "episode/score": 9.100000038743019, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 466736, "time": 60022.146156311035, "episode/length": 221.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 467192, "time": 60078.261798381805, "episode/length": 58.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 467960, "time": 60170.217275857925, "episode/length": 171.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 468056, "time": 60182.98025274277, "episode/length": 250.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9840637450199203, "episode/intrinsic_return": 0.0}
{"step": 468200, "time": 60201.89735841751, "episode/length": 182.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 468720, "time": 60264.68903660774, "episode/length": 324.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9907692307692307, "episode/intrinsic_return": 0.0}
{"step": 468720, "time": 60264.699833869934, "episode/length": 270.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.985239852398524, "episode/intrinsic_return": 0.0}
{"step": 468784, "time": 60275.5759871006, "episode/length": 360.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9944598337950139, "episode/intrinsic_return": 0.0}
{"step": 468880, "time": 60288.7200615406, "episode/length": 428.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9906759906759907, "episode/intrinsic_return": 0.0}
{"step": 469224, "time": 60330.40709853172, "episode/length": 253.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9960629921259843, "episode/intrinsic_return": 0.0}
{"step": 469232, "time": 60332.89128947258, "episode/length": 43.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 469433, "time": 60358.65039086342, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.4411001632462686, "train/action_min": 0.0, "train/action_std": 3.0774690428776528, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04360922222113728, "train/actor_opt_grad_steps": 115960.0, "train/actor_opt_loss": -12.109912498080316, "train/adv_mag": 0.4478320725521638, "train/adv_max": 0.4177957257228111, "train/adv_mean": 0.0021907154715716305, "train/adv_min": -0.3788661122025542, "train/adv_std": 0.05469437364247901, "train/cont_avg": 0.9945535991915423, "train/cont_loss_mean": 0.0001592178886188317, "train/cont_loss_std": 0.00483282422079351, "train/cont_neg_acc": 0.9938087347728103, "train/cont_neg_loss": 0.021752429349785576, "train/cont_pos_acc": 0.9999950744619417, "train/cont_pos_loss": 4.2318561076487656e-05, "train/cont_pred": 0.9945689807483806, "train/cont_rate": 0.9945535991915423, "train/dyn_loss_mean": 6.801599585594823, "train/dyn_loss_std": 8.938458729739214, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1380183928048433, "train/extr_critic_critic_opt_grad_steps": 115960.0, "train/extr_critic_critic_opt_loss": 16838.420121074316, "train/extr_critic_mag": 8.906329093287834, "train/extr_critic_max": 8.906329093287834, "train/extr_critic_mean": 2.159266063823036, "train/extr_critic_min": -0.5820046562460525, "train/extr_critic_std": 2.1121864443394673, "train/extr_return_normed_mag": 1.5047328952533097, "train/extr_return_normed_max": 1.5047328952533097, "train/extr_return_normed_mean": 0.3606138875087102, "train/extr_return_normed_min": -0.10749488292419496, "train/extr_return_normed_std": 0.32664436346559383, "train/extr_return_rate": 0.7060116441985268, "train/extr_return_raw_mag": 9.687092800045487, "train/extr_return_raw_max": 9.687092800045487, "train/extr_return_raw_mean": 2.1736490299452598, "train/extr_return_raw_min": -0.9007309733042076, "train/extr_return_raw_std": 2.145083107165436, "train/extr_reward_mag": 1.0422732047180632, "train/extr_reward_max": 1.0422732047180632, "train/extr_reward_mean": 0.044240376759153696, "train/extr_reward_min": -0.6961156361138643, "train/extr_reward_std": 0.20582795172781493, "train/image_loss_mean": 3.8315260914427722, "train/image_loss_std": 8.916040050449656, "train/model_loss_mean": 7.964178014157423, "train/model_loss_std": 13.05120011704478, "train/model_opt_grad_norm": 40.95101344170262, "train/model_opt_grad_steps": 115860.02985074627, "train/model_opt_loss": 14973.673587628266, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1878.1094527363184, "train/policy_entropy_mag": 2.5326581973934648, "train/policy_entropy_max": 2.5326581973934648, "train/policy_entropy_mean": 0.43419021471815916, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.5990500522786705, "train/policy_logprob_mag": 7.438384122516386, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.4336617950776323, "train/policy_logprob_min": -7.438384122516386, "train/policy_logprob_std": 1.044440656455595, "train/policy_randomness_mag": 0.8939172023564429, "train/policy_randomness_max": 0.8939172023564429, "train/policy_randomness_mean": 0.15325009137095502, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.21143838029299208, "train/post_ent_mag": 59.40859956883673, "train/post_ent_max": 59.40859956883673, "train/post_ent_mean": 42.56376133629339, "train/post_ent_min": 19.74667337521985, "train/post_ent_std": 6.822632002000192, "train/prior_ent_mag": 75.82748257461472, "train/prior_ent_max": 75.82748257461472, "train/prior_ent_mean": 49.35069003508459, "train/prior_ent_min": 29.683292455341093, "train/prior_ent_std": 7.441441028272335, "train/rep_loss_mean": 6.801599585594823, "train/rep_loss_std": 8.938458729739214, "train/reward_avg": 0.03314287912804837, "train/reward_loss_mean": 0.05153295305089571, "train/reward_loss_std": 0.21626936677676528, "train/reward_max_data": 1.0174129394749505, "train/reward_max_pred": 1.0143423471877824, "train/reward_neg_acc": 0.994465220033826, "train/reward_neg_loss": 0.023784570076238753, "train/reward_pos_acc": 0.9827072030276208, "train/reward_pos_loss": 0.7571932878067245, "train/reward_pred": 0.03269467615888486, "train/reward_rate": 0.03792560634328358, "train_stats/sum_log_reward": 8.211111297210058, "train_stats/max_log_achievement_collect_coal": 0.9166666666666666, "train_stats/max_log_achievement_collect_drink": 4.888888888888889, "train_stats/max_log_achievement_collect_sapling": 1.5277777777777777, "train_stats/max_log_achievement_collect_stone": 13.666666666666666, "train_stats/max_log_achievement_collect_wood": 5.277777777777778, "train_stats/max_log_achievement_defeat_skeleton": 0.027777777777777776, "train_stats/max_log_achievement_defeat_zombie": 0.16666666666666666, "train_stats/max_log_achievement_eat_cow": 0.027777777777777776, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.2222222222222223, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_furnace": 1.7777777777777777, "train_stats/max_log_achievement_place_plant": 1.4444444444444444, "train_stats/max_log_achievement_place_stone": 4.805555555555555, "train_stats/max_log_achievement_place_table": 1.8055555555555556, "train_stats/max_log_achievement_wake_up": 2.388888888888889, "train_stats/mean_log_entropy": 0.4971681344840262, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 4.3944117351202294e-05, "report/cont_loss_std": 0.0001550851302454248, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0003941236063838005, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 4.2225867218803614e-05, "report/cont_pred": 0.9950771331787109, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 5.68625020980835, "report/dyn_loss_std": 8.854541778564453, "report/image_loss_mean": 4.208261489868164, "report/image_loss_std": 12.005600929260254, "report/model_loss_mean": 7.675593376159668, "report/model_loss_std": 15.517817497253418, "report/post_ent_mag": 60.77677917480469, "report/post_ent_max": 60.77677917480469, "report/post_ent_mean": 44.31340026855469, "report/post_ent_min": 21.301504135131836, "report/post_ent_std": 7.088253974914551, "report/prior_ent_mag": 75.77023315429688, "report/prior_ent_max": 75.77023315429688, "report/prior_ent_mean": 49.86623764038086, "report/prior_ent_min": 31.956281661987305, "report/prior_ent_std": 7.60806131362915, "report/rep_loss_mean": 5.68625020980835, "report/rep_loss_std": 8.854541778564453, "report/reward_avg": 0.02324218861758709, "report/reward_loss_mean": 0.055538203567266464, "report/reward_loss_std": 0.25773885846138, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.003000259399414, "report/reward_neg_acc": 0.9869346618652344, "report/reward_neg_loss": 0.02832811325788498, "report/reward_pos_acc": 0.8965517282485962, "report/reward_pos_loss": 0.989125669002533, "report/reward_pred": 0.020785771310329437, "report/reward_rate": 0.0283203125, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 3.609446866903454e-05, "eval/cont_loss_std": 0.0002469989995006472, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.001035513123497367, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 3.315787762403488e-05, "eval/cont_pred": 0.997040331363678, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 19.929481506347656, "eval/dyn_loss_std": 12.628189086914062, "eval/image_loss_mean": 21.37293815612793, "eval/image_loss_std": 21.26801109313965, "eval/model_loss_mean": 33.472537994384766, "eval/model_loss_std": 26.606531143188477, "eval/post_ent_mag": 54.60943603515625, "eval/post_ent_max": 54.60943603515625, "eval/post_ent_mean": 40.05731201171875, "eval/post_ent_min": 18.832199096679688, "eval/post_ent_std": 6.733165264129639, "eval/prior_ent_mag": 75.77023315429688, "eval/prior_ent_max": 75.77023315429688, "eval/prior_ent_mean": 53.3603630065918, "eval/prior_ent_min": 32.946441650390625, "eval/prior_ent_std": 6.248931884765625, "eval/rep_loss_mean": 19.929481506347656, "eval/rep_loss_std": 12.628189086914062, "eval/reward_avg": 0.033203125, "eval/reward_loss_mean": 0.1418764740228653, "eval/reward_loss_std": 0.856870710849762, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0011682510375977, "eval/reward_neg_acc": 0.9888325333595276, "eval/reward_neg_loss": 0.09594365209341049, "eval/reward_pos_acc": 0.9487179517745972, "eval/reward_pos_loss": 1.3019747734069824, "eval/reward_pred": 0.032704468816518784, "eval/reward_rate": 0.0380859375, "replay/size": 468929.0, "replay/inserts": 8068.0, "replay/samples": 32272.0, "replay/insert_wait_avg": 1.545849565119216e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.41275514064594e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 96664.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 8.195638656616211e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3306069374084, "timer/env.step_count": 1009.0, "timer/env.step_total": 82.49097418785095, "timer/env.step_frac": 0.0824637111128726, "timer/env.step_avg": 0.08175517758954505, "timer/env.step_min": 0.02318739891052246, "timer/env.step_max": 3.3324038982391357, "timer/replay._sample_count": 32272.0, "timer/replay._sample_total": 15.780843496322632, "timer/replay._sample_frac": 0.015775627964275667, "timer/replay._sample_avg": 0.0004889949025880836, "timer/replay._sample_min": 0.0003676414489746094, "timer/replay._sample_max": 0.010996580123901367, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1009.0, "timer/agent.policy_total": 16.026082038879395, "timer/agent.policy_frac": 0.016020785456064886, "timer/agent.policy_avg": 0.015883133834370063, "timer/agent.policy_min": 0.00961923599243164, "timer/agent.policy_max": 0.07236099243164062, "timer/dataset_train_count": 2017.0, "timer/dataset_train_total": 0.30256056785583496, "timer/dataset_train_frac": 0.0003024605722923426, "timer/dataset_train_avg": 0.00015000523939307634, "timer/dataset_train_min": 9.369850158691406e-05, "timer/dataset_train_max": 0.0004940032958984375, "timer/agent.train_count": 2017.0, "timer/agent.train_total": 898.6786029338837, "timer/agent.train_frac": 0.898381591747212, "timer/agent.train_avg": 0.44555210854431515, "timer/agent.train_min": 0.43295836448669434, "timer/agent.train_max": 0.9733438491821289, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4761052131652832, "timer/agent.report_frac": 0.00047594786150042645, "timer/agent.report_avg": 0.2380526065826416, "timer/agent.report_min": 0.23034095764160156, "timer/agent.report_max": 0.24576425552368164, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.6464462280273438e-05, "timer/dataset_eval_frac": 2.645571583708359e-08, "timer/dataset_eval_avg": 2.6464462280273438e-05, "timer/dataset_eval_min": 2.6464462280273438e-05, "timer/dataset_eval_max": 2.6464462280273438e-05, "fps": 8.065217557398881}
{"step": 469480, "time": 60363.98223376274, "episode/length": 159.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.98125, "episode/intrinsic_return": 0.0}
{"step": 469504, "time": 60368.23858690262, "episode/length": 192.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 469944, "time": 60420.66904902458, "episode/length": 144.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9724137931034482, "episode/intrinsic_return": 0.0}
{"step": 470048, "time": 60434.296345472336, "episode/length": 165.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 470080, "time": 60453.56247138977, "eval_episode/length": 45.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9782608695652174}
{"step": 470080, "time": 60461.71413564682, "eval_episode/length": 162.0, "eval_episode/score": 10.100000023841858, "eval_episode/reward_rate": 0.9938650306748467}
{"step": 470080, "time": 60464.06279373169, "eval_episode/length": 169.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 470080, "time": 60466.226383924484, "eval_episode/length": 175.0, "eval_episode/score": 6.100000023841858, "eval_episode/reward_rate": 0.9943181818181818}
{"step": 470080, "time": 60468.194944381714, "eval_episode/length": 176.0, "eval_episode/score": 9.100000023841858, "eval_episode/reward_rate": 0.9943502824858758}
{"step": 470080, "time": 60471.643323898315, "eval_episode/length": 205.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9951456310679612}
{"step": 470080, "time": 60474.21291732788, "eval_episode/length": 215.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9629629629629629}
{"step": 470080, "time": 60479.50045752525, "eval_episode/length": 241.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9793388429752066}
{"step": 470104, "time": 60482.29771232605, "episode/length": 172.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 470384, "time": 60516.209335803986, "episode/length": 144.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 470440, "time": 60524.9158911705, "episode/length": 297.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9798657718120806, "episode/intrinsic_return": 0.0}
{"step": 470472, "time": 60530.65890312195, "episode/length": 154.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9612903225806452, "episode/intrinsic_return": 0.0}
{"step": 471184, "time": 60614.58813333511, "episode/length": 209.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 471200, "time": 60617.91676282883, "episode/length": 214.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9813953488372092, "episode/intrinsic_return": 0.0}
{"step": 471312, "time": 60632.40397429466, "episode/length": 170.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 471536, "time": 60659.7825357914, "episode/length": 143.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 471544, "time": 60662.22340679169, "episode/length": 179.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 471584, "time": 60668.40268731117, "episode/length": 138.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9640287769784173, "episode/intrinsic_return": 0.0}
{"step": 471648, "time": 60677.474244594574, "episode/length": 150.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9536423841059603, "episode/intrinsic_return": 0.0}
{"step": 471664, "time": 60680.739809036255, "episode/length": 201.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 472424, "time": 60770.438779592514, "episode/length": 154.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 472736, "time": 60808.34492278099, "episode/length": 191.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 472984, "time": 60838.905299663544, "episode/length": 166.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 473160, "time": 60861.68249797821, "episode/length": 201.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 473232, "time": 60872.13779902458, "episode/length": 100.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9900990099009901, "episode/intrinsic_return": 0.0}
{"step": 473400, "time": 60893.22723531723, "episode/length": 232.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9785407725321889, "episode/intrinsic_return": 0.0}
{"step": 473512, "time": 60907.6190135479, "episode/length": 240.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.983402489626556, "episode/intrinsic_return": 0.0}
{"step": 473632, "time": 60923.03341627121, "episode/length": 289.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.996551724137931, "episode/intrinsic_return": 0.0}
{"step": 474168, "time": 60987.16811013222, "episode/length": 312.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9936102236421726, "episode/intrinsic_return": 0.0}
{"step": 474200, "time": 60992.43473529816, "episode/length": 151.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 474768, "time": 61059.651844739914, "episode/length": 191.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 474816, "time": 61066.85587334633, "episode/length": 162.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 475088, "time": 61099.88445329666, "episode/length": 293.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 475376, "time": 61136.075323581696, "episode/length": 150.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 475416, "time": 61142.409282684326, "episode/length": 151.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 475424, "time": 61144.80706167221, "episode/length": 252.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9723320158102767, "episode/intrinsic_return": 0.0}
{"step": 475648, "time": 61172.56834959984, "episode/length": 310.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9903536977491961, "episode/intrinsic_return": 0.0}
{"step": 475648, "time": 61172.576372385025, "episode/length": 251.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.996031746031746, "episode/intrinsic_return": 0.0}
{"step": 476432, "time": 61266.8327498436, "episode/length": 207.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 476512, "time": 61277.586443424225, "episode/length": 141.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9647887323943662, "episode/intrinsic_return": 0.0}
{"step": 476584, "time": 61287.36610531807, "episode/length": 186.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 476592, "time": 61289.70736122131, "episode/length": 146.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9591836734693877, "episode/intrinsic_return": 0.0}
{"step": 476712, "time": 61305.27891921997, "episode/length": 160.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 476792, "time": 61316.027653217316, "episode/length": 34.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.8857142857142857, "episode/intrinsic_return": 0.0}
{"step": 477024, "time": 61344.449647426605, "episode/length": 171.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 477121, "time": 61358.777913570404, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.501861730387791, "train/action_min": 0.0, "train/action_std": 3.165757803101614, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.043337074373824606, "train/actor_opt_grad_steps": 117930.0, "train/actor_opt_loss": -13.289724078511945, "train/adv_mag": 0.4435627329225985, "train/adv_max": 0.40718556361494906, "train/adv_mean": 0.002240375891633825, "train/adv_min": -0.37800798267898167, "train/adv_std": 0.05405503364733464, "train/cont_avg": 0.994641556023316, "train/cont_loss_mean": 0.0001256059636231811, "train/cont_loss_std": 0.0037860152636093576, "train/cont_neg_acc": 0.9940640685471847, "train/cont_neg_loss": 0.014835297600248789, "train/cont_pos_acc": 0.9999897998849345, "train/cont_pos_loss": 3.321465126332842e-05, "train/cont_pred": 0.9946503200679245, "train/cont_rate": 0.994641556023316, "train/dyn_loss_mean": 6.7807282932064075, "train/dyn_loss_std": 8.880795535645955, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1093037193303281, "train/extr_critic_critic_opt_grad_steps": 117930.0, "train/extr_critic_critic_opt_loss": 16791.911932278173, "train/extr_critic_mag": 8.850488628130503, "train/extr_critic_max": 8.850488628130503, "train/extr_critic_mean": 2.057745750086295, "train/extr_critic_min": -0.5704930433955218, "train/extr_critic_std": 2.0766880654300435, "train/extr_return_normed_mag": 1.5054626501903632, "train/extr_return_normed_max": 1.5054626501903632, "train/extr_return_normed_mean": 0.34939386537346817, "train/extr_return_normed_min": -0.10035879428406762, "train/extr_return_normed_std": 0.3229708361965387, "train/extr_return_rate": 0.6930949477951761, "train/extr_return_raw_mag": 9.629963039734204, "train/extr_return_raw_max": 9.629963039734204, "train/extr_return_raw_mean": 2.072412455637838, "train/extr_return_raw_min": -0.8675614521293442, "train/extr_return_raw_std": 2.111279955182051, "train/extr_reward_mag": 1.0412532974401287, "train/extr_reward_max": 1.0412532974401287, "train/extr_reward_mean": 0.04408151174803781, "train/extr_reward_min": -0.6879755629159008, "train/extr_reward_std": 0.20572724876626167, "train/image_loss_mean": 3.7201690414408946, "train/image_loss_std": 8.43188541293762, "train/model_loss_mean": 7.839984893798828, "train/model_loss_std": 12.593627988983313, "train/model_opt_grad_norm": 41.000959108273186, "train/model_opt_grad_steps": 117827.82901554405, "train/model_opt_loss": 11412.461858403498, "train/model_opt_model_opt_grad_overflow": 0.0051813471502590676, "train/model_opt_model_opt_grad_scale": 1444.300518134715, "train/policy_entropy_mag": 2.542270633223143, "train/policy_entropy_max": 2.542270633223143, "train/policy_entropy_mean": 0.45181765179559974, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6259360684014355, "train/policy_logprob_mag": 7.43838411785778, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.4524931487641804, "train/policy_logprob_min": -7.43838411785778, "train/policy_logprob_std": 1.0621330231582562, "train/policy_randomness_mag": 0.8973099691262517, "train/policy_randomness_max": 0.8973099691262517, "train/policy_randomness_mean": 0.15947180299252425, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.22092796375714435, "train/post_ent_mag": 59.22082833799056, "train/post_ent_max": 59.22082833799056, "train/post_ent_mean": 42.59736888272775, "train/post_ent_min": 19.779199407508337, "train/post_ent_std": 6.786386571399906, "train/prior_ent_mag": 75.76762635226076, "train/prior_ent_max": 75.76762635226076, "train/prior_ent_mean": 49.384026186453866, "train/prior_ent_min": 29.549805873416247, "train/prior_ent_std": 7.411387542368835, "train/rep_loss_mean": 6.7807282932064075, "train/rep_loss_std": 8.880795535645955, "train/reward_avg": 0.03345713213838907, "train/reward_loss_mean": 0.05125331816895638, "train/reward_loss_std": 0.21195411574037581, "train/reward_max_data": 1.017098449672442, "train/reward_max_pred": 1.0171326510029135, "train/reward_neg_acc": 0.9944660821109238, "train/reward_neg_loss": 0.02359800822936346, "train/reward_pos_acc": 0.9863344557544728, "train/reward_pos_loss": 0.7455214820995232, "train/reward_pred": 0.03304466978198043, "train/reward_rate": 0.03823773477979275, "train_stats/sum_log_reward": 8.27073193759453, "train_stats/max_log_achievement_collect_coal": 0.8048780487804879, "train_stats/max_log_achievement_collect_drink": 2.5365853658536586, "train_stats/max_log_achievement_collect_sapling": 1.4634146341463414, "train_stats/max_log_achievement_collect_stone": 8.731707317073171, "train_stats/max_log_achievement_collect_wood": 6.097560975609756, "train_stats/max_log_achievement_defeat_skeleton": 0.04878048780487805, "train_stats/max_log_achievement_defeat_zombie": 0.2682926829268293, "train_stats/max_log_achievement_eat_cow": 0.12195121951219512, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.146341463414634, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_furnace": 1.1219512195121952, "train_stats/max_log_achievement_place_plant": 1.4146341463414633, "train_stats/max_log_achievement_place_stone": 3.0, "train_stats/max_log_achievement_place_table": 2.1463414634146343, "train_stats/max_log_achievement_wake_up": 2.0, "train_stats/mean_log_entropy": 0.4017624738739758, "eval_stats/sum_log_reward": 8.600000202655792, "eval_stats/max_log_achievement_collect_coal": 0.875, "eval_stats/max_log_achievement_collect_drink": 1.75, "eval_stats/max_log_achievement_collect_sapling": 2.125, "eval_stats/max_log_achievement_collect_stone": 8.875, "eval_stats/max_log_achievement_collect_wood": 5.875, "eval_stats/max_log_achievement_defeat_skeleton": 0.25, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 1.125, "eval_stats/max_log_achievement_place_plant": 1.75, "eval_stats/max_log_achievement_place_stone": 2.625, "eval_stats/max_log_achievement_place_table": 2.25, "eval_stats/max_log_achievement_wake_up": 1.5, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 6.937438001841656e-07, "report/cont_loss_std": 6.5739072852011304e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 2.451684622428729e-06, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 6.851179250588757e-07, "report/cont_pred": 0.9951165318489075, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 6.7866363525390625, "report/dyn_loss_std": 8.555401802062988, "report/image_loss_mean": 2.681168556213379, "report/image_loss_std": 8.57268238067627, "report/model_loss_mean": 6.810615539550781, "report/model_loss_std": 12.387947082519531, "report/post_ent_mag": 58.986419677734375, "report/post_ent_max": 58.986419677734375, "report/post_ent_mean": 41.71052932739258, "report/post_ent_min": 21.221593856811523, "report/post_ent_std": 7.048421382904053, "report/prior_ent_mag": 75.69507598876953, "report/prior_ent_max": 75.69507598876953, "report/prior_ent_mean": 48.764549255371094, "report/prior_ent_min": 28.20125961303711, "report/prior_ent_std": 8.334842681884766, "report/rep_loss_mean": 6.7866363525390625, "report/rep_loss_std": 8.555401802062988, "report/reward_avg": 0.03896484524011612, "report/reward_loss_mean": 0.05746433138847351, "report/reward_loss_std": 0.2151719629764557, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.00177001953125, "report/reward_neg_acc": 0.9969356656074524, "report/reward_neg_loss": 0.02884731814265251, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6800433993339539, "report/reward_pred": 0.0404185988008976, "report/reward_rate": 0.0439453125, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 4.113192517252173e-06, "eval/cont_loss_std": 0.00011546621681191027, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.000996940303593874, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 2.1975318986733328e-07, "eval/cont_pred": 0.9960975050926208, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 19.93431854248047, "eval/dyn_loss_std": 12.53653621673584, "eval/image_loss_mean": 20.385374069213867, "eval/image_loss_std": 24.965295791625977, "eval/model_loss_mean": 32.51289749145508, "eval/model_loss_std": 29.76360511779785, "eval/post_ent_mag": 61.51560592651367, "eval/post_ent_max": 61.51560592651367, "eval/post_ent_mean": 40.32284927368164, "eval/post_ent_min": 21.356090545654297, "eval/post_ent_std": 7.348582744598389, "eval/prior_ent_mag": 75.69507598876953, "eval/prior_ent_max": 75.69507598876953, "eval/prior_ent_mean": 54.21544647216797, "eval/prior_ent_min": 38.956573486328125, "eval/prior_ent_std": 6.220813274383545, "eval/rep_loss_mean": 19.93431854248047, "eval/rep_loss_std": 12.53653621673584, "eval/reward_avg": 0.02519531361758709, "eval/reward_loss_mean": 0.16692900657653809, "eval/reward_loss_std": 0.8963971734046936, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.013242483139038, "eval/reward_neg_acc": 0.986921489238739, "eval/reward_neg_loss": 0.08624285459518433, "eval/reward_pos_acc": 0.7000000476837158, "eval/reward_pos_loss": 2.840329885482788, "eval/reward_pred": 0.023864980787038803, "eval/reward_rate": 0.029296875, "replay/size": 476617.0, "replay/inserts": 7688.0, "replay/samples": 30752.0, "replay/insert_wait_avg": 1.5240430087626415e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.23047447502303e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 98968.0, "eval_replay/inserts": 2304.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1917824546496074e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.11106300354, "timer/env.step_count": 961.0, "timer/env.step_total": 90.42092895507812, "timer/env.step_frac": 0.09041088765034296, "timer/env.step_avg": 0.09409045676907193, "timer/env.step_min": 0.0234222412109375, "timer/env.step_max": 3.3436052799224854, "timer/replay._sample_count": 30752.0, "timer/replay._sample_total": 14.905142784118652, "timer/replay._sample_frac": 0.014903487558027236, "timer/replay._sample_avg": 0.0004846885660808615, "timer/replay._sample_min": 0.0003895759582519531, "timer/replay._sample_max": 0.01534271240234375, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1249.0, "timer/agent.policy_total": 21.19336485862732, "timer/agent.policy_frac": 0.02119101132126193, "timer/agent.policy_avg": 0.016968266500101938, "timer/agent.policy_min": 0.009589195251464844, "timer/agent.policy_max": 0.12683343887329102, "timer/dataset_train_count": 1922.0, "timer/dataset_train_total": 0.40579652786254883, "timer/dataset_train_frac": 0.0004057514638862789, "timer/dataset_train_avg": 0.0002111324286485686, "timer/dataset_train_min": 9.012222290039062e-05, "timer/dataset_train_max": 0.11047935485839844, "timer/agent.train_count": 1922.0, "timer/agent.train_total": 851.3195171356201, "timer/agent.train_frac": 0.851224977532927, "timer/agent.train_avg": 0.442934192058075, "timer/agent.train_min": 0.4284186363220215, "timer/agent.train_max": 0.962073564529419, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4757726192474365, "timer/agent.report_frac": 0.00047571978437933995, "timer/agent.report_avg": 0.23788630962371826, "timer/agent.report_min": 0.23234176635742188, "timer/agent.report_max": 0.24343085289001465, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.2901763916015625e-05, "timer/dataset_eval_frac": 3.289811015309123e-08, "timer/dataset_eval_avg": 3.2901763916015625e-05, "timer/dataset_eval_min": 3.2901763916015625e-05, "timer/dataset_eval_max": 3.2901763916015625e-05, "fps": 7.687040626428472}
{"step": 477200, "time": 61368.06294679642, "episode/length": 60.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 477440, "time": 61398.00291109085, "episode/length": 223.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9732142857142857, "episode/intrinsic_return": 0.0}
{"step": 477840, "time": 61446.01014280319, "episode/length": 156.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 478184, "time": 61487.65332746506, "episode/length": 420.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.995249406175772, "episode/intrinsic_return": 0.0}
{"step": 478216, "time": 61492.87601351738, "episode/length": 222.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9820627802690582, "episode/intrinsic_return": 0.0}
{"step": 478320, "time": 61506.55704212189, "episode/length": 139.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 478360, "time": 61512.72500228882, "episode/length": 220.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9909502262443439, "episode/intrinsic_return": 0.0}
{"step": 478552, "time": 61536.43034815788, "episode/length": 138.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.0}
{"step": 478792, "time": 61566.416915893555, "episode/length": 220.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9683257918552036, "episode/intrinsic_return": 0.0}
{"step": 478888, "time": 61579.052490234375, "episode/length": 83.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9285714285714286, "episode/intrinsic_return": 0.0}
{"step": 479008, "time": 61594.47179222107, "episode/length": 145.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.958904109589041, "episode/intrinsic_return": 0.0}
{"step": 479376, "time": 61638.643672943115, "episode/length": 131.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9924242424242424, "episode/intrinsic_return": 0.0}
{"step": 479384, "time": 61641.045989751816, "episode/length": 46.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 479472, "time": 61652.86130738258, "episode/length": 334.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9880597014925373, "episode/intrinsic_return": 0.0}
{"step": 479952, "time": 61710.55146026611, "episode/length": 132.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9924812030075187, "episode/intrinsic_return": 0.0}
{"step": 480008, "time": 61718.57075095177, "episode/length": 181.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.967032967032967, "episode/intrinsic_return": 0.0}
{"step": 480064, "time": 61740.85303449631, "eval_episode/length": 44.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.8888888888888888}
{"step": 480064, "time": 61745.99030804634, "eval_episode/length": 138.0, "eval_episode/score": 7.0999999940395355, "eval_episode/reward_rate": 0.9928057553956835}
{"step": 480064, "time": 61748.24459028244, "eval_episode/length": 157.0, "eval_episode/score": 8.100000031292439, "eval_episode/reward_rate": 0.9936708860759493}
{"step": 480064, "time": 61750.30874967575, "eval_episode/length": 168.0, "eval_episode/score": 10.100000016391277, "eval_episode/reward_rate": 0.9822485207100592}
{"step": 480064, "time": 61752.23958969116, "eval_episode/length": 178.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9776536312849162}
{"step": 480064, "time": 61753.783609867096, "eval_episode/length": 179.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9944444444444445}
{"step": 480064, "time": 61755.633246421814, "eval_episode/length": 185.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9946236559139785}
{"step": 480064, "time": 61757.740839242935, "eval_episode/length": 199.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.975}
{"step": 480200, "time": 61773.419498205185, "episode/length": 229.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 480440, "time": 61802.806064367294, "episode/length": 281.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 480616, "time": 61824.853920936584, "episode/length": 142.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 480720, "time": 61838.40496826172, "episode/length": 166.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 481040, "time": 61876.90682530403, "episode/length": 207.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 481224, "time": 61899.64131832123, "episode/length": 303.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9835526315789473, "episode/intrinsic_return": 0.0}
{"step": 481504, "time": 61933.72936344147, "episode/length": 193.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9690721649484536, "episode/intrinsic_return": 0.0}
{"step": 481576, "time": 61944.07209897041, "episode/length": 141.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 481688, "time": 61958.479514837265, "episode/length": 209.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 481776, "time": 61970.13106894493, "episode/length": 144.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 482440, "time": 62048.61767029762, "episode/length": 214.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 482688, "time": 62079.04187989235, "episode/length": 182.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9672131147540983, "episode/intrinsic_return": 0.0}
{"step": 482992, "time": 62116.24296379089, "episode/length": 176.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 483200, "time": 62141.801517248154, "episode/length": 188.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 483272, "time": 62151.5905752182, "episode/length": 220.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 483608, "time": 62193.73431301117, "episode/length": 425.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9788732394366197, "episode/intrinsic_return": 0.0}
{"step": 484248, "time": 62270.16126680374, "episode/length": 225.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9778761061946902, "episode/intrinsic_return": 0.0}
{"step": 484352, "time": 62283.64114379883, "episode/length": 413.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 484416, "time": 62292.515788555145, "episode/length": 142.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.965034965034965, "episode/intrinsic_return": 0.0}
{"step": 484576, "time": 62312.55808997154, "episode/length": 197.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 484656, "time": 62323.99505019188, "episode/length": 245.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.967479674796748, "episode/intrinsic_return": 0.0}
{"step": 484696, "time": 62330.626059532166, "episode/length": 135.0, "episode/score": 10.100000031292439, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.0}
{"step": 484704, "time": 62333.09806895256, "episode/length": 187.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 484909, "time": 62359.2118666172, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.475546610724066, "train/action_min": 0.0, "train/action_std": 3.121858684058042, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04349967357270496, "train/actor_opt_grad_steps": 119865.0, "train/actor_opt_loss": -10.00029375339791, "train/adv_mag": 0.44920306061346504, "train/adv_max": 0.42883999430641684, "train/adv_mean": 0.003109701738964956, "train/adv_min": -0.366931311939795, "train/adv_std": 0.055014687868737686, "train/cont_avg": 0.9947899887242269, "train/cont_loss_mean": 0.00013308494651989664, "train/cont_loss_std": 0.003989275157839963, "train/cont_neg_acc": 0.995676043120073, "train/cont_neg_loss": 0.011524346901587658, "train/cont_pos_acc": 0.9999797227456397, "train/cont_pos_loss": 6.10991898586194e-05, "train/cont_pred": 0.9947868905116602, "train/cont_rate": 0.9947899887242269, "train/dyn_loss_mean": 6.835493645717189, "train/dyn_loss_std": 8.925172400228757, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1178004047305314, "train/extr_critic_critic_opt_grad_steps": 119865.0, "train/extr_critic_critic_opt_loss": 16903.919066124356, "train/extr_critic_mag": 8.878989514616347, "train/extr_critic_max": 8.878989514616347, "train/extr_critic_mean": 2.039818653126353, "train/extr_critic_min": -0.5537932238627955, "train/extr_critic_std": 2.0809774331210815, "train/extr_return_normed_mag": 1.510539067160223, "train/extr_return_normed_max": 1.510539067160223, "train/extr_return_normed_mean": 0.34292384121835845, "train/extr_return_normed_min": -0.09851615405497477, "train/extr_return_normed_std": 0.3219007918822397, "train/extr_return_rate": 0.6833679342700034, "train/extr_return_raw_mag": 9.744064579304961, "train/extr_return_raw_max": 9.744064579304961, "train/extr_return_raw_mean": 2.060265371479939, "train/extr_return_raw_min": -0.844730681211678, "train/extr_return_raw_std": 2.11842856456324, "train/extr_reward_mag": 1.0388264901859243, "train/extr_reward_max": 1.0388264901859243, "train/extr_reward_mean": 0.04446748708442007, "train/extr_reward_min": -0.6720401214570114, "train/extr_reward_std": 0.20579037339109735, "train/image_loss_mean": 3.821813472767466, "train/image_loss_std": 8.829189892896672, "train/model_loss_mean": 7.973441104299014, "train/model_loss_std": 12.978394493614275, "train/model_opt_grad_norm": 37.80264288125579, "train/model_opt_grad_steps": 119761.11340206186, "train/model_opt_loss": 11379.527001449742, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1430.4123711340205, "train/policy_entropy_mag": 2.556676377955171, "train/policy_entropy_max": 2.556676377955171, "train/policy_entropy_mean": 0.45030824886154885, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6291672005174086, "train/policy_logprob_mag": 7.438384117539396, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.45104876252793774, "train/policy_logprob_min": -7.438384117539396, "train/policy_logprob_std": 1.0601773839635946, "train/policy_randomness_mag": 0.902394565724835, "train/policy_randomness_max": 0.902394565724835, "train/policy_randomness_mean": 0.15893905168187986, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.2220684107892292, "train/post_ent_mag": 59.560400894007735, "train/post_ent_max": 59.560400894007735, "train/post_ent_mean": 42.78937951314081, "train/post_ent_min": 19.731709391800397, "train/post_ent_std": 6.848191647185493, "train/prior_ent_mag": 75.88382280487374, "train/prior_ent_max": 75.88382280487374, "train/prior_ent_mean": 49.624745260808886, "train/prior_ent_min": 29.386840358222884, "train/prior_ent_std": 7.396671641733229, "train/rep_loss_mean": 6.835493645717189, "train/rep_loss_std": 8.925172400228757, "train/reward_avg": 0.03220340658996984, "train/reward_loss_mean": 0.050198419403630436, "train/reward_loss_std": 0.21026398026451623, "train/reward_max_data": 1.0149484571722365, "train/reward_max_pred": 1.0125107986410868, "train/reward_neg_acc": 0.9943609194657237, "train/reward_neg_loss": 0.023602598437981813, "train/reward_pos_acc": 0.9854985014679506, "train/reward_pos_loss": 0.7464441362115526, "train/reward_pred": 0.03196125199595831, "train/reward_rate": 0.03692312338917526, "train_stats/sum_log_reward": 8.330769355480488, "train_stats/max_log_achievement_collect_coal": 0.6923076923076923, "train_stats/max_log_achievement_collect_drink": 4.769230769230769, "train_stats/max_log_achievement_collect_sapling": 1.3076923076923077, "train_stats/max_log_achievement_collect_stone": 9.615384615384615, "train_stats/max_log_achievement_collect_wood": 5.615384615384615, "train_stats/max_log_achievement_defeat_skeleton": 0.07692307692307693, "train_stats/max_log_achievement_defeat_zombie": 0.1794871794871795, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.1538461538461537, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_furnace": 1.1282051282051282, "train_stats/max_log_achievement_place_plant": 1.205128205128205, "train_stats/max_log_achievement_place_stone": 3.923076923076923, "train_stats/max_log_achievement_place_table": 1.9487179487179487, "train_stats/max_log_achievement_wake_up": 2.128205128205128, "train_stats/mean_log_entropy": 0.41562014397902364, "eval_stats/sum_log_reward": 7.725000232458115, "eval_stats/max_log_achievement_collect_coal": 0.125, "eval_stats/max_log_achievement_collect_drink": 4.375, "eval_stats/max_log_achievement_collect_sapling": 1.5, "eval_stats/max_log_achievement_collect_stone": 8.25, "eval_stats/max_log_achievement_collect_wood": 6.125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.125, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.875, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.625, "eval_stats/max_log_achievement_place_plant": 1.5, "eval_stats/max_log_achievement_place_stone": 4.125, "eval_stats/max_log_achievement_place_table": 2.5, "eval_stats/max_log_achievement_wake_up": 1.5, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 2.462730662955437e-06, "report/cont_loss_std": 9.238538041245192e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 7.1525391831528395e-06, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.4489504539815243e-06, "report/cont_pred": 0.9970678687095642, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 6.857601642608643, "report/dyn_loss_std": 8.705750465393066, "report/image_loss_mean": 3.741960048675537, "report/image_loss_std": 6.3757147789001465, "report/model_loss_mean": 7.898656845092773, "report/model_loss_std": 10.218809127807617, "report/post_ent_mag": 60.050086975097656, "report/post_ent_max": 60.050086975097656, "report/post_ent_mean": 43.077484130859375, "report/post_ent_min": 19.928730010986328, "report/post_ent_std": 6.982195854187012, "report/prior_ent_mag": 75.94352722167969, "report/prior_ent_max": 75.94352722167969, "report/prior_ent_mean": 50.09789276123047, "report/prior_ent_min": 30.470844268798828, "report/prior_ent_std": 7.644816875457764, "report/rep_loss_mean": 6.857601642608643, "report/rep_loss_std": 8.705750465393066, "report/reward_avg": 0.0263671875, "report/reward_loss_mean": 0.04213385656476021, "report/reward_loss_std": 0.21018163859844208, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.000554084777832, "report/reward_neg_acc": 0.9899294972419739, "report/reward_neg_loss": 0.022405235096812248, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6740861535072327, "report/reward_pred": 0.02741674892604351, "report/reward_rate": 0.0302734375, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.00024670458515174687, "eval/cont_loss_std": 0.007740744389593601, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 6.646834663115442e-06, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.00024740994558669627, "eval/cont_pred": 0.9968513250350952, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 19.954681396484375, "eval/dyn_loss_std": 13.136870384216309, "eval/image_loss_mean": 18.96900177001953, "eval/image_loss_std": 23.38682746887207, "eval/model_loss_mean": 31.12141227722168, "eval/model_loss_std": 28.586374282836914, "eval/post_ent_mag": 55.21006393432617, "eval/post_ent_max": 55.21006393432617, "eval/post_ent_mean": 39.08332061767578, "eval/post_ent_min": 22.700176239013672, "eval/post_ent_std": 6.426930904388428, "eval/prior_ent_mag": 75.94352722167969, "eval/prior_ent_max": 75.94352722167969, "eval/prior_ent_mean": 51.644500732421875, "eval/prior_ent_min": 32.856910705566406, "eval/prior_ent_std": 6.5962233543396, "eval/rep_loss_mean": 19.954681396484375, "eval/rep_loss_std": 13.136870384216309, "eval/reward_avg": 0.04804687201976776, "eval/reward_loss_mean": 0.17935553193092346, "eval/reward_loss_std": 0.9868993759155273, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0004725456237793, "eval/reward_neg_acc": 0.9897013902664185, "eval/reward_neg_loss": 0.09630893170833588, "eval/reward_pos_acc": 0.8679245710372925, "eval/reward_pos_loss": 1.7008320093154907, "eval/reward_pred": 0.04520050063729286, "eval/reward_rate": 0.0517578125, "replay/size": 484405.0, "replay/inserts": 7788.0, "replay/samples": 31152.0, "replay/insert_wait_avg": 1.5106578331209172e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.214320275375766e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 1600.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.137852668762207e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.748603820800781e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4210810661316, "timer/env.step_count": 973.0, "timer/env.step_total": 88.62980198860168, "timer/env.step_frac": 0.08859249736535982, "timer/env.step_avg": 0.09108921067687738, "timer/env.step_min": 0.023533344268798828, "timer/env.step_max": 2.030973196029663, "timer/replay._sample_count": 31152.0, "timer/replay._sample_total": 15.034881830215454, "timer/replay._sample_frac": 0.015028553590847005, "timer/replay._sample_avg": 0.0004826297454486214, "timer/replay._sample_min": 0.0003592967987060547, "timer/replay._sample_max": 0.03240323066711426, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1173.0, "timer/agent.policy_total": 18.5324809551239, "timer/agent.policy_frac": 0.018524680562882735, "timer/agent.policy_avg": 0.015799216500531885, "timer/agent.policy_min": 0.00946497917175293, "timer/agent.policy_max": 0.06382632255554199, "timer/dataset_train_count": 1947.0, "timer/dataset_train_total": 0.3629724979400635, "timer/dataset_train_frac": 0.0003628197214249523, "timer/dataset_train_avg": 0.00018642655261431098, "timer/dataset_train_min": 8.606910705566406e-05, "timer/dataset_train_max": 0.07508730888366699, "timer/agent.train_count": 1947.0, "timer/agent.train_total": 862.0523912906647, "timer/agent.train_frac": 0.8616895501362188, "timer/agent.train_avg": 0.44275931756069065, "timer/agent.train_min": 0.4241821765899658, "timer/agent.train_max": 0.9329450130462646, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4726266860961914, "timer/agent.report_frac": 0.0004724277557131456, "timer/agent.report_avg": 0.2363133430480957, "timer/agent.report_min": 0.23038077354431152, "timer/agent.report_max": 0.24224591255187988, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.47955322265625e-05, "timer/dataset_eval_frac": 2.478509569204432e-08, "timer/dataset_eval_avg": 2.47955322265625e-05, "timer/dataset_eval_min": 2.47955322265625e-05, "timer/dataset_eval_max": 2.47955322265625e-05, "fps": 7.784613431907057}
{"step": 485200, "time": 62392.87860631943, "episode/length": 427.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9976635514018691, "episode/intrinsic_return": 0.0}
{"step": 485616, "time": 62442.73616147041, "episode/length": 149.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 485680, "time": 62451.55224728584, "episode/length": 137.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.0}
{"step": 485760, "time": 62462.30967736244, "episode/length": 137.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9637681159420289, "episode/intrinsic_return": 0.0}
{"step": 485800, "time": 62468.39459657669, "episode/length": 193.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9690721649484536, "episode/intrinsic_return": 0.0}
{"step": 486032, "time": 62496.688381671906, "episode/length": 209.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 486168, "time": 62513.84470009804, "episode/length": 50.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 486176, "time": 62516.24407410622, "episode/length": 183.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 486464, "time": 62551.038492679596, "episode/length": 220.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 487176, "time": 62634.91768050194, "episode/length": 171.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9651162790697675, "episode/intrinsic_return": 0.0}
{"step": 487256, "time": 62645.652042627335, "episode/length": 204.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 487584, "time": 62685.493200063705, "episode/length": 297.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9966442953020134, "episode/intrinsic_return": 0.0}
{"step": 487832, "time": 62715.892486810684, "episode/length": 268.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9851301115241635, "episode/intrinsic_return": 0.0}
{"step": 488096, "time": 62748.233339071274, "episode/length": 239.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9625, "episode/intrinsic_return": 0.0}
{"step": 488152, "time": 62756.22913789749, "episode/length": 39.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 488600, "time": 62809.55450963974, "episode/length": 167.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 488656, "time": 62817.63686680794, "episode/length": 184.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 488920, "time": 62849.748034477234, "episode/length": 39.0, "episode/score": 2.100000023841858, "episode/reward_rate": 0.9, "episode/intrinsic_return": 0.0}
{"step": 489112, "time": 62873.564145088196, "episode/length": 367.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 489192, "time": 62884.24342083931, "episode/length": 129.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9923076923076923, "episode/intrinsic_return": 0.0}
{"step": 489208, "time": 62887.5319647789, "episode/length": 396.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9874055415617129, "episode/intrinsic_return": 0.0}
{"step": 489344, "time": 62904.65501952171, "episode/length": 359.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9972222222222222, "episode/intrinsic_return": 0.0}
{"step": 489488, "time": 62922.72649073601, "episode/length": 36.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 489736, "time": 62952.97273898125, "episode/length": 134.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9925925925925926, "episode/intrinsic_return": 0.0}
{"step": 490048, "time": 63004.67489004135, "eval_episode/length": 38.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 490048, "time": 63011.01952624321, "eval_episode/length": 156.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9617834394904459}
{"step": 490048, "time": 63013.23941230774, "eval_episode/length": 174.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 490048, "time": 63014.862494945526, "eval_episode/length": 175.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9772727272727273}
{"step": 490048, "time": 63016.351989507675, "eval_episode/length": 176.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9774011299435028}
{"step": 490048, "time": 63018.25953793526, "eval_episode/length": 187.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.973404255319149}
{"step": 490048, "time": 63020.115050554276, "eval_episode/length": 197.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9949494949494949}
{"step": 490048, "time": 63022.538987636566, "eval_episode/length": 180.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9668508287292817}
{"step": 490680, "time": 63096.130843639374, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 490952, "time": 63129.12726330757, "episode/length": 151.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9539473684210527, "episode/intrinsic_return": 0.0}
{"step": 491048, "time": 63141.917753219604, "episode/length": 432.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9792147806004619, "episode/intrinsic_return": 0.0}
{"step": 491080, "time": 63147.65265917778, "episode/length": 269.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9962962962962963, "episode/intrinsic_return": 0.0}
{"step": 491344, "time": 63180.09387564659, "episode/length": 266.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9925093632958801, "episode/intrinsic_return": 0.0}
{"step": 491384, "time": 63186.38211107254, "episode/length": 410.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9805352798053528, "episode/intrinsic_return": 0.0}
{"step": 491400, "time": 63189.70693087578, "episode/length": 285.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9755244755244755, "episode/intrinsic_return": 0.0}
{"step": 492080, "time": 63270.99410891533, "episode/length": 140.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 492152, "time": 63280.896782159805, "episode/length": 332.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.990990990990991, "episode/intrinsic_return": 0.0}
{"step": 492288, "time": 63298.07932424545, "episode/length": 150.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 492392, "time": 63311.62656545639, "episode/length": 167.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 492624, "time": 63339.93434429169, "episode/length": 154.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 492773, "time": 63359.57308459282, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.444796334668465, "train/action_min": 0.0, "train/action_std": 3.1101975767745587, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04431097676533128, "train/actor_opt_grad_steps": 121820.0, "train/actor_opt_loss": -9.880434246535229, "train/adv_mag": 0.4523396606977821, "train/adv_max": 0.42296303044720956, "train/adv_mean": 0.0030010853431773044, "train/adv_min": -0.3770533322077717, "train/adv_std": 0.055537410780106704, "train/cont_avg": 0.994804885786802, "train/cont_loss_mean": 8.868496363506928e-05, "train/cont_loss_std": 0.0027103173549061685, "train/cont_neg_acc": 0.9971517203422973, "train/cont_neg_loss": 0.013316166630507668, "train/cont_pos_acc": 0.9999999782155613, "train/cont_pos_loss": 1.2490614570019323e-05, "train/cont_pred": 0.9948196329441167, "train/cont_rate": 0.994804885786802, "train/dyn_loss_mean": 6.970948195094384, "train/dyn_loss_std": 8.9876919010569, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1008575543534331, "train/extr_critic_critic_opt_grad_steps": 121820.0, "train/extr_critic_critic_opt_loss": 17066.319901054885, "train/extr_critic_mag": 9.009996811145454, "train/extr_critic_max": 9.009996811145454, "train/extr_critic_mean": 2.1124997169233217, "train/extr_critic_min": -0.5431502803328073, "train/extr_critic_std": 2.1060218895752416, "train/extr_return_normed_mag": 1.5042047688198574, "train/extr_return_normed_max": 1.5042047688198574, "train/extr_return_normed_mean": 0.3489586924235833, "train/extr_return_normed_min": -0.0971275251642399, "train/extr_return_normed_std": 0.32245259085282457, "train/extr_return_rate": 0.6960584221757607, "train/extr_return_raw_mag": 9.814900867830072, "train/extr_return_raw_max": 9.814900867830072, "train/extr_return_raw_mean": 2.1324639762113544, "train/extr_return_raw_min": -0.8345537648588268, "train/extr_return_raw_std": 2.144578102881533, "train/extr_reward_mag": 1.0455721029775398, "train/extr_reward_max": 1.0455721029775398, "train/extr_reward_mean": 0.044903539461532825, "train/extr_reward_min": -0.6816516019366115, "train/extr_reward_std": 0.20664624688286468, "train/image_loss_mean": 3.862926598127723, "train/image_loss_std": 8.812468896662523, "train/model_loss_mean": 8.097041795701545, "train/model_loss_std": 13.004248086571089, "train/model_opt_grad_norm": 41.962727021197885, "train/model_opt_grad_steps": 121714.461928934, "train/model_opt_loss": 11367.677392330266, "train/model_opt_model_opt_grad_overflow": 0.005076142131979695, "train/model_opt_model_opt_grad_scale": 1402.284263959391, "train/policy_entropy_mag": 2.547712778682031, "train/policy_entropy_max": 2.547712778682031, "train/policy_entropy_mean": 0.44317456293227103, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6192284910206868, "train/policy_logprob_mag": 7.438384123865118, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.44297458223885083, "train/policy_logprob_min": -7.438384123865118, "train/policy_logprob_std": 1.0541551736405659, "train/policy_randomness_mag": 0.8992308084734806, "train/policy_randomness_max": 0.8992308084734806, "train/policy_randomness_mean": 0.1564211725507896, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.21856048324991603, "train/post_ent_mag": 59.543470779651315, "train/post_ent_max": 59.543470779651315, "train/post_ent_mean": 42.669390644518856, "train/post_ent_min": 19.742653764443954, "train/post_ent_std": 6.813038232967938, "train/prior_ent_mag": 75.88377287424156, "train/prior_ent_max": 75.88377287424156, "train/prior_ent_mean": 49.64021014683138, "train/prior_ent_min": 29.822172987884677, "train/prior_ent_std": 7.386204951910803, "train/rep_loss_mean": 6.970948195094384, "train/rep_loss_std": 8.9876919010569, "train/reward_avg": 0.033510965129672575, "train/reward_loss_mean": 0.051457613857869566, "train/reward_loss_std": 0.2187975847025208, "train/reward_max_data": 1.0157360443609016, "train/reward_max_pred": 1.0151543217867158, "train/reward_neg_acc": 0.9945040563036343, "train/reward_neg_loss": 0.02367375109363631, "train/reward_pos_acc": 0.9845893567588728, "train/reward_pos_loss": 0.7544164848206613, "train/reward_pred": 0.03308519530039148, "train/reward_rate": 0.0382148239213198, "train_stats/sum_log_reward": 7.627777910894817, "train_stats/max_log_achievement_collect_coal": 0.3888888888888889, "train_stats/max_log_achievement_collect_drink": 4.138888888888889, "train_stats/max_log_achievement_collect_sapling": 1.3333333333333333, "train_stats/max_log_achievement_collect_stone": 11.583333333333334, "train_stats/max_log_achievement_collect_wood": 5.694444444444445, "train_stats/max_log_achievement_defeat_skeleton": 0.027777777777777776, "train_stats/max_log_achievement_defeat_zombie": 0.1111111111111111, "train_stats/max_log_achievement_eat_cow": 0.027777777777777776, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.25, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_furnace": 1.3055555555555556, "train_stats/max_log_achievement_place_plant": 1.2777777777777777, "train_stats/max_log_achievement_place_stone": 4.777777777777778, "train_stats/max_log_achievement_place_table": 2.0, "train_stats/max_log_achievement_wake_up": 2.4444444444444446, "train_stats/mean_log_entropy": 0.45688901303542984, "eval_stats/sum_log_reward": 8.600000262260437, "eval_stats/max_log_achievement_collect_coal": 0.875, "eval_stats/max_log_achievement_collect_drink": 2.375, "eval_stats/max_log_achievement_collect_sapling": 1.625, "eval_stats/max_log_achievement_collect_stone": 7.125, "eval_stats/max_log_achievement_collect_wood": 4.75, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.875, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 1.0, "eval_stats/max_log_achievement_place_plant": 1.625, "eval_stats/max_log_achievement_place_stone": 2.625, "eval_stats/max_log_achievement_place_table": 1.75, "eval_stats/max_log_achievement_wake_up": 1.25, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 7.512626893912966e-07, "report/cont_loss_std": 7.982745046319906e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.415597307641292e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 6.986951461840363e-07, "report/cont_pred": 0.9960931539535522, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 7.781748294830322, "report/dyn_loss_std": 9.219407081604004, "report/image_loss_mean": 4.316682815551758, "report/image_loss_std": 11.34721851348877, "report/model_loss_mean": 9.052055358886719, "report/model_loss_std": 15.463784217834473, "report/post_ent_mag": 60.435638427734375, "report/post_ent_max": 60.435638427734375, "report/post_ent_mean": 42.51340866088867, "report/post_ent_min": 20.441158294677734, "report/post_ent_std": 6.647040843963623, "report/prior_ent_mag": 75.59867095947266, "report/prior_ent_max": 75.59867095947266, "report/prior_ent_mean": 50.58976364135742, "report/prior_ent_min": 32.950618743896484, "report/prior_ent_std": 7.059489727020264, "report/rep_loss_mean": 7.781748294830322, "report/rep_loss_std": 9.219407081604004, "report/reward_avg": 0.03593750298023224, "report/reward_loss_mean": 0.06632368266582489, "report/reward_loss_std": 0.45596200227737427, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.001190423965454, "report/reward_neg_acc": 0.9969512820243835, "report/reward_neg_loss": 0.020351024344563484, "report/reward_pos_acc": 0.925000011920929, "report/reward_pos_loss": 1.197251319885254, "report/reward_pred": 0.033744268119335175, "report/reward_rate": 0.0390625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 1.8482788846085896e-06, "eval/cont_loss_std": 4.322690438129939e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0004819853638764471, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 4.3749423639383167e-07, "eval/cont_pred": 0.9970713257789612, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 21.5383358001709, "eval/dyn_loss_std": 14.26971435546875, "eval/image_loss_mean": 17.40151596069336, "eval/image_loss_std": 20.481718063354492, "eval/model_loss_mean": 30.496902465820312, "eval/model_loss_std": 26.804210662841797, "eval/post_ent_mag": 55.930015563964844, "eval/post_ent_max": 55.930015563964844, "eval/post_ent_mean": 38.701087951660156, "eval/post_ent_min": 21.475879669189453, "eval/post_ent_std": 6.894468307495117, "eval/prior_ent_mag": 75.59867095947266, "eval/prior_ent_max": 75.59867095947266, "eval/prior_ent_mean": 52.614990234375, "eval/prior_ent_min": 33.85509490966797, "eval/prior_ent_std": 6.408924102783203, "eval/rep_loss_mean": 21.5383358001709, "eval/rep_loss_std": 14.26971435546875, "eval/reward_avg": 0.03691406175494194, "eval/reward_loss_mean": 0.17238397896289825, "eval/reward_loss_std": 0.9367998838424683, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0006422996520996, "eval/reward_neg_acc": 0.9938900470733643, "eval/reward_neg_loss": 0.06990320980548859, "eval/reward_pos_acc": 0.7142857313156128, "eval/reward_pos_loss": 2.568481922149658, "eval/reward_pred": 0.027976902201771736, "eval/reward_rate": 0.041015625, "replay/size": 492269.0, "replay/inserts": 7864.0, "replay/samples": 31456.0, "replay/insert_wait_avg": 1.4939361525697602e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.185603691869446e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 1760.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0525638406926936e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.195638656616211e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3460366725922, "timer/env.step_count": 983.0, "timer/env.step_total": 81.15964531898499, "timer/env.step_frac": 0.08113157082017619, "timer/env.step_avg": 0.08256322006000508, "timer/env.step_min": 0.02322673797607422, "timer/env.step_max": 1.9938557147979736, "timer/replay._sample_count": 31456.0, "timer/replay._sample_total": 15.080030918121338, "timer/replay._sample_frac": 0.015074814479478916, "timer/replay._sample_avg": 0.00047940077944180244, "timer/replay._sample_min": 0.0003647804260253906, "timer/replay._sample_max": 0.010502099990844727, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1203.0, "timer/agent.policy_total": 18.93750810623169, "timer/agent.policy_frac": 0.01893095730075835, "timer/agent.policy_avg": 0.015741902000192595, "timer/agent.policy_min": 0.009414196014404297, "timer/agent.policy_max": 0.04579567909240723, "timer/dataset_train_count": 1966.0, "timer/dataset_train_total": 0.36115097999572754, "timer/dataset_train_frac": 0.0003610260517420636, "timer/dataset_train_avg": 0.00018369836215449011, "timer/dataset_train_min": 8.7738037109375e-05, "timer/dataset_train_max": 0.08096837997436523, "timer/agent.train_count": 1966.0, "timer/agent.train_total": 868.8765406608582, "timer/agent.train_frac": 0.86857598151832, "timer/agent.train_avg": 0.44195144489362065, "timer/agent.train_min": 0.4194674491882324, "timer/agent.train_max": 0.9757030010223389, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47351813316345215, "timer/agent.report_frac": 0.00047335433520434095, "timer/agent.report_avg": 0.23675906658172607, "timer/agent.report_min": 0.23073148727416992, "timer/agent.report_max": 0.24278664588928223, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9325485229492188e-05, "timer/dataset_eval_frac": 2.931534104642058e-08, "timer/dataset_eval_avg": 2.9325485229492188e-05, "timer/dataset_eval_min": 2.9325485229492188e-05, "timer/dataset_eval_max": 2.9325485229492188e-05, "fps": 7.861171718309513}
{"step": 492920, "time": 63376.4231197834, "episode/length": 65.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9848484848484849, "episode/intrinsic_return": 0.0}
{"step": 492936, "time": 63379.70273017883, "episode/length": 198.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9698492462311558, "episode/intrinsic_return": 0.0}
{"step": 493296, "time": 63422.79808306694, "episode/length": 44.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.8888888888888888, "episode/intrinsic_return": 0.0}
{"step": 493712, "time": 63472.64787721634, "episode/length": 194.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 493728, "time": 63476.02652144432, "episode/length": 290.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9965635738831615, "episode/intrinsic_return": 0.0}
{"step": 493808, "time": 63486.83033156395, "episode/length": 189.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 493808, "time": 63486.83730840683, "episode/length": 147.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 494208, "time": 63536.47791790962, "episode/length": 440.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 494232, "time": 63540.80148434639, "episode/length": 268.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9814126394052045, "episode/intrinsic_return": 0.0}
{"step": 494344, "time": 63555.282994031906, "episode/length": 66.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9850746268656716, "episode/intrinsic_return": 0.0}
{"step": 494352, "time": 63557.67872214317, "episode/length": 178.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 494744, "time": 63604.83659505844, "episode/length": 63.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.984375, "episode/intrinsic_return": 0.0}
{"step": 495304, "time": 63671.76705980301, "episode/length": 186.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 495504, "time": 63696.39878821373, "episode/length": 223.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 495640, "time": 63714.553087711334, "episode/length": 160.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9627329192546584, "episode/intrinsic_return": 0.0}
{"step": 496256, "time": 63787.545724868774, "episode/length": 369.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 496488, "time": 63816.01212143898, "episode/length": 284.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 496520, "time": 63821.30665063858, "episode/length": 221.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 496776, "time": 63852.76445937157, "episode/length": 183.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 497208, "time": 63904.27564191818, "episode/length": 434.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9977011494252873, "episode/intrinsic_return": 0.0}
{"step": 497464, "time": 63935.34664392471, "episode/length": 227.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9780701754385965, "episode/intrinsic_return": 0.0}
{"step": 497488, "time": 63939.6432993412, "episode/length": 120.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9917355371900827, "episode/intrinsic_return": 0.0}
{"step": 497632, "time": 63957.75548028946, "episode/length": 410.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9781021897810219, "episode/intrinsic_return": 0.0}
{"step": 497696, "time": 63966.739780664444, "episode/length": 179.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 497808, "time": 63981.26917004585, "episode/length": 287.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9965277777777778, "episode/intrinsic_return": 0.0}
{"step": 498152, "time": 64022.54208469391, "episode/length": 82.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9879518072289156, "episode/intrinsic_return": 0.0}
{"step": 498424, "time": 64055.681623220444, "episode/length": 205.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.970873786407767, "episode/intrinsic_return": 0.0}
{"step": 499000, "time": 64124.034757614136, "episode/length": 170.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 499176, "time": 64146.135556697845, "episode/length": 170.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 499304, "time": 64162.46080946922, "episode/length": 351.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9914772727272727, "episode/intrinsic_return": 0.0}
{"step": 499320, "time": 64165.811115026474, "episode/length": 202.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 499328, "time": 64168.20317363739, "episode/length": 264.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9773584905660377, "episode/intrinsic_return": 0.0}
{"step": 499488, "time": 64188.21775102615, "episode/length": 166.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 499736, "time": 64219.82277035713, "episode/length": 283.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9964788732394366, "episode/intrinsic_return": 0.0}
{"step": 499832, "time": 64232.38087964058, "episode/length": 175.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9659090909090909, "episode/intrinsic_return": 0.0}
{"step": 500032, "time": 64274.50818705559, "eval_episode/length": 129.0, "eval_episode/score": 9.099999971687794, "eval_episode/reward_rate": 0.9923076923076923}
{"step": 500032, "time": 64276.66641664505, "eval_episode/length": 149.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9666666666666667}
{"step": 500032, "time": 64278.86166214943, "eval_episode/length": 165.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9759036144578314}
{"step": 500032, "time": 64280.561143398285, "eval_episode/length": 170.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9941520467836257}
{"step": 500032, "time": 64282.96166443825, "eval_episode/length": 191.0, "eval_episode/score": 7.099999971687794, "eval_episode/reward_rate": 0.9947916666666666}
{"step": 500032, "time": 64285.71477270126, "eval_episode/length": 223.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9776785714285714}
{"step": 500032, "time": 64287.6208012104, "eval_episode/length": 234.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9829787234042553}
{"step": 500032, "time": 64289.58058094978, "eval_episode/length": 244.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9959183673469387}
{"step": 500408, "time": 64333.20828771591, "episode/length": 137.0, "episode/score": 8.099999964237213, "episode/reward_rate": 0.9710144927536232, "episode/intrinsic_return": 0.0}
{"step": 500568, "time": 64353.16218447685, "episode/length": 154.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 500576, "time": 64355.59792995453, "episode/length": 196.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9695431472081218, "episode/intrinsic_return": 0.0}
{"step": 500593, "time": 64359.984494924545, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.423122934194711, "train/action_min": 0.0, "train/action_std": 3.125474089842576, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04370959500471751, "train/actor_opt_grad_steps": 123780.0, "train/actor_opt_loss": -11.109903994045006, "train/adv_mag": 0.44816644619672724, "train/adv_max": 0.40999356829203093, "train/adv_mean": 0.002680469311356622, "train/adv_min": -0.37931304971377056, "train/adv_std": 0.054271131238112086, "train/cont_avg": 0.9946764823717948, "train/cont_loss_mean": 3.169010205196762e-05, "train/cont_loss_std": 0.0008695766359854436, "train/cont_neg_acc": 0.9989690722263965, "train/cont_neg_loss": 0.0026877181380511044, "train/cont_pos_acc": 0.9999949565300574, "train/cont_pos_loss": 1.8544492580838905e-05, "train/cont_pred": 0.9946716116024897, "train/cont_rate": 0.9946764823717948, "train/dyn_loss_mean": 6.800728245270558, "train/dyn_loss_std": 8.924145771906925, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.108591480132861, "train/extr_critic_critic_opt_grad_steps": 123780.0, "train/extr_critic_critic_opt_loss": 16915.401677684295, "train/extr_critic_mag": 9.032357944586337, "train/extr_critic_max": 9.032357944586337, "train/extr_critic_mean": 2.1112192367896054, "train/extr_critic_min": -0.5799423236113328, "train/extr_critic_std": 2.120582837936206, "train/extr_return_normed_mag": 1.4969787377577561, "train/extr_return_normed_max": 1.4969787377577561, "train/extr_return_normed_mean": 0.34796363535599834, "train/extr_return_normed_min": -0.0992425826879648, "train/extr_return_normed_std": 0.3216521242490182, "train/extr_return_rate": 0.6938739015505864, "train/extr_return_raw_mag": 9.83060164818397, "train/extr_return_raw_max": 9.83060164818397, "train/extr_return_raw_mean": 2.1291845719019573, "train/extr_return_raw_min": -0.8684324973668808, "train/extr_return_raw_std": 2.1561494539945554, "train/extr_reward_mag": 1.044714976579715, "train/extr_reward_max": 1.044714976579715, "train/extr_reward_mean": 0.04450066441144699, "train/extr_reward_min": -0.6979514201482137, "train/extr_reward_std": 0.20613520122491397, "train/image_loss_mean": 3.755169271811461, "train/image_loss_std": 8.518611922630896, "train/model_loss_mean": 7.886494555840126, "train/model_loss_std": 12.70217403509678, "train/model_opt_grad_norm": 38.86787443894606, "train/model_opt_grad_steps": 123673.00512820513, "train/model_opt_loss": 14170.66409755609, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1801.2820512820513, "train/policy_entropy_mag": 2.5620439957349728, "train/policy_entropy_max": 2.5620439957349728, "train/policy_entropy_mean": 0.44616436881896776, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6277260740598043, "train/policy_logprob_mag": 7.438384134341509, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.44626366771184484, "train/policy_logprob_min": -7.438384134341509, "train/policy_logprob_std": 1.0587527956718052, "train/policy_randomness_mag": 0.9042890976636838, "train/policy_randomness_max": 0.9042890976636838, "train/policy_randomness_mean": 0.15747644358720536, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.2215597567649988, "train/post_ent_mag": 59.5459346477802, "train/post_ent_max": 59.5459346477802, "train/post_ent_mean": 42.79568344507462, "train/post_ent_min": 19.241867725665752, "train/post_ent_std": 6.863283406771147, "train/prior_ent_mag": 75.77609299879808, "train/prior_ent_max": 75.77609299879808, "train/prior_ent_mean": 49.5933607052534, "train/prior_ent_min": 29.622443517049152, "train/prior_ent_std": 7.399584007263184, "train/rep_loss_mean": 6.800728245270558, "train/rep_loss_std": 8.924145771906925, "train/reward_avg": 0.03306139811682395, "train/reward_loss_mean": 0.050856667976730906, "train/reward_loss_std": 0.208123250802358, "train/reward_max_data": 1.0210256460385445, "train/reward_max_pred": 1.020379719367394, "train/reward_neg_acc": 0.9943024403009659, "train/reward_neg_loss": 0.023819864885165142, "train/reward_pos_acc": 0.9872054274265583, "train/reward_pos_loss": 0.7382481449689621, "train/reward_pred": 0.03279645207982797, "train/reward_rate": 0.03788561698717949, "train_stats/sum_log_reward": 8.363158163271452, "train_stats/max_log_achievement_collect_coal": 1.368421052631579, "train_stats/max_log_achievement_collect_drink": 3.3947368421052633, "train_stats/max_log_achievement_collect_sapling": 1.0526315789473684, "train_stats/max_log_achievement_collect_stone": 13.210526315789474, "train_stats/max_log_achievement_collect_wood": 6.421052631578948, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.23684210526315788, "train_stats/max_log_achievement_eat_cow": 0.02631578947368421, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.368421052631579, "train_stats/max_log_achievement_make_wood_sword": 0.02631578947368421, "train_stats/max_log_achievement_place_furnace": 1.9210526315789473, "train_stats/max_log_achievement_place_plant": 1.0, "train_stats/max_log_achievement_place_stone": 4.2631578947368425, "train_stats/max_log_achievement_place_table": 2.1578947368421053, "train_stats/max_log_achievement_wake_up": 2.026315789473684, "train_stats/mean_log_entropy": 0.45941034763267163, "eval_stats/sum_log_reward": 7.1000001430511475, "eval_stats/max_log_achievement_collect_coal": 0.25, "eval_stats/max_log_achievement_collect_drink": 3.375, "eval_stats/max_log_achievement_collect_sapling": 1.75, "eval_stats/max_log_achievement_collect_stone": 5.75, "eval_stats/max_log_achievement_collect_wood": 5.625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.375, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.5, "eval_stats/max_log_achievement_place_plant": 1.5, "eval_stats/max_log_achievement_place_stone": 2.375, "eval_stats/max_log_achievement_place_table": 2.125, "eval_stats/max_log_achievement_wake_up": 1.75, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 5.096150289318757e-06, "report/cont_loss_std": 0.00011103015276603401, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00026133417850360274, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 3.83884889743058e-06, "report/cont_pred": 0.9951146841049194, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 5.883011817932129, "report/dyn_loss_std": 7.953160285949707, "report/image_loss_mean": 2.9486143589019775, "report/image_loss_std": 7.3672661781311035, "report/model_loss_mean": 6.531578540802002, "report/model_loss_std": 10.921236038208008, "report/post_ent_mag": 60.44982147216797, "report/post_ent_max": 60.44982147216797, "report/post_ent_mean": 42.74322509765625, "report/post_ent_min": 20.10613441467285, "report/post_ent_std": 6.945474624633789, "report/prior_ent_mag": 75.82788848876953, "report/prior_ent_max": 75.82788848876953, "report/prior_ent_mean": 48.82854461669922, "report/prior_ent_min": 29.298429489135742, "report/prior_ent_std": 7.473883628845215, "report/rep_loss_mean": 5.883011817932129, "report/rep_loss_std": 7.953160285949707, "report/reward_avg": 0.04921875149011612, "report/reward_loss_mean": 0.053152188658714294, "report/reward_loss_std": 0.20146925747394562, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0023736953735352, "report/reward_neg_acc": 0.9958763122558594, "report/reward_neg_loss": 0.015263594686985016, "report/reward_pos_acc": 0.9814814925193787, "report/reward_pos_loss": 0.7337436079978943, "report/reward_pred": 0.04826875776052475, "report/reward_rate": 0.052734375, "eval/cont_avg": 0.9912109375, "eval/cont_loss_mean": 5.776066973339766e-05, "eval/cont_loss_std": 0.0013571676099672914, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.005503823049366474, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 9.470455552218482e-06, "eval/cont_pred": 0.991249144077301, "eval/cont_rate": 0.9912109375, "eval/dyn_loss_mean": 19.55699920654297, "eval/dyn_loss_std": 12.249334335327148, "eval/image_loss_mean": 17.527502059936523, "eval/image_loss_std": 20.353050231933594, "eval/model_loss_mean": 29.414079666137695, "eval/model_loss_std": 24.791349411010742, "eval/post_ent_mag": 63.012630462646484, "eval/post_ent_max": 63.012630462646484, "eval/post_ent_mean": 42.096229553222656, "eval/post_ent_min": 20.4261417388916, "eval/post_ent_std": 7.612703323364258, "eval/prior_ent_mag": 75.82788848876953, "eval/prior_ent_max": 75.82788848876953, "eval/prior_ent_mean": 54.6583251953125, "eval/prior_ent_min": 36.741573333740234, "eval/prior_ent_std": 6.550230503082275, "eval/rep_loss_mean": 19.55699920654297, "eval/rep_loss_std": 12.249334335327148, "eval/reward_avg": 0.0263671875, "eval/reward_loss_mean": 0.1523214429616928, "eval/reward_loss_std": 0.8127707242965698, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0000336170196533, "eval/reward_neg_acc": 0.9908998012542725, "eval/reward_neg_loss": 0.07319091260433197, "eval/reward_pos_acc": 0.7428571581840515, "eval/reward_pos_loss": 2.388324499130249, "eval/reward_pred": 0.01968938298523426, "eval/reward_rate": 0.0341796875, "replay/size": 500089.0, "replay/inserts": 7820.0, "replay/samples": 31280.0, "replay/insert_wait_avg": 1.5405437830464005e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.300806777251651e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 1960.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0705724054453324e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.387731552124023e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3671832084656, "timer/env.step_count": 978.0, "timer/env.step_total": 84.27434921264648, "timer/env.step_frac": 0.08424341644470422, "timer/env.step_avg": 0.08617009121947493, "timer/env.step_min": 0.02338862419128418, "timer/env.step_max": 3.4209814071655273, "timer/replay._sample_count": 31280.0, "timer/replay._sample_total": 15.147371530532837, "timer/replay._sample_frac": 0.015141811711526617, "timer/replay._sample_avg": 0.0004842510080093618, "timer/replay._sample_min": 0.00037860870361328125, "timer/replay._sample_max": 0.011070966720581055, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1223.0, "timer/agent.policy_total": 19.26656723022461, "timer/agent.policy_frac": 0.01925949546688565, "timer/agent.policy_avg": 0.015753530032890112, "timer/agent.policy_min": 0.009472370147705078, "timer/agent.policy_max": 0.06567621231079102, "timer/dataset_train_count": 1955.0, "timer/dataset_train_total": 0.28455281257629395, "timer/dataset_train_frac": 0.0002844483679119212, "timer/dataset_train_avg": 0.00014555131078071302, "timer/dataset_train_min": 8.726119995117188e-05, "timer/dataset_train_max": 0.0006191730499267578, "timer/agent.train_count": 1955.0, "timer/agent.train_total": 864.857460975647, "timer/agent.train_frac": 0.8645400163985789, "timer/agent.train_avg": 0.44238233297987056, "timer/agent.train_min": 0.42983341217041016, "timer/agent.train_max": 0.9581949710845947, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.5023925304412842, "timer/agent.report_frac": 0.0005022081280495094, "timer/agent.report_avg": 0.2511962652206421, "timer/agent.report_min": 0.23074841499328613, "timer/agent.report_max": 0.27164411544799805, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.6702880859375e-05, "timer/dataset_eval_frac": 2.6693079608760427e-08, "timer/dataset_eval_avg": 2.6702880859375e-05, "timer/dataset_eval_min": 2.6702880859375e-05, "timer/dataset_eval_max": 2.6702880859375e-05, "fps": 7.816949754305582}
{"step": 500640, "time": 64365.324199438095, "episode/length": 164.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 500776, "time": 64382.60730051994, "episode/length": 117.0, "episode/score": 9.1000000461936, "episode/reward_rate": 0.9915254237288136, "episode/intrinsic_return": 0.0}
{"step": 500904, "time": 64398.996290922165, "episode/length": 176.0, "episode/score": 9.099999964237213, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 501576, "time": 64478.356300115585, "episode/length": 299.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.99, "episode/intrinsic_return": 0.0}
{"step": 501616, "time": 64484.619809150696, "episode/length": 88.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9550561797752809, "episode/intrinsic_return": 0.0}
{"step": 501920, "time": 64521.32569742203, "episode/length": 272.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 501928, "time": 64523.74868488312, "episode/length": 168.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 501984, "time": 64531.658148765564, "episode/length": 176.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.96045197740113, "episode/intrinsic_return": 0.0}
{"step": 502312, "time": 64571.20601224899, "episode/length": 237.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9789915966386554, "episode/intrinsic_return": 0.0}
{"step": 502400, "time": 64582.87929391861, "episode/length": 59.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9166666666666666, "episode/intrinsic_return": 0.0}
{"step": 502464, "time": 64591.697328567505, "episode/length": 210.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 502472, "time": 64594.15114855766, "episode/length": 228.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 503152, "time": 64674.63011479378, "episode/length": 152.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 503504, "time": 64716.89485645294, "episode/length": 235.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 503512, "time": 64719.338181734085, "episode/length": 44.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 503944, "time": 64771.06040644646, "episode/length": 192.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9896373056994818, "episode/intrinsic_return": 0.0}
{"step": 504160, "time": 64797.5667848587, "episode/length": 210.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 504184, "time": 64801.78482198715, "episode/length": 233.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9786324786324786, "episode/intrinsic_return": 0.0}
{"step": 504192, "time": 64804.16087961197, "episode/length": 215.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 504536, "time": 64845.61038351059, "episode/length": 46.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9148936170212766, "episode/intrinsic_return": 0.0}
{"step": 504560, "time": 64849.87052607536, "episode/length": 130.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9923664122137404, "episode/intrinsic_return": 0.0}
{"step": 504728, "time": 64871.096625089645, "episode/length": 342.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9912536443148688, "episode/intrinsic_return": 0.0}
{"step": 504936, "time": 64897.008028030396, "episode/length": 25.0, "episode/score": 2.100000023841858, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 505112, "time": 64918.87040948868, "episode/length": 200.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 505744, "time": 64993.674800634384, "episode/length": 194.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 506064, "time": 65032.446878671646, "episode/length": 233.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 506312, "time": 65063.22972989082, "episode/length": 171.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9651162790697675, "episode/intrinsic_return": 0.0}
{"step": 506320, "time": 65065.611605882645, "episode/length": 219.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 506384, "time": 65074.53123044968, "episode/length": 230.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9826839826839827, "episode/intrinsic_return": 0.0}
{"step": 506440, "time": 65082.56147813797, "episode/length": 165.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 506696, "time": 65113.70336198807, "episode/length": 639.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9953125, "episode/intrinsic_return": 0.0}
{"step": 507400, "time": 65196.53770184517, "episode/length": 431.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 507424, "time": 65200.89329576492, "episode/length": 122.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.959349593495935, "episode/intrinsic_return": 0.0}
{"step": 507632, "time": 65226.37470459938, "episode/length": 235.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9661016949152542, "episode/intrinsic_return": 0.0}
{"step": 507664, "time": 65231.64824795723, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9644970414201184, "episode/intrinsic_return": 0.0}
{"step": 508136, "time": 65289.0944378376, "episode/length": 179.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 508216, "time": 65299.964985609055, "episode/length": 236.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9789029535864979, "episode/intrinsic_return": 0.0}
{"step": 508504, "time": 65334.72701048851, "episode/length": 304.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 508656, "time": 65353.78376889229, "episode/length": 156.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 508689, "time": 65359.967867136, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.385446633024169, "train/action_min": 0.0, "train/action_std": 3.0535491840005506, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.042925341109850725, "train/actor_opt_grad_steps": 125770.0, "train/actor_opt_loss": -11.987073729264326, "train/adv_mag": 0.4507621607463348, "train/adv_max": 0.41612974161584976, "train/adv_mean": 0.002198802897877559, "train/adv_min": -0.3713215196073936, "train/adv_std": 0.05385802245786037, "train/cont_avg": 0.9950113531403941, "train/cont_loss_mean": 0.00010415779193435407, "train/cont_loss_std": 0.00317508460524362, "train/cont_neg_acc": 0.9944444448489861, "train/cont_neg_loss": 0.017503975281134745, "train/cont_pos_acc": 0.9999999817956258, "train/cont_pos_loss": 1.2866233455659832e-05, "train/cont_pred": 0.9950292985427556, "train/cont_rate": 0.9950113531403941, "train/dyn_loss_mean": 7.033347101634359, "train/dyn_loss_std": 9.008297490368923, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1239223494905557, "train/extr_critic_critic_opt_grad_steps": 125770.0, "train/extr_critic_critic_opt_loss": 16986.983177147475, "train/extr_critic_mag": 8.97025361554376, "train/extr_critic_max": 8.97025361554376, "train/extr_critic_mean": 2.0642180718811862, "train/extr_critic_min": -0.5654738571843491, "train/extr_critic_std": 2.0986588582616723, "train/extr_return_normed_mag": 1.5040984382770333, "train/extr_return_normed_max": 1.5040984382770333, "train/extr_return_normed_mean": 0.34384115502752105, "train/extr_return_normed_min": -0.09877888509645838, "train/extr_return_normed_std": 0.3213458702041598, "train/extr_return_rate": 0.6895715055500933, "train/extr_return_raw_mag": 9.77678231770182, "train/extr_return_raw_max": 9.77678231770182, "train/extr_return_raw_mean": 2.0787940254352364, "train/extr_return_raw_min": -0.857883544391012, "train/extr_return_raw_std": 2.1322478607957587, "train/extr_reward_mag": 1.0444955743592361, "train/extr_reward_max": 1.0444955743592361, "train/extr_reward_mean": 0.04369317160304544, "train/extr_reward_min": -0.6885994743243814, "train/extr_reward_std": 0.2038076968469056, "train/image_loss_mean": 3.8826768539222005, "train/image_loss_std": 8.983686714924028, "train/model_loss_mean": 8.154483919660446, "train/model_loss_std": 13.179920811958501, "train/model_opt_grad_norm": 40.41462869597186, "train/model_opt_grad_steps": 125661.52709359606, "train/model_opt_loss": 11060.127799799877, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1348.5221674876848, "train/policy_entropy_mag": 2.564282127201851, "train/policy_entropy_max": 2.564282127201851, "train/policy_entropy_mean": 0.438437032141709, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6158080231673612, "train/policy_logprob_mag": 7.438384114815096, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.4376718501739314, "train/policy_logprob_min": -7.438384114815096, "train/policy_logprob_std": 1.0515696192022614, "train/policy_randomness_mag": 0.9050790611746276, "train/policy_randomness_max": 0.9050790611746276, "train/policy_randomness_mean": 0.1547490323485412, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.21735320948614864, "train/post_ent_mag": 59.554317060949764, "train/post_ent_max": 59.554317060949764, "train/post_ent_mean": 42.78781979189718, "train/post_ent_min": 19.666058498063112, "train/post_ent_std": 6.857621322124462, "train/prior_ent_mag": 75.82460322638451, "train/prior_ent_max": 75.82460322638451, "train/prior_ent_mean": 49.804089325402174, "train/prior_ent_min": 29.572162008050626, "train/prior_ent_std": 7.343007916887405, "train/rep_loss_mean": 7.033347101634359, "train/rep_loss_std": 9.008297490368923, "train/reward_avg": 0.03389537767530075, "train/reward_loss_mean": 0.05169467091230043, "train/reward_loss_std": 0.21489132346190842, "train/reward_max_data": 1.017733994375896, "train/reward_max_pred": 1.015043308582212, "train/reward_neg_acc": 0.99429365185094, "train/reward_neg_loss": 0.023826790643222812, "train/reward_pos_acc": 0.9857927361145395, "train/reward_pos_loss": 0.7481774558574695, "train/reward_pred": 0.03340565310011209, "train/reward_rate": 0.03847560036945813, "train_stats/sum_log_reward": 7.997436132186499, "train_stats/max_log_achievement_collect_coal": 0.3333333333333333, "train_stats/max_log_achievement_collect_drink": 3.5128205128205128, "train_stats/max_log_achievement_collect_sapling": 1.3846153846153846, "train_stats/max_log_achievement_collect_stone": 9.948717948717949, "train_stats/max_log_achievement_collect_wood": 6.153846153846154, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.3076923076923077, "train_stats/max_log_achievement_eat_cow": 0.05128205128205128, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.02564102564102564, "train_stats/max_log_achievement_make_wood_pickaxe": 1.2820512820512822, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_furnace": 1.2820512820512822, "train_stats/max_log_achievement_place_plant": 1.358974358974359, "train_stats/max_log_achievement_place_stone": 3.1794871794871793, "train_stats/max_log_achievement_place_table": 2.230769230769231, "train_stats/max_log_achievement_wake_up": 2.051282051282051, "train_stats/mean_log_entropy": 0.3797099219682889, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 7.007192471064627e-05, "report/cont_loss_std": 0.0018629499245435, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 9.5338502433151e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 6.992300768615678e-05, "report/cont_pred": 0.9940733909606934, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 7.7002153396606445, "report/dyn_loss_std": 9.925116539001465, "report/image_loss_mean": 4.113138198852539, "report/image_loss_std": 8.264317512512207, "report/model_loss_mean": 8.785872459411621, "report/model_loss_std": 13.029052734375, "report/post_ent_mag": 59.3527717590332, "report/post_ent_max": 59.3527717590332, "report/post_ent_mean": 42.35013198852539, "report/post_ent_min": 20.05148696899414, "report/post_ent_std": 7.0371856689453125, "report/prior_ent_mag": 75.81163024902344, "report/prior_ent_max": 75.81163024902344, "report/prior_ent_mean": 49.68993377685547, "report/prior_ent_min": 33.952938079833984, "report/prior_ent_std": 7.591383457183838, "report/rep_loss_mean": 7.7002153396606445, "report/rep_loss_std": 9.925116539001465, "report/reward_avg": 0.03818359598517418, "report/reward_loss_mean": 0.052535444498062134, "report/reward_loss_std": 0.1878250390291214, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0023105144500732, "report/reward_neg_acc": 0.9949030876159668, "report/reward_neg_loss": 0.025326719507575035, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6732740998268127, "report/reward_pred": 0.03999937325716019, "report/reward_rate": 0.0419921875, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.0002886006550397724, "eval/cont_loss_std": 0.00917794369161129, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.1469789743423462, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.5353124354078318e-06, "eval/cont_pred": 0.9982941150665283, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 19.15577507019043, "eval/dyn_loss_std": 13.178912162780762, "eval/image_loss_mean": 18.983110427856445, "eval/image_loss_std": 23.208986282348633, "eval/model_loss_mean": 30.61701202392578, "eval/model_loss_std": 28.625858306884766, "eval/post_ent_mag": 55.195194244384766, "eval/post_ent_max": 55.195194244384766, "eval/post_ent_mean": 40.51416015625, "eval/post_ent_min": 19.844524383544922, "eval/post_ent_std": 7.002294540405273, "eval/prior_ent_mag": 75.81163024902344, "eval/prior_ent_max": 75.81163024902344, "eval/prior_ent_mean": 52.71080780029297, "eval/prior_ent_min": 33.698280334472656, "eval/prior_ent_std": 6.704034805297852, "eval/rep_loss_mean": 19.15577507019043, "eval/rep_loss_std": 13.178912162780762, "eval/reward_avg": 0.04404296725988388, "eval/reward_loss_mean": 0.14014932513237, "eval/reward_loss_std": 0.8614940047264099, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0012173652648926, "eval/reward_neg_acc": 0.9907881021499634, "eval/reward_neg_loss": 0.03898322954773903, "eval/reward_pos_acc": 0.7446808218955994, "eval/reward_pos_loss": 2.243112325668335, "eval/reward_pred": 0.03445471078157425, "eval/reward_rate": 0.0458984375, "replay/size": 508185.0, "replay/inserts": 8096.0, "replay/samples": 32384.0, "replay/insert_wait_avg": 1.5204485226054436e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.387780742682958e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 6.854534149169922e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 999.9947645664215, "timer/env.step_count": 1012.0, "timer/env.step_total": 86.14110517501831, "timer/env.step_frac": 0.08614155616341396, "timer/env.step_avg": 0.08511966914527501, "timer/env.step_min": 0.022977352142333984, "timer/env.step_max": 1.965479850769043, "timer/replay._sample_count": 32384.0, "timer/replay._sample_total": 15.688591957092285, "timer/replay._sample_frac": 0.01568867409410344, "timer/replay._sample_avg": 0.0004844550382007252, "timer/replay._sample_min": 0.0003452301025390625, "timer/replay._sample_max": 0.010758399963378906, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1012.0, "timer/agent.policy_total": 16.008474111557007, "timer/agent.policy_frac": 0.0160085579232987, "timer/agent.policy_avg": 0.015818650307862656, "timer/agent.policy_min": 0.009792089462280273, "timer/agent.policy_max": 0.05640101432800293, "timer/dataset_train_count": 2024.0, "timer/dataset_train_total": 0.29718637466430664, "timer/dataset_train_frac": 0.00029718793057197747, "timer/dataset_train_avg": 0.00014683121277880764, "timer/dataset_train_min": 8.869171142578125e-05, "timer/dataset_train_max": 0.00048542022705078125, "timer/agent.train_count": 2024.0, "timer/agent.train_total": 894.6577849388123, "timer/agent.train_frac": 0.8946624688847433, "timer/agent.train_avg": 0.4420245973017847, "timer/agent.train_min": 0.4329097270965576, "timer/agent.train_max": 0.9763908386230469, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47323155403137207, "timer/agent.report_frac": 0.0004732340316167117, "timer/agent.report_avg": 0.23661577701568604, "timer/agent.report_min": 0.23095393180847168, "timer/agent.report_max": 0.2422776222229004, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.765655517578125e-05, "timer/dataset_eval_frac": 2.7656699970596946e-08, "timer/dataset_eval_avg": 2.765655517578125e-05, "timer/dataset_eval_min": 2.765655517578125e-05, "timer/dataset_eval_max": 2.765655517578125e-05, "fps": 8.09593384553416}
{"step": 508720, "time": 65363.43404626846, "episode/length": 161.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 508784, "time": 65372.30905294418, "episode/length": 299.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9766666666666667, "episode/intrinsic_return": 0.0}
{"step": 509256, "time": 65429.61410284042, "episode/length": 198.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 509384, "time": 65446.05454659462, "episode/length": 155.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 509600, "time": 65472.747329473495, "episode/length": 245.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9796747967479674, "episode/intrinsic_return": 0.0}
{"step": 509640, "time": 65478.786969423294, "episode/length": 177.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9662921348314607, "episode/intrinsic_return": 0.0}
{"step": 509776, "time": 65496.03619503975, "episode/length": 158.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 509816, "time": 65502.207391262054, "episode/length": 144.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 510016, "time": 65541.72944831848, "eval_episode/length": 54.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9818181818181818}
{"step": 510016, "time": 65546.56952166557, "eval_episode/length": 120.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9917355371900827}
{"step": 510016, "time": 65552.21382117271, "eval_episode/length": 195.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.9846938775510204}
{"step": 510016, "time": 65554.31719613075, "eval_episode/length": 199.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.975}
{"step": 510016, "time": 65556.32590150833, "eval_episode/length": 201.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9801980198019802}
{"step": 510016, "time": 65558.37932348251, "eval_episode/length": 204.0, "eval_episode/score": 10.099999994039536, "eval_episode/reward_rate": 0.9951219512195122}
{"step": 510016, "time": 65561.38145112991, "eval_episode/length": 214.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9953488372093023}
{"step": 510016, "time": 65565.76980090141, "eval_episode/length": 236.0, "eval_episode/score": 10.099999979138374, "eval_episode/reward_rate": 0.9957805907172996}
{"step": 510496, "time": 65621.39643287659, "episode/length": 213.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9626168224299065, "episode/intrinsic_return": 0.0}
{"step": 510696, "time": 65646.14297819138, "episode/length": 246.0, "episode/score": 10.100000016391277, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 510792, "time": 65658.89918708801, "episode/length": 143.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 510912, "time": 65674.35741114616, "episode/length": 206.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 511088, "time": 65696.41942477226, "episode/length": 158.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 511248, "time": 65716.5166311264, "episode/length": 183.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 511392, "time": 65734.54316520691, "episode/length": 223.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 511408, "time": 65737.88259887695, "episode/length": 252.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.9802371541501976, "episode/intrinsic_return": 0.0}
{"step": 511968, "time": 65804.03020167351, "episode/length": 71.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9444444444444444, "episode/intrinsic_return": 0.0}
{"step": 511976, "time": 65806.50693321228, "episode/length": 159.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 512184, "time": 65832.3046195507, "episode/length": 173.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 512200, "time": 65836.19841861725, "episode/length": 212.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 512456, "time": 65867.89934182167, "episode/length": 130.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9618320610687023, "episode/intrinsic_return": 0.0}
{"step": 512568, "time": 65882.81845808029, "episode/length": 184.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 512888, "time": 65921.40973210335, "episode/length": 246.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9838056680161943, "episode/intrinsic_return": 0.0}
{"step": 512976, "time": 65933.21439862251, "episode/length": 215.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 513488, "time": 65994.47306966782, "episode/length": 160.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 513520, "time": 65999.6526043415, "episode/length": 166.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 513832, "time": 66037.53269910812, "episode/length": 171.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 514184, "time": 66080.43724322319, "episode/length": 275.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 514232, "time": 66087.40485334396, "episode/length": 167.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 514352, "time": 66102.73372220993, "episode/length": 171.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 514624, "time": 66135.7968943119, "episode/length": 256.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9844357976653697, "episode/intrinsic_return": 0.0}
{"step": 514680, "time": 66143.78954029083, "episode/length": 338.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9882005899705014, "episode/intrinsic_return": 0.0}
{"step": 514712, "time": 66148.98368191719, "episode/length": 152.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.0}
{"step": 515176, "time": 66204.17623400688, "episode/length": 61.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 515200, "time": 66208.45962119102, "episode/length": 170.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 515376, "time": 66230.2276661396, "episode/length": 231.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9698275862068966, "episode/intrinsic_return": 0.0}
{"step": 515536, "time": 66250.50903201103, "episode/length": 162.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 515800, "time": 66283.15799999237, "episode/length": 180.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 515824, "time": 66287.93765497208, "episode/length": 204.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 516360, "time": 66352.70838522911, "episode/length": 205.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.970873786407767, "episode/intrinsic_return": 0.0}
{"step": 516405, "time": 66360.27834153175, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.428247639552299, "train/action_min": 0.0, "train/action_std": 3.067928069613758, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04373660075618195, "train/actor_opt_grad_steps": 127750.0, "train/actor_opt_loss": -12.097094809897051, "train/adv_mag": 0.45281807560994836, "train/adv_max": 0.412392509107145, "train/adv_mean": 0.0024276644191201027, "train/adv_min": -0.388168120476866, "train/adv_std": 0.05457642164872718, "train/cont_avg": 0.9948692519430051, "train/cont_loss_mean": 0.00012380858219157662, "train/cont_loss_std": 0.003595351502727148, "train/cont_neg_acc": 0.9980364343045289, "train/cont_neg_loss": 0.010278012580298602, "train/cont_pos_acc": 0.99998981501772, "train/cont_pos_loss": 5.0453006731883144e-05, "train/cont_pred": 0.9948570678888825, "train/cont_rate": 0.9948692519430051, "train/dyn_loss_mean": 6.858209535865586, "train/dyn_loss_std": 8.889046817245879, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1093435333800439, "train/extr_critic_critic_opt_grad_steps": 127750.0, "train/extr_critic_critic_opt_loss": 16829.57181023316, "train/extr_critic_mag": 8.863094868437614, "train/extr_critic_max": 8.863094868437614, "train/extr_critic_mean": 2.056075040540547, "train/extr_critic_min": -0.5480809761452551, "train/extr_critic_std": 2.062327641279586, "train/extr_return_normed_mag": 1.517538014471222, "train/extr_return_normed_max": 1.517538014471222, "train/extr_return_normed_mean": 0.3490871148560331, "train/extr_return_normed_min": -0.09821746108445478, "train/extr_return_normed_std": 0.32262228853961966, "train/extr_return_rate": 0.688878354939772, "train/extr_return_raw_mag": 9.662811328710053, "train/extr_return_raw_max": 9.662811328710053, "train/extr_return_raw_mean": 2.0718406500593987, "train/extr_return_raw_min": -0.8332797290438815, "train/extr_return_raw_std": 2.0956724474467143, "train/extr_reward_mag": 1.0457697989409451, "train/extr_reward_max": 1.0457697989409451, "train/extr_reward_mean": 0.045319048301775224, "train/extr_reward_min": -0.6745199280081635, "train/extr_reward_std": 0.20780562296741367, "train/image_loss_mean": 3.712295570521775, "train/image_loss_std": 8.429432290823348, "train/model_loss_mean": 7.8787304601521075, "train/model_loss_std": 12.545699228276861, "train/model_opt_grad_norm": 38.35730693006762, "train/model_opt_grad_steps": 127640.38860103628, "train/model_opt_loss": 14228.980618017325, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1806.9948186528497, "train/policy_entropy_mag": 2.576761765801227, "train/policy_entropy_max": 2.576761765801227, "train/policy_entropy_mean": 0.44158646356256515, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6173769850187351, "train/policy_logprob_mag": 7.438384130211074, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.44192006087673763, "train/policy_logprob_min": -7.438384130211074, "train/policy_logprob_std": 1.0564561878461294, "train/policy_randomness_mag": 0.9094838259133651, "train/policy_randomness_max": 0.9094838259133651, "train/policy_randomness_mean": 0.15586064254064017, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.217906982324284, "train/post_ent_mag": 59.570067726886336, "train/post_ent_max": 59.570067726886336, "train/post_ent_mean": 42.89650433792352, "train/post_ent_min": 19.617924705070536, "train/post_ent_std": 6.891445229090557, "train/prior_ent_mag": 75.82111935788485, "train/prior_ent_max": 75.82111935788485, "train/prior_ent_mean": 49.779961581057215, "train/prior_ent_min": 30.043047939557486, "train/prior_ent_std": 7.334846568231138, "train/rep_loss_mean": 6.858209535865586, "train/rep_loss_std": 8.889046817245879, "train/reward_avg": 0.03452780892001224, "train/reward_loss_mean": 0.05138532715063021, "train/reward_loss_std": 0.211696363560894, "train/reward_max_data": 1.017098449672442, "train/reward_max_pred": 1.0166163913944224, "train/reward_neg_acc": 0.9944920017929275, "train/reward_neg_loss": 0.023035916123404096, "train/reward_pos_acc": 0.9849911770672378, "train/reward_pos_loss": 0.7488782727038922, "train/reward_pred": 0.03411370115306402, "train/reward_rate": 0.03915863827720207, "train_stats/sum_log_reward": 8.350000178813934, "train_stats/max_log_achievement_collect_coal": 0.825, "train_stats/max_log_achievement_collect_drink": 4.05, "train_stats/max_log_achievement_collect_sapling": 1.275, "train_stats/max_log_achievement_collect_stone": 9.975, "train_stats/max_log_achievement_collect_wood": 5.725, "train_stats/max_log_achievement_defeat_skeleton": 0.025, "train_stats/max_log_achievement_defeat_zombie": 0.275, "train_stats/max_log_achievement_eat_cow": 0.075, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.225, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_furnace": 1.325, "train_stats/max_log_achievement_place_plant": 1.2, "train_stats/max_log_achievement_place_stone": 3.425, "train_stats/max_log_achievement_place_table": 2.025, "train_stats/max_log_achievement_wake_up": 1.675, "train_stats/mean_log_entropy": 0.3803747955709696, "eval_stats/sum_log_reward": 8.10000005364418, "eval_stats/max_log_achievement_collect_coal": 1.75, "eval_stats/max_log_achievement_collect_drink": 2.5, "eval_stats/max_log_achievement_collect_sapling": 1.125, "eval_stats/max_log_achievement_collect_stone": 11.125, "eval_stats/max_log_achievement_collect_wood": 5.0, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.375, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.25, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 1.625, "eval_stats/max_log_achievement_place_plant": 1.0, "eval_stats/max_log_achievement_place_stone": 2.125, "eval_stats/max_log_achievement_place_table": 1.75, "eval_stats/max_log_achievement_wake_up": 1.0, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 6.226047844393179e-05, "report/cont_loss_std": 0.001910068211145699, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.010208657011389732, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.458541757732746e-06, "report/cont_pred": 0.9941961765289307, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 6.349330902099609, "report/dyn_loss_std": 8.399864196777344, "report/image_loss_mean": 2.559542179107666, "report/image_loss_std": 5.758968830108643, "report/model_loss_mean": 6.421698093414307, "report/model_loss_std": 9.841981887817383, "report/post_ent_mag": 63.633453369140625, "report/post_ent_max": 63.633453369140625, "report/post_ent_mean": 42.93603515625, "report/post_ent_min": 21.238821029663086, "report/post_ent_std": 6.781752586364746, "report/prior_ent_mag": 76.09808349609375, "report/prior_ent_max": 76.09808349609375, "report/prior_ent_mean": 49.222721099853516, "report/prior_ent_min": 29.915040969848633, "report/prior_ent_std": 7.288377285003662, "report/rep_loss_mean": 6.349330902099609, "report/rep_loss_std": 8.399864196777344, "report/reward_avg": 0.0419921875, "report/reward_loss_mean": 0.05249503254890442, "report/reward_loss_std": 0.2153802514076233, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.039902687072754, "report/reward_neg_acc": 0.9999999403953552, "report/reward_neg_loss": 0.01952042244374752, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7086225152015686, "report/reward_pred": 0.041201457381248474, "report/reward_rate": 0.0478515625, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 3.1262040920410072e-06, "eval/cont_loss_std": 2.4014372684177943e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00010415451106382534, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.928496996901231e-06, "eval/cont_pred": 0.9980441331863403, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 19.848966598510742, "eval/dyn_loss_std": 13.368025779724121, "eval/image_loss_mean": 17.22271728515625, "eval/image_loss_std": 30.179670333862305, "eval/model_loss_mean": 29.29633903503418, "eval/model_loss_std": 34.33449935913086, "eval/post_ent_mag": 60.40228271484375, "eval/post_ent_max": 60.40228271484375, "eval/post_ent_mean": 39.168827056884766, "eval/post_ent_min": 18.732568740844727, "eval/post_ent_std": 7.352317810058594, "eval/prior_ent_mag": 76.09808349609375, "eval/prior_ent_max": 76.09808349609375, "eval/prior_ent_mean": 52.38460922241211, "eval/prior_ent_min": 36.437313079833984, "eval/prior_ent_std": 6.156353950500488, "eval/rep_loss_mean": 19.848966598510742, "eval/rep_loss_std": 13.368025779724121, "eval/reward_avg": 0.05527343600988388, "eval/reward_loss_mean": 0.16423866152763367, "eval/reward_loss_std": 0.9613646864891052, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.004624843597412, "eval/reward_neg_acc": 0.9896373748779297, "eval/reward_neg_loss": 0.08305521309375763, "eval/reward_pos_acc": 0.8305084705352783, "eval/reward_pos_loss": 1.492069959640503, "eval/reward_pred": 0.04977340251207352, "eval/reward_rate": 0.0576171875, "replay/size": 515901.0, "replay/inserts": 7716.0, "replay/samples": 30864.0, "replay/insert_wait_avg": 1.5382571440400578e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.389709083078561e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 1896.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.201524010187463e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.748603820800781e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.293054819107, "timer/env.step_count": 964.0, "timer/env.step_total": 89.26842093467712, "timer/env.step_frac": 0.0892422680579547, "timer/env.step_avg": 0.09260209640526673, "timer/env.step_min": 0.022619009017944336, "timer/env.step_max": 2.0314128398895264, "timer/replay._sample_count": 30864.0, "timer/replay._sample_total": 14.967313528060913, "timer/replay._sample_frac": 0.014962928569735598, "timer/replay._sample_avg": 0.00048494406195117006, "timer/replay._sample_min": 0.0004031658172607422, "timer/replay._sample_max": 0.01062631607055664, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1201.0, "timer/agent.policy_total": 19.490998029708862, "timer/agent.policy_frac": 0.019485287772225524, "timer/agent.policy_avg": 0.01622897421291329, "timer/agent.policy_min": 0.009807348251342773, "timer/agent.policy_max": 0.19028544425964355, "timer/dataset_train_count": 1929.0, "timer/dataset_train_total": 0.2866044044494629, "timer/dataset_train_frac": 0.00028652043825425983, "timer/dataset_train_avg": 0.00014857667415731616, "timer/dataset_train_min": 9.036064147949219e-05, "timer/dataset_train_max": 0.0011076927185058594, "timer/agent.train_count": 1929.0, "timer/agent.train_total": 853.7320985794067, "timer/agent.train_frac": 0.8534819815716861, "timer/agent.train_avg": 0.4425775523998998, "timer/agent.train_min": 0.4316275119781494, "timer/agent.train_max": 0.9589624404907227, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47459840774536133, "timer/agent.report_frac": 0.000474459365141936, "timer/agent.report_avg": 0.23729920387268066, "timer/agent.report_min": 0.23087143898010254, "timer/agent.report_max": 0.2437269687652588, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7894973754882812e-05, "timer/dataset_eval_frac": 2.788680139334501e-08, "timer/dataset_eval_avg": 2.7894973754882812e-05, "timer/dataset_eval_min": 2.7894973754882812e-05, "timer/dataset_eval_max": 2.7894973754882812e-05, "fps": 7.713631194909767}
{"step": 516624, "time": 66385.62890648842, "episode/length": 155.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 516848, "time": 66413.36423826218, "episode/length": 163.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9634146341463414, "episode/intrinsic_return": 0.0}
{"step": 517120, "time": 66446.68264174461, "episode/length": 61.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9193548387096774, "episode/intrinsic_return": 0.0}
{"step": 517264, "time": 66465.04966497421, "episode/length": 260.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9808429118773946, "episode/intrinsic_return": 0.0}
{"step": 517344, "time": 66475.7510368824, "episode/length": 339.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9911764705882353, "episode/intrinsic_return": 0.0}
{"step": 517464, "time": 66491.281676054, "episode/length": 204.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 517744, "time": 66525.4431169033, "episode/length": 317.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9968553459119497, "episode/intrinsic_return": 0.0}
{"step": 517864, "time": 66540.89701724052, "episode/length": 257.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9806201550387597, "episode/intrinsic_return": 0.0}
{"step": 518192, "time": 66580.9170229435, "episode/length": 228.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 518288, "time": 66593.58677315712, "episode/length": 145.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 518496, "time": 66619.31815695763, "episode/length": 153.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9545454545454546, "episode/intrinsic_return": 0.0}
{"step": 518536, "time": 66626.07060647011, "episode/length": 210.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9715639810426541, "episode/intrinsic_return": 0.0}
{"step": 518776, "time": 66655.51510715485, "episode/length": 163.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 519000, "time": 66683.11597251892, "episode/length": 156.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9554140127388535, "episode/intrinsic_return": 0.0}
{"step": 519600, "time": 66754.39159846306, "episode/length": 175.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9659090909090909, "episode/intrinsic_return": 0.0}
{"step": 519808, "time": 66780.04182624817, "episode/length": 189.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 520000, "time": 66820.56455087662, "eval_episode/length": 113.0, "eval_episode/score": 8.100000023841858, "eval_episode/reward_rate": 0.9649122807017544}
{"step": 520000, "time": 66822.99561667442, "eval_episode/length": 136.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9927007299270073}
{"step": 520000, "time": 66825.15119051933, "eval_episode/length": 152.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9934640522875817}
{"step": 520000, "time": 66826.67781543732, "eval_episode/length": 154.0, "eval_episode/score": 9.100000023841858, "eval_episode/reward_rate": 0.9935483870967742}
{"step": 520000, "time": 66828.91106653214, "eval_episode/length": 174.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 520000, "time": 66830.85701656342, "eval_episode/length": 187.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9627659574468085}
{"step": 520000, "time": 66832.84620165825, "eval_episode/length": 200.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9800995024875622}
{"step": 520000, "time": 66836.68501377106, "eval_episode/length": 260.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9846743295019157}
{"step": 520296, "time": 66870.9910171032, "episode/length": 60.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 520304, "time": 66873.47966742516, "episode/length": 225.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9690265486725663, "episode/intrinsic_return": 0.0}
{"step": 520376, "time": 66883.46557331085, "episode/length": 199.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 520592, "time": 66909.96179270744, "episode/length": 340.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9912023460410557, "episode/intrinsic_return": 0.0}
{"step": 520664, "time": 66919.81538414955, "episode/length": 207.0, "episode/score": 9.099999964237213, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 520784, "time": 66935.248462677, "episode/length": 429.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9790697674418605, "episode/intrinsic_return": 0.0}
{"step": 520896, "time": 66949.73934316635, "episode/length": 64.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9384615384615385, "episode/intrinsic_return": 0.0}
{"step": 521432, "time": 67013.49393773079, "episode/length": 361.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 521504, "time": 67023.84327435493, "episode/length": 237.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 521672, "time": 67044.93265008926, "episode/length": 171.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 521744, "time": 67054.6921312809, "episode/length": 179.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 522552, "time": 67149.98315858841, "episode/length": 244.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 522664, "time": 67164.54288935661, "episode/length": 249.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 522968, "time": 67201.40641665459, "episode/length": 161.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 523088, "time": 67216.82685685158, "episode/length": 273.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9854014598540146, "episode/intrinsic_return": 0.0}
{"step": 523104, "time": 67220.33963036537, "episode/length": 199.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 523320, "time": 67247.00765800476, "episode/length": 196.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9695431472081218, "episode/intrinsic_return": 0.0}
{"step": 523592, "time": 67280.51754450798, "episode/length": 350.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9943019943019943, "episode/intrinsic_return": 0.0}
{"step": 523760, "time": 67301.46496939659, "episode/length": 290.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9862542955326461, "episode/intrinsic_return": 0.0}
{"step": 524088, "time": 67340.96505689621, "episode/length": 191.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 524104, "time": 67344.1993560791, "episode/length": 179.0, "episode/score": 10.099999964237213, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 524192, "time": 67355.93387913704, "episode/length": 108.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9908256880733946, "episode/intrinsic_return": 0.0}
{"step": 524205, "time": 67360.34973883629, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.459532439403045, "train/action_min": 0.0, "train/action_std": 3.077376807041657, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04337583719155727, "train/actor_opt_grad_steps": 129690.0, "train/actor_opt_loss": -9.912791484135848, "train/adv_mag": 0.4541157129483345, "train/adv_max": 0.43354332599884426, "train/adv_mean": 0.002877110010432751, "train/adv_min": -0.3647188051388814, "train/adv_std": 0.05433500472169656, "train/cont_avg": 0.9947566105769231, "train/cont_loss_mean": 4.3700775239877215e-05, "train/cont_loss_std": 0.0012214723872358054, "train/cont_neg_acc": 0.997115857207898, "train/cont_neg_loss": 0.005785501513527538, "train/cont_pos_acc": 0.9999949461374528, "train/cont_pos_loss": 1.8868063866998105e-05, "train/cont_pred": 0.9947590879904918, "train/cont_rate": 0.9947566105769231, "train/dyn_loss_mean": 7.023294370602339, "train/dyn_loss_std": 8.988936490278977, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.075079742150429, "train/extr_critic_critic_opt_grad_steps": 129690.0, "train/extr_critic_critic_opt_loss": 16773.64563301282, "train/extr_critic_mag": 8.798214721679688, "train/extr_critic_max": 8.798214721679688, "train/extr_critic_mean": 2.048270316613026, "train/extr_critic_min": -0.5451201610076122, "train/extr_critic_std": 2.0865026052181537, "train/extr_return_normed_mag": 1.5231559331600482, "train/extr_return_normed_max": 1.5231559331600482, "train/extr_return_normed_mean": 0.34598546211536113, "train/extr_return_normed_min": -0.10221447485188644, "train/extr_return_normed_std": 0.3268441882653114, "train/extr_return_rate": 0.6763578748091673, "train/extr_return_raw_mag": 9.713468825511443, "train/extr_return_raw_max": 9.713468825511443, "train/extr_return_raw_mean": 2.066940610836714, "train/extr_return_raw_min": -0.8449274495626107, "train/extr_return_raw_std": 2.123694050617707, "train/extr_reward_mag": 1.0418936130328056, "train/extr_reward_max": 1.0418936130328056, "train/extr_reward_mean": 0.044694499289378145, "train/extr_reward_min": -0.6760229532535259, "train/extr_reward_std": 0.20647344314135038, "train/image_loss_mean": 3.829432047330416, "train/image_loss_std": 8.891282810308994, "train/model_loss_mean": 8.094484519958495, "train/model_loss_std": 13.066782061258952, "train/model_opt_grad_norm": 41.31986084962502, "train/model_opt_grad_steps": 129578.53846153847, "train/model_opt_loss": 10556.74828475561, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1301.2820512820513, "train/policy_entropy_mag": 2.5752496462601884, "train/policy_entropy_max": 2.5752496462601884, "train/policy_entropy_mean": 0.45699304067171537, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6363806424996792, "train/policy_logprob_mag": 7.438384144122784, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.4566036737882174, "train/policy_logprob_min": -7.438384144122784, "train/policy_logprob_std": 1.0670403177921588, "train/policy_randomness_mag": 0.9089501130275237, "train/policy_randomness_max": 0.9089501130275237, "train/policy_randomness_mean": 0.1612984883479583, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.22461444047781137, "train/post_ent_mag": 59.4374514457507, "train/post_ent_max": 59.4374514457507, "train/post_ent_mean": 42.74497389182066, "train/post_ent_min": 19.548803143623548, "train/post_ent_std": 6.841902921138666, "train/prior_ent_mag": 75.85374360695863, "train/prior_ent_max": 75.85374360695863, "train/prior_ent_mean": 49.76862053504357, "train/prior_ent_min": 30.137216714712288, "train/prior_ent_std": 7.349679973797921, "train/rep_loss_mean": 7.023294370602339, "train/rep_loss_std": 8.988936490278977, "train/reward_avg": 0.03411959107869711, "train/reward_loss_mean": 0.051032176785744156, "train/reward_loss_std": 0.20707018979084799, "train/reward_max_data": 1.0169230809578529, "train/reward_max_pred": 1.0162401150434446, "train/reward_neg_acc": 0.9940769378955547, "train/reward_neg_loss": 0.023201620339965208, "train/reward_pos_acc": 0.9873270826461987, "train/reward_pos_loss": 0.7409189734703455, "train/reward_pred": 0.03382707600219127, "train/reward_rate": 0.0388671875, "train_stats/sum_log_reward": 8.46842130234367, "train_stats/max_log_achievement_collect_coal": 0.6578947368421053, "train_stats/max_log_achievement_collect_drink": 3.8947368421052633, "train_stats/max_log_achievement_collect_sapling": 1.5526315789473684, "train_stats/max_log_achievement_collect_stone": 11.947368421052632, "train_stats/max_log_achievement_collect_wood": 6.052631578947368, "train_stats/max_log_achievement_defeat_skeleton": 0.05263157894736842, "train_stats/max_log_achievement_defeat_zombie": 0.18421052631578946, "train_stats/max_log_achievement_eat_cow": 0.05263157894736842, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.394736842105263, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_furnace": 1.7105263157894737, "train_stats/max_log_achievement_place_plant": 1.5, "train_stats/max_log_achievement_place_stone": 3.3684210526315788, "train_stats/max_log_achievement_place_table": 2.1052631578947367, "train_stats/max_log_achievement_wake_up": 2.0, "train_stats/mean_log_entropy": 0.4549505326308702, "eval_stats/sum_log_reward": 7.975000023841858, "eval_stats/max_log_achievement_collect_coal": 0.375, "eval_stats/max_log_achievement_collect_drink": 2.5, "eval_stats/max_log_achievement_collect_sapling": 1.875, "eval_stats/max_log_achievement_collect_stone": 7.375, "eval_stats/max_log_achievement_collect_wood": 5.875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.25, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.75, "eval_stats/max_log_achievement_place_plant": 1.5, "eval_stats/max_log_achievement_place_stone": 2.875, "eval_stats/max_log_achievement_place_table": 1.875, "eval_stats/max_log_achievement_wake_up": 1.75, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.00017445879348088056, "report/cont_loss_std": 0.0044613792560994625, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.009925052523612976, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.00013622116239275783, "report/cont_pred": 0.9960049986839294, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 5.636175632476807, "report/dyn_loss_std": 7.909487724304199, "report/image_loss_mean": 3.0945510864257812, "report/image_loss_std": 6.000777244567871, "report/model_loss_mean": 6.527893543243408, "report/model_loss_std": 9.813759803771973, "report/post_ent_mag": 61.36669158935547, "report/post_ent_max": 61.36669158935547, "report/post_ent_mean": 42.925819396972656, "report/post_ent_min": 22.02347183227539, "report/post_ent_std": 7.005418300628662, "report/prior_ent_mag": 75.24969482421875, "report/prior_ent_max": 75.24969482421875, "report/prior_ent_mean": 49.335304260253906, "report/prior_ent_min": 31.13228988647461, "report/prior_ent_std": 7.464527130126953, "report/rep_loss_mean": 5.636175632476807, "report/rep_loss_std": 7.909487724304199, "report/reward_avg": 0.03378906473517418, "report/reward_loss_mean": 0.051462531089782715, "report/reward_loss_std": 0.21913844347000122, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0018348693847656, "report/reward_neg_acc": 0.9939086437225342, "report/reward_neg_loss": 0.023132866248488426, "report/reward_pos_acc": 0.9743589758872986, "report/reward_pos_loss": 0.7669681310653687, "report/reward_pred": 0.03259044140577316, "report/reward_rate": 0.0380859375, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 2.5413457478862256e-05, "eval/cont_loss_std": 0.00067868921905756, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0011509181931614876, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.2106392862042412e-05, "eval/cont_pred": 0.9970519542694092, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 17.488719940185547, "eval/dyn_loss_std": 12.392959594726562, "eval/image_loss_mean": 17.59345245361328, "eval/image_loss_std": 20.575031280517578, "eval/model_loss_mean": 28.174251556396484, "eval/model_loss_std": 24.787382125854492, "eval/post_ent_mag": 58.19061279296875, "eval/post_ent_max": 58.19061279296875, "eval/post_ent_mean": 40.537803649902344, "eval/post_ent_min": 19.655237197875977, "eval/post_ent_std": 6.974672794342041, "eval/prior_ent_mag": 75.24969482421875, "eval/prior_ent_max": 75.24969482421875, "eval/prior_ent_mean": 52.24647521972656, "eval/prior_ent_min": 34.18105697631836, "eval/prior_ent_std": 7.24216890335083, "eval/rep_loss_mean": 17.488719940185547, "eval/rep_loss_std": 12.392959594726562, "eval/reward_avg": 0.02910156175494194, "eval/reward_loss_mean": 0.08754360675811768, "eval/reward_loss_std": 0.5938385725021362, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.001218318939209, "eval/reward_neg_acc": 0.9929364323616028, "eval/reward_neg_loss": 0.02578374557197094, "eval/reward_pos_acc": 0.7878787517547607, "eval/reward_pos_loss": 1.9422110319137573, "eval/reward_pred": 0.024437634274363518, "eval/reward_rate": 0.0322265625, "replay/size": 523701.0, "replay/inserts": 7800.0, "replay/samples": 31200.0, "replay/insert_wait_avg": 1.5276211958665114e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.333510961288061e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 2088.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.072198495097544e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.897615432739258e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.059915304184, "timer/env.step_count": 975.0, "timer/env.step_total": 85.99408388137817, "timer/env.step_frac": 0.08598893182837122, "timer/env.step_avg": 0.0881990603911571, "timer/env.step_min": 0.02348184585571289, "timer/env.step_max": 2.081885814666748, "timer/replay._sample_count": 31200.0, "timer/replay._sample_total": 15.226505517959595, "timer/replay._sample_frac": 0.015225593271907327, "timer/replay._sample_avg": 0.0004880290230115255, "timer/replay._sample_min": 0.0003693103790283203, "timer/replay._sample_max": 0.032534122467041016, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1236.0, "timer/agent.policy_total": 19.492575645446777, "timer/agent.policy_frac": 0.01949140781181876, "timer/agent.policy_avg": 0.015770692269778945, "timer/agent.policy_min": 0.009335756301879883, "timer/agent.policy_max": 0.04152655601501465, "timer/dataset_train_count": 1950.0, "timer/dataset_train_total": 0.2926294803619385, "timer/dataset_train_frac": 0.00029261194842804055, "timer/dataset_train_avg": 0.00015006640018560947, "timer/dataset_train_min": 9.369850158691406e-05, "timer/dataset_train_max": 0.0007398128509521484, "timer/agent.train_count": 1950.0, "timer/agent.train_total": 862.7337739467621, "timer/agent.train_frac": 0.8626820860871601, "timer/agent.train_avg": 0.44242757638295493, "timer/agent.train_min": 0.430816650390625, "timer/agent.train_max": 0.554276704788208, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.46885013580322266, "timer/agent.report_frac": 0.00046882204618771715, "timer/agent.report_avg": 0.23442506790161133, "timer/agent.report_min": 0.2271440029144287, "timer/agent.report_max": 0.24170613288879395, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9325485229492188e-05, "timer/dataset_eval_frac": 2.932372828939192e-08, "timer/dataset_eval_avg": 2.9325485229492188e-05, "timer/dataset_eval_min": 2.9325485229492188e-05, "timer/dataset_eval_max": 2.9325485229492188e-05, "fps": 7.799432324671592}
{"step": 524632, "time": 67411.05946087837, "episode/length": 207.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9711538461538461, "episode/intrinsic_return": 0.0}
{"step": 524720, "time": 67422.88853693008, "episode/length": 201.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 525112, "time": 67470.01623010635, "episode/length": 252.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9960474308300395, "episode/intrinsic_return": 0.0}
{"step": 525160, "time": 67477.62215399742, "episode/length": 195.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 525272, "time": 67492.56746220589, "episode/length": 147.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 525344, "time": 67502.49222898483, "episode/length": 143.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 525352, "time": 67505.29245257378, "episode/length": 155.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 526296, "time": 67617.93557143211, "episode/length": 196.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 526488, "time": 67641.78708815575, "episode/length": 231.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.978448275862069, "episode/intrinsic_return": 0.0}
{"step": 526720, "time": 67670.5956082344, "episode/length": 171.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 526728, "time": 67672.96798443794, "episode/length": 171.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 527080, "time": 67715.7545785904, "episode/length": 414.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9879518072289156, "episode/intrinsic_return": 0.0}
{"step": 527440, "time": 67759.65727710724, "episode/length": 142.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.958041958041958, "episode/intrinsic_return": 0.0}
{"step": 527464, "time": 67763.95509576797, "episode/length": 273.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9817518248175182, "episode/intrinsic_return": 0.0}
{"step": 527912, "time": 67817.4929125309, "episode/length": 58.0, "episode/score": 6.100000016391277, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 527984, "time": 67827.3876543045, "episode/length": 64.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9230769230769231, "episode/intrinsic_return": 0.0}
{"step": 528056, "time": 67837.21192288399, "episode/length": 367.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9891304347826086, "episode/intrinsic_return": 0.0}
{"step": 528096, "time": 67843.4062743187, "episode/length": 170.0, "episode/score": 10.099999964237213, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 528152, "time": 67851.35187625885, "episode/length": 178.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9608938547486033, "episode/intrinsic_return": 0.0}
{"step": 528360, "time": 67876.9536409378, "episode/length": 399.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9975, "episode/intrinsic_return": 0.0}
{"step": 528536, "time": 67898.78707718849, "episode/length": 181.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 528752, "time": 67925.47520804405, "episode/length": 282.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9787985865724381, "episode/intrinsic_return": 0.0}
{"step": 528848, "time": 67938.22758460045, "episode/length": 60.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 529024, "time": 67959.98679494858, "episode/length": 108.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9908256880733946, "episode/intrinsic_return": 0.0}
{"step": 529224, "time": 67984.59045219421, "episode/length": 154.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 529416, "time": 68008.47158694267, "episode/length": 109.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9636363636363636, "episode/intrinsic_return": 0.0}
{"step": 529448, "time": 68013.68237113953, "episode/length": 168.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 529512, "time": 68022.68664646149, "episode/length": 60.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9180327868852459, "episode/intrinsic_return": 0.0}
{"step": 529800, "time": 68057.67932629585, "episode/length": 217.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.981651376146789, "episode/intrinsic_return": 0.0}
{"step": 530088, "time": 68109.22002911568, "eval_episode/length": 109.0, "eval_episode/score": 9.100000023841858, "eval_episode/reward_rate": 0.990909090909091}
{"step": 530088, "time": 68112.92711687088, "eval_episode/length": 161.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9691358024691358}
{"step": 530088, "time": 68115.0177090168, "eval_episode/length": 177.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9719101123595506}
{"step": 530088, "time": 68117.67609906197, "eval_episode/length": 205.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9951456310679612}
{"step": 530088, "time": 68120.01065540314, "eval_episode/length": 224.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9777777777777777}
{"step": 530088, "time": 68121.57507538795, "eval_episode/length": 225.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9778761061946902}
{"step": 530088, "time": 68124.29861497879, "eval_episode/length": 255.0, "eval_episode/score": 8.099999979138374, "eval_episode/reward_rate": 0.9921875}
{"step": 530088, "time": 68129.18272686005, "eval_episode/length": 85.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9418604651162791}
{"step": 530224, "time": 68144.91737127304, "episode/length": 288.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.986159169550173, "episode/intrinsic_return": 0.0}
{"step": 530328, "time": 68158.41365528107, "episode/length": 196.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 530464, "time": 68175.767370224, "episode/length": 201.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 530776, "time": 68213.33504748344, "episode/length": 165.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 530800, "time": 68217.6683857441, "episode/length": 196.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 531192, "time": 68264.66517138481, "episode/length": 48.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.8979591836734694, "episode/intrinsic_return": 0.0}
{"step": 531216, "time": 68269.4836294651, "episode/length": 224.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.0}
{"step": 531264, "time": 68277.0108191967, "episode/length": 218.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 531552, "time": 68312.80355882645, "episode/length": 218.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9863013698630136, "episode/intrinsic_return": 0.0}
{"step": 531624, "time": 68322.80221319199, "episode/length": 174.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 531776, "time": 68341.79501771927, "episode/length": 163.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 531917, "time": 68360.50686430931, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.5046971770765865, "train/action_min": 0.0, "train/action_std": 3.1073066595304817, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04349970920831737, "train/actor_opt_grad_steps": 131630.0, "train/actor_opt_loss": -11.327345065193473, "train/adv_mag": 0.44121039562274755, "train/adv_max": 0.40870251108945344, "train/adv_mean": 0.0023840586673880026, "train/adv_min": -0.3742775390494055, "train/adv_std": 0.05397577944737642, "train/cont_avg": 0.994783233484456, "train/cont_loss_mean": 7.374705556334144e-05, "train/cont_loss_std": 0.002077733071230353, "train/cont_neg_acc": 0.9972222223877907, "train/cont_neg_loss": 0.012165249961517096, "train/cont_pos_acc": 0.999994887589173, "train/cont_pos_loss": 2.8390208021852664e-05, "train/cont_pred": 0.9947738474514818, "train/cont_rate": 0.994783233484456, "train/dyn_loss_mean": 6.892769862950774, "train/dyn_loss_std": 8.981406799869834, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0744011886996927, "train/extr_critic_critic_opt_grad_steps": 131630.0, "train/extr_critic_critic_opt_loss": 16814.90547583387, "train/extr_critic_mag": 8.949114023712633, "train/extr_critic_max": 8.949114023712633, "train/extr_critic_mean": 2.072920946259573, "train/extr_critic_min": -0.5541280372155145, "train/extr_critic_std": 2.10811307331441, "train/extr_return_normed_mag": 1.5096261377779314, "train/extr_return_normed_max": 1.5096261377779314, "train/extr_return_normed_mean": 0.34471045650657595, "train/extr_return_normed_min": -0.10036365789182754, "train/extr_return_normed_std": 0.3236754058710652, "train/extr_return_rate": 0.681884886069619, "train/extr_return_raw_mag": 9.792498395850622, "train/extr_return_raw_max": 9.792498395850622, "train/extr_return_raw_mean": 2.08868004003337, "train/extr_return_raw_min": -0.8549784445083203, "train/extr_return_raw_std": 2.140660571928469, "train/extr_reward_mag": 1.0472375420091067, "train/extr_reward_max": 1.0472375420091067, "train/extr_reward_mean": 0.04576930782994149, "train/extr_reward_min": -0.6821893496834552, "train/extr_reward_std": 0.20835022473891165, "train/image_loss_mean": 3.738306858996653, "train/image_loss_std": 8.743752027422653, "train/model_loss_mean": 7.925215563008205, "train/model_loss_std": 12.928147471630512, "train/model_opt_grad_norm": 38.65606244734532, "train/model_opt_grad_steps": 131517.08808290155, "train/model_opt_loss": 13102.363875789346, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1658.0310880829015, "train/policy_entropy_mag": 2.576337188019036, "train/policy_entropy_max": 2.576337188019036, "train/policy_entropy_mean": 0.45657157511908775, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.638688460224033, "train/policy_logprob_mag": 7.438384154917663, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.45711780876075664, "train/policy_logprob_min": -7.438384154917663, "train/policy_logprob_std": 1.0680701037762697, "train/policy_randomness_mag": 0.9093339690272673, "train/policy_randomness_max": 0.9093339690272673, "train/policy_randomness_mean": 0.16114973091554147, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.22542899731218505, "train/post_ent_mag": 59.637736424263274, "train/post_ent_max": 59.637736424263274, "train/post_ent_mean": 43.01619487228789, "train/post_ent_min": 19.52671783822806, "train/post_ent_std": 6.864216120131893, "train/prior_ent_mag": 75.83900961604144, "train/prior_ent_max": 75.83900961604144, "train/prior_ent_mean": 49.91123231087324, "train/prior_ent_min": 29.82325023196522, "train/prior_ent_std": 7.347757979378182, "train/rep_loss_mean": 6.892769862950774, "train/rep_loss_std": 8.981406799869834, "train/reward_avg": 0.034368928087576064, "train/reward_loss_mean": 0.051173021563285376, "train/reward_loss_std": 0.210704874652655, "train/reward_max_data": 1.0202072587037951, "train/reward_max_pred": 1.0187715810815288, "train/reward_neg_acc": 0.9943792140545623, "train/reward_neg_loss": 0.02296726078933848, "train/reward_pos_acc": 0.9863757324342283, "train/reward_pos_loss": 0.7461347129060815, "train/reward_pred": 0.034018714521369786, "train/reward_rate": 0.03908779954663212, "train_stats/sum_log_reward": 8.275000143051148, "train_stats/max_log_achievement_collect_coal": 0.5, "train_stats/max_log_achievement_collect_drink": 3.25, "train_stats/max_log_achievement_collect_sapling": 1.6, "train_stats/max_log_achievement_collect_stone": 10.875, "train_stats/max_log_achievement_collect_wood": 5.925, "train_stats/max_log_achievement_defeat_skeleton": 0.025, "train_stats/max_log_achievement_defeat_zombie": 0.25, "train_stats/max_log_achievement_eat_cow": 0.05, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.325, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_furnace": 1.5, "train_stats/max_log_achievement_place_plant": 1.55, "train_stats/max_log_achievement_place_stone": 3.3, "train_stats/max_log_achievement_place_table": 2.075, "train_stats/max_log_achievement_wake_up": 1.55, "train_stats/mean_log_entropy": 0.37236039973795415, "eval_stats/sum_log_reward": 7.725000202655792, "eval_stats/max_log_achievement_collect_coal": 1.0, "eval_stats/max_log_achievement_collect_drink": 3.25, "eval_stats/max_log_achievement_collect_sapling": 1.375, "eval_stats/max_log_achievement_collect_stone": 8.25, "eval_stats/max_log_achievement_collect_wood": 6.375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.25, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.25, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 1.125, "eval_stats/max_log_achievement_place_plant": 1.25, "eval_stats/max_log_achievement_place_stone": 2.375, "eval_stats/max_log_achievement_place_table": 2.25, "eval_stats/max_log_achievement_wake_up": 1.25, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 3.401592039153911e-06, "report/cont_loss_std": 4.258707122062333e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 9.086659702006727e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.8860813472419977e-06, "report/cont_pred": 0.9941383600234985, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 7.107931137084961, "report/dyn_loss_std": 9.075472831726074, "report/image_loss_mean": 2.7049574851989746, "report/image_loss_std": 6.687063217163086, "report/model_loss_mean": 7.031322479248047, "report/model_loss_std": 11.261188507080078, "report/post_ent_mag": 60.408729553222656, "report/post_ent_max": 60.408729553222656, "report/post_ent_mean": 41.66636657714844, "report/post_ent_min": 20.77393341064453, "report/post_ent_std": 6.868602752685547, "report/prior_ent_mag": 76.00294494628906, "report/prior_ent_max": 76.00294494628906, "report/prior_ent_mean": 48.74297332763672, "report/prior_ent_min": 30.42621421813965, "report/prior_ent_std": 7.384488582611084, "report/rep_loss_mean": 7.107931137084961, "report/rep_loss_std": 9.075472831726074, "report/reward_avg": 0.05205078050494194, "report/reward_loss_mean": 0.06160314008593559, "report/reward_loss_std": 0.2634304463863373, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0018115043640137, "report/reward_neg_acc": 0.9968976378440857, "report/reward_neg_loss": 0.01775667816400528, "report/reward_pos_acc": 0.9649122953414917, "report/reward_pos_loss": 0.8054546117782593, "report/reward_pred": 0.050248440355062485, "report/reward_rate": 0.0556640625, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.0012583681382238865, "eval/cont_loss_std": 0.038768187165260315, "eval/cont_neg_acc": 0.8333333730697632, "eval/cont_neg_loss": 0.21444585919380188, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.860132783804147e-06, "eval/cont_pred": 0.9948770999908447, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 19.754058837890625, "eval/dyn_loss_std": 12.690327644348145, "eval/image_loss_mean": 20.862716674804688, "eval/image_loss_std": 21.32063102722168, "eval/model_loss_mean": 32.847450256347656, "eval/model_loss_std": 26.28407096862793, "eval/post_ent_mag": 57.61470413208008, "eval/post_ent_max": 57.61470413208008, "eval/post_ent_mean": 41.548927307128906, "eval/post_ent_min": 20.16787338256836, "eval/post_ent_std": 7.047698497772217, "eval/prior_ent_mag": 76.00294494628906, "eval/prior_ent_max": 76.00294494628906, "eval/prior_ent_mean": 54.657814025878906, "eval/prior_ent_min": 37.24217987060547, "eval/prior_ent_std": 6.518731117248535, "eval/rep_loss_mean": 19.754058837890625, "eval/rep_loss_std": 12.690327644348145, "eval/reward_avg": 0.0341796875, "eval/reward_loss_mean": 0.13103611767292023, "eval/reward_loss_std": 0.7208552360534668, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0023512840270996, "eval/reward_neg_acc": 0.9908537268638611, "eval/reward_neg_loss": 0.07186374068260193, "eval/reward_pos_acc": 0.8500000238418579, "eval/reward_pos_loss": 1.5866765975952148, "eval/reward_pred": 0.03204694390296936, "eval/reward_rate": 0.0390625, "replay/size": 531413.0, "replay/inserts": 7712.0, "replay/samples": 30848.0, "replay/insert_wait_avg": 1.532871940818565e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.410004302179171e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 2736.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1156699810808862e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1422774791718, "timer/env.step_count": 964.0, "timer/env.step_total": 89.47509002685547, "timer/env.step_frac": 0.08946236154757373, "timer/env.step_avg": 0.092816483430348, "timer/env.step_min": 0.023623228073120117, "timer/env.step_max": 2.086855888366699, "timer/replay._sample_count": 30848.0, "timer/replay._sample_total": 15.16431975364685, "timer/replay._sample_frac": 0.0151621625193848, "timer/replay._sample_avg": 0.0004915819422214358, "timer/replay._sample_min": 0.00035858154296875, "timer/replay._sample_max": 0.024520158767700195, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1306.0, "timer/agent.policy_total": 20.57516574859619, "timer/agent.policy_frac": 0.020572238782321322, "timer/agent.policy_avg": 0.015754338245479473, "timer/agent.policy_min": 0.009367227554321289, "timer/agent.policy_max": 0.07626008987426758, "timer/dataset_train_count": 1928.0, "timer/dataset_train_total": 0.40176844596862793, "timer/dataset_train_frac": 0.0004017112914987187, "timer/dataset_train_avg": 0.0002083861234277116, "timer/dataset_train_min": 9.393692016601562e-05, "timer/dataset_train_max": 0.06685566902160645, "timer/agent.train_count": 1928.0, "timer/agent.train_total": 855.3401253223419, "timer/agent.train_frac": 0.8552184469975619, "timer/agent.train_avg": 0.44364114383938896, "timer/agent.train_min": 0.42772626876831055, "timer/agent.train_max": 0.9140925407409668, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4725344181060791, "timer/agent.report_frac": 0.00047246719666434634, "timer/agent.report_avg": 0.23626720905303955, "timer/agent.report_min": 0.22876262664794922, "timer/agent.report_max": 0.24377179145812988, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.956390380859375e-05, "timer/dataset_eval_frac": 2.955969812925884e-08, "timer/dataset_eval_avg": 2.956390380859375e-05, "timer/dataset_eval_min": 2.956390380859375e-05, "timer/dataset_eval_max": 2.956390380859375e-05, "fps": 7.710796057677788}
{"step": 531920, "time": 68360.53008008003, "episode/length": 142.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 531968, "time": 68368.08205962181, "episode/length": 204.0, "episode/score": 11.099999971687794, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 532464, "time": 68427.12218594551, "episode/length": 149.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 532600, "time": 68445.73286533356, "episode/length": 130.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9923664122137404, "episode/intrinsic_return": 0.0}
{"step": 532600, "time": 68445.74204301834, "episode/length": 175.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 533328, "time": 68533.90929722786, "episode/length": 175.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 533488, "time": 68553.9868979454, "episode/length": 283.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9859154929577465, "episode/intrinsic_return": 0.0}
{"step": 533520, "time": 68559.18466162682, "episode/length": 193.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9690721649484536, "episode/intrinsic_return": 0.0}
{"step": 534040, "time": 68621.86124658585, "episode/length": 282.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9858657243816255, "episode/intrinsic_return": 0.0}
{"step": 534056, "time": 68625.17020273209, "episode/length": 303.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9835526315789473, "episode/intrinsic_return": 0.0}
{"step": 534200, "time": 68643.51716184616, "episode/length": 199.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 534856, "time": 68722.02909302711, "episode/length": 190.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 535000, "time": 68740.4332511425, "episode/length": 188.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 535016, "time": 68743.78527450562, "episode/length": 318.0, "episode/score": 10.099999964237213, "episode/reward_rate": 0.9905956112852664, "episode/intrinsic_return": 0.0}
{"step": 535496, "time": 68801.15390133858, "episode/length": 161.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 535504, "time": 68803.53662538528, "episode/length": 247.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 535800, "time": 68839.52305817604, "episode/length": 217.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 535952, "time": 68858.54787921906, "episode/length": 116.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9572649572649573, "episode/intrinsic_return": 0.0}
{"step": 536064, "time": 68873.02449083328, "episode/length": 432.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9792147806004619, "episode/intrinsic_return": 0.0}
{"step": 536360, "time": 68908.95221233368, "episode/length": 187.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 536584, "time": 68936.42009925842, "episode/length": 134.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9925925925925926, "episode/intrinsic_return": 0.0}
{"step": 536592, "time": 68938.89120650291, "episode/length": 318.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.987460815047022, "episode/intrinsic_return": 0.0}
{"step": 536600, "time": 68941.32785224915, "episode/length": 199.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 536976, "time": 68986.52021026611, "episode/length": 184.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9621621621621622, "episode/intrinsic_return": 0.0}
{"step": 537296, "time": 69025.17318749428, "episode/length": 167.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 537368, "time": 69035.0592391491, "episode/length": 162.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 537424, "time": 69043.31872820854, "episode/length": 202.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 537728, "time": 69080.14058184624, "episode/length": 141.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 538008, "time": 69114.11026787758, "episode/length": 205.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 538200, "time": 69138.0743393898, "episode/length": 58.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 538296, "time": 69150.76099967957, "episode/length": 164.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9636363636363636, "episode/intrinsic_return": 0.0}
{"step": 538344, "time": 69157.74968266487, "episode/length": 217.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 538600, "time": 69189.00882005692, "episode/length": 73.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9459459459459459, "episode/intrinsic_return": 0.0}
{"step": 538696, "time": 69201.70752286911, "episode/length": 263.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9962121212121212, "episode/intrinsic_return": 0.0}
{"step": 538800, "time": 69215.21963644028, "episode/length": 171.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 538864, "time": 69224.16459536552, "episode/length": 195.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9693877551020408, "episode/intrinsic_return": 0.0}
{"step": 539256, "time": 69271.08704471588, "episode/length": 131.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9545454545454546, "episode/intrinsic_return": 0.0}
{"step": 539472, "time": 69297.58790755272, "episode/length": 83.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9880952380952381, "episode/intrinsic_return": 0.0}
{"step": 539552, "time": 69308.39062738419, "episode/length": 156.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 539768, "time": 69334.96605300903, "episode/length": 299.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 539912, "time": 69353.17540311813, "episode/length": 195.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 539957, "time": 69360.79352355003, "train_stats/sum_log_reward": 8.343902636955423, "train_stats/max_log_achievement_collect_coal": 0.6341463414634146, "train_stats/max_log_achievement_collect_drink": 3.3902439024390243, "train_stats/max_log_achievement_collect_sapling": 1.3170731707317074, "train_stats/max_log_achievement_collect_stone": 10.951219512195122, "train_stats/max_log_achievement_collect_wood": 5.975609756097561, "train_stats/max_log_achievement_defeat_skeleton": 0.0975609756097561, "train_stats/max_log_achievement_defeat_zombie": 0.2682926829268293, "train_stats/max_log_achievement_eat_cow": 0.12195121951219512, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.2682926829268293, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_furnace": 1.6097560975609757, "train_stats/max_log_achievement_place_plant": 1.2439024390243902, "train_stats/max_log_achievement_place_stone": 3.073170731707317, "train_stats/max_log_achievement_place_table": 2.0, "train_stats/max_log_achievement_wake_up": 1.7073170731707317, "train_stats/mean_log_entropy": 0.37397547575031836, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.396238108772543, "train/action_min": 0.0, "train/action_std": 3.06118480008633, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04315947984062617, "train/actor_opt_grad_steps": 133600.0, "train/actor_opt_loss": -12.175972723768124, "train/adv_mag": 0.44376013972866, "train/adv_max": 0.40872968014199934, "train/adv_mean": 0.0026367918204409785, "train/adv_min": -0.3807708460893204, "train/adv_std": 0.054409170365748716, "train/cont_avg": 0.9947868081467661, "train/cont_loss_mean": 0.00014470420916239986, "train/cont_loss_std": 0.00431892302055838, "train/cont_neg_acc": 0.9953782680022776, "train/cont_neg_loss": 0.019014286353840767, "train/cont_pos_acc": 0.9999950821719953, "train/cont_pos_loss": 3.5284134386432046e-05, "train/cont_pred": 0.994792278429762, "train/cont_rate": 0.9947868081467661, "train/dyn_loss_mean": 6.9328215608549355, "train/dyn_loss_std": 8.96137160685525, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.083810575269348, "train/extr_critic_critic_opt_grad_steps": 133600.0, "train/extr_critic_critic_opt_loss": 16936.61765877643, "train/extr_critic_mag": 8.93383480660358, "train/extr_critic_max": 8.93383480660358, "train/extr_critic_mean": 2.0391598646320515, "train/extr_critic_min": -0.5559834241867065, "train/extr_critic_std": 2.0911573112307495, "train/extr_return_normed_mag": 1.5068613788974818, "train/extr_return_normed_max": 1.5068613788974818, "train/extr_return_normed_mean": 0.34256327441379203, "train/extr_return_normed_min": -0.09550643556598407, "train/extr_return_normed_std": 0.322021662447583, "train/extr_return_rate": 0.6831879369655058, "train/extr_return_raw_mag": 9.74163106662124, "train/extr_return_raw_max": 9.74163106662124, "train/extr_return_raw_mean": 2.0565106394279065, "train/extr_return_raw_min": -0.8361665163170638, "train/extr_return_raw_std": 2.125965730467839, "train/extr_reward_mag": 1.0497348640688615, "train/extr_reward_max": 1.0497348640688615, "train/extr_reward_mean": 0.046160284466856154, "train/extr_reward_min": -0.6757302628227727, "train/extr_reward_std": 0.20954818682587562, "train/image_loss_mean": 3.7469712228917365, "train/image_loss_std": 8.648932079770672, "train/model_loss_mean": 7.959365704759437, "train/model_loss_std": 12.828983230970392, "train/model_opt_grad_norm": 38.1292401498823, "train/model_opt_grad_steps": 133485.67164179104, "train/model_opt_loss": 12664.77484161225, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1592.039800995025, "train/policy_entropy_mag": 2.597392394174984, "train/policy_entropy_max": 2.597392394174984, "train/policy_entropy_mean": 0.4456365095145667, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6261895745251309, "train/policy_logprob_mag": 7.438384148611951, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.44638528218909873, "train/policy_logprob_min": -7.438384148611951, "train/policy_logprob_std": 1.0619263880288423, "train/policy_randomness_mag": 0.9167655312006746, "train/policy_randomness_max": 0.9167655312006746, "train/policy_randomness_mean": 0.1572901328182339, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.2210174395670345, "train/post_ent_mag": 59.36119789389235, "train/post_ent_max": 59.36119789389235, "train/post_ent_mean": 42.850537124557874, "train/post_ent_min": 19.765116886119937, "train/post_ent_std": 6.848131775262937, "train/prior_ent_mag": 75.87347146409068, "train/prior_ent_max": 75.87347146409068, "train/prior_ent_mean": 49.788735878408254, "train/prior_ent_min": 29.950229511925237, "train/prior_ent_std": 7.343324609063751, "train/rep_loss_mean": 6.9328215608549355, "train/rep_loss_std": 8.96137160685525, "train/reward_avg": 0.0352777128214415, "train/reward_loss_mean": 0.0525568514988197, "train/reward_loss_std": 0.21639261709813454, "train/reward_max_data": 1.0164179143620962, "train/reward_max_pred": 1.0166762580919029, "train/reward_neg_acc": 0.9945028157376531, "train/reward_neg_loss": 0.023904499018666755, "train/reward_pos_acc": 0.9864236143097949, "train/reward_pos_loss": 0.7433637958853992, "train/reward_pred": 0.03496127211447082, "train/reward_rate": 0.039917599502487564, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 3.2217967600445263e-06, "report/cont_loss_std": 3.0693197913933545e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00048686264199204743, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 1.3251659538582317e-06, "report/cont_pred": 0.9960943460464478, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 5.9106950759887695, "report/dyn_loss_std": 8.631115913391113, "report/image_loss_mean": 2.519860029220581, "report/image_loss_std": 5.944657802581787, "report/model_loss_mean": 6.101444244384766, "report/model_loss_std": 10.250597953796387, "report/post_ent_mag": 59.013694763183594, "report/post_ent_max": 59.013694763183594, "report/post_ent_mean": 43.71733856201172, "report/post_ent_min": 16.575599670410156, "report/post_ent_std": 6.798425674438477, "report/prior_ent_mag": 76.31907653808594, "report/prior_ent_max": 76.31907653808594, "report/prior_ent_mean": 49.44156265258789, "report/prior_ent_min": 30.08050537109375, "report/prior_ent_std": 7.25600528717041, "report/rep_loss_mean": 5.9106950759887695, "report/rep_loss_std": 8.631115913391113, "report/reward_avg": 0.02412109263241291, "report/reward_loss_mean": 0.035164013504981995, "report/reward_loss_std": 0.14273712038993835, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.0597994327545166, "report/reward_neg_acc": 0.9959757924079895, "report/reward_neg_loss": 0.015441431663930416, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6886389255523682, "report/reward_pred": 0.0247091893106699, "report/reward_rate": 0.029296875, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 2.1520697828236734e-06, "eval/cont_loss_std": 1.3751566257269587e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00040614642784930766, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.7571583157405257e-06, "eval/cont_pred": 0.9990220665931702, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 20.4420166015625, "eval/dyn_loss_std": 12.569594383239746, "eval/image_loss_mean": 20.547163009643555, "eval/image_loss_std": 24.044851303100586, "eval/model_loss_mean": 33.00907897949219, "eval/model_loss_std": 28.759775161743164, "eval/post_ent_mag": 56.715755462646484, "eval/post_ent_max": 56.715755462646484, "eval/post_ent_mean": 39.74103927612305, "eval/post_ent_min": 16.558208465576172, "eval/post_ent_std": 6.6974053382873535, "eval/prior_ent_mag": 76.31907653808594, "eval/prior_ent_max": 76.31907653808594, "eval/prior_ent_mean": 52.448516845703125, "eval/prior_ent_min": 36.437278747558594, "eval/prior_ent_std": 5.912322998046875, "eval/rep_loss_mean": 20.4420166015625, "eval/rep_loss_std": 12.569594383239746, "eval/reward_avg": 0.0517578125, "eval/reward_loss_mean": 0.19670401513576508, "eval/reward_loss_std": 1.0056732892990112, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0024120807647705, "eval/reward_neg_acc": 0.9845201969146729, "eval/reward_neg_loss": 0.08175390213727951, "eval/reward_pos_acc": 0.7454545497894287, "eval/reward_pos_loss": 2.2219159603118896, "eval/reward_pred": 0.045669689774513245, "eval/reward_rate": 0.0537109375, "replay/size": 539453.0, "replay/inserts": 8040.0, "replay/samples": 32160.0, "replay/insert_wait_avg": 1.5502248830463163e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.406321924124191e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2753684520721, "timer/env.step_count": 1005.0, "timer/env.step_total": 88.9897530078888, "timer/env.step_frac": 0.08896525478339089, "timer/env.step_avg": 0.0885470179182973, "timer/env.step_min": 0.023293256759643555, "timer/env.step_max": 3.182243824005127, "timer/replay._sample_count": 32160.0, "timer/replay._sample_total": 15.726995706558228, "timer/replay._sample_frac": 0.015722666180309708, "timer/replay._sample_avg": 0.0004890234983382534, "timer/replay._sample_min": 0.0003826618194580078, "timer/replay._sample_max": 0.010506629943847656, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1005.0, "timer/agent.policy_total": 16.03219246864319, "timer/agent.policy_frac": 0.01602777892397074, "timer/agent.policy_avg": 0.015952430317057897, "timer/agent.policy_min": 0.009614944458007812, "timer/agent.policy_max": 0.07129716873168945, "timer/dataset_train_count": 2010.0, "timer/dataset_train_total": 0.3058640956878662, "timer/dataset_train_frac": 0.000305779893551904, "timer/dataset_train_avg": 0.00015217119188451055, "timer/dataset_train_min": 9.202957153320312e-05, "timer/dataset_train_max": 0.001224517822265625, "timer/agent.train_count": 2010.0, "timer/agent.train_total": 891.4844827651978, "timer/agent.train_frac": 0.8912390636438159, "timer/agent.train_avg": 0.44352461829114315, "timer/agent.train_min": 0.4313361644744873, "timer/agent.train_max": 0.9856371879577637, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4746978282928467, "timer/agent.report_frac": 0.000474567147472043, "timer/agent.report_avg": 0.23734891414642334, "timer/agent.report_min": 0.23003029823303223, "timer/agent.report_max": 0.24466753005981445, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.765655517578125e-05, "timer/dataset_eval_frac": 2.7648941529550823e-08, "timer/dataset_eval_avg": 2.765655517578125e-05, "timer/dataset_eval_min": 2.765655517578125e-05, "timer/dataset_eval_max": 2.765655517578125e-05, "fps": 8.037673631987804}
{"step": 539968, "time": 69361.98379969597, "episode/length": 158.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 540072, "time": 69393.45886969566, "eval_episode/length": 139.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9642857142857143}
{"step": 540072, "time": 69395.0150411129, "eval_episode/length": 141.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9647887323943662}
{"step": 540072, "time": 69398.73814034462, "eval_episode/length": 196.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9644670050761421}
{"step": 540072, "time": 69400.89742445946, "eval_episode/length": 211.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9952830188679245}
{"step": 540072, "time": 69402.48463392258, "eval_episode/length": 214.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9953488372093023}
{"step": 540072, "time": 69404.68597912788, "eval_episode/length": 232.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9828326180257511}
{"step": 540072, "time": 69408.80158925056, "eval_episode/length": 298.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9765886287625418}
{"step": 540072, "time": 69410.62740492821, "eval_episode/length": 307.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.987012987012987}
{"step": 540144, "time": 69418.9567937851, "episode/length": 192.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 540488, "time": 69460.3647801876, "episode/length": 153.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 541096, "time": 69533.71861052513, "episode/length": 202.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 541128, "time": 69538.93700027466, "episode/length": 196.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 541448, "time": 69577.64207649231, "episode/length": 184.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 541584, "time": 69595.00541448593, "episode/length": 226.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.973568281938326, "episode/intrinsic_return": 0.0}
{"step": 542072, "time": 69653.20747041702, "episode/length": 269.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9740740740740741, "episode/intrinsic_return": 0.0}
{"step": 542080, "time": 69655.61010575294, "episode/length": 241.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9793388429752066, "episode/intrinsic_return": 0.0}
{"step": 542104, "time": 69659.94255948067, "episode/length": 201.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 542176, "time": 69669.87189221382, "episode/length": 413.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9903381642512077, "episode/intrinsic_return": 0.0}
{"step": 542200, "time": 69674.27895283699, "episode/length": 93.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9361702127659575, "episode/intrinsic_return": 0.0}
{"step": 542248, "time": 69681.30509877205, "episode/length": 143.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 542592, "time": 69722.73706459999, "episode/length": 60.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9180327868852459, "episode/intrinsic_return": 0.0}
{"step": 542776, "time": 69745.66909837723, "episode/length": 205.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 542800, "time": 69749.95003223419, "episode/length": 151.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 543464, "time": 69828.57634472847, "episode/length": 157.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 543656, "time": 69852.52181959152, "episode/length": 197.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 543840, "time": 69875.24277806282, "episode/length": 198.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 543880, "time": 69881.92218852043, "episode/length": 160.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 544040, "time": 69902.53099822998, "episode/length": 244.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9755102040816327, "episode/intrinsic_return": 0.0}
{"step": 544064, "time": 69906.83337426186, "episode/length": 235.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9661016949152542, "episode/intrinsic_return": 0.0}
{"step": 544184, "time": 69922.37022781372, "episode/length": 172.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 544432, "time": 69952.6047706604, "episode/length": 206.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9710144927536232, "episode/intrinsic_return": 0.0}
{"step": 544992, "time": 70019.13008403778, "episode/length": 166.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9580838323353293, "episode/intrinsic_return": 0.0}
{"step": 545104, "time": 70033.64140534401, "episode/length": 204.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 545264, "time": 70053.76962900162, "episode/length": 152.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 545440, "time": 70075.75497698784, "episode/length": 171.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 545456, "time": 70079.1488468647, "episode/length": 201.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9653465346534653, "episode/intrinsic_return": 0.0}
{"step": 545496, "time": 70085.34249043465, "episode/length": 163.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9634146341463414, "episode/intrinsic_return": 0.0}
{"step": 546648, "time": 70220.9144024849, "episode/length": 192.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9689119170984456, "episode/intrinsic_return": 0.0}
{"step": 546664, "time": 70224.30175566673, "episode/length": 152.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 546736, "time": 70234.16929101944, "episode/length": 217.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.981651376146789, "episode/intrinsic_return": 0.0}
{"step": 546864, "time": 70250.52573347092, "episode/length": 199.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 546920, "time": 70258.46888422966, "episode/length": 182.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 546968, "time": 70265.63643813133, "episode/length": 316.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9842271293375394, "episode/intrinsic_return": 0.0}
{"step": 547152, "time": 70288.63940668106, "episode/length": 206.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 547264, "time": 70303.870459795, "episode/length": 422.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 547737, "time": 70361.1386013031, "train_stats/sum_log_reward": 8.389473905688838, "train_stats/max_log_achievement_collect_coal": 0.6842105263157895, "train_stats/max_log_achievement_collect_drink": 3.4210526315789473, "train_stats/max_log_achievement_collect_sapling": 1.736842105263158, "train_stats/max_log_achievement_collect_stone": 10.421052631578947, "train_stats/max_log_achievement_collect_wood": 6.105263157894737, "train_stats/max_log_achievement_defeat_skeleton": 0.07894736842105263, "train_stats/max_log_achievement_defeat_zombie": 0.18421052631578946, "train_stats/max_log_achievement_eat_cow": 0.05263157894736842, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.263157894736842, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_furnace": 1.368421052631579, "train_stats/max_log_achievement_place_plant": 1.631578947368421, "train_stats/max_log_achievement_place_stone": 3.263157894736842, "train_stats/max_log_achievement_place_table": 2.1842105263157894, "train_stats/max_log_achievement_wake_up": 1.8421052631578947, "train_stats/mean_log_entropy": 0.381119881021349, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.480632978616302, "train/action_min": 0.0, "train/action_std": 3.06362809225456, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04324731029109242, "train/actor_opt_grad_steps": 135575.0, "train/actor_opt_loss": -12.16500158275756, "train/adv_mag": 0.4476754310512051, "train/adv_max": 0.412479234264069, "train/adv_mean": 0.0023826372057087187, "train/adv_min": -0.3901980826535176, "train/adv_std": 0.054701372577818395, "train/cont_avg": 0.9947195151417526, "train/cont_loss_mean": 0.00018555121910321525, "train/cont_loss_std": 0.005753207636616091, "train/cont_neg_acc": 0.9901652772402026, "train/cont_neg_loss": 0.0321695254019359, "train/cont_pos_acc": 0.9999847814594347, "train/cont_pos_loss": 2.7317336487435066e-05, "train/cont_pred": 0.9947438347585422, "train/cont_rate": 0.9947195151417526, "train/dyn_loss_mean": 6.935031355041819, "train/dyn_loss_std": 8.963924702909804, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0851445883205257, "train/extr_critic_critic_opt_grad_steps": 135575.0, "train/extr_critic_critic_opt_loss": 16825.799829856638, "train/extr_critic_mag": 8.821406792119607, "train/extr_critic_max": 8.821406792119607, "train/extr_critic_mean": 1.9791171630633246, "train/extr_critic_min": -0.5595761402366087, "train/extr_critic_std": 2.078529870387205, "train/extr_return_normed_mag": 1.515188211632758, "train/extr_return_normed_max": 1.515188211632758, "train/extr_return_normed_mean": 0.3408330102095899, "train/extr_return_normed_min": -0.09835790840851277, "train/extr_return_normed_std": 0.3254872949160251, "train/extr_return_rate": 0.6650515160302526, "train/extr_return_raw_mag": 9.616147488662877, "train/extr_return_raw_max": 9.616147488662877, "train/extr_return_raw_mean": 1.9945793084262573, "train/extr_return_raw_min": -0.8559211126922333, "train/extr_return_raw_std": 2.1125916156572164, "train/extr_reward_mag": 1.046705926816488, "train/extr_reward_max": 1.046705926816488, "train/extr_reward_mean": 0.04508104454725981, "train/extr_reward_min": -0.6785471973959932, "train/extr_reward_std": 0.2068648579501614, "train/image_loss_mean": 3.8419708763201212, "train/image_loss_std": 9.031160954347591, "train/model_loss_mean": 8.055174343364754, "train/model_loss_std": 13.159576514332565, "train/model_opt_grad_norm": 37.80560080538091, "train/model_opt_grad_steps": 135459.45360824742, "train/model_opt_loss": 13128.612699842944, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1636.5979381443299, "train/policy_entropy_mag": 2.606294158807735, "train/policy_entropy_max": 2.606294158807735, "train/policy_entropy_mean": 0.4629274405462226, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6438403401485423, "train/policy_logprob_mag": 7.438384117539396, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.46269733666144697, "train/policy_logprob_min": -7.438384117539396, "train/policy_logprob_std": 1.0732502092405694, "train/policy_randomness_mag": 0.9199074638873032, "train/policy_randomness_max": 0.9199074638873032, "train/policy_randomness_mean": 0.16339307190063074, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.22724738540415912, "train/post_ent_mag": 59.27328731104271, "train/post_ent_max": 59.27328731104271, "train/post_ent_mean": 42.930045314670835, "train/post_ent_min": 19.63871222427211, "train/post_ent_std": 6.859458810275363, "train/prior_ent_mag": 75.88843654357281, "train/prior_ent_max": 75.88843654357281, "train/prior_ent_mean": 49.89883861345114, "train/prior_ent_min": 29.665302463413514, "train/prior_ent_std": 7.298760025771623, "train/rep_loss_mean": 6.935031355041819, "train/rep_loss_std": 8.963924702909804, "train/reward_avg": 0.034381543674995914, "train/reward_loss_mean": 0.051999076298370805, "train/reward_loss_std": 0.2106467706640971, "train/reward_max_data": 1.020103097576456, "train/reward_max_pred": 1.0176518135464068, "train/reward_neg_acc": 0.9943159016751751, "train/reward_neg_loss": 0.023647990406577273, "train/reward_pos_acc": 0.9852850409512667, "train/reward_pos_loss": 0.7477498011490733, "train/reward_pred": 0.03393535283826215, "train/reward_rate": 0.039238683956185565, "eval_stats/sum_log_reward": 8.850000202655792, "eval_stats/max_log_achievement_collect_coal": 0.375, "eval_stats/max_log_achievement_collect_drink": 4.5, "eval_stats/max_log_achievement_collect_sapling": 1.375, "eval_stats/max_log_achievement_collect_stone": 8.875, "eval_stats/max_log_achievement_collect_wood": 6.375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.375, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.125, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 1.125, "eval_stats/max_log_achievement_place_plant": 1.375, "eval_stats/max_log_achievement_place_stone": 3.125, "eval_stats/max_log_achievement_place_table": 2.375, "eval_stats/max_log_achievement_wake_up": 2.0, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 2.7803976081486326e-06, "report/cont_loss_std": 3.8399284676415846e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 7.886318780947477e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 2.2567205633095e-06, "report/cont_pred": 0.9931623935699463, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 6.977451324462891, "report/dyn_loss_std": 8.980204582214355, "report/image_loss_mean": 4.210649490356445, "report/image_loss_std": 9.20166301727295, "report/model_loss_mean": 8.445778846740723, "report/model_loss_std": 12.931428909301758, "report/post_ent_mag": 62.01512145996094, "report/post_ent_max": 62.01512145996094, "report/post_ent_mean": 43.562950134277344, "report/post_ent_min": 21.3760986328125, "report/post_ent_std": 6.728549480438232, "report/prior_ent_mag": 76.09048461914062, "report/prior_ent_max": 76.09048461914062, "report/prior_ent_mean": 50.68318557739258, "report/prior_ent_min": 30.295551300048828, "report/prior_ent_std": 7.578405857086182, "report/rep_loss_mean": 6.977451324462891, "report/rep_loss_std": 8.980204582214355, "report/reward_avg": 0.03125, "report/reward_loss_mean": 0.0486551932990551, "report/reward_loss_std": 0.19063730537891388, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0012152194976807, "report/reward_neg_acc": 0.9929006099700928, "report/reward_neg_loss": 0.02172304131090641, "report/reward_pos_acc": 0.9736841917037964, "report/reward_pos_loss": 0.7474736571311951, "report/reward_pred": 0.030932273715734482, "report/reward_rate": 0.037109375, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 3.648808706202544e-05, "eval/cont_loss_std": 0.0010787744540721178, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00011349451960995793, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 3.6261819332139567e-05, "eval/cont_pred": 0.9970351457595825, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 18.891769409179688, "eval/dyn_loss_std": 13.274319648742676, "eval/image_loss_mean": 15.97490119934082, "eval/image_loss_std": 22.335153579711914, "eval/model_loss_mean": 27.414649963378906, "eval/model_loss_std": 27.99576187133789, "eval/post_ent_mag": 55.215885162353516, "eval/post_ent_max": 55.215885162353516, "eval/post_ent_mean": 39.163246154785156, "eval/post_ent_min": 20.415435791015625, "eval/post_ent_std": 6.722620964050293, "eval/prior_ent_mag": 76.09048461914062, "eval/prior_ent_max": 76.09048461914062, "eval/prior_ent_mean": 52.339111328125, "eval/prior_ent_min": 34.05912399291992, "eval/prior_ent_std": 6.363290309906006, "eval/rep_loss_mean": 18.891769409179688, "eval/rep_loss_std": 13.274319648742676, "eval/reward_avg": 0.05156250298023224, "eval/reward_loss_mean": 0.10465233772993088, "eval/reward_loss_std": 0.5979963541030884, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0018112659454346, "eval/reward_neg_acc": 0.9938015937805176, "eval/reward_neg_loss": 0.025184249505400658, "eval/reward_pos_acc": 0.8571429252624512, "eval/reward_pos_loss": 1.478314995765686, "eval/reward_pred": 0.04124300554394722, "eval/reward_rate": 0.0546875, "replay/size": 547233.0, "replay/inserts": 7780.0, "replay/samples": 31120.0, "replay/insert_wait_avg": 1.5201176346727386e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.409592827059003e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 2464.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0913649162688813e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.152557373046875e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3255386352539, "timer/env.step_count": 973.0, "timer/env.step_total": 83.97272205352783, "timer/env.step_frac": 0.083945394584339, "timer/env.step_avg": 0.08630290036333796, "timer/env.step_min": 0.023569345474243164, "timer/env.step_max": 2.0896332263946533, "timer/replay._sample_count": 31120.0, "timer/replay._sample_total": 15.251380681991577, "timer/replay._sample_frac": 0.015246417384083851, "timer/replay._sample_avg": 0.0004900829267992153, "timer/replay._sample_min": 0.00041031837463378906, "timer/replay._sample_max": 0.021864652633666992, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1281.0, "timer/agent.policy_total": 20.191794395446777, "timer/agent.policy_frac": 0.020185223325393135, "timer/agent.policy_avg": 0.015762524898865555, "timer/agent.policy_min": 0.00921940803527832, "timer/agent.policy_max": 0.07201981544494629, "timer/dataset_train_count": 1945.0, "timer/dataset_train_total": 0.2916276454925537, "timer/dataset_train_frac": 0.0002915327403221374, "timer/dataset_train_avg": 0.00014993709279822814, "timer/dataset_train_min": 9.179115295410156e-05, "timer/dataset_train_max": 0.0012195110321044922, "timer/agent.train_count": 1945.0, "timer/agent.train_total": 862.8123714923859, "timer/agent.train_frac": 0.8625315841376223, "timer/agent.train_avg": 0.44360533238683075, "timer/agent.train_min": 0.4333462715148926, "timer/agent.train_max": 0.9647073745727539, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47667646408081055, "timer/agent.report_frac": 0.0004765213379747769, "timer/agent.report_avg": 0.23833823204040527, "timer/agent.report_min": 0.2330000400543213, "timer/agent.report_max": 0.24367642402648926, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.765655517578125e-05, "timer/dataset_eval_frac": 2.7647554828514267e-08, "timer/dataset_eval_avg": 2.765655517578125e-05, "timer/dataset_eval_min": 2.765655517578125e-05, "timer/dataset_eval_max": 2.765655517578125e-05, "fps": 7.777361981706628}
{"step": 548368, "time": 70434.25618171692, "episode/length": 180.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9613259668508287, "episode/intrinsic_return": 0.0}
{"step": 548448, "time": 70445.11268210411, "episode/length": 197.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 548536, "time": 70456.7759642601, "episode/length": 224.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 548616, "time": 70467.56153321266, "episode/length": 245.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9959349593495935, "episode/intrinsic_return": 0.0}
{"step": 548728, "time": 70482.13719153404, "episode/length": 196.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 549376, "time": 70560.58102416992, "episode/length": 338.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9852507374631269, "episode/intrinsic_return": 0.0}
{"step": 549528, "time": 70579.83473062515, "episode/length": 282.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9964664310954063, "episode/intrinsic_return": 0.0}
{"step": 549544, "time": 70583.21477603912, "episode/length": 321.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9968944099378882, "episode/intrinsic_return": 0.0}
{"step": 549552, "time": 70585.6197385788, "episode/length": 147.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 549920, "time": 70629.70505023003, "episode/length": 162.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9631901840490797, "episode/intrinsic_return": 0.0}
{"step": 549976, "time": 70637.80734872818, "episode/length": 190.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9685863874345549, "episode/intrinsic_return": 0.0}
{"step": 550056, "time": 70668.62100720406, "eval_episode/length": 147.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9932432432432432}
{"step": 550056, "time": 70670.57708024979, "eval_episode/length": 157.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9746835443037974}
{"step": 550056, "time": 70672.30047011375, "eval_episode/length": 162.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9938650306748467}
{"step": 550056, "time": 70674.35339784622, "eval_episode/length": 175.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9715909090909091}
{"step": 550056, "time": 70676.09809398651, "eval_episode/length": 182.0, "eval_episode/score": 10.100000023841858, "eval_episode/reward_rate": 0.994535519125683}
{"step": 550056, "time": 70678.76136183739, "eval_episode/length": 63.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.921875}
{"step": 550056, "time": 70678.76871275902, "eval_episode/length": 211.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9811320754716981}
{"step": 550056, "time": 70682.4287276268, "eval_episode/length": 220.0, "eval_episode/score": 11.100000008940697, "eval_episode/reward_rate": 0.9683257918552036}
{"step": 550384, "time": 70721.80764245987, "episode/length": 206.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9710144927536232, "episode/intrinsic_return": 0.0}
{"step": 550888, "time": 70781.88088202477, "episode/length": 169.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 550936, "time": 70789.44113063812, "episode/length": 194.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 551072, "time": 70807.32768321037, "episode/length": 143.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 551512, "time": 70860.00790548325, "episode/length": 191.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9895833333333334, "episode/intrinsic_return": 0.0}
{"step": 551984, "time": 70916.59471559525, "episode/length": 430.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9791183294663574, "episode/intrinsic_return": 0.0}
{"step": 552144, "time": 70936.73394298553, "episode/length": 219.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9727272727272728, "episode/intrinsic_return": 0.0}
{"step": 552168, "time": 70941.05463242531, "episode/length": 159.0, "episode/score": 9.099999949336052, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 552176, "time": 70943.59720873833, "episode/length": 154.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 552368, "time": 70967.80398607254, "episode/length": 161.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 552576, "time": 70994.29269957542, "episode/length": 73.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9324324324324325, "episode/intrinsic_return": 0.0}
{"step": 552680, "time": 71007.83673739433, "episode/length": 391.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 552752, "time": 71017.62484145164, "episode/length": 399.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9775, "episode/intrinsic_return": 0.0}
{"step": 552760, "time": 71020.16496610641, "episode/length": 155.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 553440, "time": 71100.64808440208, "episode/length": 158.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9622641509433962, "episode/intrinsic_return": 0.0}
{"step": 553712, "time": 71133.94484353065, "episode/length": 191.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 553952, "time": 71163.26281237602, "episode/length": 158.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 553960, "time": 71165.79309940338, "episode/length": 150.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 553984, "time": 71170.02604532242, "episode/length": 175.0, "episode/score": 8.100000031292439, "episode/reward_rate": 0.9602272727272727, "episode/intrinsic_return": 0.0}
{"step": 554088, "time": 71183.5186047554, "episode/length": 165.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 554144, "time": 71191.51230287552, "episode/length": 249.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.996, "episode/intrinsic_return": 0.0}
{"step": 554952, "time": 71286.5939693451, "episode/length": 322.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9876160990712074, "episode/intrinsic_return": 0.0}
{"step": 555160, "time": 71312.24999809265, "episode/length": 149.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 555296, "time": 71329.53726625443, "episode/length": 163.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 555416, "time": 71344.89621186256, "episode/length": 182.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 555488, "time": 71354.81470155716, "episode/length": 174.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9657142857142857, "episode/intrinsic_return": 0.0}
{"step": 555525, "time": 71361.52676725388, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.514535757211538, "train/action_min": 0.0, "train/action_std": 3.140335339766282, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.044353931550032054, "train/actor_opt_grad_steps": 137520.0, "train/actor_opt_loss": -10.916988938645675, "train/adv_mag": 0.45124114904648216, "train/adv_max": 0.4176618577578129, "train/adv_mean": 0.0029764847841504843, "train/adv_min": -0.37728211207267565, "train/adv_std": 0.055732312798500064, "train/cont_avg": 0.9947666266025641, "train/cont_loss_mean": 0.00014783440140094266, "train/cont_loss_std": 0.00435191634881635, "train/cont_neg_acc": 0.9957875471848708, "train/cont_neg_loss": 0.017184188934865792, "train/cont_pos_acc": 0.9999949436921339, "train/cont_pos_loss": 4.4916394278970985e-05, "train/cont_pred": 0.994769099736825, "train/cont_rate": 0.9947666266025641, "train/dyn_loss_mean": 6.980872917175293, "train/dyn_loss_std": 8.980842624566494, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1122005942540292, "train/extr_critic_critic_opt_grad_steps": 137520.0, "train/extr_critic_critic_opt_loss": 16978.756169871795, "train/extr_critic_mag": 8.876334420228616, "train/extr_critic_max": 8.876334420228616, "train/extr_critic_mean": 2.023139598430731, "train/extr_critic_min": -0.5390422979990641, "train/extr_critic_std": 2.1052585271688606, "train/extr_return_normed_mag": 1.5206761311262083, "train/extr_return_normed_max": 1.5206761311262083, "train/extr_return_normed_mean": 0.3459101636440326, "train/extr_return_normed_min": -0.09454927853284738, "train/extr_return_normed_std": 0.3266535165982369, "train/extr_return_rate": 0.6756841304974678, "train/extr_return_raw_mag": 9.748087878104968, "train/extr_return_raw_max": 9.748087878104968, "train/extr_return_raw_mean": 2.0426539225456044, "train/extr_return_raw_min": -0.8469519040523431, "train/extr_return_raw_std": 2.143147315734472, "train/extr_reward_mag": 1.0479095617930094, "train/extr_reward_max": 1.0479095617930094, "train/extr_reward_mean": 0.046351174847819865, "train/extr_reward_min": -0.6603396317897698, "train/extr_reward_std": 0.20939022287344322, "train/image_loss_mean": 3.7813899027995572, "train/image_loss_std": 8.785927552443285, "train/model_loss_mean": 8.021199338864058, "train/model_loss_std": 12.94685593140431, "train/model_opt_grad_norm": 38.59558623599023, "train/model_opt_grad_steps": 137403.00512820514, "train/model_opt_loss": 14936.844083032853, "train/model_opt_model_opt_grad_overflow": 0.005128205128205128, "train/model_opt_model_opt_grad_scale": 1852.5641025641025, "train/policy_entropy_mag": 2.6207611083984377, "train/policy_entropy_max": 2.6207611083984377, "train/policy_entropy_mean": 0.47501555253297856, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6635494273442488, "train/policy_logprob_mag": 7.438384171021291, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.4744030836300972, "train/policy_logprob_min": -7.438384171021291, "train/policy_logprob_std": 1.0821170164988592, "train/policy_randomness_mag": 0.9250136613845825, "train/policy_randomness_max": 0.9250136613845825, "train/policy_randomness_mean": 0.16765964405658917, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.23420382761038266, "train/post_ent_mag": 59.53698556362054, "train/post_ent_max": 59.53698556362054, "train/post_ent_mean": 42.95962367913662, "train/post_ent_min": 19.764958161574143, "train/post_ent_std": 6.9000346379402355, "train/prior_ent_mag": 75.94488873604017, "train/prior_ent_max": 75.94488873604017, "train/prior_ent_mean": 49.99270461644882, "train/prior_ent_min": 30.243672072581756, "train/prior_ent_std": 7.3328670403896234, "train/rep_loss_mean": 6.980872917175293, "train/rep_loss_std": 8.980842624566494, "train/reward_avg": 0.03490334503734723, "train/reward_loss_mean": 0.05113788513609996, "train/reward_loss_std": 0.20721563964318007, "train/reward_max_data": 1.0205128254034581, "train/reward_max_pred": 1.0185968301235102, "train/reward_neg_acc": 0.9944376707077026, "train/reward_neg_loss": 0.023095149002396145, "train/reward_pos_acc": 0.9869567470672803, "train/reward_pos_loss": 0.7363679616879194, "train/reward_pred": 0.03454063301667189, "train/reward_rate": 0.039458133012820515, "train_stats/sum_log_reward": 8.613513624345934, "train_stats/max_log_achievement_collect_coal": 0.5405405405405406, "train_stats/max_log_achievement_collect_drink": 4.216216216216216, "train_stats/max_log_achievement_collect_sapling": 1.6216216216216217, "train_stats/max_log_achievement_collect_stone": 10.81081081081081, "train_stats/max_log_achievement_collect_wood": 6.0, "train_stats/max_log_achievement_defeat_skeleton": 0.10810810810810811, "train_stats/max_log_achievement_defeat_zombie": 0.21621621621621623, "train_stats/max_log_achievement_eat_cow": 0.08108108108108109, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.3243243243243243, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_furnace": 1.3243243243243243, "train_stats/max_log_achievement_place_plant": 1.6216216216216217, "train_stats/max_log_achievement_place_stone": 3.972972972972973, "train_stats/max_log_achievement_place_table": 2.027027027027027, "train_stats/max_log_achievement_wake_up": 2.135135135135135, "train_stats/mean_log_entropy": 0.44892221568404017, "eval_stats/sum_log_reward": 8.475000262260437, "eval_stats/max_log_achievement_collect_coal": 0.75, "eval_stats/max_log_achievement_collect_drink": 3.625, "eval_stats/max_log_achievement_collect_sapling": 2.125, "eval_stats/max_log_achievement_collect_stone": 9.5, "eval_stats/max_log_achievement_collect_wood": 5.625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.125, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.125, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 1.0, "eval_stats/max_log_achievement_place_plant": 2.125, "eval_stats/max_log_achievement_place_stone": 4.375, "eval_stats/max_log_achievement_place_table": 1.625, "eval_stats/max_log_achievement_wake_up": 1.5, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 7.949006976559758e-05, "report/cont_loss_std": 0.002515507861971855, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.497483390267007e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 7.993411418283358e-05, "report/cont_pred": 0.993087887763977, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 6.856314659118652, "report/dyn_loss_std": 9.086691856384277, "report/image_loss_mean": 3.303767681121826, "report/image_loss_std": 9.319972038269043, "report/model_loss_mean": 7.477095127105713, "report/model_loss_std": 13.596800804138184, "report/post_ent_mag": 56.57984161376953, "report/post_ent_max": 56.57984161376953, "report/post_ent_mean": 42.27368927001953, "report/post_ent_min": 19.999099731445312, "report/post_ent_std": 6.053886413574219, "report/prior_ent_mag": 75.9949951171875, "report/prior_ent_max": 75.9949951171875, "report/prior_ent_mean": 49.11412811279297, "report/prior_ent_min": 27.144268035888672, "report/prior_ent_std": 6.512251853942871, "report/rep_loss_mean": 6.856314659118652, "report/rep_loss_std": 9.086691856384277, "report/reward_avg": 0.03486328199505806, "report/reward_loss_mean": 0.05945904180407524, "report/reward_loss_std": 0.23860567808151245, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0012383460998535, "report/reward_neg_acc": 0.9979612231254578, "report/reward_neg_loss": 0.027875198051333427, "report/reward_pos_acc": 0.9767441749572754, "report/reward_pos_loss": 0.7800113558769226, "report/reward_pred": 0.03446342051029205, "report/reward_rate": 0.0419921875, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 4.744400712297647e-07, "eval/cont_loss_std": 4.615530087903608e-06, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 1.4624390132667031e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 4.606082484315266e-07, "eval/cont_pred": 0.9990230798721313, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 18.92030143737793, "eval/dyn_loss_std": 12.713842391967773, "eval/image_loss_mean": 16.85643768310547, "eval/image_loss_std": 19.832792282104492, "eval/model_loss_mean": 28.294431686401367, "eval/model_loss_std": 24.55359649658203, "eval/post_ent_mag": 59.890201568603516, "eval/post_ent_max": 59.890201568603516, "eval/post_ent_mean": 41.3594970703125, "eval/post_ent_min": 17.856060028076172, "eval/post_ent_std": 7.725508689880371, "eval/prior_ent_mag": 75.9949951171875, "eval/prior_ent_max": 75.9949951171875, "eval/prior_ent_mean": 53.8466796875, "eval/prior_ent_min": 36.253021240234375, "eval/prior_ent_std": 6.127551078796387, "eval/rep_loss_mean": 18.92030143737793, "eval/rep_loss_std": 12.713842391967773, "eval/reward_avg": 0.02724609337747097, "eval/reward_loss_mean": 0.08581572771072388, "eval/reward_loss_std": 0.6591214537620544, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0008659362792969, "eval/reward_neg_acc": 0.9929577112197876, "eval/reward_neg_loss": 0.03456942364573479, "eval/reward_pos_acc": 0.8666667342185974, "eval/reward_pos_loss": 1.7837769985198975, "eval/reward_pred": 0.025657404214143753, "eval/reward_rate": 0.029296875, "replay/size": 555021.0, "replay/inserts": 7788.0, "replay/samples": 31152.0, "replay/insert_wait_avg": 1.550271808641901e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.492903874480057e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 1768.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1380171883699582e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 6.705522537231445e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3770973682404, "timer/env.step_count": 973.0, "timer/env.step_total": 82.5919497013092, "timer/env.step_frac": 0.0825608162347873, "timer/env.step_avg": 0.08488381264266105, "timer/env.step_min": 0.023448944091796875, "timer/env.step_max": 2.0671756267547607, "timer/replay._sample_count": 31152.0, "timer/replay._sample_total": 15.334798574447632, "timer/replay._sample_frac": 0.015329018042086253, "timer/replay._sample_avg": 0.0004922572731910513, "timer/replay._sample_min": 0.0003719329833984375, "timer/replay._sample_max": 0.010887861251831055, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1194.0, "timer/agent.policy_total": 20.386913776397705, "timer/agent.policy_frac": 0.020379228822841843, "timer/agent.policy_avg": 0.017074467149411812, "timer/agent.policy_min": 0.009478330612182617, "timer/agent.policy_max": 0.11159610748291016, "timer/dataset_train_count": 1947.0, "timer/dataset_train_total": 0.29445457458496094, "timer/dataset_train_frac": 0.0002943435783961893, "timer/dataset_train_avg": 0.000151235015195152, "timer/dataset_train_min": 9.226799011230469e-05, "timer/dataset_train_max": 0.0005331039428710938, "timer/agent.train_count": 1947.0, "timer/agent.train_total": 865.2239747047424, "timer/agent.train_frac": 0.8648978240115108, "timer/agent.train_avg": 0.44438827668451075, "timer/agent.train_min": 0.43200135231018066, "timer/agent.train_max": 1.8636107444763184, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4721653461456299, "timer/agent.report_frac": 0.0004719873609539714, "timer/agent.report_avg": 0.23608267307281494, "timer/agent.report_min": 0.23000884056091309, "timer/agent.report_max": 0.2421565055847168, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.6464462280273438e-05, "timer/dataset_eval_frac": 2.6454486363087766e-08, "timer/dataset_eval_avg": 2.6464462280273438e-05, "timer/dataset_eval_min": 2.6464462280273438e-05, "timer/dataset_eval_max": 2.6464462280273438e-05, "fps": 7.784955384306981}
{"step": 555776, "time": 71390.58511924744, "episode/length": 257.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9844961240310077, "episode/intrinsic_return": 0.0}
{"step": 556192, "time": 71440.45576000214, "episode/length": 255.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9765625, "episode/intrinsic_return": 0.0}
{"step": 556656, "time": 71495.85845160484, "episode/length": 212.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 556688, "time": 71501.15380120277, "episode/length": 158.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 556768, "time": 71511.94397234917, "episode/length": 200.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 556776, "time": 71514.42938375473, "episode/length": 416.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9904076738609112, "episode/intrinsic_return": 0.0}
{"step": 556832, "time": 71522.35647845268, "episode/length": 167.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 556912, "time": 71533.24244832993, "episode/length": 141.0, "episode/score": 8.1000000461936, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 557848, "time": 71645.01238203049, "episode/length": 206.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.966183574879227, "episode/intrinsic_return": 0.0}
{"step": 558000, "time": 71664.15866947174, "episode/length": 167.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 558128, "time": 71680.65019583702, "episode/length": 179.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 558264, "time": 71697.87898278236, "episode/length": 168.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9585798816568047, "episode/intrinsic_return": 0.0}
{"step": 558432, "time": 71718.97550582886, "episode/length": 391.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9974489795918368, "episode/intrinsic_return": 0.0}
{"step": 558464, "time": 71724.24806118011, "episode/length": 210.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 558816, "time": 71766.53470611572, "episode/length": 255.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.99609375, "episode/intrinsic_return": 0.0}
{"step": 558864, "time": 71773.62114357948, "episode/length": 53.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9259259259259259, "episode/intrinsic_return": 0.0}
{"step": 559368, "time": 71833.43693709373, "episode/length": 170.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9649122807017544, "episode/intrinsic_return": 0.0}
{"step": 559448, "time": 71844.15870523453, "episode/length": 164.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 559544, "time": 71856.82575511932, "episode/length": 159.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 559808, "time": 71889.58033704758, "episode/length": 244.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 560040, "time": 71936.15496277809, "eval_episode/length": 146.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9931972789115646}
{"step": 560040, "time": 71938.66618490219, "eval_episode/length": 170.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9941520467836257}
{"step": 560040, "time": 71940.20549273491, "eval_episode/length": 171.0, "eval_episode/score": 7.100000023841858, "eval_episode/reward_rate": 0.9941860465116279}
{"step": 560040, "time": 71942.90097212791, "eval_episode/length": 198.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9748743718592965}
{"step": 560040, "time": 71942.90908956528, "eval_episode/length": 198.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9899497487437185}
{"step": 560040, "time": 71948.38172626495, "eval_episode/length": 89.0, "eval_episode/score": 7.100000023841858, "eval_episode/reward_rate": 0.9888888888888889}
{"step": 560040, "time": 71948.39098715782, "eval_episode/length": 260.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9808429118773946}
{"step": 560040, "time": 71953.62015223503, "eval_episode/length": 166.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9760479041916168}
{"step": 560352, "time": 71989.54409575462, "episode/length": 185.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9623655913978495, "episode/intrinsic_return": 0.0}
{"step": 560776, "time": 72040.5651667118, "episode/length": 244.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 561040, "time": 72072.7206671238, "episode/length": 321.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9968944099378882, "episode/intrinsic_return": 0.0}
{"step": 561040, "time": 72072.72830104828, "episode/length": 186.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 561064, "time": 72078.59040880203, "episode/length": 211.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 561392, "time": 72118.22095775604, "episode/length": 197.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9646464646464646, "episode/intrinsic_return": 0.0}
{"step": 561400, "time": 72120.66612267494, "episode/length": 41.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.8809523809523809, "episode/intrinsic_return": 0.0}
{"step": 561608, "time": 72146.39630794525, "episode/length": 269.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9740740740740741, "episode/intrinsic_return": 0.0}
{"step": 561728, "time": 72161.9757232666, "episode/length": 85.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9883720930232558, "episode/intrinsic_return": 0.0}
{"step": 561864, "time": 72179.86992049217, "episode/length": 135.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 561928, "time": 72189.36646652222, "episode/length": 636.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9968602825745683, "episode/intrinsic_return": 0.0}
{"step": 562016, "time": 72201.18372321129, "episode/length": 207.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 562336, "time": 72239.80537509918, "episode/length": 58.0, "episode/score": 2.099999949336052, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 562776, "time": 72292.90757417679, "episode/length": 171.0, "episode/score": 9.099999964237213, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 562840, "time": 72301.86983919144, "episode/length": 224.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 563304, "time": 72357.26278400421, "episode/length": 171.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 563320, "time": 72360.61028885841, "episode/length": 213.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9813084112149533, "episode/intrinsic_return": 0.0}
{"step": 563321, "time": 72363.13523864746, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.515885729667468, "train/action_min": 0.0, "train/action_std": 3.122771315696912, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0437129352050714, "train/actor_opt_grad_steps": 139470.0, "train/actor_opt_loss": -11.401661389760482, "train/adv_mag": 0.4442978745851761, "train/adv_max": 0.4162028525120173, "train/adv_mean": 0.0030714062225272827, "train/adv_min": -0.3761821929460917, "train/adv_std": 0.05527226428190867, "train/cont_avg": 0.994901842948718, "train/cont_loss_mean": 4.430491536581007e-05, "train/cont_loss_std": 0.0012243252934747663, "train/cont_neg_acc": 0.9992673996167305, "train/cont_neg_loss": 0.0020861525263078363, "train/cont_pos_acc": 0.999989901139186, "train/cont_pos_loss": 3.109718233997974e-05, "train/cont_pred": 0.9948845826662503, "train/cont_rate": 0.994901842948718, "train/dyn_loss_mean": 7.089539117079514, "train/dyn_loss_std": 8.976453607510297, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0753930749037326, "train/extr_critic_critic_opt_grad_steps": 139470.0, "train/extr_critic_critic_opt_loss": 17013.115209334937, "train/extr_critic_mag": 8.97169895661183, "train/extr_critic_max": 8.97169895661183, "train/extr_critic_mean": 1.9756626061904126, "train/extr_critic_min": -0.5686930949871357, "train/extr_critic_std": 2.1253362863491745, "train/extr_return_normed_mag": 1.5181016964790148, "train/extr_return_normed_max": 1.5181016964790148, "train/extr_return_normed_mean": 0.33415250892822557, "train/extr_return_normed_min": -0.09333726805754197, "train/extr_return_normed_std": 0.32434512476126354, "train/extr_return_rate": 0.6535954505969317, "train/extr_return_raw_mag": 9.901642183157113, "train/extr_return_raw_max": 9.901642183157113, "train/extr_return_raw_mean": 1.9961814476893498, "train/extr_return_raw_min": -0.8584932217231164, "train/extr_return_raw_std": 2.166075897216797, "train/extr_reward_mag": 1.0438240772638565, "train/extr_reward_max": 1.0438240772638565, "train/extr_reward_mean": 0.046133730904414104, "train/extr_reward_min": -0.6863270765695817, "train/extr_reward_std": 0.20874746082684933, "train/image_loss_mean": 3.80521879196167, "train/image_loss_std": 8.719110997517904, "train/model_loss_mean": 8.111554211836594, "train/model_loss_std": 12.880888430277507, "train/model_opt_grad_norm": 38.67373294341259, "train/model_opt_grad_steps": 139351.53846153847, "train/model_opt_loss": 10297.43664863782, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1269.2307692307693, "train/policy_entropy_mag": 2.6108893003219213, "train/policy_entropy_max": 2.6108893003219213, "train/policy_entropy_mean": 0.4740579311664288, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6579482628748967, "train/policy_logprob_mag": 7.43838415145874, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.47498596478731203, "train/policy_logprob_min": -7.43838415145874, "train/policy_logprob_std": 1.084919427602719, "train/policy_randomness_mag": 0.9215293480799749, "train/policy_randomness_max": 0.9215293480799749, "train/policy_randomness_mean": 0.16732164636636393, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.23222686312137505, "train/post_ent_mag": 59.4766488295335, "train/post_ent_max": 59.4766488295335, "train/post_ent_mean": 42.799908545078374, "train/post_ent_min": 19.798283058557754, "train/post_ent_std": 6.860213702764266, "train/prior_ent_mag": 75.83280843098959, "train/prior_ent_max": 75.83280843098959, "train/prior_ent_mean": 49.901004145695616, "train/prior_ent_min": 30.193728119287737, "train/prior_ent_std": 7.344992923736572, "train/rep_loss_mean": 7.089539117079514, "train/rep_loss_std": 8.976453607510297, "train/reward_avg": 0.03518579692985767, "train/reward_loss_mean": 0.052567636527312105, "train/reward_loss_std": 0.2151615064113568, "train/reward_max_data": 1.0210256460385445, "train/reward_max_pred": 1.0190757079002184, "train/reward_neg_acc": 0.9939947418677502, "train/reward_neg_loss": 0.02412462508162627, "train/reward_pos_acc": 0.9864615415915464, "train/reward_pos_loss": 0.7402532620307727, "train/reward_pred": 0.034957075085586466, "train/reward_rate": 0.03979366987179487, "train_stats/sum_log_reward": 8.559459647616825, "train_stats/max_log_achievement_collect_coal": 0.8648648648648649, "train_stats/max_log_achievement_collect_drink": 3.7837837837837838, "train_stats/max_log_achievement_collect_sapling": 1.5405405405405406, "train_stats/max_log_achievement_collect_stone": 12.027027027027026, "train_stats/max_log_achievement_collect_wood": 6.0, "train_stats/max_log_achievement_defeat_skeleton": 0.08108108108108109, "train_stats/max_log_achievement_defeat_zombie": 0.21621621621621623, "train_stats/max_log_achievement_eat_cow": 0.16216216216216217, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.02702702702702703, "train_stats/max_log_achievement_make_wood_pickaxe": 1.162162162162162, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_furnace": 1.7837837837837838, "train_stats/max_log_achievement_place_plant": 1.4054054054054055, "train_stats/max_log_achievement_place_stone": 3.2162162162162162, "train_stats/max_log_achievement_place_table": 2.189189189189189, "train_stats/max_log_achievement_wake_up": 2.108108108108108, "train_stats/mean_log_entropy": 0.4411978181954977, "eval_stats/sum_log_reward": 8.225000202655792, "eval_stats/max_log_achievement_collect_coal": 0.375, "eval_stats/max_log_achievement_collect_drink": 2.5, "eval_stats/max_log_achievement_collect_sapling": 1.25, "eval_stats/max_log_achievement_collect_stone": 7.625, "eval_stats/max_log_achievement_collect_wood": 6.25, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.125, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 1.0, "eval_stats/max_log_achievement_place_plant": 1.125, "eval_stats/max_log_achievement_place_stone": 2.75, "eval_stats/max_log_achievement_place_table": 2.5, "eval_stats/max_log_achievement_wake_up": 2.0, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 1.2265201803529635e-05, "report/cont_loss_std": 0.0003601289354264736, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 4.578260632115416e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.210073969559744e-05, "report/cont_pred": 0.995105504989624, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 6.964261054992676, "report/dyn_loss_std": 8.571731567382812, "report/image_loss_mean": 3.077517032623291, "report/image_loss_std": 7.569962024688721, "report/model_loss_mean": 7.309433937072754, "report/model_loss_std": 11.091065406799316, "report/post_ent_mag": 57.74813461303711, "report/post_ent_max": 57.74813461303711, "report/post_ent_mean": 42.05810546875, "report/post_ent_min": 20.95191192626953, "report/post_ent_std": 6.883622169494629, "report/prior_ent_mag": 75.78838348388672, "report/prior_ent_max": 75.78838348388672, "report/prior_ent_mean": 49.40189743041992, "report/prior_ent_min": 29.16149139404297, "report/prior_ent_std": 7.037309646606445, "report/rep_loss_mean": 6.964261054992676, "report/rep_loss_std": 8.571731567382812, "report/reward_avg": 0.04140625149011612, "report/reward_loss_mean": 0.053348638117313385, "report/reward_loss_std": 0.17959153652191162, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.127631664276123, "report/reward_neg_acc": 0.9887295365333557, "report/reward_neg_loss": 0.02241508476436138, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6823310256004333, "report/reward_pred": 0.042233459651470184, "report/reward_rate": 0.046875, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 2.5053784611372976e-06, "eval/cont_loss_std": 3.955829743063077e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 4.7599172830814496e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.2841134068585234e-06, "eval/cont_pred": 0.9951152205467224, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 19.509441375732422, "eval/dyn_loss_std": 12.951790809631348, "eval/image_loss_mean": 15.68989086151123, "eval/image_loss_std": 17.167556762695312, "eval/model_loss_mean": 27.59198760986328, "eval/model_loss_std": 22.573240280151367, "eval/post_ent_mag": 57.252655029296875, "eval/post_ent_max": 57.252655029296875, "eval/post_ent_mean": 40.811279296875, "eval/post_ent_min": 20.024072647094727, "eval/post_ent_std": 7.120795726776123, "eval/prior_ent_mag": 75.78838348388672, "eval/prior_ent_max": 75.78838348388672, "eval/prior_ent_mean": 53.091331481933594, "eval/prior_ent_min": 33.31938934326172, "eval/prior_ent_std": 7.052515506744385, "eval/rep_loss_mean": 19.509441375732422, "eval/rep_loss_std": 12.951790809631348, "eval/reward_avg": 0.04658203572034836, "eval/reward_loss_mean": 0.1964302957057953, "eval/reward_loss_std": 1.019382119178772, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0018301010131836, "eval/reward_neg_acc": 0.9897013902664185, "eval/reward_neg_loss": 0.08558052778244019, "eval/reward_pos_acc": 0.7735849022865295, "eval/reward_pos_loss": 2.2272820472717285, "eval/reward_pred": 0.03763778135180473, "eval/reward_rate": 0.0517578125, "replay/size": 562817.0, "replay/inserts": 7796.0, "replay/samples": 31184.0, "replay/insert_wait_avg": 1.5085265843179545e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.401802039501177e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 2512.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.119390414778594e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.08970832824707e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1001.5899066925049, "timer/env.step_count": 975.0, "timer/env.step_total": 83.50811195373535, "timer/env.step_frac": 0.08337555260465791, "timer/env.step_avg": 0.08564934559357472, "timer/env.step_min": 0.02335500717163086, "timer/env.step_max": 3.1183922290802, "timer/replay._sample_count": 31184.0, "timer/replay._sample_total": 15.361137866973877, "timer/replay._sample_frac": 0.015336753859371562, "timer/replay._sample_avg": 0.0004925967761343598, "timer/replay._sample_min": 0.0004127025604248047, "timer/replay._sample_max": 0.03527188301086426, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1289.0, "timer/agent.policy_total": 20.30808663368225, "timer/agent.policy_frac": 0.020275849924191555, "timer/agent.policy_avg": 0.015754915929931924, "timer/agent.policy_min": 0.009382963180541992, "timer/agent.policy_max": 0.07508039474487305, "timer/dataset_train_count": 1949.0, "timer/dataset_train_total": 0.29180073738098145, "timer/dataset_train_frac": 0.00029133753787972857, "timer/dataset_train_avg": 0.00014971818234016493, "timer/dataset_train_min": 9.250640869140625e-05, "timer/dataset_train_max": 0.0004303455352783203, "timer/agent.train_count": 1949.0, "timer/agent.train_total": 863.6844706535339, "timer/agent.train_frac": 0.8623134726922633, "timer/agent.train_avg": 0.443142365650864, "timer/agent.train_min": 0.43009233474731445, "timer/agent.train_max": 0.9463083744049072, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47373342514038086, "timer/agent.report_frac": 0.00047298142880129913, "timer/agent.report_avg": 0.23686671257019043, "timer/agent.report_min": 0.23093795776367188, "timer/agent.report_max": 0.24279546737670898, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.6702880859375e-05, "timer/dataset_eval_frac": 2.666049316286987e-08, "timer/dataset_eval_avg": 2.6702880859375e-05, "timer/dataset_eval_min": 2.6702880859375e-05, "timer/dataset_eval_max": 2.6702880859375e-05, "fps": 7.783503186784899}
{"step": 563392, "time": 72371.28168606758, "episode/length": 207.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 563712, "time": 72409.79686331749, "episode/length": 171.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 563992, "time": 72443.85780477524, "episode/length": 324.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9969230769230769, "episode/intrinsic_return": 0.0}
{"step": 564344, "time": 72486.13168859482, "episode/length": 195.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 564888, "time": 72550.9237101078, "episode/length": 146.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 565112, "time": 72578.47580361366, "episode/length": 283.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9859154929577465, "episode/intrinsic_return": 0.0}
{"step": 565136, "time": 72582.86892199516, "episode/length": 98.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.98989898989899, "episode/intrinsic_return": 0.0}
{"step": 565144, "time": 72585.31130361557, "episode/length": 229.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 565200, "time": 72593.30799818039, "episode/length": 234.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 565264, "time": 72603.66454863548, "episode/length": 405.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9975369458128078, "episode/intrinsic_return": 0.0}
{"step": 565312, "time": 72610.75062942505, "episode/length": 164.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 566280, "time": 72724.64877414703, "episode/length": 120.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9917355371900827, "episode/intrinsic_return": 0.0}
{"step": 566520, "time": 72754.05269527435, "episode/length": 390.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9872122762148338, "episode/intrinsic_return": 0.0}
{"step": 566872, "time": 72796.4655251503, "episode/length": 216.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9723502304147466, "episode/intrinsic_return": 0.0}
{"step": 566880, "time": 72799.13506674767, "episode/length": 209.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 567120, "time": 72829.30129384995, "episode/length": 231.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9698275862068966, "episode/intrinsic_return": 0.0}
{"step": 567208, "time": 72840.91738915443, "episode/length": 289.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 567768, "time": 72907.69021606445, "episode/length": 185.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 567952, "time": 72930.56766080856, "episode/length": 350.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9943019943019943, "episode/intrinsic_return": 0.0}
{"step": 568208, "time": 72961.82095384598, "episode/length": 166.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 568264, "time": 72969.98019313812, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 568328, "time": 72978.90374493599, "episode/length": 225.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 568568, "time": 73008.7525677681, "episode/length": 431.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 568736, "time": 73029.69139242172, "episode/length": 201.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9851485148514851, "episode/intrinsic_return": 0.0}
{"step": 569240, "time": 73089.67690134048, "episode/length": 253.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9724409448818898, "episode/intrinsic_return": 0.0}
{"step": 569408, "time": 73110.74891281128, "episode/length": 142.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 569424, "time": 73114.04577755928, "episode/length": 151.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 569464, "time": 73120.25906181335, "episode/length": 211.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 569640, "time": 73142.0688803196, "episode/length": 163.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 569664, "time": 73146.41196012497, "episode/length": 213.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 570024, "time": 73205.9850692749, "eval_episode/length": 81.0, "eval_episode/score": 8.100000023841858, "eval_episode/reward_rate": 0.9878048780487805}
{"step": 570024, "time": 73210.61099147797, "eval_episode/length": 157.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9746835443037974}
{"step": 570024, "time": 73212.40970540047, "eval_episode/length": 165.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9698795180722891}
{"step": 570024, "time": 73214.20336937904, "eval_episode/length": 171.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9709302325581395}
{"step": 570024, "time": 73216.64748311043, "eval_episode/length": 192.0, "eval_episode/score": 6.0999999940395355, "eval_episode/reward_rate": 0.9948186528497409}
{"step": 570024, "time": 73219.89831614494, "eval_episode/length": 233.0, "eval_episode/score": 9.099999994039536, "eval_episode/reward_rate": 0.9957264957264957}
{"step": 570024, "time": 73219.90688180923, "eval_episode/length": 233.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9700854700854701}
{"step": 570024, "time": 73224.17744207382, "eval_episode/length": 260.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9770114942528736}
{"step": 570200, "time": 73244.59240055084, "episode/length": 203.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 570208, "time": 73247.04074835777, "episode/length": 70.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9436619718309859, "episode/intrinsic_return": 0.0}
{"step": 570528, "time": 73286.12809109688, "episode/length": 132.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9924812030075187, "episode/intrinsic_return": 0.0}
{"step": 570792, "time": 73318.18178915977, "episode/length": 172.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 571136, "time": 73360.32192707062, "episode/length": 213.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9813084112149533, "episode/intrinsic_return": 0.0}
{"step": 571141, "time": 73363.26680374146, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.537679349459134, "train/action_min": 0.0, "train/action_std": 3.181955694540953, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04263963361199086, "train/actor_opt_grad_steps": 141420.0, "train/actor_opt_loss": -10.939007128354831, "train/adv_mag": 0.4491725857441242, "train/adv_max": 0.4203293601671855, "train/adv_mean": 0.002852242046085452, "train/adv_min": -0.38337806188143214, "train/adv_std": 0.054312000786646816, "train/cont_avg": 0.9950520833333333, "train/cont_loss_mean": 6.28105410165803e-05, "train/cont_loss_std": 0.0018155823122306641, "train/cont_neg_acc": 0.9987179487179487, "train/cont_neg_loss": 0.007025499780819444, "train/cont_pos_acc": 0.9999949522507496, "train/cont_pos_loss": 3.417928125071075e-05, "train/cont_pred": 0.9950443142499679, "train/cont_rate": 0.9950520833333333, "train/dyn_loss_mean": 6.979177978711251, "train/dyn_loss_std": 9.027750059274526, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0679895352094602, "train/extr_critic_critic_opt_grad_steps": 141420.0, "train/extr_critic_critic_opt_loss": 17024.160912459934, "train/extr_critic_mag": 9.065699293674566, "train/extr_critic_max": 9.065699293674566, "train/extr_critic_mean": 1.9306143354146907, "train/extr_critic_min": -0.5534315690016135, "train/extr_critic_std": 2.110426384363419, "train/extr_return_normed_mag": 1.5088858879529512, "train/extr_return_normed_max": 1.5088858879529512, "train/extr_return_normed_mean": 0.3225078725661987, "train/extr_return_normed_min": -0.09497818849407709, "train/extr_return_normed_std": 0.31899398259627515, "train/extr_return_rate": 0.6489773982610458, "train/extr_return_raw_mag": 9.937846110417293, "train/extr_return_raw_max": 9.937846110417293, "train/extr_return_raw_mean": 1.9498099813094505, "train/extr_return_raw_min": -0.8615768240048335, "train/extr_return_raw_std": 2.1480237649037286, "train/extr_reward_mag": 1.0462217905582525, "train/extr_reward_max": 1.0462217905582525, "train/extr_reward_mean": 0.04481830099263252, "train/extr_reward_min": -0.6698813261129917, "train/extr_reward_std": 0.20607990217514527, "train/image_loss_mean": 3.7900093408731315, "train/image_loss_std": 8.873521477136856, "train/model_loss_mean": 8.028731104043814, "train/model_loss_std": 13.08213507823455, "train/model_opt_grad_norm": 37.03613728254269, "train/model_opt_grad_steps": 141299.64102564103, "train/model_opt_loss": 10344.17738631811, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1288.4615384615386, "train/policy_entropy_mag": 2.600725925885714, "train/policy_entropy_max": 2.600725925885714, "train/policy_entropy_mean": 0.48238519919224276, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6678788982904874, "train/policy_logprob_mag": 7.438384122114915, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.4818353166946998, "train/policy_logprob_min": -7.438384122114915, "train/policy_logprob_std": 1.0850953753177937, "train/policy_randomness_mag": 0.9179421204787034, "train/policy_randomness_max": 0.9179421204787034, "train/policy_randomness_mean": 0.17026080664915916, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.2357319420728928, "train/post_ent_mag": 59.52640991210937, "train/post_ent_max": 59.52640991210937, "train/post_ent_mean": 42.87001106066582, "train/post_ent_min": 19.570531913561698, "train/post_ent_std": 6.876086530929957, "train/prior_ent_mag": 75.87605234781901, "train/prior_ent_max": 75.87605234781901, "train/prior_ent_mean": 49.88817958342723, "train/prior_ent_min": 29.92789446512858, "train/prior_ent_std": 7.394847759833703, "train/rep_loss_mean": 6.979177978711251, "train/rep_loss_std": 9.027750059274526, "train/reward_avg": 0.03361177865224771, "train/reward_loss_mean": 0.05115222624288156, "train/reward_loss_std": 0.21167166141363292, "train/reward_max_data": 1.0179487222280257, "train/reward_max_pred": 1.0171076242740338, "train/reward_neg_acc": 0.9944340391036791, "train/reward_neg_loss": 0.023660565564074577, "train/reward_pos_acc": 0.9862080803284279, "train/reward_pos_loss": 0.7467859292641664, "train/reward_pred": 0.03330880705362711, "train/reward_rate": 0.038141025641025644, "train_stats/sum_log_reward": 8.41428587777274, "train_stats/max_log_achievement_collect_coal": 0.7428571428571429, "train_stats/max_log_achievement_collect_drink": 3.8285714285714287, "train_stats/max_log_achievement_collect_sapling": 1.4285714285714286, "train_stats/max_log_achievement_collect_stone": 10.685714285714285, "train_stats/max_log_achievement_collect_wood": 6.714285714285714, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.22857142857142856, "train_stats/max_log_achievement_eat_cow": 0.02857142857142857, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.457142857142857, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_furnace": 1.457142857142857, "train_stats/max_log_achievement_place_plant": 1.3428571428571427, "train_stats/max_log_achievement_place_stone": 3.7142857142857144, "train_stats/max_log_achievement_place_table": 2.3714285714285714, "train_stats/max_log_achievement_wake_up": 2.0, "train_stats/mean_log_entropy": 0.46974738836288454, "eval_stats/sum_log_reward": 8.100000262260437, "eval_stats/max_log_achievement_collect_coal": 0.125, "eval_stats/max_log_achievement_collect_drink": 3.25, "eval_stats/max_log_achievement_collect_sapling": 1.875, "eval_stats/max_log_achievement_collect_stone": 10.0, "eval_stats/max_log_achievement_collect_wood": 6.25, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.25, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.5, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 1.0, "eval_stats/max_log_achievement_place_plant": 1.75, "eval_stats/max_log_achievement_place_stone": 4.75, "eval_stats/max_log_achievement_place_table": 2.125, "eval_stats/max_log_achievement_wake_up": 1.625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 3.7160705232963664e-06, "report/cont_loss_std": 2.0829334971494973e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 4.42120035586413e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 3.5173663945897715e-06, "report/cont_pred": 0.9951139092445374, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 8.22771167755127, "report/dyn_loss_std": 9.74178695678711, "report/image_loss_mean": 4.532582759857178, "report/image_loss_std": 11.605783462524414, "report/model_loss_mean": 9.521537780761719, "report/model_loss_std": 16.258411407470703, "report/post_ent_mag": 59.589080810546875, "report/post_ent_max": 59.589080810546875, "report/post_ent_mean": 42.53071594238281, "report/post_ent_min": 16.709163665771484, "report/post_ent_std": 6.67012357711792, "report/prior_ent_mag": 76.0544662475586, "report/prior_ent_max": 76.0544662475586, "report/prior_ent_mean": 50.57729721069336, "report/prior_ent_min": 30.605533599853516, "report/prior_ent_std": 7.303596019744873, "report/rep_loss_mean": 8.22771167755127, "report/rep_loss_std": 9.74178695678711, "report/reward_avg": 0.02812500111758709, "report/reward_loss_mean": 0.052324697375297546, "report/reward_loss_std": 0.17848487198352814, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0017750263214111, "report/reward_neg_acc": 0.9908998012542725, "report/reward_neg_loss": 0.02942034602165222, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6995362043380737, "report/reward_pred": 0.028609851375222206, "report/reward_rate": 0.0341796875, "eval/cont_avg": 0.9931640625, "eval/cont_loss_mean": 1.167474238172872e-06, "eval/cont_loss_std": 4.801353043148993e-06, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 5.055441215517931e-05, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 8.275443974525842e-07, "eval/cont_pred": 0.9931635856628418, "eval/cont_rate": 0.9931640625, "eval/dyn_loss_mean": 18.866493225097656, "eval/dyn_loss_std": 12.79008674621582, "eval/image_loss_mean": 14.564901351928711, "eval/image_loss_std": 17.757553100585938, "eval/model_loss_mean": 26.03464126586914, "eval/model_loss_std": 22.693580627441406, "eval/post_ent_mag": 59.537288665771484, "eval/post_ent_max": 59.537288665771484, "eval/post_ent_mean": 39.95164489746094, "eval/post_ent_min": 21.25619888305664, "eval/post_ent_std": 6.963618755340576, "eval/prior_ent_mag": 76.0544662475586, "eval/prior_ent_max": 76.0544662475586, "eval/prior_ent_mean": 52.517791748046875, "eval/prior_ent_min": 35.39811706542969, "eval/prior_ent_std": 6.608620643615723, "eval/rep_loss_mean": 18.866493225097656, "eval/rep_loss_std": 12.79008674621582, "eval/reward_avg": 0.05283203348517418, "eval/reward_loss_mean": 0.14984259009361267, "eval/reward_loss_std": 0.7920383214950562, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0000362396240234, "eval/reward_neg_acc": 0.9917098879814148, "eval/reward_neg_loss": 0.041775401681661606, "eval/reward_pos_acc": 0.7457627058029175, "eval/reward_pos_loss": 1.9173822402954102, "eval/reward_pred": 0.04121173918247223, "eval/reward_rate": 0.0576171875, "replay/size": 570637.0, "replay/inserts": 7820.0, "replay/samples": 31280.0, "replay/insert_wait_avg": 1.533897331608531e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.396175511352851e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 2088.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.107710074647633e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.3262033462524414e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1210608482361, "timer/env.step_count": 977.0, "timer/env.step_total": 80.46717405319214, "timer/env.step_frac": 0.08045743380800845, "timer/env.step_avg": 0.08236148828371764, "timer/env.step_min": 0.02313971519470215, "timer/env.step_max": 2.000110387802124, "timer/replay._sample_count": 31280.0, "timer/replay._sample_total": 15.376952648162842, "timer/replay._sample_frac": 0.01537509132656514, "timer/replay._sample_avg": 0.0004915905578057175, "timer/replay._sample_min": 0.0003981590270996094, "timer/replay._sample_max": 0.009313344955444336, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1238.0, "timer/agent.policy_total": 19.684961557388306, "timer/agent.policy_frac": 0.019682578767707213, "timer/agent.policy_avg": 0.015900615151363737, "timer/agent.policy_min": 0.009568214416503906, "timer/agent.policy_max": 0.07556700706481934, "timer/dataset_train_count": 1955.0, "timer/dataset_train_total": 0.29532957077026367, "timer/dataset_train_frac": 0.00029529382224966323, "timer/dataset_train_avg": 0.0001510637190640735, "timer/dataset_train_min": 9.441375732421875e-05, "timer/dataset_train_max": 0.0008337497711181641, "timer/agent.train_count": 1955.0, "timer/agent.train_total": 866.8546884059906, "timer/agent.train_frac": 0.8667497589449643, "timer/agent.train_avg": 0.4434039326884862, "timer/agent.train_min": 0.4305124282836914, "timer/agent.train_max": 1.0466179847717285, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4742543697357178, "timer/agent.report_frac": 0.0004741969630491401, "timer/agent.report_avg": 0.2371271848678589, "timer/agent.report_min": 0.22951459884643555, "timer/agent.report_max": 0.24473977088928223, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.123283386230469e-05, "timer/dataset_eval_frac": 3.122905324662904e-08, "timer/dataset_eval_avg": 3.123283386230469e-05, "timer/dataset_eval_min": 3.123283386230469e-05, "timer/dataset_eval_max": 3.123283386230469e-05, "fps": 7.81894060101699}
{"step": 571424, "time": 73395.97199988365, "episode/length": 151.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 571536, "time": 73410.38417506218, "episode/length": 286.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9860627177700348, "episode/intrinsic_return": 0.0}
{"step": 571720, "time": 73433.22992420197, "episode/length": 372.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9839142091152815, "episode/intrinsic_return": 0.0}
{"step": 572336, "time": 73506.72496557236, "episode/length": 99.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.95, "episode/intrinsic_return": 0.0}
{"step": 572488, "time": 73525.85408711433, "episode/length": 132.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9924812030075187, "episode/intrinsic_return": 0.0}
{"step": 572840, "time": 73568.38774681091, "episode/length": 255.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9765625, "episode/intrinsic_return": 0.0}
{"step": 572976, "time": 73585.81169390678, "episode/length": 413.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 573048, "time": 73595.6393327713, "episode/length": 314.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 573552, "time": 73656.95887589455, "episode/length": 418.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9785202863961814, "episode/intrinsic_return": 0.0}
{"step": 573568, "time": 73660.43651223183, "episode/length": 230.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 573664, "time": 73672.97889375687, "episode/length": 165.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 574064, "time": 73720.85575318336, "episode/length": 152.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 574576, "time": 73782.02378034592, "episode/length": 199.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 574608, "time": 73787.77611613274, "episode/length": 264.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 574640, "time": 73793.00542354584, "episode/length": 437.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 574656, "time": 73796.32496213913, "episode/length": 135.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9632352941176471, "episode/intrinsic_return": 0.0}
{"step": 575064, "time": 73845.29158854485, "episode/length": 174.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 575096, "time": 73850.4953699112, "episode/length": 255.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9765625, "episode/intrinsic_return": 0.0}
{"step": 575296, "time": 73875.21622252464, "episode/length": 153.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.961038961038961, "episode/intrinsic_return": 0.0}
{"step": 575360, "time": 73884.12077736855, "episode/length": 225.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9734513274336283, "episode/intrinsic_return": 0.0}
{"step": 575696, "time": 73924.61287331581, "episode/length": 135.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.0}
{"step": 576256, "time": 73991.28013253212, "episode/length": 199.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 576352, "time": 74003.80907392502, "episode/length": 156.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 576432, "time": 74014.53253912926, "episode/length": 141.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 576728, "time": 74050.64839076996, "episode/length": 207.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9663461538461539, "episode/intrinsic_return": 0.0}
{"step": 577376, "time": 74127.22272753716, "episode/length": 341.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 577888, "time": 74188.37858319283, "episode/length": 413.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9879227053140096, "episode/intrinsic_return": 0.0}
{"step": 577952, "time": 74197.19952893257, "episode/length": 152.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 577960, "time": 74199.66612386703, "episode/length": 212.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 577976, "time": 74203.0111207962, "episode/length": 202.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9704433497536946, "episode/intrinsic_return": 0.0}
{"step": 578120, "time": 74221.04554629326, "episode/length": 344.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9884057971014493, "episode/intrinsic_return": 0.0}
{"step": 578704, "time": 74290.61637854576, "episode/length": 165.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 578888, "time": 74313.42964434624, "episode/length": 115.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9913793103448276, "episode/intrinsic_return": 0.0}
{"step": 579240, "time": 74355.88052082062, "episode/length": 442.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9796839729119639, "episode/intrinsic_return": 0.0}
{"step": 579281, "time": 74363.51496648788, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.451541077856924, "train/action_min": 0.0, "train/action_std": 3.096149413024678, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04400099976463061, "train/actor_opt_grad_steps": 143415.0, "train/actor_opt_loss": -13.46141494270049, "train/adv_mag": 0.4527072491599064, "train/adv_max": 0.419210954477974, "train/adv_mean": 0.0025638590200376746, "train/adv_min": -0.38765253287320045, "train/adv_std": 0.054827579991051964, "train/cont_avg": 0.9949400658700981, "train/cont_loss_mean": 0.00013701184221109124, "train/cont_loss_std": 0.0041781373704998705, "train/cont_neg_acc": 0.9979866953457103, "train/cont_neg_loss": 0.006955024530038916, "train/cont_pos_acc": 0.999985532433379, "train/cont_pos_loss": 9.116495943844678e-05, "train/cont_pred": 0.9949269832349291, "train/cont_rate": 0.9949400658700981, "train/dyn_loss_mean": 7.025827964146932, "train/dyn_loss_std": 9.019129734413296, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0931783686665928, "train/extr_critic_critic_opt_grad_steps": 143415.0, "train/extr_critic_critic_opt_loss": 17079.345420687805, "train/extr_critic_mag": 9.084917765037686, "train/extr_critic_max": 9.084917765037686, "train/extr_critic_mean": 1.9960975535944396, "train/extr_critic_min": -0.5637400874904558, "train/extr_critic_std": 2.1413066235243106, "train/extr_return_normed_mag": 1.5122857759980595, "train/extr_return_normed_max": 1.5122857759980595, "train/extr_return_normed_mean": 0.3330661585810138, "train/extr_return_normed_min": -0.09355880106415819, "train/extr_return_normed_std": 0.32418760014515297, "train/extr_return_rate": 0.6605820172265464, "train/extr_return_raw_mag": 9.936044646244422, "train/extr_return_raw_max": 9.936044646244422, "train/extr_return_raw_mean": 2.013301089698193, "train/extr_return_raw_min": -0.8532401837554633, "train/extr_return_raw_std": 2.178575653071497, "train/extr_reward_mag": 1.0490798669702865, "train/extr_reward_max": 1.0490798669702865, "train/extr_reward_mean": 0.04552034818220372, "train/extr_reward_min": -0.662842682763642, "train/extr_reward_std": 0.20775443381246397, "train/image_loss_mean": 3.825434967583301, "train/image_loss_std": 8.839940192652683, "train/model_loss_mean": 8.093389167505151, "train/model_loss_std": 13.012627568899417, "train/model_opt_grad_norm": 36.37080640745867, "train/model_opt_grad_steps": 143293.00980392157, "train/model_opt_loss": 12154.302985696231, "train/model_opt_model_opt_grad_overflow": 0.004901960784313725, "train/model_opt_model_opt_grad_scale": 1495.0980392156862, "train/policy_entropy_mag": 2.619507505613215, "train/policy_entropy_max": 2.619507505613215, "train/policy_entropy_mean": 0.4654153334159477, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6560587159851018, "train/policy_logprob_mag": 7.438384137901605, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.4658697931205525, "train/policy_logprob_min": -7.438384137901605, "train/policy_logprob_std": 1.078016929766711, "train/policy_randomness_mag": 0.9245711971147388, "train/policy_randomness_max": 0.9245711971147388, "train/policy_randomness_mean": 0.16427118787724598, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.23155993522674428, "train/post_ent_mag": 59.62176676357494, "train/post_ent_max": 59.62176676357494, "train/post_ent_mean": 43.03687652887083, "train/post_ent_min": 19.63312536127427, "train/post_ent_std": 6.9105025249369, "train/prior_ent_mag": 75.92040039511288, "train/prior_ent_max": 75.92040039511288, "train/prior_ent_mean": 50.067474870120776, "train/prior_ent_min": 30.105242888132732, "train/prior_ent_std": 7.337093797384524, "train/rep_loss_mean": 7.025827964146932, "train/rep_loss_std": 9.019129734413296, "train/reward_avg": 0.03425197206510633, "train/reward_loss_mean": 0.052320435953636966, "train/reward_loss_std": 0.21385237209352792, "train/reward_max_data": 1.0210784363980387, "train/reward_max_pred": 1.019615097957499, "train/reward_neg_acc": 0.994318227557575, "train/reward_neg_loss": 0.02407710775550382, "train/reward_pos_acc": 0.9854985002209159, "train/reward_pos_loss": 0.7491137072736141, "train/reward_pred": 0.033727449237131606, "train/reward_rate": 0.03891410079656863, "train_stats/sum_log_reward": 8.629411991904764, "train_stats/max_log_achievement_collect_coal": 0.8235294117647058, "train_stats/max_log_achievement_collect_drink": 6.9411764705882355, "train_stats/max_log_achievement_collect_sapling": 1.5, "train_stats/max_log_achievement_collect_stone": 13.529411764705882, "train_stats/max_log_achievement_collect_wood": 6.676470588235294, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.23529411764705882, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.4411764705882353, "train_stats/max_log_achievement_make_wood_sword": 0.058823529411764705, "train_stats/max_log_achievement_place_furnace": 1.8823529411764706, "train_stats/max_log_achievement_place_plant": 1.411764705882353, "train_stats/max_log_achievement_place_stone": 4.382352941176471, "train_stats/max_log_achievement_place_table": 2.2941176470588234, "train_stats/max_log_achievement_wake_up": 2.235294117647059, "train_stats/mean_log_entropy": 0.48556766527540546, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 3.2545485737500712e-06, "report/cont_loss_std": 5.1014358177781105e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0003633255255408585, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 7.761839242448332e-07, "report/cont_pred": 0.9931658506393433, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 7.459183692932129, "report/dyn_loss_std": 9.120915412902832, "report/image_loss_mean": 3.2743778228759766, "report/image_loss_std": 9.36567497253418, "report/model_loss_mean": 7.811403274536133, "report/model_loss_std": 13.671013832092285, "report/post_ent_mag": 58.88037872314453, "report/post_ent_max": 58.88037872314453, "report/post_ent_mean": 41.9670295715332, "report/post_ent_min": 21.2147159576416, "report/post_ent_std": 6.693846702575684, "report/prior_ent_mag": 76.19644165039062, "report/prior_ent_max": 76.19644165039062, "report/prior_ent_mean": 49.740535736083984, "report/prior_ent_min": 32.88751220703125, "report/prior_ent_std": 7.080300807952881, "report/rep_loss_mean": 7.459183692932129, "report/rep_loss_std": 9.120915412902832, "report/reward_avg": 0.04746093600988388, "report/reward_loss_mean": 0.061512209475040436, "report/reward_loss_std": 0.19433444738388062, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0157346725463867, "report/reward_neg_acc": 0.9938080906867981, "report/reward_neg_loss": 0.02680071070790291, "report/reward_pos_acc": 0.9999999403953552, "report/reward_pos_loss": 0.6730656623840332, "report/reward_pred": 0.04799605906009674, "report/reward_rate": 0.0537109375, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.0002440089883748442, "eval/cont_loss_std": 0.00547442864626646, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.04142886400222778, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.2691851907220553e-06, "eval/cont_pred": 0.994367778301239, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 20.349090576171875, "eval/dyn_loss_std": 12.615476608276367, "eval/image_loss_mean": 22.062969207763672, "eval/image_loss_std": 21.91719627380371, "eval/model_loss_mean": 34.47319030761719, "eval/model_loss_std": 26.625715255737305, "eval/post_ent_mag": 57.803016662597656, "eval/post_ent_max": 57.803016662597656, "eval/post_ent_mean": 39.8062629699707, "eval/post_ent_min": 20.599365234375, "eval/post_ent_std": 6.76407527923584, "eval/prior_ent_mag": 76.19644165039062, "eval/prior_ent_max": 76.19644165039062, "eval/prior_ent_mean": 52.83081817626953, "eval/prior_ent_min": 34.33433532714844, "eval/prior_ent_std": 6.668014049530029, "eval/rep_loss_mean": 20.349090576171875, "eval/rep_loss_std": 12.615476608276367, "eval/reward_avg": 0.03896484524011612, "eval/reward_loss_mean": 0.20052418112754822, "eval/reward_loss_std": 1.0483776330947876, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.000903606414795, "eval/reward_neg_acc": 0.9918116331100464, "eval/reward_neg_loss": 0.09755436331033707, "eval/reward_pos_acc": 0.7659574151039124, "eval/reward_pos_loss": 2.3409814834594727, "eval/reward_pred": 0.032357268035411835, "eval/reward_rate": 0.0458984375, "replay/size": 578777.0, "replay/inserts": 8140.0, "replay/samples": 32560.0, "replay/insert_wait_avg": 1.5258203267465351e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.450800270061821e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 8.940696716308594e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2357442378998, "timer/env.step_count": 1018.0, "timer/env.step_total": 78.44236612319946, "timer/env.step_frac": 0.07842387814581284, "timer/env.step_avg": 0.07705536947269102, "timer/env.step_min": 0.02322077751159668, "timer/env.step_max": 2.027977228164673, "timer/replay._sample_count": 32560.0, "timer/replay._sample_total": 16.0405113697052, "timer/replay._sample_frac": 0.016036730802823685, "timer/replay._sample_avg": 0.000492644698086769, "timer/replay._sample_min": 0.0003714561462402344, "timer/replay._sample_max": 0.010452747344970703, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1018.0, "timer/agent.policy_total": 16.30892825126648, "timer/agent.policy_frac": 0.016305084421565627, "timer/agent.policy_avg": 0.01602055820360165, "timer/agent.policy_min": 0.009891986846923828, "timer/agent.policy_max": 0.07289004325866699, "timer/dataset_train_count": 2035.0, "timer/dataset_train_total": 0.3052237033843994, "timer/dataset_train_frac": 0.00030515176561397096, "timer/dataset_train_avg": 0.0001499870778301717, "timer/dataset_train_min": 9.274482727050781e-05, "timer/dataset_train_max": 0.0005893707275390625, "timer/agent.train_count": 2035.0, "timer/agent.train_total": 902.2414956092834, "timer/agent.train_frac": 0.9020288475060645, "timer/agent.train_avg": 0.4433619143043162, "timer/agent.train_min": 0.43234705924987793, "timer/agent.train_max": 1.0135657787322998, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4714641571044922, "timer/agent.report_frac": 0.0004713530383416866, "timer/agent.report_avg": 0.2357320785522461, "timer/agent.report_min": 0.23042058944702148, "timer/agent.report_max": 0.2410435676574707, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.765655517578125e-05, "timer/dataset_eval_frac": 2.765003683891876e-08, "timer/dataset_eval_avg": 2.765655517578125e-05, "timer/dataset_eval_min": 2.765655517578125e-05, "timer/dataset_eval_max": 2.765655517578125e-05, "fps": 8.137968113717644}
{"step": 579360, "time": 74372.55617928505, "episode/length": 183.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 579520, "time": 74392.68489456177, "episode/length": 174.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 579768, "time": 74422.91313648224, "episode/length": 416.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9952038369304557, "episode/intrinsic_return": 0.0}
{"step": 579936, "time": 74443.9177415371, "episode/length": 51.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9230769230769231, "episode/intrinsic_return": 0.0}
{"step": 580008, "time": 74469.57583522797, "eval_episode/length": 81.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9390243902439024}
{"step": 580008, "time": 74471.8712182045, "eval_episode/length": 98.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9393939393939394}
{"step": 580008, "time": 74476.64853906631, "eval_episode/length": 180.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9613259668508287}
{"step": 580008, "time": 74479.08195924759, "eval_episode/length": 202.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9655172413793104}
{"step": 580008, "time": 74480.83162736893, "eval_episode/length": 207.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9951923076923077}
{"step": 580008, "time": 74480.8390071392, "eval_episode/length": 207.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9759615384615384}
{"step": 580008, "time": 74484.73805141449, "eval_episode/length": 226.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9779735682819384}
{"step": 580008, "time": 74488.73166394234, "eval_episode/length": 87.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9431818181818182}
{"step": 580176, "time": 74508.3157582283, "episode/length": 183.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 580808, "time": 74583.45566630363, "episode/length": 239.0, "episode/score": 8.1000000461936, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 580856, "time": 74590.6936454773, "episode/length": 201.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 580944, "time": 74602.44102478027, "episode/length": 373.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9919786096256684, "episode/intrinsic_return": 0.0}
{"step": 581032, "time": 74614.09275269508, "episode/length": 136.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9635036496350365, "episode/intrinsic_return": 0.0}
{"step": 581072, "time": 74620.39071726799, "episode/length": 213.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 581424, "time": 74662.92402935028, "episode/length": 430.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9791183294663574, "episode/intrinsic_return": 0.0}
{"step": 581536, "time": 74677.40985441208, "episode/length": 220.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 581800, "time": 74710.91759300232, "episode/length": 117.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9915254237288136, "episode/intrinsic_return": 0.0}
{"step": 581840, "time": 74717.00175023079, "episode/length": 128.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9922480620155039, "episode/intrinsic_return": 0.0}
{"step": 582144, "time": 74753.71483302116, "episode/length": 133.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9925373134328358, "episode/intrinsic_return": 0.0}
{"step": 582416, "time": 74786.76797175407, "episode/length": 279.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9785714285714285, "episode/intrinsic_return": 0.0}
{"step": 582768, "time": 74829.15163755417, "episode/length": 115.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9568965517241379, "episode/intrinsic_return": 0.0}
{"step": 582776, "time": 74831.67376375198, "episode/length": 217.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.963302752293578, "episode/intrinsic_return": 0.0}
{"step": 582952, "time": 74853.5632455349, "episode/length": 250.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9960159362549801, "episode/intrinsic_return": 0.0}
{"step": 583056, "time": 74867.13919973373, "episode/length": 189.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 583152, "time": 74879.88791060448, "episode/length": 125.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9920634920634921, "episode/intrinsic_return": 0.0}
{"step": 583240, "time": 74892.35775113106, "episode/length": 179.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 583280, "time": 74899.13950967789, "episode/length": 231.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9698275862068966, "episode/intrinsic_return": 0.0}
{"step": 583656, "time": 74944.6422483921, "episode/length": 154.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9548387096774194, "episode/intrinsic_return": 0.0}
{"step": 583952, "time": 74980.5854921341, "episode/length": 83.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9880952380952381, "episode/intrinsic_return": 0.0}
{"step": 584160, "time": 75006.17468905449, "episode/length": 173.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 584352, "time": 75029.855001688, "episode/length": 149.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 584440, "time": 75041.67660021782, "episode/length": 185.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 584504, "time": 75050.57919239998, "episode/length": 157.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 584520, "time": 75054.02947974205, "episode/length": 217.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 584680, "time": 75074.1463367939, "episode/length": 202.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 584904, "time": 75102.17763829231, "episode/length": 155.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 585712, "time": 75197.66095972061, "episode/length": 193.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9639175257731959, "episode/intrinsic_return": 0.0}
{"step": 585720, "time": 75200.45308732986, "episode/length": 159.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 585824, "time": 75214.71217775345, "episode/length": 183.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 585896, "time": 75225.05190753937, "episode/length": 173.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 586040, "time": 75243.26823234558, "episode/length": 260.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9961685823754789, "episode/intrinsic_return": 0.0}
{"step": 586168, "time": 75259.57434797287, "episode/length": 205.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 586248, "time": 75270.35694169998, "episode/length": 195.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 586568, "time": 75309.10029125214, "episode/length": 207.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 587017, "time": 75363.78923249245, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.407363180051814, "train/action_min": 0.0, "train/action_std": 3.049077958022992, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04358619091540112, "train/actor_opt_grad_steps": 145400.0, "train/actor_opt_loss": -10.440185281858234, "train/adv_mag": 0.4633847862636487, "train/adv_max": 0.4217856639098627, "train/adv_mean": 0.0030236721323699902, "train/adv_min": -0.3981008518081873, "train/adv_std": 0.05515865433401394, "train/cont_avg": 0.9946364961139896, "train/cont_loss_mean": 0.0001180223286648265, "train/cont_loss_std": 0.0035559204287570877, "train/cont_neg_acc": 0.9947854671627283, "train/cont_neg_loss": 0.016491486976477177, "train/cont_pos_acc": 0.9999999808523939, "train/cont_pos_loss": 1.9349985123908294e-05, "train/cont_pred": 0.9946470266796764, "train/cont_rate": 0.9946364961139896, "train/dyn_loss_mean": 6.984863713615299, "train/dyn_loss_std": 8.969504885105271, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.105564916689779, "train/extr_critic_critic_opt_grad_steps": 145400.0, "train/extr_critic_critic_opt_loss": 17029.076854962757, "train/extr_critic_mag": 8.983040661391817, "train/extr_critic_max": 8.983040661391817, "train/extr_critic_mean": 1.9987496230268726, "train/extr_critic_min": -0.5576543826513339, "train/extr_critic_std": 2.118156562197394, "train/extr_return_normed_mag": 1.516388986394813, "train/extr_return_normed_max": 1.516388986394813, "train/extr_return_normed_mean": 0.3368391254096451, "train/extr_return_normed_min": -0.09633835804663174, "train/extr_return_normed_std": 0.32490986601058686, "train/extr_return_rate": 0.6622247753056838, "train/extr_return_raw_mag": 9.839670270218132, "train/extr_return_raw_max": 9.839670270218132, "train/extr_return_raw_mean": 2.0187839275814707, "train/extr_return_raw_min": -0.8532352473760516, "train/extr_return_raw_std": 2.1543371411802856, "train/extr_reward_mag": 1.0492661209304097, "train/extr_reward_max": 1.0492661209304097, "train/extr_reward_mean": 0.04558981213853767, "train/extr_reward_min": -0.6791244776137753, "train/extr_reward_std": 0.20869521873911429, "train/image_loss_mean": 3.791051133309004, "train/image_loss_std": 8.698717737444943, "train/model_loss_mean": 8.034037073659155, "train/model_loss_std": 12.878818398312584, "train/model_opt_grad_norm": 36.85901938818897, "train/model_opt_grad_steps": 145276.3730569948, "train/model_opt_loss": 11982.48365902283, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1489.6373056994819, "train/policy_entropy_mag": 2.6345770099620127, "train/policy_entropy_max": 2.6345770099620127, "train/policy_entropy_mean": 0.45869268608216796, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.645223107208242, "train/policy_logprob_mag": 7.438384164800298, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.45856771413526387, "train/policy_logprob_min": -7.438384164800298, "train/policy_logprob_std": 1.0723043179882623, "train/policy_randomness_mag": 0.9298900699368413, "train/policy_randomness_max": 0.9298900699368413, "train/policy_randomness_mean": 0.16189838980609272, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.22773544335921195, "train/post_ent_mag": 59.42911563141976, "train/post_ent_max": 59.42911563141976, "train/post_ent_mean": 42.94318006446324, "train/post_ent_min": 19.826283247359676, "train/post_ent_std": 6.881903008475822, "train/prior_ent_mag": 75.92697447939858, "train/prior_ent_max": 75.92697447939858, "train/prior_ent_mean": 49.954511237268, "train/prior_ent_min": 29.979888659067104, "train/prior_ent_std": 7.399774492095789, "train/rep_loss_mean": 6.984863713615299, "train/rep_loss_std": 8.969504885105271, "train/reward_avg": 0.0344154791028234, "train/reward_loss_mean": 0.05194970818690068, "train/reward_loss_std": 0.20778826118442062, "train/reward_max_data": 1.0160621799953242, "train/reward_max_pred": 1.0154432194220588, "train/reward_neg_acc": 0.9943815701366089, "train/reward_neg_loss": 0.023838706415899368, "train/reward_pos_acc": 0.9873526235318555, "train/reward_pos_loss": 0.7417697196179721, "train/reward_pred": 0.03405183259339839, "train/reward_rate": 0.0391839378238342, "train_stats/sum_log_reward": 8.800000190734863, "train_stats/max_log_achievement_collect_coal": 0.675, "train_stats/max_log_achievement_collect_drink": 4.2, "train_stats/max_log_achievement_collect_sapling": 1.475, "train_stats/max_log_achievement_collect_stone": 11.7, "train_stats/max_log_achievement_collect_wood": 6.0, "train_stats/max_log_achievement_defeat_skeleton": 0.05, "train_stats/max_log_achievement_defeat_zombie": 0.25, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.3, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_furnace": 1.65, "train_stats/max_log_achievement_place_plant": 1.375, "train_stats/max_log_achievement_place_stone": 3.7, "train_stats/max_log_achievement_place_table": 2.075, "train_stats/max_log_achievement_wake_up": 2.15, "train_stats/mean_log_entropy": 0.39842516705393793, "eval_stats/sum_log_reward": 8.725000023841858, "eval_stats/max_log_achievement_collect_coal": 1.125, "eval_stats/max_log_achievement_collect_drink": 1.25, "eval_stats/max_log_achievement_collect_sapling": 1.125, "eval_stats/max_log_achievement_collect_stone": 14.0, "eval_stats/max_log_achievement_collect_wood": 4.375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.375, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 2.125, "eval_stats/max_log_achievement_place_plant": 1.125, "eval_stats/max_log_achievement_place_stone": 3.875, "eval_stats/max_log_achievement_place_table": 1.5, "eval_stats/max_log_achievement_wake_up": 1.5, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 8.032782716327347e-06, "report/cont_loss_std": 0.0002357221528654918, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.6560190488235094e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 7.990940503077582e-06, "report/cont_pred": 0.9951093792915344, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 6.1638641357421875, "report/dyn_loss_std": 8.477123260498047, "report/image_loss_mean": 2.6554408073425293, "report/image_loss_std": 6.151516437530518, "report/model_loss_mean": 6.407279014587402, "report/model_loss_std": 10.28789234161377, "report/post_ent_mag": 57.6508674621582, "report/post_ent_max": 57.6508674621582, "report/post_ent_mean": 43.530452728271484, "report/post_ent_min": 20.885988235473633, "report/post_ent_std": 6.606442928314209, "report/prior_ent_mag": 76.0202865600586, "report/prior_ent_max": 76.0202865600586, "report/prior_ent_mean": 49.704185485839844, "report/prior_ent_min": 32.760826110839844, "report/prior_ent_std": 6.540258407592773, "report/rep_loss_mean": 6.1638641357421875, "report/rep_loss_std": 8.477123260498047, "report/reward_avg": 0.02900390699505806, "report/reward_loss_mean": 0.05351182445883751, "report/reward_loss_std": 0.2557887136936188, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0012128353118896, "report/reward_neg_acc": 0.9959554076194763, "report/reward_neg_loss": 0.025275152176618576, "report/reward_pos_acc": 0.9714285731315613, "report/reward_pos_loss": 0.851399302482605, "report/reward_pred": 0.02788299135863781, "report/reward_rate": 0.0341796875, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.0013125560944899917, "eval/cont_loss_std": 0.04182588309049606, "eval/cont_neg_acc": 0.75, "eval/cont_neg_loss": 0.33505958318710327, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 3.7443610381160397e-06, "eval/cont_pred": 0.9968118667602539, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 18.920907974243164, "eval/dyn_loss_std": 13.079435348510742, "eval/image_loss_mean": 17.427326202392578, "eval/image_loss_std": 24.321802139282227, "eval/model_loss_mean": 29.021181106567383, "eval/model_loss_std": 29.06144905090332, "eval/post_ent_mag": 57.42530059814453, "eval/post_ent_max": 57.42530059814453, "eval/post_ent_mean": 40.15525436401367, "eval/post_ent_min": 21.077125549316406, "eval/post_ent_std": 6.683619976043701, "eval/prior_ent_mag": 76.0202865600586, "eval/prior_ent_max": 76.0202865600586, "eval/prior_ent_mean": 51.87098693847656, "eval/prior_ent_min": 34.876712799072266, "eval/prior_ent_std": 6.6043782234191895, "eval/rep_loss_mean": 18.920907974243164, "eval/rep_loss_std": 13.079435348510742, "eval/reward_avg": 0.05410156399011612, "eval/reward_loss_mean": 0.23999592661857605, "eval/reward_loss_std": 1.1966562271118164, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.0024065971374512, "eval/reward_neg_acc": 0.9854922890663147, "eval/reward_neg_loss": 0.10932277888059616, "eval/reward_pos_acc": 0.7457627058029175, "eval/reward_pos_loss": 2.377277374267578, "eval/reward_pred": 0.04672102630138397, "eval/reward_rate": 0.0576171875, "replay/size": 586513.0, "replay/inserts": 7736.0, "replay/samples": 30944.0, "replay/insert_wait_avg": 1.5091933040362479e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.501817785103294e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 2328.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1687426222968348e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.08970832824707e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2576172351837, "timer/env.step_count": 967.0, "timer/env.step_total": 89.0788996219635, "timer/env.step_frac": 0.08905595727247433, "timer/env.step_avg": 0.0921188207052363, "timer/env.step_min": 0.0235445499420166, "timer/env.step_max": 2.083672046661377, "timer/replay._sample_count": 30944.0, "timer/replay._sample_total": 15.28631067276001, "timer/replay._sample_frac": 0.015282373669908124, "timer/replay._sample_avg": 0.0004939991815137025, "timer/replay._sample_min": 0.0004088878631591797, "timer/replay._sample_max": 0.031346797943115234, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1258.0, "timer/agent.policy_total": 19.84782361984253, "timer/agent.policy_frac": 0.01984271179529128, "timer/agent.policy_avg": 0.015777284276504395, "timer/agent.policy_min": 0.009537458419799805, "timer/agent.policy_max": 0.06635642051696777, "timer/dataset_train_count": 1934.0, "timer/dataset_train_total": 0.4082939624786377, "timer/dataset_train_frac": 0.00040818880600700124, "timer/dataset_train_avg": 0.0002111137344770619, "timer/dataset_train_min": 9.036064147949219e-05, "timer/dataset_train_max": 0.11423563957214355, "timer/agent.train_count": 1934.0, "timer/agent.train_total": 857.6132686138153, "timer/agent.train_frac": 0.8573923895569501, "timer/agent.train_avg": 0.4434401595728104, "timer/agent.train_min": 0.42714500427246094, "timer/agent.train_max": 0.9721865653991699, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.476917028427124, "timer/agent.report_frac": 0.00047679419802407744, "timer/agent.report_avg": 0.238458514213562, "timer/agent.report_min": 0.23185253143310547, "timer/agent.report_max": 0.24506449699401855, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.6226043701171875e-05, "timer/dataset_eval_frac": 2.621928916038989e-08, "timer/dataset_eval_avg": 2.6226043701171875e-05, "timer/dataset_eval_min": 2.6226043701171875e-05, "timer/dataset_eval_max": 2.6226043701171875e-05, "fps": 7.733901672023599}
{"step": 587032, "time": 75365.42729258537, "episode/length": 141.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 587152, "time": 75381.01270771027, "episode/length": 165.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 587248, "time": 75393.59121608734, "episode/length": 191.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 587328, "time": 75404.36841082573, "episode/length": 200.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 587688, "time": 75447.3936867714, "episode/length": 205.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 587768, "time": 75458.15667319298, "episode/length": 199.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.97, "episode/intrinsic_return": 0.0}
{"step": 588024, "time": 75489.4217865467, "episode/length": 181.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 588064, "time": 75495.62298130989, "episode/length": 226.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.973568281938326, "episode/intrinsic_return": 0.0}
{"step": 588304, "time": 75525.09161114693, "episode/length": 143.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 588400, "time": 75537.80448532104, "episode/length": 143.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 588456, "time": 75545.78879857063, "episode/length": 177.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9662921348314607, "episode/intrinsic_return": 0.0}
{"step": 588488, "time": 75551.14859724045, "episode/length": 89.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9888888888888889, "episode/intrinsic_return": 0.0}
{"step": 588904, "time": 75600.79681706429, "episode/length": 196.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 589008, "time": 75614.38733959198, "episode/length": 164.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9636363636363636, "episode/intrinsic_return": 0.0}
{"step": 589624, "time": 75687.2892677784, "episode/length": 141.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 589696, "time": 75697.20372319221, "episode/length": 154.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 589784, "time": 75709.00983691216, "episode/length": 219.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 589792, "time": 75711.58558702469, "episode/length": 173.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 590048, "time": 75744.11091303825, "episode/length": 247.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 590096, "time": 75767.18100094795, "eval_episode/length": 60.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.9344262295081968}
{"step": 590096, "time": 75772.62292957306, "eval_episode/length": 158.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9685534591194969}
{"step": 590096, "time": 75774.23104310036, "eval_episode/length": 160.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9937888198757764}
{"step": 590096, "time": 75775.93532681465, "eval_episode/length": 163.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9695121951219512}
{"step": 590096, "time": 75778.70872330666, "eval_episode/length": 190.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9738219895287958}
{"step": 590096, "time": 75780.31747984886, "eval_episode/length": 194.0, "eval_episode/score": 10.100000016391277, "eval_episode/reward_rate": 0.9948717948717949}
{"step": 590096, "time": 75782.19638442993, "eval_episode/length": 43.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9772727272727273}
{"step": 590096, "time": 75784.64036297798, "eval_episode/length": 166.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9760479041916168}
{"step": 590136, "time": 75789.3507835865, "episode/length": 153.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 590520, "time": 75836.02102208138, "episode/length": 90.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9560439560439561, "episode/intrinsic_return": 0.0}
{"step": 590704, "time": 75858.84249711037, "episode/length": 114.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.991304347826087, "episode/intrinsic_return": 0.0}
{"step": 591136, "time": 75910.67987179756, "episode/length": 265.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9887218045112782, "episode/intrinsic_return": 0.0}
{"step": 591184, "time": 75917.69244670868, "episode/length": 359.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9916666666666667, "episode/intrinsic_return": 0.0}
{"step": 591368, "time": 75940.61679077148, "episode/length": 208.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 591760, "time": 75987.54774308205, "episode/length": 202.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 591832, "time": 75997.40102219582, "episode/length": 275.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.967391304347826, "episode/intrinsic_return": 0.0}
{"step": 591912, "time": 76008.14289522171, "episode/length": 173.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 591976, "time": 76017.08713173866, "episode/length": 158.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9622641509433962, "episode/intrinsic_return": 0.0}
{"step": 592272, "time": 76053.06334066391, "episode/length": 277.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9964028776978417, "episode/intrinsic_return": 0.0}
{"step": 592536, "time": 76085.32088947296, "episode/length": 168.0, "episode/score": 10.099999964237213, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 592544, "time": 76087.75474405289, "episode/length": 175.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 592928, "time": 76133.83795285225, "episode/length": 48.0, "episode/score": 1.0999999940395355, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 593216, "time": 76168.84083771706, "episode/length": 181.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 593432, "time": 76195.59681010246, "episode/length": 199.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 593568, "time": 76213.07052111626, "episode/length": 127.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9921875, "episode/intrinsic_return": 0.0}
{"step": 593672, "time": 76226.63779139519, "episode/length": 174.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 593744, "time": 76236.50343370438, "episode/length": 220.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9728506787330317, "episode/intrinsic_return": 0.0}
{"step": 593944, "time": 76261.31062364578, "episode/length": 253.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.984251968503937, "episode/intrinsic_return": 0.0}
{"step": 594488, "time": 76325.86058139801, "episode/length": 389.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 594797, "time": 76364.24277353287, "train_stats/sum_log_reward": 8.425000241398811, "train_stats/max_log_achievement_collect_coal": 0.575, "train_stats/max_log_achievement_collect_drink": 3.65, "train_stats/max_log_achievement_collect_sapling": 1.2, "train_stats/max_log_achievement_collect_stone": 11.4, "train_stats/max_log_achievement_collect_wood": 5.875, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.275, "train_stats/max_log_achievement_eat_cow": 0.05, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.2, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_furnace": 1.4, "train_stats/max_log_achievement_place_plant": 1.1, "train_stats/max_log_achievement_place_stone": 3.975, "train_stats/max_log_achievement_place_table": 2.025, "train_stats/max_log_achievement_wake_up": 1.875, "train_stats/mean_log_entropy": 0.42023227736353874, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.504605493790064, "train/action_min": 0.0, "train/action_std": 3.2001777037596093, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.043817723332307275, "train/actor_opt_grad_steps": 147340.0, "train/actor_opt_loss": -11.854909694997163, "train/adv_mag": 0.46468725479566136, "train/adv_max": 0.419660063737478, "train/adv_mean": 0.0025397040856403644, "train/adv_min": -0.3917351676867558, "train/adv_std": 0.05514384276973896, "train/cont_avg": 0.9946614583333333, "train/cont_loss_mean": 0.00017139152375657081, "train/cont_loss_std": 0.005003965029465153, "train/cont_neg_acc": 0.9960052915108509, "train/cont_neg_loss": 0.02100818225243739, "train/cont_pos_acc": 0.999989887384268, "train/cont_pos_loss": 2.8625848429806538e-05, "train/cont_pred": 0.9946738157516871, "train/cont_rate": 0.9946614583333333, "train/dyn_loss_mean": 6.942264339251396, "train/dyn_loss_std": 8.937078647124462, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0683994788389939, "train/extr_critic_critic_opt_grad_steps": 147340.0, "train/extr_critic_critic_opt_loss": 16977.802514022434, "train/extr_critic_mag": 8.98524988125532, "train/extr_critic_max": 8.98524988125532, "train/extr_critic_mean": 2.027244001168471, "train/extr_critic_min": -0.6008720660820985, "train/extr_critic_std": 2.1147516158910897, "train/extr_return_normed_mag": 1.5240711817374597, "train/extr_return_normed_max": 1.5240711817374597, "train/extr_return_normed_mean": 0.3447195297632462, "train/extr_return_normed_min": -0.10675198091910436, "train/extr_return_normed_std": 0.3252683277313526, "train/extr_return_rate": 0.6718984044515169, "train/extr_return_raw_mag": 9.843267973875388, "train/extr_return_raw_max": 9.843267973875388, "train/extr_return_raw_mean": 2.044021981801742, "train/extr_return_raw_min": -0.9414924065272013, "train/extr_return_raw_std": 2.15083055129418, "train/extr_reward_mag": 1.0502035862360246, "train/extr_reward_max": 1.0502035862360246, "train/extr_reward_mean": 0.046197847735423306, "train/extr_reward_min": -0.717423310646644, "train/extr_reward_std": 0.2102770297955244, "train/image_loss_mean": 3.6610622295966517, "train/image_loss_std": 8.676245805544731, "train/model_loss_mean": 7.878566387372139, "train/model_loss_std": 12.820639209258252, "train/model_opt_grad_norm": 38.906135175645964, "train/model_opt_grad_steps": 147215.06666666668, "train/model_opt_loss": 14647.8474609375, "train/model_opt_model_opt_grad_overflow": 0.005128205128205128, "train/model_opt_model_opt_grad_scale": 1852.5641025641025, "train/policy_entropy_mag": 2.6297146662687645, "train/policy_entropy_max": 2.6297146662687645, "train/policy_entropy_mean": 0.4777870379961454, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6714561292758354, "train/policy_logprob_mag": 7.438384146568103, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.4777723909952702, "train/policy_logprob_min": -7.438384146568103, "train/policy_logprob_std": 1.0848929661970872, "train/policy_randomness_mag": 0.9281738745860565, "train/policy_randomness_max": 0.9281738745860565, "train/policy_randomness_mean": 0.1686378572613765, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.23699454519993218, "train/post_ent_mag": 59.26695973322942, "train/post_ent_max": 59.26695973322942, "train/post_ent_mean": 42.901568916516425, "train/post_ent_min": 19.63596422244341, "train/post_ent_std": 6.884916036556929, "train/prior_ent_mag": 75.93836763822115, "train/prior_ent_max": 75.93836763822115, "train/prior_ent_mean": 49.90932104648688, "train/prior_ent_min": 29.687906773885093, "train/prior_ent_std": 7.365985246805044, "train/rep_loss_mean": 6.942264339251396, "train/rep_loss_std": 8.937078647124462, "train/reward_avg": 0.034868790042132905, "train/reward_loss_mean": 0.051974122875776047, "train/reward_loss_std": 0.21310967222238197, "train/reward_max_data": 1.0169230809578529, "train/reward_max_pred": 1.0177077085543902, "train/reward_neg_acc": 0.9945500826224303, "train/reward_neg_loss": 0.023585640132809296, "train/reward_pos_acc": 0.9866705882243622, "train/reward_pos_loss": 0.7417443513870239, "train/reward_pred": 0.03455337128864649, "train/reward_rate": 0.0396484375, "eval_stats/sum_log_reward": 7.4750001430511475, "eval_stats/max_log_achievement_collect_coal": 0.375, "eval_stats/max_log_achievement_collect_drink": 2.625, "eval_stats/max_log_achievement_collect_sapling": 1.5, "eval_stats/max_log_achievement_collect_stone": 3.75, "eval_stats/max_log_achievement_collect_wood": 4.75, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.25, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.5, "eval_stats/max_log_achievement_place_plant": 1.5, "eval_stats/max_log_achievement_place_stone": 1.0, "eval_stats/max_log_achievement_place_table": 1.625, "eval_stats/max_log_achievement_wake_up": 1.375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 9.376019534101943e-07, "report/cont_loss_std": 1.3106396181683522e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00015441558207385242, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 4.866382710133621e-07, "report/cont_pred": 0.9970703125, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 7.441474437713623, "report/dyn_loss_std": 8.826371192932129, "report/image_loss_mean": 3.226285934448242, "report/image_loss_std": 6.286169052124023, "report/model_loss_mean": 7.751872539520264, "report/model_loss_std": 10.399346351623535, "report/post_ent_mag": 60.343162536621094, "report/post_ent_max": 60.343162536621094, "report/post_ent_mean": 42.62106704711914, "report/post_ent_min": 19.97856903076172, "report/post_ent_std": 6.9771904945373535, "report/prior_ent_mag": 75.81930541992188, "report/prior_ent_max": 75.81930541992188, "report/prior_ent_mean": 50.29607391357422, "report/prior_ent_min": 31.789209365844727, "report/prior_ent_std": 6.850886344909668, "report/rep_loss_mean": 7.441474437713623, "report/rep_loss_std": 8.826371192932129, "report/reward_avg": 0.0400390625, "report/reward_loss_mean": 0.060700923204422, "report/reward_loss_std": 0.3368726074695587, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.1078441143035889, "report/reward_neg_acc": 0.9979612231254578, "report/reward_neg_loss": 0.026530541479587555, "report/reward_pos_acc": 0.9534883499145508, "report/reward_pos_loss": 0.8402624130249023, "report/reward_pred": 0.03775591030716896, "report/reward_rate": 0.0419921875, "eval/cont_avg": 0.9931640625, "eval/cont_loss_mean": 3.37796300300397e-05, "eval/cont_loss_std": 0.0007185190916061401, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0016357508720830083, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 2.2753280063625425e-05, "eval/cont_pred": 0.9931528568267822, "eval/cont_rate": 0.9931640625, "eval/dyn_loss_mean": 19.99696922302246, "eval/dyn_loss_std": 12.714427947998047, "eval/image_loss_mean": 21.288360595703125, "eval/image_loss_std": 26.157737731933594, "eval/model_loss_mean": 33.454925537109375, "eval/model_loss_std": 30.79289436340332, "eval/post_ent_mag": 59.733646392822266, "eval/post_ent_max": 59.733646392822266, "eval/post_ent_mean": 40.14274597167969, "eval/post_ent_min": 22.05965805053711, "eval/post_ent_std": 7.390016555786133, "eval/prior_ent_mag": 75.81930541992188, "eval/prior_ent_max": 75.81930541992188, "eval/prior_ent_mean": 53.634765625, "eval/prior_ent_min": 38.069427490234375, "eval/prior_ent_std": 6.304067134857178, "eval/rep_loss_mean": 19.99696922302246, "eval/rep_loss_std": 12.714427947998047, "eval/reward_avg": 0.0419921875, "eval/reward_loss_mean": 0.16834843158721924, "eval/reward_loss_std": 0.8628920316696167, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0011982917785645, "eval/reward_neg_acc": 0.9928205013275146, "eval/reward_neg_loss": 0.06061834469437599, "eval/reward_pos_acc": 0.6938775181770325, "eval/reward_pos_loss": 2.3119571208953857, "eval/reward_pred": 0.030861159786581993, "eval/reward_rate": 0.0478515625, "replay/size": 594293.0, "replay/inserts": 7780.0, "replay/samples": 31120.0, "replay/insert_wait_avg": 1.5200256994879952e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.426907286852369e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 1824.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1229462790907474e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.387731552124023e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4399020671844, "timer/env.step_count": 972.0, "timer/env.step_total": 85.79707312583923, "timer/env.step_frac": 0.08575934741163246, "timer/env.step_avg": 0.0882685937508634, "timer/env.step_min": 0.023283004760742188, "timer/env.step_max": 2.195919990539551, "timer/replay._sample_count": 31120.0, "timer/replay._sample_total": 15.42590594291687, "timer/replay._sample_frac": 0.015419123038817923, "timer/replay._sample_avg": 0.0004956910650037555, "timer/replay._sample_min": 0.0003902912139892578, "timer/replay._sample_max": 0.02678394317626953, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1200.0, "timer/agent.policy_total": 20.694544792175293, "timer/agent.policy_frac": 0.020685445222061477, "timer/agent.policy_avg": 0.01724545399347941, "timer/agent.policy_min": 0.00962376594543457, "timer/agent.policy_max": 0.10978269577026367, "timer/dataset_train_count": 1945.0, "timer/dataset_train_total": 0.28195738792419434, "timer/dataset_train_frac": 0.0002818334088250506, "timer/dataset_train_avg": 0.00014496523800729786, "timer/dataset_train_min": 9.036064147949219e-05, "timer/dataset_train_max": 0.0012056827545166016, "timer/agent.train_count": 1945.0, "timer/agent.train_total": 862.2433552742004, "timer/agent.train_frac": 0.8618642194224442, "timer/agent.train_avg": 0.4433127790612856, "timer/agent.train_min": 0.4331808090209961, "timer/agent.train_max": 0.9418356418609619, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4775254726409912, "timer/agent.report_frac": 0.00047731550056559323, "timer/agent.report_avg": 0.2387627363204956, "timer/agent.report_min": 0.23118185997009277, "timer/agent.report_max": 0.24634361267089844, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0040740966796875e-05, "timer/dataset_eval_frac": 3.002753179348847e-08, "timer/dataset_eval_avg": 3.0040740966796875e-05, "timer/dataset_eval_min": 3.0040740966796875e-05, "timer/dataset_eval_max": 3.0040740966796875e-05, "fps": 7.776462985523524}
{"step": 594992, "time": 76386.74849915504, "episode/length": 177.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 595088, "time": 76399.49007201195, "episode/length": 233.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 595824, "time": 76487.43043351173, "episode/length": 259.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 596152, "time": 76527.08083033562, "episode/length": 207.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 596432, "time": 76561.14622449875, "episode/length": 437.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 596440, "time": 76563.52846074104, "episode/length": 180.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 596856, "time": 76613.61349320412, "episode/length": 427.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9789719626168224, "episode/intrinsic_return": 0.0}
{"step": 597232, "time": 76658.66641688347, "episode/length": 444.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 597472, "time": 76688.07429361343, "episode/length": 440.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 597744, "time": 76721.35669970512, "episode/length": 331.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9879518072289156, "episode/intrinsic_return": 0.0}
{"step": 597784, "time": 76727.45332717896, "episode/length": 244.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 598008, "time": 76754.98127675056, "episode/length": 231.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 598128, "time": 76771.69322824478, "episode/length": 211.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9716981132075472, "episode/intrinsic_return": 0.0}
{"step": 598248, "time": 76787.23991179466, "episode/length": 173.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 599080, "time": 76885.43601536751, "episode/length": 329.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.990909090909091, "episode/intrinsic_return": 0.0}
{"step": 599232, "time": 76904.76892209053, "episode/length": 180.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9834254143646409, "episode/intrinsic_return": 0.0}
{"step": 599256, "time": 76909.20884609222, "episode/length": 140.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 599528, "time": 76942.4380466938, "episode/length": 159.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 599568, "time": 76948.55152821541, "episode/length": 261.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9770992366412213, "episode/intrinsic_return": 0.0}
{"step": 599600, "time": 76953.8019797802, "episode/length": 231.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 599840, "time": 76983.2069427967, "episode/length": 228.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 600064, "time": 77010.71319580078, "episode/length": 353.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 600080, "time": 77028.10598182678, "eval_episode/length": 35.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.8611111111111112}
{"step": 600080, "time": 77034.82399225235, "eval_episode/length": 163.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9695121951219512}
{"step": 600080, "time": 77036.72802758217, "eval_episode/length": 173.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9942528735632183}
{"step": 600080, "time": 77038.72181248665, "eval_episode/length": 184.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.972972972972973}
{"step": 600080, "time": 77042.29481124878, "eval_episode/length": 233.0, "eval_episode/score": 11.099999971687794, "eval_episode/reward_rate": 0.9957264957264957}
{"step": 600080, "time": 77044.79170060158, "eval_episode/length": 256.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9727626459143969}
{"step": 600080, "time": 77046.72336483002, "eval_episode/length": 230.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9956709956709957}
{"step": 600080, "time": 77049.3934314251, "eval_episode/length": 297.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9765100671140939}
{"step": 600120, "time": 77054.06653952599, "episode/length": 64.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9384615384615385, "episode/intrinsic_return": 0.0}
{"step": 600832, "time": 77138.24693727493, "episode/length": 218.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9817351598173516, "episode/intrinsic_return": 0.0}
{"step": 600888, "time": 77146.2777364254, "episode/length": 164.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 601040, "time": 77165.31905126572, "episode/length": 188.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 601192, "time": 77184.62415409088, "episode/length": 241.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9793388429752066, "episode/intrinsic_return": 0.0}
{"step": 601408, "time": 77211.81783938408, "episode/length": 271.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9963235294117647, "episode/intrinsic_return": 0.0}
{"step": 601408, "time": 77211.82485198975, "episode/length": 160.0, "episode/score": 11.100000016391277, "episode/reward_rate": 0.9813664596273292, "episode/intrinsic_return": 0.0}
{"step": 601432, "time": 77217.7380888462, "episode/length": 198.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9698492462311558, "episode/intrinsic_return": 0.0}
{"step": 602176, "time": 77306.06136131287, "episode/length": 263.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 602184, "time": 77308.46263217926, "episode/length": 168.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9526627218934911, "episode/intrinsic_return": 0.0}
{"step": 602440, "time": 77339.85054087639, "episode/length": 155.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 602472, "time": 77345.00661444664, "episode/length": 197.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 602617, "time": 77364.2839858532, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.55208020332532, "train/action_min": 0.0, "train/action_std": 3.2579259261106834, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04289224960674078, "train/actor_opt_grad_steps": 149290.0, "train/actor_opt_loss": -11.138708454103043, "train/adv_mag": 0.4343503155769446, "train/adv_max": 0.40720440378555883, "train/adv_mean": 0.0027035850891829446, "train/adv_min": -0.36468096925662113, "train/adv_std": 0.054069633113268095, "train/cont_avg": 0.9948918269230769, "train/cont_loss_mean": 0.00020541982428910207, "train/cont_loss_std": 0.006332764577703715, "train/cont_neg_acc": 0.9944788553775885, "train/cont_neg_loss": 0.020641128773861102, "train/cont_pos_acc": 0.9999898944145594, "train/cont_pos_loss": 6.862135657063945e-05, "train/cont_pred": 0.9949035580341633, "train/cont_rate": 0.9948918269230769, "train/dyn_loss_mean": 6.993618219326704, "train/dyn_loss_std": 8.972613486265525, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0618272720239101, "train/extr_critic_critic_opt_grad_steps": 149290.0, "train/extr_critic_critic_opt_loss": 16813.55331530449, "train/extr_critic_mag": 8.982098325093586, "train/extr_critic_max": 8.982098325093586, "train/extr_critic_mean": 1.9390529366639944, "train/extr_critic_min": -0.5504990149766971, "train/extr_critic_std": 2.105233499331352, "train/extr_return_normed_mag": 1.5241939312372452, "train/extr_return_normed_max": 1.5241939312372452, "train/extr_return_normed_mean": 0.3307775067977416, "train/extr_return_normed_min": -0.09711335740792446, "train/extr_return_normed_std": 0.32365552951128057, "train/extr_return_rate": 0.6480335544317196, "train/extr_return_raw_mag": 9.848488885928424, "train/extr_return_raw_max": 9.848488885928424, "train/extr_return_raw_mean": 1.9569348714290522, "train/extr_return_raw_min": -0.8725290232743972, "train/extr_return_raw_std": 2.140184360895401, "train/extr_reward_mag": 1.054462056282239, "train/extr_reward_max": 1.054462056282239, "train/extr_reward_mean": 0.04500859941427524, "train/extr_reward_min": -0.6886270247972929, "train/extr_reward_std": 0.20694084014648045, "train/image_loss_mean": 3.9189677580808984, "train/image_loss_std": 8.89068392484616, "train/model_loss_mean": 8.166603144621238, "train/model_loss_std": 13.02576900384365, "train/model_opt_grad_norm": 38.199202821193595, "train/model_opt_grad_steps": 149163.70769230768, "train/model_opt_loss": 11223.315857872596, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1378.2051282051282, "train/policy_entropy_mag": 2.6202247864160784, "train/policy_entropy_max": 2.6202247864160784, "train/policy_entropy_mean": 0.5140296031267215, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.7085139204294254, "train/policy_logprob_mag": 7.438384141677465, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5138578009911072, "train/policy_logprob_min": -7.438384141677465, "train/policy_logprob_std": 1.1097274838349758, "train/policy_randomness_mag": 0.9248243634517376, "train/policy_randomness_max": 0.9248243634517376, "train/policy_randomness_mean": 0.18142989247273175, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.25007432095515425, "train/post_ent_mag": 59.86726430257161, "train/post_ent_max": 59.86726430257161, "train/post_ent_mean": 43.153024213741986, "train/post_ent_min": 19.665787056164863, "train/post_ent_std": 6.914162704272148, "train/prior_ent_mag": 75.93882700602214, "train/prior_ent_max": 75.93882700602214, "train/prior_ent_mean": 50.17568838657477, "train/prior_ent_min": 30.089829635620116, "train/prior_ent_std": 7.36966272745377, "train/rep_loss_mean": 6.993618219326704, "train/rep_loss_std": 8.972613486265525, "train/reward_avg": 0.034016926877964766, "train/reward_loss_mean": 0.05125905187466206, "train/reward_loss_std": 0.21006453725007865, "train/reward_max_data": 1.022564107943804, "train/reward_max_pred": 1.0194807511109572, "train/reward_neg_acc": 0.99432707291383, "train/reward_neg_loss": 0.0236930688819251, "train/reward_pos_acc": 0.9873024561466315, "train/reward_pos_loss": 0.7398345381785661, "train/reward_pred": 0.03374190886433308, "train/reward_rate": 0.03858673878205128, "train_stats/sum_log_reward": 9.305882566115436, "train_stats/max_log_achievement_collect_coal": 0.8529411764705882, "train_stats/max_log_achievement_collect_drink": 5.382352941176471, "train_stats/max_log_achievement_collect_sapling": 1.3529411764705883, "train_stats/max_log_achievement_collect_stone": 13.411764705882353, "train_stats/max_log_achievement_collect_wood": 6.588235294117647, "train_stats/max_log_achievement_defeat_skeleton": 0.029411764705882353, "train_stats/max_log_achievement_defeat_zombie": 0.6176470588235294, "train_stats/max_log_achievement_eat_cow": 0.08823529411764706, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.029411764705882353, "train_stats/max_log_achievement_make_wood_pickaxe": 1.2941176470588236, "train_stats/max_log_achievement_make_wood_sword": 0.08823529411764706, "train_stats/max_log_achievement_place_furnace": 2.0, "train_stats/max_log_achievement_place_plant": 1.2941176470588236, "train_stats/max_log_achievement_place_stone": 3.823529411764706, "train_stats/max_log_achievement_place_table": 2.2941176470588234, "train_stats/max_log_achievement_wake_up": 2.5294117647058822, "train_stats/mean_log_entropy": 0.5172872639754239, "eval_stats/sum_log_reward": 8.350000143051147, "eval_stats/max_log_achievement_collect_coal": 0.5, "eval_stats/max_log_achievement_collect_drink": 2.875, "eval_stats/max_log_achievement_collect_sapling": 1.25, "eval_stats/max_log_achievement_collect_stone": 11.875, "eval_stats/max_log_achievement_collect_wood": 6.0, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.125, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.125, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.125, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 2.125, "eval_stats/max_log_achievement_place_plant": 1.125, "eval_stats/max_log_achievement_place_stone": 2.125, "eval_stats/max_log_achievement_place_table": 2.375, "eval_stats/max_log_achievement_wake_up": 1.625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 5.618319846689701e-06, "report/cont_loss_std": 9.413440420757979e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0005889247404411435, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 1.6034284726629267e-06, "report/cont_pred": 0.9931665658950806, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 7.5200419425964355, "report/dyn_loss_std": 9.078439712524414, "report/image_loss_mean": 3.7567849159240723, "report/image_loss_std": 7.897220134735107, "report/model_loss_mean": 8.326455116271973, "report/model_loss_std": 12.274518013000488, "report/post_ent_mag": 57.2959098815918, "report/post_ent_max": 57.2959098815918, "report/post_ent_mean": 42.37223815917969, "report/post_ent_min": 17.334280014038086, "report/post_ent_std": 6.482980728149414, "report/prior_ent_mag": 75.85208892822266, "report/prior_ent_max": 75.85208892822266, "report/prior_ent_mean": 50.074954986572266, "report/prior_ent_min": 30.692115783691406, "report/prior_ent_std": 7.112656593322754, "report/rep_loss_mean": 7.5200419425964355, "report/rep_loss_std": 9.078439712524414, "report/reward_avg": 0.03437500074505806, "report/reward_loss_mean": 0.05763956531882286, "report/reward_loss_std": 0.25756749510765076, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.1044468879699707, "report/reward_neg_acc": 0.9928862452507019, "report/reward_neg_loss": 0.027301687747240067, "report/reward_pos_acc": 0.949999988079071, "report/reward_pos_loss": 0.8039514422416687, "report/reward_pred": 0.03335088491439819, "report/reward_rate": 0.0390625, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 1.2362533198029269e-05, "eval/cont_loss_std": 0.0003003956808242947, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00960538350045681, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.9851903491362464e-06, "eval/cont_pred": 0.999029815196991, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 17.98717498779297, "eval/dyn_loss_std": 13.154365539550781, "eval/image_loss_mean": 15.609230041503906, "eval/image_loss_std": 18.490144729614258, "eval/model_loss_mean": 26.545001983642578, "eval/model_loss_std": 23.891292572021484, "eval/post_ent_mag": 61.640628814697266, "eval/post_ent_max": 61.640628814697266, "eval/post_ent_mean": 41.79053497314453, "eval/post_ent_min": 18.773160934448242, "eval/post_ent_std": 8.18603229522705, "eval/prior_ent_mag": 75.85208892822266, "eval/prior_ent_max": 75.85208892822266, "eval/prior_ent_mean": 53.72657775878906, "eval/prior_ent_min": 36.34442138671875, "eval/prior_ent_std": 7.036306858062744, "eval/rep_loss_mean": 17.98717498779297, "eval/rep_loss_std": 13.154365539550781, "eval/reward_avg": 0.04150390625, "eval/reward_loss_mean": 0.14345325529575348, "eval/reward_loss_std": 0.9767904877662659, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0006494522094727, "eval/reward_neg_acc": 0.991836667060852, "eval/reward_neg_loss": 0.023762857541441917, "eval/reward_pos_acc": 0.6818181872367859, "eval/reward_pos_loss": 2.8092849254608154, "eval/reward_pred": 0.031239982694387436, "eval/reward_rate": 0.04296875, "replay/size": 602113.0, "replay/inserts": 7820.0, "replay/samples": 31280.0, "replay/insert_wait_avg": 1.5427999179381543e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.50103874889481e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 2384.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1052861309691564e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.027202129364, "timer/env.step_count": 978.0, "timer/env.step_total": 77.50985932350159, "timer/env.step_frac": 0.0775077509476336, "timer/env.step_avg": 0.07925343489110592, "timer/env.step_min": 0.022844791412353516, "timer/env.step_max": 3.1730027198791504, "timer/replay._sample_count": 31280.0, "timer/replay._sample_total": 15.50840425491333, "timer/replay._sample_frac": 0.01550798240476978, "timer/replay._sample_avg": 0.0004957929749013213, "timer/replay._sample_min": 0.00037741661071777344, "timer/replay._sample_max": 0.0290985107421875, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1276.0, "timer/agent.policy_total": 20.31027126312256, "timer/agent.policy_frac": 0.020309718795524536, "timer/agent.policy_avg": 0.015917140488340562, "timer/agent.policy_min": 0.009338617324829102, "timer/agent.policy_max": 0.07676553726196289, "timer/dataset_train_count": 1955.0, "timer/dataset_train_total": 0.3522927761077881, "timer/dataset_train_frac": 0.0003522831932547924, "timer/dataset_train_avg": 0.00018020090849503226, "timer/dataset_train_min": 8.916854858398438e-05, "timer/dataset_train_max": 0.06522941589355469, "timer/agent.train_count": 1955.0, "timer/agent.train_total": 868.3510401248932, "timer/agent.train_frac": 0.8683274197700903, "timer/agent.train_avg": 0.44416932998715764, "timer/agent.train_min": 0.42536163330078125, "timer/agent.train_max": 0.9486019611358643, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47646403312683105, "timer/agent.report_frac": 0.0004764510726431174, "timer/agent.report_avg": 0.23823201656341553, "timer/agent.report_min": 0.2314155101776123, "timer/agent.report_max": 0.24504852294921875, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.6226043701171875e-05, "timer/dataset_eval_frac": 2.6225330316343996e-08, "timer/dataset_eval_avg": 2.6226043701171875e-05, "timer/dataset_eval_min": 2.6226043701171875e-05, "timer/dataset_eval_max": 2.6226043701171875e-05, "fps": 7.819678644569252}
{"step": 602832, "time": 77389.17912197113, "episode/length": 80.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9876543209876543, "episode/intrinsic_return": 0.0}
{"step": 602840, "time": 77391.6669793129, "episode/length": 175.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9659090909090909, "episode/intrinsic_return": 0.0}
{"step": 602848, "time": 77394.0463089943, "episode/length": 225.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9778761061946902, "episode/intrinsic_return": 0.0}
{"step": 602888, "time": 77400.26439762115, "episode/length": 184.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 603864, "time": 77515.65657520294, "episode/length": 306.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.996742671009772, "episode/intrinsic_return": 0.0}
{"step": 603912, "time": 77522.71987867355, "episode/length": 179.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 604048, "time": 77539.99695539474, "episode/length": 144.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 604096, "time": 77547.03756666183, "episode/length": 239.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 604104, "time": 77549.4400126934, "episode/length": 29.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 604288, "time": 77572.37809824944, "episode/length": 230.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9783549783549783, "episode/intrinsic_return": 0.0}
{"step": 604416, "time": 77588.66978693008, "episode/length": 38.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 605272, "time": 77690.20973396301, "episode/length": 169.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 605400, "time": 77706.64243292809, "episode/length": 168.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 605424, "time": 77711.12582564354, "episode/length": 323.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9969135802469136, "episode/intrinsic_return": 0.0}
{"step": 605864, "time": 77763.84332299232, "episode/length": 377.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9920634920634921, "episode/intrinsic_return": 0.0}
{"step": 605944, "time": 77774.75811362267, "episode/length": 230.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 605952, "time": 77777.12574625015, "episode/length": 207.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 606408, "time": 77832.7519440651, "episode/length": 444.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9797752808988764, "episode/intrinsic_return": 0.0}
{"step": 606680, "time": 77865.84910559654, "episode/length": 282.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9681978798586572, "episode/intrinsic_return": 0.0}
{"step": 606752, "time": 77875.60754823685, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 606784, "time": 77880.7436079979, "episode/length": 172.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 607248, "time": 77936.32005858421, "episode/length": 61.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9354838709677419, "episode/intrinsic_return": 0.0}
{"step": 607328, "time": 77947.1341574192, "episode/length": 237.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9789915966386554, "episode/intrinsic_return": 0.0}
{"step": 607408, "time": 77958.01793646812, "episode/length": 181.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.967032967032967, "episode/intrinsic_return": 0.0}
{"step": 607424, "time": 77961.32740616798, "episode/length": 194.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 607840, "time": 78011.09340953827, "episode/length": 236.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 608008, "time": 78032.18782734871, "episode/length": 165.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 608504, "time": 78091.77971887589, "episode/length": 261.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9961832061068703, "episode/intrinsic_return": 0.0}
{"step": 608784, "time": 78125.88810324669, "episode/length": 249.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.976, "episode/intrinsic_return": 0.0}
{"step": 608864, "time": 78136.66156029701, "episode/length": 191.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 608968, "time": 78150.17788028717, "episode/length": 192.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9896373056994818, "episode/intrinsic_return": 0.0}
{"step": 609008, "time": 78156.3549747467, "episode/length": 219.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 609072, "time": 78165.39703011513, "episode/length": 207.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 609224, "time": 78184.57201600075, "episode/length": 151.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 609384, "time": 78204.63804912567, "episode/length": 192.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 610032, "time": 78281.59730100632, "episode/length": 145.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9657534246575342, "episode/intrinsic_return": 0.0}
{"step": 610064, "time": 78302.51223373413, "eval_episode/length": 43.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.8863636363636364}
{"step": 610064, "time": 78305.29493260384, "eval_episode/length": 61.0, "eval_episode/score": 4.099999971687794, "eval_episode/reward_rate": 0.9838709677419355}
{"step": 610064, "time": 78312.06097960472, "eval_episode/length": 186.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9732620320855615}
{"step": 610064, "time": 78314.10023880005, "eval_episode/length": 138.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9568345323741008}
{"step": 610064, "time": 78316.17346978188, "eval_episode/length": 212.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9953051643192489}
{"step": 610064, "time": 78318.35790157318, "eval_episode/length": 217.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9770642201834863}
{"step": 610064, "time": 78321.2428381443, "eval_episode/length": 237.0, "eval_episode/score": 9.099999971687794, "eval_episode/reward_rate": 0.9957983193277311}
{"step": 610064, "time": 78323.16843938828, "eval_episode/length": 194.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 610208, "time": 78339.9434466362, "episode/length": 212.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 610320, "time": 78354.44615149498, "episode/length": 168.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 610381, "time": 78364.42210102081, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.455251162814111, "train/action_min": 0.0, "train/action_std": 3.1233687056708583, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04301272418119551, "train/actor_opt_grad_steps": 151235.0, "train/actor_opt_loss": -11.006155064166283, "train/adv_mag": 0.44968476261674745, "train/adv_max": 0.40678176698610957, "train/adv_mean": 0.00265938740214795, "train/adv_min": -0.3959022394775115, "train/adv_std": 0.054046139409093516, "train/cont_avg": 0.9949057667525774, "train/cont_loss_mean": 0.0002478101904467415, "train/cont_loss_std": 0.007670604500080839, "train/cont_neg_acc": 0.9926116844427955, "train/cont_neg_loss": 0.047107759504356604, "train/cont_pos_acc": 0.9999949197793744, "train/cont_pos_loss": 4.4499346515474065e-05, "train/cont_pred": 0.9949217395684153, "train/cont_rate": 0.9949057667525774, "train/dyn_loss_mean": 7.03379850780841, "train/dyn_loss_std": 8.998217885027227, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0940507250962799, "train/extr_critic_critic_opt_grad_steps": 151235.0, "train/extr_critic_critic_opt_loss": 16879.325567815722, "train/extr_critic_mag": 8.955375332193276, "train/extr_critic_max": 8.955375332193276, "train/extr_critic_mean": 1.9276204004730146, "train/extr_critic_min": -0.5585213997929367, "train/extr_critic_std": 2.1159881605315456, "train/extr_return_normed_mag": 1.5188982714082777, "train/extr_return_normed_max": 1.5188982714082777, "train/extr_return_normed_mean": 0.3275249791667633, "train/extr_return_normed_min": -0.09779920480838142, "train/extr_return_normed_std": 0.3260500918804985, "train/extr_return_rate": 0.6435644534445301, "train/extr_return_raw_mag": 9.804653592945375, "train/extr_return_raw_max": 9.804653592945375, "train/extr_return_raw_mean": 1.9451748685738475, "train/extr_return_raw_min": -0.8611283385262047, "train/extr_return_raw_std": 2.1512853589254557, "train/extr_reward_mag": 1.050618067230146, "train/extr_reward_max": 1.050618067230146, "train/extr_reward_mean": 0.04428703550095718, "train/extr_reward_min": -0.6809611615446425, "train/extr_reward_std": 0.2054140832774418, "train/image_loss_mean": 3.861440770404855, "train/image_loss_std": 8.857821875011798, "train/model_loss_mean": 8.13306374156598, "train/model_loss_std": 13.00956264967771, "train/model_opt_grad_norm": 38.648489690197565, "train/model_opt_grad_steps": 151107.09278350516, "train/model_opt_loss": 11985.373089662533, "train/model_opt_model_opt_grad_overflow": 0.005154639175257732, "train/model_opt_model_opt_grad_scale": 1469.0721649484535, "train/policy_entropy_mag": 2.6297693424618123, "train/policy_entropy_max": 2.6297693424618123, "train/policy_entropy_mean": 0.4865807021401592, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6709305392098182, "train/policy_logprob_mag": 7.438384134744861, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.48653912083389833, "train/policy_logprob_min": -7.438384134744861, "train/policy_logprob_std": 1.0923167712909658, "train/policy_randomness_mag": 0.9281931728431859, "train/policy_randomness_max": 0.9281931728431859, "train/policy_randomness_mean": 0.17174163510658078, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.2368090381634604, "train/post_ent_mag": 59.76749858659567, "train/post_ent_max": 59.76749858659567, "train/post_ent_mean": 43.06845096706115, "train/post_ent_min": 19.725939824409092, "train/post_ent_std": 6.920957442411442, "train/prior_ent_mag": 75.94432496532951, "train/prior_ent_max": 75.94432496532951, "train/prior_ent_mean": 50.13745685459412, "train/prior_ent_min": 30.130827077885264, "train/prior_ent_std": 7.404813454323208, "train/rep_loss_mean": 7.03379850780841, "train/rep_loss_std": 8.998217885027227, "train/reward_avg": 0.034406209450944795, "train/reward_loss_mean": 0.051096061167796865, "train/reward_loss_std": 0.2064196341431018, "train/reward_max_data": 1.019587633536034, "train/reward_max_pred": 1.0170209801074155, "train/reward_neg_acc": 0.9941073665299367, "train/reward_neg_loss": 0.0231564517718615, "train/reward_pos_acc": 0.9872229216025048, "train/reward_pos_loss": 0.7389429322223073, "train/reward_pred": 0.03402784864235785, "train/reward_rate": 0.03898699259020619, "train_stats/sum_log_reward": 8.257894848522387, "train_stats/max_log_achievement_collect_coal": 0.4473684210526316, "train_stats/max_log_achievement_collect_drink": 3.5789473684210527, "train_stats/max_log_achievement_collect_sapling": 1.5, "train_stats/max_log_achievement_collect_stone": 11.342105263157896, "train_stats/max_log_achievement_collect_wood": 6.2631578947368425, "train_stats/max_log_achievement_defeat_skeleton": 0.02631578947368421, "train_stats/max_log_achievement_defeat_zombie": 0.2894736842105263, "train_stats/max_log_achievement_eat_cow": 0.07894736842105263, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.368421052631579, "train_stats/max_log_achievement_make_wood_sword": 0.02631578947368421, "train_stats/max_log_achievement_place_furnace": 1.394736842105263, "train_stats/max_log_achievement_place_plant": 1.3421052631578947, "train_stats/max_log_achievement_place_stone": 4.184210526315789, "train_stats/max_log_achievement_place_table": 2.236842105263158, "train_stats/max_log_achievement_wake_up": 1.9736842105263157, "train_stats/mean_log_entropy": 0.4145945253732957, "eval_stats/sum_log_reward": 7.5999999940395355, "eval_stats/max_log_achievement_collect_coal": 0.75, "eval_stats/max_log_achievement_collect_drink": 1.5, "eval_stats/max_log_achievement_collect_sapling": 1.5, "eval_stats/max_log_achievement_collect_stone": 10.875, "eval_stats/max_log_achievement_collect_wood": 4.75, "eval_stats/max_log_achievement_defeat_skeleton": 0.25, "eval_stats/max_log_achievement_defeat_zombie": 0.125, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.25, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 1.75, "eval_stats/max_log_achievement_place_plant": 1.5, "eval_stats/max_log_achievement_place_stone": 3.375, "eval_stats/max_log_achievement_place_table": 1.625, "eval_stats/max_log_achievement_wake_up": 1.625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 2.8141789698565844e-06, "report/cont_loss_std": 4.8449186579091474e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.020801119011594e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.777898998829187e-06, "report/cont_pred": 0.9951145648956299, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 6.151628017425537, "report/dyn_loss_std": 8.838990211486816, "report/image_loss_mean": 2.800732135772705, "report/image_loss_std": 5.7164387702941895, "report/model_loss_mean": 6.527939796447754, "report/model_loss_std": 10.027155876159668, "report/post_ent_mag": 62.144561767578125, "report/post_ent_max": 62.144561767578125, "report/post_ent_mean": 42.95643615722656, "report/post_ent_min": 20.000783920288086, "report/post_ent_std": 6.711859226226807, "report/prior_ent_mag": 76.20094299316406, "report/prior_ent_max": 76.20094299316406, "report/prior_ent_mean": 49.34559631347656, "report/prior_ent_min": 29.04558563232422, "report/prior_ent_std": 7.601809978485107, "report/rep_loss_mean": 6.151628017425537, "report/rep_loss_std": 8.838990211486816, "report/reward_avg": 0.02304687350988388, "report/reward_loss_mean": 0.03622817620635033, "report/reward_loss_std": 0.14812594652175903, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0009455680847168, "report/reward_neg_acc": 0.9979940056800842, "report/reward_neg_loss": 0.019047817215323448, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6706288456916809, "report/reward_pred": 0.023654691874980927, "report/reward_rate": 0.0263671875, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 5.219337708695093e-06, "eval/cont_loss_std": 0.00011281028855592012, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00025391936651431024, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 3.9990241020859685e-06, "eval/cont_pred": 0.9951145648956299, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 19.962310791015625, "eval/dyn_loss_std": 13.704608917236328, "eval/image_loss_mean": 12.66804313659668, "eval/image_loss_std": 16.626224517822266, "eval/model_loss_mean": 24.801429748535156, "eval/model_loss_std": 22.219491958618164, "eval/post_ent_mag": 61.789119720458984, "eval/post_ent_max": 61.789119720458984, "eval/post_ent_mean": 39.802188873291016, "eval/post_ent_min": 17.14684295654297, "eval/post_ent_std": 7.812780380249023, "eval/prior_ent_mag": 76.20094299316406, "eval/prior_ent_max": 76.20094299316406, "eval/prior_ent_mean": 52.87660598754883, "eval/prior_ent_min": 31.56035041809082, "eval/prior_ent_std": 6.62945032119751, "eval/rep_loss_mean": 19.962310791015625, "eval/rep_loss_std": 13.704608917236328, "eval/reward_avg": 0.046875, "eval/reward_loss_mean": 0.15599331259727478, "eval/reward_loss_std": 0.8890251517295837, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0057880878448486, "eval/reward_neg_acc": 0.9814624786376953, "eval/reward_neg_loss": 0.0699164867401123, "eval/reward_pos_acc": 0.8301886916160583, "eval/reward_pos_loss": 1.7329856157302856, "eval/reward_pred": 0.047798506915569305, "eval/reward_rate": 0.0517578125, "replay/size": 609877.0, "replay/inserts": 7764.0, "replay/samples": 31056.0, "replay/insert_wait_avg": 1.5062686403285345e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.375959635149382e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 1912.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.153187771721365e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1771917343139648e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1231682300568, "timer/env.step_count": 970.0, "timer/env.step_total": 84.16220879554749, "timer/env.step_frac": 0.08415184396187068, "timer/env.step_avg": 0.08676516370674998, "timer/env.step_min": 0.023557424545288086, "timer/env.step_max": 2.066556453704834, "timer/replay._sample_count": 31056.0, "timer/replay._sample_total": 15.225632190704346, "timer/replay._sample_frac": 0.015223757107486602, "timer/replay._sample_avg": 0.0004902637876965594, "timer/replay._sample_min": 0.00040912628173828125, "timer/replay._sample_max": 0.007904767990112305, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1209.0, "timer/agent.policy_total": 19.38988471031189, "timer/agent.policy_frac": 0.019387496786647446, "timer/agent.policy_avg": 0.01603795261398833, "timer/agent.policy_min": 0.009599685668945312, "timer/agent.policy_max": 0.07601237297058105, "timer/dataset_train_count": 1941.0, "timer/dataset_train_total": 0.35866570472717285, "timer/dataset_train_frac": 0.0003586215339475763, "timer/dataset_train_avg": 0.0001847839797667042, "timer/dataset_train_min": 8.7738037109375e-05, "timer/dataset_train_max": 0.07836771011352539, "timer/agent.train_count": 1941.0, "timer/agent.train_total": 860.9791412353516, "timer/agent.train_frac": 0.8608731090182103, "timer/agent.train_avg": 0.4435750341243439, "timer/agent.train_min": 0.4253270626068115, "timer/agent.train_max": 0.9879152774810791, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4763600826263428, "timer/agent.report_frac": 0.00047630141742378515, "timer/agent.report_avg": 0.2381800413131714, "timer/agent.report_min": 0.23229265213012695, "timer/agent.report_max": 0.24406743049621582, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.574920654296875e-05, "timer/dataset_eval_frac": 2.5746035449351474e-08, "timer/dataset_eval_avg": 2.574920654296875e-05, "timer/dataset_eval_min": 2.574920654296875e-05, "timer/dataset_eval_max": 2.574920654296875e-05, "fps": 7.7629313676176155}
{"step": 610448, "time": 78372.11192035675, "episode/length": 152.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 610656, "time": 78397.82657599449, "episode/length": 158.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 611144, "time": 78457.02220726013, "episode/length": 266.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 611192, "time": 78464.04747986794, "episode/length": 300.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9966777408637874, "episode/intrinsic_return": 0.0}
{"step": 611704, "time": 78525.32409977913, "episode/length": 156.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 611792, "time": 78537.12861394882, "episode/length": 197.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 612064, "time": 78570.55276703835, "episode/length": 217.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9724770642201835, "episode/intrinsic_return": 0.0}
{"step": 612328, "time": 78603.21552801132, "episode/length": 286.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9860627177700348, "episode/intrinsic_return": 0.0}
{"step": 612368, "time": 78609.35136604309, "episode/length": 411.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9927184466019418, "episode/intrinsic_return": 0.0}
{"step": 612800, "time": 78661.49197483063, "episode/length": 267.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.996268656716418, "episode/intrinsic_return": 0.0}
{"step": 612840, "time": 78667.82776856422, "episode/length": 211.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 613288, "time": 78721.46691417694, "episode/length": 186.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 613504, "time": 78748.05414628983, "episode/length": 288.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9792387543252595, "episode/intrinsic_return": 0.0}
{"step": 613640, "time": 78765.36618280411, "episode/length": 163.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 613736, "time": 78777.86209988594, "episode/length": 208.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 613912, "time": 78799.62641406059, "episode/length": 133.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9925373134328358, "episode/intrinsic_return": 0.0}
{"step": 614016, "time": 78813.11337900162, "episode/length": 63.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9375, "episode/intrinsic_return": 0.0}
{"step": 614056, "time": 78819.29426550865, "episode/length": 293.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9829931972789115, "episode/intrinsic_return": 0.0}
{"step": 614176, "time": 78834.75095129013, "episode/length": 225.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9734513274336283, "episode/intrinsic_return": 0.0}
{"step": 614536, "time": 78879.32370686531, "episode/length": 155.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 614544, "time": 78881.92462706566, "episode/length": 65.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9848484848484849, "episode/intrinsic_return": 0.0}
{"step": 614640, "time": 78894.49742174149, "episode/length": 229.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 614936, "time": 78930.39104890823, "episode/length": 149.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 615304, "time": 78974.84432601929, "episode/length": 207.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 615496, "time": 78998.5802025795, "episode/length": 119.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9916666666666667, "episode/intrinsic_return": 0.0}
{"step": 615752, "time": 79030.03041958809, "episode/length": 150.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9735099337748344, "episode/intrinsic_return": 0.0}
{"step": 616072, "time": 79068.56887817383, "episode/length": 251.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 616104, "time": 79073.8028562069, "episode/length": 273.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9781021897810219, "episode/intrinsic_return": 0.0}
{"step": 616112, "time": 79076.18827152252, "episode/length": 100.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9900990099009901, "episode/intrinsic_return": 0.0}
{"step": 616136, "time": 79080.42901682854, "episode/length": 244.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 616296, "time": 79100.54744052887, "episode/length": 27.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.8571428571428571, "episode/intrinsic_return": 0.0}
{"step": 616304, "time": 79103.03778147697, "episode/length": 207.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9711538461538461, "episode/intrinsic_return": 0.0}
{"step": 616488, "time": 79126.04283690453, "episode/length": 193.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 617128, "time": 79202.85033583641, "episode/length": 203.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 617264, "time": 79220.08664178848, "episode/length": 140.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9645390070921985, "episode/intrinsic_return": 0.0}
{"step": 617544, "time": 79254.0722310543, "episode/length": 178.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 617800, "time": 79285.1712884903, "episode/length": 187.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9680851063829787, "episode/intrinsic_return": 0.0}
{"step": 617840, "time": 79291.40539741516, "episode/length": 191.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 617872, "time": 79296.55434083939, "episode/length": 264.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9962264150943396, "episode/intrinsic_return": 0.0}
{"step": 617936, "time": 79305.42205834389, "episode/length": 48.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 618040, "time": 79318.84405875206, "episode/length": 241.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9752066115702479, "episode/intrinsic_return": 0.0}
{"step": 618184, "time": 79337.12337779999, "episode/length": 211.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 618401, "time": 79364.72687077522, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.437514575559701, "train/action_min": 0.0, "train/action_std": 3.1066259151667506, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.043675044653427544, "train/actor_opt_grad_steps": 153210.0, "train/actor_opt_loss": -12.330749355812571, "train/adv_mag": 0.4506753312414558, "train/adv_max": 0.41313442187522775, "train/adv_mean": 0.00243942955532828, "train/adv_min": -0.38542323933905037, "train/adv_std": 0.05512163161638364, "train/cont_avg": 0.9947673740671642, "train/cont_loss_mean": 9.912072118836975e-05, "train/cont_loss_std": 0.0030111428120641963, "train/cont_neg_acc": 0.9960554375577328, "train/cont_neg_loss": 0.01163571266805327, "train/cont_pos_acc": 0.999985333698899, "train/cont_pos_loss": 3.589704393842564e-05, "train/cont_pred": 0.9947691245458612, "train/cont_rate": 0.9947673740671642, "train/dyn_loss_mean": 6.984396929764629, "train/dyn_loss_std": 8.945655103939682, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0580426599848922, "train/extr_critic_critic_opt_grad_steps": 153210.0, "train/extr_critic_critic_opt_loss": 16916.911356304416, "train/extr_critic_mag": 8.969581604003906, "train/extr_critic_max": 8.969581604003906, "train/extr_critic_mean": 1.9432536061130352, "train/extr_critic_min": -0.5746426872946137, "train/extr_critic_std": 2.0897039714737318, "train/extr_return_normed_mag": 1.5273018903400175, "train/extr_return_normed_max": 1.5273018903400175, "train/extr_return_normed_mean": 0.33136607513795446, "train/extr_return_normed_min": -0.10870645678977468, "train/extr_return_normed_std": 0.3247481698717051, "train/extr_return_rate": 0.6501133990525013, "train/extr_return_raw_mag": 9.776408480174506, "train/extr_return_raw_max": 9.776408480174506, "train/extr_return_raw_mean": 1.959193977253947, "train/extr_return_raw_min": -0.9173979957898458, "train/extr_return_raw_std": 2.122785460889636, "train/extr_reward_mag": 1.0511386892688808, "train/extr_reward_max": 1.0511386892688808, "train/extr_reward_mean": 0.04515384889175346, "train/extr_reward_min": -0.6788943839903495, "train/extr_reward_std": 0.20753085272229133, "train/image_loss_mean": 3.69341614353123, "train/image_loss_std": 8.567040009285087, "train/model_loss_mean": 7.936849890656732, "train/model_loss_std": 12.725075285233075, "train/model_opt_grad_norm": 35.62130029403155, "train/model_opt_grad_steps": 153080.62189054728, "train/model_opt_loss": 12878.598385027984, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1616.915422885572, "train/policy_entropy_mag": 2.638153103453603, "train/policy_entropy_max": 2.638153103453603, "train/policy_entropy_mean": 0.47293362273505674, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6590586242391102, "train/policy_logprob_mag": 7.438384146239627, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.47360223902398674, "train/policy_logprob_min": -7.438384146239627, "train/policy_logprob_std": 1.0846668143770588, "train/policy_randomness_mag": 0.9311522737664369, "train/policy_randomness_max": 0.9311522737664369, "train/policy_randomness_mean": 0.16692481582882393, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.23261877153050248, "train/post_ent_mag": 59.65622496723535, "train/post_ent_max": 59.65622496723535, "train/post_ent_mean": 42.972295694683325, "train/post_ent_min": 19.69167780520311, "train/post_ent_std": 6.888771517359795, "train/prior_ent_mag": 75.85445240836832, "train/prior_ent_max": 75.85445240836832, "train/prior_ent_mean": 50.00406039413528, "train/prior_ent_min": 30.02897941057955, "train/prior_ent_std": 7.38277432218713, "train/rep_loss_mean": 6.984396929764629, "train/rep_loss_std": 8.945655103939682, "train/reward_avg": 0.03544678936587341, "train/reward_loss_mean": 0.05269650616381892, "train/reward_loss_std": 0.21187906056197722, "train/reward_max_data": 1.0218905524827948, "train/reward_max_pred": 1.0210026935558414, "train/reward_neg_acc": 0.9943763014689013, "train/reward_neg_loss": 0.02390525822726945, "train/reward_pos_acc": 0.988007476970331, "train/reward_pos_loss": 0.7405192819400807, "train/reward_pred": 0.03504525940513136, "train/reward_rate": 0.0402382618159204, "train_stats/sum_log_reward": 8.338095420882816, "train_stats/max_log_achievement_collect_coal": 0.7142857142857143, "train_stats/max_log_achievement_collect_drink": 3.761904761904762, "train_stats/max_log_achievement_collect_sapling": 1.5714285714285714, "train_stats/max_log_achievement_collect_stone": 11.571428571428571, "train_stats/max_log_achievement_collect_wood": 5.190476190476191, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.38095238095238093, "train_stats/max_log_achievement_eat_cow": 0.023809523809523808, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.0714285714285714, "train_stats/max_log_achievement_make_wood_sword": 0.023809523809523808, "train_stats/max_log_achievement_place_furnace": 1.8333333333333333, "train_stats/max_log_achievement_place_plant": 1.5, "train_stats/max_log_achievement_place_stone": 2.9761904761904763, "train_stats/max_log_achievement_place_table": 1.7857142857142858, "train_stats/max_log_achievement_wake_up": 1.9761904761904763, "train_stats/mean_log_entropy": 0.42136938426466214, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 7.81220878707245e-05, "report/cont_loss_std": 0.0023400289937853813, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0005797488847747445, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 7.417226152028888e-05, "report/cont_pred": 0.992121160030365, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 7.021919250488281, "report/dyn_loss_std": 9.041117668151855, "report/image_loss_mean": 3.1442387104034424, "report/image_loss_std": 10.13007926940918, "report/model_loss_mean": 7.420269966125488, "report/model_loss_std": 14.304086685180664, "report/post_ent_mag": 57.351341247558594, "report/post_ent_max": 57.351341247558594, "report/post_ent_mean": 41.82310104370117, "report/post_ent_min": 19.196306228637695, "report/post_ent_std": 6.556612968444824, "report/prior_ent_mag": 75.69580078125, "report/prior_ent_max": 75.69580078125, "report/prior_ent_mean": 49.15235137939453, "report/prior_ent_min": 31.9266357421875, "report/prior_ent_std": 7.64017915725708, "report/rep_loss_mean": 7.021919250488281, "report/rep_loss_std": 9.041117668151855, "report/reward_avg": 0.03486327826976776, "report/reward_loss_mean": 0.06280224025249481, "report/reward_loss_std": 0.24523942172527313, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0006129741668701, "report/reward_neg_acc": 0.9908350706100464, "report/reward_neg_loss": 0.03299569711089134, "report/reward_pos_acc": 0.9761905074119568, "report/reward_pos_loss": 0.7597076296806335, "report/reward_pred": 0.03447416424751282, "report/reward_rate": 0.041015625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 4.059418188262498e-06, "eval/cont_loss_std": 8.850932499626651e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0013684474397450686, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 5.0442757526525384e-08, "eval/cont_pred": 0.9970743656158447, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 18.046995162963867, "eval/dyn_loss_std": 13.763012886047363, "eval/image_loss_mean": 16.97917938232422, "eval/image_loss_std": 21.282583236694336, "eval/model_loss_mean": 27.948366165161133, "eval/model_loss_std": 26.694225311279297, "eval/post_ent_mag": 58.95415496826172, "eval/post_ent_max": 58.95415496826172, "eval/post_ent_mean": 40.69806671142578, "eval/post_ent_min": 17.754894256591797, "eval/post_ent_std": 7.940971374511719, "eval/prior_ent_mag": 75.69580078125, "eval/prior_ent_max": 75.69580078125, "eval/prior_ent_mean": 52.99263000488281, "eval/prior_ent_min": 34.27721405029297, "eval/prior_ent_std": 6.900258541107178, "eval/rep_loss_mean": 18.046995162963867, "eval/rep_loss_std": 13.763012886047363, "eval/reward_avg": 0.05703124776482582, "eval/reward_loss_mean": 0.14098763465881348, "eval/reward_loss_std": 0.7163137793540955, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.000598669052124, "eval/reward_neg_acc": 0.9812889695167542, "eval/reward_neg_loss": 0.06888379901647568, "eval/reward_pos_acc": 0.9032257795333862, "eval/reward_pos_loss": 1.2597601413726807, "eval/reward_pred": 0.058592893183231354, "eval/reward_rate": 0.060546875, "replay/size": 617897.0, "replay/inserts": 8020.0, "replay/samples": 32080.0, "replay/insert_wait_avg": 1.5332811788430535e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.402346913059453e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2910704612732, "timer/env.step_count": 1003.0, "timer/env.step_total": 91.6538245677948, "timer/env.step_frac": 0.09162715460963743, "timer/env.step_avg": 0.09137968551126102, "timer/env.step_min": 0.022979259490966797, "timer/env.step_max": 2.165041923522949, "timer/replay._sample_count": 32080.0, "timer/replay._sample_total": 15.813825845718384, "timer/replay._sample_frac": 0.015809224247524286, "timer/replay._sample_avg": 0.0004929496834700244, "timer/replay._sample_min": 0.00039768218994140625, "timer/replay._sample_max": 0.03482460975646973, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1003.0, "timer/agent.policy_total": 16.10828137397766, "timer/agent.policy_frac": 0.016103594093416735, "timer/agent.policy_avg": 0.016060101070765366, "timer/agent.policy_min": 0.009699106216430664, "timer/agent.policy_max": 0.06526732444763184, "timer/dataset_train_count": 2005.0, "timer/dataset_train_total": 0.3624532222747803, "timer/dataset_train_frac": 0.000362347753547014, "timer/dataset_train_avg": 0.00018077467445126198, "timer/dataset_train_min": 8.96453857421875e-05, "timer/dataset_train_max": 0.06430530548095703, "timer/agent.train_count": 2005.0, "timer/agent.train_total": 889.2701649665833, "timer/agent.train_frac": 0.8890114000083057, "timer/agent.train_avg": 0.443526266816251, "timer/agent.train_min": 0.42859530448913574, "timer/agent.train_max": 0.9865846633911133, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4724130630493164, "timer/agent.report_frac": 0.00047227559757328266, "timer/agent.report_avg": 0.2362065315246582, "timer/agent.report_min": 0.23052334785461426, "timer/agent.report_max": 0.24188971519470215, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.790855407714844e-05, "timer/dataset_eval_frac": 3.789752322758148e-08, "timer/dataset_eval_avg": 3.790855407714844e-05, "timer/dataset_eval_min": 3.790855407714844e-05, "timer/dataset_eval_max": 3.790855407714844e-05, "fps": 8.017558860858399}
{"step": 618456, "time": 79370.9522819519, "episode/length": 165.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 618720, "time": 79403.04471492767, "episode/length": 181.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 619112, "time": 79449.72467184067, "episode/length": 154.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 619296, "time": 79472.49727678299, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 619344, "time": 79479.47600769997, "episode/length": 162.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 619544, "time": 79504.19629406929, "episode/length": 200.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 619592, "time": 79511.3096818924, "episode/length": 175.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 619848, "time": 79542.77700328827, "episode/length": 62.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 620048, "time": 79582.18255281448, "eval_episode/length": 48.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9795918367346939}
{"step": 620048, "time": 79584.01913666725, "eval_episode/length": 51.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9807692307692307}
{"step": 620048, "time": 79586.64652323723, "eval_episode/length": 76.0, "eval_episode/score": 7.0999999940395355, "eval_episode/reward_rate": 0.987012987012987}
{"step": 620048, "time": 79588.7085185051, "eval_episode/length": 91.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9456521739130435}
{"step": 620048, "time": 79590.19887661934, "eval_episode/length": 41.0, "eval_episode/score": 6.0999999940395355, "eval_episode/reward_rate": 0.9761904761904762}
{"step": 620048, "time": 79595.21659398079, "eval_episode/length": 104.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9904761904761905}
{"step": 620048, "time": 79598.2974486351, "eval_episode/length": 209.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9619047619047619}
{"step": 620048, "time": 79600.5212135315, "eval_episode/length": 163.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9695121951219512}
{"step": 620128, "time": 79609.83190894127, "episode/length": 290.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9896907216494846, "episode/intrinsic_return": 0.0}
{"step": 620328, "time": 79634.5035276413, "episode/length": 200.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9800995024875622, "episode/intrinsic_return": 0.0}
{"step": 620704, "time": 79679.50562238693, "episode/length": 198.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 620896, "time": 79703.21607208252, "episode/length": 199.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 621016, "time": 79718.47372746468, "episode/length": 183.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 621464, "time": 79771.76187968254, "episode/length": 233.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9700854700854701, "episode/intrinsic_return": 0.0}
{"step": 621656, "time": 79795.39009404182, "episode/length": 399.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9925, "episode/intrinsic_return": 0.0}
{"step": 621888, "time": 79823.91875314713, "episode/length": 254.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.996078431372549, "episode/intrinsic_return": 0.0}
{"step": 621896, "time": 79826.32639288902, "episode/length": 195.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 622296, "time": 79874.3492307663, "episode/length": 174.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 622368, "time": 79884.1512272358, "episode/length": 207.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 622768, "time": 79933.15787506104, "episode/length": 329.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.990909090909091, "episode/intrinsic_return": 0.0}
{"step": 622856, "time": 79944.81532120705, "episode/length": 173.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 623040, "time": 79967.73447775841, "episode/length": 172.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 623216, "time": 79989.60079741478, "episode/length": 164.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9636363636363636, "episode/intrinsic_return": 0.0}
{"step": 623512, "time": 80025.50642609596, "episode/length": 58.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9322033898305084, "episode/intrinsic_return": 0.0}
{"step": 623824, "time": 80063.19103264809, "episode/length": 181.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 623840, "time": 80066.5649137497, "episode/length": 192.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 624312, "time": 80122.75189399719, "episode/length": 136.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9562043795620438, "episode/intrinsic_return": 0.0}
{"step": 624512, "time": 80147.56686782837, "episode/length": 436.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9794050343249427, "episode/intrinsic_return": 0.0}
{"step": 624712, "time": 80172.27133655548, "episode/length": 352.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9858356940509915, "episode/intrinsic_return": 0.0}
{"step": 624864, "time": 80191.43435525894, "episode/length": 250.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9721115537848606, "episode/intrinsic_return": 0.0}
{"step": 624896, "time": 80196.80490016937, "episode/length": 265.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9962406015037594, "episode/intrinsic_return": 0.0}
{"step": 625168, "time": 80229.91293215752, "episode/length": 167.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 625576, "time": 80278.74233865738, "episode/length": 157.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 625784, "time": 80304.45608019829, "episode/length": 283.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9964788732394366, "episode/intrinsic_return": 0.0}
{"step": 625880, "time": 80317.08428120613, "episode/length": 122.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.959349593495935, "episode/intrinsic_return": 0.0}
{"step": 625920, "time": 80323.29586482048, "episode/length": 259.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9769230769230769, "episode/intrinsic_return": 0.0}
{"step": 626176, "time": 80354.60409975052, "episode/length": 207.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 626245, "time": 80364.97597837448, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.421542732083068, "train/action_min": 0.0, "train/action_std": 3.1244744865261778, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.043474260432531636, "train/actor_opt_grad_steps": 155195.0, "train/actor_opt_loss": -12.194596090943229, "train/adv_mag": 0.44653573981961425, "train/adv_max": 0.4169988074168867, "train/adv_mean": 0.0024690722830218084, "train/adv_min": -0.37617153218206095, "train/adv_std": 0.054903115811092515, "train/cont_avg": 0.9948680644132653, "train/cont_loss_mean": 9.979972225171214e-05, "train/cont_loss_std": 0.0021618714157917956, "train/cont_neg_acc": 0.9954700858165056, "train/cont_neg_loss": 0.007245116316446981, "train/cont_pos_acc": 0.9999899173877678, "train/cont_pos_loss": 6.157618082625049e-05, "train/cont_pred": 0.9948604830673763, "train/cont_rate": 0.9948680644132653, "train/dyn_loss_mean": 7.061971031889623, "train/dyn_loss_std": 9.001608712332589, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0644253303810043, "train/extr_critic_critic_opt_grad_steps": 155195.0, "train/extr_critic_critic_opt_loss": 16929.093336455677, "train/extr_critic_mag": 8.955960409981865, "train/extr_critic_max": 8.955960409981865, "train/extr_critic_mean": 1.899914192910097, "train/extr_critic_min": -0.5726176323939343, "train/extr_critic_std": 2.0882627063867996, "train/extr_return_normed_mag": 1.5385934868637396, "train/extr_return_normed_max": 1.5385934868637396, "train/extr_return_normed_mean": 0.326922959134895, "train/extr_return_normed_min": -0.10079886156077288, "train/extr_return_normed_std": 0.32400898506142656, "train/extr_return_rate": 0.6414541147497236, "train/extr_return_raw_mag": 9.863740901557767, "train/extr_return_raw_max": 9.863740901557767, "train/extr_return_raw_mean": 1.9161085541151008, "train/extr_return_raw_min": -0.8897965954882758, "train/extr_return_raw_std": 2.125505593358254, "train/extr_reward_mag": 1.0455393560078678, "train/extr_reward_max": 1.0455393560078678, "train/extr_reward_mean": 0.044945677314713904, "train/extr_reward_min": -0.6850564546731054, "train/extr_reward_std": 0.2073159803237234, "train/image_loss_mean": 3.8571263405741476, "train/image_loss_std": 8.809822500968465, "train/model_loss_mean": 8.146122827821848, "train/model_loss_std": 12.9987232393148, "train/model_opt_grad_norm": 36.97993964565043, "train/model_opt_grad_steps": 155063.93367346938, "train/model_opt_loss": 10868.037633779097, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1326.530612244898, "train/policy_entropy_mag": 2.6657138892582486, "train/policy_entropy_max": 2.6657138892582486, "train/policy_entropy_mean": 0.4894284716978365, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6845976080821485, "train/policy_logprob_mag": 7.438384136375116, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.48962899601581145, "train/policy_logprob_min": -7.438384136375116, "train/policy_logprob_std": 1.0962398462757772, "train/policy_randomness_mag": 0.9408800200540193, "train/policy_randomness_max": 0.9408800200540193, "train/policy_randomness_mean": 0.17274677320098392, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.24163291489287297, "train/post_ent_mag": 59.70301065639574, "train/post_ent_max": 59.70301065639574, "train/post_ent_mean": 43.01002936460534, "train/post_ent_min": 19.635544484975387, "train/post_ent_std": 6.9555262911076445, "train/prior_ent_mag": 75.88958269236039, "train/prior_ent_max": 75.88958269236039, "train/prior_ent_mean": 50.10809950925866, "train/prior_ent_min": 30.12834289122601, "train/prior_ent_std": 7.4290242633041075, "train/rep_loss_mean": 7.061971031889623, "train/rep_loss_std": 9.001608712332589, "train/reward_avg": 0.03483388449388499, "train/reward_loss_mean": 0.05171407227005277, "train/reward_loss_std": 0.20935599224603907, "train/reward_max_data": 1.0209183723342663, "train/reward_max_pred": 1.0187487407606475, "train/reward_neg_acc": 0.9940469432242063, "train/reward_neg_loss": 0.023531113447127293, "train/reward_pos_acc": 0.9868826425197174, "train/reward_pos_loss": 0.7378021101562344, "train/reward_pred": 0.03464920820706353, "train/reward_rate": 0.039476044323979595, "train_stats/sum_log_reward": 8.721621822666478, "train_stats/max_log_achievement_collect_coal": 1.0, "train_stats/max_log_achievement_collect_drink": 5.54054054054054, "train_stats/max_log_achievement_collect_sapling": 1.2432432432432432, "train_stats/max_log_achievement_collect_stone": 10.891891891891891, "train_stats/max_log_achievement_collect_wood": 6.081081081081081, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.43243243243243246, "train_stats/max_log_achievement_eat_cow": 0.08108108108108109, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.3243243243243243, "train_stats/max_log_achievement_make_wood_sword": 0.02702702702702703, "train_stats/max_log_achievement_place_furnace": 1.6486486486486487, "train_stats/max_log_achievement_place_plant": 1.2432432432432432, "train_stats/max_log_achievement_place_stone": 2.5405405405405403, "train_stats/max_log_achievement_place_table": 2.081081081081081, "train_stats/max_log_achievement_wake_up": 2.027027027027027, "train_stats/mean_log_entropy": 0.4398258960730321, "eval_stats/sum_log_reward": 7.100000083446503, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 1.5, "eval_stats/max_log_achievement_collect_sapling": 1.125, "eval_stats/max_log_achievement_collect_stone": 4.75, "eval_stats/max_log_achievement_collect_wood": 4.0, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.25, "eval_stats/max_log_achievement_place_plant": 1.125, "eval_stats/max_log_achievement_place_stone": 3.0, "eval_stats/max_log_achievement_place_table": 1.375, "eval_stats/max_log_achievement_wake_up": 0.875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 1.2828892295146943e-06, "report/cont_loss_std": 7.277546501427423e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 6.958992162253708e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.082182961908984e-06, "report/cont_pred": 0.9970694184303284, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 6.237851142883301, "report/dyn_loss_std": 8.78722095489502, "report/image_loss_mean": 2.4649016857147217, "report/image_loss_std": 6.968042373657227, "report/model_loss_mean": 6.2438249588012695, "report/model_loss_std": 11.370841026306152, "report/post_ent_mag": 58.593505859375, "report/post_ent_max": 58.593505859375, "report/post_ent_mean": 43.38611602783203, "report/post_ent_min": 19.493919372558594, "report/post_ent_std": 6.233038902282715, "report/prior_ent_mag": 76.30104064941406, "report/prior_ent_max": 76.30104064941406, "report/prior_ent_mean": 49.30101776123047, "report/prior_ent_min": 26.998292922973633, "report/prior_ent_std": 6.742446422576904, "report/rep_loss_mean": 6.237851142883301, "report/rep_loss_std": 8.78722095489502, "report/reward_avg": 0.02382812462747097, "report/reward_loss_mean": 0.03621162474155426, "report/reward_loss_std": 0.22047176957130432, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.000047206878662, "report/reward_neg_acc": 0.9979940056800842, "report/reward_neg_loss": 0.017735812813043594, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7184481024742126, "report/reward_pred": 0.023264851421117783, "report/reward_rate": 0.0263671875, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 2.6314755814382806e-05, "eval/cont_loss_std": 0.0006863618036732078, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.004309649579226971, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.0691711622712319e-06, "eval/cont_pred": 0.9941645860671997, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 19.92129898071289, "eval/dyn_loss_std": 13.123604774475098, "eval/image_loss_mean": 15.925481796264648, "eval/image_loss_std": 17.954391479492188, "eval/model_loss_mean": 28.004728317260742, "eval/model_loss_std": 23.28042221069336, "eval/post_ent_mag": 58.3935432434082, "eval/post_ent_max": 58.3935432434082, "eval/post_ent_mean": 39.72972106933594, "eval/post_ent_min": 20.834278106689453, "eval/post_ent_std": 7.488946914672852, "eval/prior_ent_mag": 76.30104064941406, "eval/prior_ent_max": 76.30104064941406, "eval/prior_ent_mean": 52.62068557739258, "eval/prior_ent_min": 35.848609924316406, "eval/prior_ent_std": 6.642709255218506, "eval/rep_loss_mean": 19.92129898071289, "eval/rep_loss_std": 13.123604774475098, "eval/reward_avg": 0.05312499776482582, "eval/reward_loss_mean": 0.12644237279891968, "eval/reward_loss_std": 0.7718836069107056, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0000290870666504, "eval/reward_neg_acc": 0.9927611351013184, "eval/reward_neg_loss": 0.027696989476680756, "eval/reward_pos_acc": 0.8245614171028137, "eval/reward_pos_loss": 1.8016490936279297, "eval/reward_pred": 0.04546045511960983, "eval/reward_rate": 0.0556640625, "replay/size": 625741.0, "replay/inserts": 7844.0, "replay/samples": 31376.0, "replay/insert_wait_avg": 1.5166205815184426e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.40096071798664e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 1704.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1025460113382115e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.748603820800781e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2327871322632, "timer/env.step_count": 980.0, "timer/env.step_total": 81.22056555747986, "timer/env.step_frac": 0.08120166285524878, "timer/env.step_avg": 0.08287812811987741, "timer/env.step_min": 0.023570537567138672, "timer/env.step_max": 1.698885202407837, "timer/replay._sample_count": 31376.0, "timer/replay._sample_total": 15.297097206115723, "timer/replay._sample_frac": 0.015293537067479624, "timer/replay._sample_avg": 0.00048754134389711, "timer/replay._sample_min": 0.0003616809844970703, "timer/replay._sample_max": 0.010592222213745117, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1193.0, "timer/agent.policy_total": 18.930739879608154, "timer/agent.policy_frac": 0.018926334072575143, "timer/agent.policy_avg": 0.01586818095524573, "timer/agent.policy_min": 0.009572982788085938, "timer/agent.policy_max": 0.07509160041809082, "timer/dataset_train_count": 1961.0, "timer/dataset_train_total": 0.2868812084197998, "timer/dataset_train_frac": 0.00028681444170842286, "timer/dataset_train_avg": 0.00014629332402845476, "timer/dataset_train_min": 8.535385131835938e-05, "timer/dataset_train_max": 0.0006511211395263672, "timer/agent.train_count": 1961.0, "timer/agent.train_total": 867.1850292682648, "timer/agent.train_frac": 0.8669832067338489, "timer/agent.train_avg": 0.4422157211974833, "timer/agent.train_min": 0.43157458305358887, "timer/agent.train_max": 0.9418153762817383, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47525453567504883, "timer/agent.report_frac": 0.00047514392828257166, "timer/agent.report_avg": 0.23762726783752441, "timer/agent.report_min": 0.2326219081878662, "timer/agent.report_max": 0.24263262748718262, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.6464462280273438e-05, "timer/dataset_eval_frac": 2.6458303127763775e-08, "timer/dataset_eval_avg": 2.6464462280273438e-05, "timer/dataset_eval_min": 2.6464462280273438e-05, "timer/dataset_eval_max": 2.6464462280273438e-05, "fps": 7.842058997362251}
{"step": 626296, "time": 80370.75153589249, "episode/length": 197.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 626752, "time": 80425.3561360836, "episode/length": 197.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 626856, "time": 80438.88841032982, "episode/length": 248.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9799196787148594, "episode/intrinsic_return": 0.0}
{"step": 626920, "time": 80447.99154686928, "episode/length": 141.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 627320, "time": 80495.95649337769, "episode/length": 142.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.958041958041958, "episode/intrinsic_return": 0.0}
{"step": 627616, "time": 80531.84096431732, "episode/length": 254.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.996078431372549, "episode/intrinsic_return": 0.0}
{"step": 627832, "time": 80558.38805747032, "episode/length": 113.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9912280701754386, "episode/intrinsic_return": 0.0}
{"step": 627976, "time": 80576.75770926476, "episode/length": 256.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9961089494163424, "episode/intrinsic_return": 0.0}
{"step": 628016, "time": 80582.86459136009, "episode/length": 144.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 628328, "time": 80621.0660583973, "episode/length": 253.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9803149606299213, "episode/intrinsic_return": 0.0}
{"step": 628584, "time": 80652.27398228645, "episode/length": 228.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9737991266375546, "episode/intrinsic_return": 0.0}
{"step": 628728, "time": 80670.41016983986, "episode/length": 175.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 629104, "time": 80715.63926911354, "episode/length": 402.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9925558312655087, "episode/intrinsic_return": 0.0}
{"step": 629368, "time": 80747.79794859886, "episode/length": 191.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.984375, "episode/intrinsic_return": 0.0}
{"step": 629424, "time": 80756.369805336, "episode/length": 180.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 629704, "time": 80790.48944354057, "episode/length": 260.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 629808, "time": 80803.99166226387, "episode/length": 184.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 629816, "time": 80806.39981842041, "episode/length": 135.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.0}
{"step": 630032, "time": 80851.24310708046, "eval_episode/length": 106.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9626168224299065}
{"step": 630032, "time": 80855.85604095459, "eval_episode/length": 183.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9619565217391305}
{"step": 630032, "time": 80857.47591543198, "eval_episode/length": 186.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9625668449197861}
{"step": 630032, "time": 80859.01996779442, "eval_episode/length": 188.0, "eval_episode/score": 8.100000023841858, "eval_episode/reward_rate": 0.9947089947089947}
{"step": 630032, "time": 80861.00764989853, "eval_episode/length": 199.0, "eval_episode/score": 10.099999971687794, "eval_episode/reward_rate": 0.995}
{"step": 630032, "time": 80863.31543540955, "eval_episode/length": 220.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9728506787330317}
{"step": 630032, "time": 80865.16056871414, "eval_episode/length": 230.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9956709956709957}
{"step": 630032, "time": 80868.32479023933, "eval_episode/length": 272.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9853479853479854}
{"step": 630168, "time": 80883.96109485626, "episode/length": 99.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 630600, "time": 80935.4650490284, "episode/length": 322.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9876160990712074, "episode/intrinsic_return": 0.0}
{"step": 631048, "time": 80990.47749066353, "episode/length": 202.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9704433497536946, "episode/intrinsic_return": 0.0}
{"step": 631056, "time": 80992.80248641968, "episode/length": 154.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 631072, "time": 80996.03039479256, "episode/length": 310.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9807073954983923, "episode/intrinsic_return": 0.0}
{"step": 631336, "time": 81028.15228867531, "episode/length": 190.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9685863874345549, "episode/intrinsic_return": 0.0}
{"step": 631344, "time": 81030.66348361969, "episode/length": 204.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 631672, "time": 81070.32495188713, "episode/length": 320.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9875389408099688, "episode/intrinsic_return": 0.0}
{"step": 631976, "time": 81107.2007727623, "episode/length": 171.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 632016, "time": 81113.3292684555, "episode/length": 230.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 632280, "time": 81145.4336335659, "episode/length": 152.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 632400, "time": 81160.91787266731, "episode/length": 168.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9644970414201184, "episode/intrinsic_return": 0.0}
{"step": 632648, "time": 81191.53200244904, "episode/length": 162.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 633064, "time": 81241.27543139458, "episode/length": 215.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 633096, "time": 81246.39609694481, "episode/length": 55.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 633184, "time": 81258.11673903465, "episode/length": 112.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9557522123893806, "episode/intrinsic_return": 0.0}
{"step": 633200, "time": 81261.4237241745, "episode/length": 265.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9962406015037594, "episode/intrinsic_return": 0.0}
{"step": 633312, "time": 81275.8487071991, "episode/length": 166.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9640718562874252, "episode/intrinsic_return": 0.0}
{"step": 633408, "time": 81288.55360269547, "episode/length": 173.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 634045, "time": 81365.00873064995, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.381297263120993, "train/action_min": 0.0, "train/action_std": 3.0741537998884154, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.043969269765493195, "train/actor_opt_grad_steps": 157150.0, "train/actor_opt_loss": -11.4355373889972, "train/adv_mag": 0.4447231338574336, "train/adv_max": 0.4113277290111933, "train/adv_mean": 0.0027988447590569896, "train/adv_min": -0.3831255593360999, "train/adv_std": 0.05547011131659532, "train/cont_avg": 0.9948617788461539, "train/cont_loss_mean": 8.128136370901418e-05, "train/cont_loss_std": 0.002412891509737118, "train/cont_neg_acc": 0.9989637306317146, "train/cont_neg_loss": 0.005886062959415978, "train/cont_pos_acc": 0.9999899045014993, "train/cont_pos_loss": 5.254735571983159e-05, "train/cont_pred": 0.9948409004089159, "train/cont_rate": 0.9948617788461539, "train/dyn_loss_mean": 7.134496681506818, "train/dyn_loss_std": 8.974737793360001, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0582377507136418, "train/extr_critic_critic_opt_grad_steps": 157150.0, "train/extr_critic_critic_opt_loss": 17086.881725761217, "train/extr_critic_mag": 8.973394188514122, "train/extr_critic_max": 8.973394188514122, "train/extr_critic_mean": 1.9227493286132813, "train/extr_critic_min": -0.5596818771117773, "train/extr_critic_std": 2.0972070522797415, "train/extr_return_normed_mag": 1.5353749189621364, "train/extr_return_normed_max": 1.5353749189621364, "train/extr_return_normed_mean": 0.32811749852620636, "train/extr_return_normed_min": -0.09962483808780327, "train/extr_return_normed_std": 0.32492313186327615, "train/extr_return_rate": 0.6459512221507537, "train/extr_return_raw_mag": 9.866403457445976, "train/extr_return_raw_max": 9.866403457445976, "train/extr_return_raw_mean": 1.9411172014016371, "train/extr_return_raw_min": -0.866765243273515, "train/extr_return_raw_std": 2.133062668947073, "train/extr_reward_mag": 1.051811338082338, "train/extr_reward_max": 1.051811338082338, "train/extr_reward_mean": 0.04600125667758477, "train/extr_reward_min": -0.704037297077668, "train/extr_reward_std": 0.2094027272401712, "train/image_loss_mean": 3.766288413756933, "train/image_loss_std": 8.822795325059158, "train/model_loss_mean": 8.100560396145552, "train/model_loss_std": 13.009565549019056, "train/model_opt_grad_norm": 35.57434621957632, "train/model_opt_grad_steps": 157017.7282051282, "train/model_opt_loss": 12110.492257612179, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1500.0, "train/policy_entropy_mag": 2.6557527370941947, "train/policy_entropy_max": 2.6557527370941947, "train/policy_entropy_mean": 0.47163343857496215, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.677608760809287, "train/policy_logprob_mag": 7.438384114778959, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.47138440639544754, "train/policy_logprob_min": -7.438384114778959, "train/policy_logprob_std": 1.0838754886235946, "train/policy_randomness_mag": 0.9373641701845022, "train/policy_randomness_max": 0.9373641701845022, "train/policy_randomness_mean": 0.1664659077158341, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.23916615805564784, "train/post_ent_mag": 59.82999590360201, "train/post_ent_max": 59.82999590360201, "train/post_ent_mean": 42.94846338125376, "train/post_ent_min": 19.709117375887356, "train/post_ent_std": 6.906164205991304, "train/prior_ent_mag": 76.05304095928486, "train/prior_ent_max": 76.05304095928486, "train/prior_ent_mean": 50.14876286433293, "train/prior_ent_min": 29.98393347324469, "train/prior_ent_std": 7.419811155857184, "train/rep_loss_mean": 7.134496681506818, "train/rep_loss_std": 8.974737793360001, "train/reward_avg": 0.035988581591309646, "train/reward_loss_mean": 0.05349266672363648, "train/reward_loss_std": 0.21555868402505532, "train/reward_max_data": 1.0220512873087173, "train/reward_max_pred": 1.0218238806113218, "train/reward_neg_acc": 0.9940999776889117, "train/reward_neg_loss": 0.024082135662245444, "train/reward_pos_acc": 0.9860118869023445, "train/reward_pos_loss": 0.7465394863715539, "train/reward_pred": 0.03556383789922946, "train/reward_rate": 0.04066005608974359, "train_stats/sum_log_reward": 9.100000201044855, "train_stats/max_log_achievement_collect_coal": 0.972972972972973, "train_stats/max_log_achievement_collect_drink": 3.4864864864864864, "train_stats/max_log_achievement_collect_sapling": 1.3243243243243243, "train_stats/max_log_achievement_collect_stone": 14.054054054054054, "train_stats/max_log_achievement_collect_wood": 6.405405405405405, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.2702702702702703, "train_stats/max_log_achievement_eat_cow": 0.10810810810810811, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.3783783783783783, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_furnace": 2.027027027027027, "train_stats/max_log_achievement_place_plant": 1.3243243243243243, "train_stats/max_log_achievement_place_stone": 4.1891891891891895, "train_stats/max_log_achievement_place_table": 2.135135135135135, "train_stats/max_log_achievement_wake_up": 1.7567567567567568, "train_stats/mean_log_entropy": 0.4461910056101309, "eval_stats/sum_log_reward": 9.975000143051147, "eval_stats/max_log_achievement_collect_coal": 0.875, "eval_stats/max_log_achievement_collect_drink": 2.375, "eval_stats/max_log_achievement_collect_sapling": 1.5, "eval_stats/max_log_achievement_collect_stone": 13.25, "eval_stats/max_log_achievement_collect_wood": 4.75, "eval_stats/max_log_achievement_defeat_skeleton": 0.25, "eval_stats/max_log_achievement_defeat_zombie": 0.375, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 2.25, "eval_stats/max_log_achievement_place_plant": 1.5, "eval_stats/max_log_achievement_place_stone": 3.0, "eval_stats/max_log_achievement_place_table": 1.75, "eval_stats/max_log_achievement_wake_up": 1.625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 1.7104288417613134e-05, "report/cont_loss_std": 0.00034458725713193417, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 4.42349846707657e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.6944384697126225e-05, "report/cont_pred": 0.9941241145133972, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 5.5203399658203125, "report/dyn_loss_std": 8.499349594116211, "report/image_loss_mean": 3.3690149784088135, "report/image_loss_std": 7.129724979400635, "report/model_loss_mean": 6.727208137512207, "report/model_loss_std": 11.087234497070312, "report/post_ent_mag": 62.98344421386719, "report/post_ent_max": 62.98344421386719, "report/post_ent_mean": 44.33643341064453, "report/post_ent_min": 20.51029396057129, "report/post_ent_std": 7.01779842376709, "report/prior_ent_mag": 76.22630310058594, "report/prior_ent_max": 76.22630310058594, "report/prior_ent_mean": 49.45757293701172, "report/prior_ent_min": 28.26079559326172, "report/prior_ent_std": 7.5489630699157715, "report/rep_loss_mean": 5.5203399658203125, "report/rep_loss_std": 8.499349594116211, "report/reward_avg": 0.03486328199505806, "report/reward_loss_mean": 0.045971836894750595, "report/reward_loss_std": 0.1986204832792282, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.001237392425537, "report/reward_neg_acc": 0.9969512820243835, "report/reward_neg_loss": 0.015570977702736855, "report/reward_pos_acc": 0.949999988079071, "report/reward_pos_loss": 0.7938330173492432, "report/reward_pred": 0.03304783254861832, "report/reward_rate": 0.0390625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 5.008800144423731e-06, "eval/cont_loss_std": 3.458306673564948e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0003943651681765914, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 3.4819122447515838e-06, "eval/cont_pred": 0.9960918426513672, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 19.817201614379883, "eval/dyn_loss_std": 13.36306381225586, "eval/image_loss_mean": 14.938677787780762, "eval/image_loss_std": 18.454593658447266, "eval/model_loss_mean": 26.96807861328125, "eval/model_loss_std": 23.701679229736328, "eval/post_ent_mag": 56.64670944213867, "eval/post_ent_max": 56.64670944213867, "eval/post_ent_mean": 39.0184326171875, "eval/post_ent_min": 19.079551696777344, "eval/post_ent_std": 6.877941131591797, "eval/prior_ent_mag": 76.22630310058594, "eval/prior_ent_max": 76.22630310058594, "eval/prior_ent_mean": 51.26587677001953, "eval/prior_ent_min": 34.821842193603516, "eval/prior_ent_std": 6.234718322753906, "eval/rep_loss_mean": 19.817201614379883, "eval/rep_loss_std": 13.36306381225586, "eval/reward_avg": 0.0576171875, "eval/reward_loss_mean": 0.1390736699104309, "eval/reward_loss_std": 0.6850210428237915, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0006380081176758, "eval/reward_neg_acc": 0.9812889695167542, "eval/reward_neg_loss": 0.055917639285326004, "eval/reward_pos_acc": 0.8709677457809448, "eval/reward_pos_loss": 1.429333209991455, "eval/reward_pred": 0.05908984690904617, "eval/reward_rate": 0.060546875, "replay/size": 633541.0, "replay/inserts": 7800.0, "replay/samples": 31200.0, "replay/insert_wait_avg": 1.5291189536070212e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.383945660713391e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 2184.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1009392720875723e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.450580596923828e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0180723667145, "timer/env.step_count": 975.0, "timer/env.step_total": 82.18583226203918, "timer/env.step_frac": 0.08218434699638208, "timer/env.step_avg": 0.08429316129439916, "timer/env.step_min": 0.022916316986083984, "timer/env.step_max": 2.003817081451416, "timer/replay._sample_count": 31200.0, "timer/replay._sample_total": 15.250895738601685, "timer/replay._sample_frac": 0.015250620123802183, "timer/replay._sample_avg": 0.0004888107608526181, "timer/replay._sample_min": 0.00037932395935058594, "timer/replay._sample_max": 0.020212888717651367, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1248.0, "timer/agent.policy_total": 20.947879552841187, "timer/agent.policy_frac": 0.02094750098192169, "timer/agent.policy_avg": 0.016785159898109924, "timer/agent.policy_min": 0.009366512298583984, "timer/agent.policy_max": 0.11192965507507324, "timer/dataset_train_count": 1950.0, "timer/dataset_train_total": 0.3355424404144287, "timer/dataset_train_frac": 0.00033553637647798696, "timer/dataset_train_avg": 0.0001720730463663737, "timer/dataset_train_min": 8.797645568847656e-05, "timer/dataset_train_max": 0.05654740333557129, "timer/agent.train_count": 1950.0, "timer/agent.train_total": 864.0907099246979, "timer/agent.train_frac": 0.8640750940427295, "timer/agent.train_avg": 0.44312344098702455, "timer/agent.train_min": 0.4308793544769287, "timer/agent.train_max": 0.9397647380828857, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4749643802642822, "timer/agent.report_frac": 0.0004749557966889513, "timer/agent.report_avg": 0.2374821901321411, "timer/agent.report_min": 0.23036456108093262, "timer/agent.report_max": 0.2445998191833496, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.6464462280273438e-05, "timer/dataset_eval_frac": 2.646398401344962e-08, "timer/dataset_eval_avg": 2.6464462280273438e-05, "timer/dataset_eval_min": 2.6464462280273438e-05, "timer/dataset_eval_max": 2.6464462280273438e-05, "fps": 7.79974442346702}
{"step": 634056, "time": 81366.16598439217, "episode/length": 297.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9798657718120806, "episode/intrinsic_return": 0.0}
{"step": 634520, "time": 81421.49152994156, "episode/length": 166.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9640718562874252, "episode/intrinsic_return": 0.0}
{"step": 634592, "time": 81431.6357755661, "episode/length": 273.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9963503649635036, "episode/intrinsic_return": 0.0}
{"step": 634904, "time": 81469.98629760742, "episode/length": 225.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 635016, "time": 81484.87364196777, "episode/length": 200.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 635256, "time": 81514.34656333923, "episode/length": 273.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9744525547445255, "episode/intrinsic_return": 0.0}
{"step": 635312, "time": 81522.2871890068, "episode/length": 249.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 635400, "time": 81533.9439034462, "episode/length": 274.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 635560, "time": 81554.17322564125, "episode/length": 187.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 636080, "time": 81616.23873710632, "episode/length": 194.0, "episode/score": 9.1000000461936, "episode/reward_rate": 0.9692307692307692, "episode/intrinsic_return": 0.0}
{"step": 636216, "time": 81633.40521025658, "episode/length": 163.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 636352, "time": 81650.80636453629, "episode/length": 219.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 636424, "time": 81660.60582637787, "episode/length": 175.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 636728, "time": 81697.50974488258, "episode/length": 145.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 637032, "time": 81734.41372489929, "episode/length": 214.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 637088, "time": 81742.36894512177, "episode/length": 210.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9620853080568721, "episode/intrinsic_return": 0.0}
{"step": 637304, "time": 81768.99699616432, "episode/length": 255.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.99609375, "episode/intrinsic_return": 0.0}
{"step": 637472, "time": 81790.03838896751, "episode/length": 156.0, "episode/score": 8.100000031292439, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 638000, "time": 81853.6395251751, "episode/length": 196.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9847715736040609, "episode/intrinsic_return": 0.0}
{"step": 638120, "time": 81868.95393490791, "episode/length": 254.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 638320, "time": 81893.73659086227, "episode/length": 198.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 638520, "time": 81918.6215980053, "episode/length": 185.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 638632, "time": 81933.13975739479, "episode/length": 192.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 638736, "time": 81946.73323392868, "episode/length": 178.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 638776, "time": 81952.89929008484, "episode/length": 302.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9966996699669967, "episode/intrinsic_return": 0.0}
{"step": 638856, "time": 81963.65674996376, "episode/length": 41.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 639192, "time": 82005.47459769249, "episode/length": 214.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9720930232558139, "episode/intrinsic_return": 0.0}
{"step": 639464, "time": 82038.7317636013, "episode/length": 167.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 639712, "time": 82069.0131881237, "episode/length": 173.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 639840, "time": 82085.39219713211, "episode/length": 150.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 639976, "time": 82103.05519986153, "episode/length": 154.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 640016, "time": 82130.8806385994, "eval_episode/length": 163.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9939024390243902}
{"step": 640016, "time": 82132.61514210701, "eval_episode/length": 168.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9763313609467456}
{"step": 640016, "time": 82134.38718342781, "eval_episode/length": 174.0, "eval_episode/score": 11.099999964237213, "eval_episode/reward_rate": 0.9771428571428571}
{"step": 640016, "time": 82136.09639048576, "eval_episode/length": 178.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9553072625698324}
{"step": 640016, "time": 82138.11931371689, "eval_episode/length": 191.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.96875}
{"step": 640016, "time": 82139.85547971725, "eval_episode/length": 198.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.9798994974874372}
{"step": 640016, "time": 82141.54900193214, "eval_episode/length": 202.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9753694581280788}
{"step": 640016, "time": 82144.11319494247, "eval_episode/length": 231.0, "eval_episode/score": 9.099999979138374, "eval_episode/reward_rate": 0.9913793103448276}
{"step": 640248, "time": 82171.04699540138, "episode/length": 280.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.99644128113879, "episode/intrinsic_return": 0.0}
{"step": 640304, "time": 82179.04442691803, "episode/length": 104.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9619047619047619, "episode/intrinsic_return": 0.0}
{"step": 640736, "time": 82230.79966020584, "episode/length": 192.0, "episode/score": 9.099999964237213, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 640768, "time": 82236.5583331585, "episode/length": 131.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9924242424242424, "episode/intrinsic_return": 0.0}
{"step": 641200, "time": 82289.11553192139, "episode/length": 169.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 641232, "time": 82294.31366038322, "episode/length": 296.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9966329966329966, "episode/intrinsic_return": 0.0}
{"step": 641376, "time": 82312.67174100876, "episode/length": 133.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9925373134328358, "episode/intrinsic_return": 0.0}
{"step": 641448, "time": 82322.53011775017, "episode/length": 183.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 641528, "time": 82333.84230995178, "episode/length": 159.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 641773, "time": 82365.38895845413, "train_stats/sum_log_reward": 9.075000250339508, "train_stats/max_log_achievement_collect_coal": 0.85, "train_stats/max_log_achievement_collect_drink": 2.725, "train_stats/max_log_achievement_collect_sapling": 1.175, "train_stats/max_log_achievement_collect_stone": 15.425, "train_stats/max_log_achievement_collect_wood": 6.05, "train_stats/max_log_achievement_defeat_skeleton": 0.025, "train_stats/max_log_achievement_defeat_zombie": 0.45, "train_stats/max_log_achievement_eat_cow": 0.05, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.3, "train_stats/max_log_achievement_make_wood_sword": 0.025, "train_stats/max_log_achievement_place_furnace": 2.35, "train_stats/max_log_achievement_place_plant": 1.125, "train_stats/max_log_achievement_place_stone": 3.775, "train_stats/max_log_achievement_place_table": 2.025, "train_stats/max_log_achievement_wake_up": 1.7, "train_stats/mean_log_entropy": 0.4270635686814785, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.391749248603465, "train/action_min": 0.0, "train/action_std": 3.060146190959555, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04343315507309425, "train/actor_opt_grad_steps": 159090.0, "train/actor_opt_loss": -10.855825273020898, "train/adv_mag": 0.4508425392635128, "train/adv_max": 0.4280820252672996, "train/adv_mean": 0.0030204461515160913, "train/adv_min": -0.36935704792101764, "train/adv_std": 0.05501620712752787, "train/cont_avg": 0.9948338325777202, "train/cont_loss_mean": 9.041023082265709e-05, "train/cont_loss_std": 0.002749895585631649, "train/cont_neg_acc": 0.9970207254503675, "train/cont_neg_loss": 0.017371811215669396, "train/cont_pos_acc": 0.999999978381735, "train/cont_pos_loss": 1.812568637887151e-05, "train/cont_pred": 0.9948355885984984, "train/cont_rate": 0.9948338325777202, "train/dyn_loss_mean": 7.056295686435205, "train/dyn_loss_std": 8.97497637901899, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0887062864600068, "train/extr_critic_critic_opt_grad_steps": 159090.0, "train/extr_critic_critic_opt_loss": 17008.27649874514, "train/extr_critic_mag": 8.93425808545839, "train/extr_critic_max": 8.93425808545839, "train/extr_critic_mean": 1.9160295965758012, "train/extr_critic_min": -0.5471210584739329, "train/extr_critic_std": 2.0743103231173103, "train/extr_return_normed_mag": 1.5318150304142057, "train/extr_return_normed_max": 1.5318150304142057, "train/extr_return_normed_mean": 0.32502889880244595, "train/extr_return_normed_min": -0.10285776471381361, "train/extr_return_normed_std": 0.3220584924511341, "train/extr_return_rate": 0.6502024302828497, "train/extr_return_raw_mag": 9.85115058187376, "train/extr_return_raw_max": 9.85115058187376, "train/extr_return_raw_mean": 1.9358407024274835, "train/extr_return_raw_min": -0.8707488330534703, "train/extr_return_raw_std": 2.112467951107519, "train/extr_reward_mag": 1.0463090115878249, "train/extr_reward_max": 1.0463090115878249, "train/extr_reward_mean": 0.04542253855519344, "train/extr_reward_min": -0.6974804673170178, "train/extr_reward_std": 0.20799714164721533, "train/image_loss_mean": 3.7854092429956623, "train/image_loss_std": 8.848827275587487, "train/model_loss_mean": 8.071720778015612, "train/model_loss_std": 13.001821305467674, "train/model_opt_grad_norm": 34.9708072731532, "train/model_opt_grad_steps": 158956.64248704663, "train/model_opt_loss": 14107.50537615366, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1748.7046632124352, "train/policy_entropy_mag": 2.6640545012419707, "train/policy_entropy_max": 2.6640545012419707, "train/policy_entropy_mean": 0.472842240580623, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6686381567945134, "train/policy_logprob_mag": 7.43838415985898, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.47191643004590367, "train/policy_logprob_min": -7.43838415985898, "train/policy_logprob_std": 1.0836635324621449, "train/policy_randomness_mag": 0.9402943299842005, "train/policy_randomness_max": 0.9402943299842005, "train/policy_randomness_mean": 0.16689256069110464, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.2359999262298327, "train/post_ent_mag": 59.56628475288036, "train/post_ent_max": 59.56628475288036, "train/post_ent_mean": 42.97087035895629, "train/post_ent_min": 19.516437318040918, "train/post_ent_std": 6.920446119160232, "train/prior_ent_mag": 75.97317647192763, "train/prior_ent_max": 75.97317647192763, "train/prior_ent_mean": 50.085303746356864, "train/prior_ent_min": 30.152591774500713, "train/prior_ent_std": 7.415668623435065, "train/rep_loss_mean": 7.056295686435205, "train/rep_loss_std": 8.97497637901899, "train/reward_avg": 0.03488048480659569, "train/reward_loss_mean": 0.052443725399557176, "train/reward_loss_std": 0.21406431812696505, "train/reward_max_data": 1.020725393542354, "train/reward_max_pred": 1.0205436389063307, "train/reward_neg_acc": 0.9942817091941833, "train/reward_neg_loss": 0.023970265004185507, "train/reward_pos_acc": 0.9860669374465942, "train/reward_pos_loss": 0.7475427744302108, "train/reward_pred": 0.03447747754097139, "train/reward_rate": 0.03958367066062176, "eval_stats/sum_log_reward": 9.225000321865082, "eval_stats/max_log_achievement_collect_coal": 1.125, "eval_stats/max_log_achievement_collect_drink": 1.875, "eval_stats/max_log_achievement_collect_sapling": 1.25, "eval_stats/max_log_achievement_collect_stone": 11.375, "eval_stats/max_log_achievement_collect_wood": 6.5, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.5, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 1.625, "eval_stats/max_log_achievement_place_plant": 1.125, "eval_stats/max_log_achievement_place_stone": 4.0, "eval_stats/max_log_achievement_place_table": 2.5, "eval_stats/max_log_achievement_wake_up": 1.875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.00016095385944936424, "report/cont_loss_std": 0.005086464807391167, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00011109094339190051, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.00016119852080009878, "report/cont_pred": 0.9949696063995361, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 5.915732383728027, "report/dyn_loss_std": 9.158232688903809, "report/image_loss_mean": 4.04264497756958, "report/image_loss_std": 9.714313507080078, "report/model_loss_mean": 7.634364128112793, "report/model_loss_std": 14.080368041992188, "report/post_ent_mag": 58.59537124633789, "report/post_ent_max": 58.59537124633789, "report/post_ent_mean": 43.87874221801758, "report/post_ent_min": 19.334285736083984, "report/post_ent_std": 6.928345203399658, "report/prior_ent_mag": 75.8939208984375, "report/prior_ent_max": 75.8939208984375, "report/prior_ent_mean": 49.68260955810547, "report/prior_ent_min": 32.71867752075195, "report/prior_ent_std": 7.310364723205566, "report/rep_loss_mean": 5.915732383728027, "report/rep_loss_std": 9.158232688903809, "report/reward_avg": 0.0244140625, "report/reward_loss_mean": 0.04211860150098801, "report/reward_loss_std": 0.17901167273521423, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.1177620887756348, "report/reward_neg_acc": 0.9959757924079895, "report/reward_neg_loss": 0.01995379477739334, "report/reward_pos_acc": 0.9666666984558105, "report/reward_pos_loss": 0.7765125632286072, "report/reward_pred": 0.02328379452228546, "report/reward_rate": 0.029296875, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.0018726229900494218, "eval/cont_loss_std": 0.056323111057281494, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0010391760151833296, "eval/cont_pos_acc": 0.9990195631980896, "eval/cont_pos_loss": 0.0018758914666250348, "eval/cont_pred": 0.9951777458190918, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 21.34634780883789, "eval/dyn_loss_std": 13.909671783447266, "eval/image_loss_mean": 18.682640075683594, "eval/image_loss_std": 20.621292114257812, "eval/model_loss_mean": 31.655929565429688, "eval/model_loss_std": 26.648286819458008, "eval/post_ent_mag": 57.203941345214844, "eval/post_ent_max": 57.203941345214844, "eval/post_ent_mean": 38.987754821777344, "eval/post_ent_min": 21.807193756103516, "eval/post_ent_std": 7.08992338180542, "eval/prior_ent_mag": 75.8939208984375, "eval/prior_ent_max": 75.8939208984375, "eval/prior_ent_mean": 52.995975494384766, "eval/prior_ent_min": 38.8199577331543, "eval/prior_ent_std": 6.00295877456665, "eval/rep_loss_mean": 21.34634780883789, "eval/rep_loss_std": 13.909671783447266, "eval/reward_avg": 0.05625000223517418, "eval/reward_loss_mean": 0.1636073887348175, "eval/reward_loss_std": 0.8207231760025024, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 0.999990701675415, "eval/reward_neg_acc": 0.9875389933586121, "eval/reward_neg_loss": 0.048573534935712814, "eval/reward_pos_acc": 0.8032787442207336, "eval/reward_pos_loss": 1.9796336889266968, "eval/reward_pred": 0.04485563188791275, "eval/reward_rate": 0.0595703125, "replay/size": 641269.0, "replay/inserts": 7728.0, "replay/samples": 30912.0, "replay/insert_wait_avg": 1.5615367988128347e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.438934244230914e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 1856.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1789901503201189e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.046627044677734e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3689744472504, "timer/env.step_count": 966.0, "timer/env.step_total": 89.3443672657013, "timer/env.step_frac": 0.08931141363622172, "timer/env.step_avg": 0.09248899302867629, "timer/env.step_min": 0.0236818790435791, "timer/env.step_max": 2.1053731441497803, "timer/replay._sample_count": 30912.0, "timer/replay._sample_total": 15.073525667190552, "timer/replay._sample_frac": 0.01506796597277456, "timer/replay._sample_avg": 0.00048762699492723056, "timer/replay._sample_min": 0.000362396240234375, "timer/replay._sample_max": 0.019914865493774414, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1198.0, "timer/agent.policy_total": 18.874274969100952, "timer/agent.policy_frac": 0.018867313412563452, "timer/agent.policy_avg": 0.01575482050843151, "timer/agent.policy_min": 0.009439706802368164, "timer/agent.policy_max": 0.05073904991149902, "timer/dataset_train_count": 1932.0, "timer/dataset_train_total": 0.2925093173980713, "timer/dataset_train_frac": 0.0002924014287425258, "timer/dataset_train_avg": 0.00015140233819775945, "timer/dataset_train_min": 9.226799011230469e-05, "timer/dataset_train_max": 0.0009338855743408203, "timer/agent.train_count": 1932.0, "timer/agent.train_total": 858.1416342258453, "timer/agent.train_frac": 0.8578251186768441, "timer/agent.train_avg": 0.44417268852269426, "timer/agent.train_min": 0.4317770004272461, "timer/agent.train_max": 0.969231367111206, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4795403480529785, "timer/agent.report_frac": 0.0004793634751796921, "timer/agent.report_avg": 0.23977017402648926, "timer/agent.report_min": 0.23206400871276855, "timer/agent.report_max": 0.24747633934020996, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0279159545898438e-05, "timer/dataset_eval_frac": 3.026799143049099e-08, "timer/dataset_eval_avg": 3.0279159545898438e-05, "timer/dataset_eval_min": 3.0279159545898438e-05, "timer/dataset_eval_max": 3.0279159545898438e-05, "fps": 7.725038701152785}
{"step": 641960, "time": 82387.0633096695, "episode/length": 397.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9974874371859297, "episode/intrinsic_return": 0.0}
{"step": 642056, "time": 82399.97067213058, "episode/length": 160.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 642128, "time": 82409.86746311188, "episode/length": 173.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 642384, "time": 82441.12203359604, "episode/length": 106.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9532710280373832, "episode/intrinsic_return": 0.0}
{"step": 642552, "time": 82462.22088360786, "episode/length": 146.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9659863945578231, "episode/intrinsic_return": 0.0}
{"step": 643064, "time": 82523.18427324295, "episode/length": 228.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9781659388646288, "episode/intrinsic_return": 0.0}
{"step": 643144, "time": 82533.92579340935, "episode/length": 147.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 643472, "time": 82574.2847726345, "episode/length": 252.0, "episode/score": 9.099999964237213, "episode/reward_rate": 0.9841897233201581, "episode/intrinsic_return": 0.0}
{"step": 643520, "time": 82581.21343111992, "episode/length": 182.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 643592, "time": 82591.04089045525, "episode/length": 182.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 644208, "time": 82663.91960024834, "episode/length": 132.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9924812030075187, "episode/intrinsic_return": 0.0}
{"step": 644224, "time": 82667.15954971313, "episode/length": 208.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 644360, "time": 82684.31276750565, "episode/length": 246.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9878542510121457, "episode/intrinsic_return": 0.0}
{"step": 644424, "time": 82693.32733106613, "episode/length": 169.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 644688, "time": 82725.28782463074, "episode/length": 435.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 644896, "time": 82751.03829836845, "episode/length": 177.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 645824, "time": 82859.98336100578, "episode/length": 141.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 645904, "time": 82870.87910795212, "episode/length": 288.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9965397923875432, "episode/intrinsic_return": 0.0}
{"step": 645952, "time": 82877.90460968018, "episode/length": 215.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 645960, "time": 82880.43185043335, "episode/length": 304.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9770491803278688, "episode/intrinsic_return": 0.0}
{"step": 646120, "time": 82900.6381418705, "episode/length": 211.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9716981132075472, "episode/intrinsic_return": 0.0}
{"step": 646448, "time": 82939.96298670769, "episode/length": 260.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9808429118773946, "episode/intrinsic_return": 0.0}
{"step": 647088, "time": 83015.67177557945, "episode/length": 359.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9888888888888889, "episode/intrinsic_return": 0.0}
{"step": 647248, "time": 83036.94492387772, "episode/length": 177.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 647592, "time": 83078.36469888687, "episode/length": 204.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 647656, "time": 83087.87018823624, "episode/length": 150.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 647672, "time": 83091.1971771717, "episode/length": 220.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 647760, "time": 83102.93117594719, "episode/length": 224.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.0}
{"step": 647784, "time": 83107.1450510025, "episode/length": 360.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9944598337950139, "episode/intrinsic_return": 0.0}
{"step": 648080, "time": 83143.34957265854, "episode/length": 50.0, "episode/score": 2.0999999940395355, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 648232, "time": 83163.14803886414, "episode/length": 58.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 648296, "time": 83172.1286084652, "episode/length": 150.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 649008, "time": 83255.85449433327, "episode/length": 176.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 649136, "time": 83272.24274301529, "episode/length": 235.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 649328, "time": 83295.99675989151, "episode/length": 192.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 649368, "time": 83302.26908826828, "episode/length": 213.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 649616, "time": 83332.43978023529, "episode/length": 436.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9794050343249427, "episode/intrinsic_return": 0.0}
{"step": 649648, "time": 83337.6132876873, "episode/length": 176.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9661016949152542, "episode/intrinsic_return": 0.0}
{"step": 649869, "time": 83365.59243392944, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.447201568301361, "train/action_min": 0.0, "train/action_std": 3.1108458750318775, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04362178178928276, "train/actor_opt_grad_steps": 161065.0, "train/actor_opt_loss": -11.53943911390287, "train/adv_mag": 0.44485420977125073, "train/adv_max": 0.4103907233122552, "train/adv_mean": 0.002788131691800973, "train/adv_min": -0.3835129623513411, "train/adv_std": 0.05469815077094158, "train/cont_avg": 0.9949914913366337, "train/cont_loss_mean": 0.00022431131110166273, "train/cont_loss_std": 0.006906671377434199, "train/cont_neg_acc": 0.9897277234214368, "train/cont_neg_loss": 0.04275979222488291, "train/cont_pos_acc": 0.9999902437228968, "train/cont_pos_loss": 3.59946303516544e-05, "train/cont_pred": 0.9950042620743855, "train/cont_rate": 0.9949914913366337, "train/dyn_loss_mean": 7.028420514399462, "train/dyn_loss_std": 8.962042256156996, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0668694908075993, "train/extr_critic_critic_opt_grad_steps": 161065.0, "train/extr_critic_critic_opt_loss": 16837.23388671875, "train/extr_critic_mag": 8.972053381476071, "train/extr_critic_max": 8.972053381476071, "train/extr_critic_mean": 1.9948312899853924, "train/extr_critic_min": -0.5463939421247728, "train/extr_critic_std": 2.1014015550660616, "train/extr_return_normed_mag": 1.5254670995296817, "train/extr_return_normed_max": 1.5254670995296817, "train/extr_return_normed_mean": 0.33395659525205595, "train/extr_return_normed_min": -0.1012971729113914, "train/extr_return_normed_std": 0.3234241980284748, "train/extr_return_rate": 0.6591120384412237, "train/extr_return_raw_mag": 9.890053621613154, "train/extr_return_raw_max": 9.890053621613154, "train/extr_return_raw_mean": 2.0132602506344863, "train/extr_return_raw_min": -0.8643376145622518, "train/extr_return_raw_std": 2.1381542523308554, "train/extr_reward_mag": 1.0523593201495633, "train/extr_reward_max": 1.0523593201495633, "train/extr_reward_mean": 0.046528554982551845, "train/extr_reward_min": -0.6942517072847574, "train/extr_reward_std": 0.2104746956046265, "train/image_loss_mean": 3.7097372772670028, "train/image_loss_std": 8.528751226935055, "train/model_loss_mean": 7.9788868120401215, "train/model_loss_std": 12.682168540388052, "train/model_opt_grad_norm": 35.9340997572562, "train/model_opt_grad_steps": 160930.55940594058, "train/model_opt_loss": 14103.769615853187, "train/model_opt_model_opt_grad_overflow": 0.0049504950495049506, "train/model_opt_model_opt_grad_scale": 1757.4257425742574, "train/policy_entropy_mag": 2.6822148408039963, "train/policy_entropy_max": 2.6822148408039963, "train/policy_entropy_mean": 0.494558052851422, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6934875739683019, "train/policy_logprob_mag": 7.438384167038568, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.49461395994271384, "train/policy_logprob_min": -7.438384167038568, "train/policy_logprob_std": 1.1033045622971978, "train/policy_randomness_mag": 0.9467041339024459, "train/policy_randomness_max": 0.9467041339024459, "train/policy_randomness_mean": 0.1745572911188154, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.244770679290932, "train/post_ent_mag": 59.63043717110511, "train/post_ent_max": 59.63043717110511, "train/post_ent_mean": 43.0265011740203, "train/post_ent_min": 19.899173996236065, "train/post_ent_std": 6.927964328539254, "train/prior_ent_mag": 75.98790740966797, "train/prior_ent_max": 75.98790740966797, "train/prior_ent_mean": 50.120069824823055, "train/prior_ent_min": 30.112457294275266, "train/prior_ent_std": 7.355545445243911, "train/rep_loss_mean": 7.028420514399462, "train/rep_loss_std": 8.962042256156996, "train/reward_avg": 0.03608156698709815, "train/reward_loss_mean": 0.05187293560714415, "train/reward_loss_std": 0.20906671682501785, "train/reward_max_data": 1.0217821834110978, "train/reward_max_pred": 1.0191455689987334, "train/reward_neg_acc": 0.9941330847173634, "train/reward_neg_loss": 0.02279624147893916, "train/reward_pos_acc": 0.9877080412784426, "train/reward_pos_loss": 0.7410577045808925, "train/reward_pred": 0.03570561936254253, "train/reward_rate": 0.04056118502475248, "train_stats/sum_log_reward": 8.62631607055664, "train_stats/max_log_achievement_collect_coal": 0.6578947368421053, "train_stats/max_log_achievement_collect_drink": 3.789473684210526, "train_stats/max_log_achievement_collect_sapling": 1.2894736842105263, "train_stats/max_log_achievement_collect_stone": 11.789473684210526, "train_stats/max_log_achievement_collect_wood": 5.815789473684211, "train_stats/max_log_achievement_defeat_skeleton": 0.02631578947368421, "train_stats/max_log_achievement_defeat_zombie": 0.23684210526315788, "train_stats/max_log_achievement_eat_cow": 0.02631578947368421, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.394736842105263, "train_stats/max_log_achievement_make_wood_sword": 0.02631578947368421, "train_stats/max_log_achievement_place_furnace": 1.8157894736842106, "train_stats/max_log_achievement_place_plant": 1.263157894736842, "train_stats/max_log_achievement_place_stone": 3.6315789473684212, "train_stats/max_log_achievement_place_table": 1.9210526315789473, "train_stats/max_log_achievement_wake_up": 2.236842105263158, "train_stats/mean_log_entropy": 0.5421489759495384, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 6.238691639737226e-06, "report/cont_loss_std": 3.23112981277518e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 5.3059311539982446e-06, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 6.245111762837041e-06, "report/cont_pred": 0.9931578636169434, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 7.459648132324219, "report/dyn_loss_std": 9.580146789550781, "report/image_loss_mean": 4.599618911743164, "report/image_loss_std": 9.89189338684082, "report/model_loss_mean": 9.131217956542969, "report/model_loss_std": 14.060247421264648, "report/post_ent_mag": 61.16606140136719, "report/post_ent_max": 61.16606140136719, "report/post_ent_mean": 43.622352600097656, "report/post_ent_min": 19.729961395263672, "report/post_ent_std": 7.028459072113037, "report/prior_ent_mag": 76.45370483398438, "report/prior_ent_max": 76.45370483398438, "report/prior_ent_mean": 50.930110931396484, "report/prior_ent_min": 31.137874603271484, "report/prior_ent_std": 7.810451984405518, "report/rep_loss_mean": 7.459648132324219, "report/rep_loss_std": 9.580146789550781, "report/reward_avg": 0.03554687649011612, "report/reward_loss_mean": 0.05580359697341919, "report/reward_loss_std": 0.20377294719219208, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0010011196136475, "report/reward_neg_acc": 0.9918534159660339, "report/reward_neg_loss": 0.027174199000000954, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.725186288356781, "report/reward_pred": 0.03438539057970047, "report/reward_rate": 0.041015625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 7.12717201167834e-06, "eval/cont_loss_std": 8.917366358218715e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 5.845934992976254e-06, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 7.1321960604109336e-06, "eval/cont_pred": 0.9960867166519165, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 16.495283126831055, "eval/dyn_loss_std": 12.681715965270996, "eval/image_loss_mean": 13.079078674316406, "eval/image_loss_std": 14.481149673461914, "eval/model_loss_mean": 23.123268127441406, "eval/model_loss_std": 20.078874588012695, "eval/post_ent_mag": 60.71247863769531, "eval/post_ent_max": 60.71247863769531, "eval/post_ent_mean": 41.77863311767578, "eval/post_ent_min": 19.09404182434082, "eval/post_ent_std": 7.38160514831543, "eval/prior_ent_mag": 76.45370483398438, "eval/prior_ent_max": 76.45370483398438, "eval/prior_ent_mean": 53.23712921142578, "eval/prior_ent_min": 36.54857635498047, "eval/prior_ent_std": 6.933104038238525, "eval/rep_loss_mean": 16.495283126831055, "eval/rep_loss_std": 12.681715965270996, "eval/reward_avg": 0.04130859300494194, "eval/reward_loss_mean": 0.14701411128044128, "eval/reward_loss_std": 0.9433760046958923, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9999802112579346, "eval/reward_neg_acc": 0.9907975196838379, "eval/reward_neg_loss": 0.03258313611149788, "eval/reward_pos_acc": 0.717391312122345, "eval/reward_pos_loss": 2.57991623878479, "eval/reward_pred": 0.03111443854868412, "eval/reward_rate": 0.044921875, "replay/size": 649365.0, "replay/inserts": 8096.0, "replay/samples": 32384.0, "replay/insert_wait_avg": 1.526956737277065e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.420837172406464e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 9.387731552124023e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1874225139618, "timer/env.step_count": 1012.0, "timer/env.step_total": 85.0272045135498, "timer/env.step_frac": 0.08501127148733256, "timer/env.step_avg": 0.08401897679204526, "timer/env.step_min": 0.022980451583862305, "timer/env.step_max": 2.127794027328491, "timer/replay._sample_count": 32384.0, "timer/replay._sample_total": 15.789063930511475, "timer/replay._sample_frac": 0.01578610525897817, "timer/replay._sample_avg": 0.00048755755714277035, "timer/replay._sample_min": 0.00040602684020996094, "timer/replay._sample_max": 0.00954580307006836, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1012.0, "timer/agent.policy_total": 16.099977016448975, "timer/agent.policy_frac": 0.016096960083722942, "timer/agent.policy_avg": 0.01590906819807211, "timer/agent.policy_min": 0.009778738021850586, "timer/agent.policy_max": 0.07710385322570801, "timer/dataset_train_count": 2024.0, "timer/dataset_train_total": 0.4371159076690674, "timer/dataset_train_frac": 0.00043703399765853947, "timer/dataset_train_avg": 0.00021596635754400563, "timer/dataset_train_min": 8.96453857421875e-05, "timer/dataset_train_max": 0.11063504219055176, "timer/agent.train_count": 2024.0, "timer/agent.train_total": 895.7157461643219, "timer/agent.train_frac": 0.8955479003254697, "timer/agent.train_avg": 0.4425473054171551, "timer/agent.train_min": 0.4236717224121094, "timer/agent.train_max": 0.938983678817749, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47754669189453125, "timer/agent.report_frac": 0.0004774572056647364, "timer/agent.report_avg": 0.23877334594726562, "timer/agent.report_min": 0.23343658447265625, "timer/agent.report_max": 0.244110107421875, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.4557113647460938e-05, "timer/dataset_eval_frac": 2.4552511953946453e-08, "timer/dataset_eval_avg": 2.4557113647460938e-05, "timer/dataset_eval_min": 2.4557113647460938e-05, "timer/dataset_eval_max": 2.4557113647460938e-05, "fps": 8.094359237527565}
{"step": 650000, "time": 83398.43280625343, "eval_episode/length": 133.0, "eval_episode/score": 10.099999994039536, "eval_episode/reward_rate": 0.9925373134328358}
{"step": 650000, "time": 83401.19357585907, "eval_episode/length": 166.0, "eval_episode/score": 8.099999971687794, "eval_episode/reward_rate": 0.9940119760479041}
{"step": 650000, "time": 83403.34125351906, "eval_episode/length": 181.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9945054945054945}
{"step": 650000, "time": 83405.72494602203, "eval_episode/length": 201.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9702970297029703}
{"step": 650000, "time": 83408.79993104935, "eval_episode/length": 237.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9873949579831933}
{"step": 650000, "time": 83410.96439099312, "eval_episode/length": 251.0, "eval_episode/score": 11.100000008940697, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 650000, "time": 83413.31239438057, "eval_episode/length": 269.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9814814814814815}
{"step": 650000, "time": 83415.39944028854, "eval_episode/length": 149.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.96}
{"step": 650240, "time": 83443.36575889587, "episode/length": 269.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9740740740740741, "episode/intrinsic_return": 0.0}
{"step": 650368, "time": 83459.89298081398, "episode/length": 124.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.992, "episode/intrinsic_return": 0.0}
{"step": 650696, "time": 83499.46989417076, "episode/length": 210.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9715639810426541, "episode/intrinsic_return": 0.0}
{"step": 650784, "time": 83511.2929944992, "episode/length": 205.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 650824, "time": 83517.4277112484, "episode/length": 150.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 650936, "time": 83531.918561697, "episode/length": 200.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 651056, "time": 83547.22005081177, "episode/length": 175.0, "episode/score": 9.100000031292439, "episode/reward_rate": 0.9602272727272727, "episode/intrinsic_return": 0.0}
{"step": 651304, "time": 83577.57032394409, "episode/length": 375.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 651672, "time": 83621.84731531143, "episode/length": 162.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 652096, "time": 83672.54447174072, "episode/length": 163.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 652216, "time": 83688.04549622536, "episode/length": 189.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 652456, "time": 83717.48696899414, "episode/length": 189.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 652528, "time": 83727.34040737152, "episode/length": 285.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9965034965034965, "episode/intrinsic_return": 0.0}
{"step": 652928, "time": 83775.37680578232, "episode/length": 58.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 653040, "time": 83789.98790860176, "episode/length": 247.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 653120, "time": 83800.78561472893, "episode/length": 286.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9860627177700348, "episode/intrinsic_return": 0.0}
{"step": 653720, "time": 83872.38893318176, "episode/length": 202.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9802955665024631, "episode/intrinsic_return": 0.0}
{"step": 654016, "time": 83908.45788478851, "episode/length": 338.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9852507374631269, "episode/intrinsic_return": 0.0}
{"step": 654112, "time": 83921.21893692017, "episode/length": 123.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 654232, "time": 83936.63533401489, "episode/length": 251.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.996031746031746, "episode/intrinsic_return": 0.0}
{"step": 654376, "time": 83955.00200390816, "episode/length": 180.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9668508287292817, "episode/intrinsic_return": 0.0}
{"step": 655008, "time": 84030.00521159172, "episode/length": 309.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 655168, "time": 84050.17209792137, "episode/length": 436.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9977116704805492, "episode/intrinsic_return": 0.0}
{"step": 655616, "time": 84105.09286141396, "episode/length": 172.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 655744, "time": 84122.02863359451, "episode/length": 203.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 655776, "time": 84127.26260471344, "episode/length": 219.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 655824, "time": 84134.39205312729, "episode/length": 180.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9668508287292817, "episode/intrinsic_return": 0.0}
{"step": 655872, "time": 84141.37552475929, "episode/length": 107.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9537037037037037, "episode/intrinsic_return": 0.0}
{"step": 656008, "time": 84158.59944987297, "episode/length": 285.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9790209790209791, "episode/intrinsic_return": 0.0}
{"step": 656176, "time": 84179.66079425812, "episode/length": 53.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9259259259259259, "episode/intrinsic_return": 0.0}
{"step": 656488, "time": 84217.68158626556, "episode/length": 430.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9953596287703016, "episode/intrinsic_return": 0.0}
{"step": 656744, "time": 84248.95342516899, "episode/length": 196.0, "episode/score": 9.100000031292439, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 657232, "time": 84308.74206233025, "episode/length": 169.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 657240, "time": 84311.29725050926, "episode/length": 202.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 657360, "time": 84326.7519030571, "episode/length": 197.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 657368, "time": 84329.0954387188, "episode/length": 192.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9689119170984456, "episode/intrinsic_return": 0.0}
{"step": 657408, "time": 84335.25793910027, "episode/length": 82.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9518072289156626, "episode/intrinsic_return": 0.0}
{"step": 657649, "time": 84365.95539903641, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.3911455203325325, "train/action_min": 0.0, "train/action_std": 3.056229920265002, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0436004910331506, "train/actor_opt_grad_steps": 163050.0, "train/actor_opt_loss": -12.24504180365266, "train/adv_mag": 0.46085163003359086, "train/adv_max": 0.42531679089252766, "train/adv_mean": 0.002585280049392261, "train/adv_min": -0.38300355825668725, "train/adv_std": 0.05485376683183205, "train/cont_avg": 0.9946414262820513, "train/cont_loss_mean": 9.980834628293404e-05, "train/cont_loss_std": 0.0029130956505474762, "train/cont_neg_acc": 0.9965811967849731, "train/cont_neg_loss": 0.012095016246931687, "train/cont_pos_acc": 0.9999848637825404, "train/cont_pos_loss": 3.67192187294945e-05, "train/cont_pred": 0.9946402717859317, "train/cont_rate": 0.9946414262820513, "train/dyn_loss_mean": 7.094095758291391, "train/dyn_loss_std": 9.011939386221078, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0650545331148, "train/extr_critic_critic_opt_grad_steps": 163050.0, "train/extr_critic_critic_opt_loss": 16992.182642227563, "train/extr_critic_mag": 9.068336892739321, "train/extr_critic_max": 9.068336892739321, "train/extr_critic_mean": 1.9974079260459312, "train/extr_critic_min": -0.5617903263140948, "train/extr_critic_std": 2.1437189059379773, "train/extr_return_normed_mag": 1.5181783859546367, "train/extr_return_normed_max": 1.5181783859546367, "train/extr_return_normed_mean": 0.3315593848625819, "train/extr_return_normed_min": -0.09864202763598699, "train/extr_return_normed_std": 0.32481168057674015, "train/extr_return_rate": 0.6520666733766214, "train/extr_return_raw_mag": 9.97933714450934, "train/extr_return_raw_max": 9.97933714450934, "train/extr_return_raw_mean": 2.0147478543795074, "train/extr_return_raw_min": -0.8735395228251432, "train/extr_return_raw_std": 2.1805946203378532, "train/extr_reward_mag": 1.058414107102614, "train/extr_reward_max": 1.058414107102614, "train/extr_reward_mean": 0.045847439880554494, "train/extr_reward_min": -0.7019677076584253, "train/extr_reward_std": 0.20904862987689482, "train/image_loss_mean": 3.8438162485758465, "train/image_loss_std": 8.853886618980994, "train/model_loss_mean": 8.153333162650084, "train/model_loss_std": 13.037478574117024, "train/model_opt_grad_norm": 36.17068121494391, "train/model_opt_grad_steps": 162913.3076923077, "train/model_opt_loss": 8196.923528896234, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1012.8205128205128, "train/policy_entropy_mag": 2.6828407984513505, "train/policy_entropy_max": 2.6828407984513505, "train/policy_entropy_mean": 0.4895813138057024, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6828126476361202, "train/policy_logprob_mag": 7.43838415145874, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.4887780155891027, "train/policy_logprob_min": -7.43838415145874, "train/policy_logprob_std": 1.09732477695514, "train/policy_randomness_mag": 0.9469250672902816, "train/policy_randomness_max": 0.9469250672902816, "train/policy_randomness_mean": 0.17280071924130122, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.241002901777243, "train/post_ent_mag": 59.418990501990685, "train/post_ent_max": 59.418990501990685, "train/post_ent_mean": 42.9863035935622, "train/post_ent_min": 19.8206091709626, "train/post_ent_std": 6.852844189374875, "train/prior_ent_mag": 75.90823297745142, "train/prior_ent_max": 75.90823297745142, "train/prior_ent_mean": 50.11974356235602, "train/prior_ent_min": 30.159524712195765, "train/prior_ent_std": 7.396315938998491, "train/rep_loss_mean": 7.094095758291391, "train/rep_loss_std": 9.011939386221078, "train/reward_avg": 0.03524138607944433, "train/reward_loss_mean": 0.05295972084769836, "train/reward_loss_std": 0.208910418397341, "train/reward_max_data": 1.026153852389409, "train/reward_max_pred": 1.0234717735877403, "train/reward_neg_acc": 0.9943355807891259, "train/reward_neg_loss": 0.024323634726878925, "train/reward_pos_acc": 0.9881599083924905, "train/reward_pos_loss": 0.7378977372096135, "train/reward_pred": 0.03482771681096309, "train/reward_rate": 0.04012419871794872, "eval_stats/sum_log_reward": 8.350000143051147, "eval_stats/max_log_achievement_collect_coal": 0.75, "eval_stats/max_log_achievement_collect_drink": 3.125, "eval_stats/max_log_achievement_collect_sapling": 1.125, "eval_stats/max_log_achievement_collect_stone": 17.125, "eval_stats/max_log_achievement_collect_wood": 5.5, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.25, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.5, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 2.625, "eval_stats/max_log_achievement_place_plant": 1.125, "eval_stats/max_log_achievement_place_stone": 3.125, "eval_stats/max_log_achievement_place_table": 1.625, "eval_stats/max_log_achievement_wake_up": 1.875, "eval_stats/mean_log_entropy": 0.0, "train_stats/sum_log_reward": 8.80270292952254, "train_stats/max_log_achievement_collect_coal": 0.7297297297297297, "train_stats/max_log_achievement_collect_drink": 4.378378378378378, "train_stats/max_log_achievement_collect_sapling": 1.4054054054054055, "train_stats/max_log_achievement_collect_stone": 13.35135135135135, "train_stats/max_log_achievement_collect_wood": 6.378378378378378, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.2972972972972973, "train_stats/max_log_achievement_eat_cow": 0.10810810810810811, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.3243243243243243, "train_stats/max_log_achievement_make_wood_sword": 0.02702702702702703, "train_stats/max_log_achievement_place_furnace": 2.0, "train_stats/max_log_achievement_place_plant": 1.2432432432432432, "train_stats/max_log_achievement_place_stone": 4.216216216216216, "train_stats/max_log_achievement_place_table": 2.1621621621621623, "train_stats/max_log_achievement_wake_up": 2.0, "train_stats/mean_log_entropy": 0.49378797573012273, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 4.429951331985649e-06, "report/cont_loss_std": 7.96080130385235e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0006724181585013866, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 4.928893417854852e-07, "report/cont_pred": 0.994144082069397, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 7.367860317230225, "report/dyn_loss_std": 9.121770858764648, "report/image_loss_mean": 4.631529808044434, "report/image_loss_std": 8.776667594909668, "report/model_loss_mean": 9.095098495483398, "report/model_loss_std": 12.8983154296875, "report/post_ent_mag": 59.557125091552734, "report/post_ent_max": 59.557125091552734, "report/post_ent_mean": 42.95713806152344, "report/post_ent_min": 19.887033462524414, "report/post_ent_std": 6.721652507781982, "report/prior_ent_mag": 75.70691680908203, "report/prior_ent_max": 75.70691680908203, "report/prior_ent_mean": 50.23432922363281, "report/prior_ent_min": 29.844165802001953, "report/prior_ent_std": 7.126386642456055, "report/rep_loss_mean": 7.367860317230225, "report/rep_loss_std": 9.121770858764648, "report/reward_avg": 0.02949218824505806, "report/reward_loss_mean": 0.042848747223615646, "report/reward_loss_std": 0.1535215973854065, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.001230239868164, "report/reward_neg_acc": 0.997973620891571, "report/reward_neg_loss": 0.01916639134287834, "report/reward_pos_acc": 0.9999999403953552, "report/reward_pos_loss": 0.6745914816856384, "report/reward_pred": 0.030295569449663162, "report/reward_rate": 0.0361328125, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.00017802520596887916, "eval/cont_loss_std": 0.005224911961704493, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.03026634454727173, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 6.873524398542941e-07, "eval/cont_pred": 0.9943044185638428, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 19.606281280517578, "eval/dyn_loss_std": 12.568781852722168, "eval/image_loss_mean": 18.21623992919922, "eval/image_loss_std": 18.946678161621094, "eval/model_loss_mean": 30.110595703125, "eval/model_loss_std": 23.932798385620117, "eval/post_ent_mag": 56.7356071472168, "eval/post_ent_max": 56.7356071472168, "eval/post_ent_mean": 40.139312744140625, "eval/post_ent_min": 22.818151473999023, "eval/post_ent_std": 6.464277744293213, "eval/prior_ent_mag": 75.70691680908203, "eval/prior_ent_max": 75.70691680908203, "eval/prior_ent_mean": 53.1798095703125, "eval/prior_ent_min": 34.19647979736328, "eval/prior_ent_std": 6.608095169067383, "eval/rep_loss_mean": 19.606281280517578, "eval/rep_loss_std": 12.568781852722168, "eval/reward_avg": 0.04365234822034836, "eval/reward_loss_mean": 0.13040927052497864, "eval/reward_loss_std": 0.659989058971405, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0017871856689453, "eval/reward_neg_acc": 0.989733099937439, "eval/reward_neg_loss": 0.07626274228096008, "eval/reward_pos_acc": 0.8999999761581421, "eval/reward_pos_loss": 1.1851838827133179, "eval/reward_pred": 0.044298332184553146, "eval/reward_rate": 0.048828125, "replay/size": 657145.0, "replay/inserts": 7780.0, "replay/samples": 31120.0, "replay/insert_wait_avg": 1.5304450204255956e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.471266013491123e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 2272.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1031056793642716e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3480634689331, "timer/env.step_count": 973.0, "timer/env.step_total": 81.70390319824219, "timer/env.step_frac": 0.08167547494910464, "timer/env.step_avg": 0.08397112353365076, "timer/env.step_min": 0.022862672805786133, "timer/env.step_max": 1.9253129959106445, "timer/replay._sample_count": 31120.0, "timer/replay._sample_total": 15.210094213485718, "timer/replay._sample_frac": 0.015204801977365035, "timer/replay._sample_avg": 0.0004887562407932429, "timer/replay._sample_min": 0.0004162788391113281, "timer/replay._sample_max": 0.03614091873168945, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1257.0, "timer/agent.policy_total": 19.82270121574402, "timer/agent.policy_frac": 0.01981580405824381, "timer/agent.policy_avg": 0.015769849813638836, "timer/agent.policy_min": 0.009523868560791016, "timer/agent.policy_max": 0.06634330749511719, "timer/dataset_train_count": 1945.0, "timer/dataset_train_total": 0.2852044105529785, "timer/dataset_train_frac": 0.00028510517585645913, "timer/dataset_train_avg": 0.00014663465838199408, "timer/dataset_train_min": 8.96453857421875e-05, "timer/dataset_train_max": 0.0004813671112060547, "timer/agent.train_count": 1945.0, "timer/agent.train_total": 865.3123912811279, "timer/agent.train_frac": 0.8650113124430526, "timer/agent.train_avg": 0.444890689604693, "timer/agent.train_min": 0.4333069324493408, "timer/agent.train_max": 2.0228238105773926, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47829580307006836, "timer/agent.report_frac": 0.0004781293836981795, "timer/agent.report_avg": 0.23914790153503418, "timer/agent.report_min": 0.23234033584594727, "timer/agent.report_max": 0.2459554672241211, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.765655517578125e-05, "timer/dataset_eval_frac": 2.7646932288623513e-08, "timer/dataset_eval_avg": 2.765655517578125e-05, "timer/dataset_eval_min": 2.765655517578125e-05, "timer/dataset_eval_max": 2.765655517578125e-05, "fps": 7.777185380275058}
{"step": 658000, "time": 84407.3128426075, "episode/length": 78.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9240506329113924, "episode/intrinsic_return": 0.0}
{"step": 658016, "time": 84411.38638401031, "episode/length": 229.0, "episode/score": 11.100000016391277, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 658104, "time": 84423.64613723755, "episode/length": 201.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 658592, "time": 84481.97785997391, "episode/length": 169.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9588235294117647, "episode/intrinsic_return": 0.0}
{"step": 658616, "time": 84486.23794007301, "episode/length": 325.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9846625766871165, "episode/intrinsic_return": 0.0}
{"step": 658792, "time": 84508.2756114006, "episode/length": 172.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 659240, "time": 84561.86687207222, "episode/length": 234.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 659376, "time": 84579.15872740746, "episode/length": 171.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9651162790697675, "episode/intrinsic_return": 0.0}
{"step": 659680, "time": 84615.9911262989, "episode/length": 196.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9644670050761421, "episode/intrinsic_return": 0.0}
{"step": 659792, "time": 84630.44779849052, "episode/length": 149.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 659936, "time": 84648.76521158218, "episode/length": 164.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 660088, "time": 84667.89135599136, "episode/length": 355.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9859550561797753, "episode/intrinsic_return": 0.0}
{"step": 660088, "time": 84683.5390048027, "eval_episode/length": 84.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9882352941176471}
{"step": 660088, "time": 84685.37259554863, "eval_episode/length": 92.0, "eval_episode/score": 7.100000023841858, "eval_episode/reward_rate": 0.989247311827957}
{"step": 660088, "time": 84689.38010549545, "eval_episode/length": 158.0, "eval_episode/score": 7.100000023841858, "eval_episode/reward_rate": 0.9937106918238994}
{"step": 660088, "time": 84692.30352663994, "eval_episode/length": 191.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9739583333333334}
{"step": 660088, "time": 84693.91778349876, "eval_episode/length": 193.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9948453608247423}
{"step": 660088, "time": 84696.44576191902, "eval_episode/length": 216.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9769585253456221}
{"step": 660088, "time": 84698.81893491745, "eval_episode/length": 237.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9831932773109243}
{"step": 660088, "time": 84700.57102560997, "eval_episode/length": 83.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9404761904761905}
{"step": 660304, "time": 84727.07718324661, "episode/length": 285.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9790209790209791, "episode/intrinsic_return": 0.0}
{"step": 660600, "time": 84763.74071574211, "episode/length": 169.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 660656, "time": 84772.19826364517, "episode/length": 159.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.95625, "episode/intrinsic_return": 0.0}
{"step": 660824, "time": 84793.15652775764, "episode/length": 253.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9803149606299213, "episode/intrinsic_return": 0.0}
{"step": 661304, "time": 84850.65453338623, "episode/length": 170.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 661400, "time": 84863.29524946213, "episode/length": 200.0, "episode/score": 11.099999964237213, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 661752, "time": 84905.63319683075, "episode/length": 258.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9961389961389961, "episode/intrinsic_return": 0.0}
{"step": 662248, "time": 84965.06536889076, "episode/length": 205.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 662352, "time": 84978.87737441063, "episode/length": 282.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9787985865724381, "episode/intrinsic_return": 0.0}
{"step": 662456, "time": 84992.99613833427, "episode/length": 203.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 662528, "time": 85002.97052788734, "episode/length": 152.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 662744, "time": 85029.49866509438, "episode/length": 167.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 663496, "time": 85118.38145518303, "episode/length": 354.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9943661971830986, "episode/intrinsic_return": 0.0}
{"step": 663544, "time": 85125.60845065117, "episode/length": 126.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9921259842519685, "episode/intrinsic_return": 0.0}
{"step": 663768, "time": 85154.39108037949, "episode/length": 432.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9792147806004619, "episode/intrinsic_return": 0.0}
{"step": 663920, "time": 85173.52598595619, "episode/length": 195.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 663984, "time": 85182.52896547318, "episode/length": 190.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 664160, "time": 85204.47896122932, "episode/length": 176.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 664480, "time": 85243.20933365822, "episode/length": 61.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9354838709677419, "episode/intrinsic_return": 0.0}
{"step": 664624, "time": 85261.37774896622, "episode/length": 358.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9888579387186629, "episode/intrinsic_return": 0.0}
{"step": 664888, "time": 85293.75234341621, "episode/length": 173.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 664896, "time": 85296.78840994835, "episode/length": 168.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 665296, "time": 85345.76387953758, "episode/length": 141.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 665384, "time": 85357.54461193085, "episode/length": 94.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9894736842105263, "episode/intrinsic_return": 0.0}
{"step": 665437, "time": 85366.22613143921, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.46385247646234, "train/action_min": 0.0, "train/action_std": 3.1154767794486804, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.042760170957981014, "train/actor_opt_grad_steps": 165000.0, "train/actor_opt_loss": -11.537320071668962, "train/adv_mag": 0.4349040115490938, "train/adv_max": 0.40631162310257934, "train/adv_mean": 0.0029142575142871536, "train/adv_min": -0.3721597391825456, "train/adv_std": 0.054343753995803684, "train/cont_avg": 0.9948717948717949, "train/cont_loss_mean": 0.00014432069784613933, "train/cont_loss_std": 0.004427911728582027, "train/cont_neg_acc": 0.9973870580012981, "train/cont_neg_loss": 0.012555516701531115, "train/cont_pos_acc": 0.9999748077148046, "train/cont_pos_loss": 7.288660449084534e-05, "train/cont_pred": 0.9948629428178836, "train/cont_rate": 0.9948717948717949, "train/dyn_loss_mean": 7.008248400076842, "train/dyn_loss_std": 8.992316458775447, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0687919775644938, "train/extr_critic_critic_opt_grad_steps": 165000.0, "train/extr_critic_critic_opt_loss": 16918.934545272437, "train/extr_critic_mag": 9.145365671011119, "train/extr_critic_max": 9.145365671011119, "train/extr_critic_mean": 2.030253074108026, "train/extr_critic_min": -0.5453139531306731, "train/extr_critic_std": 2.162468201074845, "train/extr_return_normed_mag": 1.5174169246967022, "train/extr_return_normed_max": 1.5174169246967022, "train/extr_return_normed_mean": 0.3331244551982635, "train/extr_return_normed_min": -0.09333778474575434, "train/extr_return_normed_std": 0.3250252535709968, "train/extr_return_rate": 0.6587984457994118, "train/extr_return_raw_mag": 10.07026205307398, "train/extr_return_raw_max": 10.07026205307398, "train/extr_return_raw_mean": 2.049995743922698, "train/extr_return_raw_min": -0.8380145685795026, "train/extr_return_raw_std": 2.201116316135113, "train/extr_reward_mag": 1.0509628002460187, "train/extr_reward_max": 1.0509628002460187, "train/extr_reward_mean": 0.047321972738091765, "train/extr_reward_min": -0.671439102368477, "train/extr_reward_std": 0.21178183593811134, "train/image_loss_mean": 3.7963571193890693, "train/image_loss_std": 8.900754341712364, "train/model_loss_mean": 8.054433551201454, "train/model_loss_std": 13.064676191867926, "train/model_opt_grad_norm": 36.28699116854324, "train/model_opt_grad_steps": 164862.51794871796, "train/model_opt_loss": 16096.960719651443, "train/model_opt_model_opt_grad_overflow": 0.005128205128205128, "train/model_opt_model_opt_grad_scale": 1993.5897435897436, "train/policy_entropy_mag": 2.6731104288345726, "train/policy_entropy_max": 2.6731104288345726, "train/policy_entropy_mean": 0.5009919687723502, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6978803899043645, "train/policy_logprob_mag": 7.438384134341509, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5008535802364349, "train/policy_logprob_min": -7.438384134341509, "train/policy_logprob_std": 1.108501857977647, "train/policy_randomness_mag": 0.9434906757794894, "train/policy_randomness_max": 0.9434906757794894, "train/policy_randomness_mean": 0.17682817864876527, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.24632115188317422, "train/post_ent_mag": 59.57642740102915, "train/post_ent_max": 59.57642740102915, "train/post_ent_mean": 43.08811170137846, "train/post_ent_min": 19.862990340208395, "train/post_ent_std": 6.921295337187938, "train/prior_ent_mag": 75.84761661627354, "train/prior_ent_max": 75.84761661627354, "train/prior_ent_mean": 50.12937481219952, "train/prior_ent_min": 30.160505607800605, "train/prior_ent_std": 7.400614029321915, "train/rep_loss_mean": 7.008248400076842, "train/rep_loss_std": 8.992316458775447, "train/reward_avg": 0.03570763216568874, "train/reward_loss_mean": 0.05298307965963315, "train/reward_loss_std": 0.2137608052064211, "train/reward_max_data": 1.0241025698490631, "train/reward_max_pred": 1.0223332985853537, "train/reward_neg_acc": 0.9939756494302016, "train/reward_neg_loss": 0.023841602102113075, "train/reward_pos_acc": 0.98562995776152, "train/reward_pos_loss": 0.7483695941093641, "train/reward_pred": 0.03521451256118524, "train/reward_rate": 0.040369591346153845, "train_stats/sum_log_reward": 8.877778000301785, "train_stats/max_log_achievement_collect_coal": 0.75, "train_stats/max_log_achievement_collect_drink": 3.9166666666666665, "train_stats/max_log_achievement_collect_sapling": 1.3611111111111112, "train_stats/max_log_achievement_collect_stone": 13.055555555555555, "train_stats/max_log_achievement_collect_wood": 5.944444444444445, "train_stats/max_log_achievement_defeat_skeleton": 0.027777777777777776, "train_stats/max_log_achievement_defeat_zombie": 0.3611111111111111, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.1388888888888888, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_furnace": 1.8611111111111112, "train_stats/max_log_achievement_place_plant": 1.2777777777777777, "train_stats/max_log_achievement_place_stone": 3.4166666666666665, "train_stats/max_log_achievement_place_table": 2.111111111111111, "train_stats/max_log_achievement_wake_up": 2.0833333333333335, "train_stats/mean_log_entropy": 0.4733542630241977, "eval_stats/sum_log_reward": 6.600000083446503, "eval_stats/max_log_achievement_collect_coal": 0.625, "eval_stats/max_log_achievement_collect_drink": 3.125, "eval_stats/max_log_achievement_collect_sapling": 0.875, "eval_stats/max_log_achievement_collect_stone": 9.0, "eval_stats/max_log_achievement_collect_wood": 4.625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.875, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 1.125, "eval_stats/max_log_achievement_place_plant": 0.875, "eval_stats/max_log_achievement_place_stone": 3.75, "eval_stats/max_log_achievement_place_table": 1.625, "eval_stats/max_log_achievement_wake_up": 1.75, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 4.991115019947756e-06, "report/cont_loss_std": 5.6323420722037554e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 6.834142550360411e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 4.55507552032941e-06, "report/cont_pred": 0.9931600093841553, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 5.602179527282715, "report/dyn_loss_std": 8.555488586425781, "report/image_loss_mean": 2.840979814529419, "report/image_loss_std": 8.744281768798828, "report/model_loss_mean": 6.266229152679443, "report/model_loss_std": 12.63153076171875, "report/post_ent_mag": 60.5839729309082, "report/post_ent_max": 60.5839729309082, "report/post_ent_mean": 42.96775817871094, "report/post_ent_min": 17.507949829101562, "report/post_ent_std": 6.808149337768555, "report/prior_ent_mag": 75.57784271240234, "report/prior_ent_max": 75.57784271240234, "report/prior_ent_mean": 48.3643798828125, "report/prior_ent_min": 31.335521697998047, "report/prior_ent_std": 7.809115886688232, "report/rep_loss_mean": 5.602179527282715, "report/rep_loss_std": 8.555488586425781, "report/reward_avg": 0.03525390475988388, "report/reward_loss_mean": 0.06393654644489288, "report/reward_loss_std": 0.24266228079795837, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0005755424499512, "report/reward_neg_acc": 0.9979633688926697, "report/reward_neg_loss": 0.037846639752388, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6739434599876404, "report/reward_pred": 0.03643941134214401, "report/reward_rate": 0.041015625, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 4.6765911974944174e-05, "eval/cont_loss_std": 0.0007699342095293105, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.004158091265708208, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 3.872026354656555e-05, "eval/cont_pred": 0.9980165958404541, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 21.07758331298828, "eval/dyn_loss_std": 13.21892261505127, "eval/image_loss_mean": 19.06072998046875, "eval/image_loss_std": 20.038379669189453, "eval/model_loss_mean": 31.879247665405273, "eval/model_loss_std": 25.411483764648438, "eval/post_ent_mag": 55.41352462768555, "eval/post_ent_max": 55.41352462768555, "eval/post_ent_mean": 38.87078094482422, "eval/post_ent_min": 18.93490219116211, "eval/post_ent_std": 6.519763946533203, "eval/prior_ent_mag": 75.57784271240234, "eval/prior_ent_max": 75.57784271240234, "eval/prior_ent_mean": 52.378211975097656, "eval/prior_ent_min": 34.38829040527344, "eval/prior_ent_std": 6.520495414733887, "eval/rep_loss_mean": 21.07758331298828, "eval/rep_loss_std": 13.21892261505127, "eval/reward_avg": 0.05048828199505806, "eval/reward_loss_mean": 0.17192120850086212, "eval/reward_loss_std": 0.9264499545097351, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0004994869232178, "eval/reward_neg_acc": 0.9845201969146729, "eval/reward_neg_loss": 0.07243059575557709, "eval/reward_pos_acc": 0.8181818127632141, "eval/reward_pos_loss": 1.9247649908065796, "eval/reward_pred": 0.04905049502849579, "eval/reward_rate": 0.0537109375, "replay/size": 664933.0, "replay/inserts": 7788.0, "replay/samples": 31152.0, "replay/insert_wait_avg": 1.5295770269941537e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.492750806568461e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 1944.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.095449973526315e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.450580596923828e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.258909702301, "timer/env.step_count": 973.0, "timer/env.step_total": 84.02551436424255, "timer/env.step_frac": 0.08400376497446085, "timer/env.step_avg": 0.08635715761998207, "timer/env.step_min": 0.02338695526123047, "timer/env.step_max": 2.210176467895508, "timer/replay._sample_count": 31152.0, "timer/replay._sample_total": 15.276188373565674, "timer/replay._sample_frac": 0.015272234243944102, "timer/replay._sample_avg": 0.0004903758466090676, "timer/replay._sample_min": 0.00038552284240722656, "timer/replay._sample_max": 0.010279178619384766, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1216.0, "timer/agent.policy_total": 19.43917441368103, "timer/agent.policy_frac": 0.019434142725573478, "timer/agent.policy_avg": 0.015986163169145584, "timer/agent.policy_min": 0.009538888931274414, "timer/agent.policy_max": 0.062039852142333984, "timer/dataset_train_count": 1947.0, "timer/dataset_train_total": 0.2915313243865967, "timer/dataset_train_frac": 0.0002914558636357089, "timer/dataset_train_avg": 0.00014973360266389146, "timer/dataset_train_min": 8.988380432128906e-05, "timer/dataset_train_max": 0.0006072521209716797, "timer/agent.train_count": 1947.0, "timer/agent.train_total": 864.7285876274109, "timer/agent.train_frac": 0.8645047589576313, "timer/agent.train_avg": 0.4441338405893225, "timer/agent.train_min": 0.43246889114379883, "timer/agent.train_max": 0.9649522304534912, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4725823402404785, "timer/agent.report_frac": 0.00047246001575844935, "timer/agent.report_avg": 0.23629117012023926, "timer/agent.report_min": 0.22895121574401855, "timer/agent.report_max": 0.24363112449645996, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9802322387695312e-05, "timer/dataset_eval_frac": 2.9794608274536776e-08, "timer/dataset_eval_avg": 2.9802322387695312e-05, "timer/dataset_eval_min": 2.9802322387695312e-05, "timer/dataset_eval_max": 2.9802322387695312e-05, "fps": 7.7858779024630635}
{"step": 665480, "time": 85371.11631059647, "episode/length": 194.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 665792, "time": 85408.85871601105, "episode/length": 442.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9954853273137697, "episode/intrinsic_return": 0.0}
{"step": 665920, "time": 85425.31423687935, "episode/length": 179.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 666152, "time": 85453.8931107521, "episode/length": 297.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9966442953020134, "episode/intrinsic_return": 0.0}
{"step": 666392, "time": 85483.24357485771, "episode/length": 187.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 666728, "time": 85523.9936800003, "episode/length": 167.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 666800, "time": 85534.3979742527, "episode/length": 237.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9747899159663865, "episode/intrinsic_return": 0.0}
{"step": 667032, "time": 85562.88141703606, "episode/length": 154.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 667168, "time": 85580.26987457275, "episode/length": 233.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 667200, "time": 85585.51581811905, "episode/length": 159.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 667232, "time": 85590.74706339836, "episode/length": 218.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 667280, "time": 85597.80591249466, "episode/length": 140.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 668096, "time": 85694.42911028862, "episode/length": 212.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 668168, "time": 85704.36288166046, "episode/length": 170.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9649122807017544, "episode/intrinsic_return": 0.0}
{"step": 668392, "time": 85732.46990895271, "episode/length": 152.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 668672, "time": 85766.51170539856, "episode/length": 204.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 668784, "time": 85781.11669778824, "episode/length": 187.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 668936, "time": 85800.24605822563, "episode/length": 212.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9812206572769953, "episode/intrinsic_return": 0.0}
{"step": 669392, "time": 85854.72850561142, "episode/length": 273.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9817518248175182, "episode/intrinsic_return": 0.0}
{"step": 669464, "time": 85864.56341028214, "episode/length": 341.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9970760233918129, "episode/intrinsic_return": 0.0}
{"step": 669720, "time": 85895.86521673203, "episode/length": 193.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 669856, "time": 85913.2409851551, "episode/length": 219.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 670032, "time": 85935.24628448486, "episode/length": 204.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9804878048780488, "episode/intrinsic_return": 0.0}
{"step": 670072, "time": 85961.71391487122, "eval_episode/length": 151.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9605263157894737}
{"step": 670072, "time": 85963.5863609314, "eval_episode/length": 162.0, "eval_episode/score": 9.100000023841858, "eval_episode/reward_rate": 0.9938650306748467}
{"step": 670072, "time": 85966.07725048065, "eval_episode/length": 186.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9786096256684492}
{"step": 670072, "time": 85967.83699989319, "eval_episode/length": 192.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9948186528497409}
{"step": 670072, "time": 85969.5855846405, "eval_episode/length": 199.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.995}
{"step": 670072, "time": 85971.21656847, "eval_episode/length": 204.0, "eval_episode/score": 10.099999994039536, "eval_episode/reward_rate": 0.9951219512195122}
{"step": 670072, "time": 85974.99692440033, "eval_episode/length": 64.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9230769230769231}
{"step": 670072, "time": 85976.71494317055, "eval_episode/length": 269.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9962962962962963}
{"step": 670104, "time": 85980.42579007149, "episode/length": 178.0, "episode/score": 10.099999964237213, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 670600, "time": 86039.54767346382, "episode/length": 207.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 670832, "time": 86068.06193614006, "episode/length": 138.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9640287769784173, "episode/intrinsic_return": 0.0}
{"step": 670856, "time": 86072.46273970604, "episode/length": 258.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9961389961389961, "episode/intrinsic_return": 0.0}
{"step": 670872, "time": 86075.77391815186, "episode/length": 175.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 671136, "time": 86108.2255256176, "episode/length": 159.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 671368, "time": 86136.60547494888, "episode/length": 166.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 671448, "time": 86147.40053582191, "episode/length": 256.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.980544747081712, "episode/intrinsic_return": 0.0}
{"step": 671816, "time": 86192.858335495, "episode/length": 55.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 671848, "time": 86198.58587265015, "episode/length": 217.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.981651376146789, "episode/intrinsic_return": 0.0}
{"step": 672104, "time": 86229.7624862194, "episode/length": 155.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 672328, "time": 86257.36020994186, "episode/length": 186.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 672528, "time": 86281.9783103466, "episode/length": 88.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9550561797752809, "episode/intrinsic_return": 0.0}
{"step": 672648, "time": 86297.38808250427, "episode/length": 149.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 672680, "time": 86302.69196748734, "episode/length": 225.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 672696, "time": 86306.05055809021, "episode/length": 194.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 673072, "time": 86351.12221932411, "episode/length": 308.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9838187702265372, "episode/intrinsic_return": 0.0}
{"step": 673181, "time": 86366.31027293205, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.512455283051327, "train/action_min": 0.0, "train/action_std": 3.1957438078569007, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.043001661164000865, "train/actor_opt_grad_steps": 166940.0, "train/actor_opt_loss": -12.382686531837123, "train/adv_mag": 0.4408929378875179, "train/adv_max": 0.41144478490933234, "train/adv_mean": 0.0025463792232951936, "train/adv_min": -0.37757180438140514, "train/adv_std": 0.05429815147747648, "train/cont_avg": 0.9949653902202072, "train/cont_loss_mean": 9.117443595792908e-05, "train/cont_loss_std": 0.0027585209234906156, "train/cont_neg_acc": 0.9969282017470641, "train/cont_neg_loss": 0.014006654499907425, "train/cont_pos_acc": 0.9999948872803407, "train/cont_pos_loss": 1.9409848008703724e-05, "train/cont_pred": 0.9949693957758691, "train/cont_rate": 0.9949653902202072, "train/dyn_loss_mean": 7.134874437757107, "train/dyn_loss_std": 8.988222008542076, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0641741310994242, "train/extr_critic_critic_opt_grad_steps": 166940.0, "train/extr_critic_critic_opt_loss": 16865.59861763277, "train/extr_critic_mag": 9.050364509147684, "train/extr_critic_max": 9.050364509147684, "train/extr_critic_mean": 1.9846163469275044, "train/extr_critic_min": -0.538607290371712, "train/extr_critic_std": 2.1196546011020483, "train/extr_return_normed_mag": 1.5160135469288405, "train/extr_return_normed_max": 1.5160135469288405, "train/extr_return_normed_mean": 0.32921356510930727, "train/extr_return_normed_min": -0.09270475031759763, "train/extr_return_normed_std": 0.3212108799676203, "train/extr_return_rate": 0.6576843502607987, "train/extr_return_raw_mag": 9.968430672284853, "train/extr_return_raw_max": 9.968430672284853, "train/extr_return_raw_mean": 2.0017155655925136, "train/extr_return_raw_min": -0.8308655499176658, "train/extr_return_raw_std": 2.1564302920059837, "train/extr_reward_mag": 1.0496239983356062, "train/extr_reward_max": 1.0496239983356062, "train/extr_reward_mean": 0.0465399417254128, "train/extr_reward_min": -0.6825201369320173, "train/extr_reward_std": 0.20983697929530565, "train/image_loss_mean": 3.750895514389394, "train/image_loss_std": 8.690027091169604, "train/model_loss_mean": 8.084013081585187, "train/model_loss_std": 12.866400244322465, "train/model_opt_grad_norm": 34.57215694565847, "train/model_opt_grad_steps": 166800.35751295337, "train/model_opt_loss": 11810.54729244252, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1450.7772020725388, "train/policy_entropy_mag": 2.677818834472814, "train/policy_entropy_max": 2.677818834472814, "train/policy_entropy_mean": 0.5215784053419538, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.7235384517074249, "train/policy_logprob_mag": 7.438384137623051, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5214714383214248, "train/policy_logprob_min": -7.438384137623051, "train/policy_logprob_std": 1.121401250053564, "train/policy_randomness_mag": 0.9451525344132142, "train/policy_randomness_max": 0.9451525344132142, "train/policy_randomness_mean": 0.18409428787972643, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.2553773227442114, "train/post_ent_mag": 59.38419041608899, "train/post_ent_max": 59.38419041608899, "train/post_ent_mean": 42.959900969668375, "train/post_ent_min": 19.629907331318435, "train/post_ent_std": 6.940569230311893, "train/prior_ent_mag": 75.92929009946516, "train/prior_ent_max": 75.92929009946516, "train/prior_ent_mean": 50.12016369518221, "train/prior_ent_min": 30.209879040100414, "train/prior_ent_std": 7.34792137393062, "train/rep_loss_mean": 7.134874437757107, "train/rep_loss_std": 8.988222008542076, "train/reward_avg": 0.03564250699384379, "train/reward_loss_mean": 0.0521017351993625, "train/reward_loss_std": 0.21066118444803464, "train/reward_max_data": 1.0202072587037951, "train/reward_max_pred": 1.0193949962527022, "train/reward_neg_acc": 0.9946087299233274, "train/reward_neg_loss": 0.023134666268226398, "train/reward_pos_acc": 0.9864829797201206, "train/reward_pos_loss": 0.7465104386596482, "train/reward_pred": 0.035159014913354825, "train/reward_rate": 0.040292057966321244, "train_stats/sum_log_reward": 8.775000178813935, "train_stats/max_log_achievement_collect_coal": 0.8, "train_stats/max_log_achievement_collect_drink": 4.725, "train_stats/max_log_achievement_collect_sapling": 1.4, "train_stats/max_log_achievement_collect_stone": 12.225, "train_stats/max_log_achievement_collect_wood": 6.275, "train_stats/max_log_achievement_defeat_skeleton": 0.025, "train_stats/max_log_achievement_defeat_zombie": 0.4, "train_stats/max_log_achievement_eat_cow": 0.075, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.025, "train_stats/max_log_achievement_make_wood_pickaxe": 1.15, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_furnace": 1.925, "train_stats/max_log_achievement_place_plant": 1.3, "train_stats/max_log_achievement_place_stone": 3.075, "train_stats/max_log_achievement_place_table": 2.3, "train_stats/max_log_achievement_wake_up": 2.15, "train_stats/mean_log_entropy": 0.42577729038894174, "eval_stats/sum_log_reward": 9.225000381469727, "eval_stats/max_log_achievement_collect_coal": 1.125, "eval_stats/max_log_achievement_collect_drink": 2.125, "eval_stats/max_log_achievement_collect_sapling": 1.375, "eval_stats/max_log_achievement_collect_stone": 18.125, "eval_stats/max_log_achievement_collect_wood": 5.0, "eval_stats/max_log_achievement_defeat_skeleton": 0.125, "eval_stats/max_log_achievement_defeat_zombie": 0.25, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.25, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 3.25, "eval_stats/max_log_achievement_place_plant": 1.375, "eval_stats/max_log_achievement_place_stone": 2.5, "eval_stats/max_log_achievement_place_table": 1.875, "eval_stats/max_log_achievement_wake_up": 1.75, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 2.1102180198795395e-06, "report/cont_loss_std": 3.3891603379743174e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.5179451793301268e-06, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 2.1142943751328858e-06, "report/cont_pred": 0.9931620359420776, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 6.840963363647461, "report/dyn_loss_std": 8.739887237548828, "report/image_loss_mean": 3.1653096675872803, "report/image_loss_std": 10.108119010925293, "report/model_loss_mean": 7.314713478088379, "report/model_loss_std": 14.280699729919434, "report/post_ent_mag": 60.379032135009766, "report/post_ent_max": 60.379032135009766, "report/post_ent_mean": 43.31555938720703, "report/post_ent_min": 21.978897094726562, "report/post_ent_std": 7.168629169464111, "report/prior_ent_mag": 75.84056091308594, "report/prior_ent_max": 75.84056091308594, "report/prior_ent_mean": 50.40807342529297, "report/prior_ent_min": 31.480791091918945, "report/prior_ent_std": 6.658011436462402, "report/rep_loss_mean": 6.840963363647461, "report/rep_loss_std": 8.739887237548828, "report/reward_avg": 0.02753906138241291, "report/reward_loss_mean": 0.04482376202940941, "report/reward_loss_std": 0.16027726233005524, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.002246618270874, "report/reward_neg_acc": 0.9939393401145935, "report/reward_neg_loss": 0.022463412955403328, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6959044337272644, "report/reward_pred": 0.02761070989072323, "report/reward_rate": 0.033203125, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 9.131244587479159e-05, "eval/cont_loss_std": 0.0028622904792428017, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.09163716435432434, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.824825403673458e-06, "eval/cont_pred": 0.9991071820259094, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 18.03551483154297, "eval/dyn_loss_std": 12.403252601623535, "eval/image_loss_mean": 15.674043655395508, "eval/image_loss_std": 17.678192138671875, "eval/model_loss_mean": 26.609575271606445, "eval/model_loss_std": 22.454315185546875, "eval/post_ent_mag": 59.667274475097656, "eval/post_ent_max": 59.667274475097656, "eval/post_ent_mean": 41.44642639160156, "eval/post_ent_min": 20.68245506286621, "eval/post_ent_std": 7.256227493286133, "eval/prior_ent_mag": 75.84056091308594, "eval/prior_ent_max": 75.84056091308594, "eval/prior_ent_mean": 54.15030288696289, "eval/prior_ent_min": 40.63322448730469, "eval/prior_ent_std": 5.819472789764404, "eval/rep_loss_mean": 18.03551483154297, "eval/rep_loss_std": 12.403252601623535, "eval/reward_avg": 0.04326171800494194, "eval/reward_loss_mean": 0.11413349211215973, "eval/reward_loss_std": 0.5926361680030823, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.001983404159546, "eval/reward_neg_acc": 0.9918116331100464, "eval/reward_neg_loss": 0.04102904349565506, "eval/reward_pos_acc": 0.8085106015205383, "eval/reward_pos_loss": 1.633772611618042, "eval/reward_pred": 0.0341140478849411, "eval/reward_rate": 0.0458984375, "replay/size": 672677.0, "replay/inserts": 7744.0, "replay/samples": 30976.0, "replay/insert_wait_avg": 1.5336804646105806e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.402936904883581e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 2160.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0875640092072664e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.897615432739258e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0666055679321, "timer/env.step_count": 968.0, "timer/env.step_total": 86.46018838882446, "timer/env.step_frac": 0.08645443004241124, "timer/env.step_avg": 0.08931837643473602, "timer/env.step_min": 0.022326231002807617, "timer/env.step_max": 2.0395374298095703, "timer/replay._sample_count": 30976.0, "timer/replay._sample_total": 15.152626752853394, "timer/replay._sample_frac": 0.015151617570760003, "timer/replay._sample_avg": 0.000489173126060608, "timer/replay._sample_min": 0.00034046173095703125, "timer/replay._sample_max": 0.02938103675842285, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1238.0, "timer/agent.policy_total": 20.959047079086304, "timer/agent.policy_frac": 0.020957651182826748, "timer/agent.policy_avg": 0.016929763391830617, "timer/agent.policy_min": 0.009526252746582031, "timer/agent.policy_max": 0.11081695556640625, "timer/dataset_train_count": 1936.0, "timer/dataset_train_total": 0.2809903621673584, "timer/dataset_train_frac": 0.0002809716478911778, "timer/dataset_train_avg": 0.0001451396498798339, "timer/dataset_train_min": 8.821487426757812e-05, "timer/dataset_train_max": 0.0008645057678222656, "timer/agent.train_count": 1936.0, "timer/agent.train_total": 859.693389415741, "timer/agent.train_frac": 0.8596361328628966, "timer/agent.train_avg": 0.44405650279738684, "timer/agent.train_min": 0.4346799850463867, "timer/agent.train_max": 0.9607863426208496, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4780445098876953, "timer/agent.report_frac": 0.0004780126715822258, "timer/agent.report_avg": 0.23902225494384766, "timer/agent.report_min": 0.23251867294311523, "timer/agent.report_max": 0.24552583694458008, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.6702880859375e-05, "timer/dataset_eval_frac": 2.6701102417284083e-08, "timer/dataset_eval_avg": 2.6702880859375e-05, "timer/dataset_eval_min": 2.6702880859375e-05, "timer/dataset_eval_max": 2.6702880859375e-05, "fps": 7.743360384605224}
{"step": 673200, "time": 86368.42249417305, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
