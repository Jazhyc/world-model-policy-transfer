{"step": 992, "time": 121.31072926521301, "episode/length": 123.0, "episode/score": 2.1000000163912773, "episode/reward_rate": 0.9758064516129032, "episode/intrinsic_return": 0.0}
{"step": 1304, "time": 123.61401987075806, "episode/length": 162.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 1352, "time": 125.09629225730896, "episode/length": 168.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 1360, "time": 126.47027087211609, "episode/length": 169.0, "episode/score": 3.1000000163912773, "episode/reward_rate": 0.9823529411764705, "episode/intrinsic_return": 0.0}
{"step": 1424, "time": 127.93582582473755, "episode/length": 177.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 1560, "time": 129.6624014377594, "episode/length": 194.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 1560, "time": 143.4174680709839, "eval_episode/length": 147.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9932432432432432}
{"step": 1560, "time": 144.94391798973083, "eval_episode/length": 155.0, "eval_episode/score": 2.0999999791383743, "eval_episode/reward_rate": 0.9935897435897436}
{"step": 1560, "time": 146.56454730033875, "eval_episode/length": 165.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9939759036144579}
{"step": 1560, "time": 148.0365800857544, "eval_episode/length": 170.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9707602339181286}
{"step": 1560, "time": 148.04510116577148, "eval_episode/length": 170.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9707602339181286}
{"step": 1560, "time": 150.88563323020935, "eval_episode/length": 179.0, "eval_episode/score": 3.100000001490116, "eval_episode/reward_rate": 0.9777777777777777}
{"step": 1560, "time": 150.89425802230835, "eval_episode/length": 179.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9944444444444445}
{"step": 1560, "time": 150.90251970291138, "eval_episode/length": 179.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9944444444444445}
{"step": 1560, "time": 155.3747742176056, "train_stats/sum_log_reward": 2.599999984105428, "train_stats/max_log_achievement_collect_sapling": 1.3333333333333333, "train_stats/max_log_achievement_place_plant": 1.1666666666666667, "train_stats/max_log_achievement_wake_up": 2.0, "train_stats/max_log_achievement_collect_wood": 0.75, "train_stats/max_log_achievement_collect_drink": 0.3333333333333333, "train_stats/max_log_achievement_place_table": 1.0, "eval_stats/sum_log_reward": 1.7249999418854713, "eval_stats/max_log_achievement_collect_drink": 0.0, "eval_stats/max_log_achievement_collect_sapling": 0.625, "eval_stats/max_log_achievement_collect_wood": 0.375, "eval_stats/max_log_achievement_place_plant": 0.625, "eval_stats/max_log_achievement_place_table": 0.125, "eval_stats/max_log_achievement_wake_up": 2.125}
{"step": 1560, "time": 195.4049255847931, "eval_episode/length": 104.0, "eval_episode/score": 1.0999999940395355, "eval_episode/reward_rate": 0.9904761904761905}
{"step": 1560, "time": 199.29211258888245, "eval_episode/length": 148.0, "eval_episode/score": 3.0999999940395355, "eval_episode/reward_rate": 0.9932885906040269}
{"step": 1560, "time": 200.98767018318176, "eval_episode/length": 151.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9539473684210527}
{"step": 1560, "time": 203.25836896896362, "eval_episode/length": 169.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9941176470588236}
{"step": 1560, "time": 204.977294921875, "eval_episode/length": 171.0, "eval_episode/score": 0.09999999403953552, "eval_episode/reward_rate": 0.9941860465116279}
{"step": 1560, "time": 207.29123282432556, "eval_episode/length": 190.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9790575916230366}
{"step": 1560, "time": 209.23370671272278, "eval_episode/length": 201.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9752475247524752}
{"step": 1560, "time": 210.76454877853394, "eval_episode/length": 202.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9753694581280788}
{"step": 1561, "time": 327.76746368408203, "eval_stats/sum_log_reward": 2.099999949336052, "eval_stats/max_log_achievement_collect_drink": 1.125, "eval_stats/max_log_achievement_collect_sapling": 1.625, "eval_stats/max_log_achievement_collect_wood": 0.875, "eval_stats/max_log_achievement_place_plant": 1.0, "eval_stats/max_log_achievement_place_table": 0.25, "eval_stats/max_log_achievement_wake_up": 2.25, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 7.2991943359375, "train/action_min": 0.0, "train/action_std": 4.87638521194458, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0003583008365239948, "train/actor_opt_grad_steps": 1.0, "train/actor_opt_loss": -2.1934900283813477, "train/adv_mag": 0.0, "train/adv_max": 0.0, "train/adv_mean": 0.0, "train/adv_min": 0.0, "train/adv_std": 0.0, "train/cont_avg": 0.9970703125, "train/cont_loss_mean": 0.6668773889541626, "train/cont_loss_std": 0.2919393479824066, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 0.9178594350814819, "train/cont_pos_acc": 0.585700273513794, "train/cont_pos_loss": 0.6661399006843567, "train/cont_pred": 0.5347480177879333, "train/cont_rate": 0.9970703125, "train/dyn_loss_mean": 10.893134117126465, "train/dyn_loss_std": 0.5549198985099792, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 7.775616645812988, "train/extr_critic_critic_opt_grad_steps": 1.0, "train/extr_critic_critic_opt_loss": 31556.60546875, "train/extr_critic_mag": 0.0, "train/extr_critic_max": 0.0, "train/extr_critic_mean": 0.0, "train/extr_critic_min": 0.0, "train/extr_critic_std": 0.0, "train/extr_return_normed_mag": 0.0, "train/extr_return_normed_max": 0.0, "train/extr_return_normed_mean": 0.0, "train/extr_return_normed_min": 0.0, "train/extr_return_normed_std": 0.0, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.0, "train/extr_return_raw_max": 0.0, "train/extr_return_raw_mean": 0.0, "train/extr_return_raw_min": 0.0, "train/extr_return_raw_std": 0.0, "train/extr_reward_mag": 0.0, "train/extr_reward_max": 0.0, "train/extr_reward_mean": 0.0, "train/extr_reward_min": 0.0, "train/extr_reward_std": 0.0, "train/image_loss_mean": 3597.2412109375, "train/image_loss_std": 161.73831176757812, "train/model_loss_mean": 3609.985107421875, "train/model_loss_std": 161.63522338867188, "train/model_opt_grad_norm": NaN, "train/model_opt_grad_steps": 0.0, "train/model_opt_loss": 36099852.0, "train/model_opt_model_opt_grad_overflow": 1.0, "train/model_opt_model_opt_grad_scale": 5000.0, "train/policy_entropy_mag": 2.7772536277770996, "train/policy_entropy_max": 2.7772536277770996, "train/policy_entropy_mean": 2.5674045085906982, "train/policy_entropy_min": 1.6442451477050781, "train/policy_entropy_std": 0.08522703498601913, "train/policy_logprob_mag": 5.349081993103027, "train/policy_logprob_max": -0.4828236699104309, "train/policy_logprob_mean": -2.571742296218872, "train/policy_logprob_min": -5.349081993103027, "train/policy_logprob_std": 0.6838160753250122, "train/policy_randomness_mag": 0.9802486300468445, "train/policy_randomness_max": 0.9802486300468445, "train/policy_randomness_mean": 0.9061811566352844, "train/policy_randomness_min": 0.580346405506134, "train/policy_randomness_std": 0.030081404373049736, "train/post_ent_mag": 106.28645324707031, "train/post_ent_max": 106.28645324707031, "train/post_ent_mean": 105.59217834472656, "train/post_ent_min": 104.90826416015625, "train/post_ent_std": 0.2736022472381592, "train/prior_ent_mag": 106.3428955078125, "train/prior_ent_max": 106.3428955078125, "train/prior_ent_mean": 105.52317810058594, "train/prior_ent_min": 104.59539794921875, "train/prior_ent_std": 0.29770398139953613, "train/rep_loss_mean": 10.893134117126465, "train/rep_loss_std": 0.5549198985099792, "train/reward_avg": 0.01591796986758709, "train/reward_loss_mean": 5.541262626647949, "train/reward_loss_std": 9.542561656417092e-07, "train/reward_max_data": 1.0, "train/reward_max_pred": 0.0, "train/reward_neg_acc": 1.0000001192092896, "train/reward_neg_loss": 5.541263103485107, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 5.541263580322266, "train/reward_pred": 0.0, "train/reward_rate": 0.017578125, "train/params_agent/wm/model_opt": 181569923.0, "train/params_agent/task_behavior/critic/critic_opt": 9708799.0, "train/params_agent/task_behavior/ac/actor_opt": 9464849.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.6811871528625488, "report/cont_loss_std": 0.2889641523361206, "report/cont_neg_acc": 0.3333333432674408, "report/cont_neg_loss": 0.6584250926971436, "report/cont_pos_acc": 0.5680705308914185, "report/cont_pos_loss": 0.681253969669342, "report/cont_pred": 0.5257878303527832, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 10.934032440185547, "report/dyn_loss_std": 0.5571997165679932, "report/image_loss_mean": 3595.36376953125, "report/image_loss_std": 161.74798583984375, "report/model_loss_mean": 3608.146484375, "report/model_loss_std": 161.68809509277344, "report/post_ent_mag": 106.35810089111328, "report/post_ent_max": 106.35810089111328, "report/post_ent_mean": 105.60248565673828, "report/post_ent_min": 104.90849304199219, "report/post_ent_std": 0.28148072957992554, "report/prior_ent_mag": 106.38584899902344, "report/prior_ent_max": 106.38584899902344, "report/prior_ent_mean": 105.5242691040039, "report/prior_ent_min": 104.50613403320312, "report/prior_ent_std": 0.31955641508102417, "report/rep_loss_mean": 10.934032440185547, "report/rep_loss_std": 0.5571997165679932, "report/reward_avg": 0.01591796986758709, "report/reward_loss_mean": 5.541262626647949, "report/reward_loss_std": 9.542561656417092e-07, "report/reward_max_data": 1.0, "report/reward_max_pred": 0.0, "report/reward_neg_acc": 1.0000001192092896, "report/reward_neg_loss": 5.541263103485107, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 5.541263580322266, "report/reward_pred": 0.0, "report/reward_rate": 0.017578125, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.6112586259841919, "eval/cont_loss_std": 0.26107990741729736, "eval/cont_neg_acc": 0.5, "eval/cont_neg_loss": 0.7545729875564575, "eval/cont_pos_acc": 0.6643835306167603, "eval/cont_pos_loss": 0.6109781265258789, "eval/cont_pred": 0.5601705312728882, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 10.93524169921875, "eval/dyn_loss_std": 0.4834803640842438, "eval/image_loss_mean": 3685.38671875, "eval/image_loss_std": 156.04713439941406, "eval/model_loss_mean": 3698.10009765625, "eval/model_loss_std": 155.9782257080078, "eval/post_ent_mag": 106.18610382080078, "eval/post_ent_max": 106.18610382080078, "eval/post_ent_mean": 105.58604431152344, "eval/post_ent_min": 104.935546875, "eval/post_ent_std": 0.21476426720619202, "eval/prior_ent_mag": 106.48075866699219, "eval/prior_ent_max": 106.48075866699219, "eval/prior_ent_mean": 105.53848266601562, "eval/prior_ent_min": 104.62265014648438, "eval/prior_ent_std": 0.2993445098400116, "eval/rep_loss_mean": 10.93524169921875, "eval/rep_loss_std": 0.4834803640842438, "eval/reward_avg": 0.009765625, "eval/reward_loss_mean": 5.541262626647949, "eval/reward_loss_std": 9.548376738166553e-07, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 5.541262626647949, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.541264057159424, "eval/reward_pred": 0.0, "eval/reward_rate": 0.013671875, "replay/size": 1057.0, "replay/inserts": 1057.0, "replay/samples": 112.0, "replay/insert_wait_avg": 1.5644950469710856e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.834259850638253e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 2680.0, "eval_replay/inserts": 2680.0, "eval_replay/samples": 112.0, "eval_replay/insert_wait_avg": 2.549922288353763e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.919915880475725e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 220.30999994277954, "timer/env.step_count": 196.0, "timer/env.step_total": 23.482908010482788, "timer/env.step_frac": 0.10659029556798118, "timer/env.step_avg": 0.11981075515552443, "timer/env.step_min": 0.019104719161987305, "timer/env.step_max": 11.150829553604126, "timer/replay._sample_count": 112.0, "timer/replay._sample_total": 0.15169692039489746, "timer/replay._sample_frac": 0.0006885612111765115, "timer/replay._sample_avg": 0.001354436789240156, "timer/replay._sample_min": 0.00044655799865722656, "timer/replay._sample_max": 0.01472020149230957, "timer/agent.save_count": 1.0, "timer/agent.save_total": 11.52220344543457, "timer/agent.save_frac": 0.052299956644851334, "timer/agent.save_avg": 11.52220344543457, "timer/agent.save_min": 11.52220344543457, "timer/agent.save_max": 11.52220344543457, "timer/agent.policy_count": 204.0, "timer/agent.policy_total": 25.13931179046631, "timer/agent.policy_frac": 0.11410880939129257, "timer/agent.policy_avg": 0.12323192054150152, "timer/agent.policy_min": 0.009974956512451172, "timer/agent.policy_max": 19.54469895362854, "timer/dataset_train_count": 1.0, "timer/dataset_train_total": 3.814697265625e-05, "timer/dataset_train_frac": 1.7315134431554536e-07, "timer/dataset_train_avg": 3.814697265625e-05, "timer/dataset_train_min": 3.814697265625e-05, "timer/dataset_train_max": 3.814697265625e-05, "timer/agent.train_count": 1.0, "timer/agent.train_total": 90.0442955493927, "timer/agent.train_frac": 0.4087163341327204, "timer/agent.train_avg": 90.0442955493927, "timer/agent.train_min": 90.0442955493927, "timer/agent.train_max": 90.0442955493927, "timer/agent.report_count": 2.0, "timer/agent.report_total": 23.260624647140503, "timer/agent.report_frac": 0.10558133835587089, "timer/agent.report_avg": 11.630312323570251, "timer/agent.report_min": 0.2465682029724121, "timer/agent.report_max": 23.01405644416809, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.743171691894531e-05, "timer/dataset_eval_frac": 1.6990475660962888e-07, "timer/dataset_eval_avg": 3.743171691894531e-05, "timer/dataset_eval_min": 3.743171691894531e-05, "timer/dataset_eval_max": 3.743171691894531e-05}
{"step": 1656, "time": 370.97650361061096, "episode/length": 206.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 1808, "time": 441.59399819374084, "episode/length": 225.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 1992, "time": 526.4556262493134, "episode/length": 70.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9295774647887324, "episode/intrinsic_return": 0.0}
{"step": 2408, "time": 716.2661747932434, "episode/length": 137.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9492753623188406, "episode/intrinsic_return": 0.0}
{"step": 2424, "time": 724.9523916244507, "episode/length": 178.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 2904, "time": 944.722327709198, "episode/length": 193.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 2912, "time": 949.779842376709, "episode/length": 168.0, "episode/score": 1.0999999791383743, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 2936, "time": 962.1886909008026, "episode/length": 140.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 2984, "time": 985.4199903011322, "episode/length": 202.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 3424, "time": 1185.8098194599152, "episode/length": 178.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 3552, "time": 1245.9904408454895, "episode/length": 236.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9831223628691983, "episode/intrinsic_return": 0.0}
{"step": 3592, "time": 1265.8100128173828, "episode/length": 147.0, "episode/score": 2.0999999940395355, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 3674, "time": 1305.2080752849579, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.399645186148549, "train/action_min": 0.0, "train/action_std": 2.22281789384182, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.045900717001381854, "train/actor_opt_grad_steps": 1060.0, "train/actor_opt_loss": 320.724578416743, "train/adv_mag": 1.6501781371779634, "train/adv_max": 1.6501781371779634, "train/adv_mean": 0.096591122451272, "train/adv_min": -0.4294249214126036, "train/adv_std": 0.20384173662461322, "train/cont_avg": 0.9955568720379147, "train/cont_loss_mean": 0.008843881192845043, "train/cont_loss_std": 0.08952012741363398, "train/cont_neg_acc": 0.6852788021832562, "train/cont_neg_loss": 1.0607242447234244, "train/cont_pos_acc": 0.9979647892346314, "train/cont_pos_loss": 0.0046466668602706315, "train/cont_pred": 0.993406811596658, "train/cont_rate": 0.9955568720379147, "train/dyn_loss_mean": 4.061066581174661, "train/dyn_loss_std": 6.943757558744665, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 4.435574993985524, "train/extr_critic_critic_opt_grad_steps": 1060.0, "train/extr_critic_critic_opt_loss": 25171.27409008442, "train/extr_critic_mag": 2.543679919288057, "train/extr_critic_max": 2.543679918158111, "train/extr_critic_mean": 1.4106337282856476, "train/extr_critic_min": 0.003908079947340545, "train/extr_critic_std": 0.777757356934782, "train/extr_return_normed_mag": 2.145813569407778, "train/extr_return_normed_max": 2.145813569407778, "train/extr_return_normed_mean": 0.38922178334450586, "train/extr_return_normed_min": -0.19507700976955933, "train/extr_return_normed_std": 0.31470581622942134, "train/extr_return_rate": 0.6274101209293795, "train/extr_return_raw_mag": 8.275271839493117, "train/extr_return_raw_max": 8.275271839493117, "train/extr_return_raw_mean": 1.682775716174844, "train/extr_return_raw_min": -0.6572925514537152, "train/extr_return_raw_std": 1.2410990853360258, "train/extr_reward_mag": 0.8639214750714777, "train/extr_reward_max": 0.8639214750714777, "train/extr_reward_mean": 0.058012152705297436, "train/extr_reward_min": -0.44326116857935466, "train/extr_reward_std": 0.17661830449259713, "train/image_loss_mean": 49.3952278638903, "train/image_loss_std": 21.635266841870347, "train/model_loss_mean": 52.030305575420506, "train/model_loss_std": 23.702938732942698, "train/model_opt_grad_norm": 255.00194686961964, "train/model_opt_grad_steps": 1051.0, "train/model_opt_loss": 1139.4542814860413, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 31.65728672985782, "train/policy_entropy_mag": 1.9517880412639599, "train/policy_entropy_max": 1.9517880412639599, "train/policy_entropy_mean": 0.5742140281327528, "train/policy_entropy_min": 0.29550292155753943, "train/policy_entropy_std": 0.26547669018155307, "train/policy_logprob_mag": 7.2398929324760255, "train/policy_logprob_max": -0.10233358099120912, "train/policy_logprob_mean": -0.5744216889849206, "train/policy_logprob_min": -7.2398929324760255, "train/policy_logprob_std": 0.9462380725625567, "train/policy_randomness_mag": 0.6888955289153691, "train/policy_randomness_max": 0.6888955289153691, "train/policy_randomness_mean": 0.20267235597163016, "train/policy_randomness_min": 0.1042995630141118, "train/policy_randomness_std": 0.09370162144029663, "train/post_ent_mag": 44.34137917468898, "train/post_ent_max": 44.34137917468898, "train/post_ent_mean": 25.39735741637894, "train/post_ent_min": 12.239072564653876, "train/post_ent_std": 6.142395783586525, "train/prior_ent_mag": 60.40100030763455, "train/prior_ent_max": 60.40100030763455, "train/prior_ent_mean": 30.540975444124772, "train/prior_ent_min": 15.411788194665412, "train/prior_ent_std": 7.758441049340777, "train/rep_loss_mean": 4.061066581174661, "train/rep_loss_std": 6.943757558744665, "train/reward_avg": 0.016987096309171928, "train/reward_loss_mean": 0.18959450697464542, "train/reward_loss_std": 0.39778915180612456, "train/reward_max_data": 1.0459715749415177, "train/reward_max_pred": 0.8681703828522379, "train/reward_neg_acc": 0.9951445954670838, "train/reward_neg_loss": 0.1596768899286669, "train/reward_pos_acc": 0.7900511077936226, "train/reward_pos_loss": 1.5798138134287432, "train/reward_pred": 0.015373907314052903, "train/reward_rate": 0.021243705568720378, "train_stats/sum_log_reward": 1.933333287636439, "train_stats/max_log_achievement_collect_drink": 5.333333333333333, "train_stats/max_log_achievement_collect_sapling": 3.1666666666666665, "train_stats/max_log_achievement_collect_wood": 0.16666666666666666, "train_stats/max_log_achievement_place_plant": 1.4166666666666667, "train_stats/max_log_achievement_place_table": 0.0, "train_stats/max_log_achievement_wake_up": 2.25, "train_stats/mean_log_entropy": 0.905473206192255, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.0003449513460509479, "report/cont_loss_std": 0.010224686935544014, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.06669708341360092, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.9376562704565004e-05, "report/cont_pred": 0.995376467704773, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 2.64363956451416, "report/dyn_loss_std": 6.321753025054932, "report/image_loss_mean": 5.9196672439575195, "report/image_loss_std": 5.639003753662109, "report/model_loss_mean": 7.543888092041016, "report/model_loss_std": 7.9903106689453125, "report/post_ent_mag": 33.63827133178711, "report/post_ent_max": 33.63827133178711, "report/post_ent_mean": 19.485471725463867, "report/post_ent_min": 7.8109588623046875, "report/post_ent_std": 5.167150020599365, "report/prior_ent_mag": 59.171356201171875, "report/prior_ent_max": 59.171356201171875, "report/prior_ent_mean": 22.974044799804688, "report/prior_ent_min": 10.400898933410645, "report/prior_ent_std": 7.777066707611084, "report/rep_loss_mean": 2.64363956451416, "report/rep_loss_std": 6.321753025054932, "report/reward_avg": 0.01953125, "report/reward_loss_mean": 0.037692416459321976, "report/reward_loss_std": 0.1587073653936386, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.0949814319610596, "report/reward_neg_acc": 0.9929929971694946, "report/reward_neg_loss": 0.022922368720173836, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6279035210609436, "report/reward_pred": 0.01996259018778801, "report/reward_rate": 0.0244140625, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.05318695306777954, "eval/cont_loss_std": 0.7593094706535339, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 10.890644073486328, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.002732551569352e-05, "eval/cont_pred": 0.999989926815033, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 14.640361785888672, "eval/dyn_loss_std": 10.106473922729492, "eval/image_loss_mean": 37.14751434326172, "eval/image_loss_std": 32.041202545166016, "eval/model_loss_mean": 46.16931915283203, "eval/model_loss_std": 35.371158599853516, "eval/post_ent_mag": 42.63563537597656, "eval/post_ent_max": 42.63563537597656, "eval/post_ent_mean": 26.997941970825195, "eval/post_ent_min": 8.648530960083008, "eval/post_ent_std": 7.193196773529053, "eval/prior_ent_mag": 60.86175537109375, "eval/prior_ent_max": 60.86175537109375, "eval/prior_ent_mean": 29.955284118652344, "eval/prior_ent_min": 10.865976333618164, "eval/prior_ent_std": 8.565675735473633, "eval/rep_loss_mean": 14.640361785888672, "eval/rep_loss_std": 10.106473922729492, "eval/reward_avg": 0.01337890699505806, "eval/reward_loss_mean": 0.1844034045934677, "eval/reward_loss_std": 1.1383225917816162, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.001709222793579, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.09969969093799591, "eval/reward_pos_acc": 0.4736842215061188, "eval/reward_pos_loss": 4.664783477783203, "eval/reward_pred": 0.007048892788589001, "eval/reward_rate": 0.0185546875, "replay/size": 3170.0, "replay/inserts": 2113.0, "replay/samples": 33808.0, "replay/insert_wait_avg": 2.7932096193370467e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.984004086134731e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 2680.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 8.195638656616211e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 977.4320251941681, "timer/env.step_count": 264.0, "timer/env.step_total": 25.642134428024292, "timer/env.step_frac": 0.026234186896966518, "timer/env.step_avg": 0.0971292970758496, "timer/env.step_min": 0.023957014083862305, "timer/env.step_max": 1.7142157554626465, "timer/replay._sample_count": 33808.0, "timer/replay._sample_total": 17.254288911819458, "timer/replay._sample_frac": 0.017652674014228122, "timer/replay._sample_avg": 0.0005103611249355022, "timer/replay._sample_min": 0.0003139972686767578, "timer/replay._sample_max": 0.028599023818969727, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 264.0, "timer/agent.policy_total": 4.501245498657227, "timer/agent.policy_frac": 0.004605174971387958, "timer/agent.policy_avg": 0.017050172343398586, "timer/agent.policy_min": 0.010514974594116211, "timer/agent.policy_max": 0.060503244400024414, "timer/dataset_train_count": 2113.0, "timer/dataset_train_total": 0.3876311779022217, "timer/dataset_train_frac": 0.000396581212719338, "timer/dataset_train_avg": 0.0001834506284440235, "timer/dataset_train_min": 9.5367431640625e-05, "timer/dataset_train_max": 0.0004723072052001953, "timer/agent.train_count": 2113.0, "timer/agent.train_total": 944.9548921585083, "timer/agent.train_frac": 0.9667730008854496, "timer/agent.train_avg": 0.44721007674325997, "timer/agent.train_min": 0.43578338623046875, "timer/agent.train_max": 0.5900495052337646, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48256826400756836, "timer/agent.report_frac": 0.0004937103057490934, "timer/agent.report_avg": 0.24128413200378418, "timer/agent.report_min": 0.23301196098327637, "timer/agent.report_max": 0.249556303024292, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.5762786865234375e-05, "timer/dataset_eval_frac": 3.6588515562634705e-08, "timer/dataset_eval_avg": 3.5762786865234375e-05, "timer/dataset_eval_min": 3.5762786865234375e-05, "timer/dataset_eval_max": 3.5762786865234375e-05, "fps": 2.1617612342621437}
{"step": 3992, "time": 1450.160080909729, "episode/length": 195.0, "episode/score": 2.0999999940395355, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 4096, "time": 1498.7824153900146, "episode/length": 144.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 4496, "time": 1681.204803943634, "episode/length": 197.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 4616, "time": 1737.3308699131012, "episode/length": 148.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 4664, "time": 1760.3643362522125, "episode/length": 209.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 4704, "time": 1779.9171884059906, "episode/length": 143.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 4728, "time": 1792.1935606002808, "episode/length": 227.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 5248, "time": 2027.797845363617, "episode/length": 206.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 5272, "time": 2040.1873168945312, "episode/length": 146.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 5472, "time": 2131.8096919059753, "episode/length": 184.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 5752, "time": 2260.3099052906036, "episode/length": 156.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 5848, "time": 2305.4458014965057, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.064218266219038, "train/action_min": 0.0, "train/action_std": 3.604542338903049, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03492427158946266, "train/actor_opt_grad_steps": 3200.0, "train/actor_opt_loss": 35.68571712996828, "train/adv_mag": 0.7292129525116512, "train/adv_max": 0.7240961660987221, "train/adv_mean": 0.01167091942668709, "train/adv_min": -0.4016473491757696, "train/adv_std": 0.06709620698187757, "train/cont_avg": 0.9946761592741935, "train/cont_loss_mean": 0.0002464055668168287, "train/cont_loss_std": 0.00674060691728129, "train/cont_neg_acc": 0.9912110533979204, "train/cont_neg_loss": 0.027851290119069776, "train/cont_pos_acc": 0.9999864148104796, "train/cont_pos_loss": 8.779064307041645e-05, "train/cont_pred": 0.9946890888126215, "train/cont_rate": 0.9946761592741935, "train/dyn_loss_mean": 2.772991106806812, "train/dyn_loss_std": 6.241773484489335, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.2919291343007768, "train/extr_critic_critic_opt_grad_steps": 3200.0, "train/extr_critic_critic_opt_loss": 15941.901448192684, "train/extr_critic_mag": 8.57765085686187, "train/extr_critic_max": 8.57765085686187, "train/extr_critic_mean": 3.6767494326912313, "train/extr_critic_min": -0.15253396957151352, "train/extr_critic_std": 2.6133312234131423, "train/extr_return_normed_mag": 1.6265620982042654, "train/extr_return_normed_max": 1.6265620982042654, "train/extr_return_normed_mean": 0.49503698725304845, "train/extr_return_normed_min": -0.10765295599325461, "train/extr_return_normed_std": 0.35228342463343926, "train/extr_return_rate": 0.7790571992298425, "train/extr_return_raw_mag": 12.590378871161818, "train/extr_return_raw_max": 12.590378871161818, "train/extr_return_raw_mean": 3.765558984422464, "train/extr_return_raw_min": -0.9256728465243969, "train/extr_return_raw_std": 2.7585996894792477, "train/extr_reward_mag": 1.048613440605902, "train/extr_reward_max": 1.048613440605902, "train/extr_reward_mean": 0.04338249408378167, "train/extr_reward_min": -0.6150222807985297, "train/extr_reward_std": 0.19273954698567017, "train/image_loss_mean": 5.709510747188797, "train/image_loss_std": 7.504520782127908, "train/model_loss_mean": 7.4091593439128545, "train/model_loss_std": 9.896495986094672, "train/model_opt_grad_norm": 93.81971305636218, "train/model_opt_grad_steps": 3191.0, "train/model_opt_loss": 1022.6910117716284, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 143.28917050691246, "train/policy_entropy_mag": 2.3945134960561303, "train/policy_entropy_max": 2.3945134960561303, "train/policy_entropy_mean": 0.7056728942053658, "train/policy_entropy_min": 0.0794147200161411, "train/policy_entropy_std": 0.5246246282680793, "train/policy_logprob_mag": 7.438119407073693, "train/policy_logprob_max": -0.009461665294274757, "train/policy_logprob_mean": -0.705808839078323, "train/policy_logprob_min": -7.438119407073693, "train/policy_logprob_std": 1.1892280584106798, "train/policy_randomness_mag": 0.8451581841789633, "train/policy_randomness_max": 0.8451581841789633, "train/policy_randomness_mean": 0.24907156406185044, "train/policy_randomness_min": 0.02802991115998837, "train/policy_randomness_std": 0.18516947232907818, "train/post_ent_mag": 34.80946425688432, "train/post_ent_max": 34.80946425688432, "train/post_ent_mean": 19.654816623107628, "train/post_ent_min": 8.156881969645276, "train/post_ent_std": 4.702555418014526, "train/prior_ent_mag": 60.16484595443796, "train/prior_ent_max": 60.16484595443796, "train/prior_ent_mean": 22.850463111279748, "train/prior_ent_min": 10.038018890240226, "train/prior_ent_std": 7.798571177891323, "train/rep_loss_mean": 2.772991106806812, "train/rep_loss_std": 6.241773484489335, "train/reward_avg": 0.015109716966095883, "train/reward_loss_mean": 0.03560752039646498, "train/reward_loss_std": 0.18784766105188203, "train/reward_max_data": 1.035023049824798, "train/reward_max_pred": 1.0364823231499316, "train/reward_neg_acc": 0.9962938147755812, "train/reward_neg_loss": 0.02084613575767468, "train/reward_pos_acc": 0.9794530857543242, "train/reward_pos_loss": 0.7657615597346961, "train/reward_pred": 0.014935623592598372, "train/reward_rate": 0.01990027361751152, "train_stats/sum_log_reward": 2.645454515110363, "train_stats/max_log_achievement_collect_drink": 2.909090909090909, "train_stats/max_log_achievement_collect_sapling": 1.2727272727272727, "train_stats/max_log_achievement_collect_wood": 0.9090909090909091, "train_stats/max_log_achievement_place_plant": 1.2727272727272727, "train_stats/max_log_achievement_place_table": 0.09090909090909091, "train_stats/max_log_achievement_wake_up": 2.1818181818181817, "train_stats/mean_log_entropy": 0.7251850637522611, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 1.7142097931355238e-05, "report/cont_loss_std": 0.0004992425674572587, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.002813406055793166, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 6.61171554838802e-07, "report/cont_pred": 0.9941564202308655, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 2.535879373550415, "report/dyn_loss_std": 6.996797561645508, "report/image_loss_mean": 4.452226161956787, "report/image_loss_std": 6.630854606628418, "report/model_loss_mean": 6.003857612609863, "report/model_loss_std": 9.411994934082031, "report/post_ent_mag": 33.24297332763672, "report/post_ent_max": 33.24297332763672, "report/post_ent_mean": 18.589147567749023, "report/post_ent_min": 7.7449750900268555, "report/post_ent_std": 5.006617546081543, "report/prior_ent_mag": 61.31616973876953, "report/prior_ent_max": 61.31616973876953, "report/prior_ent_mean": 21.650087356567383, "report/prior_ent_min": 9.45649242401123, "report/prior_ent_std": 7.9120612144470215, "report/rep_loss_mean": 2.535879373550415, "report/rep_loss_std": 6.996797561645508, "report/reward_avg": 0.010449218563735485, "report/reward_loss_mean": 0.030086126178503036, "report/reward_loss_std": 0.13162118196487427, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.00093412399292, "report/reward_neg_acc": 0.9970208406448364, "report/reward_neg_loss": 0.019211433827877045, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6742516160011292, "report/reward_pred": 0.010923579335212708, "report/reward_rate": 0.0166015625, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.04862078279256821, "eval/cont_loss_std": 0.7795860767364502, "eval/cont_neg_acc": 0.20000000298023224, "eval/cont_neg_loss": 9.957490921020508, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.2352161010985583e-07, "eval/cont_pred": 0.9994999170303345, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 16.285480499267578, "eval/dyn_loss_std": 11.81281566619873, "eval/image_loss_mean": 24.9016056060791, "eval/image_loss_std": 20.702909469604492, "eval/model_loss_mean": 34.905906677246094, "eval/model_loss_std": 25.818313598632812, "eval/post_ent_mag": 40.753089904785156, "eval/post_ent_max": 40.753089904785156, "eval/post_ent_mean": 23.64218521118164, "eval/post_ent_min": 7.371738433837891, "eval/post_ent_std": 6.251283645629883, "eval/prior_ent_mag": 61.31616973876953, "eval/prior_ent_max": 61.31616973876953, "eval/prior_ent_mean": 27.233463287353516, "eval/prior_ent_min": 8.245826721191406, "eval/prior_ent_std": 8.536416053771973, "eval/rep_loss_mean": 16.285480499267578, "eval/rep_loss_std": 11.81281566619873, "eval/reward_avg": 0.00927734375, "eval/reward_loss_mean": 0.18439006805419922, "eval/reward_loss_std": 1.1306818723678589, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0044159889221191, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.1051078513264656, "eval/reward_pos_acc": 0.3333333432674408, "eval/reward_pos_loss": 5.517441272735596, "eval/reward_pred": 0.0026943550910800695, "eval/reward_rate": 0.0146484375, "replay/size": 5344.0, "replay/inserts": 2174.0, "replay/samples": 34784.0, "replay/insert_wait_avg": 3.0298022469360016e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.311201479858286e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 2680.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 7.599592208862305e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2262816429138, "timer/env.step_count": 271.0, "timer/env.step_total": 24.048943996429443, "timer/env.step_frac": 0.024043503392980274, "timer/env.step_avg": 0.08874149076173227, "timer/env.step_min": 0.02426910400390625, "timer/env.step_max": 1.6920349597930908, "timer/replay._sample_count": 34784.0, "timer/replay._sample_total": 17.663241624832153, "timer/replay._sample_frac": 0.017659245661711204, "timer/replay._sample_avg": 0.0005077978847985324, "timer/replay._sample_min": 0.0003352165222167969, "timer/replay._sample_max": 0.011338472366333008, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 271.0, "timer/agent.policy_total": 4.5183024406433105, "timer/agent.policy_frac": 0.004517280263043886, "timer/agent.policy_avg": 0.016672702733001147, "timer/agent.policy_min": 0.01017904281616211, "timer/agent.policy_max": 0.022536516189575195, "timer/dataset_train_count": 2174.0, "timer/dataset_train_total": 0.41144347190856934, "timer/dataset_train_frac": 0.0004113503908663109, "timer/dataset_train_avg": 0.00018925642682086907, "timer/dataset_train_min": 0.00010037422180175781, "timer/dataset_train_max": 0.0012240409851074219, "timer/agent.train_count": 2174.0, "timer/agent.train_total": 969.4137172698975, "timer/agent.train_frac": 0.9691944063673218, "timer/agent.train_avg": 0.445912473445215, "timer/agent.train_min": 0.434201717376709, "timer/agent.train_max": 1.064648151397705, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48757505416870117, "timer/agent.report_frac": 0.00048746474984424383, "timer/agent.report_avg": 0.24378752708435059, "timer/agent.report_min": 0.24315547943115234, "timer/agent.report_max": 0.24441957473754883, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.123283386230469e-05, "timer/dataset_eval_frac": 3.12257680442104e-08, "timer/dataset_eval_avg": 3.123283386230469e-05, "timer/dataset_eval_min": 3.123283386230469e-05, "timer/dataset_eval_max": 3.123283386230469e-05, "fps": 2.1734822015110846}
{"step": 5992, "time": 2370.6260018348694, "episode/length": 160.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 6064, "time": 2404.6497724056244, "episode/length": 180.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 6248, "time": 2488.858705997467, "episode/length": 189.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 6288, "time": 2508.3886699676514, "episode/length": 202.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 6384, "time": 2553.3192217350006, "episode/length": 138.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.0}
{"step": 6456, "time": 2587.5046169757843, "episode/length": 150.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 6928, "time": 2802.452874660492, "episode/length": 181.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 7264, "time": 2955.280992269516, "episode/length": 158.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 7472, "time": 3050.106788635254, "episode/length": 135.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9632352941176471, "episode/intrinsic_return": 0.0}
{"step": 7480, "time": 3055.287104845047, "episode/length": 153.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 7480, "time": 3055.2932546138763, "episode/length": 127.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.953125, "episode/intrinsic_return": 0.0}
{"step": 7576, "time": 3101.5790116786957, "episode/length": 188.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 7800, "time": 3203.7841482162476, "episode/length": 188.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 7952, "time": 3273.959220647812, "episode/length": 274.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 7960, "time": 3279.452490568161, "episode/length": 59.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9166666666666666, "episode/intrinsic_return": 0.0}
{"step": 8013, "time": 3305.7873010635376, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.592839816748272, "train/action_min": 0.0, "train/action_std": 4.530244869021227, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03295240446513149, "train/actor_opt_grad_steps": 5370.0, "train/actor_opt_loss": 8.42365219381376, "train/adv_mag": 0.687405010384898, "train/adv_max": 0.6718980186545904, "train/adv_mean": 0.005014362338271039, "train/adv_min": -0.43112792486694, "train/adv_std": 0.05323753771179008, "train/cont_avg": 0.9947211621543779, "train/cont_loss_mean": 0.00031888043774965923, "train/cont_loss_std": 0.0089785547357924, "train/cont_neg_acc": 0.9910723437911354, "train/cont_neg_loss": 0.04572080398072809, "train/cont_pos_acc": 0.999968271925702, "train/cont_pos_loss": 0.0001005485469729532, "train/cont_pred": 0.9947238317283068, "train/cont_rate": 0.9947211621543779, "train/dyn_loss_mean": 2.716659364612421, "train/dyn_loss_std": 6.66158070542296, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.232882464536324, "train/extr_critic_critic_opt_grad_steps": 5370.0, "train/extr_critic_critic_opt_loss": 15599.324758784562, "train/extr_critic_mag": 13.046997782272127, "train/extr_critic_max": 13.046997782272127, "train/extr_critic_mean": 4.018225467699464, "train/extr_critic_min": -0.39299395556823447, "train/extr_critic_std": 3.4724359874901136, "train/extr_return_normed_mag": 1.5485531888249833, "train/extr_return_normed_max": 1.5485531888249833, "train/extr_return_normed_mean": 0.4063302503066129, "train/extr_return_normed_min": -0.093154402518396, "train/extr_return_normed_std": 0.3435280135562343, "train/extr_return_rate": 0.7773896950181178, "train/extr_return_raw_mag": 16.062946104234264, "train/extr_return_raw_max": 16.062946104234264, "train/extr_return_raw_mean": 4.069654537236087, "train/extr_return_raw_min": -1.1509018666733246, "train/extr_return_raw_std": 3.597760655363584, "train/extr_reward_mag": 1.03970088167674, "train/extr_reward_max": 1.03970088167674, "train/extr_reward_mean": 0.034126291914160625, "train/extr_reward_min": -0.6741627526173394, "train/extr_reward_std": 0.1787074547140829, "train/image_loss_mean": 5.2531484986230526, "train/image_loss_std": 9.05465205803445, "train/model_loss_mean": 6.91637168611799, "train/model_loss_std": 11.60192032343781, "train/model_opt_grad_norm": 78.3358075981316, "train/model_opt_grad_steps": 5360.571428571428, "train/model_opt_loss": 2667.3934449929798, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 385.9447004608295, "train/policy_entropy_mag": 2.4519167232073946, "train/policy_entropy_max": 2.4519167232073946, "train/policy_entropy_mean": 0.7194303254927358, "train/policy_entropy_min": 0.07938266047684278, "train/policy_entropy_std": 0.5822148443916426, "train/policy_logprob_mag": 7.438309599177629, "train/policy_logprob_max": -0.00945721831052534, "train/policy_logprob_mean": -0.719375377426499, "train/policy_logprob_min": -7.438309599177629, "train/policy_logprob_std": 1.2016018184099329, "train/policy_randomness_mag": 0.8654190049193422, "train/policy_randomness_max": 0.8654190049193422, "train/policy_randomness_mean": 0.2539273339757172, "train/policy_randomness_min": 0.028018595522037847, "train/policy_randomness_std": 0.20549629196043936, "train/post_ent_mag": 34.952000244421896, "train/post_ent_max": 34.952000244421896, "train/post_ent_mean": 18.793003337174518, "train/post_ent_min": 8.221515653320171, "train/post_ent_std": 4.390540455892888, "train/prior_ent_mag": 62.91939975369361, "train/prior_ent_max": 62.91939975369361, "train/prior_ent_mean": 21.766609596217283, "train/prior_ent_min": 9.802392502534225, "train/prior_ent_std": 8.054000415010936, "train/rep_loss_mean": 2.716659364612421, "train/rep_loss_std": 6.66158070542296, "train/reward_avg": 0.015209173282591222, "train/reward_loss_mean": 0.032908697719878865, "train/reward_loss_std": 0.17859347889088265, "train/reward_max_data": 1.0271889465745143, "train/reward_max_pred": 1.0282132065241238, "train/reward_neg_acc": 0.9970410782071303, "train/reward_neg_loss": 0.018463650973693978, "train/reward_pos_acc": 0.9857110548678631, "train/reward_pos_loss": 0.7423810302387185, "train/reward_pred": 0.015078908644728191, "train/reward_rate": 0.02001278081797235, "train_stats/sum_log_reward": 2.2333332702517508, "train_stats/max_log_achievement_collect_drink": 3.933333333333333, "train_stats/max_log_achievement_collect_sapling": 1.0, "train_stats/max_log_achievement_collect_wood": 0.6, "train_stats/max_log_achievement_place_plant": 1.0, "train_stats/max_log_achievement_place_table": 0.0, "train_stats/max_log_achievement_wake_up": 2.2, "train_stats/mean_log_entropy": 0.8488559206326802, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 2.7520465664565563e-05, "report/cont_loss_std": 5.6783050240483135e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 4.6488667067023925e-06, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.7655269150272943e-05, "report/cont_pred": 0.9941131472587585, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 2.81143856048584, "report/dyn_loss_std": 7.0716400146484375, "report/image_loss_mean": 5.639138221740723, "report/image_loss_std": 7.755883693695068, "report/model_loss_mean": 7.36784553527832, "report/model_loss_std": 10.512006759643555, "report/post_ent_mag": 36.3680534362793, "report/post_ent_max": 36.3680534362793, "report/post_ent_mean": 19.4407958984375, "report/post_ent_min": 8.455928802490234, "report/post_ent_std": 5.028480052947998, "report/prior_ent_mag": 64.43643951416016, "report/prior_ent_max": 64.43643951416016, "report/prior_ent_mean": 22.662715911865234, "report/prior_ent_min": 10.726150512695312, "report/prior_ent_std": 8.646318435668945, "report/rep_loss_mean": 2.81143856048584, "report/rep_loss_std": 7.0716400146484375, "report/reward_avg": 0.01806640625, "report/reward_loss_mean": 0.04181676357984543, "report/reward_loss_std": 0.1766405999660492, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0087690353393555, "report/reward_neg_acc": 0.9950000643730164, "report/reward_neg_loss": 0.0266217403113842, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.674942672252655, "report/reward_pred": 0.018210668116807938, "report/reward_rate": 0.0234375, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.002785417716950178, "eval/cont_loss_std": 0.08863403648138046, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 2.8376893997192383, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.425056871084962e-05, "eval/cont_pred": 0.9999285340309143, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 19.338054656982422, "eval/dyn_loss_std": 11.717117309570312, "eval/image_loss_mean": 36.50862121582031, "eval/image_loss_std": 32.127159118652344, "eval/model_loss_mean": 48.262447357177734, "eval/model_loss_std": 36.48982238769531, "eval/post_ent_mag": 37.75568389892578, "eval/post_ent_max": 37.75568389892578, "eval/post_ent_mean": 23.849164962768555, "eval/post_ent_min": 8.215815544128418, "eval/post_ent_std": 6.205978870391846, "eval/prior_ent_mag": 64.43643951416016, "eval/prior_ent_max": 64.43643951416016, "eval/prior_ent_mean": 28.658584594726562, "eval/prior_ent_min": 8.99921989440918, "eval/prior_ent_std": 8.99544906616211, "eval/rep_loss_mean": 19.338054656982422, "eval/rep_loss_std": 11.717117309570312, "eval/reward_avg": 0.01289062574505806, "eval/reward_loss_mean": 0.1482073962688446, "eval/reward_loss_std": 1.125989317893982, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0034451484680176, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.037487760186195374, "eval/reward_pos_acc": 0.20000001788139343, "eval/reward_pos_loss": 7.595948219299316, "eval/reward_pred": 0.002031424082815647, "eval/reward_rate": 0.0146484375, "replay/size": 7509.0, "replay/inserts": 2165.0, "replay/samples": 34640.0, "replay/insert_wait_avg": 2.8931791732823324e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.850675054290278e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 2680.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3329768180847, "timer/env.step_count": 271.0, "timer/env.step_total": 32.140854597091675, "timer/env.step_frac": 0.032130155999982236, "timer/env.step_avg": 0.11860093947266301, "timer/env.step_min": 0.02430558204650879, "timer/env.step_max": 3.3242712020874023, "timer/replay._sample_count": 34640.0, "timer/replay._sample_total": 17.087811946868896, "timer/replay._sample_frac": 0.01708212399557472, "timer/replay._sample_avg": 0.0004932971116301645, "timer/replay._sample_min": 0.0003256797790527344, "timer/replay._sample_max": 0.033872127532958984, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 271.0, "timer/agent.policy_total": 4.464391231536865, "timer/agent.policy_frac": 0.004462905187568095, "timer/agent.policy_avg": 0.016473768382054853, "timer/agent.policy_min": 0.010015249252319336, "timer/agent.policy_max": 0.041335344314575195, "timer/dataset_train_count": 2165.0, "timer/dataset_train_total": 0.4052746295928955, "timer/dataset_train_frac": 0.0004051397274555676, "timer/dataset_train_avg": 0.00018719382429233049, "timer/dataset_train_min": 9.417533874511719e-05, "timer/dataset_train_max": 0.0005195140838623047, "timer/agent.train_count": 2165.0, "timer/agent.train_total": 961.6058783531189, "timer/agent.train_frac": 0.9612857924686726, "timer/agent.train_avg": 0.4441597590545584, "timer/agent.train_min": 0.4339725971221924, "timer/agent.train_max": 0.5874102115631104, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47382044792175293, "timer/agent.report_frac": 0.00047366272921333416, "timer/agent.report_avg": 0.23691022396087646, "timer/agent.report_min": 0.2296128273010254, "timer/agent.report_max": 0.24420762062072754, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.170967102050781e-05, "timer/dataset_eval_frac": 3.169911594974277e-08, "timer/dataset_eval_avg": 3.170967102050781e-05, "timer/dataset_eval_min": 3.170967102050781e-05, "timer/dataset_eval_max": 3.170967102050781e-05, "fps": 2.1642540902785616}
{"step": 8152, "time": 3368.2336614131927, "episode/length": 152.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 8504, "time": 3528.088722705841, "episode/length": 154.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 8688, "time": 3613.222352027893, "episode/length": 151.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 8792, "time": 3663.43239068985, "episode/length": 151.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 8880, "time": 3704.944752216339, "episode/length": 46.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9148936170212766, "episode/intrinsic_return": 0.0}
{"step": 9064, "time": 3791.308182477951, "episode/length": 157.0, "episode/score": 2.0999999940395355, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 9160, "time": 3835.832048177719, "episode/length": 150.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 9520, "time": 3998.4547181129456, "episode/length": 194.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 9688, "time": 4074.9005558490753, "episode/length": 275.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9963768115942029, "episode/intrinsic_return": 0.0}
{"step": 9800, "time": 4126.53240442276, "episode/length": 205.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 10032, "time": 4232.307061910629, "episode/length": 167.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 10072, "time": 4251.6528515815735, "episode/length": 159.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 10088, "time": 4278.348271608353, "eval_episode/length": 145.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9931506849315068}
{"step": 10088, "time": 4280.019418478012, "eval_episode/length": 149.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9933333333333333}
{"step": 10088, "time": 4281.602931261063, "eval_episode/length": 151.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.993421052631579}
{"step": 10088, "time": 4283.330589532852, "eval_episode/length": 157.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9936708860759493}
{"step": 10088, "time": 4285.540791749954, "eval_episode/length": 170.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9941520467836257}
{"step": 10088, "time": 4288.040052652359, "eval_episode/length": 194.0, "eval_episode/score": 1.0999999940395355, "eval_episode/reward_rate": 0.9948717948717949}
{"step": 10088, "time": 4290.260185718536, "eval_episode/length": 212.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9765258215962441}
{"step": 10088, "time": 4294.660553216934, "eval_episode/length": 132.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9624060150375939}
{"step": 10112, "time": 4305.854664802551, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.993626185825893, "train/action_min": 0.0, "train/action_std": 4.2481859570457825, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03487529790117627, "train/actor_opt_grad_steps": 7505.0, "train/actor_opt_loss": 9.788242630403312, "train/adv_mag": 0.6863803229161671, "train/adv_max": 0.6560799727837244, "train/adv_mean": 0.005340702623340933, "train/adv_min": -0.4886461970351991, "train/adv_std": 0.05183797501737163, "train/cont_avg": 0.9943219866071429, "train/cont_loss_mean": 0.00022484462926738183, "train/cont_loss_std": 0.006440734692831657, "train/cont_neg_acc": 0.9947089953081948, "train/cont_neg_loss": 0.03335899598208536, "train/cont_pos_acc": 0.9999812957786378, "train/cont_pos_loss": 7.817499328288997e-05, "train/cont_pred": 0.9943192215192885, "train/cont_rate": 0.9943219866071429, "train/dyn_loss_mean": 2.6223872025807697, "train/dyn_loss_std": 7.041282438096546, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.2802221865881056, "train/extr_critic_critic_opt_grad_steps": 7505.0, "train/extr_critic_critic_opt_loss": 15897.53884858631, "train/extr_critic_mag": 16.128726264408655, "train/extr_critic_max": 16.128726264408655, "train/extr_critic_mean": 3.9416617717061726, "train/extr_critic_min": -0.5002419375237964, "train/extr_critic_std": 4.1856631585529875, "train/extr_return_normed_mag": 1.4299950372605097, "train/extr_return_normed_max": 1.4299950372605097, "train/extr_return_normed_mean": 0.33485709088189264, "train/extr_return_normed_min": -0.06960572708575498, "train/extr_return_normed_std": 0.3386430156372842, "train/extr_return_rate": 0.6962503457353229, "train/extr_return_raw_mag": 17.953958420526412, "train/extr_return_raw_max": 17.953958420526412, "train/extr_return_raw_mean": 4.009551379794166, "train/extr_return_raw_min": -1.1416663381315413, "train/extr_return_raw_std": 4.317742843854995, "train/extr_reward_mag": 1.0351029725301832, "train/extr_reward_max": 1.0351029725301832, "train/extr_reward_mean": 0.031053464460585798, "train/extr_reward_min": -0.6749047688075475, "train/extr_reward_std": 0.17370450517960956, "train/image_loss_mean": 3.908985920179458, "train/image_loss_std": 6.703315799576895, "train/model_loss_mean": 5.515998026302882, "train/model_loss_std": 9.694321307681856, "train/model_opt_grad_norm": 65.37022860390799, "train/model_opt_grad_steps": 7494.633333333333, "train/model_opt_loss": 3790.382246907552, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 691.9642857142857, "train/policy_entropy_mag": 2.5146765970048452, "train/policy_entropy_max": 2.5146765970048452, "train/policy_entropy_mean": 0.894289919024422, "train/policy_entropy_min": 0.07937774356632006, "train/policy_entropy_std": 0.708655804111844, "train/policy_logprob_mag": 7.438355988547915, "train/policy_logprob_max": -0.009456395929945367, "train/policy_logprob_mean": -0.8951398977211543, "train/policy_logprob_min": -7.438355988547915, "train/policy_logprob_std": 1.2671455315181188, "train/policy_randomness_mag": 0.8875704836277735, "train/policy_randomness_max": 0.8875704836277735, "train/policy_randomness_mean": 0.3156450962736493, "train/policy_randomness_min": 0.02801686002030259, "train/policy_randomness_std": 0.2501243993639946, "train/post_ent_mag": 33.29274870554606, "train/post_ent_max": 33.29274870554606, "train/post_ent_mean": 18.521447445097422, "train/post_ent_min": 8.755479678653536, "train/post_ent_std": 4.167088096482413, "train/prior_ent_mag": 65.10375522431873, "train/prior_ent_max": 65.10375522431873, "train/prior_ent_mean": 21.32070524124872, "train/prior_ent_min": 10.022444239116851, "train/prior_ent_std": 8.14019976797558, "train/rep_loss_mean": 2.6223872025807697, "train/rep_loss_std": 7.041282438096546, "train/reward_avg": 0.014660528220147604, "train/reward_loss_mean": 0.03335494720155285, "train/reward_loss_std": 0.1726869555101508, "train/reward_max_data": 1.0233333388964334, "train/reward_max_pred": 1.0232091284933544, "train/reward_neg_acc": 0.9967359474727085, "train/reward_neg_loss": 0.01906520047092012, "train/reward_pos_acc": 0.981753705229078, "train/reward_pos_loss": 0.74517942070961, "train/reward_pred": 0.01454163432963902, "train/reward_rate": 0.019796316964285715, "train_stats/sum_log_reward": 2.3499999195337296, "train_stats/max_log_achievement_collect_drink": 5.5, "train_stats/max_log_achievement_collect_sapling": 1.25, "train_stats/max_log_achievement_collect_wood": 1.0833333333333333, "train_stats/max_log_achievement_place_plant": 1.0, "train_stats/max_log_achievement_place_table": 0.0, "train_stats/max_log_achievement_wake_up": 1.6666666666666667, "train_stats/mean_log_entropy": 1.0085376997788746, "eval_stats/sum_log_reward": 2.1000000089406967, "eval_stats/max_log_achievement_collect_drink": 9.5, "eval_stats/max_log_achievement_collect_sapling": 0.75, "eval_stats/max_log_achievement_collect_wood": 0.125, "eval_stats/max_log_achievement_place_plant": 0.75, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 1.875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 8.87831538420869e-06, "report/cont_loss_std": 0.0001340632588835433, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0008081032428890467, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 4.1677558328956366e-06, "report/cont_pred": 0.9941412210464478, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 2.5866146087646484, "report/dyn_loss_std": 7.200717926025391, "report/image_loss_mean": 3.7953991889953613, "report/image_loss_std": 6.8138556480407715, "report/model_loss_mean": 5.381586074829102, "report/model_loss_std": 9.543696403503418, "report/post_ent_mag": 33.486572265625, "report/post_ent_max": 33.486572265625, "report/post_ent_mean": 18.5991268157959, "report/post_ent_min": 9.804244041442871, "report/post_ent_std": 4.094673156738281, "report/prior_ent_mag": 68.14944458007812, "report/prior_ent_max": 68.14944458007812, "report/prior_ent_mean": 21.454689025878906, "report/prior_ent_min": 11.392877578735352, "report/prior_ent_std": 8.391670227050781, "report/rep_loss_mean": 2.5866146087646484, "report/rep_loss_std": 7.200717926025391, "report/reward_avg": 0.01035156287252903, "report/reward_loss_mean": 0.03420956805348396, "report/reward_loss_std": 0.17424225807189941, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.0849609375, "report/reward_neg_acc": 0.9930486679077148, "report/reward_neg_loss": 0.02094954252243042, "report/reward_pos_acc": 0.9411764740943909, "report/reward_pos_loss": 0.8196709752082825, "report/reward_pred": 0.009529427625238895, "report/reward_rate": 0.0166015625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.00821834709495306, "eval/cont_loss_std": 0.24802090227603912, "eval/cont_neg_acc": 0.75, "eval/cont_neg_loss": 2.1036999225616455, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 7.732368203505757e-07, "eval/cont_pred": 0.9974679946899414, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 20.836803436279297, "eval/dyn_loss_std": 11.945945739746094, "eval/image_loss_mean": 35.164695739746094, "eval/image_loss_std": 32.59768295288086, "eval/model_loss_mean": 47.79810333251953, "eval/model_loss_std": 37.527095794677734, "eval/post_ent_mag": 37.187721252441406, "eval/post_ent_max": 37.187721252441406, "eval/post_ent_mean": 23.874202728271484, "eval/post_ent_min": 10.79368782043457, "eval/post_ent_std": 5.445908069610596, "eval/prior_ent_mag": 68.14944458007812, "eval/prior_ent_max": 68.14944458007812, "eval/prior_ent_mean": 29.580623626708984, "eval/prior_ent_min": 9.81879997253418, "eval/prior_ent_std": 9.89509105682373, "eval/rep_loss_mean": 20.836803436279297, "eval/rep_loss_std": 11.945945739746094, "eval/reward_avg": 0.0087890625, "eval/reward_loss_mean": 0.12310779839754105, "eval/reward_loss_std": 0.9795470833778381, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0005054473876953, "eval/reward_neg_acc": 0.9990108609199524, "eval/reward_neg_loss": 0.04905859753489494, "eval/reward_pos_acc": 0.38461539149284363, "eval/reward_pos_loss": 5.881857395172119, "eval/reward_pred": 0.0012472146190702915, "eval/reward_rate": 0.0126953125, "replay/size": 9608.0, "replay/inserts": 2099.0, "replay/samples": 33584.0, "replay/insert_wait_avg": 2.629419574855679e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.316477245350802e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 4960.0, "eval_replay/inserts": 2280.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0769618184942948e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.748603820800781e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0556700229645, "timer/env.step_count": 262.0, "timer/env.step_total": 25.25547957420349, "timer/env.step_frac": 0.025254073679341817, "timer/env.step_avg": 0.09639496020688355, "timer/env.step_min": 0.023392915725708008, "timer/env.step_max": 1.6784987449645996, "timer/replay._sample_count": 33584.0, "timer/replay._sample_total": 17.188929557800293, "timer/replay._sample_frac": 0.017187972702965206, "timer/replay._sample_avg": 0.0005118190077953874, "timer/replay._sample_min": 0.00032019615173339844, "timer/replay._sample_max": 0.02554798126220703, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 547.0, "timer/agent.policy_total": 8.487695455551147, "timer/agent.policy_frac": 0.008487222971653411, "timer/agent.policy_avg": 0.015516810704846704, "timer/agent.policy_min": 0.009462356567382812, "timer/agent.policy_max": 0.0215456485748291, "timer/dataset_train_count": 2099.0, "timer/dataset_train_total": 0.3994765281677246, "timer/dataset_train_frac": 0.0003994542905381971, "timer/dataset_train_avg": 0.00019031754557776302, "timer/dataset_train_min": 9.059906005859375e-05, "timer/dataset_train_max": 0.0012984275817871094, "timer/agent.train_count": 2099.0, "timer/agent.train_total": 933.9273881912231, "timer/agent.train_frac": 0.9338753993262967, "timer/agent.train_avg": 0.4449392035213069, "timer/agent.train_min": 0.4313478469848633, "timer/agent.train_max": 0.631622314453125, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47083163261413574, "timer/agent.report_frac": 0.000470805422865433, "timer/agent.report_avg": 0.23541581630706787, "timer/agent.report_min": 0.22797393798828125, "timer/agent.report_max": 0.2428576946258545, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7894973754882812e-05, "timer/dataset_eval_frac": 2.789342092749922e-08, "timer/dataset_eval_avg": 2.7894973754882812e-05, "timer/dataset_eval_min": 2.7894973754882812e-05, "timer/dataset_eval_max": 2.7894973754882812e-05, "fps": 2.098859665821866}
{"step": 10344, "time": 4409.840240955353, "episode/length": 159.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 10464, "time": 4465.000529766083, "episode/length": 162.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 10536, "time": 4498.815951824188, "episode/length": 126.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.952755905511811, "episode/intrinsic_return": 0.0}
{"step": 10800, "time": 4618.372322320938, "episode/length": 239.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 11176, "time": 4788.1166117191315, "episode/length": 142.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.965034965034965, "episode/intrinsic_return": 0.0}
{"step": 11528, "time": 4948.124757528305, "episode/length": 229.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9826086956521739, "episode/intrinsic_return": 0.0}
{"step": 11632, "time": 4996.36830997467, "episode/length": 194.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 11656, "time": 5008.607388019562, "episode/length": 163.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 11944, "time": 5139.520616054535, "episode/length": 184.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 12008, "time": 5169.583636760712, "episode/length": 150.0, "episode/score": 1.0999999940395355, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 12072, "time": 5199.9546818733215, "episode/length": 283.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9823943661971831, "episode/intrinsic_return": 0.0}
{"step": 12168, "time": 5244.64516377449, "episode/length": 203.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 12300, "time": 5306.1763689517975, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.8586534473994005, "train/action_min": 0.0, "train/action_std": 4.258611431949215, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03719911196154274, "train/actor_opt_grad_steps": 9650.0, "train/actor_opt_loss": -3.6092514581638113, "train/adv_mag": 0.6902860386730874, "train/adv_max": 0.6483772010563715, "train/adv_mean": 0.0029730440294491985, "train/adv_min": -0.5132689249433883, "train/adv_std": 0.05173839373539572, "train/cont_avg": 0.9946801869292238, "train/cont_loss_mean": 8.901046869172949e-05, "train/cont_loss_std": 0.00263560879100924, "train/cont_neg_acc": 0.9950097856456286, "train/cont_neg_loss": 0.013998636210994073, "train/cont_pos_acc": 0.9999955010740724, "train/cont_pos_loss": 1.6014472434305035e-05, "train/cont_pred": 0.9946960534679291, "train/cont_rate": 0.9946801869292238, "train/dyn_loss_mean": 2.6047157686050624, "train/dyn_loss_std": 7.153482084404932, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.3098587423699086, "train/extr_critic_critic_opt_grad_steps": 9650.0, "train/extr_critic_critic_opt_loss": 16246.674898330479, "train/extr_critic_mag": 17.42181344663716, "train/extr_critic_max": 17.42181344663716, "train/extr_critic_mean": 3.873169620287473, "train/extr_critic_min": -0.5605863985949999, "train/extr_critic_std": 4.234040242896232, "train/extr_return_normed_mag": 1.445505637828618, "train/extr_return_normed_max": 1.445505637828618, "train/extr_return_normed_mean": 0.31881574810095575, "train/extr_return_normed_min": -0.07046039283411688, "train/extr_return_normed_std": 0.3312541191980719, "train/extr_return_rate": 0.6890173508832443, "train/extr_return_raw_mag": 18.63149265393819, "train/extr_return_raw_max": 18.63149265393819, "train/extr_return_raw_mean": 3.9120783280564226, "train/extr_return_raw_min": -1.175093373479364, "train/extr_return_raw_std": 4.330232096589319, "train/extr_reward_mag": 1.0339767410330576, "train/extr_reward_max": 1.0339767410330576, "train/extr_reward_mean": 0.029172652365945993, "train/extr_reward_min": -0.6837302353828465, "train/extr_reward_std": 0.16904586553573608, "train/image_loss_mean": 3.6350274450702753, "train/image_loss_std": 6.870444019091184, "train/model_loss_mean": 5.229851594254306, "train/model_loss_std": 9.94947878519694, "train/model_opt_grad_norm": 65.63259564578262, "train/model_opt_grad_steps": 9637.885844748858, "train/model_opt_loss": 3908.687559084261, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 759.1324200913242, "train/policy_entropy_mag": 2.533772882261233, "train/policy_entropy_max": 2.533772882261233, "train/policy_entropy_mean": 0.7927267744660922, "train/policy_entropy_min": 0.07937625087967747, "train/policy_entropy_std": 0.7041570900782058, "train/policy_logprob_mag": 7.438373541723103, "train/policy_logprob_max": -0.009456029136295188, "train/policy_logprob_mean": -0.7933397056305245, "train/policy_logprob_min": -7.438373541723103, "train/policy_logprob_std": 1.2371865080916173, "train/policy_randomness_mag": 0.8943106360631446, "train/policy_randomness_max": 0.8943106360631446, "train/policy_randomness_mean": 0.27979776399320666, "train/policy_randomness_min": 0.028016333149312293, "train/policy_randomness_std": 0.24853654974671804, "train/post_ent_mag": 32.05131237256472, "train/post_ent_max": 32.05131237256472, "train/post_ent_mean": 18.252180021103115, "train/post_ent_min": 9.117251555124918, "train/post_ent_std": 3.912290925848974, "train/prior_ent_mag": 66.9698445568346, "train/prior_ent_max": 66.9698445568346, "train/prior_ent_mean": 20.99576686179801, "train/prior_ent_min": 10.145711755099361, "train/prior_ent_std": 8.179286941545739, "train/rep_loss_mean": 2.6047157686050624, "train/rep_loss_std": 7.153482084404932, "train/reward_avg": 0.014658693551111405, "train/reward_loss_mean": 0.03190569076942255, "train/reward_loss_std": 0.1660334055554377, "train/reward_max_data": 1.0187214656507588, "train/reward_max_pred": 1.0207841635839034, "train/reward_neg_acc": 0.996717223293705, "train/reward_neg_loss": 0.017917444440429885, "train/reward_pos_acc": 0.9856168981556479, "train/reward_pos_loss": 0.7350677823367184, "train/reward_pred": 0.014532503101030646, "train/reward_rate": 0.01950003567351598, "train_stats/sum_log_reward": 2.5166666011015573, "train_stats/max_log_achievement_collect_drink": 8.833333333333334, "train_stats/max_log_achievement_collect_sapling": 0.6666666666666666, "train_stats/max_log_achievement_collect_wood": 0.8333333333333334, "train_stats/max_log_achievement_place_plant": 0.5833333333333334, "train_stats/max_log_achievement_place_table": 0.0, "train_stats/max_log_achievement_wake_up": 2.25, "train_stats/mean_log_entropy": 0.8674933065970739, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 3.845647370326333e-06, "report/cont_loss_std": 3.904055483872071e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00013067593681626022, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.846983989002183e-06, "report/cont_pred": 0.9921857118606567, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 2.5454306602478027, "report/dyn_loss_std": 7.472916603088379, "report/image_loss_mean": 3.347709894180298, "report/image_loss_std": 5.206151962280273, "report/model_loss_mean": 4.902958869934082, "report/model_loss_std": 8.677961349487305, "report/post_ent_mag": 31.473072052001953, "report/post_ent_max": 31.473072052001953, "report/post_ent_mean": 18.322742462158203, "report/post_ent_min": 8.073348999023438, "report/post_ent_std": 4.060600280761719, "report/prior_ent_mag": 68.3199462890625, "report/prior_ent_max": 68.3199462890625, "report/prior_ent_mean": 21.160221099853516, "report/prior_ent_min": 9.714338302612305, "report/prior_ent_std": 8.462116241455078, "report/rep_loss_mean": 2.5454306602478027, "report/rep_loss_std": 7.472916603088379, "report/reward_avg": 0.007226561661809683, "report/reward_loss_mean": 0.027986619621515274, "report/reward_loss_std": 0.12536169588565826, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0035226345062256, "report/reward_neg_acc": 0.997026801109314, "report/reward_neg_loss": 0.018380213528871536, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6741774678230286, "report/reward_pred": 0.007300960831344128, "report/reward_rate": 0.0146484375, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.0004820549220312387, "eval/cont_loss_std": 0.015365555882453918, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.24651890993118286, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 5.738071422456414e-07, "eval/cont_pred": 0.9984269142150879, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 19.244361877441406, "eval/dyn_loss_std": 12.633991241455078, "eval/image_loss_mean": 29.191112518310547, "eval/image_loss_std": 26.59212875366211, "eval/model_loss_mean": 40.940311431884766, "eval/model_loss_std": 32.232818603515625, "eval/post_ent_mag": 34.269775390625, "eval/post_ent_max": 34.269775390625, "eval/post_ent_mean": 22.54329490661621, "eval/post_ent_min": 9.198936462402344, "eval/post_ent_std": 6.476707935333252, "eval/prior_ent_mag": 68.3199462890625, "eval/prior_ent_max": 68.3199462890625, "eval/prior_ent_mean": 27.560977935791016, "eval/prior_ent_min": 9.832650184631348, "eval/prior_ent_std": 9.783695220947266, "eval/rep_loss_mean": 19.244361877441406, "eval/rep_loss_std": 12.633991241455078, "eval/reward_avg": 0.015625, "eval/reward_loss_mean": 0.20209725201129913, "eval/reward_loss_std": 1.5148273706436157, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.000995397567749, "eval/reward_neg_acc": 1.0000001192092896, "eval/reward_neg_loss": 0.03691357746720314, "eval/reward_pos_acc": 0.2777777910232544, "eval/reward_pos_loss": 9.434029579162598, "eval/reward_pred": 0.0036665720399469137, "eval/reward_rate": 0.017578125, "replay/size": 11796.0, "replay/inserts": 2188.0, "replay/samples": 35008.0, "replay/insert_wait_avg": 2.5103689329715706e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.136552926609241e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 4960.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 8.940696716308594e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3108139038086, "timer/env.step_count": 274.0, "timer/env.step_total": 25.32443404197693, "timer/env.step_frac": 0.02531656530148455, "timer/env.step_avg": 0.09242494175903988, "timer/env.step_min": 0.023006916046142578, "timer/env.step_max": 1.7000141143798828, "timer/replay._sample_count": 35008.0, "timer/replay._sample_total": 16.878621816635132, "timer/replay._sample_frac": 0.016873377336354783, "timer/replay._sample_avg": 0.00048213613507298706, "timer/replay._sample_min": 0.0003428459167480469, "timer/replay._sample_max": 0.015758752822875977, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 274.0, "timer/agent.policy_total": 4.376354455947876, "timer/agent.policy_frac": 0.004374994646782568, "timer/agent.policy_avg": 0.015972096554554293, "timer/agent.policy_min": 0.009828329086303711, "timer/agent.policy_max": 0.03856372833251953, "timer/dataset_train_count": 2188.0, "timer/dataset_train_total": 0.4369196891784668, "timer/dataset_train_frac": 0.00043678393065985755, "timer/dataset_train_avg": 0.0001996890718365936, "timer/dataset_train_min": 9.34600830078125e-05, "timer/dataset_train_max": 0.040830135345458984, "timer/agent.train_count": 2188.0, "timer/agent.train_total": 968.5098323822021, "timer/agent.train_frac": 0.968208899594417, "timer/agent.train_avg": 0.44264617567742326, "timer/agent.train_min": 0.42678284645080566, "timer/agent.train_max": 0.551241397857666, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4752345085144043, "timer/agent.report_frac": 0.00047508684491748737, "timer/agent.report_avg": 0.23761725425720215, "timer/agent.report_min": 0.22980928421020508, "timer/agent.report_max": 0.24542522430419922, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9325485229492188e-05, "timer/dataset_eval_frac": 2.931637329306346e-08, "timer/dataset_eval_avg": 2.9325485229492188e-05, "timer/dataset_eval_min": 2.9325485229492188e-05, "timer/dataset_eval_max": 2.9325485229492188e-05, "fps": 2.1872947028205223}
{"step": 12496, "time": 5394.995574951172, "episode/length": 120.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9421487603305785, "episode/intrinsic_return": 0.0}
{"step": 12832, "time": 5548.683797597885, "episode/length": 146.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 13064, "time": 5655.1961581707, "episode/length": 235.0, "episode/score": 3.099999964237213, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 13176, "time": 5706.887269020081, "episode/length": 145.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 13224, "time": 5729.947624921799, "episode/length": 198.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 13464, "time": 5838.663332700729, "episode/length": 120.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9504132231404959, "episode/intrinsic_return": 0.0}
{"step": 13720, "time": 5954.693517208099, "episode/length": 193.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 13896, "time": 6035.0198793411255, "episode/length": 227.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 14232, "time": 6186.93855714798, "episode/length": 174.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 14495, "time": 6306.28520488739, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.248731360587899, "train/action_min": 0.0, "train/action_std": 4.443713780407492, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03878635299056088, "train/actor_opt_grad_steps": 11840.0, "train/actor_opt_loss": 1.7164549603718056, "train/adv_mag": 0.7565977993893297, "train/adv_max": 0.7201991277198269, "train/adv_mean": 0.0033728261607152634, "train/adv_min": -0.5752996418574085, "train/adv_std": 0.055802155294578916, "train/cont_avg": 0.9946578909817352, "train/cont_loss_mean": 0.00032619399183328294, "train/cont_loss_std": 0.010024268654625797, "train/cont_neg_acc": 0.989984710282142, "train/cont_neg_loss": 0.04919552659212585, "train/cont_pos_acc": 0.9999730951709834, "train/cont_pos_loss": 6.189439057950297e-05, "train/cont_pred": 0.9946730455307111, "train/cont_rate": 0.9946578909817352, "train/dyn_loss_mean": 2.6329285151337922, "train/dyn_loss_std": 7.30396612158649, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.3481309724180666, "train/extr_critic_critic_opt_grad_steps": 11840.0, "train/extr_critic_critic_opt_loss": 16583.824196454054, "train/extr_critic_mag": 18.208371362729704, "train/extr_critic_max": 18.208371362729704, "train/extr_critic_mean": 3.6071777730227605, "train/extr_critic_min": -0.5826321785852789, "train/extr_critic_std": 4.106918201054612, "train/extr_return_normed_mag": 1.5129655319261768, "train/extr_return_normed_max": 1.5129655319261768, "train/extr_return_normed_mean": 0.30941431598576236, "train/extr_return_normed_min": -0.06790730709711847, "train/extr_return_normed_std": 0.332420241342832, "train/extr_return_rate": 0.6689682383787686, "train/extr_return_raw_mag": 18.86643967563159, "train/extr_return_raw_max": 18.86643967563159, "train/extr_return_raw_mean": 3.6499832999216366, "train/extr_return_raw_min": -1.131170794027581, "train/extr_return_raw_std": 4.210288384189345, "train/extr_reward_mag": 1.0252726165126993, "train/extr_reward_max": 1.0252726165126993, "train/extr_reward_mean": 0.02660007960669118, "train/extr_reward_min": -0.6864370842502542, "train/extr_reward_std": 0.16286784053257067, "train/image_loss_mean": 3.2669951730667184, "train/image_loss_std": 6.313336742523054, "train/model_loss_mean": 4.879864001382976, "train/model_loss_std": 9.548265084828415, "train/model_opt_grad_norm": 53.92570437252794, "train/model_opt_grad_steps": 11826.296803652967, "train/model_opt_loss": 3989.661808379709, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 819.0639269406392, "train/policy_entropy_mag": 2.510556616195261, "train/policy_entropy_max": 2.510556616195261, "train/policy_entropy_mean": 0.8603151884253166, "train/policy_entropy_min": 0.07937555341687921, "train/policy_entropy_std": 0.7174017295989816, "train/policy_logprob_mag": 7.43837814461695, "train/policy_logprob_max": -0.009455864258178565, "train/policy_logprob_mean": -0.8603945965091931, "train/policy_logprob_min": -7.43837814461695, "train/policy_logprob_std": 1.2474769179679488, "train/policy_randomness_mag": 0.8861163152407293, "train/policy_randomness_max": 0.8861163152407293, "train/policy_randomness_mean": 0.30365350685979675, "train/policy_randomness_min": 0.028016087007985267, "train/policy_randomness_std": 0.25321132720333256, "train/post_ent_mag": 31.648185163872427, "train/post_ent_max": 31.648185163872427, "train/post_ent_mean": 18.348619504606344, "train/post_ent_min": 9.371057573518797, "train/post_ent_std": 3.7799419540248507, "train/prior_ent_mag": 68.59701036427118, "train/prior_ent_max": 68.59701036427118, "train/prior_ent_mean": 21.16314869710844, "train/prior_ent_min": 10.634484752672448, "train/prior_ent_std": 8.283373103294199, "train/rep_loss_mean": 2.6329285151337922, "train/rep_loss_std": 7.30396612158649, "train/reward_avg": 0.015182648271377535, "train/reward_loss_mean": 0.03278549342122797, "train/reward_loss_std": 0.17170888348801494, "train/reward_max_data": 1.012785391176128, "train/reward_max_pred": 1.0145010371186418, "train/reward_neg_acc": 0.9966196491293711, "train/reward_neg_loss": 0.018488697027234727, "train/reward_pos_acc": 0.9897015532946478, "train/reward_pos_loss": 0.7281730335597034, "train/reward_pred": 0.015166240496577941, "train/reward_rate": 0.020097567066210045, "train_stats/sum_log_reward": 3.655555486679077, "train_stats/max_log_achievement_collect_drink": 4.444444444444445, "train_stats/max_log_achievement_collect_sapling": 1.4444444444444444, "train_stats/max_log_achievement_collect_wood": 1.7777777777777777, "train_stats/max_log_achievement_eat_cow": 0.1111111111111111, "train_stats/max_log_achievement_place_plant": 1.3333333333333333, "train_stats/max_log_achievement_place_table": 0.3333333333333333, "train_stats/max_log_achievement_wake_up": 2.111111111111111, "train_stats/mean_log_entropy": 0.843167589770423, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 1.3090009360894328e-06, "report/cont_loss_std": 1.5183632058324292e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 7.0366695581469685e-06, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.26390125387843e-06, "report/cont_pred": 0.9921861886978149, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 2.904087543487549, "report/dyn_loss_std": 7.589421272277832, "report/image_loss_mean": 3.2099356651306152, "report/image_loss_std": 5.736015796661377, "report/model_loss_mean": 4.991152763366699, "report/model_loss_std": 9.085614204406738, "report/post_ent_mag": 31.458343505859375, "report/post_ent_max": 31.458343505859375, "report/post_ent_mean": 18.88909149169922, "report/post_ent_min": 8.914895057678223, "report/post_ent_std": 3.7669315338134766, "report/prior_ent_mag": 67.92161560058594, "report/prior_ent_max": 67.92161560058594, "report/prior_ent_mean": 21.90386390686035, "report/prior_ent_min": 10.889443397521973, "report/prior_ent_std": 8.555617332458496, "report/rep_loss_mean": 2.904087543487549, "report/rep_loss_std": 7.589421272277832, "report/reward_avg": 0.01982421800494194, "report/reward_loss_mean": 0.038763631135225296, "report/reward_loss_std": 0.173958882689476, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0011110305786133, "report/reward_neg_acc": 0.9989979863166809, "report/reward_neg_loss": 0.0220247320830822, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6812798976898193, "report/reward_pred": 0.020591210573911667, "report/reward_rate": 0.025390625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 2.7607679840002675e-06, "eval/cont_loss_std": 5.004337435821071e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0005179370637051761, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 7.404687494272366e-07, "eval/cont_pred": 0.9960949420928955, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 21.499494552612305, "eval/dyn_loss_std": 13.78272533416748, "eval/image_loss_mean": 58.355072021484375, "eval/image_loss_std": 77.90715026855469, "eval/model_loss_mean": 71.45037078857422, "eval/model_loss_std": 82.49581146240234, "eval/post_ent_mag": 42.00851058959961, "eval/post_ent_max": 42.00851058959961, "eval/post_ent_mean": 24.16741371154785, "eval/post_ent_min": 9.688484191894531, "eval/post_ent_std": 6.631545066833496, "eval/prior_ent_mag": 67.92161560058594, "eval/prior_ent_max": 67.92161560058594, "eval/prior_ent_mean": 29.650527954101562, "eval/prior_ent_min": 9.571565628051758, "eval/prior_ent_std": 10.437127113342285, "eval/rep_loss_mean": 21.499494552612305, "eval/rep_loss_std": 13.78272533416748, "eval/reward_avg": 0.01162109337747097, "eval/reward_loss_mean": 0.1956011950969696, "eval/reward_loss_std": 1.1565698385238647, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9981381893157959, "eval/reward_neg_acc": 0.9990079998970032, "eval/reward_neg_loss": 0.12067510932683945, "eval/reward_pos_acc": 0.5, "eval/reward_pos_loss": 4.9159440994262695, "eval/reward_pred": 0.004954664967954159, "eval/reward_rate": 0.015625, "replay/size": 13991.0, "replay/inserts": 2195.0, "replay/samples": 35120.0, "replay/insert_wait_avg": 2.6800637907753775e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.278283799156242e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 4960.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 7.897615432739258e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0956506729126, "timer/env.step_count": 274.0, "timer/env.step_total": 21.31859254837036, "timer/env.step_frac": 0.0213165536056738, "timer/env.step_avg": 0.07780508229332249, "timer/env.step_min": 0.02357196807861328, "timer/env.step_max": 2.0014801025390625, "timer/replay._sample_count": 35120.0, "timer/replay._sample_total": 17.28974151611328, "timer/replay._sample_frac": 0.017288087898872383, "timer/replay._sample_avg": 0.000492304712873385, "timer/replay._sample_min": 0.0003333091735839844, "timer/replay._sample_max": 0.010699987411499023, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 274.0, "timer/agent.policy_total": 4.409479379653931, "timer/agent.policy_frac": 0.004409057650322767, "timer/agent.policy_avg": 0.016092990436693176, "timer/agent.policy_min": 0.009828567504882812, "timer/agent.policy_max": 0.03945803642272949, "timer/dataset_train_count": 2195.0, "timer/dataset_train_total": 0.39254331588745117, "timer/dataset_train_frac": 0.0003925057724461946, "timer/dataset_train_avg": 0.00017883522363892993, "timer/dataset_train_min": 9.012222290039062e-05, "timer/dataset_train_max": 0.0009324550628662109, "timer/agent.train_count": 2195.0, "timer/agent.train_total": 972.2869203090668, "timer/agent.train_frac": 0.9721939293055272, "timer/agent.train_avg": 0.4429553167695065, "timer/agent.train_min": 0.43242764472961426, "timer/agent.train_max": 0.5687644481658936, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47594523429870605, "timer/agent.report_frac": 0.0004758997141708067, "timer/agent.report_avg": 0.23797261714935303, "timer/agent.report_min": 0.23109936714172363, "timer/agent.report_max": 0.24484586715698242, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0279159545898438e-05, "timer/dataset_eval_frac": 3.027626360091173e-08, "timer/dataset_eval_avg": 3.0279159545898438e-05, "timer/dataset_eval_min": 3.0279159545898438e-05, "timer/dataset_eval_max": 3.0279159545898438e-05, "fps": 2.1947619844827027}
{"step": 14560, "time": 6335.760085105896, "episode/length": 326.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9908256880733946, "episode/intrinsic_return": 0.0}
{"step": 14584, "time": 6347.965116024017, "episode/length": 169.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 14608, "time": 6360.359055042267, "episode/length": 192.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 14704, "time": 6405.086658000946, "episode/length": 154.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 14888, "time": 6489.331599473953, "episode/length": 145.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.0}
{"step": 15176, "time": 6621.480992794037, "episode/length": 249.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.984, "episode/intrinsic_return": 0.0}
{"step": 15664, "time": 6841.85430765152, "episode/length": 137.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.0}
{"step": 15856, "time": 6929.1696236133575, "episode/length": 155.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 15896, "time": 6948.505044937134, "episode/length": 207.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 16032, "time": 7010.7754917144775, "episode/length": 266.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9812734082397003, "episode/intrinsic_return": 0.0}
{"step": 16104, "time": 7044.3404223918915, "episode/length": 151.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 16144, "time": 7063.703903198242, "episode/length": 179.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 16680, "time": 7306.382858276367, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.055271375124858, "train/action_min": 0.0, "train/action_std": 4.176017124358922, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03603636561021141, "train/actor_opt_grad_steps": 14030.0, "train/actor_opt_loss": 3.1264067849816253, "train/adv_mag": 0.6643345668979975, "train/adv_max": 0.6186527155986116, "train/adv_mean": 0.004205429213603674, "train/adv_min": -0.5218253704510867, "train/adv_std": 0.04988337360900831, "train/cont_avg": 0.9944839825913242, "train/cont_loss_mean": 0.00023172780172797617, "train/cont_loss_std": 0.005794014631811485, "train/cont_neg_acc": 0.9975646883929701, "train/cont_neg_loss": 0.006363194902277445, "train/cont_pos_acc": 0.9999685801871835, "train/cont_pos_loss": 0.00019506337405055424, "train/cont_pred": 0.994450216151808, "train/cont_rate": 0.9944839825913242, "train/dyn_loss_mean": 2.6168684208229798, "train/dyn_loss_std": 7.378058951739307, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.3266677461802687, "train/extr_critic_critic_opt_grad_steps": 14030.0, "train/extr_critic_critic_opt_loss": 16487.27039187357, "train/extr_critic_mag": 18.418767280230238, "train/extr_critic_max": 18.418767280230238, "train/extr_critic_mean": 4.139535900664656, "train/extr_critic_min": -0.5682718242140121, "train/extr_critic_std": 4.228003778414095, "train/extr_return_normed_mag": 1.449966053984481, "train/extr_return_normed_max": 1.449966053984481, "train/extr_return_normed_mean": 0.3296690791437071, "train/extr_return_normed_min": -0.07355126153388525, "train/extr_return_normed_std": 0.3278390701911221, "train/extr_return_rate": 0.8036411165102432, "train/extr_return_raw_mag": 18.944529320007046, "train/extr_return_raw_max": 18.944529320007046, "train/extr_return_raw_mean": 4.194973486199227, "train/extr_return_raw_min": -1.114364472017985, "train/extr_return_raw_std": 4.322193342801098, "train/extr_reward_mag": 1.0192318800921853, "train/extr_reward_max": 1.0192318800921853, "train/extr_reward_mean": 0.027302433881211226, "train/extr_reward_min": -0.6792517944013692, "train/extr_reward_std": 0.1639243793678066, "train/image_loss_mean": 2.9772283372269372, "train/image_loss_std": 6.012923177518801, "train/model_loss_mean": 4.580584851574136, "train/model_loss_std": 9.338898149255204, "train/model_opt_grad_norm": 49.449299383600916, "train/model_opt_grad_steps": 14014.986301369863, "train/model_opt_loss": 4376.233821503103, "train/model_opt_model_opt_grad_overflow": 0.0045662100456621, "train/model_opt_model_opt_grad_scale": 967.4657534246576, "train/policy_entropy_mag": 2.4492943428422764, "train/policy_entropy_max": 2.4492943428422764, "train/policy_entropy_mean": 0.7771100279403059, "train/policy_entropy_min": 0.07937533592116343, "train/policy_entropy_std": 0.6554452529236606, "train/policy_logprob_mag": 7.43837993003462, "train/policy_logprob_max": -0.009455809310146663, "train/policy_logprob_mean": -0.7769121364371417, "train/policy_logprob_min": -7.43837993003462, "train/policy_logprob_std": 1.2094410772192967, "train/policy_randomness_mag": 0.8644934190462713, "train/policy_randomness_max": 0.8644934190462713, "train/policy_randomness_mean": 0.27428573914314514, "train/policy_randomness_min": 0.028016010256798844, "train/policy_randomness_std": 0.23134341189578245, "train/post_ent_mag": 31.264458913236993, "train/post_ent_max": 31.264458913236993, "train/post_ent_mean": 18.46920053490765, "train/post_ent_min": 9.745379713572323, "train/post_ent_std": 3.6879613257978603, "train/prior_ent_mag": 69.46650103564676, "train/prior_ent_max": 69.46650103564676, "train/prior_ent_mean": 21.231816043592477, "train/prior_ent_min": 10.777668626341102, "train/prior_ent_std": 8.34950240888552, "train/rep_loss_mean": 2.6168684208229798, "train/rep_loss_std": 7.378058951739307, "train/reward_avg": 0.015882295073694697, "train/reward_loss_mean": 0.03300374127141961, "train/reward_loss_std": 0.16621375971869246, "train/reward_max_data": 1.009589043382096, "train/reward_max_pred": 1.0115842966184223, "train/reward_neg_acc": 0.996944204585193, "train/reward_neg_loss": 0.018149982304333553, "train/reward_pos_acc": 0.9865073458244812, "train/reward_pos_loss": 0.7318933812994936, "train/reward_pred": 0.015783130431539255, "train/reward_rate": 0.02086900684931507, "train_stats/sum_log_reward": 4.099999904632568, "train_stats/max_log_achievement_collect_drink": 6.0, "train_stats/max_log_achievement_collect_sapling": 2.3333333333333335, "train_stats/max_log_achievement_collect_wood": 1.6666666666666667, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.16666666666666666, "train_stats/max_log_achievement_place_plant": 1.75, "train_stats/max_log_achievement_place_table": 0.4166666666666667, "train_stats/max_log_achievement_wake_up": 1.8333333333333333, "train_stats/mean_log_entropy": 0.8482100913921992, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.0018894923850893974, "report/cont_loss_std": 0.06036829203367233, "report/cont_neg_acc": 0.800000011920929, "report/cont_neg_loss": 0.38658636808395386, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.8729273278950131e-06, "report/cont_pred": 0.9959506988525391, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 3.054516553878784, "report/dyn_loss_std": 7.826440811157227, "report/image_loss_mean": 3.573735475540161, "report/image_loss_std": 7.285626411437988, "report/model_loss_mean": 5.43076753616333, "report/model_loss_std": 11.155817985534668, "report/post_ent_mag": 32.561912536621094, "report/post_ent_max": 32.561912536621094, "report/post_ent_mean": 19.578235626220703, "report/post_ent_min": 10.6624755859375, "report/post_ent_std": 3.7580482959747314, "report/prior_ent_mag": 69.84619903564453, "report/prior_ent_max": 69.84619903564453, "report/prior_ent_mean": 22.434480667114258, "report/prior_ent_min": 11.975955963134766, "report/prior_ent_std": 8.489029884338379, "report/rep_loss_mean": 3.054516553878784, "report/rep_loss_std": 7.826440811157227, "report/reward_avg": 0.01191406138241291, "report/reward_loss_mean": 0.022432802245020866, "report/reward_loss_std": 0.1132030189037323, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0034685134887695, "report/reward_neg_acc": 0.9980159401893616, "report/reward_neg_loss": 0.012066790834069252, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6754915714263916, "report/reward_pred": 0.012184932827949524, "report/reward_rate": 0.015625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.02020004764199257, "eval/cont_loss_std": 0.48809683322906494, "eval/cont_neg_acc": 0.5, "eval/cont_neg_loss": 5.169367790222168, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 7.242105311888736e-06, "eval/cont_pred": 0.998038113117218, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 24.7582950592041, "eval/dyn_loss_std": 13.897696495056152, "eval/image_loss_mean": 67.55012512207031, "eval/image_loss_std": 71.48878479003906, "eval/model_loss_mean": 82.65721893310547, "eval/model_loss_std": 75.9859390258789, "eval/post_ent_mag": 38.231781005859375, "eval/post_ent_max": 38.231781005859375, "eval/post_ent_mean": 25.561267852783203, "eval/post_ent_min": 10.748836517333984, "eval/post_ent_std": 6.419277191162109, "eval/prior_ent_mag": 69.84619903564453, "eval/prior_ent_max": 69.84619903564453, "eval/prior_ent_mean": 31.22516632080078, "eval/prior_ent_min": 10.794610977172852, "eval/prior_ent_std": 11.333959579467773, "eval/rep_loss_mean": 24.7582950592041, "eval/rep_loss_std": 13.897696495056152, "eval/reward_avg": 0.01396484486758709, "eval/reward_loss_mean": 0.23191863298416138, "eval/reward_loss_std": 1.417549967765808, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0026311874389648, "eval/reward_neg_acc": 0.9980120062828064, "eval/reward_neg_loss": 0.17294946312904358, "eval/reward_pos_acc": 0.6111111044883728, "eval/reward_pos_loss": 3.5276401042938232, "eval/reward_pred": 0.009425092488527298, "eval/reward_rate": 0.017578125, "replay/size": 16176.0, "replay/inserts": 2185.0, "replay/samples": 34960.0, "replay/insert_wait_avg": 2.676944165262532e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.726030437024289e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 4960.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 9.834766387939453e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.082939863205, "timer/env.step_count": 273.0, "timer/env.step_total": 25.18772292137146, "timer/env.step_frac": 0.02518563402833042, "timer/env.step_avg": 0.09226272132370499, "timer/env.step_min": 0.023279666900634766, "timer/env.step_max": 1.628722906112671, "timer/replay._sample_count": 34960.0, "timer/replay._sample_total": 17.742255926132202, "timer/replay._sample_frac": 0.01774078450789197, "timer/replay._sample_avg": 0.0005075015997177404, "timer/replay._sample_min": 0.00034928321838378906, "timer/replay._sample_max": 0.028261899948120117, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 273.0, "timer/agent.policy_total": 4.42779278755188, "timer/agent.policy_frac": 0.004427425577480134, "timer/agent.policy_avg": 0.016219021199823738, "timer/agent.policy_min": 0.010203361511230469, "timer/agent.policy_max": 0.04252433776855469, "timer/dataset_train_count": 2185.0, "timer/dataset_train_total": 0.38725996017456055, "timer/dataset_train_frac": 0.00038722784355018735, "timer/dataset_train_avg": 0.0001772356797137577, "timer/dataset_train_min": 9.036064147949219e-05, "timer/dataset_train_max": 0.0007734298706054688, "timer/agent.train_count": 2185.0, "timer/agent.train_total": 968.1269912719727, "timer/agent.train_frac": 0.9680467016109651, "timer/agent.train_avg": 0.4430787145409486, "timer/agent.train_min": 0.43056249618530273, "timer/agent.train_max": 0.5661811828613281, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47829246520996094, "timer/agent.report_frac": 0.00047825279898823546, "timer/agent.report_avg": 0.23914623260498047, "timer/agent.report_min": 0.23091554641723633, "timer/agent.report_max": 0.2473769187927246, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 6.651878356933594e-05, "timer/dataset_eval_frac": 6.65132669680723e-08, "timer/dataset_eval_avg": 6.651878356933594e-05, "timer/dataset_eval_min": 6.651878356933594e-05, "timer/dataset_eval_max": 6.651878356933594e-05, "fps": 2.184792318610615}
{"step": 16904, "time": 7407.171139717102, "episode/length": 215.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 16928, "time": 7419.482954502106, "episode/length": 157.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 17256, "time": 7568.654802083969, "episode/length": 174.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 17368, "time": 7620.293376207352, "episode/length": 152.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.0}
{"step": 17384, "time": 7629.000818729401, "episode/length": 185.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 17384, "time": 7629.010046482086, "episode/length": 168.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 17544, "time": 7703.943864107132, "episode/length": 369.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9756756756756757, "episode/intrinsic_return": 0.0}
{"step": 18032, "time": 7925.5162353515625, "episode/length": 240.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.983402489626556, "episode/intrinsic_return": 0.0}
{"step": 18224, "time": 8013.422935247421, "episode/length": 104.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9523809523809523, "episode/intrinsic_return": 0.0}
{"step": 18360, "time": 8075.879575014114, "episode/length": 181.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 18472, "time": 8127.866709470749, "episode/length": 192.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9689119170984456, "episode/intrinsic_return": 0.0}
{"step": 18552, "time": 8165.092027902603, "episode/length": 161.0, "episode/score": 2.0999999791383743, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 18640, "time": 8205.911539316177, "episode/length": 156.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 18784, "time": 8271.865982055664, "episode/length": 176.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 18857, "time": 8306.710799217224, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.394887054021457, "train/action_min": 0.0, "train/action_std": 4.559071595767676, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03469775245451982, "train/actor_opt_grad_steps": 16210.0, "train/actor_opt_loss": -0.9242418735944731, "train/adv_mag": 0.635326021827311, "train/adv_max": 0.5956870888784733, "train/adv_mean": 0.0028919742393982277, "train/adv_min": -0.4959686602452933, "train/adv_std": 0.04726675703846914, "train/cont_avg": 0.9943881408410138, "train/cont_loss_mean": 0.000193900724830431, "train/cont_loss_std": 0.005884160931066634, "train/cont_neg_acc": 0.9935867899024542, "train/cont_neg_loss": 0.03324040042855306, "train/cont_pos_acc": 0.9999909315790448, "train/cont_pos_loss": 3.5702739675844613e-05, "train/cont_pred": 0.9944011000444263, "train/cont_rate": 0.9943881408410138, "train/dyn_loss_mean": 2.6712886122514576, "train/dyn_loss_std": 7.434650150861608, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.3261522389776697, "train/extr_critic_critic_opt_grad_steps": 16210.0, "train/extr_critic_critic_opt_loss": 16202.589902253745, "train/extr_critic_mag": 19.785858694858813, "train/extr_critic_max": 19.785858694858813, "train/extr_critic_mean": 4.573332078995243, "train/extr_critic_min": -0.5777049635961857, "train/extr_critic_std": 4.858996523140762, "train/extr_return_normed_mag": 1.3744902336103026, "train/extr_return_normed_max": 1.3744902336103026, "train/extr_return_normed_mean": 0.3194904354173467, "train/extr_return_normed_min": -0.056641951838534, "train/extr_return_normed_std": 0.32960920358583123, "train/extr_return_rate": 0.795084226790661, "train/extr_return_raw_mag": 20.448944030269498, "train/extr_return_raw_max": 20.448944030269498, "train/extr_return_raw_mean": 4.616968720739338, "train/extr_return_raw_min": -1.0259746436699195, "train/extr_return_raw_std": 4.946115274033788, "train/extr_reward_mag": 1.0154290462968536, "train/extr_reward_max": 1.0154290462968536, "train/extr_reward_mean": 0.026304816037485128, "train/extr_reward_min": -0.6787255996932632, "train/extr_reward_std": 0.1629124247396047, "train/image_loss_mean": 2.8669735660201394, "train/image_loss_std": 5.922274794996059, "train/model_loss_mean": 4.503359745175058, "train/model_loss_std": 9.293110823301676, "train/model_opt_grad_norm": 51.495968124284175, "train/model_opt_grad_steps": 16192.963133640553, "train/model_opt_loss": 4376.77397359681, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 979.2626728110599, "train/policy_entropy_mag": 2.4966006059251074, "train/policy_entropy_max": 2.4966006059251074, "train/policy_entropy_mean": 0.8532922111348622, "train/policy_entropy_min": 0.07937523241966002, "train/policy_entropy_std": 0.7067917044261633, "train/policy_logprob_mag": 7.438380979722546, "train/policy_logprob_max": -0.009455769292769893, "train/policy_logprob_mean": -0.8536799462160207, "train/policy_logprob_min": -7.438380979722546, "train/policy_logprob_std": 1.2421827321777696, "train/policy_randomness_mag": 0.8811904524328522, "train/policy_randomness_max": 0.8811904524328522, "train/policy_randomness_mean": 0.30117470582234696, "train/policy_randomness_min": 0.028015973758862316, "train/policy_randomness_std": 0.24946645417246402, "train/post_ent_mag": 32.19284223741101, "train/post_ent_max": 32.19284223741101, "train/post_ent_mean": 18.578745767268167, "train/post_ent_min": 9.846236892559562, "train/post_ent_std": 3.725494894563877, "train/prior_ent_mag": 70.19481838243898, "train/prior_ent_max": 70.19481838243898, "train/prior_ent_mean": 21.415737319102487, "train/prior_ent_min": 11.204485598797072, "train/prior_ent_std": 8.488696300489012, "train/rep_loss_mean": 2.6712886122514576, "train/rep_loss_std": 7.434650150861608, "train/reward_avg": 0.016259090434159, "train/reward_loss_mean": 0.0334190768511614, "train/reward_loss_std": 0.16445185017475883, "train/reward_max_data": 1.0092165920591574, "train/reward_max_pred": 1.0110408512678015, "train/reward_neg_acc": 0.9967121915883183, "train/reward_neg_loss": 0.01823325465918274, "train/reward_pos_acc": 0.9874903389385769, "train/reward_pos_loss": 0.7279491289969413, "train/reward_pred": 0.01615070588972574, "train/reward_rate": 0.021394369239631335, "train_stats/sum_log_reward": 3.7428570645196095, "train_stats/max_log_achievement_collect_drink": 3.9285714285714284, "train_stats/max_log_achievement_collect_sapling": 2.2857142857142856, "train_stats/max_log_achievement_collect_wood": 1.5714285714285714, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.14285714285714285, "train_stats/max_log_achievement_place_plant": 1.7142857142857142, "train_stats/max_log_achievement_place_table": 0.2857142857142857, "train_stats/max_log_achievement_wake_up": 1.9285714285714286, "train_stats/mean_log_entropy": 0.7418239499841418, "train_stats/max_log_achievement_make_wood_pickaxe": 0.09090909090909091, "train_stats/max_log_achievement_defeat_zombie": 0.1, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 1.4304000615084078e-06, "report/cont_loss_std": 3.0270391562225996e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.156016060122056e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.370696281810524e-06, "report/cont_pred": 0.9941393136978149, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 2.5473337173461914, "report/dyn_loss_std": 7.653384685516357, "report/image_loss_mean": 2.815514087677002, "report/image_loss_std": 5.882193088531494, "report/model_loss_mean": 4.369255065917969, "report/model_loss_std": 9.097457885742188, "report/post_ent_mag": 31.614961624145508, "report/post_ent_max": 31.614961624145508, "report/post_ent_mean": 17.98601722717285, "report/post_ent_min": 10.47324275970459, "report/post_ent_std": 3.5979578495025635, "report/prior_ent_mag": 70.34043884277344, "report/prior_ent_max": 70.34043884277344, "report/prior_ent_mean": 20.843910217285156, "report/prior_ent_min": 11.842008590698242, "report/prior_ent_std": 8.605206489562988, "report/rep_loss_mean": 2.5473337173461914, "report/rep_loss_std": 7.653384685516357, "report/reward_avg": 0.008984374813735485, "report/reward_loss_mean": 0.025339482352137566, "report/reward_loss_std": 0.12018530070781708, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0023562908172607, "report/reward_neg_acc": 0.99702388048172, "report/reward_neg_loss": 0.01504292618483305, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6740225553512573, "report/reward_pred": 0.00940913986414671, "report/reward_rate": 0.015625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.013555826619267464, "eval/cont_loss_std": 0.4333818256855011, "eval/cont_neg_acc": 0.6666666865348816, "eval/cont_neg_loss": 4.625378131866455, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 4.9277691687166225e-06, "eval/cont_pred": 0.9980430603027344, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 24.09736442565918, "eval/dyn_loss_std": 14.169753074645996, "eval/image_loss_mean": 67.87545776367188, "eval/image_loss_std": 83.70501708984375, "eval/model_loss_mean": 82.59432983398438, "eval/model_loss_std": 89.00364685058594, "eval/post_ent_mag": 39.58800506591797, "eval/post_ent_max": 39.58800506591797, "eval/post_ent_mean": 25.51274871826172, "eval/post_ent_min": 10.592784881591797, "eval/post_ent_std": 6.3419575691223145, "eval/prior_ent_mag": 70.34043884277344, "eval/prior_ent_max": 70.34043884277344, "eval/prior_ent_mean": 31.140682220458984, "eval/prior_ent_min": 9.716802597045898, "eval/prior_ent_std": 10.29723834991455, "eval/rep_loss_mean": 24.09736442565918, "eval/rep_loss_std": 14.169753074645996, "eval/reward_avg": 0.00957031175494194, "eval/reward_loss_mean": 0.24689005315303802, "eval/reward_loss_std": 1.3998923301696777, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.000558853149414, "eval/reward_neg_acc": 0.9980178475379944, "eval/reward_neg_loss": 0.16535727679729462, "eval/reward_pos_acc": 0.40000003576278687, "eval/reward_pos_loss": 5.73132848739624, "eval/reward_pred": 0.00431730505079031, "eval/reward_rate": 0.0146484375, "replay/size": 18353.0, "replay/inserts": 2177.0, "replay/samples": 34832.0, "replay/insert_wait_avg": 2.548461339317115e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.336819779725046e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 4960.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 7.599592208862305e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.318412065506, "timer/env.step_count": 273.0, "timer/env.step_total": 28.809995412826538, "timer/env.step_frac": 0.028800824882687367, "timer/env.step_avg": 0.10553111872830234, "timer/env.step_min": 0.023729801177978516, "timer/env.step_max": 3.2255024909973145, "timer/replay._sample_count": 34832.0, "timer/replay._sample_total": 17.022671699523926, "timer/replay._sample_frac": 0.017017253200783025, "timer/replay._sample_avg": 0.0004887078462196809, "timer/replay._sample_min": 0.00033593177795410156, "timer/replay._sample_max": 0.007628917694091797, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 273.0, "timer/agent.policy_total": 4.39787483215332, "timer/agent.policy_frac": 0.004396474941486256, "timer/agent.policy_avg": 0.016109431619609232, "timer/agent.policy_min": 0.009836435317993164, "timer/agent.policy_max": 0.0422060489654541, "timer/dataset_train_count": 2177.0, "timer/dataset_train_total": 0.38169264793395996, "timer/dataset_train_frac": 0.0003815711510756085, "timer/dataset_train_avg": 0.00017532964994669727, "timer/dataset_train_min": 8.654594421386719e-05, "timer/dataset_train_max": 0.0013663768768310547, "timer/agent.train_count": 2177.0, "timer/agent.train_total": 964.9775071144104, "timer/agent.train_frac": 0.9646703444375057, "timer/agent.train_avg": 0.4432602237548968, "timer/agent.train_min": 0.43092989921569824, "timer/agent.train_max": 0.5594081878662109, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47591614723205566, "timer/agent.report_frac": 0.0004757646580245993, "timer/agent.report_avg": 0.23795807361602783, "timer/agent.report_min": 0.23106074333190918, "timer/agent.report_max": 0.24485540390014648, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.075599670410156e-05, "timer/dataset_eval_frac": 3.0746206740906716e-08, "timer/dataset_eval_avg": 3.075599670410156e-05, "timer/dataset_eval_min": 3.075599670410156e-05, "timer/dataset_eval_max": 3.075599670410156e-05, "fps": 2.1762802197289153}
{"step": 18880, "time": 8317.278501987457, "episode/length": 40.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 19200, "time": 8462.178750753403, "episode/length": 206.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 19424, "time": 8564.534958839417, "episode/length": 132.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9473684210526315, "episode/intrinsic_return": 0.0}
{"step": 19568, "time": 8631.202070951462, "episode/length": 191.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 19640, "time": 8665.02510881424, "episode/length": 176.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 19936, "time": 8799.156408548355, "episode/length": 161.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 19960, "time": 8811.460058927536, "episode/length": 185.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 19976, "time": 8820.176901578903, "episode/length": 136.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9562043795620438, "episode/intrinsic_return": 0.0}
{"step": 20072, "time": 8880.004712820053, "eval_episode/length": 79.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.925}
{"step": 20072, "time": 8883.935456514359, "eval_episode/length": 143.0, "eval_episode/score": 2.0999999940395355, "eval_episode/reward_rate": 0.9930555555555556}
{"step": 20072, "time": 8886.096519470215, "eval_episode/length": 161.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9938271604938271}
{"step": 20072, "time": 8887.78896856308, "eval_episode/length": 167.0, "eval_episode/score": 2.0999999716877937, "eval_episode/reward_rate": 0.9940476190476191}
{"step": 20072, "time": 8889.849429607391, "eval_episode/length": 182.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9726775956284153}
{"step": 20072, "time": 8891.519584655762, "eval_episode/length": 186.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9946524064171123}
{"step": 20072, "time": 8893.882957696915, "eval_episode/length": 208.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9760765550239234}
{"step": 20072, "time": 8895.717280864716, "eval_episode/length": 137.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9927536231884058}
{"step": 20368, "time": 9028.538336992264, "episode/length": 197.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 20528, "time": 9101.72059583664, "episode/length": 165.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 20976, "time": 9304.622596502304, "episode/length": 175.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 20977, "time": 9307.024281978607, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.253825925431162, "train/action_min": 0.0, "train/action_std": 4.253264087551045, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0380542567702678, "train/actor_opt_grad_steps": 18355.0, "train/actor_opt_loss": 8.812237983674935, "train/adv_mag": 0.6398913258651517, "train/adv_max": 0.602716197663883, "train/adv_mean": 0.006035549519154147, "train/adv_min": -0.5269213242913192, "train/adv_std": 0.05226708558511059, "train/cont_avg": 0.9945229584316038, "train/cont_loss_mean": 6.745295127879612e-05, "train/cont_loss_std": 0.002091912590771419, "train/cont_neg_acc": 0.9978773585467968, "train/cont_neg_loss": 0.00821259928319735, "train/cont_pos_acc": 0.9999999820061449, "train/cont_pos_loss": 9.499720067758903e-06, "train/cont_pred": 0.9945286880686598, "train/cont_rate": 0.9945229584316038, "train/dyn_loss_mean": 2.643632992258612, "train/dyn_loss_std": 7.460890799198511, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.3862118979669966, "train/extr_critic_critic_opt_grad_steps": 18355.0, "train/extr_critic_critic_opt_loss": 16544.69170106132, "train/extr_critic_mag": 20.48389677731496, "train/extr_critic_max": 20.48389677731496, "train/extr_critic_mean": 5.320200252083112, "train/extr_critic_min": -0.5383993600899318, "train/extr_critic_std": 4.954885707711274, "train/extr_return_normed_mag": 1.3404409331533145, "train/extr_return_normed_max": 1.3404409331533145, "train/extr_return_normed_mean": 0.33522421571443667, "train/extr_return_normed_min": -0.07166741411465238, "train/extr_return_normed_std": 0.32145209280106257, "train/extr_return_rate": 0.907566563419576, "train/extr_return_raw_mag": 21.276349890906857, "train/extr_return_raw_max": 21.276349890906857, "train/extr_return_raw_mean": 5.417151073239884, "train/extr_return_raw_min": -1.0241168811917305, "train/extr_return_raw_std": 5.076791829658005, "train/extr_reward_mag": 1.0164121288173604, "train/extr_reward_max": 1.0164121288173604, "train/extr_reward_mean": 0.027217385205352364, "train/extr_reward_min": -0.6834780618829547, "train/extr_reward_std": 0.16525518718474316, "train/image_loss_mean": 2.53854194395947, "train/image_loss_std": 5.524725647467487, "train/model_loss_mean": 4.159265242657572, "train/model_loss_std": 8.97657303765135, "train/model_opt_grad_norm": 47.92889008432064, "train/model_opt_grad_steps": 18336.35849056604, "train/model_opt_loss": 5315.60889362839, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1279.4811320754718, "train/policy_entropy_mag": 2.435218207116397, "train/policy_entropy_max": 2.435218207116397, "train/policy_entropy_mean": 0.7271447727140391, "train/policy_entropy_min": 0.0793751447971137, "train/policy_entropy_std": 0.6411245102589985, "train/policy_logprob_mag": 7.438382834758398, "train/policy_logprob_max": -0.0094557284193008, "train/policy_logprob_mean": -0.7263972191315777, "train/policy_logprob_min": -7.438382834758398, "train/policy_logprob_std": 1.1910481526041932, "train/policy_randomness_mag": 0.8595251626563523, "train/policy_randomness_max": 0.8595251626563523, "train/policy_randomness_mean": 0.25665019529889216, "train/policy_randomness_min": 0.02801594285751289, "train/policy_randomness_std": 0.22628881852581817, "train/post_ent_mag": 31.99325802641095, "train/post_ent_max": 31.99325802641095, "train/post_ent_mean": 18.619289749073534, "train/post_ent_min": 9.771342918557941, "train/post_ent_std": 3.7745094917855173, "train/prior_ent_mag": 70.61484074142744, "train/prior_ent_max": 70.61484074142744, "train/prior_ent_mean": 21.37452749036393, "train/prior_ent_min": 10.877091920600748, "train/prior_ent_std": 8.55123980989996, "train/rep_loss_mean": 2.643632992258612, "train/rep_loss_std": 7.460890799198511, "train/reward_avg": 0.017382812354590674, "train/reward_loss_mean": 0.03447603154048886, "train/reward_loss_std": 0.1682666279375553, "train/reward_max_data": 1.0084905680620446, "train/reward_max_pred": 1.010526862909209, "train/reward_neg_acc": 0.9965795601876277, "train/reward_neg_loss": 0.018655075570832024, "train/reward_pos_acc": 0.9877566810486451, "train/reward_pos_loss": 0.7267104066767782, "train/reward_pred": 0.01724097099076113, "train/reward_rate": 0.022354989681603772, "train_stats/sum_log_reward": 2.8272726752541284, "train_stats/max_log_achievement_collect_drink": 1.3636363636363635, "train_stats/max_log_achievement_collect_sapling": 1.4545454545454546, "train_stats/max_log_achievement_collect_wood": 1.2727272727272727, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.09090909090909091, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.3636363636363635, "train_stats/max_log_achievement_place_table": 0.09090909090909091, "train_stats/max_log_achievement_wake_up": 1.4545454545454546, "train_stats/mean_log_entropy": 0.7989368519999764, "eval_stats/sum_log_reward": 2.2249999344348907, "eval_stats/max_log_achievement_collect_drink": 6.0, "eval_stats/max_log_achievement_collect_sapling": 1.75, "eval_stats/max_log_achievement_collect_wood": 0.25, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 1.125, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 0.375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 9.337425694866397e-07, "report/cont_loss_std": 1.2670621799770743e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00014075502986088395, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 3.854237604627997e-07, "report/cont_pred": 0.9960940480232239, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 2.598112106323242, "report/dyn_loss_std": 7.19875955581665, "report/image_loss_mean": 2.483762264251709, "report/image_loss_std": 5.425759792327881, "report/model_loss_mean": 4.072798728942871, "report/model_loss_std": 8.697394371032715, "report/post_ent_mag": 31.30177116394043, "report/post_ent_max": 31.30177116394043, "report/post_ent_mean": 18.557884216308594, "report/post_ent_min": 10.540257453918457, "report/post_ent_std": 3.7077219486236572, "report/prior_ent_mag": 71.45631408691406, "report/prior_ent_max": 71.45631408691406, "report/prior_ent_mean": 21.350553512573242, "report/prior_ent_min": 11.663154602050781, "report/prior_ent_std": 8.456954002380371, "report/rep_loss_mean": 2.598112106323242, "report/rep_loss_std": 7.19875955581665, "report/reward_avg": 0.01923828199505806, "report/reward_loss_mean": 0.03016841597855091, "report/reward_loss_std": 0.16372765600681305, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0054001808166504, "report/reward_neg_acc": 0.9940059781074524, "report/reward_neg_loss": 0.015465459786355495, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6700665950775146, "report/reward_pred": 0.0190884992480278, "report/reward_rate": 0.0224609375, "eval/cont_avg": 0.9912109375, "eval/cont_loss_mean": 0.02847699075937271, "eval/cont_loss_std": 0.530806839466095, "eval/cont_neg_acc": 0.6666666865348816, "eval/cont_neg_loss": 3.219719648361206, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.00018025928875431418, "eval/cont_pred": 0.9939767122268677, "eval/cont_rate": 0.9912109375, "eval/dyn_loss_mean": 21.047016143798828, "eval/dyn_loss_std": 12.16870403289795, "eval/image_loss_mean": 34.806968688964844, "eval/image_loss_std": 40.189735412597656, "eval/model_loss_mean": 47.6586799621582, "eval/model_loss_std": 44.551448822021484, "eval/post_ent_mag": 36.70870590209961, "eval/post_ent_max": 36.70870590209961, "eval/post_ent_mean": 24.272315979003906, "eval/post_ent_min": 10.039837837219238, "eval/post_ent_std": 5.455043315887451, "eval/prior_ent_mag": 71.45631408691406, "eval/prior_ent_max": 71.45631408691406, "eval/prior_ent_mean": 30.0079402923584, "eval/prior_ent_min": 10.262418746948242, "eval/prior_ent_std": 10.384132385253906, "eval/rep_loss_mean": 21.047016143798828, "eval/rep_loss_std": 12.16870403289795, "eval/reward_avg": 0.00908203050494194, "eval/reward_loss_mean": 0.19502317905426025, "eval/reward_loss_std": 1.1400986909866333, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.001230239868164, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.1245913878083229, "eval/reward_pos_acc": 0.529411792755127, "eval/reward_pos_loss": 4.367071628570557, "eval/reward_pred": 0.0014072740450501442, "eval/reward_rate": 0.0166015625, "replay/size": 20473.0, "replay/inserts": 2120.0, "replay/samples": 33920.0, "replay/insert_wait_avg": 2.5952762027956403e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.324412746249505e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 6704.0, "eval_replay/inserts": 1744.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0776683824871659e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.493661880493164e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2987470626831, "timer/env.step_count": 265.0, "timer/env.step_total": 23.51071286201477, "timer/env.step_frac": 0.023503691203305574, "timer/env.step_avg": 0.08871967117741422, "timer/env.step_min": 0.023589372634887695, "timer/env.step_max": 1.9721593856811523, "timer/replay._sample_count": 33920.0, "timer/replay._sample_total": 16.37718939781189, "timer/replay._sample_frac": 0.016372298221808752, "timer/replay._sample_avg": 0.00048281808366190714, "timer/replay._sample_min": 0.0003407001495361328, "timer/replay._sample_max": 0.009646177291870117, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 483.0, "timer/agent.policy_total": 7.587712287902832, "timer/agent.policy_frac": 0.007585446158143946, "timer/agent.policy_avg": 0.015709549250316424, "timer/agent.policy_min": 0.009449481964111328, "timer/agent.policy_max": 0.04880833625793457, "timer/dataset_train_count": 2120.0, "timer/dataset_train_total": 0.36447668075561523, "timer/dataset_train_frac": 0.0003643678269375814, "timer/dataset_train_avg": 0.00017192296262057323, "timer/dataset_train_min": 8.678436279296875e-05, "timer/dataset_train_max": 0.0006551742553710938, "timer/agent.train_count": 2120.0, "timer/agent.train_total": 939.3920745849609, "timer/agent.train_frac": 0.939111517777493, "timer/agent.train_avg": 0.4431094691438495, "timer/agent.train_min": 0.4336376190185547, "timer/agent.train_max": 0.5817618370056152, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47177886962890625, "timer/agent.report_frac": 0.0004716379691709666, "timer/agent.report_avg": 0.23588943481445312, "timer/agent.report_min": 0.229506254196167, "timer/agent.report_max": 0.24227261543273926, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 5.030632019042969e-05, "timer/dataset_eval_frac": 5.0291295813526866e-08, "timer/dataset_eval_avg": 5.030632019042969e-05, "timer/dataset_eval_min": 5.030632019042969e-05, "timer/dataset_eval_max": 5.030632019042969e-05, "fps": 2.1193413070458234}
{"step": 21056, "time": 9343.01198554039, "episode/length": 203.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 21360, "time": 9481.12763953209, "episode/length": 214.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 21656, "time": 9615.25439286232, "episode/length": 209.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 21664, "time": 9620.286831378937, "episode/length": 215.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 21848, "time": 9704.078025102615, "episode/length": 164.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 21984, "time": 9766.608016729355, "episode/length": 125.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9603174603174603, "episode/intrinsic_return": 0.0}
{"step": 22008, "time": 9779.056408882141, "episode/length": 204.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9609756097560975, "episode/intrinsic_return": 0.0}
{"step": 22016, "time": 9784.100654125214, "episode/length": 256.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9766536964980544, "episode/intrinsic_return": 0.0}
{"step": 22136, "time": 9839.492755413055, "episode/length": 96.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9484536082474226, "episode/intrinsic_return": 0.0}
{"step": 22448, "time": 9980.951289653778, "episode/length": 173.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 22872, "time": 10172.43396782875, "episode/length": 150.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 22896, "time": 10184.617826461792, "episode/length": 154.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 23008, "time": 10236.533643484116, "episode/length": 144.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9724137931034482, "episode/intrinsic_return": 0.0}
{"step": 23161, "time": 10307.14054441452, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.320933999536244, "train/action_min": 0.0, "train/action_std": 4.265424632590656, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03578754271206246, "train/actor_opt_grad_steps": 20510.0, "train/actor_opt_loss": -3.786392714130824, "train/adv_mag": 0.6354511697270554, "train/adv_max": 0.6019897225512761, "train/adv_mean": 0.0032855086240874388, "train/adv_min": -0.5198943568691271, "train/adv_std": 0.0487168413846324, "train/cont_avg": 0.994787207477169, "train/cont_loss_mean": 0.00015160328542423564, "train/cont_loss_std": 0.004516195483086228, "train/cont_neg_acc": 0.9981245929247713, "train/cont_neg_loss": 0.01118643049914357, "train/cont_pos_acc": 0.9999820717937871, "train/cont_pos_loss": 7.703707227432933e-05, "train/cont_pred": 0.9947804721523094, "train/cont_rate": 0.994787207477169, "train/dyn_loss_mean": 2.651668501771204, "train/dyn_loss_std": 7.484360505456793, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.4144602586689605, "train/extr_critic_critic_opt_grad_steps": 20510.0, "train/extr_critic_critic_opt_loss": 16042.657806257135, "train/extr_critic_mag": 24.067046483357746, "train/extr_critic_max": 24.067046483357746, "train/extr_critic_mean": 6.369032065073649, "train/extr_critic_min": -0.42731890776386, "train/extr_critic_std": 5.5560801736840375, "train/extr_return_normed_mag": 1.3353776273117761, "train/extr_return_normed_max": 1.3353776273117761, "train/extr_return_normed_mean": 0.3270172733966618, "train/extr_return_normed_min": -0.06503494472570343, "train/extr_return_normed_std": 0.30745899684080796, "train/extr_return_rate": 0.9250226418177286, "train/extr_return_raw_mag": 25.073530127468718, "train/extr_return_raw_max": 25.073530127468718, "train/extr_return_raw_mean": 6.429887399281541, "train/extr_return_raw_min": -0.817614464965313, "train/extr_return_raw_std": 5.6847332656111345, "train/extr_reward_mag": 1.020305641165607, "train/extr_reward_max": 1.020305641165607, "train/extr_reward_mean": 0.02646083730489832, "train/extr_reward_min": -0.6680276072732935, "train/extr_reward_std": 0.16095122171047072, "train/image_loss_mean": 2.512944134947372, "train/image_loss_std": 5.605274725722396, "train/model_loss_mean": 4.138178275600416, "train/model_loss_std": 9.088761695443768, "train/model_opt_grad_norm": 41.60150007134703, "train/model_opt_grad_steps": 20489.08219178082, "train/model_opt_loss": 3993.5977181212543, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 970.3196347031964, "train/policy_entropy_mag": 2.3848954205099306, "train/policy_entropy_max": 2.3848954205099306, "train/policy_entropy_mean": 0.639483745647892, "train/policy_entropy_min": 0.0793751234605432, "train/policy_entropy_std": 0.5834674467779186, "train/policy_logprob_mag": 7.4383830000820765, "train/policy_logprob_max": -0.00945571535288199, "train/policy_logprob_mean": -0.639142747066881, "train/policy_logprob_min": -7.4383830000820765, "train/policy_logprob_std": 1.1468994383398257, "train/policy_randomness_mag": 0.8417634261797552, "train/policy_randomness_max": 0.8417634261797552, "train/policy_randomness_mean": 0.22570969892419093, "train/policy_randomness_min": 0.02801593529171051, "train/policy_randomness_std": 0.2059384049618081, "train/post_ent_mag": 31.902888415610953, "train/post_ent_max": 31.902888415610953, "train/post_ent_mean": 18.75583357789201, "train/post_ent_min": 10.215749357388988, "train/post_ent_std": 3.708583382166684, "train/prior_ent_mag": 71.14484638928279, "train/prior_ent_max": 71.14484638928279, "train/prior_ent_mean": 21.547933900737327, "train/prior_ent_min": 11.35773883889255, "train/prior_ent_std": 8.530031265189114, "train/rep_loss_mean": 2.651668501771204, "train/rep_loss_std": 7.484360505456793, "train/reward_avg": 0.01687268104582821, "train/reward_loss_mean": 0.0340814113565912, "train/reward_loss_std": 0.16493708232086, "train/reward_max_data": 1.0100456644955291, "train/reward_max_pred": 1.011839469273885, "train/reward_neg_acc": 0.9963627580094011, "train/reward_neg_loss": 0.018840493047482348, "train/reward_pos_acc": 0.9878536533547319, "train/reward_pos_loss": 0.7254993047344086, "train/reward_pred": 0.016763934723131323, "train/reward_rate": 0.021618150684931507, "train_stats/sum_log_reward": 3.869230710543119, "train_stats/max_log_achievement_collect_drink": 4.3076923076923075, "train_stats/max_log_achievement_collect_sapling": 1.6153846153846154, "train_stats/max_log_achievement_collect_wood": 1.8461538461538463, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.23076923076923078, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.4615384615384615, "train_stats/max_log_achievement_place_table": 0.5384615384615384, "train_stats/max_log_achievement_wake_up": 1.4615384615384615, "train_stats/mean_log_entropy": 0.5665428432134482, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 2.2615644411416724e-05, "report/cont_loss_std": 0.0004665084707085043, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0029700917657464743, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 8.153052476700395e-06, "report/cont_pred": 0.9951234459877014, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 2.5864906311035156, "report/dyn_loss_std": 7.501372814178467, "report/image_loss_mean": 1.7615556716918945, "report/image_loss_std": 3.8303065299987793, "report/model_loss_mean": 3.340791702270508, "report/model_loss_std": 7.639239311218262, "report/post_ent_mag": 31.490924835205078, "report/post_ent_max": 31.490924835205078, "report/post_ent_mean": 18.172889709472656, "report/post_ent_min": 9.832508087158203, "report/post_ent_std": 3.4412310123443604, "report/prior_ent_mag": 71.60655212402344, "report/prior_ent_max": 71.60655212402344, "report/prior_ent_mean": 20.916425704956055, "report/prior_ent_min": 11.586230278015137, "report/prior_ent_std": 8.624897003173828, "report/rep_loss_mean": 2.5864906311035156, "report/rep_loss_std": 7.501372814178467, "report/reward_avg": 0.01279296912252903, "report/reward_loss_mean": 0.027319228276610374, "report/reward_loss_std": 0.1244756355881691, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0005474090576172, "report/reward_neg_acc": 0.9940358400344849, "report/reward_neg_loss": 0.015404253266751766, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6932340860366821, "report/reward_pred": 0.012559687718749046, "report/reward_rate": 0.017578125, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.009059496223926544, "eval/cont_loss_std": 0.2874622344970703, "eval/cont_neg_acc": 0.8333333730697632, "eval/cont_neg_loss": 1.5447239875793457, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 8.429236004303675e-06, "eval/cont_pred": 0.9951711893081665, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 25.30194854736328, "eval/dyn_loss_std": 12.501352310180664, "eval/image_loss_mean": 97.19139862060547, "eval/image_loss_std": 93.871337890625, "eval/model_loss_mean": 112.63685607910156, "eval/model_loss_std": 97.4500961303711, "eval/post_ent_mag": 37.6494026184082, "eval/post_ent_max": 37.6494026184082, "eval/post_ent_mean": 27.42504119873047, "eval/post_ent_min": 12.912284851074219, "eval/post_ent_std": 4.852869987487793, "eval/prior_ent_mag": 71.60655212402344, "eval/prior_ent_max": 71.60655212402344, "eval/prior_ent_mean": 33.92164611816406, "eval/prior_ent_min": 13.28668212890625, "eval/prior_ent_std": 10.002772331237793, "eval/rep_loss_mean": 25.30194854736328, "eval/rep_loss_std": 12.501352310180664, "eval/reward_avg": 0.02177734300494194, "eval/reward_loss_mean": 0.25523027777671814, "eval/reward_loss_std": 1.4576915502548218, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0000360012054443, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.10970740020275116, "eval/reward_pos_acc": 0.37037038803100586, "eval/reward_pos_loss": 5.628798007965088, "eval/reward_pred": 0.0044043585658073425, "eval/reward_rate": 0.0263671875, "replay/size": 22657.0, "replay/inserts": 2184.0, "replay/samples": 34944.0, "replay/insert_wait_avg": 2.5393106998541416e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.48612778090732e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 6704.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 7.450580596923828e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1059565544128, "timer/env.step_count": 273.0, "timer/env.step_total": 26.36713671684265, "timer/env.step_frac": 0.026364343241873384, "timer/env.step_avg": 0.09658291837671301, "timer/env.step_min": 0.02317070960998535, "timer/env.step_max": 1.6020421981811523, "timer/replay._sample_count": 34944.0, "timer/replay._sample_total": 17.010127544403076, "timer/replay._sample_frac": 0.01700832540084727, "timer/replay._sample_avg": 0.00048678249611959354, "timer/replay._sample_min": 0.0003361701965332031, "timer/replay._sample_max": 0.012206554412841797, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 273.0, "timer/agent.policy_total": 4.390990734100342, "timer/agent.policy_frac": 0.004390525529143212, "timer/agent.policy_avg": 0.016084215143224695, "timer/agent.policy_min": 0.009865999221801758, "timer/agent.policy_max": 0.06469559669494629, "timer/dataset_train_count": 2184.0, "timer/dataset_train_total": 0.3700850009918213, "timer/dataset_train_frac": 0.00037004579221470323, "timer/dataset_train_avg": 0.00016945283928196945, "timer/dataset_train_min": 8.535385131835938e-05, "timer/dataset_train_max": 0.0006649494171142578, "timer/agent.train_count": 2184.0, "timer/agent.train_total": 967.262556552887, "timer/agent.train_frac": 0.9671600796032865, "timer/agent.train_avg": 0.4428857859674391, "timer/agent.train_min": 0.4316399097442627, "timer/agent.train_max": 0.5706264972686768, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4747774600982666, "timer/agent.report_frac": 0.0004747271596441445, "timer/agent.report_avg": 0.2373887300491333, "timer/agent.report_min": 0.23139476776123047, "timer/agent.report_max": 0.24338269233703613, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0517578125e-05, "timer/dataset_eval_frac": 3.0514344930151035e-08, "timer/dataset_eval_avg": 3.0517578125e-05, "timer/dataset_eval_min": 3.0517578125e-05, "timer/dataset_eval_max": 3.0517578125e-05, "fps": 2.18374133495836}
{"step": 23336, "time": 10385.732048749924, "episode/length": 165.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 23384, "time": 10408.704598426819, "episode/length": 170.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 23448, "time": 10439.007060527802, "episode/length": 163.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 23800, "time": 10598.330892324448, "episode/length": 226.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9823788546255506, "episode/intrinsic_return": 0.0}
{"step": 24000, "time": 10689.38034915924, "episode/length": 193.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 24160, "time": 10762.740085601807, "episode/length": 157.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 24240, "time": 10800.185118436813, "episode/length": 153.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 24560, "time": 10945.306372880936, "episode/length": 210.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 24624, "time": 10976.250939369202, "episode/length": 154.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 24664, "time": 10995.55456829071, "episode/length": 165.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 24760, "time": 11040.26760673523, "episode/length": 163.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 25112, "time": 11199.887311458588, "episode/length": 43.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.8863636363636364, "episode/intrinsic_return": 0.0}
{"step": 25248, "time": 11262.432578086853, "episode/length": 155.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 25343, "time": 11307.149856328964, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.990831287629014, "train/action_min": 0.0, "train/action_std": 4.123082521858565, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03677653159877849, "train/actor_opt_grad_steps": 22695.0, "train/actor_opt_loss": -4.127620071036007, "train/adv_mag": 0.6602726932785926, "train/adv_max": 0.6244090321140552, "train/adv_mean": 0.0034638198014379984, "train/adv_min": -0.5219387767511771, "train/adv_std": 0.050842365668659364, "train/cont_avg": 0.9946109876720184, "train/cont_loss_mean": 3.3786342501124275e-05, "train/cont_loss_std": 0.000911379017667276, "train/cont_neg_acc": 0.9994266055045872, "train/cont_neg_loss": 0.0012375287948097296, "train/cont_pos_acc": 0.9999954681330865, "train/cont_pos_loss": 2.6237369651469786e-05, "train/cont_pred": 0.9946007025898049, "train/cont_rate": 0.9946109876720184, "train/dyn_loss_mean": 2.680330991744995, "train/dyn_loss_std": 7.521771175052048, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.4042720860297526, "train/extr_critic_critic_opt_grad_steps": 22695.0, "train/extr_critic_critic_opt_loss": 16402.177859805044, "train/extr_critic_mag": 24.825496034884672, "train/extr_critic_max": 24.825496034884672, "train/extr_critic_mean": 6.647859135898975, "train/extr_critic_min": -0.4903938409385331, "train/extr_critic_std": 5.686288221166768, "train/extr_return_normed_mag": 1.3497846613236524, "train/extr_return_normed_max": 1.3497846613236524, "train/extr_return_normed_mean": 0.3488709178129467, "train/extr_return_normed_min": -0.05616360754970837, "train/extr_return_normed_std": 0.30776739653644214, "train/extr_return_rate": 0.9083698145840147, "train/extr_return_raw_mag": 25.55580336894464, "train/extr_return_raw_max": 25.55580336894464, "train/extr_return_raw_mean": 6.713841263307344, "train/extr_return_raw_min": -0.911445127167833, "train/extr_return_raw_std": 5.796021384930392, "train/extr_reward_mag": 1.0173622271336547, "train/extr_reward_max": 1.0173622271336547, "train/extr_reward_mean": 0.025212874471577346, "train/extr_reward_min": -0.674682403376343, "train/extr_reward_std": 0.15852914388300082, "train/image_loss_mean": 2.382202541609423, "train/image_loss_std": 5.352406736907609, "train/model_loss_mean": 4.025243717596071, "train/model_loss_std": 8.871818441863454, "train/model_opt_grad_norm": 40.098913498974724, "train/model_opt_grad_steps": 22672.610091743118, "train/model_opt_loss": 5639.028302393922, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1404.8165137614678, "train/policy_entropy_mag": 2.3584494164230625, "train/policy_entropy_max": 2.3584494164230625, "train/policy_entropy_mean": 0.5775777455590186, "train/policy_entropy_min": 0.0793751059527244, "train/policy_entropy_std": 0.5455162132825326, "train/policy_logprob_mag": 7.438383277403105, "train/policy_logprob_max": -0.009455696628386275, "train/policy_logprob_mean": -0.5778016664019419, "train/policy_logprob_min": -7.438383277403105, "train/policy_logprob_std": 1.1137219481511946, "train/policy_randomness_mag": 0.832429147915009, "train/policy_randomness_max": 0.832429147915009, "train/policy_randomness_mean": 0.20385959853819752, "train/policy_randomness_min": 0.028015928992300952, "train/policy_randomness_std": 0.1925432853605769, "train/post_ent_mag": 31.88862632611476, "train/post_ent_max": 31.88862632611476, "train/post_ent_mean": 18.708140128249422, "train/post_ent_min": 10.339534479543703, "train/post_ent_std": 3.688595826472711, "train/prior_ent_mag": 71.52217431024674, "train/prior_ent_max": 71.52217431024674, "train/prior_ent_mean": 21.5152040184091, "train/prior_ent_min": 11.514285301943438, "train/prior_ent_std": 8.604037197358018, "train/rep_loss_mean": 2.680330991744995, "train/rep_loss_std": 7.521771175052048, "train/reward_avg": 0.017566477775214872, "train/reward_loss_mean": 0.03480879725768752, "train/reward_loss_std": 0.16640709678924412, "train/reward_max_data": 1.009174314113932, "train/reward_max_pred": 1.010224897380269, "train/reward_neg_acc": 0.9963944053978001, "train/reward_neg_loss": 0.01876900564887723, "train/reward_pos_acc": 0.9867857896953548, "train/reward_pos_loss": 0.728787081230671, "train/reward_pred": 0.017435931267404774, "train/reward_rate": 0.022514693233944953, "train_stats/sum_log_reward": 3.099999909217541, "train_stats/max_log_achievement_collect_drink": 1.9230769230769231, "train_stats/max_log_achievement_collect_sapling": 1.5384615384615385, "train_stats/max_log_achievement_collect_wood": 1.2307692307692308, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.15384615384615385, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.4615384615384615, "train_stats/max_log_achievement_place_table": 0.23076923076923078, "train_stats/max_log_achievement_wake_up": 1.6923076923076923, "train_stats/mean_log_entropy": 0.5754619412697278, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 3.2274959949063486e-07, "report/cont_loss_std": 2.662301767486497e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 5.327970029611606e-06, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 3.0312128274090355e-07, "report/cont_pred": 0.9960935115814209, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 2.667790174484253, "report/dyn_loss_std": 7.637481689453125, "report/image_loss_mean": 2.602281332015991, "report/image_loss_std": 3.9939773082733154, "report/model_loss_mean": 4.244870185852051, "report/model_loss_std": 7.813743591308594, "report/post_ent_mag": 30.260765075683594, "report/post_ent_max": 30.260765075683594, "report/post_ent_mean": 19.073270797729492, "report/post_ent_min": 10.344637870788574, "report/post_ent_std": 3.7025046348571777, "report/prior_ent_mag": 71.68269348144531, "report/prior_ent_max": 71.68269348144531, "report/prior_ent_mean": 21.815582275390625, "report/prior_ent_min": 10.902909278869629, "report/prior_ent_std": 8.31859302520752, "report/rep_loss_mean": 2.667790174484253, "report/rep_loss_std": 7.637481689453125, "report/reward_avg": 0.02226562425494194, "report/reward_loss_mean": 0.041914548724889755, "report/reward_loss_std": 0.1968349665403366, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0030152797698975, "report/reward_neg_acc": 0.996990978717804, "report/reward_neg_loss": 0.02143612876534462, "report/reward_pos_acc": 0.9629629850387573, "report/reward_pos_loss": 0.798099160194397, "report/reward_pred": 0.021715359762310982, "report/reward_rate": 0.0263671875, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.014345720410346985, "eval/cont_loss_std": 0.4208342432975769, "eval/cont_neg_acc": 0.3333333432674408, "eval/cont_neg_loss": 4.8963518142700195, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 9.442114787816536e-07, "eval/cont_pred": 0.9987496733665466, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 24.50432014465332, "eval/dyn_loss_std": 11.912259101867676, "eval/image_loss_mean": 61.38105773925781, "eval/image_loss_std": 73.30027770996094, "eval/model_loss_mean": 76.27293395996094, "eval/model_loss_std": 76.6137466430664, "eval/post_ent_mag": 39.839759826660156, "eval/post_ent_max": 39.839759826660156, "eval/post_ent_mean": 25.741331100463867, "eval/post_ent_min": 11.671319961547852, "eval/post_ent_std": 5.097029209136963, "eval/prior_ent_mag": 71.68269348144531, "eval/prior_ent_max": 71.68269348144531, "eval/prior_ent_mean": 31.068153381347656, "eval/prior_ent_min": 12.042688369750977, "eval/prior_ent_std": 9.668126106262207, "eval/rep_loss_mean": 24.50432014465332, "eval/rep_loss_std": 11.912259101867676, "eval/reward_avg": 0.014550781808793545, "eval/reward_loss_mean": 0.1749347299337387, "eval/reward_loss_std": 1.0592496395111084, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0000529289245605, "eval/reward_neg_acc": 0.998009979724884, "eval/reward_neg_loss": 0.10201699286699295, "eval/reward_pos_acc": 0.42105263471603394, "eval/reward_pos_loss": 4.031899929046631, "eval/reward_pred": 0.005764222703874111, "eval/reward_rate": 0.0185546875, "replay/size": 24839.0, "replay/inserts": 2182.0, "replay/samples": 34912.0, "replay/insert_wait_avg": 2.680406124628978e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.454951239987102e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 6704.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 7.450580596923828e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 999.9966740608215, "timer/env.step_count": 272.0, "timer/env.step_total": 26.499006032943726, "timer/env.step_frac": 0.02649909416731921, "timer/env.step_avg": 0.09742281629758723, "timer/env.step_min": 0.023163795471191406, "timer/env.step_max": 1.5992913246154785, "timer/replay._sample_count": 34912.0, "timer/replay._sample_total": 17.156055688858032, "timer/replay._sample_frac": 0.017156112749045573, "timer/replay._sample_avg": 0.0004914085612069785, "timer/replay._sample_min": 0.00036144256591796875, "timer/replay._sample_max": 0.01123952865600586, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 272.0, "timer/agent.policy_total": 4.295641183853149, "timer/agent.policy_frac": 0.004295655470941977, "timer/agent.policy_avg": 0.015792798470048344, "timer/agent.policy_min": 0.009658098220825195, "timer/agent.policy_max": 0.030681610107421875, "timer/dataset_train_count": 2182.0, "timer/dataset_train_total": 0.36879873275756836, "timer/dataset_train_frac": 0.0003687999593638022, "timer/dataset_train_avg": 0.00016901866762491675, "timer/dataset_train_min": 8.559226989746094e-05, "timer/dataset_train_max": 0.0007300376892089844, "timer/agent.train_count": 2182.0, "timer/agent.train_total": 966.9869494438171, "timer/agent.train_frac": 0.9669901655942941, "timer/agent.train_avg": 0.4431654213766348, "timer/agent.train_min": 0.43309998512268066, "timer/agent.train_max": 0.5513758659362793, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4744527339935303, "timer/agent.report_frac": 0.00047445431199971493, "timer/agent.report_avg": 0.23722636699676514, "timer/agent.report_min": 0.23072195053100586, "timer/agent.report_max": 0.24373078346252441, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.6226043701171875e-05, "timer/dataset_eval_frac": 2.6226130927688226e-08, "timer/dataset_eval_avg": 2.6226043701171875e-05, "timer/dataset_eval_min": 2.6226043701171875e-05, "timer/dataset_eval_max": 2.6226043701171875e-05, "fps": 2.1819805487983897}
{"step": 25360, "time": 11314.989920854568, "episode/length": 194.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 25496, "time": 11377.484544277191, "episode/length": 166.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 25856, "time": 11540.285009860992, "episode/length": 161.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 25992, "time": 11602.621047496796, "episode/length": 170.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 26016, "time": 11615.034011125565, "episode/length": 168.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 26064, "time": 11638.013360977173, "episode/length": 227.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 26064, "time": 11638.020006656647, "episode/length": 87.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9886363636363636, "episode/intrinsic_return": 0.0}
{"step": 26392, "time": 11788.24142408371, "episode/length": 159.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 26808, "time": 11976.506352901459, "episode/length": 194.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9641025641025641, "episode/intrinsic_return": 0.0}
{"step": 26864, "time": 12003.324093580246, "episode/length": 170.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 27064, "time": 12094.247705936432, "episode/length": 150.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 27240, "time": 12174.482783317566, "episode/length": 146.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 27280, "time": 12193.96657705307, "episode/length": 151.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 27464, "time": 12278.027175188065, "episode/length": 180.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 27525, "time": 12307.21683716774, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.694681430081709, "train/action_min": 0.0, "train/action_std": 4.117349403713821, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03710634945763634, "train/actor_opt_grad_steps": 24875.0, "train/actor_opt_loss": -0.5056743823470325, "train/adv_mag": 0.6433972436080285, "train/adv_max": 0.5913742433447357, "train/adv_mean": 0.0042664320537386035, "train/adv_min": -0.5371791472949019, "train/adv_std": 0.05008898607087792, "train/cont_avg": 0.9943153311353211, "train/cont_loss_mean": 0.0001517993730504706, "train/cont_loss_std": 0.004209096860546659, "train/cont_neg_acc": 0.9972167366660685, "train/cont_neg_loss": 0.012679563518666889, "train/cont_pos_acc": 0.9999864374825714, "train/cont_pos_loss": 7.99742096213544e-05, "train/cont_pred": 0.9943039882073709, "train/cont_rate": 0.9943153311353211, "train/dyn_loss_mean": 2.7481615105900197, "train/dyn_loss_std": 7.604836680473538, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.3298957246706027, "train/extr_critic_critic_opt_grad_steps": 24875.0, "train/extr_critic_critic_opt_loss": 15831.658933307053, "train/extr_critic_mag": 25.744887177003633, "train/extr_critic_max": 25.744887177003633, "train/extr_critic_mean": 7.22336303640943, "train/extr_critic_min": -0.5905080311888948, "train/extr_critic_std": 5.446507080979304, "train/extr_return_normed_mag": 1.4073925792077266, "train/extr_return_normed_max": 1.4073925792077266, "train/extr_return_normed_mean": 0.390985976391976, "train/extr_return_normed_min": -0.06065464983566092, "train/extr_return_normed_std": 0.29591601533353873, "train/extr_return_rate": 0.894818889711975, "train/extr_return_raw_mag": 26.43511101084018, "train/extr_return_raw_max": 26.43511101084018, "train/extr_return_raw_mean": 7.3030747404885945, "train/extr_return_raw_min": -1.188036394228629, "train/extr_return_raw_std": 5.575241473836637, "train/extr_reward_mag": 1.019547965548454, "train/extr_reward_max": 1.019547965548454, "train/extr_reward_mean": 0.02414869962670251, "train/extr_reward_min": -0.6779292739859415, "train/extr_reward_std": 0.15719781364869634, "train/image_loss_mean": 2.358218987873935, "train/image_loss_std": 5.807279798962655, "train/model_loss_mean": 4.042076494715629, "train/model_loss_std": 9.360170600611136, "train/model_opt_grad_norm": 40.49333115327193, "train/model_opt_grad_steps": 24850.798165137614, "train/model_opt_loss": 6029.967378108873, "train/model_opt_model_opt_grad_overflow": 0.0045871559633027525, "train/model_opt_model_opt_grad_scale": 1490.8256880733945, "train/policy_entropy_mag": 2.3165349424432176, "train/policy_entropy_max": 2.3165349424432176, "train/policy_entropy_mean": 0.5477480590343475, "train/policy_entropy_min": 0.07937509395660611, "train/policy_entropy_std": 0.5214209448580348, "train/policy_logprob_mag": 7.438383413017343, "train/policy_logprob_max": -0.009455687404875087, "train/policy_logprob_mean": -0.5476870138984208, "train/policy_logprob_min": -7.438383413017343, "train/policy_logprob_std": 1.0924437912779117, "train/policy_randomness_mag": 0.8176351769254842, "train/policy_randomness_max": 0.8176351769254842, "train/policy_randomness_mean": 0.19333102800157093, "train/policy_randomness_min": 0.02801592474581178, "train/policy_randomness_std": 0.18403871350605552, "train/post_ent_mag": 32.225800330485775, "train/post_ent_max": 32.225800330485775, "train/post_ent_mean": 18.856092767977934, "train/post_ent_min": 10.480453219982461, "train/post_ent_std": 3.6675157317327796, "train/prior_ent_mag": 71.89026795833483, "train/prior_ent_max": 71.89026795833483, "train/prior_ent_mean": 21.715762532085453, "train/prior_ent_min": 11.621213116777053, "train/prior_ent_std": 8.723296758231767, "train/rep_loss_mean": 2.7481615105900197, "train/rep_loss_std": 7.604836680473538, "train/reward_avg": 0.01778284459024531, "train/reward_loss_mean": 0.03480881992556633, "train/reward_loss_std": 0.16853870331830934, "train/reward_max_data": 1.0096330298196285, "train/reward_max_pred": 1.011462430341528, "train/reward_neg_acc": 0.9965892811433985, "train/reward_neg_loss": 0.018734060951995604, "train/reward_pos_acc": 0.9879253006309544, "train/reward_pos_loss": 0.7254975954873846, "train/reward_pred": 0.017724214288312088, "train/reward_rate": 0.022756594036697247, "train_stats/sum_log_reward": 3.171428500541619, "train_stats/max_log_achievement_collect_drink": 2.2857142857142856, "train_stats/max_log_achievement_collect_sapling": 1.2857142857142858, "train_stats/max_log_achievement_collect_wood": 1.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.07142857142857142, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.2142857142857142, "train_stats/max_log_achievement_place_table": 0.14285714285714285, "train_stats/max_log_achievement_wake_up": 1.5, "train_stats/mean_log_entropy": 0.5377538076468876, "report/cont_avg": 0.990234375, "report/cont_loss_mean": 3.0593307087656285e-07, "report/cont_loss_std": 4.6045659019000595e-07, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 4.209527105558664e-06, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.6743609282675607e-07, "report/cont_pred": 0.9902342557907104, "report/cont_rate": 0.990234375, "report/dyn_loss_mean": 2.953402042388916, "report/dyn_loss_std": 8.109512329101562, "report/image_loss_mean": 2.738861322402954, "report/image_loss_std": 6.010910987854004, "report/model_loss_mean": 4.551153659820557, "report/model_loss_std": 9.698478698730469, "report/post_ent_mag": 30.530101776123047, "report/post_ent_max": 30.530101776123047, "report/post_ent_mean": 19.672813415527344, "report/post_ent_min": 9.845311164855957, "report/post_ent_std": 3.348397731781006, "report/prior_ent_mag": 72.55819702148438, "report/prior_ent_max": 72.55819702148438, "report/prior_ent_mean": 22.75311851501465, "report/prior_ent_min": 11.221232414245605, "report/prior_ent_std": 9.204062461853027, "report/rep_loss_mean": 2.953402042388916, "report/rep_loss_std": 8.109512329101562, "report/reward_avg": 0.011914062313735485, "report/reward_loss_mean": 0.04025127738714218, "report/reward_loss_std": 0.1601671278476715, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0023412704467773, "report/reward_neg_acc": 0.9970089793205261, "report/reward_neg_loss": 0.026987185701727867, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.673769474029541, "report/reward_pred": 0.012579468078911304, "report/reward_rate": 0.0205078125, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.011875747703015804, "eval/cont_loss_std": 0.3541618287563324, "eval/cont_neg_acc": 0.6000000238418579, "eval/cont_neg_loss": 2.432096242904663, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.831574192896369e-07, "eval/cont_pred": 0.9966868162155151, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 25.2886962890625, "eval/dyn_loss_std": 13.589469909667969, "eval/image_loss_mean": 60.320133209228516, "eval/image_loss_std": 70.04365539550781, "eval/model_loss_mean": 75.67390441894531, "eval/model_loss_std": 74.3385009765625, "eval/post_ent_mag": 37.126495361328125, "eval/post_ent_max": 37.126495361328125, "eval/post_ent_mean": 25.532777786254883, "eval/post_ent_min": 13.91763687133789, "eval/post_ent_std": 4.846956729888916, "eval/prior_ent_mag": 72.55819702148438, "eval/prior_ent_max": 72.55819702148438, "eval/prior_ent_mean": 32.15930938720703, "eval/prior_ent_min": 11.986132621765137, "eval/prior_ent_std": 10.045832633972168, "eval/rep_loss_mean": 25.2886962890625, "eval/rep_loss_std": 13.589469909667969, "eval/reward_avg": 0.02119140699505806, "eval/reward_loss_mean": 0.16867879033088684, "eval/reward_loss_std": 1.106289267539978, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0018279552459717, "eval/reward_neg_acc": 0.9989979863166809, "eval/reward_neg_loss": 0.06071120500564575, "eval/reward_pos_acc": 0.5, "eval/reward_pos_loss": 4.3129730224609375, "eval/reward_pred": 0.008373832330107689, "eval/reward_rate": 0.025390625, "replay/size": 27021.0, "replay/inserts": 2182.0, "replay/samples": 34912.0, "replay/insert_wait_avg": 2.6173595984412596e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.416025200204823e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 6704.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 6.705522537231445e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0549776554108, "timer/env.step_count": 273.0, "timer/env.step_total": 28.16038227081299, "timer/env.step_frac": 0.028158834164131542, "timer/env.step_avg": 0.10315158340957138, "timer/env.step_min": 0.02276897430419922, "timer/env.step_max": 3.2037720680236816, "timer/replay._sample_count": 34912.0, "timer/replay._sample_total": 16.98611879348755, "timer/replay._sample_frac": 0.0169851849878402, "timer/replay._sample_avg": 0.0004865409828565407, "timer/replay._sample_min": 0.00034880638122558594, "timer/replay._sample_max": 0.02096104621887207, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 273.0, "timer/agent.policy_total": 4.309005260467529, "timer/agent.policy_frac": 0.004308768374484592, "timer/agent.policy_avg": 0.01578390205299461, "timer/agent.policy_min": 0.009591817855834961, "timer/agent.policy_max": 0.03984856605529785, "timer/dataset_train_count": 2182.0, "timer/dataset_train_total": 0.36582493782043457, "timer/dataset_train_frac": 0.0003658048267287231, "timer/dataset_train_avg": 0.00016765579185171154, "timer/dataset_train_min": 8.535385131835938e-05, "timer/dataset_train_max": 0.0006594657897949219, "timer/agent.train_count": 2182.0, "timer/agent.train_total": 965.5006911754608, "timer/agent.train_frac": 0.9654476131292691, "timer/agent.train_avg": 0.4424842764323835, "timer/agent.train_min": 0.43186140060424805, "timer/agent.train_max": 0.561154842376709, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4718148708343506, "timer/agent.report_frac": 0.0004717889329849663, "timer/agent.report_avg": 0.2359074354171753, "timer/agent.report_min": 0.22886347770690918, "timer/agent.report_max": 0.2429513931274414, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8371810913085938e-05, "timer/dataset_eval_frac": 2.837025118319247e-08, "timer/dataset_eval_avg": 2.8371810913085938e-05, "timer/dataset_eval_min": 2.8371810913085938e-05, "timer/dataset_eval_max": 2.8371810913085938e-05, "fps": 2.1818529015455037}
{"step": 27800, "time": 12431.254761219025, "episode/length": 64.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9230769230769231, "episode/intrinsic_return": 0.0}
{"step": 27864, "time": 12461.540854215622, "episode/length": 233.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 28064, "time": 12553.137904405594, "episode/length": 156.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 28072, "time": 12558.303469657898, "episode/length": 209.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 28088, "time": 12567.007063865662, "episode/length": 152.0, "episode/score": 1.0999999791383743, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 28200, "time": 12618.860584259033, "episode/length": 141.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 28408, "time": 12714.187377929688, "episode/length": 117.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9576271186440678, "episode/intrinsic_return": 0.0}
{"step": 29056, "time": 13008.985831260681, "episode/length": 148.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 29112, "time": 13035.836181402206, "episode/length": 163.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 29272, "time": 13109.844300031662, "episode/length": 150.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 29320, "time": 13133.522062301636, "episode/length": 153.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 29576, "time": 13250.550904989243, "episode/length": 171.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 29672, "time": 13295.277626514435, "episode/length": 157.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 29693, "time": 13307.29188990593, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.179028489073301, "train/action_min": 0.0, "train/action_std": 4.468724763887819, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.036876092214257486, "train/actor_opt_grad_steps": 27050.0, "train/actor_opt_loss": -19.340762354502207, "train/adv_mag": 0.6550875453080999, "train/adv_max": 0.6150635759676656, "train/adv_mean": 0.00038744649897578436, "train/adv_min": -0.5295262961618362, "train/adv_std": 0.049391042209371995, "train/cont_avg": 0.994307135656682, "train/cont_loss_mean": 2.450633692381391e-05, "train/cont_loss_std": 0.000654052384941863, "train/cont_neg_acc": 0.99907834106876, "train/cont_neg_loss": 0.002744622885297067, "train/cont_pos_acc": 0.9999999829701015, "train/cont_pos_loss": 1.1296927582951938e-05, "train/cont_pred": 0.9943036931451015, "train/cont_rate": 0.994307135656682, "train/dyn_loss_mean": 2.7377474890326576, "train/dyn_loss_std": 7.620953419241488, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.3562288753997345, "train/extr_critic_critic_opt_grad_steps": 27050.0, "train/extr_critic_critic_opt_loss": 16251.845604118664, "train/extr_critic_mag": 26.66831029724965, "train/extr_critic_max": 26.66831029724965, "train/extr_critic_mean": 6.49935743665915, "train/extr_critic_min": -0.6569072002639419, "train/extr_critic_std": 6.133889265324114, "train/extr_return_normed_mag": 1.362317922477898, "train/extr_return_normed_max": 1.362317922477898, "train/extr_return_normed_mean": 0.3286493930811157, "train/extr_return_normed_min": -0.05416112744210777, "train/extr_return_normed_std": 0.30817900920793206, "train/extr_return_rate": 0.8877049574654223, "train/extr_return_raw_mag": 27.50094282791911, "train/extr_return_raw_max": 27.50094282791911, "train/extr_return_raw_mean": 6.507439616638394, "train/extr_return_raw_min": -1.2992992431337382, "train/extr_return_raw_std": 6.262384553109446, "train/extr_reward_mag": 1.0274070858406033, "train/extr_reward_max": 1.0274070858406033, "train/extr_reward_mean": 0.023504638688183876, "train/extr_reward_min": -0.6874209323786371, "train/extr_reward_std": 0.15775890504160234, "train/image_loss_mean": 2.2315027537983134, "train/image_loss_std": 5.3179677213941305, "train/model_loss_mean": 3.9092006716310705, "train/model_loss_std": 8.903070867336291, "train/model_opt_grad_norm": 38.66992667413527, "train/model_opt_grad_steps": 27023.94470046083, "train/model_opt_loss": 5594.977985716086, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1428.5714285714287, "train/policy_entropy_mag": 2.347118309565953, "train/policy_entropy_max": 2.347118309565953, "train/policy_entropy_mean": 0.6248225290929118, "train/policy_entropy_min": 0.07937506675582877, "train/policy_entropy_std": 0.5725888704649315, "train/policy_logprob_mag": 7.438383489160493, "train/policy_logprob_max": -0.009455677186254808, "train/policy_logprob_mean": -0.6254277803381467, "train/policy_logprob_min": -7.438383489160493, "train/policy_logprob_std": 1.1276335169642753, "train/policy_randomness_mag": 0.8284297623941975, "train/policy_randomness_max": 0.8284297623941975, "train/policy_randomness_mean": 0.22053493456357084, "train/policy_randomness_min": 0.028015915227169813, "train/policy_randomness_std": 0.20209874432482478, "train/post_ent_mag": 32.52182410279727, "train/post_ent_max": 32.52182410279727, "train/post_ent_mean": 18.88956865407355, "train/post_ent_min": 10.614941465140488, "train/post_ent_std": 3.6032314838901645, "train/prior_ent_mag": 72.29006149362309, "train/prior_ent_max": 72.29006149362309, "train/prior_ent_mean": 21.727841328915364, "train/prior_ent_min": 11.66718445615285, "train/prior_ent_std": 8.70177922490555, "train/rep_loss_mean": 2.7377474890326576, "train/rep_loss_std": 7.620953419241488, "train/reward_avg": 0.01830672148683791, "train/reward_loss_mean": 0.03502490676184129, "train/reward_loss_std": 0.16876787544670194, "train/reward_max_data": 1.0175115249123992, "train/reward_max_pred": 1.017981353443339, "train/reward_neg_acc": 0.9964494194303241, "train/reward_neg_loss": 0.018489183437439702, "train/reward_pos_acc": 0.9873522495344487, "train/reward_pos_loss": 0.7278919986316136, "train/reward_pred": 0.018174183606449085, "train/reward_rate": 0.023320492511520737, "train_stats/sum_log_reward": 3.2538461134983945, "train_stats/max_log_achievement_collect_drink": 2.3846153846153846, "train_stats/max_log_achievement_collect_sapling": 1.6923076923076923, "train_stats/max_log_achievement_collect_wood": 1.5384615384615385, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.15384615384615385, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.6153846153846154, "train_stats/max_log_achievement_place_table": 0.38461538461538464, "train_stats/max_log_achievement_wake_up": 1.0769230769230769, "train_stats/mean_log_entropy": 0.517463641671034, "report/cont_avg": 0.990234375, "report/cont_loss_mean": 7.68998361309059e-05, "report/cont_loss_std": 0.002346681896597147, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0075611635111272335, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 3.0905355288268765e-06, "report/cont_pred": 0.9903024435043335, "report/cont_rate": 0.990234375, "report/dyn_loss_mean": 3.0419349670410156, "report/dyn_loss_std": 7.940571308135986, "report/image_loss_mean": 2.0332822799682617, "report/image_loss_std": 4.1603264808654785, "report/model_loss_mean": 3.8965559005737305, "report/model_loss_std": 8.067798614501953, "report/post_ent_mag": 34.29637145996094, "report/post_ent_max": 34.29637145996094, "report/post_ent_mean": 19.362546920776367, "report/post_ent_min": 8.553628921508789, "report/post_ent_std": 4.439108371734619, "report/prior_ent_mag": 72.18925476074219, "report/prior_ent_max": 72.18925476074219, "report/prior_ent_mean": 22.563011169433594, "report/prior_ent_min": 10.643211364746094, "report/prior_ent_std": 9.72482967376709, "report/rep_loss_mean": 3.0419349670410156, "report/rep_loss_std": 7.940571308135986, "report/reward_avg": 0.02128906175494194, "report/reward_loss_mean": 0.03803582489490509, "report/reward_loss_std": 0.15725019574165344, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0024261474609375, "report/reward_neg_acc": 0.9919679760932922, "report/reward_neg_loss": 0.018633723258972168, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.728196382522583, "report/reward_pred": 0.020594004541635513, "report/reward_rate": 0.02734375, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 2.077032877423335e-05, "eval/cont_loss_std": 0.0005727640818804502, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.004670380614697933, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 2.5365641249663895e-06, "eval/cont_pred": 0.9961092472076416, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 23.724750518798828, "eval/dyn_loss_std": 13.585250854492188, "eval/image_loss_mean": 84.42149353027344, "eval/image_loss_std": 97.24435424804688, "eval/model_loss_mean": 98.80928802490234, "eval/model_loss_std": 101.45301818847656, "eval/post_ent_mag": 38.632537841796875, "eval/post_ent_max": 38.632537841796875, "eval/post_ent_mean": 25.58108139038086, "eval/post_ent_min": 11.315620422363281, "eval/post_ent_std": 5.184620380401611, "eval/prior_ent_mag": 72.18925476074219, "eval/prior_ent_max": 72.18925476074219, "eval/prior_ent_mean": 31.23341178894043, "eval/prior_ent_min": 11.446077346801758, "eval/prior_ent_std": 10.169349670410156, "eval/rep_loss_mean": 23.724750518798828, "eval/rep_loss_std": 13.585250854492188, "eval/reward_avg": 0.01894531399011612, "eval/reward_loss_mean": 0.15291719138622284, "eval/reward_loss_std": 1.0448927879333496, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0005238056182861, "eval/reward_neg_acc": 0.9970029592514038, "eval/reward_neg_loss": 0.05684470757842064, "eval/reward_pos_acc": 0.52173912525177, "eval/reward_pos_loss": 4.334158420562744, "eval/reward_pred": 0.009365515783429146, "eval/reward_rate": 0.0224609375, "replay/size": 29189.0, "replay/inserts": 2168.0, "replay/samples": 34688.0, "replay/insert_wait_avg": 2.7447828947398057e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.77960208509241e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 6704.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 7.748603820800781e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0593078136444, "timer/env.step_count": 271.0, "timer/env.step_total": 27.35682988166809, "timer/env.step_frac": 0.027355207504119232, "timer/env.step_avg": 0.10094771174047266, "timer/env.step_min": 0.023409128189086914, "timer/env.step_max": 2.0139048099517822, "timer/replay._sample_count": 34688.0, "timer/replay._sample_total": 17.747589111328125, "timer/replay._sample_frac": 0.01774653660304244, "timer/replay._sample_avg": 0.0005116348336983431, "timer/replay._sample_min": 0.00035953521728515625, "timer/replay._sample_max": 0.04052305221557617, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 271.0, "timer/agent.policy_total": 4.412508249282837, "timer/agent.policy_frac": 0.004412246568585594, "timer/agent.policy_avg": 0.016282318263036298, "timer/agent.policy_min": 0.010084867477416992, "timer/agent.policy_max": 0.020348072052001953, "timer/dataset_train_count": 2168.0, "timer/dataset_train_total": 0.37732958793640137, "timer/dataset_train_frac": 0.0003773072106706642, "timer/dataset_train_avg": 0.000174045012885794, "timer/dataset_train_min": 8.940696716308594e-05, "timer/dataset_train_max": 0.0004756450653076172, "timer/agent.train_count": 2168.0, "timer/agent.train_total": 965.912926197052, "timer/agent.train_frac": 0.9658556434105452, "timer/agent.train_avg": 0.4455317925263155, "timer/agent.train_min": 0.43455052375793457, "timer/agent.train_max": 0.7563865184783936, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47933292388916016, "timer/agent.report_frac": 0.00047930449738735017, "timer/agent.report_avg": 0.23966646194458008, "timer/agent.report_min": 0.23182415962219238, "timer/agent.report_max": 0.24750876426696777, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.075599670410156e-05, "timer/dataset_eval_frac": 3.0754172741355834e-08, "timer/dataset_eval_avg": 3.075599670410156e-05, "timer/dataset_eval_min": 3.075599670410156e-05, "timer/dataset_eval_max": 3.075599670410156e-05, "fps": 2.1678438712507706}
{"step": 30048, "time": 13467.813802242279, "episode/length": 246.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 30056, "time": 13488.031516075134, "eval_episode/length": 67.0, "eval_episode/score": 2.100000023841858, "eval_episode/reward_rate": 0.9852941176470589}
{"step": 30056, "time": 13490.940103530884, "eval_episode/length": 103.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9519230769230769}
{"step": 30056, "time": 13495.670062065125, "eval_episode/length": 151.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.993421052631579}
{"step": 30056, "time": 13497.130165576935, "eval_episode/length": 152.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9607843137254902}
{"step": 30056, "time": 13498.823468923569, "eval_episode/length": 158.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9685534591194969}
{"step": 30056, "time": 13500.470788240433, "eval_episode/length": 161.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9691358024691358}
{"step": 30056, "time": 13502.23408293724, "eval_episode/length": 167.0, "eval_episode/score": 1.0999999940395355, "eval_episode/reward_rate": 0.9940476190476191}
{"step": 30056, "time": 13504.27097940445, "eval_episode/length": 180.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.994475138121547}
{"step": 30128, "time": 13536.597426891327, "episode/length": 360.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9944598337950139, "episode/intrinsic_return": 0.0}
{"step": 30432, "time": 13675.261223316193, "episode/length": 138.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.0}
{"step": 30624, "time": 13763.37787938118, "episode/length": 168.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 30728, "time": 13812.00805735588, "episode/length": 208.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 30888, "time": 13886.054532289505, "episode/length": 163.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 31152, "time": 14007.07654929161, "episode/length": 137.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9492753623188406, "episode/intrinsic_return": 0.0}
{"step": 31344, "time": 14095.315395355225, "episode/length": 208.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 31680, "time": 14248.174327850342, "episode/length": 155.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 31807, "time": 14307.49060845375, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.925884518013182, "train/action_min": 0.0, "train/action_std": 4.241393814719684, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.041834228817744276, "train/actor_opt_grad_steps": 29190.0, "train/actor_opt_loss": 4.1238913059022755, "train/adv_mag": 0.7156486906711524, "train/adv_max": 0.6777696682943553, "train/adv_mean": 0.004505183900183808, "train/adv_min": -0.5778859760523972, "train/adv_std": 0.056723952258085186, "train/cont_avg": 0.9942100488744076, "train/cont_loss_mean": 7.865304109489408e-05, "train/cont_loss_std": 0.0024186456673399408, "train/cont_neg_acc": 0.9951026857746721, "train/cont_neg_loss": 0.011576968340599602, "train/cont_pos_acc": 0.9999860025130177, "train/cont_pos_loss": 2.9300147649462305e-05, "train/cont_pred": 0.9942125870153238, "train/cont_rate": 0.9942100488744076, "train/dyn_loss_mean": 2.798653279435578, "train/dyn_loss_std": 7.659214365538827, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.493538609330688, "train/extr_critic_critic_opt_grad_steps": 29190.0, "train/extr_critic_critic_opt_loss": 17401.081364780806, "train/extr_critic_mag": 26.893044259310898, "train/extr_critic_max": 26.893044259310898, "train/extr_critic_mean": 5.579635779439555, "train/extr_critic_min": -0.6160102173050434, "train/extr_critic_std": 5.626584375074124, "train/extr_return_normed_mag": 1.501565662323016, "train/extr_return_normed_max": 1.501565662323016, "train/extr_return_normed_mean": 0.31435236638473674, "train/extr_return_normed_min": -0.052353802132663003, "train/extr_return_normed_std": 0.31115864979994806, "train/extr_return_rate": 0.8810784912787343, "train/extr_return_raw_mag": 27.48297299028008, "train/extr_return_raw_max": 27.48297299028008, "train/extr_return_raw_mean": 5.661012741061748, "train/extr_return_raw_min": -1.0736759491441374, "train/extr_return_raw_std": 5.741169680916302, "train/extr_reward_mag": 1.018307754778749, "train/extr_reward_max": 1.018307754778749, "train/extr_reward_mean": 0.022084248322834617, "train/extr_reward_min": -0.6825711116971562, "train/extr_reward_std": 0.15228501866214084, "train/image_loss_mean": 2.256382009994362, "train/image_loss_std": 5.576584308633307, "train/model_loss_mean": 3.9710198906360645, "train/model_loss_std": 9.175188950452759, "train/model_opt_grad_norm": 43.07013869624567, "train/model_opt_grad_steps": 29162.16587677725, "train/model_opt_loss": 5547.709642744742, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1404.0284360189573, "train/policy_entropy_mag": 2.371104535333353, "train/policy_entropy_max": 2.371104535333353, "train/policy_entropy_mean": 0.6245946346018552, "train/policy_entropy_min": 0.0793750191469328, "train/policy_entropy_std": 0.5946916327657292, "train/policy_logprob_mag": 7.43838351371729, "train/policy_logprob_max": -0.009455658124662689, "train/policy_logprob_mean": -0.6245411782750586, "train/policy_logprob_min": -7.43838351371729, "train/policy_logprob_std": 1.1328966013063186, "train/policy_randomness_mag": 0.8368958480550215, "train/policy_randomness_max": 0.8368958480550215, "train/policy_randomness_mean": 0.22045449714807538, "train/policy_randomness_min": 0.028015898531788333, "train/policy_randomness_std": 0.20990004973106474, "train/post_ent_mag": 33.01804843559084, "train/post_ent_max": 33.01804843559084, "train/post_ent_mean": 19.102945074650915, "train/post_ent_min": 10.524244249714494, "train/post_ent_std": 3.629602797223493, "train/prior_ent_mag": 72.72193496487152, "train/prior_ent_max": 72.72193496487152, "train/prior_ent_mean": 21.99041400023546, "train/prior_ent_min": 11.698091515997575, "train/prior_ent_std": 8.7919814010367, "train/rep_loss_mean": 2.798653279435578, "train/rep_loss_std": 7.659214365538827, "train/reward_avg": 0.017640143508197502, "train/reward_loss_mean": 0.03536725040719407, "train/reward_loss_std": 0.1729828425069556, "train/reward_max_data": 1.0080568739588227, "train/reward_max_pred": 1.0091263835464044, "train/reward_neg_acc": 0.9965248825425785, "train/reward_neg_loss": 0.019181668634804503, "train/reward_pos_acc": 0.9853317833624745, "train/reward_pos_loss": 0.7344547945176255, "train/reward_pred": 0.017506101084828942, "train/reward_rate": 0.022757146030805687, "train_stats/sum_log_reward": 3.433333237965902, "train_stats/max_log_achievement_collect_drink": 5.222222222222222, "train_stats/max_log_achievement_collect_sapling": 1.6666666666666667, "train_stats/max_log_achievement_collect_wood": 1.1111111111111112, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.1111111111111111, "train_stats/max_log_achievement_make_wood_pickaxe": 0.1111111111111111, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.6666666666666667, "train_stats/max_log_achievement_place_table": 0.3333333333333333, "train_stats/max_log_achievement_wake_up": 1.5555555555555556, "train_stats/mean_log_entropy": 0.6146427591641744, "eval_stats/sum_log_reward": 2.5999999046325684, "eval_stats/max_log_achievement_collect_drink": 1.25, "eval_stats/max_log_achievement_collect_sapling": 0.75, "eval_stats/max_log_achievement_collect_wood": 1.125, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.125, "eval_stats/max_log_achievement_place_plant": 0.75, "eval_stats/max_log_achievement_place_table": 0.375, "eval_stats/max_log_achievement_wake_up": 1.0, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 8.37176173718035e-07, "report/cont_loss_std": 3.4983452223968925e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 3.013691457454115e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 7.510848263336811e-07, "report/cont_pred": 0.9970695972442627, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 3.2793900966644287, "report/dyn_loss_std": 7.90413761138916, "report/image_loss_mean": 4.866580009460449, "report/image_loss_std": 15.662858963012695, "report/model_loss_mean": 6.860074996948242, "report/model_loss_std": 18.487035751342773, "report/post_ent_mag": 35.113624572753906, "report/post_ent_max": 35.113624572753906, "report/post_ent_mean": 19.16916847229004, "report/post_ent_min": 10.38613510131836, "report/post_ent_std": 3.6830379962921143, "report/prior_ent_mag": 72.99769592285156, "report/prior_ent_max": 72.99769592285156, "report/prior_ent_mean": 22.327831268310547, "report/prior_ent_min": 11.70179557800293, "report/prior_ent_std": 8.60385513305664, "report/rep_loss_mean": 3.2793900966644287, "report/rep_loss_std": 7.90413761138916, "report/reward_avg": 0.02109375037252903, "report/reward_loss_mean": 0.025859873741865158, "report/reward_loss_std": 0.1755196452140808, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0005121231079102, "report/reward_neg_acc": 0.9990009665489197, "report/reward_neg_loss": 0.00766468932852149, "report/reward_pos_acc": 0.95652174949646, "report/reward_pos_loss": 0.8177459836006165, "report/reward_pred": 0.019980425015091896, "report/reward_rate": 0.0224609375, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.004458495881408453, "eval/cont_loss_std": 0.10410916805267334, "eval/cont_neg_acc": 0.6000000238418579, "eval/cont_neg_loss": 0.9129614233970642, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 6.801603831263492e-07, "eval/cont_pred": 0.9969457387924194, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 24.079252243041992, "eval/dyn_loss_std": 13.20425033569336, "eval/image_loss_mean": 52.066776275634766, "eval/image_loss_std": 56.1403923034668, "eval/model_loss_mean": 66.73503112792969, "eval/model_loss_std": 60.692230224609375, "eval/post_ent_mag": 38.00623321533203, "eval/post_ent_max": 38.00623321533203, "eval/post_ent_mean": 24.817934036254883, "eval/post_ent_min": 11.216316223144531, "eval/post_ent_std": 4.7953338623046875, "eval/prior_ent_mag": 72.99769592285156, "eval/prior_ent_max": 72.99769592285156, "eval/prior_ent_mean": 31.495080947875977, "eval/prior_ent_min": 12.620645523071289, "eval/prior_ent_std": 9.553832054138184, "eval/rep_loss_mean": 24.079252243041992, "eval/rep_loss_std": 13.20425033569336, "eval/reward_avg": 0.01689453050494194, "eval/reward_loss_mean": 0.21625696122646332, "eval/reward_loss_std": 1.3062775135040283, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9989180564880371, "eval/reward_neg_acc": 0.9990019798278809, "eval/reward_neg_loss": 0.11394210159778595, "eval/reward_pos_acc": 0.5, "eval/reward_pos_loss": 4.87623405456543, "eval/reward_pred": 0.007043304853141308, "eval/reward_rate": 0.021484375, "replay/size": 31303.0, "replay/inserts": 2114.0, "replay/samples": 33824.0, "replay/insert_wait_avg": 2.6254238897375938e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.636598403880138e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 8152.0, "eval_replay/inserts": 1448.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1240909112751154e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.046627044677734e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1869213581085, "timer/env.step_count": 264.0, "timer/env.step_total": 20.485990524291992, "timer/env.step_frac": 0.02048216197075942, "timer/env.step_avg": 0.07759844895565149, "timer/env.step_min": 0.02327704429626465, "timer/env.step_max": 1.7017171382904053, "timer/replay._sample_count": 33824.0, "timer/replay._sample_total": 17.079140663146973, "timer/replay._sample_frac": 0.01707594880360561, "timer/replay._sample_avg": 0.000504941481289823, "timer/replay._sample_min": 0.0003561973571777344, "timer/replay._sample_max": 0.03974008560180664, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 445.0, "timer/agent.policy_total": 8.247054815292358, "timer/agent.policy_frac": 0.008245513552700786, "timer/agent.policy_avg": 0.018532707450095186, "timer/agent.policy_min": 0.009949922561645508, "timer/agent.policy_max": 0.11640143394470215, "timer/dataset_train_count": 2114.0, "timer/dataset_train_total": 0.36952829360961914, "timer/dataset_train_frac": 0.00036945923378787376, "timer/dataset_train_avg": 0.00017480051731770063, "timer/dataset_train_min": 9.107589721679688e-05, "timer/dataset_train_max": 0.0003323554992675781, "timer/agent.train_count": 2114.0, "timer/agent.train_total": 941.7708370685577, "timer/agent.train_frac": 0.9415948328836071, "timer/agent.train_avg": 0.4454923543370661, "timer/agent.train_min": 0.43491458892822266, "timer/agent.train_max": 0.5830776691436768, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.46397972106933594, "timer/agent.report_frac": 0.0004638930095579723, "timer/agent.report_avg": 0.23198986053466797, "timer/agent.report_min": 0.22134065628051758, "timer/agent.report_max": 0.24263906478881836, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.765655517578125e-05, "timer/dataset_eval_frac": 2.7651386541055412e-08, "timer/dataset_eval_avg": 2.765655517578125e-05, "timer/dataset_eval_min": 2.765655517578125e-05, "timer/dataset_eval_max": 2.765655517578125e-05, "fps": 2.113578432134273}
{"step": 31904, "time": 14351.498467445374, "episode/length": 221.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 32064, "time": 14425.237869739532, "episode/length": 166.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 32208, "time": 14491.498557806015, "episode/length": 164.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 32432, "time": 14593.752413034439, "episode/length": 225.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9646017699115044, "episode/intrinsic_return": 0.0}
{"step": 32600, "time": 14671.192920684814, "episode/length": 435.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9793577981651376, "episode/intrinsic_return": 0.0}
{"step": 32728, "time": 14730.483563899994, "episode/length": 172.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 32816, "time": 14772.370413303375, "episode/length": 207.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 33272, "time": 14979.140795230865, "episode/length": 150.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 33320, "time": 15002.216734409332, "episode/length": 176.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 33480, "time": 15075.862431526184, "episode/length": 224.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 33752, "time": 15200.168058156967, "episode/length": 192.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 33856, "time": 15248.625281572342, "episode/length": 177.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 33983, "time": 15307.856387615204, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.914144253512041, "train/action_min": 0.0, "train/action_std": 4.166517300343295, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04345962088213328, "train/actor_opt_grad_steps": 31335.0, "train/actor_opt_loss": 9.608926246472455, "train/adv_mag": 0.708143199255707, "train/adv_max": 0.6758598880756885, "train/adv_mean": 0.007114485740995915, "train/adv_min": -0.5685021107623337, "train/adv_std": 0.05870110864554523, "train/cont_avg": 0.9946513044724771, "train/cont_loss_mean": 0.0002684709871787768, "train/cont_loss_std": 0.006350144355968253, "train/cont_neg_acc": 0.9962811278640678, "train/cont_neg_loss": 0.020060267400236174, "train/cont_pos_acc": 0.9999684666821717, "train/cont_pos_loss": 0.00015180444411255664, "train/cont_pred": 0.994640168246873, "train/cont_rate": 0.9946513044724771, "train/dyn_loss_mean": 2.7590792507206627, "train/dyn_loss_std": 7.648972996877967, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.3924162874528028, "train/extr_critic_critic_opt_grad_steps": 31335.0, "train/extr_critic_critic_opt_loss": 16616.273459898224, "train/extr_critic_mag": 27.225582569017323, "train/extr_critic_max": 27.225582569017323, "train/extr_critic_mean": 7.524061301432618, "train/extr_critic_min": -0.5987787771662441, "train/extr_critic_std": 5.805301090992919, "train/extr_return_normed_mag": 1.4055972134848254, "train/extr_return_normed_max": 1.4055972134848254, "train/extr_return_normed_mean": 0.39111613065277767, "train/extr_return_normed_min": -0.04922520284703292, "train/extr_return_normed_std": 0.30154897928784746, "train/extr_return_rate": 0.8646729714279875, "train/extr_return_raw_mag": 27.732284169678294, "train/extr_return_raw_max": 27.732284169678294, "train/extr_return_raw_mean": 7.664006340394327, "train/extr_return_raw_min": -1.0647589856878332, "train/extr_return_raw_std": 5.975062321085448, "train/extr_reward_mag": 1.0256111457807209, "train/extr_reward_max": 1.0256111457807209, "train/extr_reward_mean": 0.023150914036797, "train/extr_reward_min": -0.6818275604773005, "train/extr_reward_std": 0.15363852290111943, "train/image_loss_mean": 2.190895708329087, "train/image_loss_std": 5.564087277158685, "train/model_loss_mean": 3.881006141321375, "train/model_loss_std": 9.14462697177852, "train/model_opt_grad_norm": 39.98284253724125, "train/model_opt_grad_steps": 31305.45871559633, "train/model_opt_loss": 6033.951085641844, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1565.366972477064, "train/policy_entropy_mag": 2.351824015652368, "train/policy_entropy_max": 2.351824015652368, "train/policy_entropy_mean": 0.5474593107580045, "train/policy_entropy_min": 0.07937503855572928, "train/policy_entropy_std": 0.5441875960848747, "train/policy_logprob_mag": 7.438383574879498, "train/policy_logprob_max": -0.009455660819460492, "train/policy_logprob_mean": -0.5454860404817337, "train/policy_logprob_min": -7.438383574879498, "train/policy_logprob_std": 1.0910862574883557, "train/policy_randomness_mag": 0.8300906690435672, "train/policy_randomness_max": 0.8300906690435672, "train/policy_randomness_mean": 0.1932291126032488, "train/policy_randomness_min": 0.028015905299112884, "train/policy_randomness_std": 0.1920743433570643, "train/post_ent_mag": 33.20458903881388, "train/post_ent_max": 33.20458903881388, "train/post_ent_mean": 19.095838415513345, "train/post_ent_min": 10.57260677355145, "train/post_ent_std": 3.6078182185461762, "train/prior_ent_mag": 73.1498652116968, "train/prior_ent_max": 73.1498652116968, "train/prior_ent_mean": 21.971467385598277, "train/prior_ent_min": 11.727082396865985, "train/prior_ent_std": 8.754003866003194, "train/rep_loss_mean": 2.7590792507206627, "train/rep_loss_std": 7.648972996877967, "train/reward_avg": 0.017760894391600283, "train/reward_loss_mean": 0.03439440021137579, "train/reward_loss_std": 0.17033941141509135, "train/reward_max_data": 1.0082568827025387, "train/reward_max_pred": 1.0103585074800965, "train/reward_neg_acc": 0.9967429689857938, "train/reward_neg_loss": 0.018140706737790634, "train/reward_pos_acc": 0.9867460364048634, "train/reward_pos_loss": 0.7375275749679006, "train/reward_pred": 0.0175585304429635, "train/reward_rate": 0.02266252150229358, "train_stats/sum_log_reward": 3.516666571299235, "train_stats/max_log_achievement_collect_drink": 5.333333333333333, "train_stats/max_log_achievement_collect_sapling": 1.3333333333333333, "train_stats/max_log_achievement_collect_wood": 1.75, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.1666666666666667, "train_stats/max_log_achievement_place_table": 0.5833333333333334, "train_stats/max_log_achievement_wake_up": 1.75, "train_stats/mean_log_entropy": 0.5996618246038755, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 6.491351314252825e-07, "report/cont_loss_std": 3.107812744929106e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 3.469139483058825e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 5.156360316505015e-07, "report/cont_pred": 0.9960934519767761, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 2.6335721015930176, "report/dyn_loss_std": 7.278897762298584, "report/image_loss_mean": 1.7270910739898682, "report/image_loss_std": 3.3144640922546387, "report/model_loss_mean": 3.3390088081359863, "report/model_loss_std": 6.949710845947266, "report/post_ent_mag": 34.6800651550293, "report/post_ent_max": 34.6800651550293, "report/post_ent_mean": 19.853172302246094, "report/post_ent_min": 9.64736557006836, "report/post_ent_std": 3.813527822494507, "report/prior_ent_mag": 73.69877624511719, "report/prior_ent_max": 73.69877624511719, "report/prior_ent_mean": 22.67632484436035, "report/prior_ent_min": 10.77138900756836, "report/prior_ent_std": 8.642189979553223, "report/rep_loss_mean": 2.6335721015930176, "report/rep_loss_std": 7.278897762298584, "report/reward_avg": 0.015136719681322575, "report/reward_loss_mean": 0.0317736491560936, "report/reward_loss_std": 0.20981934666633606, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0014514923095703, "report/reward_neg_acc": 0.9960199594497681, "report/reward_neg_loss": 0.013961686752736568, "report/reward_pos_acc": 0.8947368264198303, "report/reward_pos_loss": 0.9739328026771545, "report/reward_pred": 0.0136703010648489, "report/reward_rate": 0.0185546875, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 2.6420912035973743e-06, "eval/cont_loss_std": 5.846176645718515e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0005272983107715845, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 5.846158614986052e-07, "eval/cont_pred": 0.9960952997207642, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 27.438940048217773, "eval/dyn_loss_std": 12.605679512023926, "eval/image_loss_mean": 72.81301879882812, "eval/image_loss_std": 69.95475006103516, "eval/model_loss_mean": 89.41531372070312, "eval/model_loss_std": 74.15011596679688, "eval/post_ent_mag": 36.351234436035156, "eval/post_ent_max": 36.351234436035156, "eval/post_ent_mean": 26.010761260986328, "eval/post_ent_min": 14.289673805236816, "eval/post_ent_std": 4.502054214477539, "eval/prior_ent_mag": 73.69877624511719, "eval/prior_ent_max": 73.69877624511719, "eval/prior_ent_mean": 32.33494567871094, "eval/prior_ent_min": 12.388340950012207, "eval/prior_ent_std": 9.253662109375, "eval/rep_loss_mean": 27.438940048217773, "eval/rep_loss_std": 12.605679512023926, "eval/reward_avg": 0.01875000074505806, "eval/reward_loss_mean": 0.13892653584480286, "eval/reward_loss_std": 1.0251946449279785, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0015757083892822, "eval/reward_neg_acc": 0.9970059990882874, "eval/reward_neg_loss": 0.05290229618549347, "eval/reward_pos_acc": 0.5454545617103577, "eval/reward_pos_loss": 4.056939601898193, "eval/reward_pred": 0.008783973753452301, "eval/reward_rate": 0.021484375, "replay/size": 33479.0, "replay/inserts": 2176.0, "replay/samples": 34816.0, "replay/insert_wait_avg": 2.675854107912849e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.576856981305515e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 8152.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 7.003545761108398e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3547787666321, "timer/env.step_count": 272.0, "timer/env.step_total": 24.89887547492981, "timer/env.step_frac": 0.024890045015457808, "timer/env.step_avg": 0.09153998336371254, "timer/env.step_min": 0.023611783981323242, "timer/env.step_max": 1.6001441478729248, "timer/replay._sample_count": 34816.0, "timer/replay._sample_total": 17.59956693649292, "timer/replay._sample_frac": 0.017593325198278116, "timer/replay._sample_avg": 0.0005055022672476137, "timer/replay._sample_min": 0.0003654956817626953, "timer/replay._sample_max": 0.022563695907592773, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 272.0, "timer/agent.policy_total": 4.414634943008423, "timer/agent.policy_frac": 0.004413069279732298, "timer/agent.policy_avg": 0.01623027552576626, "timer/agent.policy_min": 0.009769201278686523, "timer/agent.policy_max": 0.0400090217590332, "timer/dataset_train_count": 2176.0, "timer/dataset_train_total": 0.42753100395202637, "timer/dataset_train_frac": 0.0004273793788231235, "timer/dataset_train_avg": 0.00019647564519854153, "timer/dataset_train_min": 9.34600830078125e-05, "timer/dataset_train_max": 0.04229879379272461, "timer/agent.train_count": 2176.0, "timer/agent.train_total": 968.5509774684906, "timer/agent.train_frac": 0.968207478013597, "timer/agent.train_avg": 0.44510614773368135, "timer/agent.train_min": 0.43441009521484375, "timer/agent.train_max": 0.5662546157836914, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.471874475479126, "timer/agent.report_frac": 0.00047170712380752996, "timer/agent.report_avg": 0.235937237739563, "timer/agent.report_min": 0.22800230979919434, "timer/agent.report_max": 0.24387216567993164, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 5.435943603515625e-05, "timer/dataset_eval_frac": 5.434015730117035e-08, "timer/dataset_eval_avg": 5.435943603515625e-05, "timer/dataset_eval_min": 5.435943603515625e-05, "timer/dataset_eval_max": 5.435943603515625e-05, "fps": 2.1752005804505474}
{"step": 34088, "time": 15355.454843521118, "episode/length": 101.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9607843137254902, "episode/intrinsic_return": 0.0}
{"step": 34096, "time": 15360.573048591614, "episode/length": 159.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 34200, "time": 15409.261302947998, "episode/length": 183.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 34224, "time": 15421.635437965393, "episode/length": 202.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 34656, "time": 15618.171192646027, "episode/length": 146.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 34752, "time": 15662.874366283417, "episode/length": 178.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 35136, "time": 15837.506952047348, "episode/length": 172.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 35224, "time": 15878.439735889435, "episode/length": 170.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 35400, "time": 15959.3848528862, "episode/length": 162.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 35408, "time": 15964.477415084839, "episode/length": 147.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 35464, "time": 15991.219212293625, "episode/length": 171.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 35688, "time": 16093.798922538757, "episode/length": 57.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9137931034482759, "episode/intrinsic_return": 0.0}
{"step": 35696, "time": 16098.95719408989, "episode/length": 186.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 36112, "time": 16288.420922517776, "episode/length": 169.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 36151, "time": 16308.017886638641, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.187863679525489, "train/action_min": 0.0, "train/action_std": 4.433899631148659, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04263986011941312, "train/actor_opt_grad_steps": 33510.0, "train/actor_opt_loss": -2.7925841185577593, "train/adv_mag": 0.6995874963323092, "train/adv_max": 0.6514679487399792, "train/adv_mean": 0.003724167078896835, "train/adv_min": -0.5632724771576543, "train/adv_std": 0.05671346148106909, "train/cont_avg": 0.994379140264977, "train/cont_loss_mean": 5.301600365860102e-05, "train/cont_loss_std": 0.0015952330382918657, "train/cont_neg_acc": 0.9987656356002877, "train/cont_neg_loss": 0.004518270947724375, "train/cont_pos_acc": 0.9999909043861425, "train/cont_pos_loss": 2.1080788765335173e-05, "train/cont_pred": 0.9943810748065123, "train/cont_rate": 0.994379140264977, "train/dyn_loss_mean": 2.7621049716175974, "train/dyn_loss_std": 7.706988244562105, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.3650531312837029, "train/extr_critic_critic_opt_grad_steps": 33510.0, "train/extr_critic_critic_opt_loss": 16320.78334263393, "train/extr_critic_mag": 27.13473028191773, "train/extr_critic_max": 27.13473028191773, "train/extr_critic_mean": 8.4258696868123, "train/extr_critic_min": -0.6117041292278448, "train/extr_critic_std": 5.9269591619342155, "train/extr_return_normed_mag": 1.3900368112023525, "train/extr_return_normed_max": 1.3900368112023525, "train/extr_return_normed_mean": 0.4377406227149172, "train/extr_return_normed_min": -0.04994473197767811, "train/extr_return_normed_std": 0.30571104847066416, "train/extr_return_rate": 0.8557526128632682, "train/extr_return_raw_mag": 27.34998045538977, "train/extr_return_raw_max": 27.34998045538977, "train/extr_return_raw_mean": 8.500572417738251, "train/extr_return_raw_min": -1.0350819566557485, "train/extr_return_raw_std": 6.021453935429797, "train/extr_reward_mag": 1.0210521935317922, "train/extr_reward_max": 1.0210521935317922, "train/extr_reward_mean": 0.022628467414133286, "train/extr_reward_min": -0.6767765300065142, "train/extr_reward_std": 0.1519131395055951, "train/image_loss_mean": 2.01090906951834, "train/image_loss_std": 5.129039935801985, "train/model_loss_mean": 3.7029450576975598, "train/model_loss_std": 8.818642207554408, "train/model_opt_grad_norm": 38.18479133641115, "train/model_opt_grad_steps": 33478.58525345622, "train/model_opt_loss": 5070.344863821285, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1370.967741935484, "train/policy_entropy_mag": 2.3206261314005348, "train/policy_entropy_max": 2.3206261314005348, "train/policy_entropy_mean": 0.5514295937553528, "train/policy_entropy_min": 0.07937503873889896, "train/policy_entropy_std": 0.5375070166752635, "train/policy_logprob_mag": 7.438383627597088, "train/policy_logprob_max": -0.009455665739999938, "train/policy_logprob_mean": -0.551635868401022, "train/policy_logprob_min": -7.438383627597088, "train/policy_logprob_std": 1.0968618376463788, "train/policy_randomness_mag": 0.8190791851364523, "train/policy_randomness_max": 0.8190791851364523, "train/policy_randomness_mean": 0.1946304470712688, "train/policy_randomness_min": 0.028015905347425266, "train/policy_randomness_std": 0.18971639129972678, "train/post_ent_mag": 33.951771591116206, "train/post_ent_max": 33.951771591116206, "train/post_ent_mean": 19.202701014857137, "train/post_ent_min": 10.693761838745962, "train/post_ent_std": 3.634358139082034, "train/prior_ent_mag": 73.39357332150507, "train/prior_ent_max": 73.39357332150507, "train/prior_ent_mean": 22.047380719866073, "train/prior_ent_min": 11.858344702127342, "train/prior_ent_std": 8.82661327678487, "train/rep_loss_mean": 2.7621049716175974, "train/rep_loss_std": 7.706988244562105, "train/reward_avg": 0.01771583368847241, "train/reward_loss_mean": 0.034719997725110446, "train/reward_loss_std": 0.16674174121173296, "train/reward_max_data": 1.0096774216621154, "train/reward_max_pred": 1.0106124597760389, "train/reward_neg_acc": 0.9967547539741762, "train/reward_neg_loss": 0.018691062238410733, "train/reward_pos_acc": 0.9909146211114347, "train/reward_pos_loss": 0.7188351645997043, "train/reward_pred": 0.01765032053156863, "train/reward_rate": 0.022883964573732717, "train_stats/sum_log_reward": 3.242857047489711, "train_stats/max_log_achievement_collect_drink": 1.8571428571428572, "train_stats/max_log_achievement_collect_sapling": 2.0, "train_stats/max_log_achievement_collect_wood": 1.5714285714285714, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.9285714285714286, "train_stats/max_log_achievement_place_table": 0.42857142857142855, "train_stats/max_log_achievement_wake_up": 1.2857142857142858, "train_stats/mean_log_entropy": 0.5049623612846647, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 9.675052297097864e-07, "report/cont_loss_std": 1.4986051155574387e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.5055823496368248e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 8.705354161975265e-07, "report/cont_pred": 0.9931632876396179, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 2.538142204284668, "report/dyn_loss_std": 7.440338134765625, "report/image_loss_mean": 1.712188720703125, "report/image_loss_std": 3.7947824001312256, "report/model_loss_mean": 3.274007797241211, "report/model_loss_std": 7.4670796394348145, "report/post_ent_mag": 31.94802474975586, "report/post_ent_max": 31.94802474975586, "report/post_ent_mean": 19.5184268951416, "report/post_ent_min": 11.421648025512695, "report/post_ent_std": 3.2243292331695557, "report/prior_ent_mag": 73.51560974121094, "report/prior_ent_max": 73.51560974121094, "report/prior_ent_mean": 22.236543655395508, "report/prior_ent_min": 11.5692720413208, "report/prior_ent_std": 8.61156177520752, "report/rep_loss_mean": 2.538142204284668, "report/rep_loss_std": 7.440338134765625, "report/reward_avg": 0.02265624888241291, "report/reward_loss_mean": 0.03893289342522621, "report/reward_loss_std": 0.1581859290599823, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.00421142578125, "report/reward_neg_acc": 0.9929648041725159, "report/reward_neg_loss": 0.018898852169513702, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7263078093528748, "report/reward_pred": 0.021971769630908966, "report/reward_rate": 0.0283203125, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 3.0362078177859075e-05, "eval/cont_loss_std": 0.0009454537066631019, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.03027009405195713, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 8.02226054474886e-07, "eval/cont_pred": 0.9990517497062683, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 25.913663864135742, "eval/dyn_loss_std": 13.396056175231934, "eval/image_loss_mean": 75.01081848144531, "eval/image_loss_std": 77.81226348876953, "eval/model_loss_mean": 90.79173278808594, "eval/model_loss_std": 81.72710418701172, "eval/post_ent_mag": 36.594383239746094, "eval/post_ent_max": 36.594383239746094, "eval/post_ent_mean": 26.100059509277344, "eval/post_ent_min": 12.861945152282715, "eval/post_ent_std": 3.9808619022369385, "eval/prior_ent_mag": 73.51560974121094, "eval/prior_ent_max": 73.51560974121094, "eval/prior_ent_mean": 33.348602294921875, "eval/prior_ent_min": 11.359663009643555, "eval/prior_ent_std": 9.08890438079834, "eval/rep_loss_mean": 25.913663864135742, "eval/rep_loss_std": 13.396056175231934, "eval/reward_avg": 0.02744140662252903, "eval/reward_loss_mean": 0.23268797993659973, "eval/reward_loss_std": 1.5060757398605347, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0046908855438232, "eval/reward_neg_acc": 0.9969818592071533, "eval/reward_neg_loss": 0.06613928079605103, "eval/reward_pos_acc": 0.46666669845581055, "eval/reward_pos_loss": 5.751001834869385, "eval/reward_pred": 0.012752793729305267, "eval/reward_rate": 0.029296875, "replay/size": 35647.0, "replay/inserts": 2168.0, "replay/samples": 34688.0, "replay/insert_wait_avg": 2.7086022155311277e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.603853611048737e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 8152.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 7.897615432739258e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1464531421661, "timer/env.step_count": 271.0, "timer/env.step_total": 28.13898468017578, "timer/env.step_frac": 0.028134864240903282, "timer/env.step_avg": 0.10383389180876672, "timer/env.step_min": 0.02349257469177246, "timer/env.step_max": 1.8729965686798096, "timer/replay._sample_count": 34688.0, "timer/replay._sample_total": 17.586737632751465, "timer/replay._sample_frac": 0.017584162376919007, "timer/replay._sample_avg": 0.0005069977407965712, "timer/replay._sample_min": 0.0003478527069091797, "timer/replay._sample_max": 0.024684429168701172, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 271.0, "timer/agent.policy_total": 4.39821457862854, "timer/agent.policy_frac": 0.004397570540604971, "timer/agent.policy_avg": 0.01622957409088022, "timer/agent.policy_min": 0.009827136993408203, "timer/agent.policy_max": 0.03944253921508789, "timer/dataset_train_count": 2168.0, "timer/dataset_train_total": 0.37940382957458496, "timer/dataset_train_frac": 0.000379348272828054, "timer/dataset_train_avg": 0.0001750017664089414, "timer/dataset_train_min": 9.107589721679688e-05, "timer/dataset_train_max": 0.0007197856903076172, "timer/agent.train_count": 2168.0, "timer/agent.train_total": 965.2519924640656, "timer/agent.train_frac": 0.9651106489769848, "timer/agent.train_avg": 0.4452269337933882, "timer/agent.train_min": 0.43470239639282227, "timer/agent.train_max": 0.5585036277770996, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47406792640686035, "timer/agent.report_frac": 0.0004739985078360057, "timer/agent.report_avg": 0.23703396320343018, "timer/agent.report_min": 0.22936344146728516, "timer/agent.report_max": 0.2447044849395752, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.218650817871094e-05, "timer/dataset_eval_frac": 3.2181795053704775e-08, "timer/dataset_eval_avg": 3.218650817871094e-05, "timer/dataset_eval_min": 3.218650817871094e-05, "timer/dataset_eval_max": 3.218650817871094e-05, "fps": 2.1676554029144657}
{"step": 36536, "time": 16483.26592850685, "episode/length": 174.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 36744, "time": 16578.95080971718, "episode/length": 167.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 36784, "time": 16598.600963830948, "episode/length": 171.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 36832, "time": 16622.219093561172, "episode/length": 170.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 36952, "time": 16677.89433836937, "episode/length": 157.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 37272, "time": 16823.926157474518, "episode/length": 144.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 37496, "time": 16926.604108333588, "episode/length": 27.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8214285714285714, "episode/intrinsic_return": 0.0}
{"step": 37608, "time": 16979.213750600815, "episode/length": 368.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 37688, "time": 17016.711541891098, "episode/length": 143.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 37840, "time": 17087.042681217194, "episode/length": 267.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9813432835820896, "episode/intrinsic_return": 0.0}
{"step": 38072, "time": 17193.535368919373, "episode/length": 160.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 38144, "time": 17227.562432289124, "episode/length": 163.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9634146341463414, "episode/intrinsic_return": 0.0}
{"step": 38288, "time": 17294.090125083923, "episode/length": 192.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 38315, "time": 17308.356659173965, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.044103551793982, "train/action_min": 0.0, "train/action_std": 4.384984948016979, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.039101359296452115, "train/actor_opt_grad_steps": 35675.0, "train/actor_opt_loss": -16.055872105820864, "train/adv_mag": 0.6728324168534191, "train/adv_max": 0.6115441180213734, "train/adv_mean": 0.0004718680723406713, "train/adv_min": -0.5446562985027278, "train/adv_std": 0.05108594195917249, "train/cont_avg": 0.9944842303240741, "train/cont_loss_mean": 0.00015066449665850028, "train/cont_loss_std": 0.004655783039647569, "train/cont_neg_acc": 0.9962522050848713, "train/cont_neg_loss": 0.01405454472372909, "train/cont_pos_acc": 0.9999863687488768, "train/cont_pos_loss": 5.4124770289621224e-05, "train/cont_pred": 0.9944877892180726, "train/cont_rate": 0.9944842303240741, "train/dyn_loss_mean": 2.78349131014612, "train/dyn_loss_std": 7.692389344727552, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.2221358266693574, "train/extr_critic_critic_opt_grad_steps": 35675.0, "train/extr_critic_critic_opt_loss": 14679.57310655382, "train/extr_critic_mag": 23.02397948724252, "train/extr_critic_max": 23.02397948724252, "train/extr_critic_mean": 7.670364265088682, "train/extr_critic_min": -0.6078000488104643, "train/extr_critic_std": 4.611962807399255, "train/extr_return_normed_mag": 1.5354394024169002, "train/extr_return_normed_max": 1.5354394024169002, "train/extr_return_normed_mean": 0.5015099906811008, "train/extr_return_normed_min": -0.06751258220282141, "train/extr_return_normed_std": 0.3059334080252383, "train/extr_return_rate": 0.8853287015248228, "train/extr_return_raw_mag": 23.37274507240013, "train/extr_return_raw_max": 23.37274507240013, "train/extr_return_raw_mean": 7.678333834365562, "train/extr_return_raw_min": -1.0005172536604934, "train/extr_return_raw_std": 4.667307565609614, "train/extr_reward_mag": 1.0262733532322779, "train/extr_reward_max": 1.0262733532322779, "train/extr_reward_mean": 0.023708904959709832, "train/extr_reward_min": -0.6756996501375128, "train/extr_reward_std": 0.15390343577773483, "train/image_loss_mean": 1.9466992693918723, "train/image_loss_std": 4.87074034191944, "train/model_loss_mean": 3.651691249123326, "train/model_loss_std": 8.573744032118055, "train/model_opt_grad_norm": 37.66147330955223, "train/model_opt_grad_steps": 35642.37037037037, "train/model_opt_loss": 6577.814888283058, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1828.7037037037037, "train/policy_entropy_mag": 2.329365486348117, "train/policy_entropy_max": 2.329365486348117, "train/policy_entropy_mean": 0.4958363865260725, "train/policy_entropy_min": 0.07937503364627008, "train/policy_entropy_std": 0.49475530314224736, "train/policy_logprob_mag": 7.438383627820898, "train/policy_logprob_max": -0.009455661944769047, "train/policy_logprob_mean": -0.4963400336327376, "train/policy_logprob_min": -7.438383627820898, "train/policy_logprob_std": 1.0619623034640595, "train/policy_randomness_mag": 0.8221637943276653, "train/policy_randomness_max": 0.8221637943276653, "train/policy_randomness_mean": 0.17500848709433167, "train/policy_randomness_min": 0.028015903611150052, "train/policy_randomness_std": 0.1746269098172585, "train/post_ent_mag": 34.415012439092, "train/post_ent_max": 34.415012439092, "train/post_ent_mean": 19.21097589422155, "train/post_ent_min": 10.614278195080933, "train/post_ent_std": 3.663125936631803, "train/prior_ent_mag": 73.59789286719428, "train/prior_ent_max": 73.59789286719428, "train/prior_ent_mean": 22.093522760603165, "train/prior_ent_min": 11.7965152837612, "train/prior_ent_std": 8.874955521689522, "train/rep_loss_mean": 2.78349131014612, "train/rep_loss_std": 7.692389344727552, "train/reward_avg": 0.01760344315725551, "train/reward_loss_mean": 0.03474653997734465, "train/reward_loss_std": 0.16955669210464866, "train/reward_max_data": 1.0129629660535742, "train/reward_max_pred": 1.0139574276076422, "train/reward_neg_acc": 0.9965807594082974, "train/reward_neg_loss": 0.018839496271943465, "train/reward_pos_acc": 0.9884927054798162, "train/reward_pos_loss": 0.7219198359935372, "train/reward_pred": 0.01747295249003434, "train/reward_rate": 0.022596571180555556, "train_stats/sum_log_reward": 3.253846058478722, "train_stats/max_log_achievement_collect_drink": 1.3076923076923077, "train_stats/max_log_achievement_collect_sapling": 2.0, "train_stats/max_log_achievement_collect_wood": 1.3846153846153846, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 2.0, "train_stats/max_log_achievement_place_table": 0.38461538461538464, "train_stats/max_log_achievement_wake_up": 1.7692307692307692, "train_stats/mean_log_entropy": 0.4994688286231114, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 6.082357685954776e-06, "report/cont_loss_std": 2.546582663853769e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 2.2520871425513178e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 5.952920218987856e-06, "report/cont_pred": 0.9921817183494568, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 2.559109687805176, "report/dyn_loss_std": 7.741488933563232, "report/image_loss_mean": 1.3062334060668945, "report/image_loss_std": 4.5766167640686035, "report/model_loss_mean": 2.893350839614868, "report/model_loss_std": 8.34216022491455, "report/post_ent_mag": 36.12702178955078, "report/post_ent_max": 36.12702178955078, "report/post_ent_mean": 19.19032096862793, "report/post_ent_min": 10.749603271484375, "report/post_ent_std": 3.3598790168762207, "report/prior_ent_mag": 73.52354431152344, "report/prior_ent_max": 73.52354431152344, "report/prior_ent_mean": 21.915937423706055, "report/prior_ent_min": 12.872312545776367, "report/prior_ent_std": 8.961828231811523, "report/rep_loss_mean": 2.559109687805176, "report/rep_loss_std": 7.741488933563232, "report/reward_avg": 0.02851562574505806, "report/reward_loss_mean": 0.05164546146988869, "report/reward_loss_std": 0.2500011920928955, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.111022710800171, "report/reward_neg_acc": 0.9898785948753357, "report/reward_neg_loss": 0.023432226851582527, "report/reward_pos_acc": 0.9722222089767456, "report/reward_pos_loss": 0.8259420394897461, "report/reward_pred": 0.027654435485601425, "report/reward_rate": 0.03515625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.0001739149884087965, "eval/cont_loss_std": 0.004295579623430967, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.04305364191532135, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 5.75917601963738e-06, "eval/cont_pred": 0.9962472915649414, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 24.304584503173828, "eval/dyn_loss_std": 13.579440116882324, "eval/image_loss_mean": 63.86643600463867, "eval/image_loss_std": 66.27722930908203, "eval/model_loss_mean": 78.55215454101562, "eval/model_loss_std": 71.60270690917969, "eval/post_ent_mag": 35.957923889160156, "eval/post_ent_max": 35.957923889160156, "eval/post_ent_mean": 25.45465087890625, "eval/post_ent_min": 11.552059173583984, "eval/post_ent_std": 4.292776107788086, "eval/prior_ent_mag": 73.52354431152344, "eval/prior_ent_max": 73.52354431152344, "eval/prior_ent_mean": 32.90709686279297, "eval/prior_ent_min": 11.853055953979492, "eval/prior_ent_std": 9.231782913208008, "eval/rep_loss_mean": 24.304584503173828, "eval/rep_loss_std": 13.579440116882324, "eval/reward_avg": 0.009960937313735485, "eval/reward_loss_mean": 0.10279268026351929, "eval/reward_loss_std": 0.7928280234336853, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0018155574798584, "eval/reward_neg_acc": 0.997029721736908, "eval/reward_neg_loss": 0.059952523559331894, "eval/reward_pos_acc": 0.6428571939468384, "eval/reward_pos_loss": 3.193404197692871, "eval/reward_pred": 0.007818711921572685, "eval/reward_rate": 0.013671875, "replay/size": 37811.0, "replay/inserts": 2164.0, "replay/samples": 34624.0, "replay/insert_wait_avg": 2.701709980003935e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.643799905195254e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 8152.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 9.08970832824707e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.328786611557, "timer/env.step_count": 271.0, "timer/env.step_total": 26.95104146003723, "timer/env.step_frac": 0.026942183230904793, "timer/env.step_avg": 0.0994503374909123, "timer/env.step_min": 0.02351212501525879, "timer/env.step_max": 1.9608221054077148, "timer/replay._sample_count": 34624.0, "timer/replay._sample_total": 17.525707483291626, "timer/replay._sample_frac": 0.017519947159230484, "timer/replay._sample_avg": 0.0005061722355386907, "timer/replay._sample_min": 0.00034618377685546875, "timer/replay._sample_max": 0.010717153549194336, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 271.0, "timer/agent.policy_total": 4.373143434524536, "timer/agent.policy_frac": 0.004371706076097053, "timer/agent.policy_avg": 0.01613706064400198, "timer/agent.policy_min": 0.010458946228027344, "timer/agent.policy_max": 0.02626347541809082, "timer/dataset_train_count": 2164.0, "timer/dataset_train_total": 0.3809394836425781, "timer/dataset_train_frac": 0.00038081427700680854, "timer/dataset_train_avg": 0.0001760348815353873, "timer/dataset_train_min": 8.702278137207031e-05, "timer/dataset_train_max": 0.0007300376892089844, "timer/agent.train_count": 2164.0, "timer/agent.train_total": 966.615168094635, "timer/agent.train_frac": 0.9662974624262077, "timer/agent.train_avg": 0.446679837381994, "timer/agent.train_min": 0.4369547367095947, "timer/agent.train_max": 0.5661561489105225, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47142839431762695, "timer/agent.report_frac": 0.0004712734459182267, "timer/agent.report_avg": 0.23571419715881348, "timer/agent.report_min": 0.22847604751586914, "timer/agent.report_max": 0.2429523468017578, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0994415283203125e-05, "timer/dataset_eval_frac": 3.098422808383973e-08, "timer/dataset_eval_avg": 3.0994415283203125e-05, "timer/dataset_eval_min": 3.0994415283203125e-05, "timer/dataset_eval_max": 3.0994415283203125e-05, "fps": 2.163261109559351}
{"step": 38320, "time": 17310.860240221024, "episode/length": 170.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 38848, "time": 17551.320719718933, "episode/length": 144.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 38928, "time": 17588.964931964874, "episode/length": 164.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 39016, "time": 17630.23740530014, "episode/length": 189.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 39136, "time": 17685.922694206238, "episode/length": 161.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 39600, "time": 17897.27620768547, "episode/length": 190.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 39656, "time": 17924.138548851013, "episode/length": 188.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 39720, "time": 17954.475271463394, "episode/length": 178.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 39776, "time": 17981.197100162506, "episode/length": 115.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 39776, "time": 17981.2062292099, "episode/length": 181.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 40040, "time": 18120.569717407227, "eval_episode/length": 111.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9553571428571429}
{"step": 40040, "time": 18123.998774766922, "eval_episode/length": 162.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9693251533742331}
{"step": 40040, "time": 18125.65039587021, "eval_episode/length": 166.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9640718562874252}
{"step": 40040, "time": 18125.65826511383, "eval_episode/length": 166.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9940119760479041}
{"step": 40040, "time": 18129.13374209404, "eval_episode/length": 172.0, "eval_episode/score": 2.0999999940395355, "eval_episode/reward_rate": 0.9942196531791907}
{"step": 40040, "time": 18131.1025660038, "eval_episode/length": 182.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9781420765027322}
{"step": 40040, "time": 18133.432238817215, "eval_episode/length": 204.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.975609756097561}
{"step": 40040, "time": 18135.732105493546, "eval_episode/length": 226.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9955947136563876}
{"step": 40056, "time": 18142.89243721962, "episode/length": 41.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8809523809523809, "episode/intrinsic_return": 0.0}
{"step": 40240, "time": 18227.578088998795, "episode/length": 152.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 40400, "time": 18301.97540450096, "episode/length": 183.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 40410, "time": 18308.462364435196, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.131736828031994, "train/action_min": 0.0, "train/action_std": 4.508399352573213, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0365335843658873, "train/actor_opt_grad_steps": 37805.0, "train/actor_opt_loss": -17.11058862104657, "train/adv_mag": 0.6363494221653258, "train/adv_max": 0.5896835342759178, "train/adv_mean": -0.00010969259784317165, "train/adv_min": -0.4938480712828182, "train/adv_std": 0.047861384901972046, "train/cont_avg": 0.9944103422619047, "train/cont_loss_mean": 0.0001756576805210638, "train/cont_loss_std": 0.005183627679536498, "train/cont_neg_acc": 0.9948448782875424, "train/cont_neg_loss": 0.02453126806031356, "train/cont_pos_acc": 0.999990621634892, "train/cont_pos_loss": 4.307953399897239e-05, "train/cont_pred": 0.9944194765318007, "train/cont_rate": 0.9944103422619047, "train/dyn_loss_mean": 2.8134545417059034, "train/dyn_loss_std": 7.74688012940543, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.2931890181132726, "train/extr_critic_critic_opt_grad_steps": 37805.0, "train/extr_critic_critic_opt_loss": 15038.870624069941, "train/extr_critic_mag": 23.938393002464657, "train/extr_critic_max": 23.938393002464657, "train/extr_critic_mean": 6.145121878669375, "train/extr_critic_min": -0.4957874002910796, "train/extr_critic_std": 4.220706501461211, "train/extr_return_normed_mag": 1.6398716239702134, "train/extr_return_normed_max": 1.6398716239702134, "train/extr_return_normed_mean": 0.4014749710048948, "train/extr_return_normed_min": -0.0801855289244226, "train/extr_return_normed_std": 0.2937518963501567, "train/extr_return_rate": 0.9233792631399064, "train/extr_return_raw_mag": 24.160134288242887, "train/extr_return_raw_max": 24.160134288242887, "train/extr_return_raw_mean": 6.143833523704892, "train/extr_return_raw_min": -0.8764890700578689, "train/extr_return_raw_std": 4.280160620099022, "train/extr_reward_mag": 1.0232174975531443, "train/extr_reward_max": 1.0232174975531443, "train/extr_reward_mean": 0.024882542572560763, "train/extr_reward_min": -0.676482731955392, "train/extr_reward_std": 0.15691745721158526, "train/image_loss_mean": 2.0192964502743314, "train/image_loss_std": 5.375686572846912, "train/model_loss_mean": 3.7423975286029636, "train/model_loss_std": 9.07512469972883, "train/model_opt_grad_norm": 35.053365870884484, "train/model_opt_grad_steps": 37770.54285714286, "train/model_opt_loss": 5216.463604445685, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1404.7619047619048, "train/policy_entropy_mag": 2.2729551076889036, "train/policy_entropy_max": 2.2729551076889036, "train/policy_entropy_mean": 0.4787240648553485, "train/policy_entropy_min": 0.0793750143476895, "train/policy_entropy_std": 0.4811186628682273, "train/policy_logprob_mag": 7.438383676892236, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.47880983962899165, "train/policy_logprob_min": -7.438383676892236, "train/policy_logprob_std": 1.0447850179104579, "train/policy_randomness_mag": 0.8022534038339343, "train/policy_randomness_max": 0.8022534038339343, "train/policy_randomness_mean": 0.16896858779447418, "train/policy_randomness_min": 0.02801589689084462, "train/policy_randomness_std": 0.16981377551952997, "train/post_ent_mag": 34.553887467157274, "train/post_ent_max": 34.553887467157274, "train/post_ent_mean": 19.443206105913436, "train/post_ent_min": 10.636932756787255, "train/post_ent_std": 3.676789214497521, "train/prior_ent_mag": 73.81394097464425, "train/prior_ent_max": 73.81394097464425, "train/prior_ent_mean": 22.32377714429583, "train/prior_ent_min": 11.916300628298805, "train/prior_ent_std": 8.910418326514108, "train/rep_loss_mean": 2.8134545417059034, "train/rep_loss_std": 7.74688012940543, "train/reward_avg": 0.01805385028987768, "train/reward_loss_mean": 0.034852683827990574, "train/reward_loss_std": 0.16734611959684462, "train/reward_max_data": 1.0123809553328014, "train/reward_max_pred": 1.0125248801140558, "train/reward_neg_acc": 0.9967297031765893, "train/reward_neg_loss": 0.018496256585543356, "train/reward_pos_acc": 0.9875754115127382, "train/reward_pos_loss": 0.7271811559086754, "train/reward_pred": 0.017842077933961437, "train/reward_rate": 0.023037574404761906, "train_stats/sum_log_reward": 3.09999994131235, "train_stats/max_log_achievement_collect_drink": 3.6923076923076925, "train_stats/max_log_achievement_collect_sapling": 1.1538461538461537, "train_stats/max_log_achievement_collect_wood": 1.2307692307692308, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.1538461538461537, "train_stats/max_log_achievement_place_table": 0.38461538461538464, "train_stats/max_log_achievement_wake_up": 1.6153846153846154, "train_stats/mean_log_entropy": 0.48020527913020206, "eval_stats/sum_log_reward": 3.0999999791383743, "eval_stats/max_log_achievement_collect_drink": 6.625, "eval_stats/max_log_achievement_collect_sapling": 2.125, "eval_stats/max_log_achievement_collect_wood": 0.75, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.0, "eval_stats/max_log_achievement_place_table": 0.125, "eval_stats/max_log_achievement_wake_up": 2.0, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 7.584443665109575e-06, "report/cont_loss_std": 4.583678310154937e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0004467792168725282, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 5.862110810994636e-06, "report/cont_pred": 0.9960896372795105, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 2.500607967376709, "report/dyn_loss_std": 7.005074501037598, "report/image_loss_mean": 1.2549052238464355, "report/image_loss_std": 3.924264907836914, "report/model_loss_mean": 2.782822608947754, "report/model_loss_std": 7.507813453674316, "report/post_ent_mag": 36.81742858886719, "report/post_ent_max": 36.81742858886719, "report/post_ent_mean": 19.445526123046875, "report/post_ent_min": 11.426194190979004, "report/post_ent_std": 3.6033689975738525, "report/prior_ent_mag": 74.25100708007812, "report/prior_ent_max": 74.25100708007812, "report/prior_ent_mean": 21.997875213623047, "report/prior_ent_min": 12.892244338989258, "report/prior_ent_std": 8.59766674041748, "report/rep_loss_mean": 2.500607967376709, "report/rep_loss_std": 7.005074501037598, "report/reward_avg": 0.01728515699505806, "report/reward_loss_mean": 0.027545245364308357, "report/reward_loss_std": 0.1268204301595688, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0027639865875244, "report/reward_neg_acc": 0.9930209517478943, "report/reward_neg_loss": 0.013999713584780693, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6745055913925171, "report/reward_pred": 0.01732385717332363, "report/reward_rate": 0.0205078125, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.0009748230222612619, "eval/cont_loss_std": 0.030806144699454308, "eval/cont_neg_acc": 0.5, "eval/cont_neg_loss": 0.4954317808151245, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 7.196821115940111e-06, "eval/cont_pred": 0.9986565113067627, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 24.315349578857422, "eval/dyn_loss_std": 12.409626007080078, "eval/image_loss_mean": 68.33561706542969, "eval/image_loss_std": 78.64041137695312, "eval/model_loss_mean": 83.16217803955078, "eval/model_loss_std": 82.37705993652344, "eval/post_ent_mag": 37.56627655029297, "eval/post_ent_max": 37.56627655029297, "eval/post_ent_mean": 25.47901153564453, "eval/post_ent_min": 14.59152603149414, "eval/post_ent_std": 3.742318868637085, "eval/prior_ent_mag": 74.25100708007812, "eval/prior_ent_max": 74.25100708007812, "eval/prior_ent_mean": 33.20077896118164, "eval/prior_ent_min": 14.589818954467773, "eval/prior_ent_std": 8.856998443603516, "eval/rep_loss_mean": 24.315349578857422, "eval/rep_loss_std": 12.409626007080078, "eval/reward_avg": 0.01748046837747097, "eval/reward_loss_mean": 0.236372709274292, "eval/reward_loss_std": 1.392913579940796, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.0000419616699219, "eval/reward_neg_acc": 0.9990019798278809, "eval/reward_neg_loss": 0.09977579116821289, "eval/reward_pos_acc": 0.3636363744735718, "eval/reward_pos_loss": 6.457741737365723, "eval/reward_pred": 0.004222992807626724, "eval/reward_rate": 0.021484375, "replay/size": 39906.0, "replay/inserts": 2095.0, "replay/samples": 33520.0, "replay/insert_wait_avg": 2.6980561686586366e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.767381417722861e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 9968.0, "eval_replay/inserts": 1816.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1147644026163915e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0918781757355, "timer/env.step_count": 262.0, "timer/env.step_total": 26.791486263275146, "timer/env.step_frac": 0.026789024936534244, "timer/env.step_avg": 0.10225758115753873, "timer/env.step_min": 0.023481130599975586, "timer/env.step_max": 3.3255324363708496, "timer/replay._sample_count": 33520.0, "timer/replay._sample_total": 17.047229766845703, "timer/replay._sample_frac": 0.01704566364236604, "timer/replay._sample_avg": 0.0005085689071254684, "timer/replay._sample_min": 0.0003647804260253906, "timer/replay._sample_max": 0.03286480903625488, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 489.0, "timer/agent.policy_total": 7.713728904724121, "timer/agent.policy_frac": 0.007713020246494462, "timer/agent.policy_avg": 0.01577449673767714, "timer/agent.policy_min": 0.009261608123779297, "timer/agent.policy_max": 0.04931211471557617, "timer/dataset_train_count": 2095.0, "timer/dataset_train_total": 0.3633584976196289, "timer/dataset_train_frac": 0.00036332511597077466, "timer/dataset_train_avg": 0.00017344081031963194, "timer/dataset_train_min": 8.893013000488281e-05, "timer/dataset_train_max": 0.00045371055603027344, "timer/agent.train_count": 2095.0, "timer/agent.train_total": 934.681657075882, "timer/agent.train_frac": 0.9345957881198195, "timer/agent.train_avg": 0.44614876232739, "timer/agent.train_min": 0.4371016025543213, "timer/agent.train_max": 0.5755610466003418, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47104787826538086, "timer/agent.report_frac": 0.00047100460322167386, "timer/agent.report_avg": 0.23552393913269043, "timer/agent.report_min": 0.22789239883422852, "timer/agent.report_max": 0.24315547943115234, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 6.937980651855469e-05, "timer/dataset_eval_frac": 6.93734326141216e-08, "timer/dataset_eval_avg": 6.937980651855469e-05, "timer/dataset_eval_min": 6.937980651855469e-05, "timer/dataset_eval_max": 6.937980651855469e-05, "fps": 2.094782066059797}
{"step": 40920, "time": 18539.304587841034, "episode/length": 142.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 41104, "time": 18624.58470749855, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 41384, "time": 18752.908139944077, "episode/length": 222.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 41432, "time": 18776.039270877838, "episode/length": 171.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 41616, "time": 18861.179792642593, "episode/length": 171.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 41648, "time": 18877.150359153748, "episode/length": 155.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 42120, "time": 19092.3624958992, "episode/length": 307.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.987012987012987, "episode/intrinsic_return": 0.0}
{"step": 42392, "time": 19216.62202310562, "episode/length": 183.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 42424, "time": 19232.656940937042, "episode/length": 410.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9781021897810219, "episode/intrinsic_return": 0.0}
{"step": 42588, "time": 19308.738712072372, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.129569198678715, "train/action_min": 0.0, "train/action_std": 4.492234587120021, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0352887193401975, "train/actor_opt_grad_steps": 39940.0, "train/actor_opt_loss": -18.55494461605145, "train/adv_mag": 0.6245181457512939, "train/adv_max": 0.566632741881955, "train/adv_mean": -0.0001398807928738107, "train/adv_min": -0.4828019555537931, "train/adv_std": 0.044575756029461934, "train/cont_avg": 0.9943341373847926, "train/cont_loss_mean": 0.00010683598040412292, "train/cont_loss_std": 0.003156232980440369, "train/cont_neg_acc": 0.9969278038372092, "train/cont_neg_loss": 0.012639518198521153, "train/cont_pos_acc": 0.9999954392833095, "train/cont_pos_loss": 2.0018999739534925e-05, "train/cont_pred": 0.9943411259607235, "train/cont_rate": 0.9943341373847926, "train/dyn_loss_mean": 2.8509745015526695, "train/dyn_loss_std": 7.696584207121678, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.3268616946611536, "train/extr_critic_critic_opt_grad_steps": 39940.0, "train/extr_critic_critic_opt_loss": 14648.582665790611, "train/extr_critic_mag": 19.15550743929252, "train/extr_critic_max": 19.15550743929252, "train/extr_critic_mean": 4.8030105505121465, "train/extr_critic_min": -0.5771346103211152, "train/extr_critic_std": 3.6416425957657776, "train/extr_return_normed_mag": 1.5794717364596882, "train/extr_return_normed_max": 1.5794717364596882, "train/extr_return_normed_mean": 0.38946748507737017, "train/extr_return_normed_min": -0.09909562974275532, "train/extr_return_normed_std": 0.3043276076355288, "train/extr_return_rate": 0.9006405876528832, "train/extr_return_raw_mag": 19.240982947811002, "train/extr_return_raw_max": 19.240982947811002, "train/extr_return_raw_mean": 4.801148264089488, "train/extr_return_raw_min": -1.119320438960181, "train/extr_return_raw_std": 3.6873614601275886, "train/extr_reward_mag": 1.0216553760563722, "train/extr_reward_max": 1.0216553760563722, "train/extr_reward_mean": 0.0263480321946232, "train/extr_reward_min": -0.6882517112564931, "train/extr_reward_std": 0.16165750181894697, "train/image_loss_mean": 1.9242730418108576, "train/image_loss_std": 5.043453950486425, "train/model_loss_mean": 3.6700639669796287, "train/model_loss_std": 8.736297959006876, "train/model_opt_grad_norm": 39.31824882418611, "train/model_opt_grad_steps": 39903.60829493088, "train/model_opt_loss": 4887.793669388591, "train/model_opt_model_opt_grad_overflow": 0.009216589861751152, "train/model_opt_model_opt_grad_scale": 1360.8870967741937, "train/policy_entropy_mag": 2.2625634054983816, "train/policy_entropy_max": 2.2625634054983816, "train/policy_entropy_mean": 0.4794013697980186, "train/policy_entropy_min": 0.0793750140867475, "train/policy_entropy_std": 0.4836676745645462, "train/policy_logprob_mag": 7.43838369132187, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.4797959701256818, "train/policy_logprob_min": -7.43838369132187, "train/policy_logprob_std": 1.045363065284518, "train/policy_randomness_mag": 0.7985855934257331, "train/policy_randomness_max": 0.7985855934257331, "train/policy_randomness_mean": 0.16920764497073565, "train/policy_randomness_min": 0.02801589679814154, "train/policy_randomness_std": 0.17071346437326773, "train/post_ent_mag": 34.987561124810426, "train/post_ent_max": 34.987561124810426, "train/post_ent_mean": 19.670570830595658, "train/post_ent_min": 10.889560956559423, "train/post_ent_std": 3.6850871622287733, "train/prior_ent_mag": 74.11556795884937, "train/prior_ent_max": 74.11556795884937, "train/prior_ent_mean": 22.55459323127149, "train/prior_ent_min": 11.997420319763746, "train/prior_ent_std": 8.925027152909662, "train/rep_loss_mean": 2.8509745015526695, "train/rep_loss_std": 7.696584207121678, "train/reward_avg": 0.01850653425168057, "train/reward_loss_mean": 0.03509939615593253, "train/reward_loss_std": 0.1681108893955358, "train/reward_max_data": 1.0119815696769046, "train/reward_max_pred": 1.0129001997582923, "train/reward_neg_acc": 0.9968022110824761, "train/reward_neg_loss": 0.018490878365127035, "train/reward_pos_acc": 0.989710015085985, "train/reward_pos_loss": 0.7248955410197034, "train/reward_pred": 0.018399285766283212, "train/reward_rate": 0.023586009504608294, "train_stats/sum_log_reward": 4.211111108462016, "train_stats/max_log_achievement_collect_drink": 5.777777777777778, "train_stats/max_log_achievement_collect_sapling": 2.0, "train_stats/max_log_achievement_collect_wood": 3.111111111111111, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.1111111111111111, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 2.0, "train_stats/max_log_achievement_place_table": 1.3333333333333333, "train_stats/max_log_achievement_wake_up": 2.0, "train_stats/mean_log_entropy": 0.5133615401056077, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 1.8535112076278892e-06, "report/cont_loss_std": 1.983890342671657e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 7.282934348040726e-06, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 1.816140297705715e-06, "report/cont_pred": 0.9931622743606567, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 2.7358264923095703, "report/dyn_loss_std": 7.582693099975586, "report/image_loss_mean": 1.2874213457107544, "report/image_loss_std": 4.364667892456055, "report/model_loss_mean": 2.9632749557495117, "report/model_loss_std": 8.018948554992676, "report/post_ent_mag": 36.127052307128906, "report/post_ent_max": 36.127052307128906, "report/post_ent_mean": 19.847536087036133, "report/post_ent_min": 11.348442077636719, "report/post_ent_std": 3.8487393856048584, "report/prior_ent_mag": 74.19253540039062, "report/prior_ent_max": 74.19253540039062, "report/prior_ent_mean": 22.80461883544922, "report/prior_ent_min": 12.912619590759277, "report/prior_ent_std": 9.0608491897583, "report/rep_loss_mean": 2.7358264923095703, "report/rep_loss_std": 7.582693099975586, "report/reward_avg": 0.017578125, "report/reward_loss_mean": 0.034355971962213516, "report/reward_loss_std": 0.13877227902412415, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0030148029327393, "report/reward_neg_acc": 0.999000072479248, "report/reward_neg_loss": 0.01901063323020935, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6737452745437622, "report/reward_pred": 0.017777111381292343, "report/reward_rate": 0.0234375, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.002490274840965867, "eval/cont_loss_std": 0.07200108468532562, "eval/cont_neg_acc": 0.75, "eval/cont_neg_loss": 0.6312465071678162, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 2.4563856641179882e-05, "eval/cont_pred": 0.9971494078636169, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 26.03411293029785, "eval/dyn_loss_std": 13.020646095275879, "eval/image_loss_mean": 73.7520751953125, "eval/image_loss_std": 86.93455505371094, "eval/model_loss_mean": 89.67355346679688, "eval/model_loss_std": 90.65478515625, "eval/post_ent_mag": 39.08298873901367, "eval/post_ent_max": 39.08298873901367, "eval/post_ent_mean": 26.103164672851562, "eval/post_ent_min": 13.1998872756958, "eval/post_ent_std": 4.124629497528076, "eval/prior_ent_mag": 74.19253540039062, "eval/prior_ent_max": 74.19253540039062, "eval/prior_ent_mean": 33.81219482421875, "eval/prior_ent_min": 12.79390811920166, "eval/prior_ent_std": 8.985045433044434, "eval/rep_loss_mean": 26.03411293029785, "eval/rep_loss_std": 13.020646095275879, "eval/reward_avg": 0.02109374850988388, "eval/reward_loss_mean": 0.29852479696273804, "eval/reward_loss_std": 1.6070853471755981, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0042140483856201, "eval/reward_neg_acc": 0.9989979863166809, "eval/reward_neg_loss": 0.16587086021900177, "eval/reward_pos_acc": 0.42307692766189575, "eval/reward_pos_loss": 5.3903961181640625, "eval/reward_pred": 0.00814744457602501, "eval/reward_rate": 0.025390625, "replay/size": 42084.0, "replay/inserts": 2178.0, "replay/samples": 34848.0, "replay/insert_wait_avg": 2.7054706990335708e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.841787390800875e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 9968.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 8.940696716308594e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2623882293701, "timer/env.step_count": 272.0, "timer/env.step_total": 20.914970874786377, "timer/env.step_frac": 0.02090948447217868, "timer/env.step_avg": 0.07689327527494992, "timer/env.step_min": 0.02408599853515625, "timer/env.step_max": 1.614758014678955, "timer/replay._sample_count": 34848.0, "timer/replay._sample_total": 17.89362406730652, "timer/replay._sample_frac": 0.01788893022258009, "timer/replay._sample_avg": 0.0005134763563850585, "timer/replay._sample_min": 0.0003590583801269531, "timer/replay._sample_max": 0.01106119155883789, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 272.0, "timer/agent.policy_total": 4.456388473510742, "timer/agent.policy_frac": 0.004455219476360885, "timer/agent.policy_avg": 0.016383781152613023, "timer/agent.policy_min": 0.010326623916625977, "timer/agent.policy_max": 0.034264564514160156, "timer/dataset_train_count": 2178.0, "timer/dataset_train_total": 0.4198007583618164, "timer/dataset_train_frac": 0.0004196906364788275, "timer/dataset_train_avg": 0.00019274598639201855, "timer/dataset_train_min": 8.940696716308594e-05, "timer/dataset_train_max": 0.03789806365966797, "timer/agent.train_count": 2178.0, "timer/agent.train_total": 972.4034562110901, "timer/agent.train_frac": 0.9721483759200474, "timer/agent.train_avg": 0.4464662333384252, "timer/agent.train_min": 0.4330153465270996, "timer/agent.train_max": 0.5662882328033447, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4780452251434326, "timer/agent.report_frac": 0.0004779198246068731, "timer/agent.report_avg": 0.2390226125717163, "timer/agent.report_min": 0.2310781478881836, "timer/agent.report_max": 0.24696707725524902, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 4.553794860839844e-05, "timer/dataset_eval_frac": 4.5526003121049205e-08, "timer/dataset_eval_avg": 4.553794860839844e-05, "timer/dataset_eval_min": 4.553794860839844e-05, "timer/dataset_eval_max": 4.553794860839844e-05, "fps": 2.177398345484429}
{"step": 42752, "time": 19383.21825313568, "episode/length": 205.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 42768, "time": 19391.850229501724, "episode/length": 166.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 42768, "time": 19391.861561775208, "episode/length": 172.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 42896, "time": 19452.937215566635, "episode/length": 159.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 43320, "time": 19645.930643320084, "episode/length": 208.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 43696, "time": 19818.053995847702, "episode/length": 158.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 43704, "time": 19823.09449338913, "episode/length": 47.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 43760, "time": 19849.745287895203, "episode/length": 204.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 43896, "time": 19912.304832458496, "episode/length": 187.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 44136, "time": 20021.90293622017, "episode/length": 170.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 44288, "time": 20091.713397026062, "episode/length": 173.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 44448, "time": 20165.21738100052, "episode/length": 209.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 44764, "time": 20309.03054332733, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.9154836672161695, "train/action_min": 0.0, "train/action_std": 4.503694347285349, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03713443700155807, "train/actor_opt_grad_steps": 42115.0, "train/actor_opt_loss": -9.32708022575142, "train/adv_mag": 0.5773826173139275, "train/adv_max": 0.5170360229430943, "train/adv_mean": 0.0014679925371062356, "train/adv_min": -0.4817208167883234, "train/adv_std": 0.04634586718241009, "train/cont_avg": 0.9942481364678899, "train/cont_loss_mean": 1.3634209081581694e-05, "train/cont_loss_std": 0.0003068758100534311, "train/cont_neg_acc": 1.0, "train/cont_neg_loss": 0.0006607260252516584, "train/cont_pos_acc": 0.9999999811343097, "train/cont_pos_loss": 8.656809260771396e-06, "train/cont_pred": 0.9942442017410873, "train/cont_rate": 0.9942481364678899, "train/dyn_loss_mean": 2.8202296954776167, "train/dyn_loss_std": 7.753873151376707, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.2661555652771521, "train/extr_critic_critic_opt_grad_steps": 42115.0, "train/extr_critic_critic_opt_loss": 14670.194636073682, "train/extr_critic_mag": 15.595707197801783, "train/extr_critic_max": 15.595707197801783, "train/extr_critic_mean": 4.180250567033751, "train/extr_critic_min": -0.6420774804342777, "train/extr_critic_std": 3.214736984410417, "train/extr_return_normed_mag": 1.4740720131528486, "train/extr_return_normed_max": 1.4740720131528486, "train/extr_return_normed_mean": 0.3888554830069936, "train/extr_return_normed_min": -0.11103474475238301, "train/extr_return_normed_std": 0.2983721367536335, "train/extr_return_rate": 0.8990464784683437, "train/extr_return_raw_mag": 15.990026294638257, "train/extr_return_raw_max": 15.990026294638257, "train/extr_return_raw_mean": 4.195911023594918, "train/extr_return_raw_min": -1.2191538648047577, "train/extr_return_raw_std": 3.243647584674555, "train/extr_reward_mag": 1.01752827583103, "train/extr_reward_max": 1.01752827583103, "train/extr_reward_mean": 0.027608624411695593, "train/extr_reward_min": -0.6818603993555822, "train/extr_reward_std": 0.16538439797015364, "train/image_loss_mean": 1.9434459450048045, "train/image_loss_std": 5.186152912061149, "train/model_loss_mean": 3.6712079824657615, "train/model_loss_std": 8.908337140302045, "train/model_opt_grad_norm": 33.54504756752504, "train/model_opt_grad_steps": 42076.0, "train/model_opt_loss": 2332.640197193951, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 636.4678899082569, "train/policy_entropy_mag": 2.3322134127310656, "train/policy_entropy_max": 2.3322134127310656, "train/policy_entropy_mean": 0.5317105305030805, "train/policy_entropy_min": 0.07937501504197034, "train/policy_entropy_std": 0.518194399158889, "train/policy_logprob_mag": 7.438383686433145, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5325368687920614, "train/policy_logprob_min": -7.438383686433145, "train/policy_logprob_std": 1.0783468741889393, "train/policy_randomness_mag": 0.8231689878013155, "train/policy_randomness_max": 0.8231689878013155, "train/policy_randomness_mean": 0.1876704828181398, "train/policy_randomness_min": 0.028015897122271562, "train/policy_randomness_std": 0.1828998834441561, "train/post_ent_mag": 36.2199942212586, "train/post_ent_max": 36.2199942212586, "train/post_ent_mean": 19.805587156103293, "train/post_ent_min": 11.072475625834334, "train/post_ent_std": 3.7892035027162745, "train/prior_ent_mag": 74.28934629247823, "train/prior_ent_max": 74.28934629247823, "train/prior_ent_mean": 22.767823770505572, "train/prior_ent_min": 12.358147013078042, "train/prior_ent_std": 8.983713600613655, "train/rep_loss_mean": 2.8202296954776167, "train/rep_loss_std": 7.753873151376707, "train/reward_avg": 0.0184852528736132, "train/reward_loss_mean": 0.035610588139281904, "train/reward_loss_std": 0.16634301619108663, "train/reward_max_data": 1.010091745525325, "train/reward_max_pred": 1.010901890763449, "train/reward_neg_acc": 0.9962650797235857, "train/reward_neg_loss": 0.018963256434306776, "train/reward_pos_acc": 0.9899303144818052, "train/reward_pos_loss": 0.7225077346377416, "train/reward_pred": 0.018349779088374808, "train/reward_rate": 0.02370179902522936, "train_stats/sum_log_reward": 3.5166665812333426, "train_stats/max_log_achievement_collect_drink": 3.5, "train_stats/max_log_achievement_collect_sapling": 2.8333333333333335, "train_stats/max_log_achievement_collect_wood": 1.5833333333333333, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 2.75, "train_stats/max_log_achievement_place_table": 0.6666666666666666, "train_stats/max_log_achievement_wake_up": 1.25, "train_stats/mean_log_entropy": 0.5035060544808706, "report/cont_avg": 0.9990234375, "report/cont_loss_mean": 1.0808075785462279e-06, "report/cont_loss_std": 2.3127372514863964e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.7741512010616134e-06, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.0801297776197316e-06, "report/cont_pred": 0.999022364616394, "report/cont_rate": 0.9990234375, "report/dyn_loss_mean": 2.360198974609375, "report/dyn_loss_std": 7.377420425415039, "report/image_loss_mean": 2.1743218898773193, "report/image_loss_std": 6.474989891052246, "report/model_loss_mean": 3.6075165271759033, "report/model_loss_std": 9.866608619689941, "report/post_ent_mag": 37.234649658203125, "report/post_ent_max": 37.234649658203125, "report/post_ent_mean": 19.239063262939453, "report/post_ent_min": 10.724674224853516, "report/post_ent_std": 3.6636743545532227, "report/prior_ent_mag": 73.96174621582031, "report/prior_ent_max": 73.96174621582031, "report/prior_ent_mean": 21.790264129638672, "report/prior_ent_min": 12.013193130493164, "report/prior_ent_std": 8.105360984802246, "report/rep_loss_mean": 2.360198974609375, "report/rep_loss_std": 7.377420425415039, "report/reward_avg": 0.00810546800494194, "report/reward_loss_mean": 0.017074164003133774, "report/reward_loss_std": 0.0987454354763031, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0012290477752686, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00990002229809761, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6777474880218506, "report/reward_pred": 0.008070042356848717, "report/reward_rate": 0.0107421875, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.0028824189212173223, "eval/cont_loss_std": 0.0920339971780777, "eval/cont_neg_acc": 0.800000011920929, "eval/cont_neg_loss": 0.5900294780731201, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.422513719262497e-06, "eval/cont_pred": 0.9960446357727051, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 26.00916862487793, "eval/dyn_loss_std": 13.139159202575684, "eval/image_loss_mean": 83.69046020507812, "eval/image_loss_std": 91.97420501708984, "eval/model_loss_mean": 99.51995849609375, "eval/model_loss_std": 95.84046173095703, "eval/post_ent_mag": 37.234649658203125, "eval/post_ent_max": 37.234649658203125, "eval/post_ent_mean": 26.47185707092285, "eval/post_ent_min": 15.175390243530273, "eval/post_ent_std": 3.8313868045806885, "eval/prior_ent_mag": 73.96174621582031, "eval/prior_ent_max": 73.96174621582031, "eval/prior_ent_mean": 34.359344482421875, "eval/prior_ent_min": 13.773231506347656, "eval/prior_ent_std": 9.090469360351562, "eval/rep_loss_mean": 26.00916862487793, "eval/rep_loss_std": 13.139159202575684, "eval/reward_avg": 0.01826171949505806, "eval/reward_loss_mean": 0.2211264669895172, "eval/reward_loss_std": 1.3580044507980347, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0000543594360352, "eval/reward_neg_acc": 0.9990009665489197, "eval/reward_neg_loss": 0.11338604986667633, "eval/reward_pos_acc": 0.47826087474823, "eval/reward_pos_loss": 4.910176753997803, "eval/reward_pred": 0.007706860546022654, "eval/reward_rate": 0.0224609375, "replay/size": 44260.0, "replay/inserts": 2176.0, "replay/samples": 34816.0, "replay/insert_wait_avg": 2.6279731708414416e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.835641393766684e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 9968.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 7.599592208862305e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2780511379242, "timer/env.step_count": 272.0, "timer/env.step_total": 25.82310390472412, "timer/env.step_frac": 0.02581592575719077, "timer/env.step_avg": 0.0949378820026622, "timer/env.step_min": 0.023291349411010742, "timer/env.step_max": 3.147467613220215, "timer/replay._sample_count": 34816.0, "timer/replay._sample_total": 17.592881679534912, "timer/replay._sample_frac": 0.017587991318534994, "timer/replay._sample_avg": 0.0005053102504462004, "timer/replay._sample_min": 0.00037169456481933594, "timer/replay._sample_max": 0.03683829307556152, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 272.0, "timer/agent.policy_total": 4.392363548278809, "timer/agent.policy_frac": 0.00439114258608596, "timer/agent.policy_avg": 0.016148395398083853, "timer/agent.policy_min": 0.009829521179199219, "timer/agent.policy_max": 0.04263615608215332, "timer/dataset_train_count": 2176.0, "timer/dataset_train_total": 0.3798961639404297, "timer/dataset_train_frac": 0.00037979056274228633, "timer/dataset_train_avg": 0.00017458463416380042, "timer/dataset_train_min": 9.012222290039062e-05, "timer/dataset_train_max": 0.00072479248046875, "timer/agent.train_count": 2176.0, "timer/agent.train_total": 967.8448722362518, "timer/agent.train_frac": 0.9675758366738367, "timer/agent.train_avg": 0.44478165084386573, "timer/agent.train_min": 0.43517208099365234, "timer/agent.train_max": 0.5746650695800781, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47148752212524414, "timer/agent.report_frac": 0.00047135646092491605, "timer/agent.report_avg": 0.23574376106262207, "timer/agent.report_min": 0.22904396057128906, "timer/agent.report_max": 0.24244356155395508, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.765655517578125e-05, "timer/dataset_eval_frac": 2.7648867376744832e-08, "timer/dataset_eval_avg": 2.765655517578125e-05, "timer/dataset_eval_min": 2.765655517578125e-05, "timer/dataset_eval_max": 2.765655517578125e-05, "fps": 2.1753676253887546}
{"step": 45000, "time": 20415.41457915306, "episode/length": 161.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 45072, "time": 20449.215302705765, "episode/length": 163.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9817073170731707, "episode/intrinsic_return": 0.0}
{"step": 45560, "time": 20670.867968797684, "episode/length": 232.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9828326180257511, "episode/intrinsic_return": 0.0}
{"step": 45672, "time": 20722.58292412758, "episode/length": 221.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 45816, "time": 20788.930507183075, "episode/length": 209.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.0}
{"step": 45952, "time": 20851.527777910233, "episode/length": 207.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9567307692307693, "episode/intrinsic_return": 0.0}
{"step": 46112, "time": 20924.861541748047, "episode/length": 207.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 46208, "time": 20969.798467874527, "episode/length": 431.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 46480, "time": 21093.887701511383, "episode/length": 175.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 46680, "time": 21185.282825231552, "episode/length": 209.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 46952, "time": 21309.202756643295, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.693864099511273, "train/action_min": 0.0, "train/action_std": 4.344192172838673, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.039129971598857616, "train/actor_opt_grad_steps": 44300.0, "train/actor_opt_loss": -8.777482715363032, "train/adv_mag": 0.6668367549164654, "train/adv_max": 0.6200758507262626, "train/adv_mean": 0.002100821327744743, "train/adv_min": -0.5119824133915444, "train/adv_std": 0.048147539654959284, "train/cont_avg": 0.994345747716895, "train/cont_loss_mean": 0.00010440398075384115, "train/cont_loss_std": 0.0031089851113134536, "train/cont_neg_acc": 0.9977616860020545, "train/cont_neg_loss": 0.011672753475362454, "train/cont_pos_acc": 0.9999910149400093, "train/cont_pos_loss": 4.068839444861916e-05, "train/cont_pred": 0.9943459651785899, "train/cont_rate": 0.994345747716895, "train/dyn_loss_mean": 2.8212194671369577, "train/dyn_loss_std": 7.758010816356363, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.2936900364209527, "train/extr_critic_critic_opt_grad_steps": 44300.0, "train/extr_critic_critic_opt_loss": 14231.48614975742, "train/extr_critic_mag": 15.341729264281112, "train/extr_critic_max": 15.341729264281112, "train/extr_critic_mean": 4.140996642308693, "train/extr_critic_min": -0.5884195522630595, "train/extr_critic_std": 2.8335304673948243, "train/extr_return_normed_mag": 1.5963595310846965, "train/extr_return_normed_max": 1.5963595310846965, "train/extr_return_normed_mean": 0.4175167487908716, "train/extr_return_normed_min": -0.11790332329123532, "train/extr_return_normed_std": 0.2984782567579452, "train/extr_return_rate": 0.9049880964570938, "train/extr_return_raw_mag": 15.548442187374585, "train/extr_return_raw_max": 15.548442187374585, "train/extr_return_raw_mean": 4.161138498619811, "train/extr_return_raw_min": -0.996444286957179, "train/extr_return_raw_std": 2.878764834033844, "train/extr_reward_mag": 1.023930028148982, "train/extr_reward_max": 1.023930028148982, "train/extr_reward_mean": 0.027111811291205285, "train/extr_reward_min": -0.6782064214689002, "train/extr_reward_std": 0.1632536415980287, "train/image_loss_mean": 1.8898076526650556, "train/image_loss_std": 5.053944845722146, "train/model_loss_mean": 3.617830377735504, "train/model_loss_std": 8.767526763759248, "train/model_opt_grad_norm": 36.60019330238099, "train/model_opt_grad_steps": 44260.24657534246, "train/model_opt_loss": 5354.885495817281, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1484.0182648401826, "train/policy_entropy_mag": 2.342963774998983, "train/policy_entropy_max": 2.342963774998983, "train/policy_entropy_mean": 0.5045669698007574, "train/policy_entropy_min": 0.07937501544413501, "train/policy_entropy_std": 0.5009982742403196, "train/policy_logprob_mag": 7.438383696830436, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.504391986757653, "train/policy_logprob_min": -7.438383696830436, "train/policy_logprob_std": 1.0630356253009954, "train/policy_randomness_mag": 0.8269633941998765, "train/policy_randomness_max": 0.8269633941998765, "train/policy_randomness_mean": 0.17808999835628353, "train/policy_randomness_min": 0.028015897256326458, "train/policy_randomness_std": 0.17683040619440818, "train/post_ent_mag": 35.99486642776559, "train/post_ent_max": 35.99486642776559, "train/post_ent_mean": 19.736094487856512, "train/post_ent_min": 11.174557367960611, "train/post_ent_std": 3.7176223116922595, "train/prior_ent_mag": 74.49048179034229, "train/prior_ent_max": 74.49048179034229, "train/prior_ent_mean": 22.63540571029872, "train/prior_ent_min": 12.3952525151919, "train/prior_ent_std": 8.972497347827371, "train/rep_loss_mean": 2.8212194671369577, "train/rep_loss_std": 7.758010816356363, "train/reward_avg": 0.01821445118312694, "train/reward_loss_mean": 0.035186645451541904, "train/reward_loss_std": 0.1668593769884545, "train/reward_max_data": 1.0114155278358286, "train/reward_max_pred": 1.0125802249124605, "train/reward_neg_acc": 0.9966504217282822, "train/reward_neg_loss": 0.018621288384544795, "train/reward_pos_acc": 0.9892316036028405, "train/reward_pos_loss": 0.7276938179312231, "train/reward_pred": 0.018072850340934785, "train/reward_rate": 0.023357234589041095, "train_stats/sum_log_reward": 3.7999999046325685, "train_stats/max_log_achievement_collect_drink": 3.7, "train_stats/max_log_achievement_collect_sapling": 1.7, "train_stats/max_log_achievement_collect_wood": 1.1, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.1, "train_stats/max_log_achievement_make_wood_pickaxe": 0.2, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.7, "train_stats/max_log_achievement_place_table": 0.2, "train_stats/max_log_achievement_wake_up": 2.9, "train_stats/mean_log_entropy": 0.5278299659490585, "train_stats/max_log_achievement_collect_stone": 0.2857142857142857, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 2.7224789391766535e-06, "report/cont_loss_std": 5.133752347319387e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 6.7930059231002815e-06, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.7025057534046937e-06, "report/cont_pred": 0.9951145648956299, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 2.6086387634277344, "report/dyn_loss_std": 7.775271415710449, "report/image_loss_mean": 1.7744156122207642, "report/image_loss_std": 4.6678996086120605, "report/model_loss_mean": 3.3726646900177, "report/model_loss_std": 8.342180252075195, "report/post_ent_mag": 37.68903350830078, "report/post_ent_max": 37.68903350830078, "report/post_ent_mean": 19.641931533813477, "report/post_ent_min": 12.791666030883789, "report/post_ent_std": 3.3900134563446045, "report/prior_ent_mag": 73.97389221191406, "report/prior_ent_max": 73.97389221191406, "report/prior_ent_mean": 22.315410614013672, "report/prior_ent_min": 13.606404304504395, "report/prior_ent_std": 8.49372386932373, "report/rep_loss_mean": 2.6086387634277344, "report/rep_loss_std": 7.775271415710449, "report/reward_avg": 0.02011718787252903, "report/reward_loss_mean": 0.033063165843486786, "report/reward_loss_std": 0.1491548866033554, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0036039352416992, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.016144555062055588, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6824775338172913, "report/reward_pred": 0.020199621096253395, "report/reward_rate": 0.025390625, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 8.907147275749594e-05, "eval/cont_loss_std": 0.0027677302714437246, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.017788691446185112, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.223479214080726e-06, "eval/cont_pred": 0.995198130607605, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 25.15277862548828, "eval/dyn_loss_std": 13.369671821594238, "eval/image_loss_mean": 46.57745361328125, "eval/image_loss_std": 55.1024169921875, "eval/model_loss_mean": 61.85637283325195, "eval/model_loss_std": 59.497318267822266, "eval/post_ent_mag": 37.68903350830078, "eval/post_ent_max": 37.68903350830078, "eval/post_ent_mean": 25.10036277770996, "eval/post_ent_min": 15.611278533935547, "eval/post_ent_std": 4.052530288696289, "eval/prior_ent_mag": 73.97389221191406, "eval/prior_ent_max": 73.97389221191406, "eval/prior_ent_mean": 33.656028747558594, "eval/prior_ent_min": 13.361417770385742, "eval/prior_ent_std": 9.948275566101074, "eval/rep_loss_mean": 25.15277862548828, "eval/rep_loss_std": 13.369671821594238, "eval/reward_avg": 0.01406249962747097, "eval/reward_loss_mean": 0.18716347217559814, "eval/reward_loss_std": 1.2127686738967896, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0005970001220703, "eval/reward_neg_acc": 0.998009979724884, "eval/reward_neg_loss": 0.11917249858379364, "eval/reward_pos_acc": 0.5789473652839661, "eval/reward_pos_loss": 3.7835283279418945, "eval/reward_pred": 0.006842479575425386, "eval/reward_rate": 0.0185546875, "replay/size": 46448.0, "replay/inserts": 2188.0, "replay/samples": 35008.0, "replay/insert_wait_avg": 2.6613964241209154e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.559887560891495e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 9968.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 8.046627044677734e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1603174209595, "timer/env.step_count": 273.0, "timer/env.step_total": 22.358787536621094, "timer/env.step_frac": 0.02235520360803363, "timer/env.step_avg": 0.08190032064696372, "timer/env.step_min": 0.023151874542236328, "timer/env.step_max": 1.828258752822876, "timer/replay._sample_count": 35008.0, "timer/replay._sample_total": 17.14811611175537, "timer/replay._sample_frac": 0.01714536741067069, "timer/replay._sample_avg": 0.0004898342125158641, "timer/replay._sample_min": 0.00032711029052734375, "timer/replay._sample_max": 0.009473323822021484, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 273.0, "timer/agent.policy_total": 4.358911752700806, "timer/agent.policy_frac": 0.0043582130552238, "timer/agent.policy_avg": 0.015966709716852767, "timer/agent.policy_min": 0.009680986404418945, "timer/agent.policy_max": 0.01802825927734375, "timer/dataset_train_count": 2188.0, "timer/dataset_train_total": 0.39136409759521484, "timer/dataset_train_frac": 0.00039130136516953294, "timer/dataset_train_avg": 0.00017886841754808722, "timer/dataset_train_min": 9.036064147949219e-05, "timer/dataset_train_max": 0.0007920265197753906, "timer/agent.train_count": 2188.0, "timer/agent.train_total": 971.3286275863647, "timer/agent.train_frac": 0.9711729316466575, "timer/agent.train_avg": 0.4439344733027261, "timer/agent.train_min": 0.43501901626586914, "timer/agent.train_max": 0.5572137832641602, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47309327125549316, "timer/agent.report_frac": 0.0004730174383197129, "timer/agent.report_avg": 0.23654663562774658, "timer/agent.report_min": 0.23030614852905273, "timer/agent.report_max": 0.24278712272644043, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.956390380859375e-05, "timer/dataset_eval_frac": 2.9559164959501727e-08, "timer/dataset_eval_avg": 2.956390380859375e-05, "timer/dataset_eval_min": 2.956390380859375e-05, "timer/dataset_eval_max": 2.956390380859375e-05, "fps": 2.1876215569049435}
{"step": 47064, "time": 21359.741632461548, "episode/length": 173.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 47096, "time": 21375.559760332108, "episode/length": 191.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 47176, "time": 21412.975947380066, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 47232, "time": 21439.58538389206, "episode/length": 159.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 47568, "time": 21593.07727956772, "episode/length": 169.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 47808, "time": 21702.942066431046, "episode/length": 211.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 48040, "time": 21808.66501235962, "episode/length": 169.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 48536, "time": 22032.72350358963, "episode/length": 179.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 48648, "time": 22084.665320396423, "episode/length": 176.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 48856, "time": 22180.076775312424, "episode/length": 209.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.0}
{"step": 49136, "time": 22307.468020677567, "episode/length": 331.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9909638554216867, "episode/intrinsic_return": 0.0}
{"step": 49137, "time": 22310.491347312927, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.641992971437786, "train/action_min": 0.0, "train/action_std": 4.241481885997527, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03837978502376637, "train/actor_opt_grad_steps": 46485.0, "train/actor_opt_loss": -12.156792338083097, "train/adv_mag": 0.7045098267017155, "train/adv_max": 0.6460980757934238, "train/adv_mean": 0.0017141782434652144, "train/adv_min": -0.5433299340512774, "train/adv_std": 0.04740973250137283, "train/cont_avg": 0.9945303540711009, "train/cont_loss_mean": 5.8583155591982133e-05, "train/cont_loss_std": 0.0017819564623491773, "train/cont_neg_acc": 0.9986559141616118, "train/cont_neg_loss": 0.006994056752813575, "train/cont_pos_acc": 0.9999954787963027, "train/cont_pos_loss": 1.4274404738117793e-05, "train/cont_pred": 0.9945333810574418, "train/cont_rate": 0.9945303540711009, "train/dyn_loss_mean": 2.8119187300358344, "train/dyn_loss_std": 7.716023460440679, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.2225655940694546, "train/extr_critic_critic_opt_grad_steps": 46485.0, "train/extr_critic_critic_opt_loss": 14182.234159977064, "train/extr_critic_mag": 16.74111966911806, "train/extr_critic_max": 16.74111966911806, "train/extr_critic_mean": 4.0768767168762485, "train/extr_critic_min": -0.6516180454044167, "train/extr_critic_std": 2.9536953092715064, "train/extr_return_normed_mag": 1.6616873989958283, "train/extr_return_normed_max": 1.6616873989958283, "train/extr_return_normed_mean": 0.408175545958204, "train/extr_return_normed_min": -0.11081189139310373, "train/extr_return_normed_std": 0.29195169571342816, "train/extr_return_rate": 0.8863493731809319, "train/extr_return_raw_mag": 17.015981901676284, "train/extr_return_raw_max": 17.015981901676284, "train/extr_return_raw_mean": 4.094537878255232, "train/extr_return_raw_min": -1.2561133052777806, "train/extr_return_raw_std": 3.010769020526781, "train/extr_reward_mag": 1.0297045292110618, "train/extr_reward_max": 1.0297045292110618, "train/extr_reward_mean": 0.027467376872931326, "train/extr_reward_min": -0.6870483198297133, "train/extr_reward_std": 0.16554282967923978, "train/image_loss_mean": 1.8121958700341916, "train/image_loss_std": 4.869127753677718, "train/model_loss_mean": 3.5340985934668723, "train/model_loss_std": 8.584223427903762, "train/model_opt_grad_norm": 34.92912832312628, "train/model_opt_grad_steps": 46443.70183486238, "train/model_opt_loss": 5890.33571799742, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1668.5779816513761, "train/policy_entropy_mag": 2.3279752687576716, "train/policy_entropy_max": 2.3279752687576716, "train/policy_entropy_mean": 0.5074445918339108, "train/policy_entropy_min": 0.07937501459766966, "train/policy_entropy_std": 0.5048306444916156, "train/policy_logprob_mag": 7.438383703931756, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5080891489435774, "train/policy_logprob_min": -7.438383703931756, "train/policy_logprob_std": 1.064875170998617, "train/policy_randomness_mag": 0.8216731097173253, "train/policy_randomness_max": 0.8216731097173253, "train/policy_randomness_mean": 0.17910567295113836, "train/policy_randomness_min": 0.02801589697701942, "train/policy_randomness_std": 0.17818306509507906, "train/post_ent_mag": 36.299059360399156, "train/post_ent_max": 36.299059360399156, "train/post_ent_mean": 19.821118074819584, "train/post_ent_min": 11.036087049256771, "train/post_ent_std": 3.703699114125803, "train/prior_ent_mag": 74.61886075221071, "train/prior_ent_max": 74.61886075221071, "train/prior_ent_mean": 22.706105800943636, "train/prior_ent_min": 12.303383687220583, "train/prior_ent_std": 8.933750780350572, "train/rep_loss_mean": 2.8119187300358344, "train/rep_loss_std": 7.716023460440679, "train/reward_avg": 0.018326673387558362, "train/reward_loss_mean": 0.03469291415680713, "train/reward_loss_std": 0.16393893762329304, "train/reward_max_data": 1.0133027554652012, "train/reward_max_pred": 1.0148718947664312, "train/reward_neg_acc": 0.9964633406302251, "train/reward_neg_loss": 0.01834530925053522, "train/reward_pos_acc": 0.9908022289976067, "train/reward_pos_loss": 0.7197481795735315, "train/reward_pred": 0.018199692625518238, "train/reward_rate": 0.023325508887614678, "train_stats/sum_log_reward": 4.736363584345037, "train_stats/max_log_achievement_collect_drink": 2.909090909090909, "train_stats/max_log_achievement_collect_sapling": 2.727272727272727, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 2.909090909090909, "train_stats/max_log_achievement_defeat_zombie": 0.18181818181818182, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.09090909090909091, "train_stats/max_log_achievement_make_wood_sword": 0.09090909090909091, "train_stats/max_log_achievement_place_plant": 2.727272727272727, "train_stats/max_log_achievement_place_table": 1.0909090909090908, "train_stats/max_log_achievement_wake_up": 2.3636363636363638, "train_stats/mean_log_entropy": 0.4949179806492545, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 3.997324893134646e-05, "report/cont_loss_std": 0.001204645843245089, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00014694148558191955, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 3.9130976801970974e-05, "report/cont_pred": 0.9921505451202393, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 2.7100934982299805, "report/dyn_loss_std": 7.7976837158203125, "report/image_loss_mean": 1.9176995754241943, "report/image_loss_std": 3.5655946731567383, "report/model_loss_mean": 3.5822176933288574, "report/model_loss_std": 7.327638149261475, "report/post_ent_mag": 36.37223815917969, "report/post_ent_max": 36.37223815917969, "report/post_ent_mean": 19.472309112548828, "report/post_ent_min": 12.519105911254883, "report/post_ent_std": 3.4745047092437744, "report/prior_ent_mag": 75.60360717773438, "report/prior_ent_max": 75.60360717773438, "report/prior_ent_mean": 22.282825469970703, "report/prior_ent_min": 12.35470199584961, "report/prior_ent_std": 9.254495620727539, "report/rep_loss_mean": 2.7100934982299805, "report/rep_loss_std": 7.7976837158203125, "report/reward_avg": 0.01845703087747097, "report/reward_loss_mean": 0.03842208907008171, "report/reward_loss_std": 0.1578839272260666, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0018296241760254, "report/reward_neg_acc": 0.9929859638214111, "report/reward_neg_loss": 0.021848222240805626, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6746037006378174, "report/reward_pred": 0.018422577530145645, "report/reward_rate": 0.025390625, "eval/cont_avg": 0.9921875, "eval/cont_loss_mean": 0.02948351576924324, "eval/cont_loss_std": 0.6660041809082031, "eval/cont_neg_acc": 0.75, "eval/cont_neg_loss": 3.773703098297119, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.4662866760772886e-06, "eval/cont_pred": 0.9943602085113525, "eval/cont_rate": 0.9921875, "eval/dyn_loss_mean": 25.47371482849121, "eval/dyn_loss_std": 14.206785202026367, "eval/image_loss_mean": 48.19325256347656, "eval/image_loss_std": 44.569332122802734, "eval/model_loss_mean": 63.713844299316406, "eval/model_loss_std": 49.936798095703125, "eval/post_ent_mag": 38.46251678466797, "eval/post_ent_max": 38.46251678466797, "eval/post_ent_mean": 25.278900146484375, "eval/post_ent_min": 12.912163734436035, "eval/post_ent_std": 3.6639435291290283, "eval/prior_ent_mag": 75.60360717773438, "eval/prior_ent_max": 75.60360717773438, "eval/prior_ent_mean": 33.025413513183594, "eval/prior_ent_min": 15.773056983947754, "eval/prior_ent_std": 9.664641380310059, "eval/rep_loss_mean": 25.47371482849121, "eval/rep_loss_std": 14.206785202026367, "eval/reward_avg": 0.01845703087747097, "eval/reward_loss_mean": 0.20688244700431824, "eval/reward_loss_std": 1.2069730758666992, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0126559734344482, "eval/reward_neg_acc": 0.9940000176429749, "eval/reward_neg_loss": 0.13921509683132172, "eval/reward_pos_acc": 0.75, "eval/reward_pos_loss": 3.026355743408203, "eval/reward_pred": 0.017190836369991302, "eval/reward_rate": 0.0234375, "replay/size": 48633.0, "replay/inserts": 2185.0, "replay/samples": 34960.0, "replay/insert_wait_avg": 2.653375097488648e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.249125081287096e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 9968.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 7.748603820800781e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1001.2784571647644, "timer/env.step_count": 274.0, "timer/env.step_total": 24.746814250946045, "timer/env.step_frac": 0.024715216904815377, "timer/env.step_avg": 0.09031684033191988, "timer/env.step_min": 0.02341151237487793, "timer/env.step_max": 2.0416789054870605, "timer/replay._sample_count": 34960.0, "timer/replay._sample_total": 17.021209478378296, "timer/replay._sample_frac": 0.016999476376008144, "timer/replay._sample_avg": 0.0004868767013266103, "timer/replay._sample_min": 0.00035071372985839844, "timer/replay._sample_max": 0.02844405174255371, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 274.0, "timer/agent.policy_total": 4.363746643066406, "timer/agent.policy_frac": 0.004358174903136195, "timer/agent.policy_avg": 0.01592608263892849, "timer/agent.policy_min": 0.009911060333251953, "timer/agent.policy_max": 0.02376532554626465, "timer/dataset_train_count": 2185.0, "timer/dataset_train_total": 0.3845865726470947, "timer/dataset_train_frac": 0.00038409552297379495, "timer/dataset_train_avg": 0.00017601216139455136, "timer/dataset_train_min": 8.821487426757812e-05, "timer/dataset_train_max": 0.0009770393371582031, "timer/agent.train_count": 2185.0, "timer/agent.train_total": 970.0744547843933, "timer/agent.train_frac": 0.9688358396636947, "timer/agent.train_avg": 0.4439700021896537, "timer/agent.train_min": 0.43216800689697266, "timer/agent.train_max": 0.6118955612182617, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47384142875671387, "timer/agent.report_frac": 0.00047323641626970646, "timer/agent.report_avg": 0.23692071437835693, "timer/agent.report_min": 0.2307891845703125, "timer/agent.report_max": 0.24305224418640137, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9087066650390625e-05, "timer/dataset_eval_frac": 2.9049927562362636e-08, "timer/dataset_eval_avg": 2.9087066650390625e-05, "timer/dataset_eval_min": 2.9087066650390625e-05, "timer/dataset_eval_max": 2.9087066650390625e-05, "fps": 2.18218264480428}
{"step": 49224, "time": 22350.568741083145, "episode/length": 269.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9851851851851852, "episode/intrinsic_return": 0.0}
{"step": 49288, "time": 22380.725466012955, "episode/length": 155.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 49408, "time": 22436.39560174942, "episode/length": 108.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.963302752293578, "episode/intrinsic_return": 0.0}
{"step": 50024, "time": 22714.32358765602, "episode/length": 306.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.990228013029316, "episode/intrinsic_return": 0.0}
{"step": 50024, "time": 22732.68308711052, "eval_episode/length": 154.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9741935483870968}
{"step": 50024, "time": 22734.58283805847, "eval_episode/length": 161.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9691358024691358}
{"step": 50024, "time": 22736.891436338425, "eval_episode/length": 178.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.994413407821229}
{"step": 50024, "time": 22739.18198633194, "eval_episode/length": 196.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9746192893401016}
{"step": 50024, "time": 22740.98580098152, "eval_episode/length": 204.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.975609756097561}
{"step": 50024, "time": 22742.887130975723, "eval_episode/length": 214.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9767441860465116}
{"step": 50024, "time": 22744.663210630417, "eval_episode/length": 221.0, "eval_episode/score": 5.099999971687794, "eval_episode/reward_rate": 0.9954954954954955}
{"step": 50024, "time": 22747.45290827751, "eval_episode/length": 254.0, "eval_episode/score": 3.0999999791383743, "eval_episode/reward_rate": 0.996078431372549}
{"step": 50176, "time": 22816.926861286163, "episode/length": 164.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 50216, "time": 22836.435087919235, "episode/length": 300.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9966777408637874, "episode/intrinsic_return": 0.0}
{"step": 50304, "time": 22877.49004292488, "episode/length": 206.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 50512, "time": 22972.307505607605, "episode/length": 171.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 50600, "time": 23013.339157819748, "episode/length": 148.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9530201342281879, "episode/intrinsic_return": 0.0}
{"step": 50840, "time": 23122.557942152023, "episode/length": 193.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 50944, "time": 23170.857133865356, "episode/length": 214.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 51251, "time": 23310.71325778961, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.673422759433962, "train/action_min": 0.0, "train/action_std": 4.286594147952098, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.035982688853763184, "train/actor_opt_grad_steps": 48635.0, "train/actor_opt_loss": -8.317638175289655, "train/adv_mag": 0.6700883948437448, "train/adv_max": 0.6162303937774785, "train/adv_mean": 0.0019572334449892296, "train/adv_min": -0.4844821610681291, "train/adv_std": 0.0435800995449272, "train/cont_avg": 0.9944768941627359, "train/cont_loss_mean": 2.3033746686733804e-05, "train/cont_loss_std": 0.0006046072376654661, "train/cont_neg_acc": 0.9992138366654234, "train/cont_neg_loss": 0.0017508033809051238, "train/cont_pos_acc": 0.9999953533680934, "train/cont_pos_loss": 1.3533646182965162e-05, "train/cont_pred": 0.9944730766539304, "train/cont_rate": 0.9944768941627359, "train/dyn_loss_mean": 2.8127903567170196, "train/dyn_loss_std": 7.76416500559393, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.238532984875283, "train/extr_critic_critic_opt_grad_steps": 48635.0, "train/extr_critic_critic_opt_loss": 14289.229040757666, "train/extr_critic_mag": 15.264657434427514, "train/extr_critic_max": 15.264657434427514, "train/extr_critic_mean": 3.8433858144958064, "train/extr_critic_min": -0.6885605420706407, "train/extr_critic_std": 3.0554593143598088, "train/extr_return_normed_mag": 1.509040411069708, "train/extr_return_normed_max": 1.509040411069708, "train/extr_return_normed_mean": 0.38889398158721206, "train/extr_return_normed_min": -0.09398582995921936, "train/extr_return_normed_std": 0.29740259107553735, "train/extr_return_rate": 0.8793549607947188, "train/extr_return_raw_mag": 15.553186074742731, "train/extr_return_raw_max": 15.553186074742731, "train/extr_return_raw_mean": 3.8643913887581736, "train/extr_return_raw_min": -1.1829185213120479, "train/extr_return_raw_std": 3.108407693651487, "train/extr_reward_mag": 1.0189474461213597, "train/extr_reward_max": 1.0189474461213597, "train/extr_reward_mean": 0.02746595799448496, "train/extr_reward_min": -0.6781407358511439, "train/extr_reward_std": 0.16629926681096824, "train/image_loss_mean": 1.8086354597559515, "train/image_loss_std": 4.855885231269981, "train/model_loss_mean": 3.5307627443997367, "train/model_loss_std": 8.590678968519535, "train/model_opt_grad_norm": 34.9834694523382, "train/model_opt_grad_steps": 48592.25471698113, "train/model_opt_loss": 5699.884033203125, "train/model_opt_model_opt_grad_overflow": 0.0047169811320754715, "train/model_opt_model_opt_grad_scale": 1615.566037735849, "train/policy_entropy_mag": 2.362662391842536, "train/policy_entropy_max": 2.362662391842536, "train/policy_entropy_mean": 0.5258250755240332, "train/policy_entropy_min": 0.0793750147282515, "train/policy_entropy_std": 0.5263186258808622, "train/policy_logprob_mag": 7.438383707460368, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5254451742149749, "train/policy_logprob_min": -7.438383707460368, "train/policy_logprob_std": 1.0744168004899655, "train/policy_randomness_mag": 0.8339161403336615, "train/policy_randomness_max": 0.8339161403336615, "train/policy_randomness_mean": 0.18559317698456207, "train/policy_randomness_min": 0.028015897011841245, "train/policy_randomness_std": 0.18576737929065273, "train/post_ent_mag": 37.05737355969987, "train/post_ent_max": 37.05737355969987, "train/post_ent_mean": 19.979382496959758, "train/post_ent_min": 11.227902164999044, "train/post_ent_std": 3.7022947354136773, "train/prior_ent_mag": 74.87462939856188, "train/prior_ent_max": 74.87462939856188, "train/prior_ent_mean": 22.846196957354277, "train/prior_ent_min": 12.36909364754299, "train/prior_ent_std": 8.976259179835049, "train/rep_loss_mean": 2.8127903567170196, "train/rep_loss_std": 7.76416500559393, "train/reward_avg": 0.01814886118408363, "train/reward_loss_mean": 0.034430066518977565, "train/reward_loss_std": 0.16380716635371154, "train/reward_max_data": 1.0084905680620446, "train/reward_max_pred": 1.0094460057762433, "train/reward_neg_acc": 0.9966512665433703, "train/reward_neg_loss": 0.018077382400526473, "train/reward_pos_acc": 0.9903838434871638, "train/reward_pos_loss": 0.7228915213413958, "train/reward_pred": 0.01800124074622356, "train/reward_rate": 0.02317954009433962, "train_stats/sum_log_reward": 3.28181808645075, "train_stats/max_log_achievement_collect_drink": 2.1818181818181817, "train_stats/max_log_achievement_collect_sapling": 1.7272727272727273, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 1.1818181818181819, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.7272727272727273, "train_stats/max_log_achievement_place_table": 0.45454545454545453, "train_stats/max_log_achievement_wake_up": 2.3636363636363638, "train_stats/mean_log_entropy": 0.5820321440696716, "eval_stats/sum_log_reward": 4.099999904632568, "eval_stats/max_log_achievement_collect_drink": 3.125, "eval_stats/max_log_achievement_collect_sapling": 2.125, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 1.375, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.125, "eval_stats/max_log_achievement_place_table": 0.375, "eval_stats/max_log_achievement_wake_up": 2.125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 4.20259596012329e-07, "report/cont_loss_std": 3.7624731703544967e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 5.2340590627864e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.6770229055728123e-07, "report/cont_pred": 0.9970701932907104, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 2.518533706665039, "report/dyn_loss_std": 7.170043468475342, "report/image_loss_mean": 1.4740430116653442, "report/image_loss_std": 5.227347373962402, "report/model_loss_mean": 3.00976824760437, "report/model_loss_std": 8.377541542053223, "report/post_ent_mag": 32.839500427246094, "report/post_ent_max": 32.839500427246094, "report/post_ent_mean": 19.57052230834961, "report/post_ent_min": 10.612100601196289, "report/post_ent_std": 3.295799732208252, "report/prior_ent_mag": 75.14120483398438, "report/prior_ent_max": 75.14120483398438, "report/prior_ent_mean": 22.019386291503906, "report/prior_ent_min": 12.664338111877441, "report/prior_ent_std": 8.382161140441895, "report/rep_loss_mean": 2.518533706665039, "report/rep_loss_std": 7.170043468475342, "report/reward_avg": 0.01689453050494194, "report/reward_loss_mean": 0.024604618549346924, "report/reward_loss_std": 0.11965227872133255, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0000360012054443, "report/reward_neg_acc": 0.999002993106842, "report/reward_neg_loss": 0.011011607944965363, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6738327145576477, "report/reward_pred": 0.017258673906326294, "report/reward_rate": 0.0205078125, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.017778994515538216, "eval/cont_loss_std": 0.5215123891830444, "eval/cont_neg_acc": 0.6000000238418579, "eval/cont_neg_loss": 3.641085386276245, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.58612828929472e-07, "eval/cont_pred": 0.9971021413803101, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 28.139739990234375, "eval/dyn_loss_std": 12.87346076965332, "eval/image_loss_mean": 66.18570709228516, "eval/image_loss_std": 71.291015625, "eval/model_loss_mean": 83.23208618164062, "eval/model_loss_std": 75.73431396484375, "eval/post_ent_mag": 37.81876754760742, "eval/post_ent_max": 37.81876754760742, "eval/post_ent_mean": 26.11235809326172, "eval/post_ent_min": 17.360332489013672, "eval/post_ent_std": 3.5013325214385986, "eval/prior_ent_mag": 75.14120483398438, "eval/prior_ent_max": 75.14120483398438, "eval/prior_ent_mean": 33.97605895996094, "eval/prior_ent_min": 16.044498443603516, "eval/prior_ent_std": 8.833171844482422, "eval/rep_loss_mean": 28.139739990234375, "eval/rep_loss_std": 12.87346076965332, "eval/reward_avg": 0.01386718824505806, "eval/reward_loss_mean": 0.14475780725479126, "eval/reward_loss_std": 1.1774429082870483, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9988561868667603, "eval/reward_neg_acc": 0.998009979724884, "eval/reward_neg_loss": 0.08944102376699448, "eval/reward_pos_acc": 0.6315789222717285, "eval/reward_pos_loss": 3.0707249641418457, "eval/reward_pred": 0.009516801685094833, "eval/reward_rate": 0.0185546875, "replay/size": 50747.0, "replay/inserts": 2114.0, "replay/samples": 33824.0, "replay/insert_wait_avg": 2.577153713836237e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.171730106465639e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 12008.0, "eval_replay/inserts": 2040.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0718317592845243e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.046627044677734e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.206752538681, "timer/env.step_count": 264.0, "timer/env.step_total": 22.987015962600708, "timer/env.step_frac": 0.02298226432110768, "timer/env.step_avg": 0.08707203016136632, "timer/env.step_min": 0.023139476776123047, "timer/env.step_max": 1.6187455654144287, "timer/replay._sample_count": 33824.0, "timer/replay._sample_total": 16.23060154914856, "timer/replay._sample_frac": 0.016227246524733768, "timer/replay._sample_avg": 0.00047985458695448674, "timer/replay._sample_min": 0.0003631114959716797, "timer/replay._sample_max": 0.011124134063720703, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 519.0, "timer/agent.policy_total": 8.07259726524353, "timer/agent.policy_frac": 0.008070928580270045, "timer/agent.policy_avg": 0.015554137312607958, "timer/agent.policy_min": 0.009536504745483398, "timer/agent.policy_max": 0.04286789894104004, "timer/dataset_train_count": 2114.0, "timer/dataset_train_total": 0.3621501922607422, "timer/dataset_train_frac": 0.0003620753322666023, "timer/dataset_train_avg": 0.00017131040315077683, "timer/dataset_train_min": 8.606910705566406e-05, "timer/dataset_train_max": 0.0010166168212890625, "timer/agent.train_count": 2114.0, "timer/agent.train_total": 937.7714722156525, "timer/agent.train_frac": 0.9375776256613364, "timer/agent.train_avg": 0.44360050719756505, "timer/agent.train_min": 0.43474507331848145, "timer/agent.train_max": 0.570512056350708, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4733145236968994, "timer/agent.report_frac": 0.0004732166849459406, "timer/agent.report_avg": 0.2366572618484497, "timer/agent.report_min": 0.23052549362182617, "timer/agent.report_max": 0.24278903007507324, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8371810913085938e-05, "timer/dataset_eval_frac": 2.8365946181700783e-08, "timer/dataset_eval_avg": 2.8371810913085938e-05, "timer/dataset_eval_min": 2.8371810913085938e-05, "timer/dataset_eval_max": 2.8371810913085938e-05, "fps": 2.113536442434212}
{"step": 51384, "time": 23370.485424995422, "episode/length": 169.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 51672, "time": 23501.455695152283, "episode/length": 144.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 51832, "time": 23574.762814760208, "episode/length": 206.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 51872, "time": 23594.222405910492, "episode/length": 195.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 51888, "time": 23602.787425994873, "episode/length": 160.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 51968, "time": 23640.16068649292, "episode/length": 218.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 52168, "time": 23731.41954421997, "episode/length": 165.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 52448, "time": 23858.336356639862, "episode/length": 187.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 52648, "time": 23949.284477472305, "episode/length": 157.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 52944, "time": 24083.478945493698, "episode/length": 158.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 53032, "time": 24124.591965675354, "episode/length": 149.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 53088, "time": 24151.1602807045, "episode/length": 139.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 53264, "time": 24231.622442245483, "episode/length": 171.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 53336, "time": 24265.33409166336, "episode/length": 182.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 53400, "time": 24295.437843084335, "episode/length": 153.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 53430, "time": 24310.895457029343, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.679887124157827, "train/action_min": 0.0, "train/action_std": 4.126629360225222, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.049522246652786886, "train/actor_opt_grad_steps": 50785.0, "train/actor_opt_loss": 19.38962011661278, "train/adv_mag": 0.8723017827633324, "train/adv_max": 0.7885292336481426, "train/adv_mean": 0.008273923145663185, "train/adv_min": -0.7348370717479549, "train/adv_std": 0.05892571576213071, "train/cont_avg": 0.9943377293577982, "train/cont_loss_mean": 7.951869711378783e-05, "train/cont_loss_std": 0.002458727174536549, "train/cont_neg_acc": 0.9981214510738303, "train/cont_neg_loss": 0.009943162942363415, "train/cont_pos_acc": 0.9999954878190241, "train/cont_pos_loss": 1.6757209647648138e-05, "train/cont_pred": 0.9943409212138674, "train/cont_rate": 0.9943377293577982, "train/dyn_loss_mean": 2.866374802151951, "train/dyn_loss_std": 7.8019202630454245, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.3237074586229587, "train/extr_critic_critic_opt_grad_steps": 50785.0, "train/extr_critic_critic_opt_loss": 15496.8780506379, "train/extr_critic_mag": 18.020798560676226, "train/extr_critic_max": 18.020798560676226, "train/extr_critic_mean": 5.621329127101723, "train/extr_critic_min": -0.6747720542304013, "train/extr_critic_std": 3.8868090909555417, "train/extr_return_normed_mag": 1.4290368037486294, "train/extr_return_normed_max": 1.4290368037486294, "train/extr_return_normed_mean": 0.45429382370699434, "train/extr_return_normed_min": -0.07685444691995962, "train/extr_return_normed_std": 0.3062389623544632, "train/extr_return_rate": 0.8760115485125726, "train/extr_return_raw_mag": 18.377876133000086, "train/extr_return_raw_max": 18.377876133000086, "train/extr_return_raw_mean": 5.7292998121419085, "train/extr_return_raw_min": -1.1853076369937408, "train/extr_return_raw_std": 3.987028399738697, "train/extr_reward_mag": 1.023333984777468, "train/extr_reward_max": 1.023333984777468, "train/extr_reward_mean": 0.026166519133049414, "train/extr_reward_min": -0.6823185742448229, "train/extr_reward_std": 0.16429352592847762, "train/image_loss_mean": 1.823128257049333, "train/image_loss_std": 4.988917627465835, "train/model_loss_mean": 3.5776956070453747, "train/model_loss_std": 8.75271259097878, "train/model_opt_grad_norm": 34.371817715671085, "train/model_opt_grad_steps": 50740.41743119266, "train/model_opt_loss": 5128.459839987098, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1433.48623853211, "train/policy_entropy_mag": 2.3454335107715854, "train/policy_entropy_max": 2.3454335107715854, "train/policy_entropy_mean": 0.49878862062725454, "train/policy_entropy_min": 0.07937501562297891, "train/policy_entropy_std": 0.5072911232709885, "train/policy_logprob_mag": 7.438383723617694, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.49859486561302746, "train/policy_logprob_min": -7.438383723617694, "train/policy_logprob_std": 1.058142820629505, "train/policy_randomness_mag": 0.8278351037874134, "train/policy_randomness_max": 0.8278351037874134, "train/policy_randomness_mean": 0.17605049450189694, "train/policy_randomness_min": 0.02801589733587766, "train/policy_randomness_std": 0.17905150524793415, "train/post_ent_mag": 37.3601564617332, "train/post_ent_max": 37.3601564617332, "train/post_ent_mean": 20.04763611959755, "train/post_ent_min": 11.250299987442997, "train/post_ent_std": 3.705767061732231, "train/prior_ent_mag": 74.97144324626397, "train/prior_ent_max": 74.97144324626397, "train/prior_ent_mean": 22.976888341641207, "train/prior_ent_min": 12.480912632898454, "train/prior_ent_std": 9.004884413622936, "train/rep_loss_mean": 2.866374802151951, "train/rep_loss_std": 7.8019202630454245, "train/reward_avg": 0.018645176166292587, "train/reward_loss_mean": 0.03466294592229325, "train/reward_loss_std": 0.16031417230127054, "train/reward_max_data": 1.010091745525325, "train/reward_max_pred": 1.0111422992627555, "train/reward_neg_acc": 0.9964364578417682, "train/reward_neg_loss": 0.018266211415495757, "train/reward_pos_acc": 0.991152067250068, "train/reward_pos_loss": 0.7127055528513883, "train/reward_pred": 0.01853472188781571, "train/reward_rate": 0.023630124713302753, "train_stats/sum_log_reward": 3.6333332538604735, "train_stats/max_log_achievement_collect_drink": 1.4666666666666666, "train_stats/max_log_achievement_collect_sapling": 2.0, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 1.6666666666666667, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.06666666666666667, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.9333333333333333, "train_stats/max_log_achievement_place_table": 0.4666666666666667, "train_stats/max_log_achievement_wake_up": 1.6, "train_stats/mean_log_entropy": 0.44390788475672405, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 6.941560286577442e-07, "report/cont_loss_std": 1.8685695977183059e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 2.0430972654139623e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 5.778290983471379e-07, "report/cont_pred": 0.9941402673721313, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 2.624248504638672, "report/dyn_loss_std": 7.469874382019043, "report/image_loss_mean": 1.0674620866775513, "report/image_loss_std": 2.9661684036254883, "report/model_loss_mean": 2.674980640411377, "report/model_loss_std": 6.941420078277588, "report/post_ent_mag": 32.619258880615234, "report/post_ent_max": 32.619258880615234, "report/post_ent_mean": 19.661304473876953, "report/post_ent_min": 11.171931266784668, "report/post_ent_std": 3.6058385372161865, "report/prior_ent_mag": 75.07557678222656, "report/prior_ent_max": 75.07557678222656, "report/prior_ent_mean": 22.555206298828125, "report/prior_ent_min": 13.261590957641602, "report/prior_ent_std": 9.038698196411133, "report/rep_loss_mean": 2.624248504638672, "report/rep_loss_std": 7.469874382019043, "report/reward_avg": 0.02128906175494194, "report/reward_loss_mean": 0.03296862542629242, "report/reward_loss_std": 0.1435837745666504, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.001833438873291, "report/reward_neg_acc": 0.9959879517555237, "report/reward_neg_loss": 0.0156182199716568, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6736484169960022, "report/reward_pred": 0.021647673100233078, "report/reward_rate": 0.0263671875, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.0014910828322172165, "eval/cont_loss_std": 0.04760203883051872, "eval/cont_neg_acc": 0.75, "eval/cont_neg_loss": 0.3815193176269531, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 7.757241178296681e-07, "eval/cont_pred": 0.9968588948249817, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 23.285842895507812, "eval/dyn_loss_std": 13.5997314453125, "eval/image_loss_mean": 41.20890426635742, "eval/image_loss_std": 50.74442672729492, "eval/model_loss_mean": 55.31953430175781, "eval/model_loss_std": 55.88473892211914, "eval/post_ent_mag": 35.89073944091797, "eval/post_ent_max": 35.89073944091797, "eval/post_ent_mean": 25.87051773071289, "eval/post_ent_min": 12.078581809997559, "eval/post_ent_std": 3.547548294067383, "eval/prior_ent_mag": 75.07557678222656, "eval/prior_ent_max": 75.07557678222656, "eval/prior_ent_mean": 34.06340408325195, "eval/prior_ent_min": 15.624017715454102, "eval/prior_ent_std": 8.710983276367188, "eval/rep_loss_mean": 23.285842895507812, "eval/rep_loss_std": 13.5997314453125, "eval/reward_avg": 0.02197265625, "eval/reward_loss_mean": 0.1376352310180664, "eval/reward_loss_std": 1.0272067785263062, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0010662078857422, "eval/reward_neg_acc": 0.9969940185546875, "eval/reward_neg_loss": 0.04063680022954941, "eval/reward_pos_acc": 0.6153846383094788, "eval/reward_pos_loss": 3.8608834743499756, "eval/reward_pred": 0.01261092908680439, "eval/reward_rate": 0.025390625, "replay/size": 52926.0, "replay/inserts": 2179.0, "replay/samples": 34864.0, "replay/insert_wait_avg": 2.601486983349587e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.328376030363912e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 12008.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 7.450580596923828e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1683208942413, "timer/env.step_count": 272.0, "timer/env.step_total": 29.365691900253296, "timer/env.step_frac": 0.029360749872579146, "timer/env.step_avg": 0.10796210257446065, "timer/env.step_min": 0.02331852912902832, "timer/env.step_max": 1.674044132232666, "timer/replay._sample_count": 34864.0, "timer/replay._sample_total": 16.932774543762207, "timer/replay._sample_frac": 0.01692992488366635, "timer/replay._sample_avg": 0.0004856807751193841, "timer/replay._sample_min": 0.0003590583801269531, "timer/replay._sample_max": 0.03716325759887695, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 272.0, "timer/agent.policy_total": 4.2751429080963135, "timer/agent.policy_frac": 0.0042744234333216505, "timer/agent.policy_avg": 0.0157174371621188, "timer/agent.policy_min": 0.009703874588012695, "timer/agent.policy_max": 0.02982330322265625, "timer/dataset_train_count": 2179.0, "timer/dataset_train_total": 0.37834954261779785, "timer/dataset_train_frac": 0.0003782858692020149, "timer/dataset_train_avg": 0.0001736344849094988, "timer/dataset_train_min": 8.940696716308594e-05, "timer/dataset_train_max": 0.0005207061767578125, "timer/agent.train_count": 2179.0, "timer/agent.train_total": 964.4404306411743, "timer/agent.train_frac": 0.9642781224853002, "timer/agent.train_avg": 0.4426068979537285, "timer/agent.train_min": 0.4330615997314453, "timer/agent.train_max": 0.5712795257568359, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47097110748291016, "timer/agent.report_frac": 0.00047089184654620854, "timer/agent.report_avg": 0.23548555374145508, "timer/agent.report_min": 0.2282733917236328, "timer/agent.report_max": 0.24269771575927734, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8371810913085938e-05, "timer/dataset_eval_frac": 2.8367036148194496e-08, "timer/dataset_eval_avg": 2.8371810913085938e-05, "timer/dataset_eval_min": 2.8371810913085938e-05, "timer/dataset_eval_max": 2.8371810913085938e-05, "fps": 2.1786053893530926}
{"step": 53920, "time": 24532.77072119713, "episode/length": 183.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 54080, "time": 24606.913192272186, "episode/length": 178.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 54264, "time": 24691.572565078735, "episode/length": 164.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 54352, "time": 24732.769757032394, "episode/length": 135.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.0}
{"step": 54408, "time": 24759.47414970398, "episode/length": 171.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 54432, "time": 24771.741814374924, "episode/length": 167.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 54920, "time": 24993.872222661972, "episode/length": 197.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 54992, "time": 25027.740833044052, "episode/length": 198.0, "episode/score": 1.0999999940395355, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 55240, "time": 25140.87163543701, "episode/length": 144.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 55424, "time": 25225.4426612854, "episode/length": 187.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 55496, "time": 25259.517370700836, "episode/length": 153.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.987012987012987, "episode/intrinsic_return": 0.0}
{"step": 55496, "time": 25259.609466314316, "episode/length": 142.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 55568, "time": 25295.295650959015, "episode/length": 144.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 55598, "time": 25310.964196920395, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.4737978334780095, "train/action_min": 0.0, "train/action_std": 4.182878792285919, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04125990366770162, "train/actor_opt_grad_steps": 52955.0, "train/actor_opt_loss": -11.082555375027436, "train/adv_mag": 0.6571205868213265, "train/adv_max": 0.6143705054979633, "train/adv_mean": 0.00203530158332628, "train/adv_min": -0.5518450796328209, "train/adv_std": 0.050310422450786936, "train/cont_avg": 0.9946560329861112, "train/cont_loss_mean": 1.3406484858817462e-05, "train/cont_loss_std": 0.00036308724684867383, "train/cont_neg_acc": 1.0, "train/cont_neg_loss": 0.00032125292895030997, "train/cont_pos_acc": 0.999990876350138, "train/cont_pos_loss": 1.1214888487966459e-05, "train/cont_pred": 0.9946501014961137, "train/cont_rate": 0.9946560329861112, "train/dyn_loss_mean": 2.8854003813531666, "train/dyn_loss_std": 7.863164775901371, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1947099994178172, "train/extr_critic_critic_opt_grad_steps": 52955.0, "train/extr_critic_critic_opt_loss": 14169.955091688367, "train/extr_critic_mag": 21.165038850572373, "train/extr_critic_max": 21.165038850572373, "train/extr_critic_mean": 6.820605408262323, "train/extr_critic_min": -0.6606294595532947, "train/extr_critic_std": 4.261233306593365, "train/extr_return_normed_mag": 1.5059349594844713, "train/extr_return_normed_max": 1.5059349594844713, "train/extr_return_normed_mean": 0.4910799524298421, "train/extr_return_normed_min": -0.07029089053954791, "train/extr_return_normed_std": 0.3027689756342658, "train/extr_return_rate": 0.8927894587869998, "train/extr_return_raw_mag": 21.564240561591255, "train/extr_return_raw_max": 21.564240561591255, "train/extr_return_raw_mean": 6.849308102219193, "train/extr_return_raw_min": -1.1665261454052396, "train/extr_return_raw_std": 4.338672360888234, "train/extr_reward_mag": 1.0184818804264069, "train/extr_reward_max": 1.0184818804264069, "train/extr_reward_mean": 0.025153003917593095, "train/extr_reward_min": -0.677448288710029, "train/extr_reward_std": 0.16033316762359054, "train/image_loss_mean": 1.8319226644105382, "train/image_loss_std": 5.239901868833436, "train/model_loss_mean": 3.5968658802685916, "train/model_loss_std": 9.04929675437786, "train/model_opt_grad_norm": 33.87408351456678, "train/model_opt_grad_steps": 52908.625, "train/model_opt_loss": 5099.799073395906, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1417.8240740740741, "train/policy_entropy_mag": 2.3249192789748863, "train/policy_entropy_max": 2.3249192789748863, "train/policy_entropy_mean": 0.5006249587017076, "train/policy_entropy_min": 0.07937501439893688, "train/policy_entropy_std": 0.5110988531399656, "train/policy_logprob_mag": 7.438383782351458, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5006193448272016, "train/policy_logprob_min": -7.438383782351458, "train/policy_logprob_std": 1.06080542339219, "train/policy_randomness_mag": 0.8205944790884301, "train/policy_randomness_max": 0.8205944790884301, "train/policy_randomness_mean": 0.17669864102370209, "train/policy_randomness_min": 0.02801589688493146, "train/policy_randomness_std": 0.18039546637899345, "train/post_ent_mag": 37.17987950642904, "train/post_ent_max": 37.17987950642904, "train/post_ent_mean": 20.178602280440153, "train/post_ent_min": 11.396700316005283, "train/post_ent_std": 3.7133631849730455, "train/prior_ent_mag": 75.13632145634404, "train/prior_ent_max": 75.13632145634404, "train/prior_ent_mean": 23.091218603981865, "train/prior_ent_min": 12.597817169295418, "train/prior_ent_std": 8.991088955490678, "train/rep_loss_mean": 2.8854003813531666, "train/rep_loss_std": 7.863164775901371, "train/reward_avg": 0.01828794109557445, "train/reward_loss_mean": 0.0336895768823861, "train/reward_loss_std": 0.163063311845892, "train/reward_max_data": 1.0120370399068903, "train/reward_max_pred": 1.0127490013837814, "train/reward_neg_acc": 0.9967086858771466, "train/reward_neg_loss": 0.017278940630300593, "train/reward_pos_acc": 0.9891901300461204, "train/reward_pos_loss": 0.7248240841759576, "train/reward_pred": 0.01808752284894042, "train/reward_rate": 0.023098415798611112, "train_stats/sum_log_reward": 3.3307691445717444, "train_stats/max_log_achievement_collect_drink": 2.923076923076923, "train_stats/max_log_achievement_collect_sapling": 1.6923076923076923, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 1.0769230769230769, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.6153846153846154, "train_stats/max_log_achievement_place_table": 0.3076923076923077, "train_stats/max_log_achievement_wake_up": 1.5384615384615385, "train_stats/mean_log_entropy": 0.46546451632793134, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 7.109817943273811e-07, "report/cont_loss_std": 1.8692035155254416e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.8583859855425544e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 5.702505063709395e-07, "report/cont_pred": 0.9921871423721313, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 2.703185796737671, "report/dyn_loss_std": 7.779454708099365, "report/image_loss_mean": 1.1616835594177246, "report/image_loss_std": 3.0099308490753174, "report/model_loss_mean": 2.811697006225586, "report/model_loss_std": 6.851346015930176, "report/post_ent_mag": 34.334529876708984, "report/post_ent_max": 34.334529876708984, "report/post_ent_mean": 19.464595794677734, "report/post_ent_min": 11.944931030273438, "report/post_ent_std": 3.5350899696350098, "report/prior_ent_mag": 75.84599304199219, "report/prior_ent_max": 75.84599304199219, "report/prior_ent_mean": 22.308330535888672, "report/prior_ent_min": 12.058784484863281, "report/prior_ent_std": 9.30778694152832, "report/rep_loss_mean": 2.703185796737671, "report/rep_loss_std": 7.779454708099365, "report/reward_avg": 0.01386718824505806, "report/reward_loss_mean": 0.028101233765482903, "report/reward_loss_std": 0.12942583858966827, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0005912780761719, "report/reward_neg_acc": 0.9980059862136841, "report/reward_neg_loss": 0.014559764415025711, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6748676300048828, "report/reward_pred": 0.014000974595546722, "report/reward_rate": 0.0205078125, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.03247307240962982, "eval/cont_loss_std": 0.7341041564941406, "eval/cont_neg_acc": 0.6000000238418579, "eval/cont_neg_loss": 6.650071620941162, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.030224095506128e-06, "eval/cont_pred": 0.9970687031745911, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 25.206314086914062, "eval/dyn_loss_std": 12.776224136352539, "eval/image_loss_mean": 46.48262405395508, "eval/image_loss_std": 48.933135986328125, "eval/model_loss_mean": 61.89924621582031, "eval/model_loss_std": 53.410499572753906, "eval/post_ent_mag": 38.9093017578125, "eval/post_ent_max": 38.9093017578125, "eval/post_ent_mean": 25.8662109375, "eval/post_ent_min": 17.011219024658203, "eval/post_ent_std": 3.4799375534057617, "eval/prior_ent_mag": 75.84599304199219, "eval/prior_ent_max": 75.84599304199219, "eval/prior_ent_mean": 34.937164306640625, "eval/prior_ent_min": 14.627368927001953, "eval/prior_ent_std": 8.83593463897705, "eval/rep_loss_mean": 25.206314086914062, "eval/rep_loss_std": 12.776224136352539, "eval/reward_avg": 0.02978515625, "eval/reward_loss_mean": 0.26036301255226135, "eval/reward_loss_std": 1.3693015575408936, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.000915765762329, "eval/reward_neg_acc": 0.9929150342941284, "eval/reward_neg_loss": 0.1248704195022583, "eval/reward_pos_acc": 0.5555555820465088, "eval/reward_pos_loss": 3.978881359100342, "eval/reward_pred": 0.017565883696079254, "eval/reward_rate": 0.03515625, "replay/size": 55094.0, "replay/inserts": 2168.0, "replay/samples": 34688.0, "replay/insert_wait_avg": 2.6451485623292816e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.667499714671906e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 12008.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 8.493661880493164e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0572967529297, "timer/env.step_count": 271.0, "timer/env.step_total": 27.31493878364563, "timer/env.step_frac": 0.027313373816014418, "timer/env.step_avg": 0.1007931320429728, "timer/env.step_min": 0.023782014846801758, "timer/env.step_max": 3.1980624198913574, "timer/replay._sample_count": 34688.0, "timer/replay._sample_total": 17.844071865081787, "timer/replay._sample_frac": 0.017843049516282142, "timer/replay._sample_avg": 0.0005144162783983449, "timer/replay._sample_min": 0.00035262107849121094, "timer/replay._sample_max": 0.028427600860595703, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 271.0, "timer/agent.policy_total": 4.431183338165283, "timer/agent.policy_frac": 0.004430929460294748, "timer/agent.policy_avg": 0.016351230030130195, "timer/agent.policy_min": 0.010190963745117188, "timer/agent.policy_max": 0.040884971618652344, "timer/dataset_train_count": 2168.0, "timer/dataset_train_total": 0.39319348335266113, "timer/dataset_train_frac": 0.0003931709559335399, "timer/dataset_train_avg": 0.00018136230781949314, "timer/dataset_train_min": 9.274482727050781e-05, "timer/dataset_train_max": 0.00047707557678222656, "timer/agent.train_count": 2168.0, "timer/agent.train_total": 965.8099060058594, "timer/agent.train_frac": 0.9657545714047909, "timer/agent.train_avg": 0.4454842739879425, "timer/agent.train_min": 0.43534135818481445, "timer/agent.train_max": 0.5871248245239258, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4769902229309082, "timer/agent.report_frac": 0.0004769628945057851, "timer/agent.report_avg": 0.2384951114654541, "timer/agent.report_min": 0.23045754432678223, "timer/agent.report_max": 0.24653267860412598, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.600120544433594e-05, "timer/dataset_eval_frac": 3.599914281034465e-08, "timer/dataset_eval_avg": 3.600120544433594e-05, "timer/dataset_eval_min": 3.600120544433594e-05, "timer/dataset_eval_max": 3.600120544433594e-05, "fps": 2.167845017034741}
{"step": 55816, "time": 25409.87921476364, "episode/length": 172.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 56112, "time": 25545.071678876877, "episode/length": 139.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 56328, "time": 25644.439716100693, "episode/length": 94.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9473684210526315, "episode/intrinsic_return": 0.0}
{"step": 56400, "time": 25678.583078861237, "episode/length": 184.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 56632, "time": 25784.834189653397, "episode/length": 173.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 56712, "time": 25822.534024953842, "episode/length": 160.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9565217391304348, "episode/intrinsic_return": 0.0}
{"step": 56728, "time": 25831.309943437576, "episode/length": 153.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 57208, "time": 26050.193617105484, "episode/length": 136.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9635036496350365, "episode/intrinsic_return": 0.0}
{"step": 57576, "time": 26218.681061267853, "episode/length": 155.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 57640, "time": 26249.091064214706, "episode/length": 113.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9473684210526315, "episode/intrinsic_return": 0.0}
{"step": 57712, "time": 26283.096967697144, "episode/length": 236.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9789029535864979, "episode/intrinsic_return": 0.0}
{"step": 57728, "time": 26291.887177705765, "episode/length": 278.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.974910394265233, "episode/intrinsic_return": 0.0}
{"step": 57752, "time": 26304.29340171814, "episode/length": 168.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 57763, "time": 26311.39083981514, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.731360932099655, "train/action_min": 0.0, "train/action_std": 4.229612885532291, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.039841706928912944, "train/actor_opt_grad_steps": 55120.0, "train/actor_opt_loss": -16.910523800805965, "train/adv_mag": 0.6685960582599112, "train/adv_max": 0.6353827603676352, "train/adv_mean": 0.0005347658141897316, "train/adv_min": -0.5474776519883063, "train/adv_std": 0.05036900446574259, "train/cont_avg": 0.994307135656682, "train/cont_loss_mean": 7.451910003476104e-05, "train/cont_loss_std": 0.0022146913744556457, "train/cont_neg_acc": 0.9977616860020545, "train/cont_neg_loss": 0.009268697196896556, "train/cont_pos_acc": 0.9999954571372353, "train/cont_pos_loss": 1.381337687944675e-05, "train/cont_pred": 0.9943178883895346, "train/cont_rate": 0.994307135656682, "train/dyn_loss_mean": 2.9093289935643774, "train/dyn_loss_std": 7.78218113991522, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1979667338358093, "train/extr_critic_critic_opt_grad_steps": 55120.0, "train/extr_critic_critic_opt_loss": 14526.709816928284, "train/extr_critic_mag": 25.336504694503574, "train/extr_critic_max": 25.336504694503574, "train/extr_critic_mean": 6.04336922289589, "train/extr_critic_min": -0.6729568528689547, "train/extr_critic_std": 4.659696674566664, "train/extr_return_normed_mag": 1.6118928430267194, "train/extr_return_normed_max": 1.6118928430267194, "train/extr_return_normed_mean": 0.3880624555497675, "train/extr_return_normed_min": -0.08439274837825156, "train/extr_return_normed_std": 0.29788035284813646, "train/extr_return_rate": 0.8898212964633643, "train/extr_return_raw_mag": 25.529669484784527, "train/extr_return_raw_max": 25.529669484784527, "train/extr_return_raw_mean": 6.05195252466861, "train/extr_return_raw_min": -1.4638367358440627, "train/extr_return_raw_std": 4.741685943120086, "train/extr_reward_mag": 1.017210391809314, "train/extr_reward_max": 1.017210391809314, "train/extr_reward_mean": 0.02393963860030273, "train/extr_reward_min": -0.6870396609679894, "train/extr_reward_std": 0.15912201008351717, "train/image_loss_mean": 1.769497118787282, "train/image_loss_std": 4.954256142339399, "train/model_loss_mean": 3.550743777631065, "train/model_loss_std": 8.7389570776768, "train/model_opt_grad_norm": 36.50762932421425, "train/model_opt_grad_steps": 55072.253456221195, "train/model_opt_loss": 6083.484837404594, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1728.110599078341, "train/policy_entropy_mag": 2.3658509562092442, "train/policy_entropy_max": 2.3658509562092442, "train/policy_entropy_mean": 0.5366478128367306, "train/policy_entropy_min": 0.07937501693650874, "train/policy_entropy_std": 0.5451114905594681, "train/policy_logprob_mag": 7.438383772625901, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5354461152158025, "train/policy_logprob_min": -7.438383772625901, "train/policy_logprob_std": 1.0813794509606427, "train/policy_randomness_mag": 0.8350415652798068, "train/policy_randomness_max": 0.8350415652798068, "train/policy_randomness_mean": 0.18941312664390159, "train/policy_randomness_min": 0.02801589779384125, "train/policy_randomness_std": 0.19240043590420403, "train/post_ent_mag": 38.28616664376676, "train/post_ent_max": 38.28616664376676, "train/post_ent_mean": 20.357879673830375, "train/post_ent_min": 11.22429266283589, "train/post_ent_std": 3.820594199791482, "train/prior_ent_mag": 75.15074892527497, "train/prior_ent_max": 75.15074892527497, "train/prior_ent_mean": 23.314950573828913, "train/prior_ent_min": 12.459590019718293, "train/prior_ent_std": 9.065546637855917, "train/rep_loss_mean": 2.9093289935643774, "train/rep_loss_std": 7.78218113991522, "train/reward_avg": 0.01841832859621894, "train/reward_loss_mean": 0.035574749292385195, "train/reward_loss_std": 0.16916558462353895, "train/reward_max_data": 1.011059910470989, "train/reward_max_pred": 1.0109432551168627, "train/reward_neg_acc": 0.9965984359864266, "train/reward_neg_loss": 0.01893719288945404, "train/reward_pos_acc": 0.9894404933199904, "train/reward_pos_loss": 0.7232260986956583, "train/reward_pred": 0.01827564177184885, "train/reward_rate": 0.023653513824884793, "train_stats/sum_log_reward": 3.253846076818613, "train_stats/max_log_achievement_collect_drink": 3.076923076923077, "train_stats/max_log_achievement_collect_sapling": 1.3846153846153846, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 1.3076923076923077, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.3846153846153846, "train_stats/max_log_achievement_place_table": 0.23076923076923078, "train_stats/max_log_achievement_wake_up": 1.8461538461538463, "train_stats/mean_log_entropy": 0.48730416939808774, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 1.0206589649897069e-05, "report/cont_loss_std": 0.00014895774074830115, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0010422328487038612, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 3.103162953266292e-06, "report/cont_pred": 0.9931681156158447, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 2.814713954925537, "report/dyn_loss_std": 8.2562255859375, "report/image_loss_mean": 1.3825113773345947, "report/image_loss_std": 4.713383197784424, "report/model_loss_mean": 3.1055164337158203, "report/model_loss_std": 8.694096565246582, "report/post_ent_mag": 39.53533935546875, "report/post_ent_max": 39.53533935546875, "report/post_ent_mean": 20.22835350036621, "report/post_ent_min": 11.155773162841797, "report/post_ent_std": 4.04946231842041, "report/prior_ent_mag": 74.86961364746094, "report/prior_ent_max": 74.86961364746094, "report/prior_ent_mean": 23.20456314086914, "report/prior_ent_min": 12.68024730682373, "report/prior_ent_std": 9.244028091430664, "report/rep_loss_mean": 2.814713954925537, "report/rep_loss_std": 8.2562255859375, "report/reward_avg": 0.02119140699505806, "report/reward_loss_mean": 0.03416626155376434, "report/reward_loss_std": 0.1612207144498825, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.000640869140625, "report/reward_neg_acc": 0.996990978717804, "report/reward_neg_loss": 0.01743444800376892, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6520039439201355, "report/reward_pred": 0.02178238146007061, "report/reward_rate": 0.0263671875, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.0026710424572229385, "eval/cont_loss_std": 0.06404436379671097, "eval/cont_neg_acc": 0.6666666865348816, "eval/cont_neg_loss": 0.45418640971183777, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 9.851810318650678e-06, "eval/cont_pred": 0.9955215454101562, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 24.79766273498535, "eval/dyn_loss_std": 13.593509674072266, "eval/image_loss_mean": 74.62840270996094, "eval/image_loss_std": 80.95085906982422, "eval/model_loss_mean": 89.67025756835938, "eval/model_loss_std": 85.95430755615234, "eval/post_ent_mag": 39.53533935546875, "eval/post_ent_max": 39.53533935546875, "eval/post_ent_mean": 26.26095199584961, "eval/post_ent_min": 15.430870056152344, "eval/post_ent_std": 3.6644582748413086, "eval/prior_ent_mag": 74.86961364746094, "eval/prior_ent_max": 74.86961364746094, "eval/prior_ent_mean": 34.40214920043945, "eval/prior_ent_min": 17.087657928466797, "eval/prior_ent_std": 8.859500885009766, "eval/rep_loss_mean": 24.79766273498535, "eval/rep_loss_std": 13.593509674072266, "eval/reward_avg": 0.01386718638241291, "eval/reward_loss_mean": 0.16058114171028137, "eval/reward_loss_std": 0.9650744199752808, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.014514446258545, "eval/reward_neg_acc": 0.9970119595527649, "eval/reward_neg_loss": 0.1155640259385109, "eval/reward_pos_acc": 0.75, "eval/reward_pos_loss": 2.420440673828125, "eval/reward_pred": 0.012637242674827576, "eval/reward_rate": 0.01953125, "replay/size": 57259.0, "replay/inserts": 2165.0, "replay/samples": 34640.0, "replay/insert_wait_avg": 2.572387801031593e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.652520582802576e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 12008.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 9.238719940185547e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4147634506226, "timer/env.step_count": 271.0, "timer/env.step_total": 27.30573010444641, "timer/env.step_frac": 0.027294409381028832, "timer/env.step_avg": 0.10075915167692402, "timer/env.step_min": 0.023909568786621094, "timer/env.step_max": 1.9926884174346924, "timer/replay._sample_count": 34640.0, "timer/replay._sample_total": 17.901066064834595, "timer/replay._sample_frac": 0.017893644435124468, "timer/replay._sample_avg": 0.000516774424504463, "timer/replay._sample_min": 0.0003705024719238281, "timer/replay._sample_max": 0.03433537483215332, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 271.0, "timer/agent.policy_total": 4.45647406578064, "timer/agent.policy_frac": 0.004454626449543192, "timer/agent.policy_avg": 0.016444553748268042, "timer/agent.policy_min": 0.01025533676147461, "timer/agent.policy_max": 0.03968000411987305, "timer/dataset_train_count": 2165.0, "timer/dataset_train_total": 0.3884146213531494, "timer/dataset_train_frac": 0.0003882535879552925, "timer/dataset_train_avg": 0.00017940629161808288, "timer/dataset_train_min": 9.369850158691406e-05, "timer/dataset_train_max": 0.0011739730834960938, "timer/agent.train_count": 2165.0, "timer/agent.train_total": 966.1640174388885, "timer/agent.train_frac": 0.965763454056199, "timer/agent.train_avg": 0.4462651350756991, "timer/agent.train_min": 0.43411707878112793, "timer/agent.train_max": 0.6191916465759277, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4726700782775879, "timer/agent.report_frac": 0.00047247411328403235, "timer/agent.report_avg": 0.23633503913879395, "timer/agent.report_min": 0.22959113121032715, "timer/agent.report_max": 0.24307894706726074, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.170967102050781e-05, "timer/dataset_eval_frac": 3.169652446064977e-08, "timer/dataset_eval_avg": 3.170967102050781e-05, "timer/dataset_eval_min": 3.170967102050781e-05, "timer/dataset_eval_max": 3.170967102050781e-05, "fps": 2.1640752690185896}
{"step": 58144, "time": 26483.806831598282, "episode/length": 188.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 58264, "time": 26539.43047642708, "episode/length": 193.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 58480, "time": 26638.71784067154, "episode/length": 158.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 58824, "time": 26795.416333436966, "episode/length": 147.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 58832, "time": 26800.58060646057, "episode/length": 85.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9418604651162791, "episode/intrinsic_return": 0.0}
{"step": 58880, "time": 26823.71611404419, "episode/length": 162.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 59104, "time": 26926.38588118553, "episode/length": 171.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 59336, "time": 27032.817630052567, "episode/length": 197.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 59360, "time": 27045.159258127213, "episode/length": 205.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 59792, "time": 27241.621734380722, "episode/length": 190.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9685863874345549, "episode/intrinsic_return": 0.0}
{"step": 59942, "time": 27311.453652858734, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.783263880178469, "train/action_min": 0.0, "train/action_std": 4.287863120026545, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.036951567635897103, "train/actor_opt_grad_steps": 57295.0, "train/actor_opt_loss": -21.783692300729797, "train/adv_mag": 0.6100209025888268, "train/adv_max": 0.5528004576853656, "train/adv_mean": -0.000684279574877168, "train/adv_min": -0.5105749621577219, "train/adv_std": 0.04579837527980498, "train/cont_avg": 0.9941451046444955, "train/cont_loss_mean": 9.544565969603054e-05, "train/cont_loss_std": 0.002943912677814288, "train/cont_neg_acc": 0.9987257902228505, "train/cont_neg_loss": 0.011517664315010109, "train/cont_pos_acc": 0.999990984387354, "train/cont_pos_loss": 2.4583234442855078e-05, "train/cont_pred": 0.9941420861340444, "train/cont_rate": 0.9941451046444955, "train/dyn_loss_mean": 2.8523875573359496, "train/dyn_loss_std": 7.760646483220092, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.2126544014029546, "train/extr_critic_critic_opt_grad_steps": 57295.0, "train/extr_critic_critic_opt_loss": 14593.842710722478, "train/extr_critic_mag": 20.84536323197391, "train/extr_critic_max": 20.84536323197391, "train/extr_critic_mean": 4.887652008905324, "train/extr_critic_min": -0.6870783119026674, "train/extr_critic_std": 4.177898807263156, "train/extr_return_normed_mag": 1.5349630226782702, "train/extr_return_normed_max": 1.5349630226782702, "train/extr_return_normed_mean": 0.36922125156046054, "train/extr_return_normed_min": -0.07706247721243342, "train/extr_return_normed_std": 0.30651534608471287, "train/extr_return_rate": 0.8742193932380151, "train/extr_return_raw_mag": 20.94926617123665, "train/extr_return_raw_max": 20.94926617123665, "train/extr_return_raw_mean": 4.878814183243918, "train/extr_return_raw_min": -1.25685707664271, "train/extr_return_raw_std": 4.2181533093846175, "train/extr_reward_mag": 1.0209965290279563, "train/extr_reward_max": 1.0209965290279563, "train/extr_reward_mean": 0.024342564122597558, "train/extr_reward_min": -0.6688970086771414, "train/extr_reward_std": 0.1584879067649535, "train/image_loss_mean": 1.6880893884995662, "train/image_loss_std": 4.873854856972301, "train/model_loss_mean": 3.434886061817134, "train/model_loss_std": 8.636759814866092, "train/model_opt_grad_norm": 32.304932620547234, "train/model_opt_grad_steps": 57245.41743119266, "train/model_opt_loss": 5047.428379443807, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1473.6238532110092, "train/policy_entropy_mag": 2.436762524307321, "train/policy_entropy_max": 2.436762524307321, "train/policy_entropy_mean": 0.5595057452217155, "train/policy_entropy_min": 0.07937501514450125, "train/policy_entropy_std": 0.5816541072152076, "train/policy_logprob_mag": 7.438383837358667, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5594782570906736, "train/policy_logprob_min": -7.438383837358667, "train/policy_logprob_std": 1.1013604200214422, "train/policy_randomness_mag": 0.8600702365057185, "train/policy_randomness_max": 0.8600702365057185, "train/policy_randomness_mean": 0.19748097330058387, "train/policy_randomness_min": 0.028015897164992785, "train/policy_randomness_std": 0.2052983762610943, "train/post_ent_mag": 38.037114519591725, "train/post_ent_max": 38.037114519591725, "train/post_ent_mean": 20.432504443947327, "train/post_ent_min": 11.262640196249025, "train/post_ent_std": 3.7963722845829957, "train/prior_ent_mag": 75.13778655025938, "train/prior_ent_max": 75.13778655025938, "train/prior_ent_mean": 23.358679421451114, "train/prior_ent_min": 12.475936915896355, "train/prior_ent_std": 9.052331933187782, "train/rep_loss_mean": 2.8523875573359496, "train/rep_loss_std": 7.760646483220092, "train/reward_avg": 0.018274261680252236, "train/reward_loss_mean": 0.03526869683671709, "train/reward_loss_std": 0.1666382764115793, "train/reward_max_data": 1.0119266083481115, "train/reward_max_pred": 1.0132751940587246, "train/reward_neg_acc": 0.9966150924153284, "train/reward_neg_loss": 0.018881046858300037, "train/reward_pos_acc": 0.9905521924342584, "train/reward_pos_loss": 0.7156783615777252, "train/reward_pred": 0.01815420717487983, "train/reward_rate": 0.023513653956422017, "train_stats/sum_log_reward": 3.2999999642372133, "train_stats/max_log_achievement_collect_drink": 4.4, "train_stats/max_log_achievement_collect_sapling": 1.3, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 1.7, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.3, "train_stats/max_log_achievement_place_table": 0.5, "train_stats/max_log_achievement_wake_up": 1.6, "train_stats/mean_log_entropy": 0.49932539761066436, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 1.4415094256037264e-06, "report/cont_loss_std": 1.612964661035221e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00028494460275396705, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 8.867089604791545e-07, "report/cont_pred": 0.9980465769767761, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 2.5284905433654785, "report/dyn_loss_std": 7.156763553619385, "report/image_loss_mean": 0.9649494886398315, "report/image_loss_std": 2.31449294090271, "report/model_loss_mean": 2.506960868835449, "report/model_loss_std": 6.2096967697143555, "report/post_ent_mag": 34.315025329589844, "report/post_ent_max": 34.315025329589844, "report/post_ent_mean": 20.237180709838867, "report/post_ent_min": 11.548332214355469, "report/post_ent_std": 3.676894426345825, "report/prior_ent_mag": 75.43576049804688, "report/prior_ent_max": 75.43576049804688, "report/prior_ent_mean": 22.932491302490234, "report/prior_ent_min": 12.436025619506836, "report/prior_ent_std": 8.415034294128418, "report/rep_loss_mean": 2.5284905433654785, "report/rep_loss_std": 7.156763553619385, "report/reward_avg": 0.02548827975988388, "report/reward_loss_mean": 0.024915728718042374, "report/reward_loss_std": 0.1261110156774521, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0018348693847656, "report/reward_neg_acc": 0.99698805809021, "report/reward_neg_loss": 0.006753325462341309, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6709783673286438, "report/reward_pred": 0.02529604732990265, "report/reward_rate": 0.02734375, "eval/cont_avg": 0.9921875, "eval/cont_loss_mean": 0.011599560268223286, "eval/cont_loss_std": 0.36509743332862854, "eval/cont_neg_acc": 0.875, "eval/cont_neg_loss": 1.4845454692840576, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.5612804418196902e-06, "eval/cont_pred": 0.9933308362960815, "eval/cont_rate": 0.9921875, "eval/dyn_loss_mean": 23.07523536682129, "eval/dyn_loss_std": 14.328598022460938, "eval/image_loss_mean": 40.96331024169922, "eval/image_loss_std": 55.87553787231445, "eval/model_loss_mean": 55.09112548828125, "eval/model_loss_std": 60.87469482421875, "eval/post_ent_mag": 39.0100212097168, "eval/post_ent_max": 39.0100212097168, "eval/post_ent_mean": 25.110523223876953, "eval/post_ent_min": 13.464372634887695, "eval/post_ent_std": 4.092639446258545, "eval/prior_ent_mag": 75.43576049804688, "eval/prior_ent_max": 75.43576049804688, "eval/prior_ent_mean": 32.779144287109375, "eval/prior_ent_min": 14.183631896972656, "eval/prior_ent_std": 10.369352340698242, "eval/rep_loss_mean": 23.07523536682129, "eval/rep_loss_std": 14.328598022460938, "eval/reward_avg": 0.01953125, "eval/reward_loss_mean": 0.2710746228694916, "eval/reward_loss_std": 1.40959632396698, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0000495910644531, "eval/reward_neg_acc": 0.9919840097427368, "eval/reward_neg_loss": 0.1602996289730072, "eval/reward_pos_acc": 0.5384615659713745, "eval/reward_pos_loss": 4.523129940032959, "eval/reward_pred": 0.011109154671430588, "eval/reward_rate": 0.025390625, "replay/size": 59438.0, "replay/inserts": 2179.0, "replay/samples": 34864.0, "replay/insert_wait_avg": 2.5105618620859807e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.654300464736918e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 12008.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 6.705522537231445e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0487341880798, "timer/env.step_count": 272.0, "timer/env.step_total": 22.13979148864746, "timer/env.step_frac": 0.022138712576464915, "timer/env.step_avg": 0.08139629223767449, "timer/env.step_min": 0.023415327072143555, "timer/env.step_max": 1.6689364910125732, "timer/replay._sample_count": 34864.0, "timer/replay._sample_total": 18.005856037139893, "timer/replay._sample_frac": 0.018004978579127445, "timer/replay._sample_avg": 0.0005164598450304007, "timer/replay._sample_min": 0.00035572052001953125, "timer/replay._sample_max": 0.01336359977722168, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 272.0, "timer/agent.policy_total": 4.417646884918213, "timer/agent.policy_frac": 0.0044174316049755465, "timer/agent.policy_avg": 0.016241348841611075, "timer/agent.policy_min": 0.010187864303588867, "timer/agent.policy_max": 0.018788576126098633, "timer/dataset_train_count": 2179.0, "timer/dataset_train_total": 0.43021082878112793, "timer/dataset_train_frac": 0.00043018986382739415, "timer/dataset_train_avg": 0.00019743498337821381, "timer/dataset_train_min": 9.298324584960938e-05, "timer/dataset_train_max": 0.04601144790649414, "timer/agent.train_count": 2179.0, "timer/agent.train_total": 971.0592203140259, "timer/agent.train_frac": 0.9710118988375201, "timer/agent.train_avg": 0.44564443337036524, "timer/agent.train_min": 0.43216729164123535, "timer/agent.train_max": 0.574242115020752, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4729437828063965, "timer/agent.report_frac": 0.0004729207353983307, "timer/agent.report_avg": 0.23647189140319824, "timer/agent.report_min": 0.22963261604309082, "timer/agent.report_max": 0.24331116676330566, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9325485229492188e-05, "timer/dataset_eval_frac": 2.9324056145424734e-08, "timer/dataset_eval_avg": 2.9325485229492188e-05, "timer/dataset_eval_min": 2.9325485229492188e-05, "timer/dataset_eval_max": 2.9325485229492188e-05, "fps": 2.1788653268953153}
{"step": 59968, "time": 27323.32764840126, "episode/length": 185.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 60008, "time": 27360.837877988815, "eval_episode/length": 143.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9652777777777778}
{"step": 60008, "time": 27362.505895853043, "eval_episode/length": 147.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9594594594594594}
{"step": 60008, "time": 27364.670321941376, "eval_episode/length": 164.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9696969696969697}
{"step": 60008, "time": 27366.242483139038, "eval_episode/length": 166.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9940119760479041}
{"step": 60008, "time": 27367.777931690216, "eval_episode/length": 167.0, "eval_episode/score": 5.099999979138374, "eval_episode/reward_rate": 0.9880952380952381}
{"step": 60008, "time": 27370.9145758152, "eval_episode/length": 207.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9759615384615384}
{"step": 60008, "time": 27372.818413972855, "eval_episode/length": 53.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9074074074074074}
{"step": 60008, "time": 27374.631341934204, "eval_episode/length": 223.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9955357142857143}
{"step": 60224, "time": 27472.0840883255, "episode/length": 173.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 60384, "time": 27545.591938257217, "episode/length": 159.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 60552, "time": 27622.656052589417, "episode/length": 208.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 60816, "time": 27742.891980171204, "episode/length": 248.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 60880, "time": 27773.274359703064, "episode/length": 192.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 61016, "time": 27835.842211961746, "episode/length": 152.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 61272, "time": 27952.125545740128, "episode/length": 162.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9631901840490797, "episode/intrinsic_return": 0.0}
{"step": 61584, "time": 28094.048991918564, "episode/length": 169.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 61672, "time": 28135.022572517395, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 62061, "time": 28311.581386566162, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.726672190540242, "train/action_min": 0.0, "train/action_std": 4.302174685136327, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03834848561904059, "train/actor_opt_grad_steps": 59445.0, "train/actor_opt_loss": -18.631555389964355, "train/adv_mag": 0.7031502989384363, "train/adv_max": 0.6513554420111314, "train/adv_mean": 0.0004259182033253963, "train/adv_min": -0.5780933057924487, "train/adv_std": 0.04948124407245865, "train/cont_avg": 0.9946473319575472, "train/cont_loss_mean": 7.010723711558771e-05, "train/cont_loss_std": 0.0021597041092838013, "train/cont_neg_acc": 0.9994758910165643, "train/cont_neg_loss": 0.007523461955187023, "train/cont_pos_acc": 0.9999999839742229, "train/cont_pos_loss": 5.716687256136122e-06, "train/cont_pred": 0.9946493357419968, "train/cont_rate": 0.9946473319575472, "train/dyn_loss_mean": 2.9275994334580764, "train/dyn_loss_std": 7.787790471652769, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.301281600347105, "train/extr_critic_critic_opt_grad_steps": 59445.0, "train/extr_critic_critic_opt_loss": 14889.675951687796, "train/extr_critic_mag": 17.72409689651345, "train/extr_critic_max": 17.72409689651345, "train/extr_critic_mean": 3.743801573537431, "train/extr_critic_min": -0.6885154646522594, "train/extr_critic_std": 3.630887914378688, "train/extr_return_normed_mag": 1.5344133545767586, "train/extr_return_normed_max": 1.5344133545767586, "train/extr_return_normed_mean": 0.33363352680824837, "train/extr_return_normed_min": -0.08573713004237639, "train/extr_return_normed_std": 0.31214029602003546, "train/extr_return_rate": 0.8746210924297009, "train/extr_return_raw_mag": 17.960434927130645, "train/extr_return_raw_max": 17.960434927130645, "train/extr_return_raw_mean": 3.7489133128580057, "train/extr_return_raw_min": -1.2159778284576703, "train/extr_return_raw_std": 3.695500913655983, "train/extr_reward_mag": 1.0212054061439801, "train/extr_reward_max": 1.0212054061439801, "train/extr_reward_mean": 0.026187967869259837, "train/extr_reward_min": -0.666100449719519, "train/extr_reward_std": 0.16113358943389272, "train/image_loss_mean": 1.7518207447708778, "train/image_loss_std": 5.102629857243232, "train/model_loss_mean": 3.5429777379305856, "train/model_loss_std": 8.860924246176234, "train/model_opt_grad_norm": 37.74362506506578, "train/model_opt_grad_steps": 59394.03301886792, "train/model_opt_loss": 8544.001871360922, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2432.193396226415, "train/policy_entropy_mag": 2.478524367764311, "train/policy_entropy_max": 2.478524367764311, "train/policy_entropy_mean": 0.5767196359218292, "train/policy_entropy_min": 0.07937501381450104, "train/policy_entropy_std": 0.6027443352735268, "train/policy_logprob_mag": 7.438383797429642, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5773068941989035, "train/policy_logprob_min": -7.438383797429642, "train/policy_logprob_std": 1.115908257241519, "train/policy_randomness_mag": 0.874810333521861, "train/policy_randomness_max": 0.874810333521861, "train/policy_randomness_mean": 0.20355672333038077, "train/policy_randomness_min": 0.028015896713115135, "train/policy_randomness_std": 0.21274230087984283, "train/post_ent_mag": 38.56605455110658, "train/post_ent_max": 38.56605455110658, "train/post_ent_mean": 20.513471783332104, "train/post_ent_min": 11.461255244488987, "train/post_ent_std": 3.7551858222709513, "train/prior_ent_mag": 75.30247108891325, "train/prior_ent_max": 75.30247108891325, "train/prior_ent_mean": 23.445342693688733, "train/prior_ent_min": 12.639199616774073, "train/prior_ent_std": 9.011024218685222, "train/rep_loss_mean": 2.9275994334580764, "train/rep_loss_std": 7.787790471652769, "train/reward_avg": 0.018752303055733582, "train/reward_loss_mean": 0.03452722601733118, "train/reward_loss_std": 0.16575651598285954, "train/reward_max_data": 1.0113207574160594, "train/reward_max_pred": 1.0117498366337903, "train/reward_neg_acc": 0.9966130422533683, "train/reward_neg_loss": 0.01813058162169566, "train/reward_pos_acc": 0.9917258819881475, "train/reward_pos_loss": 0.7145433603030331, "train/reward_pred": 0.01869708136216087, "train/reward_rate": 0.023561873525943397, "train_stats/sum_log_reward": 4.199999880790711, "train_stats/max_log_achievement_collect_drink": 2.7, "train_stats/max_log_achievement_collect_sapling": 1.6, "train_stats/max_log_achievement_collect_stone": 0.1, "train_stats/max_log_achievement_collect_wood": 2.5, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.2, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.5, "train_stats/max_log_achievement_place_table": 0.7, "train_stats/max_log_achievement_wake_up": 1.9, "train_stats/mean_log_entropy": 0.5071299463510514, "eval_stats/sum_log_reward": 2.849999949336052, "eval_stats/max_log_achievement_collect_drink": 3.75, "eval_stats/max_log_achievement_collect_sapling": 1.875, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 0.875, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 1.875, "eval_stats/max_log_achievement_place_table": 0.125, "eval_stats/max_log_achievement_wake_up": 1.25, "eval_stats/mean_log_entropy": 0.0, "train_stats/max_log_achievement_collect_coal": 0.3333333333333333, "train_stats/max_log_achievement_place_stone": 0.16666666666666666, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.0026947609148919582, "report/cont_loss_std": 0.0859995186328888, "report/cont_neg_acc": 0.75, "report/cont_neg_loss": 0.6883412003517151, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 5.9516687542782165e-06, "report/cont_pred": 0.9970021843910217, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 2.8176932334899902, "report/dyn_loss_std": 7.637593746185303, "report/image_loss_mean": 1.8974263668060303, "report/image_loss_std": 4.6883544921875, "report/model_loss_mean": 3.621166229248047, "report/model_loss_std": 8.550541877746582, "report/post_ent_mag": 35.68524169921875, "report/post_ent_max": 35.68524169921875, "report/post_ent_mean": 20.3153076171875, "report/post_ent_min": 10.99090576171875, "report/post_ent_std": 3.745567798614502, "report/prior_ent_mag": 75.96357727050781, "report/prior_ent_max": 75.96357727050781, "report/prior_ent_mean": 23.42690086364746, "report/prior_ent_min": 11.716178894042969, "report/prior_ent_std": 8.707077980041504, "report/rep_loss_mean": 2.8176932334899902, "report/rep_loss_std": 7.637593746185303, "report/reward_avg": 0.01738281175494194, "report/reward_loss_mean": 0.03042919933795929, "report/reward_loss_std": 0.17026786506175995, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0000343322753906, "report/reward_neg_acc": 0.9940179586410522, "report/reward_neg_loss": 0.013997122645378113, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.8152564167976379, "report/reward_pred": 0.016570713371038437, "report/reward_rate": 0.0205078125, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.005939337890595198, "eval/cont_loss_std": 0.1896764189004898, "eval/cont_neg_acc": 0.800000011920929, "eval/cont_neg_loss": 1.2148784399032593, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 7.349131919909269e-06, "eval/cont_pred": 0.9960858821868896, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 25.217098236083984, "eval/dyn_loss_std": 13.766611099243164, "eval/image_loss_mean": 60.813751220703125, "eval/image_loss_std": 62.86299133300781, "eval/model_loss_mean": 76.10126495361328, "eval/model_loss_std": 68.01603698730469, "eval/post_ent_mag": 36.15107727050781, "eval/post_ent_max": 36.15107727050781, "eval/post_ent_mean": 26.121509552001953, "eval/post_ent_min": 12.527016639709473, "eval/post_ent_std": 3.583946704864502, "eval/prior_ent_mag": 75.96357727050781, "eval/prior_ent_max": 75.96357727050781, "eval/prior_ent_mean": 34.9124870300293, "eval/prior_ent_min": 15.399181365966797, "eval/prior_ent_std": 9.360751152038574, "eval/rep_loss_mean": 25.217098236083984, "eval/rep_loss_std": 13.766611099243164, "eval/reward_avg": 0.015429687686264515, "eval/reward_loss_mean": 0.1513102948665619, "eval/reward_loss_std": 0.9911938309669495, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0000495910644531, "eval/reward_neg_acc": 0.9980080127716064, "eval/reward_neg_loss": 0.10051985830068588, "eval/reward_pos_acc": 0.6500000357627869, "eval/reward_pos_loss": 2.700990915298462, "eval/reward_pred": 0.009482395835220814, "eval/reward_rate": 0.01953125, "replay/size": 61557.0, "replay/inserts": 2119.0, "replay/samples": 33904.0, "replay/insert_wait_avg": 2.5680347566843146e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.944660627825072e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 13800.0, "eval_replay/inserts": 1792.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0852568915912083e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.940696716308594e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1136848926544, "timer/env.step_count": 265.0, "timer/env.step_total": 22.488106727600098, "timer/env.step_frac": 0.022485550460209752, "timer/env.step_avg": 0.08486078010415131, "timer/env.step_min": 0.023419857025146484, "timer/env.step_max": 1.9881479740142822, "timer/replay._sample_count": 33904.0, "timer/replay._sample_total": 16.970234155654907, "timer/replay._sample_frac": 0.0169683051157093, "timer/replay._sample_avg": 0.0005005378172385237, "timer/replay._sample_min": 0.0003650188446044922, "timer/replay._sample_max": 0.010141849517822266, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 489.0, "timer/agent.policy_total": 7.759272336959839, "timer/agent.policy_frac": 0.007758390325188548, "timer/agent.policy_avg": 0.015867632590919917, "timer/agent.policy_min": 0.009582281112670898, "timer/agent.policy_max": 0.02617669105529785, "timer/dataset_train_count": 2119.0, "timer/dataset_train_total": 0.42003870010375977, "timer/dataset_train_frac": 0.0004199909534772979, "timer/dataset_train_avg": 0.00019822496465491258, "timer/dataset_train_min": 8.797645568847656e-05, "timer/dataset_train_max": 0.05333209037780762, "timer/agent.train_count": 2119.0, "timer/agent.train_total": 939.4939053058624, "timer/agent.train_frac": 0.9393871111829667, "timer/agent.train_avg": 0.4433666377092319, "timer/agent.train_min": 0.4224872589111328, "timer/agent.train_max": 0.5558915138244629, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4733889102935791, "timer/agent.report_frac": 0.000473335099243632, "timer/agent.report_avg": 0.23669445514678955, "timer/agent.report_min": 0.22910761833190918, "timer/agent.report_max": 0.24428129196166992, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0040740966796875e-05, "timer/dataset_eval_frac": 3.0037326176594866e-08, "timer/dataset_eval_avg": 3.0040740966796875e-05, "timer/dataset_eval_min": 3.0040740966796875e-05, "timer/dataset_eval_max": 3.0040740966796875e-05, "fps": 2.118732775127783}
{"step": 62088, "time": 28323.927817106247, "episode/length": 158.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 62224, "time": 28386.48781967163, "episode/length": 167.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 62464, "time": 28495.458549261093, "episode/length": 148.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9731543624161074, "episode/intrinsic_return": 0.0}
{"step": 62472, "time": 28501.01549601555, "episode/length": 181.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 62808, "time": 28653.584488391876, "episode/length": 152.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 62848, "time": 28673.012716770172, "episode/length": 435.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9793577981651376, "episode/intrinsic_return": 0.0}
{"step": 62880, "time": 28688.787086725235, "episode/length": 290.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9862542955326461, "episode/intrinsic_return": 0.0}
{"step": 63304, "time": 28880.039418697357, "episode/length": 203.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 63688, "time": 29053.728296279907, "episode/length": 199.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.97, "episode/intrinsic_return": 0.0}
{"step": 63856, "time": 29130.60049343109, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 63888, "time": 29146.32426071167, "episode/length": 207.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 63944, "time": 29172.904824733734, "episode/length": 184.0, "episode/score": 2.100000023841858, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 64208, "time": 29292.81574368477, "episode/length": 174.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 64246, "time": 29311.78327679634, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.7268100003583715, "train/action_min": 0.0, "train/action_std": 4.276942573556113, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04103365723351273, "train/actor_opt_grad_steps": 61595.0, "train/actor_opt_loss": -14.888243527561768, "train/adv_mag": 0.6920409270929634, "train/adv_max": 0.6483889157892367, "train/adv_mean": 0.001393387245424901, "train/adv_min": -0.5627719124249362, "train/adv_std": 0.050988024955085656, "train/cont_avg": 0.9943422090022935, "train/cont_loss_mean": 1.0194446990566442e-05, "train/cont_loss_std": 0.00024817743805298205, "train/cont_neg_acc": 1.0, "train/cont_neg_loss": 0.0004094133647922384, "train/cont_pos_acc": 0.9999999841418835, "train/cont_pos_loss": 7.829262110193868e-06, "train/cont_pred": 0.9943376659253321, "train/cont_rate": 0.9943422090022935, "train/dyn_loss_mean": 2.8826758270963615, "train/dyn_loss_std": 7.7982871991778735, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.336590580983993, "train/extr_critic_critic_opt_grad_steps": 61595.0, "train/extr_critic_critic_opt_loss": 15270.170136897936, "train/extr_critic_mag": 15.936756973966546, "train/extr_critic_max": 15.936756973966546, "train/extr_critic_mean": 3.0527182117514653, "train/extr_critic_min": -0.7199503954397429, "train/extr_critic_std": 3.273435605228494, "train/extr_return_normed_mag": 1.5160811691109193, "train/extr_return_normed_max": 1.5160811691109193, "train/extr_return_normed_mean": 0.3073533803497979, "train/extr_return_normed_min": -0.08615265262031227, "train/extr_return_normed_std": 0.3072775795782378, "train/extr_return_rate": 0.8490476717642688, "train/extr_return_raw_mag": 16.19137233769128, "train/extr_return_raw_max": 16.19137233769128, "train/extr_return_raw_mean": 3.0677743991580577, "train/extr_return_raw_min": -1.2045671466840517, "train/extr_return_raw_std": 3.337253699608899, "train/extr_reward_mag": 1.0203267374169935, "train/extr_reward_max": 1.0203267374169935, "train/extr_reward_mean": 0.026719330741656482, "train/extr_reward_min": -0.6660295473326237, "train/extr_reward_std": 0.1634742509607875, "train/image_loss_mean": 1.6967130773658052, "train/image_loss_std": 4.765465133780733, "train/model_loss_mean": 3.46114326726406, "train/model_loss_std": 8.550573764591043, "train/model_opt_grad_norm": 33.603285601379675, "train/model_opt_grad_steps": 61540.85779816514, "train/model_opt_loss": 3503.916137135357, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1017.7752293577981, "train/policy_entropy_mag": 2.4811117988113964, "train/policy_entropy_max": 2.4811117988113964, "train/policy_entropy_mean": 0.5991162892875321, "train/policy_entropy_min": 0.07937501415336898, "train/policy_entropy_std": 0.6160069006845492, "train/policy_logprob_mag": 7.438383846107973, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5989454243708094, "train/policy_logprob_min": -7.438383846107973, "train/policy_logprob_std": 1.127094649393624, "train/policy_randomness_mag": 0.8757235875370306, "train/policy_randomness_max": 0.8757235875370306, "train/policy_randomness_mean": 0.2114617575746064, "train/policy_randomness_min": 0.028015896831767275, "train/policy_randomness_std": 0.21742340382359443, "train/post_ent_mag": 39.19500000979922, "train/post_ent_max": 39.19500000979922, "train/post_ent_mean": 20.760722116592827, "train/post_ent_min": 11.461881143237473, "train/post_ent_std": 3.784759721624742, "train/prior_ent_mag": 75.45967913986345, "train/prior_ent_max": 75.45967913986345, "train/prior_ent_mean": 23.69700422199494, "train/prior_ent_min": 12.620280318303939, "train/prior_ent_std": 9.038542878737143, "train/rep_loss_mean": 2.8826758270963615, "train/rep_loss_std": 7.7982871991778735, "train/reward_avg": 0.018530049267301864, "train/reward_loss_mean": 0.03481448469085431, "train/reward_loss_std": 0.16033173051722552, "train/reward_max_data": 1.012385324053808, "train/reward_max_pred": 1.0130629539489746, "train/reward_neg_acc": 0.9963124454568285, "train/reward_neg_loss": 0.018434454753157605, "train/reward_pos_acc": 0.9909055027939858, "train/reward_pos_loss": 0.7116557302278116, "train/reward_pred": 0.01847349890345417, "train/reward_rate": 0.023585328268348624, "train_stats/sum_log_reward": 3.7153845246021566, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 5.461538461538462, "train_stats/max_log_achievement_collect_sapling": 1.0769230769230769, "train_stats/max_log_achievement_collect_stone": 0.15384615384615385, "train_stats/max_log_achievement_collect_wood": 1.6923076923076923, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.07692307692307693, "train_stats/max_log_achievement_make_wood_sword": 0.07692307692307693, "train_stats/max_log_achievement_place_plant": 1.0769230769230769, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 0.5384615384615384, "train_stats/max_log_achievement_wake_up": 2.6153846153846154, "train_stats/mean_log_entropy": 0.5701436423338376, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 9.981346238419064e-07, "report/cont_loss_std": 2.2346796413330594e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 8.490572326991241e-06, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 9.613710290068411e-07, "report/cont_pred": 0.9951162934303284, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 2.79764461517334, "report/dyn_loss_std": 7.897624492645264, "report/image_loss_mean": 1.2406299114227295, "report/image_loss_std": 3.380979537963867, "report/model_loss_mean": 2.954970359802246, "report/model_loss_std": 7.66467809677124, "report/post_ent_mag": 41.775299072265625, "report/post_ent_max": 41.775299072265625, "report/post_ent_mean": 20.449195861816406, "report/post_ent_min": 12.24405288696289, "report/post_ent_std": 3.741546869277954, "report/prior_ent_mag": 75.59861755371094, "report/prior_ent_max": 75.59861755371094, "report/prior_ent_mean": 23.14301300048828, "report/prior_ent_min": 12.236918449401855, "report/prior_ent_std": 9.021316528320312, "report/rep_loss_mean": 2.79764461517334, "report/rep_loss_std": 7.897624492645264, "report/reward_avg": 0.01943359524011612, "report/reward_loss_mean": 0.035752635449171066, "report/reward_loss_std": 0.2259751558303833, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0006465911865234, "report/reward_neg_acc": 0.999000072479248, "report/reward_neg_loss": 0.020442452281713486, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6736771464347839, "report/reward_pred": 0.020716819912195206, "report/reward_rate": 0.0234375, "eval/cont_avg": 0.9921875, "eval/cont_loss_mean": 0.008059092797338963, "eval/cont_loss_std": 0.25671982765197754, "eval/cont_neg_acc": 0.875, "eval/cont_neg_loss": 1.0273995399475098, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 3.278946678619832e-05, "eval/cont_pred": 0.9931319355964661, "eval/cont_rate": 0.9921875, "eval/dyn_loss_mean": 25.648794174194336, "eval/dyn_loss_std": 13.20228099822998, "eval/image_loss_mean": 49.3661003112793, "eval/image_loss_std": 55.421051025390625, "eval/model_loss_mean": 64.9556884765625, "eval/model_loss_std": 59.97721862792969, "eval/post_ent_mag": 41.775299072265625, "eval/post_ent_max": 41.775299072265625, "eval/post_ent_mean": 26.422677993774414, "eval/post_ent_min": 12.662261962890625, "eval/post_ent_std": 4.0102643966674805, "eval/prior_ent_mag": 75.59861755371094, "eval/prior_ent_max": 75.59861755371094, "eval/prior_ent_mean": 35.16078186035156, "eval/prior_ent_min": 15.846564292907715, "eval/prior_ent_std": 9.2806978225708, "eval/rep_loss_mean": 25.648794174194336, "eval/rep_loss_std": 13.20228099822998, "eval/reward_avg": 0.02080078050494194, "eval/reward_loss_mean": 0.19225504994392395, "eval/reward_loss_std": 1.1166242361068726, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.000046968460083, "eval/reward_neg_acc": 0.994979977607727, "eval/reward_neg_loss": 0.10267135500907898, "eval/reward_pos_acc": 0.6785714626312256, "eval/reward_pos_loss": 3.378875255584717, "eval/reward_pred": 0.012574132531881332, "eval/reward_rate": 0.02734375, "replay/size": 63742.0, "replay/inserts": 2185.0, "replay/samples": 34960.0, "replay/insert_wait_avg": 2.5882328129469393e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.779838291403903e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 13800.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 7.897615432739258e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1910037994385, "timer/env.step_count": 273.0, "timer/env.step_total": 26.94885778427124, "timer/env.step_frac": 0.02694371143301656, "timer/env.step_avg": 0.09871376477755033, "timer/env.step_min": 0.023255109786987305, "timer/env.step_max": 2.0205166339874268, "timer/replay._sample_count": 34960.0, "timer/replay._sample_total": 17.1948504447937, "timer/replay._sample_frac": 0.01719156679021847, "timer/replay._sample_avg": 0.0004918435481920396, "timer/replay._sample_min": 0.00035691261291503906, "timer/replay._sample_max": 0.011034488677978516, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 273.0, "timer/agent.policy_total": 4.36731743812561, "timer/agent.policy_frac": 0.0043664834232015936, "timer/agent.policy_avg": 0.015997499773353883, "timer/agent.policy_min": 0.009845733642578125, "timer/agent.policy_max": 0.04157590866088867, "timer/dataset_train_count": 2185.0, "timer/dataset_train_total": 0.3838064670562744, "timer/dataset_train_frac": 0.00038373317256234444, "timer/dataset_train_avg": 0.0001756551336641988, "timer/dataset_train_min": 9.012222290039062e-05, "timer/dataset_train_max": 0.0006763935089111328, "timer/agent.train_count": 2185.0, "timer/agent.train_total": 966.7478098869324, "timer/agent.train_frac": 0.9665631926447399, "timer/agent.train_avg": 0.44244751024573564, "timer/agent.train_min": 0.431013822555542, "timer/agent.train_max": 0.8335738182067871, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47262144088745117, "timer/agent.report_frac": 0.0004725311856356416, "timer/agent.report_avg": 0.23631072044372559, "timer/agent.report_min": 0.22914600372314453, "timer/agent.report_max": 0.24347543716430664, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.6702880859375e-05, "timer/dataset_eval_frac": 2.669778148167542e-08, "timer/dataset_eval_avg": 2.6702880859375e-05, "timer/dataset_eval_min": 2.6702880859375e-05, "timer/dataset_eval_max": 2.6702880859375e-05, "fps": 2.1845550507849323}
{"step": 64248, "time": 29312.909600257874, "episode/length": 174.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 64328, "time": 29350.186834335327, "episode/length": 180.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 65000, "time": 29652.791188955307, "episode/length": 211.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 65024, "time": 29665.112297534943, "episode/length": 145.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 65032, "time": 29670.224474430084, "episode/length": 142.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.965034965034965, "episode/intrinsic_return": 0.0}
{"step": 65304, "time": 29794.610024929047, "episode/length": 169.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 65512, "time": 29889.621053934097, "episode/length": 227.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 65616, "time": 29938.42622065544, "episode/length": 170.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 65640, "time": 29950.73218846321, "episode/length": 178.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 65696, "time": 29977.271214962006, "episode/length": 170.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 66400, "time": 30294.08143401146, "episode/length": 174.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9657142857142857, "episode/intrinsic_return": 0.0}
{"step": 66435, "time": 30312.002783060074, "train_stats/sum_log_reward": 3.554545359178023, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 4.2727272727272725, "train_stats/max_log_achievement_collect_sapling": 1.4545454545454546, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 2.727272727272727, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.18181818181818182, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.4545454545454546, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 0.9090909090909091, "train_stats/max_log_achievement_wake_up": 1.2727272727272727, "train_stats/mean_log_entropy": 0.49099071459336713, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.44487131893907, "train/action_min": 0.0, "train/action_std": 4.255325901998233, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04351369169919186, "train/actor_opt_grad_steps": 63780.0, "train/actor_opt_loss": -12.872617339247574, "train/adv_mag": 0.8187127400478816, "train/adv_max": 0.7632701757563848, "train/adv_mean": 0.0015705805493132785, "train/adv_min": -0.600237311429629, "train/adv_std": 0.05527192274253118, "train/cont_avg": 0.9944750642123288, "train/cont_loss_mean": 1.5123940147220796e-05, "train/cont_loss_std": 0.0004600402088076241, "train/cont_neg_acc": 0.9988584474885844, "train/cont_neg_loss": 0.0016493965427735351, "train/cont_pos_acc": 0.9999954956307259, "train/cont_pos_loss": 8.066052730764329e-06, "train/cont_pred": 0.9944737428399526, "train/cont_rate": 0.9944750642123288, "train/dyn_loss_mean": 2.903910144823327, "train/dyn_loss_std": 7.8572232538162305, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.373260756333669, "train/extr_critic_critic_opt_grad_steps": 63780.0, "train/extr_critic_critic_opt_loss": 15762.986172053368, "train/extr_critic_mag": 16.461661303968736, "train/extr_critic_max": 16.461661303968736, "train/extr_critic_mean": 2.7364940980798034, "train/extr_critic_min": -0.7526797660409588, "train/extr_critic_std": 2.918621294030316, "train/extr_return_normed_mag": 1.7838369248664543, "train/extr_return_normed_max": 1.7838369248664543, "train/extr_return_normed_mean": 0.3249193664010801, "train/extr_return_normed_min": -0.11441553789765051, "train/extr_return_normed_std": 0.313886952862892, "train/extr_return_rate": 0.8405186163780352, "train/extr_return_raw_mag": 16.512126935671454, "train/extr_return_raw_max": 16.512126935671454, "train/extr_return_raw_mean": 2.751065966201155, "train/extr_return_raw_min": -1.3915551762058311, "train/extr_return_raw_std": 2.9758975620139134, "train/extr_reward_mag": 1.0205084314085033, "train/extr_reward_max": 1.0205084314085033, "train/extr_reward_mean": 0.026039489468381014, "train/extr_reward_min": -0.6773775086555307, "train/extr_reward_std": 0.1624290625390397, "train/image_loss_mean": 1.6444181745455144, "train/image_loss_std": 4.809574053167752, "train/model_loss_mean": 3.4218716915339638, "train/model_loss_std": 8.659865993342988, "train/model_opt_grad_norm": 31.70105963319404, "train/model_opt_grad_steps": 63724.4200913242, "train/model_opt_loss": 5266.740998011202, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1535.3881278538813, "train/policy_entropy_mag": 2.471210700736198, "train/policy_entropy_max": 2.471210700736198, "train/policy_entropy_mean": 0.590842411534427, "train/policy_entropy_min": 0.07937501391319379, "train/policy_entropy_std": 0.6156283086293364, "train/policy_logprob_mag": 7.438383836180107, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.590937486114023, "train/policy_logprob_min": -7.438383836180107, "train/policy_logprob_std": 1.1249303714325438, "train/policy_randomness_mag": 0.8722289327072771, "train/policy_randomness_max": 0.8722289327072771, "train/policy_randomness_mean": 0.20854144247427378, "train/policy_randomness_min": 0.02801589674601272, "train/policy_randomness_std": 0.21728977812751787, "train/post_ent_mag": 39.373494048096816, "train/post_ent_max": 39.373494048096816, "train/post_ent_mean": 20.74976932403704, "train/post_ent_min": 11.580892885112327, "train/post_ent_std": 3.805014218369575, "train/prior_ent_mag": 75.52024538223057, "train/prior_ent_max": 75.52024538223057, "train/prior_ent_mean": 23.689402950408795, "train/prior_ent_min": 12.793727979268112, "train/prior_ent_std": 9.054420723762686, "train/rep_loss_mean": 2.903910144823327, "train/rep_loss_std": 7.8572232538162305, "train/reward_avg": 0.0185845639284479, "train/reward_loss_mean": 0.03509229081406441, "train/reward_loss_std": 0.16476945463380857, "train/reward_max_data": 1.0114155278358286, "train/reward_max_pred": 1.011567362911625, "train/reward_neg_acc": 0.9962327082951864, "train/reward_neg_loss": 0.018511337897906155, "train/reward_pos_acc": 0.9907502869492797, "train/reward_pos_loss": 0.721375142874783, "train/reward_pred": 0.018493141319823863, "train/reward_rate": 0.023575734874429224, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 2.4784458219073713e-07, "report/cont_loss_std": 1.3136030929672415e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.0704902706493158e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.6550553993965877e-07, "report/cont_pred": 0.9921874403953552, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 2.7127277851104736, "report/dyn_loss_std": 7.726700782775879, "report/image_loss_mean": 1.4648244380950928, "report/image_loss_std": 4.057602405548096, "report/model_loss_mean": 3.1313576698303223, "report/model_loss_std": 7.526279449462891, "report/post_ent_mag": 41.85881805419922, "report/post_ent_max": 41.85881805419922, "report/post_ent_mean": 20.788135528564453, "report/post_ent_min": 12.004151344299316, "report/post_ent_std": 3.620056629180908, "report/prior_ent_mag": 75.89092254638672, "report/prior_ent_max": 75.89092254638672, "report/prior_ent_mean": 23.436065673828125, "report/prior_ent_min": 12.858721733093262, "report/prior_ent_std": 9.14748764038086, "report/rep_loss_mean": 2.7127277851104736, "report/rep_loss_std": 7.726700782775879, "report/reward_avg": 0.0302734375, "report/reward_loss_mean": 0.03889625519514084, "report/reward_loss_std": 0.14929600059986115, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0030162334442139, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.01572686806321144, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6747671961784363, "report/reward_pred": 0.030277756974101067, "report/reward_rate": 0.03515625, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 3.7215165775705827e-06, "eval/cont_loss_std": 0.00011201019515283406, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0017990473425015807, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.081585819269094e-07, "eval/cont_pred": 0.9980502128601074, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 26.023040771484375, "eval/dyn_loss_std": 13.122806549072266, "eval/image_loss_mean": 45.017555236816406, "eval/image_loss_std": 46.38197708129883, "eval/model_loss_mean": 60.78058624267578, "eval/model_loss_std": 50.83333206176758, "eval/post_ent_mag": 38.15182113647461, "eval/post_ent_max": 38.15182113647461, "eval/post_ent_mean": 26.077964782714844, "eval/post_ent_min": 16.511554718017578, "eval/post_ent_std": 3.2829949855804443, "eval/prior_ent_mag": 75.89092254638672, "eval/prior_ent_max": 75.89092254638672, "eval/prior_ent_mean": 35.37677001953125, "eval/prior_ent_min": 16.680885314941406, "eval/prior_ent_std": 8.582847595214844, "eval/rep_loss_mean": 26.023040771484375, "eval/rep_loss_std": 13.122806549072266, "eval/reward_avg": 0.01728515513241291, "eval/reward_loss_mean": 0.14920642971992493, "eval/reward_loss_std": 0.9588409662246704, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0012335777282715, "eval/reward_neg_acc": 0.9940239191055298, "eval/reward_neg_loss": 0.09165243804454803, "eval/reward_pos_acc": 0.6000000238418579, "eval/reward_pos_loss": 3.038417339324951, "eval/reward_pred": 0.014586704783141613, "eval/reward_rate": 0.01953125, "replay/size": 65931.0, "replay/inserts": 2189.0, "replay/samples": 35024.0, "replay/insert_wait_avg": 2.5948306206101532e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.78910720549854e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 13800.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 8.791685104370117e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2078638076782, "timer/env.step_count": 274.0, "timer/env.step_total": 24.185651302337646, "timer/env.step_frac": 0.024180625025547797, "timer/env.step_avg": 0.08826880037349506, "timer/env.step_min": 0.02304530143737793, "timer/env.step_max": 2.0208840370178223, "timer/replay._sample_count": 35024.0, "timer/replay._sample_total": 17.408008337020874, "timer/replay._sample_frac": 0.01740439059412166, "timer/replay._sample_avg": 0.0004970308456207421, "timer/replay._sample_min": 0.0003654956817626953, "timer/replay._sample_max": 0.04211020469665527, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 274.0, "timer/agent.policy_total": 4.3641273975372314, "timer/agent.policy_frac": 0.004363220441922434, "timer/agent.policy_avg": 0.015927472253785515, "timer/agent.policy_min": 0.009767770767211914, "timer/agent.policy_max": 0.0410764217376709, "timer/dataset_train_count": 2189.0, "timer/dataset_train_total": 0.39447879791259766, "timer/dataset_train_frac": 0.0003943968170884615, "timer/dataset_train_avg": 0.00018020959246806655, "timer/dataset_train_min": 9.34600830078125e-05, "timer/dataset_train_max": 0.0006401538848876953, "timer/agent.train_count": 2189.0, "timer/agent.train_total": 969.4224967956543, "timer/agent.train_frac": 0.9692210308217059, "timer/agent.train_avg": 0.44286089392218103, "timer/agent.train_min": 0.4334385395050049, "timer/agent.train_max": 0.5590167045593262, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4746737480163574, "timer/agent.report_frac": 0.0004745751010288283, "timer/agent.report_avg": 0.2373368740081787, "timer/agent.report_min": 0.2297658920288086, "timer/agent.report_max": 0.24490785598754883, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7894973754882812e-05, "timer/dataset_eval_frac": 2.7889176604440804e-08, "timer/dataset_eval_avg": 2.7894973754882812e-05, "timer/dataset_eval_min": 2.7894973754882812e-05, "timer/dataset_eval_max": 2.7894973754882812e-05, "fps": 2.1885172154306813}
{"step": 66456, "time": 30321.657101869583, "episode/length": 177.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9662921348314607, "episode/intrinsic_return": 0.0}
{"step": 66864, "time": 30507.41035938263, "episode/length": 229.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 66904, "time": 30527.03413128853, "episode/length": 173.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 67048, "time": 30593.841046094894, "episode/length": 217.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 67128, "time": 30631.549986839294, "episode/length": 83.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 67136, "time": 30636.6644384861, "episode/length": 186.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9679144385026738, "episode/intrinsic_return": 0.0}
{"step": 67192, "time": 30663.495822429657, "episode/length": 40.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 67240, "time": 30686.65434074402, "episode/length": 192.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 67416, "time": 30767.5844039917, "episode/length": 224.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 68192, "time": 31119.475110292435, "episode/length": 223.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 68240, "time": 31143.284428358078, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 68352, "time": 31195.28031349182, "episode/length": 152.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 68606, "time": 31312.250772476196, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.521786175565236, "train/action_min": 0.0, "train/action_std": 4.18517940385001, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04497824417006585, "train/actor_opt_grad_steps": 65960.0, "train/actor_opt_loss": -6.2138936276062635, "train/adv_mag": 0.9584841877908751, "train/adv_max": 0.8921428421675335, "train/adv_mean": 0.003626886462014495, "train/adv_min": -0.6911393605893658, "train/adv_std": 0.059225670838822964, "train/cont_avg": 0.9944781466013825, "train/cont_loss_mean": 1.6439703223919898e-05, "train/cont_loss_std": 0.0003797647085886223, "train/cont_neg_acc": 1.0, "train/cont_neg_loss": 0.0009282558756099772, "train/cont_pos_acc": 0.999999981047371, "train/cont_pos_loss": 1.0540323077084541e-05, "train/cont_pred": 0.9944737984837475, "train/cont_rate": 0.9944781466013825, "train/dyn_loss_mean": 2.924196566304853, "train/dyn_loss_std": 7.775118601486979, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.4009321018847452, "train/extr_critic_critic_opt_grad_steps": 65960.0, "train/extr_critic_critic_opt_loss": 15952.956225698445, "train/extr_critic_mag": 17.506230138963268, "train/extr_critic_max": 17.506230138963268, "train/extr_critic_mean": 2.8082606545241746, "train/extr_critic_min": -0.7149858282458398, "train/extr_critic_std": 2.8487035420633133, "train/extr_return_normed_mag": 1.9311691550065846, "train/extr_return_normed_max": 1.9311691550065846, "train/extr_return_normed_mean": 0.3373036544581163, "train/extr_return_normed_min": -0.09446423912789964, "train/extr_return_normed_std": 0.3156663272787349, "train/extr_return_rate": 0.7998479319058256, "train/extr_return_raw_mag": 17.610242905155307, "train/extr_return_raw_max": 17.610242905155307, "train/extr_return_raw_mean": 2.8417682752081874, "train/extr_return_raw_min": -1.1552356918286617, "train/extr_return_raw_std": 2.923059842553556, "train/extr_reward_mag": 1.032285502429382, "train/extr_reward_max": 1.032285502429382, "train/extr_reward_mean": 0.02695256972917214, "train/extr_reward_min": -0.6741491995648854, "train/extr_reward_std": 0.16413403645775834, "train/image_loss_mean": 1.7165735872110464, "train/image_loss_std": 4.952081274327045, "train/model_loss_mean": 3.506340579503143, "train/model_loss_std": 8.7158203476585, "train/model_opt_grad_norm": 34.477717443545295, "train/model_opt_grad_steps": 65902.6728110599, "train/model_opt_loss": 6475.322483888969, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1860.5990783410139, "train/policy_entropy_mag": 2.4719306543675437, "train/policy_entropy_max": 2.4719306543675437, "train/policy_entropy_mean": 0.5825415162996213, "train/policy_entropy_min": 0.07937501374340278, "train/policy_entropy_std": 0.6141396192361682, "train/policy_logprob_mag": 7.438383823166245, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5834691856863312, "train/policy_logprob_min": -7.438383823166245, "train/policy_logprob_std": 1.1227356184462798, "train/policy_randomness_mag": 0.872483042528003, "train/policy_randomness_max": 0.872483042528003, "train/policy_randomness_mean": 0.2056115933002964, "train/policy_randomness_min": 0.028015896686554506, "train/policy_randomness_std": 0.21676433525876515, "train/post_ent_mag": 39.773939932546305, "train/post_ent_max": 39.773939932546305, "train/post_ent_mean": 21.05559335875621, "train/post_ent_min": 11.654437763899702, "train/post_ent_std": 3.8581884940099056, "train/prior_ent_mag": 75.66120365687779, "train/prior_ent_max": 75.66120365687779, "train/prior_ent_mean": 24.004333645517377, "train/prior_ent_min": 12.842418951922298, "train/prior_ent_std": 9.076374102298017, "train/rep_loss_mean": 2.924196566304853, "train/rep_loss_std": 7.775118601486979, "train/reward_avg": 0.019221630031114212, "train/reward_loss_mean": 0.03523260968724429, "train/reward_loss_std": 0.16350358841331325, "train/reward_max_data": 1.0188940137212728, "train/reward_max_pred": 1.0200192126260925, "train/reward_neg_acc": 0.996291338573403, "train/reward_neg_loss": 0.018205451536580302, "train/reward_pos_acc": 0.9904263665049856, "train/reward_pos_loss": 0.723066508769989, "train/reward_pred": 0.019103804283479256, "train/reward_rate": 0.024171046947004608, "train_stats/sum_log_reward": 3.9333332863946757, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 3.0, "train_stats/max_log_achievement_collect_sapling": 1.4166666666666667, "train_stats/max_log_achievement_collect_stone": 0.08333333333333333, "train_stats/max_log_achievement_collect_wood": 1.8333333333333333, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.25, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.3333333333333333, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 0.5833333333333334, "train_stats/max_log_achievement_wake_up": 1.25, "train_stats/mean_log_entropy": 0.5263519361615181, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 7.455458217009436e-06, "report/cont_loss_std": 0.0001325083285337314, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0007322089513763785, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 2.4669882350281114e-06, "report/cont_pred": 0.9931666254997253, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 3.8058228492736816, "report/dyn_loss_std": 8.22787094116211, "report/image_loss_mean": 1.905688762664795, "report/image_loss_std": 3.9324886798858643, "report/model_loss_mean": 4.214856147766113, "report/model_loss_std": 8.017574310302734, "report/post_ent_mag": 43.19084167480469, "report/post_ent_max": 43.19084167480469, "report/post_ent_mean": 22.1702880859375, "report/post_ent_min": 11.29600715637207, "report/post_ent_std": 4.076721668243408, "report/prior_ent_mag": 75.49475860595703, "report/prior_ent_max": 75.49475860595703, "report/prior_ent_mean": 25.75993537902832, "report/prior_ent_min": 11.952866554260254, "report/prior_ent_std": 9.74945068359375, "report/rep_loss_mean": 3.8058228492736816, "report/rep_loss_std": 8.22787094116211, "report/reward_avg": 0.01347656175494194, "report/reward_loss_mean": 0.025666166096925735, "report/reward_loss_std": 0.12087158858776093, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0018041133880615, "report/reward_neg_acc": 0.9970149993896484, "report/reward_neg_loss": 0.013560695573687553, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6659818291664124, "report/reward_pred": 0.01367639284580946, "report/reward_rate": 0.0185546875, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.003707579569891095, "eval/cont_loss_std": 0.10258558392524719, "eval/cont_neg_acc": 0.8333333730697632, "eval/cont_neg_loss": 0.6323873996734619, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.197675485149375e-06, "eval/cont_pred": 0.9954993724822998, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 24.840106964111328, "eval/dyn_loss_std": 13.387195587158203, "eval/image_loss_mean": 35.719364166259766, "eval/image_loss_std": 35.64623260498047, "eval/model_loss_mean": 50.850467681884766, "eval/model_loss_std": 40.90779113769531, "eval/post_ent_mag": 43.19084167480469, "eval/post_ent_max": 43.19084167480469, "eval/post_ent_mean": 26.261489868164062, "eval/post_ent_min": 16.609174728393555, "eval/post_ent_std": 3.360562801361084, "eval/prior_ent_mag": 75.49475860595703, "eval/prior_ent_max": 75.49475860595703, "eval/prior_ent_mean": 34.26055145263672, "eval/prior_ent_min": 14.665865898132324, "eval/prior_ent_std": 9.21011734008789, "eval/rep_loss_mean": 24.840106964111328, "eval/rep_loss_std": 13.387195587158203, "eval/reward_avg": 0.01689453050494194, "eval/reward_loss_mean": 0.22333483397960663, "eval/reward_loss_std": 1.242468237876892, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0017733573913574, "eval/reward_neg_acc": 0.9979979991912842, "eval/reward_neg_loss": 0.13615921139717102, "eval/reward_pos_acc": 0.5600000023841858, "eval/reward_pos_loss": 3.7068724632263184, "eval/reward_pred": 0.009168842807412148, "eval/reward_rate": 0.0244140625, "replay/size": 68102.0, "replay/inserts": 2171.0, "replay/samples": 34736.0, "replay/insert_wait_avg": 2.620737435135738e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.984098450262279e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 13800.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 1.0132789611816406e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2294340133667, "timer/env.step_count": 271.0, "timer/env.step_total": 25.866790056228638, "timer/env.step_frac": 0.025860856696087755, "timer/env.step_avg": 0.09544940980158169, "timer/env.step_min": 0.023453474044799805, "timer/env.step_max": 1.9554388523101807, "timer/replay._sample_count": 34736.0, "timer/replay._sample_total": 18.112371683120728, "timer/replay._sample_frac": 0.01810821704220982, "timer/replay._sample_avg": 0.0005214294012874461, "timer/replay._sample_min": 0.0003681182861328125, "timer/replay._sample_max": 0.028643131256103516, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 271.0, "timer/agent.policy_total": 4.420319557189941, "timer/agent.policy_frac": 0.0044193056181656715, "timer/agent.policy_avg": 0.016311142277453658, "timer/agent.policy_min": 0.01007699966430664, "timer/agent.policy_max": 0.04145216941833496, "timer/dataset_train_count": 2171.0, "timer/dataset_train_total": 0.39820146560668945, "timer/dataset_train_frac": 0.00039811012560281046, "timer/dataset_train_avg": 0.00018341845490865474, "timer/dataset_train_min": 9.512901306152344e-05, "timer/dataset_train_max": 0.0008096694946289062, "timer/agent.train_count": 2171.0, "timer/agent.train_total": 967.5441527366638, "timer/agent.train_frac": 0.967322216118401, "timer/agent.train_avg": 0.4456675047151837, "timer/agent.train_min": 0.43324780464172363, "timer/agent.train_max": 0.5699427127838135, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4765198230743408, "timer/agent.report_frac": 0.0004764105182971178, "timer/agent.report_avg": 0.2382599115371704, "timer/agent.report_min": 0.23088455200195312, "timer/agent.report_max": 0.2456352710723877, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.1948089599609375e-05, "timer/dataset_eval_frac": 3.1940761302553744e-08, "timer/dataset_eval_avg": 3.1948089599609375e-05, "timer/dataset_eval_min": 3.1948089599609375e-05, "timer/dataset_eval_max": 3.1948089599609375e-05, "fps": 2.1704737831232412}
{"step": 68720, "time": 31364.098541259766, "episode/length": 65.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9848484848484849, "episode/intrinsic_return": 0.0}
{"step": 68792, "time": 31397.953043937683, "episode/length": 171.0, "episode/score": 2.0999999940395355, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 68800, "time": 31403.017931461334, "episode/length": 207.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 68848, "time": 31426.06386232376, "episode/length": 200.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 68976, "time": 31485.057054519653, "episode/length": 222.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 69024, "time": 31508.20488667488, "episode/length": 246.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9838056680161943, "episode/intrinsic_return": 0.0}
{"step": 69856, "time": 31882.69052171707, "episode/length": 201.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 69992, "time": 31944.936285495758, "episode/length": 149.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 70096, "time": 31993.15692973137, "episode/length": 217.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 70096, "time": 32009.807346582413, "eval_episode/length": 112.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9469026548672567}
{"step": 70096, "time": 32013.24907398224, "eval_episode/length": 161.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.9691358024691358}
{"step": 70096, "time": 32014.919451475143, "eval_episode/length": 164.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9696969696969697}
{"step": 70096, "time": 32016.45377755165, "eval_episode/length": 167.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9940476190476191}
{"step": 70096, "time": 32018.525911331177, "eval_episode/length": 182.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.994535519125683}
{"step": 70096, "time": 32020.571668624878, "eval_episode/length": 196.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9949238578680203}
{"step": 70096, "time": 32020.58048415184, "eval_episode/length": 196.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9593908629441624}
{"step": 70096, "time": 32025.04043197632, "eval_episode/length": 227.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9956140350877193}
{"step": 70136, "time": 32044.53366613388, "episode/length": 166.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 70256, "time": 32099.807461500168, "episode/length": 175.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 70320, "time": 32130.11613345146, "episode/length": 167.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 70624, "time": 32267.8429377079, "episode/length": 199.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 70718, "time": 32312.48648905754, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.72036526214455, "train/action_min": 0.0, "train/action_std": 4.238142221459845, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04180136626648112, "train/actor_opt_grad_steps": 68100.0, "train/actor_opt_loss": -14.641026385799403, "train/adv_mag": 0.6954557676733387, "train/adv_max": 0.6451875214328133, "train/adv_mean": 0.0025777223688767605, "train/adv_min": -0.5508176656130931, "train/adv_std": 0.053255682714036294, "train/cont_avg": 0.9942702162322274, "train/cont_loss_mean": 2.0687087685452117e-05, "train/cont_loss_std": 0.0006083413861018855, "train/cont_neg_acc": 1.0, "train/cont_neg_loss": 0.0012666310055585838, "train/cont_pos_acc": 0.999986017767287, "train/cont_pos_loss": 1.4843762275130097e-05, "train/cont_pred": 0.9942643831691471, "train/cont_rate": 0.9942702162322274, "train/dyn_loss_mean": 2.913633346557617, "train/dyn_loss_std": 7.819068671402773, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.3321060010042236, "train/extr_critic_critic_opt_grad_steps": 68100.0, "train/extr_critic_critic_opt_loss": 15593.453573941055, "train/extr_critic_mag": 14.810413039691076, "train/extr_critic_max": 14.810413039691076, "train/extr_critic_mean": 3.148469026054816, "train/extr_critic_min": -0.6787685675643632, "train/extr_critic_std": 2.999250444755735, "train/extr_return_normed_mag": 1.5652643498651224, "train/extr_return_normed_max": 1.5652643498651224, "train/extr_return_normed_mean": 0.3459330117109263, "train/extr_return_normed_min": -0.09055639464425815, "train/extr_return_normed_std": 0.3128985134769955, "train/extr_return_rate": 0.803337325417035, "train/extr_return_raw_mag": 15.152614462432139, "train/extr_return_raw_max": 15.152614462432139, "train/extr_return_raw_mean": 3.173968862583287, "train/extr_return_raw_min": -1.110179136149691, "train/extr_return_raw_std": 3.069628395175482, "train/extr_reward_mag": 1.0288368582160552, "train/extr_reward_max": 1.0288368582160552, "train/extr_reward_mean": 0.028758275953796802, "train/extr_reward_min": -0.6840482108400896, "train/extr_reward_std": 0.16955621533484255, "train/image_loss_mean": 1.7037756733984744, "train/image_loss_std": 5.009750865647013, "train/model_loss_mean": 3.4878587914869117, "train/model_loss_std": 8.792237679540264, "train/model_opt_grad_norm": 32.011616964475806, "train/model_opt_grad_steps": 68040.8672985782, "train/model_opt_loss": 6981.604123083901, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1996.4454976303318, "train/policy_entropy_mag": 2.446674244098754, "train/policy_entropy_max": 2.446674244098754, "train/policy_entropy_mean": 0.5653590970977223, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.5947525560573379, "train/policy_logprob_mag": 7.438383861740618, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5650840983571599, "train/policy_logprob_min": -7.438383861740618, "train/policy_logprob_std": 1.1083768159857292, "train/policy_randomness_mag": 0.8635686390207842, "train/policy_randomness_max": 0.8635686390207842, "train/policy_randomness_mean": 0.1995469514651321, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.20992155401345114, "train/post_ent_mag": 40.14614881723413, "train/post_ent_max": 40.14614881723413, "train/post_ent_mean": 21.146512985229492, "train/post_ent_min": 11.72693763299011, "train/post_ent_std": 3.8314286216175386, "train/prior_ent_mag": 75.68646149838705, "train/prior_ent_max": 75.68646149838705, "train/prior_ent_mean": 24.077121996766582, "train/prior_ent_min": 12.919511144195123, "train/prior_ent_std": 9.058739915278286, "train/rep_loss_mean": 2.913633346557617, "train/rep_loss_std": 7.819068671402773, "train/reward_avg": 0.018752776900685934, "train/reward_loss_mean": 0.035882437133817315, "train/reward_loss_std": 0.16433963207836966, "train/reward_max_data": 1.0137440791062269, "train/reward_max_pred": 1.0141685969456677, "train/reward_neg_acc": 0.9963097835039075, "train/reward_neg_loss": 0.019155815938902553, "train/reward_pos_acc": 0.9904500511585254, "train/reward_pos_loss": 0.7160134852215012, "train/reward_pred": 0.018659997742481848, "train/reward_rate": 0.023983634478672987, "train_stats/sum_log_reward": 3.7923076416437445, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 2.1538461538461537, "train_stats/max_log_achievement_collect_sapling": 1.2307692307692308, "train_stats/max_log_achievement_collect_stone": 0.23076923076923078, "train_stats/max_log_achievement_collect_wood": 2.1538461538461537, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.07692307692307693, "train_stats/max_log_achievement_make_wood_pickaxe": 0.23076923076923078, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.2307692307692308, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 0.8461538461538461, "train_stats/max_log_achievement_wake_up": 1.7692307692307692, "train_stats/mean_log_entropy": 0.5258624874628507, "eval_stats/sum_log_reward": 3.599999964237213, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 2.625, "eval_stats/max_log_achievement_collect_sapling": 2.25, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 1.25, "eval_stats/max_log_achievement_defeat_zombie": 0.125, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.25, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 0.375, "eval_stats/max_log_achievement_wake_up": 1.75, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 2.0224833860993385e-06, "report/cont_loss_std": 4.363108382676728e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00024241305072791874, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 6.056429242562444e-07, "report/cont_pred": 0.9941415190696716, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 2.6281800270080566, "report/dyn_loss_std": 7.949962615966797, "report/image_loss_mean": 1.2539883852005005, "report/image_loss_std": 3.5353095531463623, "report/model_loss_mean": 2.867143392562866, "report/model_loss_std": 7.5533223152160645, "report/post_ent_mag": 40.983299255371094, "report/post_ent_max": 40.983299255371094, "report/post_ent_mean": 20.672210693359375, "report/post_ent_min": 12.452629089355469, "report/post_ent_std": 3.7797224521636963, "report/prior_ent_mag": 75.59552001953125, "report/prior_ent_max": 75.59552001953125, "report/prior_ent_mean": 23.34794044494629, "report/prior_ent_min": 13.115499496459961, "report/prior_ent_std": 9.012246131896973, "report/rep_loss_mean": 2.6281800270080566, "report/rep_loss_std": 7.949962615966797, "report/reward_avg": 0.01953125, "report/reward_loss_mean": 0.036244891583919525, "report/reward_loss_std": 0.16218282282352448, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0030224323272705, "report/reward_neg_acc": 0.9949899911880493, "report/reward_neg_loss": 0.01847922056913376, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7181732654571533, "report/reward_pred": 0.01896796002984047, "report/reward_rate": 0.025390625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.0031111317221075296, "eval/cont_loss_std": 0.09947771579027176, "eval/cont_neg_acc": 0.6666666865348816, "eval/cont_neg_loss": 1.0616471767425537, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 8.401047466577438e-07, "eval/cont_pred": 0.998005747795105, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 22.874027252197266, "eval/dyn_loss_std": 12.937952995300293, "eval/image_loss_mean": 41.8068733215332, "eval/image_loss_std": 47.56168746948242, "eval/model_loss_mean": 55.625732421875, "eval/model_loss_std": 51.57240676879883, "eval/post_ent_mag": 37.187110900878906, "eval/post_ent_max": 37.187110900878906, "eval/post_ent_mean": 26.877792358398438, "eval/post_ent_min": 14.27018928527832, "eval/post_ent_std": 3.6338677406311035, "eval/prior_ent_mag": 75.59552001953125, "eval/prior_ent_max": 75.59552001953125, "eval/prior_ent_mean": 35.3353157043457, "eval/prior_ent_min": 16.784465789794922, "eval/prior_ent_std": 9.233076095581055, "eval/rep_loss_mean": 22.874027252197266, "eval/rep_loss_std": 12.937952995300293, "eval/reward_avg": 0.01171875, "eval/reward_loss_mean": 0.09133417904376984, "eval/reward_loss_std": 0.665804922580719, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.010848045349121, "eval/reward_neg_acc": 0.99702388048172, "eval/reward_neg_loss": 0.06861940026283264, "eval/reward_pos_acc": 0.875, "eval/reward_pos_loss": 1.522365927696228, "eval/reward_pred": 0.010998171754181385, "eval/reward_rate": 0.015625, "replay/size": 70214.0, "replay/inserts": 2112.0, "replay/samples": 33792.0, "replay/insert_wait_avg": 2.6326513651645547e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.97296789559451e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 15624.0, "eval_replay/inserts": 1824.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0794192029718767e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0281801223754883e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2239384651184, "timer/env.step_count": 264.0, "timer/env.step_total": 26.64465093612671, "timer/env.step_frac": 0.026638685509780876, "timer/env.step_avg": 0.10092670809138905, "timer/env.step_min": 0.0230410099029541, "timer/env.step_max": 1.9555785655975342, "timer/replay._sample_count": 33792.0, "timer/replay._sample_total": 16.970091104507446, "timer/replay._sample_frac": 0.01696629169918558, "timer/replay._sample_avg": 0.0005021925634619864, "timer/replay._sample_min": 0.0003752708435058594, "timer/replay._sample_max": 0.02199411392211914, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 492.0, "timer/agent.policy_total": 7.642935037612915, "timer/agent.policy_frac": 0.00764122387366702, "timer/agent.policy_avg": 0.015534420808156332, "timer/agent.policy_min": 0.009402275085449219, "timer/agent.policy_max": 0.04705190658569336, "timer/dataset_train_count": 2112.0, "timer/dataset_train_total": 0.42502593994140625, "timer/dataset_train_frac": 0.0004249307815943944, "timer/dataset_train_avg": 0.00020124334277528706, "timer/dataset_train_min": 9.393692016601562e-05, "timer/dataset_train_max": 0.044806480407714844, "timer/agent.train_count": 2112.0, "timer/agent.train_total": 935.3397121429443, "timer/agent.train_frac": 0.9351303004987649, "timer/agent.train_avg": 0.44286918188586377, "timer/agent.train_min": 0.432553768157959, "timer/agent.train_max": 0.5647866725921631, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47351837158203125, "timer/agent.report_frac": 0.00047341235634558313, "timer/agent.report_avg": 0.23675918579101562, "timer/agent.report_min": 0.2307758331298828, "timer/agent.report_max": 0.24274253845214844, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.2901763916015625e-05, "timer/dataset_eval_frac": 3.2894397595107185e-08, "timer/dataset_eval_avg": 3.2901763916015625e-05, "timer/dataset_eval_min": 3.2901763916015625e-05, "timer/dataset_eval_max": 3.2901763916015625e-05, "fps": 2.111501335174904}
{"step": 71264, "time": 32557.520034074783, "episode/length": 158.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 71320, "time": 32584.147975206375, "episode/length": 182.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9672131147540983, "episode/intrinsic_return": 0.0}
{"step": 71344, "time": 32596.383805513382, "episode/length": 327.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9786585365853658, "episode/intrinsic_return": 0.0}
{"step": 71496, "time": 32665.90705513954, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 71600, "time": 32713.968997001648, "episode/length": 182.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 71744, "time": 32780.04517245293, "episode/length": 185.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 71752, "time": 32785.20469212532, "episode/length": 178.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 71984, "time": 32890.55737090111, "episode/length": 169.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 72536, "time": 33139.12660694122, "episode/length": 148.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 72632, "time": 33184.24695968628, "episode/length": 163.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 72672, "time": 33203.67517924309, "episode/length": 175.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 72911, "time": 33312.84867143631, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.586729847301136, "train/action_min": 0.0, "train/action_std": 4.207129753719677, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03975134270096367, "train/actor_opt_grad_steps": 70255.0, "train/actor_opt_loss": -16.289366014166312, "train/adv_mag": 0.6122285214337435, "train/adv_max": 0.5525171330029314, "train/adv_mean": 0.0008730611163628055, "train/adv_min": -0.5062932445244356, "train/adv_std": 0.04844438777389851, "train/cont_avg": 0.9943314985795455, "train/cont_loss_mean": 3.962017193314631e-05, "train/cont_loss_std": 0.0012081755709402841, "train/cont_neg_acc": 0.9983333335681395, "train/cont_neg_loss": 0.005267369651742435, "train/cont_pos_acc": 0.9999955025586215, "train/cont_pos_loss": 9.121594266338981e-06, "train/cont_pred": 0.9943344211036509, "train/cont_rate": 0.9943314985795455, "train/dyn_loss_mean": 2.8635906360366126, "train/dyn_loss_std": 7.734126656705683, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.297607326236638, "train/extr_critic_critic_opt_grad_steps": 70255.0, "train/extr_critic_critic_opt_loss": 15328.375306285512, "train/extr_critic_mag": 13.45627983266657, "train/extr_critic_max": 13.45627983266657, "train/extr_critic_mean": 2.917491882497614, "train/extr_critic_min": -0.7216918961568313, "train/extr_critic_std": 2.9823569758371873, "train/extr_return_normed_mag": 1.4622394957325675, "train/extr_return_normed_max": 1.4622394957325675, "train/extr_return_normed_mean": 0.3325302244587378, "train/extr_return_normed_min": -0.09920886783775958, "train/extr_return_normed_std": 0.3142824226482348, "train/extr_return_rate": 0.7868232545527545, "train/extr_return_raw_mag": 13.787920292941006, "train/extr_return_raw_max": 13.787920292941006, "train/extr_return_raw_mean": 2.925996192476966, "train/extr_return_raw_min": -1.2233494739640842, "train/extr_return_raw_std": 3.0212405529889192, "train/extr_reward_mag": 1.0294385346499357, "train/extr_reward_max": 1.0294385346499357, "train/extr_reward_mean": 0.029650782836093143, "train/extr_reward_min": -0.6746732354164123, "train/extr_reward_std": 0.17210835333574903, "train/image_loss_mean": 1.5914796634153887, "train/image_loss_std": 4.599805107441815, "train/model_loss_mean": 3.3450771234252237, "train/model_loss_std": 8.340778012709183, "train/model_opt_grad_norm": 33.4371836588263, "train/model_opt_grad_steps": 70193.4909090909, "train/model_opt_loss": 4548.29550670277, "train/model_opt_model_opt_grad_overflow": 0.004545454545454545, "train/model_opt_model_opt_grad_scale": 1357.9545454545455, "train/policy_entropy_mag": 2.485152896967801, "train/policy_entropy_max": 2.485152896967801, "train/policy_entropy_mean": 0.5837559481913394, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6177263765172525, "train/policy_logprob_mag": 7.43838385885412, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5838029723275792, "train/policy_logprob_min": -7.43838385885412, "train/policy_logprob_std": 1.1181500245224345, "train/policy_randomness_mag": 0.8771499167789113, "train/policy_randomness_max": 0.8771499167789113, "train/policy_randomness_mean": 0.20604023161259563, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.2180303041907874, "train/post_ent_mag": 40.404062609239055, "train/post_ent_max": 40.404062609239055, "train/post_ent_mean": 21.330844541029496, "train/post_ent_min": 11.855347043817693, "train/post_ent_std": 3.8295802929184655, "train/prior_ent_mag": 75.79376210299405, "train/prior_ent_max": 75.79376210299405, "train/prior_ent_mean": 24.216454124450685, "train/prior_ent_min": 12.965979233655062, "train/prior_ent_std": 9.027938964150168, "train/rep_loss_mean": 2.8635906360366126, "train/rep_loss_std": 7.734126656705683, "train/reward_avg": 0.01961248207583346, "train/reward_loss_mean": 0.03540345798669891, "train/reward_loss_std": 0.16239982663907787, "train/reward_max_data": 1.0159090947021137, "train/reward_max_pred": 1.0165925323963165, "train/reward_neg_acc": 0.9965441812168468, "train/reward_neg_loss": 0.018215634261088614, "train/reward_pos_acc": 0.990473466298797, "train/reward_pos_loss": 0.7188161045312882, "train/reward_pred": 0.01945403162601658, "train/reward_rate": 0.024596058238636365, "train_stats/sum_log_reward": 4.190908995541659, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 2.1818181818181817, "train_stats/max_log_achievement_collect_sapling": 2.3636363636363638, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 2.090909090909091, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.09090909090909091, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 2.3636363636363638, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 0.7272727272727273, "train_stats/max_log_achievement_wake_up": 1.5454545454545454, "train_stats/mean_log_entropy": 0.5550844208760695, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 2.048870783255552e-06, "report/cont_loss_std": 5.70286510992446e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 3.432704761507921e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 1.8267003270011628e-06, "report/cont_pred": 0.9931624531745911, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 2.8428902626037598, "report/dyn_loss_std": 8.07141399383545, "report/image_loss_mean": 1.4747991561889648, "report/image_loss_std": 6.0302252769470215, "report/model_loss_mean": 3.2150802612304688, "report/model_loss_std": 9.901911735534668, "report/post_ent_mag": 42.197120666503906, "report/post_ent_max": 42.197120666503906, "report/post_ent_mean": 21.057893753051758, "report/post_ent_min": 11.353975296020508, "report/post_ent_std": 4.483883380889893, "report/prior_ent_mag": 75.8106689453125, "report/prior_ent_max": 75.8106689453125, "report/prior_ent_mean": 24.024944305419922, "report/prior_ent_min": 12.884916305541992, "report/prior_ent_std": 9.42177677154541, "report/rep_loss_mean": 2.8428902626037598, "report/rep_loss_std": 8.07141399383545, "report/reward_avg": 0.00673828087747097, "report/reward_loss_mean": 0.03454508259892464, "report/reward_loss_std": 0.16366690397262573, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0000483989715576, "report/reward_neg_acc": 0.9990089535713196, "report/reward_neg_loss": 0.025043824687600136, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6736630201339722, "report/reward_pred": 0.006807711906731129, "report/reward_rate": 0.0146484375, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.00014192156959325075, "eval/cont_loss_std": 0.003843929385766387, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.04034719988703728, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.378656790824607e-05, "eval/cont_pred": 0.9971581697463989, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 22.95086669921875, "eval/dyn_loss_std": 13.160400390625, "eval/image_loss_mean": 29.647083282470703, "eval/image_loss_std": 36.379432678222656, "eval/model_loss_mean": 43.61878204345703, "eval/model_loss_std": 41.18135070800781, "eval/post_ent_mag": 37.9951057434082, "eval/post_ent_max": 37.9951057434082, "eval/post_ent_mean": 25.6417236328125, "eval/post_ent_min": 15.801636695861816, "eval/post_ent_std": 3.356520891189575, "eval/prior_ent_mag": 75.8106689453125, "eval/prior_ent_max": 75.8106689453125, "eval/prior_ent_mean": 34.65186309814453, "eval/prior_ent_min": 17.03310775756836, "eval/prior_ent_std": 9.547126770019531, "eval/rep_loss_mean": 22.95086669921875, "eval/rep_loss_std": 13.160400390625, "eval/reward_avg": 0.02255859412252903, "eval/reward_loss_mean": 0.2010345458984375, "eval/reward_loss_std": 1.3035730123519897, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.000643014907837, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.12428729981184006, "eval/reward_pos_acc": 0.6538462042808533, "eval/reward_pos_loss": 3.1469478607177734, "eval/reward_pred": 0.014473069459199905, "eval/reward_rate": 0.025390625, "replay/size": 72407.0, "replay/inserts": 2193.0, "replay/samples": 35088.0, "replay/insert_wait_avg": 2.6440218165754674e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.623170425616819e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 15624.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 8.046627044677734e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3529093265533, "timer/env.step_count": 274.0, "timer/env.step_total": 24.153987884521484, "timer/env.step_frac": 0.02414546672412056, "timer/env.step_avg": 0.08815324045445798, "timer/env.step_min": 0.023345470428466797, "timer/env.step_max": 2.0881452560424805, "timer/replay._sample_count": 35088.0, "timer/replay._sample_total": 17.282144784927368, "timer/replay._sample_frac": 0.017276047906495184, "timer/replay._sample_avg": 0.0004925371860729414, "timer/replay._sample_min": 0.0003657341003417969, "timer/replay._sample_max": 0.028490781784057617, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 274.0, "timer/agent.policy_total": 4.370056867599487, "timer/agent.policy_frac": 0.004368515177850034, "timer/agent.policy_avg": 0.01594911265547258, "timer/agent.policy_min": 0.00993037223815918, "timer/agent.policy_max": 0.050262451171875, "timer/dataset_train_count": 2193.0, "timer/dataset_train_total": 0.39246296882629395, "timer/dataset_train_frac": 0.0003923245138463221, "timer/dataset_train_avg": 0.0001789616820913333, "timer/dataset_train_min": 9.465217590332031e-05, "timer/dataset_train_max": 0.0007596015930175781, "timer/agent.train_count": 2193.0, "timer/agent.train_total": 969.7155365943909, "timer/agent.train_frac": 0.9693734356680306, "timer/agent.train_avg": 0.44218674719306467, "timer/agent.train_min": 0.43325138092041016, "timer/agent.train_max": 0.5585553646087646, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4745607376098633, "timer/agent.report_frac": 0.0004743933197828573, "timer/agent.report_avg": 0.23728036880493164, "timer/agent.report_min": 0.23065876960754395, "timer/agent.report_max": 0.24390196800231934, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8848648071289062e-05, "timer/dataset_eval_frac": 2.8838470706013374e-08, "timer/dataset_eval_avg": 2.8848648071289062e-05, "timer/dataset_eval_min": 2.8848648071289062e-05, "timer/dataset_eval_max": 2.8848648071289062e-05, "fps": 2.1921971192199914}
{"step": 72928, "time": 33320.68748450279, "episode/length": 178.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 73088, "time": 33393.9311439991, "episode/length": 166.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 73128, "time": 33413.47474813461, "episode/length": 190.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 73232, "time": 33461.472000837326, "episode/length": 185.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 73504, "time": 33585.0425992012, "episode/length": 189.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 73824, "time": 33731.21471309662, "episode/length": 160.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 73992, "time": 33808.10729980469, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 74016, "time": 33820.329810380936, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 74232, "time": 33918.539046764374, "episode/length": 162.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 74304, "time": 33952.18094086647, "episode/length": 151.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 74584, "time": 34079.26857495308, "episode/length": 181.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 74952, "time": 34245.98462319374, "episode/length": 214.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 75097, "time": 34313.291388750076, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.744595588894065, "train/action_min": 0.0, "train/action_std": 4.2110742013388816, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0405825129154762, "train/actor_opt_grad_steps": 72445.0, "train/actor_opt_loss": -14.612469425715437, "train/adv_mag": 0.6167287326187169, "train/adv_max": 0.5624677974969969, "train/adv_mean": 0.0018411441344429944, "train/adv_min": -0.4969804568575063, "train/adv_std": 0.049521962778830746, "train/cont_avg": 0.9945124354931193, "train/cont_loss_mean": 3.0222692326822512e-05, "train/cont_loss_std": 0.0009092832357243419, "train/cont_neg_acc": 0.9984709483767868, "train/cont_neg_loss": 0.004271683813700593, "train/cont_pos_acc": 0.9999999808608939, "train/cont_pos_loss": 5.136455219044803e-06, "train/cont_pred": 0.9945164527914939, "train/cont_rate": 0.9945124354931193, "train/dyn_loss_mean": 2.946587946436821, "train/dyn_loss_std": 7.867790121550954, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.3480020395112693, "train/extr_critic_critic_opt_grad_steps": 72445.0, "train/extr_critic_critic_opt_loss": 15633.559462801031, "train/extr_critic_mag": 12.618993728532704, "train/extr_critic_max": 12.618993728532704, "train/extr_critic_mean": 2.4804353276523976, "train/extr_critic_min": -0.7517520681433721, "train/extr_critic_std": 2.5963671612083363, "train/extr_return_normed_mag": 1.6072411641068416, "train/extr_return_normed_max": 1.6072411641068416, "train/extr_return_normed_mean": 0.337756262733302, "train/extr_return_normed_min": -0.12597062315689314, "train/extr_return_normed_std": 0.3199877957685278, "train/extr_return_rate": 0.727753825964184, "train/extr_return_raw_mag": 12.965505569353017, "train/extr_return_raw_max": 12.965505569353017, "train/extr_return_raw_mean": 2.4956821788341625, "train/extr_return_raw_min": -1.3286072272773182, "train/extr_return_raw_std": 2.639719638255758, "train/extr_reward_mag": 1.0329263669635178, "train/extr_reward_max": 1.0329263669635178, "train/extr_reward_mean": 0.029059256072403915, "train/extr_reward_min": -0.6873104490271402, "train/extr_reward_std": 0.17065664496990518, "train/image_loss_mean": 1.6812149890519064, "train/image_loss_std": 5.012680073396875, "train/model_loss_mean": 3.484501658229653, "train/model_loss_std": 8.829041437271538, "train/model_opt_grad_norm": 33.187805858227094, "train/model_opt_grad_steps": 72381.90825688074, "train/model_opt_loss": 6849.0616768653235, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1972.4770642201836, "train/policy_entropy_mag": 2.4882221200050565, "train/policy_entropy_max": 2.4882221200050565, "train/policy_entropy_mean": 0.6024942259996309, "train/policy_entropy_min": 0.0793750138457762, "train/policy_entropy_std": 0.6257381994243062, "train/policy_logprob_mag": 7.438383846107973, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.601444562504051, "train/policy_logprob_min": -7.438383846107973, "train/policy_logprob_std": 1.1288684207365054, "train/policy_randomness_mag": 0.8782332145839656, "train/policy_randomness_max": 0.8782332145839656, "train/policy_randomness_mean": 0.21265402128663632, "train/policy_randomness_min": 0.028015896720692105, "train/policy_randomness_std": 0.2208581241445804, "train/post_ent_mag": 40.39403938153468, "train/post_ent_max": 40.39403938153468, "train/post_ent_mean": 21.512334937349372, "train/post_ent_min": 11.93942054258574, "train/post_ent_std": 3.8867198950653776, "train/prior_ent_mag": 75.95097361573386, "train/prior_ent_max": 75.95097361573386, "train/prior_ent_mean": 24.447833866154383, "train/prior_ent_min": 13.133627821546082, "train/prior_ent_std": 9.078388179114105, "train/rep_loss_mean": 2.946587946436821, "train/rep_loss_std": 7.867790121550954, "train/reward_avg": 0.01910344382679654, "train/reward_loss_mean": 0.03530367813286705, "train/reward_loss_std": 0.16842178422786774, "train/reward_max_data": 1.014678902582291, "train/reward_max_pred": 1.0156517542830301, "train/reward_neg_acc": 0.9962733007899118, "train/reward_neg_loss": 0.018167808564345633, "train/reward_pos_acc": 0.9865130320054676, "train/reward_pos_loss": 0.731993769833801, "train/reward_pred": 0.018890542156541498, "train/reward_rate": 0.024055690940366973, "train_stats/sum_log_reward": 4.0999999443689985, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 1.5, "train_stats/max_log_achievement_collect_sapling": 1.9166666666666667, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 2.8333333333333335, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.08333333333333333, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.9166666666666667, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 1.25, "train_stats/max_log_achievement_wake_up": 1.8333333333333333, "train_stats/mean_log_entropy": 0.5620478962858518, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 4.341643216321245e-05, "report/cont_loss_std": 0.001290145912207663, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.01036965660750866, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 2.9213729249022435e-06, "report/cont_pred": 0.9961305856704712, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 2.7908332347869873, "report/dyn_loss_std": 8.185246467590332, "report/image_loss_mean": 1.4053200483322144, "report/image_loss_std": 4.166537761688232, "report/model_loss_mean": 3.111321449279785, "report/model_loss_std": 8.16421890258789, "report/post_ent_mag": 35.033851623535156, "report/post_ent_max": 35.033851623535156, "report/post_ent_mean": 20.608509063720703, "report/post_ent_min": 9.859579086303711, "report/post_ent_std": 3.7448415756225586, "report/prior_ent_mag": 76.11016082763672, "report/prior_ent_max": 76.11016082763672, "report/prior_ent_mean": 23.42195701599121, "report/prior_ent_min": 12.261308670043945, "report/prior_ent_std": 8.813941955566406, "report/rep_loss_mean": 2.7908332347869873, "report/rep_loss_std": 8.185246467590332, "report/reward_avg": 0.01777343824505806, "report/reward_loss_mean": 0.031458064913749695, "report/reward_loss_std": 0.15506651997566223, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0006442070007324, "report/reward_neg_acc": 0.9990019798278809, "report/reward_neg_loss": 0.01522057969123125, "report/reward_pos_acc": 0.9545454978942871, "report/reward_pos_loss": 0.7710016369819641, "report/reward_pred": 0.017224961891770363, "report/reward_rate": 0.021484375, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 2.42566366068786e-05, "eval/cont_loss_std": 0.00048682940541766584, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.004394238349050283, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.8141337224951712e-06, "eval/cont_pred": 0.9951356649398804, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 24.438871383666992, "eval/dyn_loss_std": 12.72219467163086, "eval/image_loss_mean": 37.81028747558594, "eval/image_loss_std": 36.70305252075195, "eval/model_loss_mean": 52.642921447753906, "eval/model_loss_std": 42.0247802734375, "eval/post_ent_mag": 38.54472732543945, "eval/post_ent_max": 38.54472732543945, "eval/post_ent_mean": 27.077682495117188, "eval/post_ent_min": 11.860977172851562, "eval/post_ent_std": 3.95821213722229, "eval/prior_ent_mag": 76.11016082763672, "eval/prior_ent_max": 76.11016082763672, "eval/prior_ent_mean": 35.52984619140625, "eval/prior_ent_min": 14.171270370483398, "eval/prior_ent_std": 9.421616554260254, "eval/rep_loss_mean": 24.438871383666992, "eval/rep_loss_std": 12.72219467163086, "eval/reward_avg": 0.01767578162252903, "eval/reward_loss_mean": 0.16928668320178986, "eval/reward_loss_std": 1.0993766784667969, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0006451606750488, "eval/reward_neg_acc": 0.9980019927024841, "eval/reward_neg_loss": 0.07118566334247589, "eval/reward_pos_acc": 0.5652173757553101, "eval/reward_pos_loss": 4.43881368637085, "eval/reward_pred": 0.00843597762286663, "eval/reward_rate": 0.0224609375, "replay/size": 74593.0, "replay/inserts": 2186.0, "replay/samples": 34976.0, "replay/insert_wait_avg": 2.6636132382517655e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.248331076053993e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 15624.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 9.238719940185547e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4296786785126, "timer/env.step_count": 274.0, "timer/env.step_total": 25.365050315856934, "timer/env.step_frac": 0.025354156175536626, "timer/env.step_avg": 0.09257317633524428, "timer/env.step_min": 0.02292776107788086, "timer/env.step_max": 1.699897050857544, "timer/replay._sample_count": 34976.0, "timer/replay._sample_total": 16.955254316329956, "timer/replay._sample_frac": 0.016947972134059925, "timer/replay._sample_avg": 0.0004847682501237979, "timer/replay._sample_min": 0.00035119056701660156, "timer/replay._sample_max": 0.031108617782592773, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 274.0, "timer/agent.policy_total": 4.373502254486084, "timer/agent.policy_frac": 0.004371623860922569, "timer/agent.policy_avg": 0.01596168706016819, "timer/agent.policy_min": 0.009943485260009766, "timer/agent.policy_max": 0.04042530059814453, "timer/dataset_train_count": 2186.0, "timer/dataset_train_total": 0.40334606170654297, "timer/dataset_train_frac": 0.0004031728269390516, "timer/dataset_train_avg": 0.00018451329446776896, "timer/dataset_train_min": 9.012222290039062e-05, "timer/dataset_train_max": 0.014074087142944336, "timer/agent.train_count": 2186.0, "timer/agent.train_total": 968.4509880542755, "timer/agent.train_frac": 0.9680350440358003, "timer/agent.train_avg": 0.4430242397320565, "timer/agent.train_min": 0.432758092880249, "timer/agent.train_max": 0.5827436447143555, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47600650787353516, "timer/agent.report_frac": 0.0004758020658706383, "timer/agent.report_avg": 0.23800325393676758, "timer/agent.report_min": 0.23051095008850098, "timer/agent.report_max": 0.24549555778503418, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9802322387695312e-05, "timer/dataset_eval_frac": 2.978952246504901e-08, "timer/dataset_eval_avg": 2.9802322387695312e-05, "timer/dataset_eval_min": 2.9802322387695312e-05, "timer/dataset_eval_max": 2.9802322387695312e-05, "fps": 2.185033318384712}
{"step": 75184, "time": 34352.54311466217, "episode/length": 209.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 75248, "time": 34382.84546351433, "episode/length": 177.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 75480, "time": 34489.38254237175, "episode/length": 182.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 75688, "time": 34584.2559595108, "episode/length": 172.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 75776, "time": 34625.25003242493, "episode/length": 222.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 76024, "time": 34738.16722035408, "episode/length": 96.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9381443298969072, "episode/intrinsic_return": 0.0}
{"step": 76088, "time": 34768.87743449211, "episode/length": 141.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9647887323943662, "episode/intrinsic_return": 0.0}
{"step": 76152, "time": 34799.161378622055, "episode/length": 239.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 76312, "time": 34872.55309796333, "episode/length": 215.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 76872, "time": 35126.07592916489, "episode/length": 173.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 77016, "time": 35192.72201395035, "episode/length": 165.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 77232, "time": 35291.64431476593, "episode/length": 181.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967032967032967, "episode/intrinsic_return": 0.0}
{"step": 77276, "time": 35313.5004734993, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.1144918739248855, "train/action_min": 0.0, "train/action_std": 4.464954220920528, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04268985198075892, "train/actor_opt_grad_steps": 74625.0, "train/actor_opt_loss": -8.867910546583866, "train/adv_mag": 0.7310666072806087, "train/adv_max": 0.6770946063579769, "train/adv_mean": 0.0034013584418020517, "train/adv_min": -0.6029185647264533, "train/adv_std": 0.05350976218597604, "train/cont_avg": 0.9945079558486238, "train/cont_loss_mean": 2.988979599982066e-05, "train/cont_loss_std": 0.0009398751334734278, "train/cont_neg_acc": 0.998580166506111, "train/cont_neg_loss": 0.0037461158767551133, "train/cont_pos_acc": 0.9999999819545571, "train/cont_pos_loss": 6.861300659751126e-06, "train/cont_pred": 0.9945126244234382, "train/cont_rate": 0.9945079558486238, "train/dyn_loss_mean": 2.9266668547184094, "train/dyn_loss_std": 7.814195685430405, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.4479125530347912, "train/extr_critic_critic_opt_grad_steps": 74625.0, "train/extr_critic_critic_opt_loss": 16071.254121272936, "train/extr_critic_mag": 15.854079876471003, "train/extr_critic_max": 15.854079876471003, "train/extr_critic_mean": 2.765577324486654, "train/extr_critic_min": -0.7575801075051684, "train/extr_critic_std": 2.999206603667058, "train/extr_return_normed_mag": 1.7505375917898405, "train/extr_return_normed_max": 1.7505375917898405, "train/extr_return_normed_mean": 0.33113545097342323, "train/extr_return_normed_min": -0.1091010725006051, "train/extr_return_normed_std": 0.32666040369130056, "train/extr_return_rate": 0.7497100559396481, "train/extr_return_raw_mag": 16.195685198547643, "train/extr_return_raw_max": 16.195685198547643, "train/extr_return_raw_mean": 2.797617896981196, "train/extr_return_raw_min": -1.335847367660715, "train/extr_return_raw_std": 3.073375538948479, "train/extr_reward_mag": 1.0299954534670628, "train/extr_reward_max": 1.0299954534670628, "train/extr_reward_mean": 0.029065895218983156, "train/extr_reward_min": -0.6819540426271771, "train/extr_reward_std": 0.17208209223703508, "train/image_loss_mean": 1.6213053702761273, "train/image_loss_std": 4.947118061398148, "train/model_loss_mean": 3.412860294000818, "train/model_loss_std": 8.741424464304513, "train/model_opt_grad_norm": 31.379364757362854, "train/model_opt_grad_steps": 74559.97706422018, "train/model_opt_loss": 6935.0689260500285, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2024.0825688073394, "train/policy_entropy_mag": 2.453692464653505, "train/policy_entropy_max": 2.453692464653505, "train/policy_entropy_mean": 0.608687734658565, "train/policy_entropy_min": 0.0793750142558999, "train/policy_entropy_std": 0.6229333863892687, "train/policy_logprob_mag": 7.438383883292522, "train/policy_logprob_max": -0.009455658106663085, "train/policy_logprob_mean": -0.608924918491906, "train/policy_logprob_min": -7.438383883292522, "train/policy_logprob_std": 1.1319291039344368, "train/policy_randomness_mag": 0.8660457623661111, "train/policy_randomness_max": 0.8660457623661111, "train/policy_randomness_mean": 0.21484005991198601, "train/policy_randomness_min": 0.02801589686594425, "train/policy_randomness_std": 0.21986815039444407, "train/post_ent_mag": 40.3703692199987, "train/post_ent_max": 40.3703692199987, "train/post_ent_mean": 21.757747588901346, "train/post_ent_min": 12.067769435567593, "train/post_ent_std": 3.877903889078613, "train/prior_ent_mag": 75.94713750016798, "train/prior_ent_max": 75.94713750016798, "train/prior_ent_mean": 24.658687775288154, "train/prior_ent_min": 13.13760899622506, "train/prior_ent_std": 9.0087116267703, "train/rep_loss_mean": 2.9266668547184094, "train/rep_loss_std": 7.814195685430405, "train/reward_avg": 0.019403579931091004, "train/reward_loss_mean": 0.03552494392892636, "train/reward_loss_std": 0.17062402725083017, "train/reward_max_data": 1.0142201868765945, "train/reward_max_pred": 1.0144220103911303, "train/reward_neg_acc": 0.9965793695471702, "train/reward_neg_loss": 0.01814150733129899, "train/reward_pos_acc": 0.9887648725181545, "train/reward_pos_loss": 0.7279064174092144, "train/reward_pred": 0.01918391902811415, "train/reward_rate": 0.024467818233944953, "train_stats/sum_log_reward": 4.016666611035665, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 2.75, "train_stats/max_log_achievement_collect_sapling": 2.0833333333333335, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 1.4166666666666667, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.08333333333333333, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 2.0833333333333335, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 0.5, "train_stats/max_log_achievement_wake_up": 1.75, "train_stats/mean_log_entropy": 0.5761105989416441, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 5.315794027183074e-08, "report/cont_loss_std": 6.132192993391072e-07, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 6.443616712203948e-06, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.1801424665568447e-08, "report/cont_pred": 0.9951171875, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 2.7506155967712402, "report/dyn_loss_std": 7.425971031188965, "report/image_loss_mean": 1.7264360189437866, "report/image_loss_std": 3.818418264389038, "report/model_loss_mean": 3.4098262786865234, "report/model_loss_std": 7.195110321044922, "report/post_ent_mag": 35.291324615478516, "report/post_ent_max": 35.291324615478516, "report/post_ent_mean": 21.68219757080078, "report/post_ent_min": 13.124492645263672, "report/post_ent_std": 3.891799211502075, "report/prior_ent_mag": 75.88275146484375, "report/prior_ent_max": 75.88275146484375, "report/prior_ent_mean": 24.617393493652344, "report/prior_ent_min": 14.651458740234375, "report/prior_ent_std": 8.709467887878418, "report/rep_loss_mean": 2.7506155967712402, "report/rep_loss_std": 7.425971031188965, "report/reward_avg": 0.02744140475988388, "report/reward_loss_mean": 0.033021003007888794, "report/reward_loss_std": 0.13756407797336578, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.004209280014038, "report/reward_neg_acc": 0.9969757795333862, "report/reward_neg_loss": 0.01235036738216877, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6738107204437256, "report/reward_pred": 0.027481835335493088, "report/reward_rate": 0.03125, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.016828525811433792, "eval/cont_loss_std": 0.5165978670120239, "eval/cont_neg_acc": 0.800000011920929, "eval/cont_neg_loss": 3.3426246643066406, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0005096058011986315, "eval/cont_pred": 0.9958672523498535, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 25.76093101501465, "eval/dyn_loss_std": 13.813150405883789, "eval/image_loss_mean": 55.155765533447266, "eval/image_loss_std": 58.42902374267578, "eval/model_loss_mean": 70.82151794433594, "eval/model_loss_std": 63.788414001464844, "eval/post_ent_mag": 43.61796188354492, "eval/post_ent_max": 43.61796188354492, "eval/post_ent_mean": 27.057567596435547, "eval/post_ent_min": 14.73710823059082, "eval/post_ent_std": 3.5484201908111572, "eval/prior_ent_mag": 75.88275146484375, "eval/prior_ent_max": 75.88275146484375, "eval/prior_ent_mean": 35.8990592956543, "eval/prior_ent_min": 17.54913902282715, "eval/prior_ent_std": 8.828351974487305, "eval/rep_loss_mean": 25.76093101501465, "eval/rep_loss_std": 13.813150405883789, "eval/reward_avg": 0.02138672024011612, "eval/reward_loss_mean": 0.19236749410629272, "eval/reward_loss_std": 1.1745864152908325, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0065221786499023, "eval/reward_neg_acc": 0.9939819574356079, "eval/reward_neg_loss": 0.13478253781795502, "eval/reward_pos_acc": 0.8148148059844971, "eval/reward_pos_loss": 2.3187460899353027, "eval/reward_pred": 0.023260977119207382, "eval/reward_rate": 0.0263671875, "replay/size": 76772.0, "replay/inserts": 2179.0, "replay/samples": 34864.0, "replay/insert_wait_avg": 2.592733662409649e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.348891626316891e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 15624.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 8.493661880493164e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1973915100098, "timer/env.step_count": 272.0, "timer/env.step_total": 27.476081371307373, "timer/env.step_frac": 0.027470658896466837, "timer/env.step_avg": 0.10101500504157122, "timer/env.step_min": 0.024158000946044922, "timer/env.step_max": 2.055100917816162, "timer/replay._sample_count": 34864.0, "timer/replay._sample_total": 16.927189826965332, "timer/replay._sample_frac": 0.016923849202816012, "timer/replay._sample_avg": 0.0004855205893461832, "timer/replay._sample_min": 0.0003345012664794922, "timer/replay._sample_max": 0.030150651931762695, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 272.0, "timer/agent.policy_total": 4.304611682891846, "timer/agent.policy_frac": 0.004303762156780996, "timer/agent.policy_avg": 0.015825778245925903, "timer/agent.policy_min": 0.010086774826049805, "timer/agent.policy_max": 0.01836562156677246, "timer/dataset_train_count": 2179.0, "timer/dataset_train_total": 0.3819749355316162, "timer/dataset_train_frac": 0.00038189955180241387, "timer/dataset_train_avg": 0.0001752982723871575, "timer/dataset_train_min": 8.654594421386719e-05, "timer/dataset_train_max": 0.0010857582092285156, "timer/agent.train_count": 2179.0, "timer/agent.train_total": 966.3322250843048, "timer/agent.train_frac": 0.9661415169513906, "timer/agent.train_avg": 0.44347509182391226, "timer/agent.train_min": 0.4304955005645752, "timer/agent.train_max": 0.5561058521270752, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4725618362426758, "timer/agent.report_frac": 0.0004724685749572328, "timer/agent.report_avg": 0.2362809181213379, "timer/agent.report_min": 0.23032808303833008, "timer/agent.report_max": 0.2422337532043457, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.1948089599609375e-05, "timer/dataset_eval_frac": 3.194178456252217e-08, "timer/dataset_eval_avg": 3.1948089599609375e-05, "timer/dataset_eval_min": 3.1948089599609375e-05, "timer/dataset_eval_max": 3.1948089599609375e-05, "fps": 2.1785425542851624}
{"step": 77392, "time": 35365.88136291504, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 77512, "time": 35421.14737415314, "episode/length": 290.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9862542955326461, "episode/intrinsic_return": 0.0}
{"step": 77560, "time": 35444.246527433395, "episode/length": 175.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9659090909090909, "episode/intrinsic_return": 0.0}
{"step": 77872, "time": 35585.74476933479, "episode/length": 194.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 78384, "time": 35817.67516541481, "episode/length": 188.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 78408, "time": 35829.8061747551, "episode/length": 297.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9966442953020134, "episode/intrinsic_return": 0.0}
{"step": 78536, "time": 35888.86599731445, "episode/length": 82.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9518072289156626, "episode/intrinsic_return": 0.0}
{"step": 78552, "time": 35898.011343717575, "episode/length": 164.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 78640, "time": 35939.074534893036, "episode/length": 140.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9645390070921985, "episode/intrinsic_return": 0.0}
{"step": 78744, "time": 35987.73033595085, "episode/length": 215.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 79224, "time": 36204.875280857086, "episode/length": 207.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 79296, "time": 36238.58503174782, "episode/length": 237.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 79459, "time": 36313.6183347702, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.059610629300459, "train/action_min": 0.0, "train/action_std": 4.427481967374819, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04486442240245572, "train/actor_opt_grad_steps": 76805.0, "train/actor_opt_loss": -5.931008693967185, "train/adv_mag": 0.7794719723933333, "train/adv_max": 0.7206634719164, "train/adv_mean": 0.0034289484126078804, "train/adv_min": -0.6303815736409721, "train/adv_std": 0.055048518104974284, "train/cont_avg": 0.9944407611811926, "train/cont_loss_mean": 0.00010547736252316297, "train/cont_loss_std": 0.003307469092584937, "train/cont_neg_acc": 0.9986620796929806, "train/cont_neg_loss": 0.010596635028395142, "train/cont_pos_acc": 0.9999954746950657, "train/cont_pos_loss": 2.785841081657482e-05, "train/cont_pred": 0.994440209154689, "train/cont_rate": 0.9944407611811926, "train/dyn_loss_mean": 2.920323815914469, "train/dyn_loss_std": 7.763515343359851, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.5413867678117315, "train/extr_critic_critic_opt_grad_steps": 76805.0, "train/extr_critic_critic_opt_loss": 16644.23556210579, "train/extr_critic_mag": 17.837125331983653, "train/extr_critic_max": 17.837125331983653, "train/extr_critic_mean": 3.2641805831445465, "train/extr_critic_min": -0.7514540498409796, "train/extr_critic_std": 3.3794768190165176, "train/extr_return_normed_mag": 1.7080681635699142, "train/extr_return_normed_max": 1.7080681635699142, "train/extr_return_normed_mean": 0.3360500384224664, "train/extr_return_normed_min": -0.0940399903359763, "train/extr_return_normed_std": 0.32089096847750725, "train/extr_return_rate": 0.793140212877081, "train/extr_return_raw_mag": 18.051860555596306, "train/extr_return_raw_max": 18.051860555596306, "train/extr_return_raw_mean": 3.301131637818223, "train/extr_return_raw_min": -1.32012964005864, "train/extr_return_raw_std": 3.449815403977665, "train/extr_reward_mag": 1.0273793038971928, "train/extr_reward_max": 1.0273793038971928, "train/extr_reward_mean": 0.028317365235725946, "train/extr_reward_min": -0.6863591692863255, "train/extr_reward_std": 0.17037790918022122, "train/image_loss_mean": 1.628000712996229, "train/image_loss_std": 4.944022115217436, "train/model_loss_mean": 3.4153449754102514, "train/model_loss_std": 8.69676840195962, "train/model_opt_grad_norm": 32.91798759056127, "train/model_opt_grad_steps": 76738.15596330275, "train/model_opt_loss": 6259.532093293076, "train/model_opt_model_opt_grad_overflow": 0.0045871559633027525, "train/model_opt_model_opt_grad_scale": 1846.3302752293578, "train/policy_entropy_mag": 2.4881106899418963, "train/policy_entropy_max": 2.4881106899418963, "train/policy_entropy_mean": 0.6000866421045513, "train/policy_entropy_min": 0.07937501391413015, "train/policy_entropy_std": 0.6281851568353285, "train/policy_logprob_mag": 7.438383863606584, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5993303596426588, "train/policy_logprob_min": -7.438383863606584, "train/policy_logprob_std": 1.1251880854641625, "train/policy_randomness_mag": 0.8781938867284618, "train/policy_randomness_max": 0.8781938867284618, "train/policy_randomness_mean": 0.2118042507849702, "train/policy_randomness_min": 0.028015896746324837, "train/policy_randomness_std": 0.2217217950372521, "train/post_ent_mag": 41.10406375150068, "train/post_ent_max": 41.10406375150068, "train/post_ent_mean": 21.831186933254976, "train/post_ent_min": 11.996845910308558, "train/post_ent_std": 3.9098920439361433, "train/prior_ent_mag": 75.96065748722181, "train/prior_ent_max": 75.96065748722181, "train/prior_ent_mean": 24.75544741394323, "train/prior_ent_min": 13.16551529158146, "train/prior_ent_std": 9.025465656857971, "train/rep_loss_mean": 2.920323815914469, "train/rep_loss_std": 7.763515343359851, "train/reward_avg": 0.019150032115023616, "train/reward_loss_mean": 0.03504450192862968, "train/reward_loss_std": 0.16098520563009683, "train/reward_max_data": 1.0110091769367182, "train/reward_max_pred": 1.0117036689312087, "train/reward_neg_acc": 0.9964161941764551, "train/reward_neg_loss": 0.018359734040232153, "train/reward_pos_acc": 0.9916099977055821, "train/reward_pos_loss": 0.7118565596024925, "train/reward_pred": 0.01905889199072615, "train/reward_rate": 0.02411392631880734, "train_stats/sum_log_reward": 4.099999914566676, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 2.5833333333333335, "train_stats/max_log_achievement_collect_sapling": 1.8333333333333333, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 1.8333333333333333, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.25, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.8333333333333333, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 0.6666666666666666, "train_stats/max_log_achievement_wake_up": 2.0833333333333335, "train_stats/mean_log_entropy": 0.574340025583903, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 4.178646122454666e-06, "report/cont_loss_std": 7.934528548503295e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0014117539394646883, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 4.277361398408175e-08, "report/cont_pred": 0.9970744848251343, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 2.61195707321167, "report/dyn_loss_std": 7.089656829833984, "report/image_loss_mean": 1.3322303295135498, "report/image_loss_std": 3.063293218612671, "report/model_loss_mean": 2.9286184310913086, "report/model_loss_std": 6.649759292602539, "report/post_ent_mag": 37.58622741699219, "report/post_ent_max": 37.58622741699219, "report/post_ent_mean": 23.0009822845459, "report/post_ent_min": 13.252690315246582, "report/post_ent_std": 3.774599313735962, "report/prior_ent_mag": 76.28248596191406, "report/prior_ent_max": 76.28248596191406, "report/prior_ent_mean": 25.764842987060547, "report/prior_ent_min": 14.009923934936523, "report/prior_ent_std": 8.453231811523438, "report/rep_loss_mean": 2.61195707321167, "report/rep_loss_std": 7.089656829833984, "report/reward_avg": 0.02275390550494194, "report/reward_loss_mean": 0.02920941449701786, "report/reward_loss_std": 0.15462686121463776, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0047316551208496, "report/reward_neg_acc": 0.9979960322380066, "report/reward_neg_loss": 0.010151350870728493, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7607458233833313, "report/reward_pred": 0.022341836243867874, "report/reward_rate": 0.025390625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 8.0233090557158e-05, "eval/cont_loss_std": 0.0022142790257930756, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.02051633782684803, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 9.151193580692052e-08, "eval/cont_pred": 0.9961714744567871, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 24.967681884765625, "eval/dyn_loss_std": 13.262009620666504, "eval/image_loss_mean": 53.415443420410156, "eval/image_loss_std": 64.28446960449219, "eval/model_loss_mean": 68.50519561767578, "eval/model_loss_std": 68.87191772460938, "eval/post_ent_mag": 42.529136657714844, "eval/post_ent_max": 42.529136657714844, "eval/post_ent_mean": 27.31749153137207, "eval/post_ent_min": 16.69879722595215, "eval/post_ent_std": 3.0719094276428223, "eval/prior_ent_mag": 76.28248596191406, "eval/prior_ent_max": 76.28248596191406, "eval/prior_ent_mean": 36.58258056640625, "eval/prior_ent_min": 21.114215850830078, "eval/prior_ent_std": 8.447715759277344, "eval/rep_loss_mean": 24.967681884765625, "eval/rep_loss_std": 13.262009620666504, "eval/reward_avg": 0.01875000074505806, "eval/reward_loss_mean": 0.10906380414962769, "eval/reward_loss_std": 0.7884059548377991, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0017993450164795, "eval/reward_neg_acc": 0.9950099587440491, "eval/reward_neg_loss": 0.06024496257305145, "eval/reward_pos_acc": 0.8181818723678589, "eval/reward_pos_loss": 2.332540273666382, "eval/reward_pred": 0.017196623608469963, "eval/reward_rate": 0.021484375, "replay/size": 78955.0, "replay/inserts": 2183.0, "replay/samples": 34928.0, "replay/insert_wait_avg": 2.5972662526863297e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.457816158474666e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 15624.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 7.003545761108398e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1027669906616, "timer/env.step_count": 273.0, "timer/env.step_total": 26.456730127334595, "timer/env.step_frac": 0.026454011528178917, "timer/env.step_avg": 0.09691109936752598, "timer/env.step_min": 0.02313685417175293, "timer/env.step_max": 2.059119939804077, "timer/replay._sample_count": 34928.0, "timer/replay._sample_total": 16.943901777267456, "timer/replay._sample_frac": 0.01694216068239882, "timer/replay._sample_avg": 0.000485109418726164, "timer/replay._sample_min": 0.0003714561462402344, "timer/replay._sample_max": 0.016777992248535156, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 273.0, "timer/agent.policy_total": 4.323856353759766, "timer/agent.policy_frac": 0.004323412049714027, "timer/agent.policy_avg": 0.015838301662123685, "timer/agent.policy_min": 0.009903430938720703, "timer/agent.policy_max": 0.04186654090881348, "timer/dataset_train_count": 2183.0, "timer/dataset_train_total": 0.38594746589660645, "timer/dataset_train_frac": 0.0003859078073125761, "timer/dataset_train_avg": 0.00017679682358983346, "timer/dataset_train_min": 9.107589721679688e-05, "timer/dataset_train_max": 0.0005974769592285156, "timer/agent.train_count": 2183.0, "timer/agent.train_total": 967.1989071369171, "timer/agent.train_frac": 0.9670995212294501, "timer/agent.train_avg": 0.443059508537296, "timer/agent.train_min": 0.43184423446655273, "timer/agent.train_max": 0.5634431838989258, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4737710952758789, "timer/agent.report_frac": 0.00047372241224916307, "timer/agent.report_avg": 0.23688554763793945, "timer/agent.report_min": 0.22974276542663574, "timer/agent.report_max": 0.24402832984924316, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7418136596679688e-05, "timer/dataset_eval_frac": 2.7415319206826775e-08, "timer/dataset_eval_avg": 2.7418136596679688e-05, "timer/dataset_eval_min": 2.7418136596679688e-05, "timer/dataset_eval_max": 2.7418136596679688e-05, "fps": 2.1827413696192766}
{"step": 79544, "time": 36352.23934173584, "episode/length": 141.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 79568, "time": 36364.56652903557, "episode/length": 33.0, "episode/score": -0.9000000283122063, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 79704, "time": 36427.467598199844, "episode/length": 164.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 79856, "time": 36498.203332185745, "episode/length": 164.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 79864, "time": 36503.33598399162, "episode/length": 139.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 80080, "time": 36619.77971792221, "eval_episode/length": 90.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.945054945054945}
{"step": 80080, "time": 36624.0800819397, "eval_episode/length": 155.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9551282051282052}
{"step": 80080, "time": 36626.95554971695, "eval_episode/length": 173.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9942528735632183}
{"step": 80080, "time": 36629.872462034225, "eval_episode/length": 195.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9744897959183674}
{"step": 80080, "time": 36632.211906671524, "eval_episode/length": 206.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9951690821256038}
{"step": 80080, "time": 36634.62375617027, "eval_episode/length": 217.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9724770642201835}
{"step": 80080, "time": 36637.097586393356, "eval_episode/length": 229.0, "eval_episode/score": 4.099999979138374, "eval_episode/reward_rate": 0.9956521739130435}
{"step": 80080, "time": 36639.98446702957, "eval_episode/length": 157.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9746835443037974}
{"step": 80232, "time": 36708.52735042572, "episode/length": 198.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9597989949748744, "episode/intrinsic_return": 0.0}
{"step": 80680, "time": 36912.096101522446, "episode/length": 141.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9647887323943662, "episode/intrinsic_return": 0.0}
{"step": 80688, "time": 36917.20588827133, "episode/length": 182.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 80808, "time": 36972.8633210659, "episode/length": 281.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 80952, "time": 37039.63061475754, "episode/length": 155.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 80992, "time": 37059.37126612663, "episode/length": 141.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 81024, "time": 37075.26584100723, "episode/length": 144.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 81240, "time": 37174.3234231472, "episode/length": 125.0, "episode/score": 1.100000023841858, "episode/reward_rate": 0.9920634920634921, "episode/intrinsic_return": 0.0}
{"step": 81248, "time": 37179.86870932579, "episode/length": 209.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 81541, "time": 37313.77275085449, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.8596606094871415, "train/action_min": 0.0, "train/action_std": 4.274549296027736, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04964905686712151, "train/actor_opt_grad_steps": 78940.0, "train/actor_opt_loss": -0.23844388248532583, "train/adv_mag": 0.8465571848399331, "train/adv_max": 0.7783136868305753, "train/adv_mean": 0.005033059388094996, "train/adv_min": -0.694932080769653, "train/adv_std": 0.05934659651877207, "train/cont_avg": 0.9942948190789473, "train/cont_loss_mean": 2.3588669077636687e-05, "train/cont_loss_std": 0.0006758077399984252, "train/cont_neg_acc": 0.9994019138755981, "train/cont_neg_loss": 0.0020620653545123193, "train/cont_pos_acc": 0.9999999848849466, "train/cont_pos_loss": 8.209431072408348e-06, "train/cont_pred": 0.9942937732883618, "train/cont_rate": 0.9942948190789473, "train/dyn_loss_mean": 2.8970264532919705, "train/dyn_loss_std": 7.799572121013295, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.4644731437190297, "train/extr_critic_critic_opt_grad_steps": 78940.0, "train/extr_critic_critic_opt_loss": 16749.14991869767, "train/extr_critic_mag": 18.136696194917963, "train/extr_critic_max": 18.136696194917963, "train/extr_critic_mean": 3.6807840634761244, "train/extr_critic_min": -0.7215095222281497, "train/extr_critic_std": 3.5759247102235494, "train/extr_return_normed_mag": 1.6402588455300582, "train/extr_return_normed_max": 1.6402588455300582, "train/extr_return_normed_mean": 0.3528186069293456, "train/extr_return_normed_min": -0.08591071181177523, "train/extr_return_normed_std": 0.3203792416593104, "train/extr_return_rate": 0.8145597035234625, "train/extr_return_raw_mag": 18.47781750802218, "train/extr_return_raw_max": 18.47781750802218, "train/extr_return_raw_mean": 3.7390899943392815, "train/extr_return_raw_min": -1.284533648399645, "train/extr_return_raw_std": 3.670268388456135, "train/extr_reward_mag": 1.0319577096181622, "train/extr_reward_max": 1.0319577096181622, "train/extr_reward_mean": 0.028786747787664668, "train/extr_reward_min": -0.6825732317837802, "train/extr_reward_std": 0.17158881642601706, "train/image_loss_mean": 1.6205759068425192, "train/image_loss_std": 4.7743872963070295, "train/model_loss_mean": 3.3942217575876334, "train/model_loss_std": 8.556017857419247, "train/model_opt_grad_norm": 32.839316950394554, "train/model_opt_grad_steps": 78871.12918660288, "train/model_opt_loss": 6231.116754121187, "train/model_opt_model_opt_grad_overflow": 0.004784688995215311, "train/model_opt_model_opt_grad_scale": 1836.1244019138755, "train/policy_entropy_mag": 2.4716368417420456, "train/policy_entropy_max": 2.4716368417420456, "train/policy_entropy_mean": 0.5934443131588293, "train/policy_entropy_min": 0.07937501385166314, "train/policy_entropy_std": 0.6184030192320427, "train/policy_logprob_mag": 7.4383838963850835, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5937132488882713, "train/policy_logprob_min": -7.4383838963850835, "train/policy_logprob_std": 1.1229680075029438, "train/policy_randomness_mag": 0.8723793403383647, "train/policy_randomness_max": 0.8723793403383647, "train/policy_randomness_mean": 0.2094598010396273, "train/policy_randomness_min": 0.028015896731443952, "train/policy_randomness_std": 0.2182691294040406, "train/post_ent_mag": 40.96599963977577, "train/post_ent_max": 40.96599963977577, "train/post_ent_mean": 21.969416504271294, "train/post_ent_min": 12.03194113553426, "train/post_ent_std": 3.955482246773095, "train/prior_ent_mag": 76.00221876664595, "train/prior_ent_max": 76.00221876664595, "train/prior_ent_mean": 24.868038414768055, "train/prior_ent_min": 13.231070372476532, "train/prior_ent_std": 9.039841697546853, "train/rep_loss_mean": 2.8970264532919705, "train/rep_loss_std": 7.799572121013295, "train/reward_avg": 0.019600403633271677, "train/reward_loss_mean": 0.03540636901186699, "train/reward_loss_std": 0.16063552809674203, "train/reward_max_data": 1.0124401943535326, "train/reward_max_pred": 1.013976882519334, "train/reward_neg_acc": 0.996268045103721, "train/reward_neg_loss": 0.01833785953597304, "train/reward_pos_acc": 0.9916648710743662, "train/reward_pos_loss": 0.7119039913113607, "train/reward_pred": 0.01951833685824389, "train/reward_rate": 0.024643017344497607, "train_stats/sum_log_reward": 2.5999999344348907, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 2.5, "train_stats/max_log_achievement_collect_sapling": 1.2142857142857142, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 1.4285714285714286, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.2142857142857142, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 0.5, "train_stats/max_log_achievement_wake_up": 1.3571428571428572, "train_stats/mean_log_entropy": 0.5074456259608269, "eval_stats/sum_log_reward": 3.099999918602407, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 1.25, "eval_stats/max_log_achievement_collect_sapling": 2.0, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 1.875, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.0, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 0.625, "eval_stats/max_log_achievement_wake_up": 1.125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 1.7565514554007677e-07, "report/cont_loss_std": 9.597715688869357e-07, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 4.034474386571674e-06, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.4527073233239207e-07, "report/cont_pred": 0.9921875, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 3.098573923110962, "report/dyn_loss_std": 7.749073028564453, "report/image_loss_mean": 1.2544159889221191, "report/image_loss_std": 3.5136406421661377, "report/model_loss_mean": 3.1494765281677246, "report/model_loss_std": 7.534971714019775, "report/post_ent_mag": 44.507259368896484, "report/post_ent_max": 44.507259368896484, "report/post_ent_mean": 23.15713882446289, "report/post_ent_min": 10.653454780578613, "report/post_ent_std": 4.123903751373291, "report/prior_ent_mag": 75.90916442871094, "report/prior_ent_max": 75.90916442871094, "report/prior_ent_mean": 26.196590423583984, "report/prior_ent_min": 12.08301067352295, "report/prior_ent_std": 9.433775901794434, "report/rep_loss_mean": 3.098573923110962, "report/rep_loss_std": 7.749073028564453, "report/reward_avg": 0.017578125, "report/reward_loss_mean": 0.03591584041714668, "report/reward_loss_std": 0.1589185893535614, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0006284713745117, "report/reward_neg_acc": 0.9970000386238098, "report/reward_neg_loss": 0.02055433765053749, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6759785413742065, "report/reward_pred": 0.017790619283914566, "report/reward_rate": 0.0234375, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.0036725143436342478, "eval/cont_loss_std": 0.07548225671052933, "eval/cont_neg_acc": 0.6666666865348816, "eval/cont_neg_loss": 0.6267017126083374, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 4.375066851025622e-07, "eval/cont_pred": 0.9960800409317017, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 25.95975685119629, "eval/dyn_loss_std": 13.313483238220215, "eval/image_loss_mean": 47.067787170410156, "eval/image_loss_std": 48.62160110473633, "eval/model_loss_mean": 62.865692138671875, "eval/model_loss_std": 53.149227142333984, "eval/post_ent_mag": 39.10782241821289, "eval/post_ent_max": 39.10782241821289, "eval/post_ent_mean": 26.815855026245117, "eval/post_ent_min": 14.399129867553711, "eval/post_ent_std": 3.7537882328033447, "eval/prior_ent_mag": 75.90916442871094, "eval/prior_ent_max": 75.90916442871094, "eval/prior_ent_mean": 35.29853820800781, "eval/prior_ent_min": 16.490251541137695, "eval/prior_ent_std": 9.021981239318848, "eval/rep_loss_mean": 25.95975685119629, "eval/rep_loss_std": 13.313483238220215, "eval/reward_avg": 0.02109375037252903, "eval/reward_loss_mean": 0.21837115287780762, "eval/reward_loss_std": 1.334942102432251, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0011224746704102, "eval/reward_neg_acc": 0.9969940185546875, "eval/reward_neg_loss": 0.09521546959877014, "eval/reward_pos_acc": 0.5384615659713745, "eval/reward_pos_loss": 4.945655822753906, "eval/reward_pred": 0.008207427337765694, "eval/reward_rate": 0.025390625, "replay/size": 81037.0, "replay/inserts": 2082.0, "replay/samples": 33312.0, "replay/insert_wait_avg": 2.5813792555751305e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.728349120426819e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 17616.0, "eval_replay/inserts": 1992.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2155517516844723e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1380770206451, "timer/env.step_count": 260.0, "timer/env.step_total": 28.625999689102173, "timer/env.step_frac": 0.028622047642038996, "timer/env.step_avg": 0.11009999880423912, "timer/env.step_min": 0.023133277893066406, "timer/env.step_max": 1.977843999862671, "timer/replay._sample_count": 33312.0, "timer/replay._sample_total": 16.993932008743286, "timer/replay._sample_frac": 0.016991585861191538, "timer/replay._sample_avg": 0.0005101444527120343, "timer/replay._sample_min": 0.0003764629364013672, "timer/replay._sample_max": 0.012826919555664062, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 509.0, "timer/agent.policy_total": 9.53165888786316, "timer/agent.policy_frac": 0.009530342966500618, "timer/agent.policy_avg": 0.018726245359259645, "timer/agent.policy_min": 0.0102081298828125, "timer/agent.policy_max": 0.11748695373535156, "timer/dataset_train_count": 2082.0, "timer/dataset_train_total": 0.3832125663757324, "timer/dataset_train_frac": 0.00038315966083133344, "timer/dataset_train_avg": 0.00018405983015164863, "timer/dataset_train_min": 9.560585021972656e-05, "timer/dataset_train_max": 0.0007789134979248047, "timer/agent.train_count": 2082.0, "timer/agent.train_total": 927.6914236545563, "timer/agent.train_frac": 0.9275633484709398, "timer/agent.train_avg": 0.4455770526678945, "timer/agent.train_min": 0.43552470207214355, "timer/agent.train_max": 0.5873167514801025, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4703371524810791, "timer/agent.report_frac": 0.0004702722186942296, "timer/agent.report_avg": 0.23516857624053955, "timer/agent.report_min": 0.22425103187561035, "timer/agent.report_max": 0.24608612060546875, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.6941299438476562e-05, "timer/dataset_eval_frac": 2.693757997768985e-08, "timer/dataset_eval_avg": 2.6941299438476562e-05, "timer/dataset_eval_min": 2.6941299438476562e-05, "timer/dataset_eval_max": 2.6941299438476562e-05, "fps": 2.081686537802954}
{"step": 82288, "time": 37649.75825190544, "episode/length": 166.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 82312, "time": 37661.99379277229, "episode/length": 164.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 82384, "time": 37695.70881867409, "episode/length": 196.0, "episode/score": 1.0999999791383743, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 82416, "time": 37711.57046961784, "episode/length": 173.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 82672, "time": 37828.24202823639, "episode/length": 178.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 82840, "time": 37905.08506965637, "episode/length": 198.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9698492462311558, "episode/intrinsic_return": 0.0}
{"step": 82984, "time": 37971.52842140198, "episode/length": 287.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9826388888888888, "episode/intrinsic_return": 0.0}
{"step": 83264, "time": 38099.012345314026, "episode/length": 73.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9324324324324325, "episode/intrinsic_return": 0.0}
{"step": 83640, "time": 38269.39197278023, "episode/length": 368.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.997289972899729, "episode/intrinsic_return": 0.0}
{"step": 83672, "time": 38285.813027858734, "episode/length": 160.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 83680, "time": 38290.80651664734, "episode/length": 157.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 83727, "time": 38313.94286632538, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.448798223372993, "train/action_min": 0.0, "train/action_std": 4.241686614281541, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.05107327343878943, "train/actor_opt_grad_steps": 81075.0, "train/actor_opt_loss": 0.9689799041717971, "train/adv_mag": 0.7611507288086306, "train/adv_max": 0.709318278442829, "train/adv_mean": 0.0051810400116064055, "train/adv_min": -0.646389332112916, "train/adv_std": 0.06192604580535254, "train/cont_avg": 0.9946468248279816, "train/cont_loss_mean": 1.4930868022453255e-05, "train/cont_loss_std": 0.0004067027283161045, "train/cont_neg_acc": 0.9988532110091743, "train/cont_neg_loss": 0.002064342424224053, "train/cont_pos_acc": 0.9999999825013887, "train/cont_pos_loss": 4.969628879081256e-06, "train/cont_pred": 0.994649604373022, "train/cont_rate": 0.9946468248279816, "train/dyn_loss_mean": 2.9368304812580073, "train/dyn_loss_std": 7.774136875747541, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.4499971174865687, "train/extr_critic_critic_opt_grad_steps": 81075.0, "train/extr_critic_critic_opt_loss": 16188.162167610379, "train/extr_critic_mag": 17.800244160748402, "train/extr_critic_max": 17.800244160748402, "train/extr_critic_mean": 4.473078815215224, "train/extr_critic_min": -0.7126390419968771, "train/extr_critic_std": 3.4729929495295253, "train/extr_return_normed_mag": 1.6296616344276917, "train/extr_return_normed_max": 1.6296616344276917, "train/extr_return_normed_mean": 0.4296469819655112, "train/extr_return_normed_min": -0.08149290652176656, "train/extr_return_normed_std": 0.3161928511540824, "train/extr_return_rate": 0.8573553214926238, "train/extr_return_raw_mag": 18.053777952806666, "train/extr_return_raw_max": 18.053777952806666, "train/extr_return_raw_mean": 4.531689443719497, "train/extr_return_raw_min": -1.215027870388206, "train/extr_return_raw_std": 3.5582823808040094, "train/extr_reward_mag": 1.0309494843176745, "train/extr_reward_max": 1.0309494843176745, "train/extr_reward_mean": 0.026550727131682526, "train/extr_reward_min": -0.678403594078274, "train/extr_reward_std": 0.16529404556532518, "train/image_loss_mean": 1.660184533771025, "train/image_loss_std": 4.882407169823253, "train/model_loss_mean": 3.4579390363955715, "train/model_loss_std": 8.644563285582656, "train/model_opt_grad_norm": 31.319931069645314, "train/model_opt_grad_steps": 81004.80733944954, "train/model_opt_loss": 6653.198306022434, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1938.073394495413, "train/policy_entropy_mag": 2.4733780589672403, "train/policy_entropy_max": 2.4733780589672403, "train/policy_entropy_mean": 0.5534805494164108, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6005302834401437, "train/policy_logprob_mag": 7.438383935788356, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5537051957681638, "train/policy_logprob_min": -7.438383935788356, "train/policy_logprob_std": 1.102216119066291, "train/policy_randomness_mag": 0.8729939129921275, "train/policy_randomness_max": 0.8729939129921275, "train/policy_randomness_mean": 0.1953543440327732, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.21196083683486378, "train/post_ent_mag": 41.51215579531608, "train/post_ent_max": 41.51215579531608, "train/post_ent_mean": 22.190391899248876, "train/post_ent_min": 12.299673684146427, "train/post_ent_std": 3.957127411431129, "train/prior_ent_mag": 76.10011455990852, "train/prior_ent_max": 76.10011455990852, "train/prior_ent_mean": 25.104591028405984, "train/prior_ent_min": 13.412130753928368, "train/prior_ent_std": 9.009812206303307, "train/rep_loss_mean": 2.9368304812580073, "train/rep_loss_std": 7.774136875747541, "train/reward_avg": 0.019136593202897987, "train/reward_loss_mean": 0.035641279080113684, "train/reward_loss_std": 0.1666100271934763, "train/reward_max_data": 1.0165137654050775, "train/reward_max_pred": 1.0162558325933755, "train/reward_neg_acc": 0.9962311332378913, "train/reward_neg_loss": 0.018882391711594452, "train/reward_pos_acc": 0.9919723056325125, "train/reward_pos_loss": 0.7138705997292055, "train/reward_pred": 0.019053418454158744, "train/reward_rate": 0.02416320240825688, "train_stats/sum_log_reward": 3.099999937144193, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 2.272727272727273, "train_stats/max_log_achievement_collect_sapling": 1.9090909090909092, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 1.0909090909090908, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.9090909090909092, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 0.36363636363636365, "train_stats/max_log_achievement_wake_up": 1.4545454545454546, "train_stats/mean_log_entropy": 0.6095787476409565, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 1.0330873010389041e-06, "report/cont_loss_std": 2.5824542717600707e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 6.045900136086857e-06, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.003542138278135e-06, "report/cont_pred": 0.9941396713256836, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 2.8816909790039062, "report/dyn_loss_std": 8.331940650939941, "report/image_loss_mean": 1.5838567018508911, "report/image_loss_std": 7.146236419677734, "report/model_loss_mean": 3.345993995666504, "report/model_loss_std": 11.157578468322754, "report/post_ent_mag": 40.884544372558594, "report/post_ent_max": 40.884544372558594, "report/post_ent_mean": 21.687152862548828, "report/post_ent_min": 12.120718002319336, "report/post_ent_std": 3.621826648712158, "report/prior_ent_mag": 76.08280944824219, "report/prior_ent_max": 76.08280944824219, "report/prior_ent_mean": 24.445903778076172, "report/prior_ent_min": 11.397700309753418, "report/prior_ent_std": 8.96713638305664, "report/rep_loss_mean": 2.8816909790039062, "report/rep_loss_std": 8.331940650939941, "report/reward_avg": 0.013378906063735485, "report/reward_loss_mean": 0.033121734857559204, "report/reward_loss_std": 0.13285353779792786, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.0916085243225098, "report/reward_neg_acc": 0.9940239191055298, "report/reward_neg_loss": 0.02041594497859478, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6709524989128113, "report/reward_pred": 0.013578776270151138, "report/reward_rate": 0.01953125, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 9.208276310346264e-07, "eval/cont_loss_std": 2.116021732945228e-06, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 1.1673992958094459e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 8.680643759362283e-07, "eval/cont_pred": 0.9951163530349731, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 25.883127212524414, "eval/dyn_loss_std": 13.010163307189941, "eval/image_loss_mean": 41.32225799560547, "eval/image_loss_std": 48.43806457519531, "eval/model_loss_mean": 56.991432189941406, "eval/model_loss_std": 53.25055694580078, "eval/post_ent_mag": 43.31236267089844, "eval/post_ent_max": 43.31236267089844, "eval/post_ent_mean": 27.117942810058594, "eval/post_ent_min": 13.743650436401367, "eval/post_ent_std": 3.305306911468506, "eval/prior_ent_mag": 76.08280944824219, "eval/prior_ent_max": 76.08280944824219, "eval/prior_ent_mean": 37.07422637939453, "eval/prior_ent_min": 15.208681106567383, "eval/prior_ent_std": 8.09277629852295, "eval/rep_loss_mean": 25.883127212524414, "eval/rep_loss_std": 13.010163307189941, "eval/reward_avg": 0.02373046986758709, "eval/reward_loss_mean": 0.1393016278743744, "eval/reward_loss_std": 0.9831029176712036, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9999706745147705, "eval/reward_neg_acc": 0.99698805809021, "eval/reward_neg_loss": 0.06453551352024078, "eval/reward_pos_acc": 0.7142857313156128, "eval/reward_pos_loss": 2.798839807510376, "eval/reward_pred": 0.018164169043302536, "eval/reward_rate": 0.02734375, "replay/size": 83223.0, "replay/inserts": 2186.0, "replay/samples": 34976.0, "replay/insert_wait_avg": 2.62227717170122e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.42324589592322e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 17616.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 9.387731552124023e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1597816944122, "timer/env.step_count": 273.0, "timer/env.step_total": 24.484134435653687, "timer/env.step_frac": 0.024480222944152082, "timer/env.step_avg": 0.08968547412327357, "timer/env.step_min": 0.022967100143432617, "timer/env.step_max": 2.036153554916382, "timer/replay._sample_count": 34976.0, "timer/replay._sample_total": 17.19682264328003, "timer/replay._sample_frac": 0.017194075344787587, "timer/replay._sample_avg": 0.0004916749383371463, "timer/replay._sample_min": 0.0003635883331298828, "timer/replay._sample_max": 0.011277198791503906, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 273.0, "timer/agent.policy_total": 4.345003843307495, "timer/agent.policy_frac": 0.004344309702142235, "timer/agent.policy_avg": 0.01591576499380035, "timer/agent.policy_min": 0.009721755981445312, "timer/agent.policy_max": 0.021113872528076172, "timer/dataset_train_count": 2186.0, "timer/dataset_train_total": 0.43862342834472656, "timer/dataset_train_frac": 0.00043855335554648716, "timer/dataset_train_avg": 0.00020065115660783465, "timer/dataset_train_min": 9.465217590332031e-05, "timer/dataset_train_max": 0.033498287200927734, "timer/agent.train_count": 2186.0, "timer/agent.train_total": 969.0304484367371, "timer/agent.train_frac": 0.9688756398453279, "timer/agent.train_avg": 0.4432893176746281, "timer/agent.train_min": 0.4251987934112549, "timer/agent.train_max": 0.5605893135070801, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.472766637802124, "timer/agent.report_frac": 0.0004726911104155682, "timer/agent.report_avg": 0.236383318901062, "timer/agent.report_min": 0.2293393611907959, "timer/agent.report_max": 0.24342727661132812, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.337860107421875e-05, "timer/dataset_eval_frac": 3.337326863680788e-08, "timer/dataset_eval_avg": 3.337860107421875e-05, "timer/dataset_eval_min": 3.337860107421875e-05, "timer/dataset_eval_max": 3.337860107421875e-05, "fps": 2.1856222743060063}
{"step": 83904, "time": 38393.67735743523, "episode/length": 198.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.0}
{"step": 84248, "time": 38549.374915122986, "episode/length": 244.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9836734693877551, "episode/intrinsic_return": 0.0}
{"step": 84296, "time": 38572.28414273262, "episode/length": 163.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 84312, "time": 38581.024252176285, "episode/length": 183.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 84824, "time": 38811.818254470825, "episode/length": 194.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 85016, "time": 38899.37218308449, "episode/length": 167.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 85096, "time": 38936.70410180092, "episode/length": 176.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 85128, "time": 38952.51696777344, "episode/length": 185.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9623655913978495, "episode/intrinsic_return": 0.0}
{"step": 85432, "time": 39090.24682569504, "episode/length": 190.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 85648, "time": 39188.30448746681, "episode/length": 168.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 85808, "time": 39261.63852882385, "episode/length": 194.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 85921, "time": 39314.25519943237, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.31195595481179, "train/action_min": 0.0, "train/action_std": 4.1921941681341695, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04257216769355265, "train/actor_opt_grad_steps": 83265.0, "train/actor_opt_loss": -22.84480708156797, "train/adv_mag": 0.7026249109344049, "train/adv_max": 0.6270161688327789, "train/adv_mean": 7.934069448806853e-05, "train/adv_min": -0.5809837278994647, "train/adv_std": 0.051988589238714085, "train/cont_avg": 0.9946555397727272, "train/cont_loss_mean": 6.769530421912862e-05, "train/cont_loss_std": 0.001976527760904774, "train/cont_neg_acc": 1.0, "train/cont_neg_loss": 0.0018924643839467261, "train/cont_pos_acc": 0.9999732025644996, "train/cont_pos_loss": 6.160478849601894e-05, "train/cont_pred": 0.9946340143680572, "train/cont_rate": 0.9946555397727272, "train/dyn_loss_mean": 2.9623526226390493, "train/dyn_loss_std": 7.852011489868164, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.2721432450142773, "train/extr_critic_critic_opt_grad_steps": 83265.0, "train/extr_critic_critic_opt_loss": 15276.131276633523, "train/extr_critic_mag": 18.45180457288569, "train/extr_critic_max": 18.45180457288569, "train/extr_critic_mean": 4.244461323998191, "train/extr_critic_min": -0.6790468779477206, "train/extr_critic_std": 3.4322238748723812, "train/extr_return_normed_mag": 1.7015823889862407, "train/extr_return_normed_max": 1.7015823889862407, "train/extr_return_normed_mean": 0.4077400608496232, "train/extr_return_normed_min": -0.0792517038824206, "train/extr_return_normed_std": 0.31647717153484173, "train/extr_return_rate": 0.8688388228416443, "train/extr_return_raw_mag": 18.535876295783304, "train/extr_return_raw_max": 18.535876295783304, "train/extr_return_raw_mean": 4.245154430649498, "train/extr_return_raw_min": -1.1224631854078986, "train/extr_return_raw_std": 3.492394778945229, "train/extr_reward_mag": 1.031810701977123, "train/extr_reward_max": 1.031810701977123, "train/extr_reward_mean": 0.02708225548902357, "train/extr_reward_min": -0.6833267260681499, "train/extr_reward_std": 0.16645534912293608, "train/image_loss_mean": 1.595070440118963, "train/image_loss_std": 4.796693565628745, "train/model_loss_mean": 3.4073829022320834, "train/model_loss_std": 8.638946119221774, "train/model_opt_grad_norm": 33.106848096847536, "train/model_opt_grad_steps": 83192.82272727272, "train/model_opt_loss": 6080.761726518111, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1784.090909090909, "train/policy_entropy_mag": 2.4303323084657844, "train/policy_entropy_max": 2.4303323084657844, "train/policy_entropy_mean": 0.5413092457435348, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.5844318740747192, "train/policy_logprob_mag": 7.438383954221552, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.541701081124219, "train/policy_logprob_min": -7.438383954221552, "train/policy_logprob_std": 1.0930392769250004, "train/policy_randomness_mag": 0.8578006541187113, "train/policy_randomness_max": 0.8578006541187113, "train/policy_randomness_mean": 0.19105841050093825, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.20627880597656423, "train/post_ent_mag": 41.914863274314186, "train/post_ent_max": 41.914863274314186, "train/post_ent_mean": 22.314596410231157, "train/post_ent_min": 12.326628520271996, "train/post_ent_std": 4.015407733483748, "train/prior_ent_mag": 76.24102200594815, "train/prior_ent_max": 76.24102200594815, "train/prior_ent_mean": 25.23829141963612, "train/prior_ent_min": 13.53317053534768, "train/prior_ent_std": 9.022303165089001, "train/rep_loss_mean": 2.9623526226390493, "train/rep_loss_std": 7.852011489868164, "train/reward_avg": 0.01885697773911736, "train/reward_loss_mean": 0.03483319552615285, "train/reward_loss_std": 0.16620302816683596, "train/reward_max_data": 1.0136363668875261, "train/reward_max_pred": 1.0153847179629587, "train/reward_neg_acc": 0.9965904625979337, "train/reward_neg_loss": 0.018119515732608057, "train/reward_pos_acc": 0.9897569068453529, "train/reward_pos_loss": 0.7229894703084773, "train/reward_pred": 0.018730411170558497, "train/reward_rate": 0.023681640625, "train_stats/sum_log_reward": 4.463636311617765, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 1.8181818181818181, "train_stats/max_log_achievement_collect_sapling": 2.090909090909091, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 2.6363636363636362, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.18181818181818182, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 2.0, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 0.9090909090909091, "train_stats/max_log_achievement_wake_up": 2.1818181818181817, "train_stats/mean_log_entropy": 0.4982648654417558, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 7.514888125115249e-07, "report/cont_loss_std": 5.063239768787753e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 2.9025366075075e-06, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 7.4093412649745e-07, "report/cont_pred": 0.9951165318489075, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 2.9977667331695557, "report/dyn_loss_std": 7.614861965179443, "report/image_loss_mean": 1.724482536315918, "report/image_loss_std": 4.385626792907715, "report/model_loss_mean": 3.5524609088897705, "report/model_loss_std": 8.199416160583496, "report/post_ent_mag": 43.26629638671875, "report/post_ent_max": 43.26629638671875, "report/post_ent_mean": 22.641937255859375, "report/post_ent_min": 12.723236083984375, "report/post_ent_std": 4.396984100341797, "report/prior_ent_mag": 76.40658569335938, "report/prior_ent_max": 76.40658569335938, "report/prior_ent_mean": 25.954193115234375, "report/prior_ent_min": 14.777969360351562, "report/prior_ent_std": 9.189684867858887, "report/rep_loss_mean": 2.9977667331695557, "report/rep_loss_std": 7.614861965179443, "report/reward_avg": 0.014355468563735485, "report/reward_loss_mean": 0.029317494481801987, "report/reward_loss_std": 0.13338664174079895, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0029792785644531, "report/reward_neg_acc": 0.9960199594497681, "report/reward_neg_loss": 0.017132176086306572, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6738566756248474, "report/reward_pred": 0.01438429020345211, "report/reward_rate": 0.0185546875, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.0005439139204099774, "eval/cont_loss_std": 0.011053124442696571, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.09599645435810089, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.00016959029017016292, "eval/cont_pred": 0.9962708353996277, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 24.428476333618164, "eval/dyn_loss_std": 13.75971794128418, "eval/image_loss_mean": 47.79205322265625, "eval/image_loss_std": 50.08390808105469, "eval/model_loss_mean": 62.68218231201172, "eval/model_loss_std": 55.29340744018555, "eval/post_ent_mag": 40.64596939086914, "eval/post_ent_max": 40.64596939086914, "eval/post_ent_mean": 27.494802474975586, "eval/post_ent_min": 12.771148681640625, "eval/post_ent_std": 3.8502755165100098, "eval/prior_ent_mag": 76.40658569335938, "eval/prior_ent_max": 76.40658569335938, "eval/prior_ent_mean": 36.70710754394531, "eval/prior_ent_min": 16.257492065429688, "eval/prior_ent_std": 9.454217910766602, "eval/rep_loss_mean": 24.428476333618164, "eval/rep_loss_std": 13.75971794128418, "eval/reward_avg": 0.02460937574505806, "eval/reward_loss_mean": 0.2324979454278946, "eval/reward_loss_std": 1.4150400161743164, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0000507831573486, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.10525599122047424, "eval/reward_pos_acc": 0.5862069129943848, "eval/reward_pos_loss": 4.5982136726379395, "eval/reward_pred": 0.010149654000997543, "eval/reward_rate": 0.0283203125, "replay/size": 85417.0, "replay/inserts": 2194.0, "replay/samples": 35104.0, "replay/insert_wait_avg": 2.5780503056542702e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.291788824493492e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 17616.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 8.493661880493164e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2996921539307, "timer/env.step_count": 275.0, "timer/env.step_total": 23.25911283493042, "timer/env.step_frac": 0.02325214434970675, "timer/env.step_avg": 0.08457859212701971, "timer/env.step_min": 0.023442506790161133, "timer/env.step_max": 1.619206190109253, "timer/replay._sample_count": 35104.0, "timer/replay._sample_total": 17.122549772262573, "timer/replay._sample_frac": 0.017117419815848228, "timer/replay._sample_avg": 0.0004877663449254379, "timer/replay._sample_min": 0.0003612041473388672, "timer/replay._sample_max": 0.032747745513916016, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 275.0, "timer/agent.policy_total": 4.352811813354492, "timer/agent.policy_frac": 0.004351507700638842, "timer/agent.policy_avg": 0.015828406594016336, "timer/agent.policy_min": 0.009915590286254883, "timer/agent.policy_max": 0.04068326950073242, "timer/dataset_train_count": 2194.0, "timer/dataset_train_total": 0.3879718780517578, "timer/dataset_train_frac": 0.0003878556407593645, "timer/dataset_train_avg": 0.00017683312582122051, "timer/dataset_train_min": 8.821487426757812e-05, "timer/dataset_train_max": 0.0011715888977050781, "timer/agent.train_count": 2194.0, "timer/agent.train_total": 970.5988755226135, "timer/agent.train_frac": 0.9703080818036015, "timer/agent.train_avg": 0.44238781929016113, "timer/agent.train_min": 0.4330615997314453, "timer/agent.train_max": 0.5593359470367432, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47560954093933105, "timer/agent.report_frac": 0.00047546704719583386, "timer/agent.report_avg": 0.23780477046966553, "timer/agent.report_min": 0.2320234775543213, "timer/agent.report_max": 0.24358606338500977, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.266334533691406e-05, "timer/dataset_eval_frac": 3.265355932138753e-08, "timer/dataset_eval_avg": 3.266334533691406e-05, "timer/dataset_eval_min": 3.266334533691406e-05, "timer/dataset_eval_max": 3.266334533691406e-05, "fps": 2.193314105634669}
{"step": 86104, "time": 39396.537658929825, "episode/length": 159.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 86264, "time": 39469.90411758423, "episode/length": 243.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9795081967213115, "episode/intrinsic_return": 0.0}
{"step": 86400, "time": 39532.49472570419, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 86424, "time": 39544.78349232674, "episode/length": 165.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 86576, "time": 39614.53212809563, "episode/length": 95.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9479166666666666, "episode/intrinsic_return": 0.0}
{"step": 86624, "time": 39637.73231005669, "episode/length": 186.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 86816, "time": 39725.21189689636, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 86848, "time": 39741.05262875557, "episode/length": 33.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8529411764705882, "episode/intrinsic_return": 0.0}
{"step": 87072, "time": 39843.02650475502, "episode/length": 177.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 87296, "time": 39944.96286821365, "episode/length": 148.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 87648, "time": 40104.71846532822, "episode/length": 172.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 87752, "time": 40153.3640768528, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 87960, "time": 40248.06312894821, "episode/length": 191.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 88104, "time": 40314.51677775383, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.651013295584862, "train/action_min": 0.0, "train/action_std": 4.318290274077599, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04109019887795962, "train/actor_opt_grad_steps": 85455.0, "train/actor_opt_loss": -17.301492895144936, "train/adv_mag": 0.6366908447731525, "train/adv_max": 0.5806319664377685, "train/adv_mean": 0.0004463802816068867, "train/adv_min": -0.5033251202981407, "train/adv_std": 0.049394041633045456, "train/cont_avg": 0.9944855576261468, "train/cont_loss_mean": 4.6310145825132774e-05, "train/cont_loss_std": 0.0013796211452889436, "train/cont_neg_acc": 0.9993386246539928, "train/cont_neg_loss": 0.001608311209482304, "train/cont_pos_acc": 0.9999864771278626, "train/cont_pos_loss": 3.724252399828821e-05, "train/cont_pred": 0.9944746004878928, "train/cont_rate": 0.9944855576261468, "train/dyn_loss_mean": 2.935437771158481, "train/dyn_loss_std": 7.769134694283162, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.2949079223182223, "train/extr_critic_critic_opt_grad_steps": 85455.0, "train/extr_critic_critic_opt_loss": 15119.46163632454, "train/extr_critic_mag": 14.711685276906424, "train/extr_critic_max": 14.711685276906424, "train/extr_critic_mean": 3.2907448033674047, "train/extr_critic_min": -0.6712665399280163, "train/extr_critic_std": 2.9626607353534173, "train/extr_return_normed_mag": 1.506885065398085, "train/extr_return_normed_max": 1.506885065398085, "train/extr_return_normed_mean": 0.3526612771760433, "train/extr_return_normed_min": -0.08956157088860733, "train/extr_return_normed_std": 0.29863630836709926, "train/extr_return_rate": 0.8598483937595962, "train/extr_return_raw_mag": 14.906090823882217, "train/extr_return_raw_max": 14.906090823882217, "train/extr_return_raw_mean": 3.2943846654454503, "train/extr_return_raw_min": -1.1282796107847757, "train/extr_return_raw_std": 2.998161794395622, "train/extr_reward_mag": 1.0312311889928416, "train/extr_reward_max": 1.0312311889928416, "train/extr_reward_mean": 0.027787095350170626, "train/extr_reward_min": -0.6877752066752233, "train/extr_reward_std": 0.16825722147702077, "train/image_loss_mean": 1.5338248509332675, "train/image_loss_std": 4.794293377924403, "train/model_loss_mean": 3.3307043368663263, "train/model_loss_std": 8.56179758605607, "train/model_opt_grad_norm": 31.711864493308813, "train/model_opt_grad_steps": 85381.61926605504, "train/model_opt_loss": 5532.303624704344, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1674.3119266055046, "train/policy_entropy_mag": 2.4514855102661555, "train/policy_entropy_max": 2.4514855102661555, "train/policy_entropy_mean": 0.5444688239228834, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.5891434495602179, "train/policy_logprob_mag": 7.438383979534884, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5441044234081146, "train/policy_logprob_min": -7.438383979534884, "train/policy_logprob_std": 1.0935049888190873, "train/policy_randomness_mag": 0.8652668059419054, "train/policy_randomness_max": 0.8652668059419054, "train/policy_randomness_mean": 0.19217360156391738, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.20794178586487377, "train/post_ent_mag": 42.16353106717451, "train/post_ent_max": 42.16353106717451, "train/post_ent_mean": 22.541859714263076, "train/post_ent_min": 12.35767682976679, "train/post_ent_std": 4.025331481881098, "train/prior_ent_mag": 76.2801696357377, "train/prior_ent_max": 76.2801696357377, "train/prior_ent_mean": 25.465260531924187, "train/prior_ent_min": 13.510989018536488, "train/prior_ent_std": 9.028150287243204, "train/rep_loss_mean": 2.935437771158481, "train/rep_loss_std": 7.769134694283162, "train/reward_avg": 0.019592173079267965, "train/reward_loss_mean": 0.035570495129656904, "train/reward_loss_std": 0.16595643105993577, "train/reward_max_data": 1.0183486282278638, "train/reward_max_pred": 1.0191017323677694, "train/reward_neg_acc": 0.9965381504745658, "train/reward_neg_loss": 0.01842493691520099, "train/reward_pos_acc": 0.9906249180299427, "train/reward_pos_loss": 0.7158153765245315, "train/reward_pred": 0.01949467420056804, "train/reward_rate": 0.02462012614678899, "train_stats/sum_log_reward": 3.715384556696965, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 3.6923076923076925, "train_stats/max_log_achievement_collect_sapling": 2.1538461538461537, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 2.6153846153846154, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.07692307692307693, "train_stats/max_log_achievement_make_wood_pickaxe": 0.07692307692307693, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 2.076923076923077, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 0.9230769230769231, "train_stats/max_log_achievement_wake_up": 1.7692307692307692, "train_stats/mean_log_entropy": 0.49778446096640366, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 9.541363397147506e-07, "report/cont_loss_std": 5.997369044052903e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 4.0739191717875656e-06, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 9.295711151935393e-07, "report/cont_pred": 0.9921866655349731, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 2.9679856300354004, "report/dyn_loss_std": 7.969965934753418, "report/image_loss_mean": 1.3831536769866943, "report/image_loss_std": 4.585254669189453, "report/model_loss_mean": 3.2081592082977295, "report/model_loss_std": 8.69115924835205, "report/post_ent_mag": 45.607208251953125, "report/post_ent_max": 45.607208251953125, "report/post_ent_mean": 23.30661964416504, "report/post_ent_min": 14.284994125366211, "report/post_ent_std": 3.7669472694396973, "report/prior_ent_mag": 76.66943359375, "report/prior_ent_max": 76.66943359375, "report/prior_ent_mean": 26.222183227539062, "report/prior_ent_min": 14.538026809692383, "report/prior_ent_std": 9.068549156188965, "report/rep_loss_mean": 2.9679856300354004, "report/rep_loss_std": 7.969965934753418, "report/reward_avg": 0.0283203125, "report/reward_loss_mean": 0.044213149696588516, "report/reward_loss_std": 0.1920434534549713, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.1012403964996338, "report/reward_neg_acc": 0.992929220199585, "report/reward_neg_loss": 0.019714264199137688, "report/reward_pos_acc": 0.9705882668495178, "report/reward_pos_loss": 0.757563054561615, "report/reward_pred": 0.02817448228597641, "report/reward_rate": 0.033203125, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 1.316207999479957e-06, "eval/cont_loss_std": 1.3909817425883375e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 3.5547745937947184e-05, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 1.1819665814982727e-06, "eval/cont_pred": 0.9960927963256836, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 25.537233352661133, "eval/dyn_loss_std": 13.74743366241455, "eval/image_loss_mean": 47.40779113769531, "eval/image_loss_std": 57.23160171508789, "eval/model_loss_mean": 62.97917938232422, "eval/model_loss_std": 62.87897491455078, "eval/post_ent_mag": 45.607208251953125, "eval/post_ent_max": 45.607208251953125, "eval/post_ent_mean": 27.104793548583984, "eval/post_ent_min": 16.748260498046875, "eval/post_ent_std": 3.490694999694824, "eval/prior_ent_mag": 76.66943359375, "eval/prior_ent_max": 76.66943359375, "eval/prior_ent_mean": 35.57714080810547, "eval/prior_ent_min": 17.391403198242188, "eval/prior_ent_std": 9.012310981750488, "eval/rep_loss_mean": 25.537233352661133, "eval/rep_loss_std": 13.74743366241455, "eval/reward_avg": 0.02041015587747097, "eval/reward_loss_mean": 0.24904358386993408, "eval/reward_loss_std": 1.4273312091827393, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0000543594360352, "eval/reward_neg_acc": 0.9929859638214111, "eval/reward_neg_loss": 0.1752341091632843, "eval/reward_pos_acc": 0.6538462042808533, "eval/reward_pos_loss": 3.0821919441223145, "eval/reward_pred": 0.016387341544032097, "eval/reward_rate": 0.025390625, "replay/size": 87600.0, "replay/inserts": 2183.0, "replay/samples": 34928.0, "replay/insert_wait_avg": 2.5690885186468415e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.218974367282394e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 17616.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 6.556510925292969e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2449476718903, "timer/env.step_count": 272.0, "timer/env.step_total": 27.028146982192993, "timer/env.step_frac": 0.027021528121788645, "timer/env.step_avg": 0.09936818743453306, "timer/env.step_min": 0.023659229278564453, "timer/env.step_max": 2.072838306427002, "timer/replay._sample_count": 34928.0, "timer/replay._sample_total": 16.84535837173462, "timer/replay._sample_frac": 0.01684123315088255, "timer/replay._sample_avg": 0.0004822880889754529, "timer/replay._sample_min": 0.00035190582275390625, "timer/replay._sample_max": 0.010370969772338867, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 272.0, "timer/agent.policy_total": 4.288512229919434, "timer/agent.policy_frac": 0.004287462026077828, "timer/agent.policy_avg": 0.015766589080586153, "timer/agent.policy_min": 0.009887456893920898, "timer/agent.policy_max": 0.018796443939208984, "timer/dataset_train_count": 2183.0, "timer/dataset_train_total": 0.41227030754089355, "timer/dataset_train_frac": 0.0004121693476187698, "timer/dataset_train_avg": 0.00018885492787031313, "timer/dataset_train_min": 8.845329284667969e-05, "timer/dataset_train_max": 0.03171491622924805, "timer/agent.train_count": 2183.0, "timer/agent.train_total": 966.8274056911469, "timer/agent.train_frac": 0.9665906415638249, "timer/agent.train_avg": 0.4428893292217805, "timer/agent.train_min": 0.42303895950317383, "timer/agent.train_max": 0.5607082843780518, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4725029468536377, "timer/agent.report_frac": 0.0004723872366997774, "timer/agent.report_avg": 0.23625147342681885, "timer/agent.report_min": 0.22939348220825195, "timer/agent.report_max": 0.24310946464538574, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.123283386230469e-05, "timer/dataset_eval_frac": 3.122518532585478e-08, "timer/dataset_eval_avg": 3.123283386230469e-05, "timer/dataset_eval_min": 3.123283386230469e-05, "timer/dataset_eval_max": 3.123283386230469e-05, "fps": 2.182434504769418}
{"step": 88192, "time": 40354.132158756256, "episode/length": 139.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 88216, "time": 40366.28716492653, "episode/length": 198.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 88608, "time": 40543.34609103203, "episode/length": 163.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9878048780487805, "episode/intrinsic_return": 0.0}
{"step": 88656, "time": 40566.38833665848, "episode/length": 229.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 88920, "time": 40685.69405055046, "episode/length": 258.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9845559845559846, "episode/intrinsic_return": 0.0}
{"step": 88952, "time": 40701.349430799484, "episode/length": 162.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 89160, "time": 40795.769725084305, "episode/length": 175.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 89408, "time": 40908.39260959625, "episode/length": 180.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 89448, "time": 40927.70604801178, "episode/length": 153.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 89776, "time": 41075.52284026146, "episode/length": 139.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9571428571428572, "episode/intrinsic_return": 0.0}
{"step": 89792, "time": 41084.580689907074, "episode/length": 199.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 90064, "time": 41221.52419137955, "eval_episode/length": 49.0, "eval_episode/score": -0.9000000059604645, "eval_episode/reward_rate": 0.98}
{"step": 90064, "time": 41226.998165369034, "eval_episode/length": 154.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9935483870967742}
{"step": 90064, "time": 41228.72827005386, "eval_episode/length": 157.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9936708860759493}
{"step": 90064, "time": 41230.30935049057, "eval_episode/length": 158.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9937106918238994}
{"step": 90064, "time": 41232.64609837532, "eval_episode/length": 182.0, "eval_episode/score": 3.0999999716877937, "eval_episode/reward_rate": 0.994535519125683}
{"step": 90064, "time": 41234.54823803902, "eval_episode/length": 143.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9930555555555556}
{"step": 90064, "time": 41236.14953827858, "eval_episode/length": 195.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9948979591836735}
{"step": 90064, "time": 41238.13003158569, "eval_episode/length": 208.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9808612440191388}
{"step": 90080, "time": 41245.284242391586, "episode/length": 183.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 90088, "time": 41250.36495876312, "episode/length": 79.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.925, "episode/intrinsic_return": 0.0}
{"step": 90226, "time": 41314.74813079834, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.734861841741598, "train/action_min": 0.0, "train/action_std": 4.2070268156393515, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04041451556643225, "train/actor_opt_grad_steps": 87605.0, "train/actor_opt_loss": -16.79064289747544, "train/adv_mag": 0.579747070681374, "train/adv_max": 0.531948299621636, "train/adv_mean": 0.0014366617466226406, "train/adv_min": -0.4564675514428121, "train/adv_std": 0.04791747908687816, "train/cont_avg": 0.9943801591981132, "train/cont_loss_mean": 8.256479023705176e-05, "train/cont_loss_std": 0.0025609856484758234, "train/cont_neg_acc": 0.9978672986346964, "train/cont_neg_loss": 0.014188787706794643, "train/cont_pos_acc": 0.9999953438088579, "train/cont_pos_loss": 2.561431834863551e-05, "train/cont_pred": 0.9943802348285351, "train/cont_rate": 0.9943801591981132, "train/dyn_loss_mean": 2.9610194845019646, "train/dyn_loss_std": 7.831826614883711, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.2756132542524699, "train/extr_critic_critic_opt_grad_steps": 87605.0, "train/extr_critic_critic_opt_loss": 15051.544686947229, "train/extr_critic_mag": 12.888931359884873, "train/extr_critic_max": 12.888931359884873, "train/extr_critic_mean": 3.0467815652208508, "train/extr_critic_min": -0.6823826044235589, "train/extr_critic_std": 2.7098967742245152, "train/extr_return_normed_mag": 1.4782761644642308, "train/extr_return_normed_max": 1.4782761644642308, "train/extr_return_normed_mean": 0.3608436370092743, "train/extr_return_normed_min": -0.09788943876354199, "train/extr_return_normed_std": 0.3018347549972669, "train/extr_return_rate": 0.8668076688388608, "train/extr_return_raw_mag": 13.265388718191183, "train/extr_return_raw_max": 13.265388718191183, "train/extr_return_raw_mean": 3.0600795419710987, "train/extr_return_raw_min": -1.125107062312792, "train/extr_return_raw_std": 2.7551206406557336, "train/extr_reward_mag": 1.032503494114246, "train/extr_reward_max": 1.032503494114246, "train/extr_reward_mean": 0.02808130172713888, "train/extr_reward_min": -0.690027118853803, "train/extr_reward_std": 0.16963516889175154, "train/image_loss_mean": 1.6003350576139845, "train/image_loss_std": 5.018505195401749, "train/model_loss_mean": 3.412457863114915, "train/model_loss_std": 8.839828032367635, "train/model_opt_grad_norm": 32.82469849766425, "train/model_opt_grad_steps": 87530.34905660378, "train/model_opt_loss": 6121.7623912883255, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1810.1415094339623, "train/policy_entropy_mag": 2.4597800947585196, "train/policy_entropy_max": 2.4597800947585196, "train/policy_entropy_mean": 0.5397300970441891, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.5844685876706861, "train/policy_logprob_mag": 7.438383930134323, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5393019692515427, "train/policy_logprob_min": -7.438383930134323, "train/policy_logprob_std": 1.0931868924284882, "train/policy_randomness_mag": 0.8681944285361272, "train/policy_randomness_max": 0.8681944285361272, "train/policy_randomness_mean": 0.19050103967201035, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.20629176483401712, "train/post_ent_mag": 42.57316081928757, "train/post_ent_max": 42.57316081928757, "train/post_ent_mean": 22.76822953853967, "train/post_ent_min": 12.45627771683459, "train/post_ent_std": 4.06690143526725, "train/prior_ent_mag": 76.34823183743458, "train/prior_ent_max": 76.34823183743458, "train/prior_ent_mean": 25.694969357184643, "train/prior_ent_min": 13.558457756942174, "train/prior_ent_std": 9.047468558797297, "train/rep_loss_mean": 2.9610194845019646, "train/rep_loss_std": 7.831826614883711, "train/reward_avg": 0.019172409233057273, "train/reward_loss_mean": 0.035428558713492916, "train/reward_loss_std": 0.16872433464060416, "train/reward_max_data": 1.0198113254781038, "train/reward_max_pred": 1.0186720175563164, "train/reward_neg_acc": 0.9966239321906611, "train/reward_neg_loss": 0.018274577739780314, "train/reward_pos_acc": 0.9891316463362496, "train/reward_pos_loss": 0.7257315881972043, "train/reward_pred": 0.01903482090093125, "train/reward_rate": 0.02424362470518868, "train_stats/sum_log_reward": 3.0230769285788903, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 2.4615384615384617, "train_stats/max_log_achievement_collect_sapling": 1.3846153846153846, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 1.6153846153846154, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.15384615384615385, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.3846153846153846, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 0.46153846153846156, "train_stats/max_log_achievement_wake_up": 1.5384615384615385, "train_stats/mean_log_entropy": 0.47571525894678557, "eval_stats/sum_log_reward": 3.7249999195337296, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 3.875, "eval_stats/max_log_achievement_collect_sapling": 1.875, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 1.375, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 1.875, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 0.625, "eval_stats/max_log_achievement_wake_up": 1.5, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 1.745516442497319e-06, "report/cont_loss_std": 3.9701310015516356e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00043152342550456524, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 4.827018074138323e-07, "report/cont_pred": 0.9970711469650269, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 2.57059383392334, "report/dyn_loss_std": 7.571226119995117, "report/image_loss_mean": 1.4796290397644043, "report/image_loss_std": 5.3013691902160645, "report/model_loss_mean": 3.046814441680908, "report/model_loss_std": 8.72176456451416, "report/post_ent_mag": 41.764835357666016, "report/post_ent_max": 41.764835357666016, "report/post_ent_mean": 22.707386016845703, "report/post_ent_min": 11.706762313842773, "report/post_ent_std": 4.4050211906433105, "report/prior_ent_mag": 76.5299072265625, "report/prior_ent_max": 76.5299072265625, "report/prior_ent_mean": 25.07839012145996, "report/prior_ent_min": 12.583317756652832, "report/prior_ent_std": 8.690557479858398, "report/rep_loss_mean": 2.57059383392334, "report/rep_loss_std": 7.571226119995117, "report/reward_avg": 0.01748047024011612, "report/reward_loss_mean": 0.02482721395790577, "report/reward_loss_std": 0.13770076632499695, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0005507469177246, "report/reward_neg_acc": 0.999002993106842, "report/reward_neg_loss": 0.011240408755838871, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6737589240074158, "report/reward_pred": 0.018169768154621124, "report/reward_rate": 0.0205078125, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.0009857788681983948, "eval/cont_loss_std": 0.03147013112902641, "eval/cont_neg_acc": 0.800000011920929, "eval/cont_neg_loss": 0.2017887383699417, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 4.848799903811596e-07, "eval/cont_pred": 0.99573814868927, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 23.37289047241211, "eval/dyn_loss_std": 13.408080101013184, "eval/image_loss_mean": 47.09473419189453, "eval/image_loss_std": 58.37221145629883, "eval/model_loss_mean": 61.311920166015625, "eval/model_loss_std": 63.518226623535156, "eval/post_ent_mag": 45.824790954589844, "eval/post_ent_max": 45.824790954589844, "eval/post_ent_mean": 27.344192504882812, "eval/post_ent_min": 15.517459869384766, "eval/post_ent_std": 3.5236318111419678, "eval/prior_ent_mag": 76.5299072265625, "eval/prior_ent_max": 76.5299072265625, "eval/prior_ent_mean": 36.00779724121094, "eval/prior_ent_min": 14.769640922546387, "eval/prior_ent_std": 8.805447578430176, "eval/rep_loss_mean": 23.37289047241211, "eval/rep_loss_std": 13.408080101013184, "eval/reward_avg": 0.02451171912252903, "eval/reward_loss_mean": 0.1924678385257721, "eval/reward_loss_std": 1.2210434675216675, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0006003379821777, "eval/reward_neg_acc": 0.9979878664016724, "eval/reward_neg_loss": 0.06185377389192581, "eval/reward_pos_acc": 0.5333333611488342, "eval/reward_pos_loss": 4.520147323608398, "eval/reward_pred": 0.010679442435503006, "eval/reward_rate": 0.029296875, "replay/size": 89722.0, "replay/inserts": 2122.0, "replay/samples": 33952.0, "replay/insert_wait_avg": 2.6521538924092285e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.334643664166795e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 19288.0, "eval_replay/inserts": 1672.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0514943793629916e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2183427810669, "timer/env.step_count": 266.0, "timer/env.step_total": 27.306751251220703, "timer/env.step_frac": 0.027300790320736748, "timer/env.step_avg": 0.10265695959105528, "timer/env.step_min": 0.023326635360717773, "timer/env.step_max": 2.1023778915405273, "timer/replay._sample_count": 33952.0, "timer/replay._sample_total": 16.423664808273315, "timer/replay._sample_frac": 0.01642007960242758, "timer/replay._sample_avg": 0.0004837318805452791, "timer/replay._sample_min": 0.0003561973571777344, "timer/replay._sample_max": 0.025719881057739258, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 475.0, "timer/agent.policy_total": 7.337632417678833, "timer/agent.policy_frac": 0.007336030648345081, "timer/agent.policy_avg": 0.015447647195113332, "timer/agent.policy_min": 0.00934457778930664, "timer/agent.policy_max": 0.02579784393310547, "timer/dataset_train_count": 2122.0, "timer/dataset_train_total": 0.3729403018951416, "timer/dataset_train_frac": 0.00037285889084796836, "timer/dataset_train_avg": 0.0001757494353888509, "timer/dataset_train_min": 9.036064147949219e-05, "timer/dataset_train_max": 0.001165628433227539, "timer/agent.train_count": 2122.0, "timer/agent.train_total": 935.5871143341064, "timer/agent.train_frac": 0.9353828802346736, "timer/agent.train_avg": 0.44089873437045546, "timer/agent.train_min": 0.4316375255584717, "timer/agent.train_max": 0.6747980117797852, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47283029556274414, "timer/agent.report_frac": 0.0004727270790176258, "timer/agent.report_avg": 0.23641514778137207, "timer/agent.report_min": 0.22957253456115723, "timer/agent.report_max": 0.24325776100158691, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0994415283203125e-05, "timer/dataset_eval_frac": 3.098764935366452e-08, "timer/dataset_eval_avg": 3.0994415283203125e-05, "timer/dataset_eval_min": 3.0994415283203125e-05, "timer/dataset_eval_max": 3.0994415283203125e-05, "fps": 2.1215096749340785}
{"step": 90288, "time": 41342.799010276794, "episode/length": 170.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 90424, "time": 41405.19748187065, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 90480, "time": 41431.77911758423, "episode/length": 87.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9545454545454546, "episode/intrinsic_return": 0.0}
{"step": 90600, "time": 41487.0307431221, "episode/length": 205.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 90752, "time": 41556.573863983154, "episode/length": 167.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 91040, "time": 41686.913103342056, "episode/length": 155.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 91400, "time": 41849.725642204285, "episode/length": 138.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.0}
{"step": 91552, "time": 41919.28327584267, "episode/length": 140.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 91768, "time": 42017.66719651222, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9565217391304348, "episode/intrinsic_return": 0.0}
{"step": 91776, "time": 42022.71828055382, "episode/length": 146.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9523809523809523, "episode/intrinsic_return": 0.0}
{"step": 91904, "time": 42081.491154909134, "episode/length": 226.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 92176, "time": 42204.44810962677, "episode/length": 261.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9770992366412213, "episode/intrinsic_return": 0.0}
{"step": 92417, "time": 42314.79393672943, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.645732165471604, "train/action_min": 0.0, "train/action_std": 4.196459921527671, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04188867190589099, "train/actor_opt_grad_steps": 89760.0, "train/actor_opt_loss": -17.091388908151078, "train/adv_mag": 0.6307569608840768, "train/adv_max": 0.5673430922641057, "train/adv_mean": 0.001211659533140489, "train/adv_min": -0.5180420276781196, "train/adv_std": 0.050234655181975126, "train/cont_avg": 0.9945553296232876, "train/cont_loss_mean": 3.319353371362262e-05, "train/cont_loss_std": 0.0010119352654687625, "train/cont_neg_acc": 0.9975646881208028, "train/cont_neg_loss": 0.004589351877302968, "train/cont_pos_acc": 0.9999910133070053, "train/cont_pos_loss": 1.5449865052533868e-05, "train/cont_pred": 0.994556044062523, "train/cont_rate": 0.9945553296232876, "train/dyn_loss_mean": 2.9623014382575743, "train/dyn_loss_std": 7.833949337266896, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.2615055441856384, "train/extr_critic_critic_opt_grad_steps": 89760.0, "train/extr_critic_critic_opt_loss": 15114.62340361016, "train/extr_critic_mag": 13.220542237094548, "train/extr_critic_max": 13.220542237094548, "train/extr_critic_mean": 2.7785988403781907, "train/extr_critic_min": -0.6756403467970896, "train/extr_critic_std": 2.7547358247243108, "train/extr_return_normed_mag": 1.541194529293879, "train/extr_return_normed_max": 1.541194529293879, "train/extr_return_normed_mean": 0.3356354803391243, "train/extr_return_normed_min": -0.099244334296957, "train/extr_return_normed_std": 0.3112251212199529, "train/extr_return_rate": 0.8514329295724494, "train/extr_return_raw_mag": 13.657539994749305, "train/extr_return_raw_max": 13.657539994749305, "train/extr_return_raw_mean": 2.789562598211036, "train/extr_return_raw_min": -1.1308695940666547, "train/extr_return_raw_std": 2.8057536681493125, "train/extr_reward_mag": 1.024665341529672, "train/extr_reward_max": 1.024665341529672, "train/extr_reward_mean": 0.02803110981521677, "train/extr_reward_min": -0.6902269304615177, "train/extr_reward_std": 0.17004676234640487, "train/image_loss_mean": 1.5689905400145543, "train/image_loss_std": 4.770585062296967, "train/model_loss_mean": 3.382618310788995, "train/model_loss_std": 8.596041918889572, "train/model_opt_grad_norm": 31.853528189002922, "train/model_opt_grad_steps": 89683.77625570777, "train/model_opt_loss": 6579.779981360588, "train/model_opt_model_opt_grad_overflow": 0.0045662100456621, "train/model_opt_model_opt_grad_scale": 1940.6392694063927, "train/policy_entropy_mag": 2.466166501720202, "train/policy_entropy_max": 2.466166501720202, "train/policy_entropy_mean": 0.5596619479732426, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6081230458059267, "train/policy_logprob_mag": 7.438383984239134, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5589837694549125, "train/policy_logprob_min": -7.438383984239134, "train/policy_logprob_std": 1.1049779762416125, "train/policy_randomness_mag": 0.870448549316354, "train/policy_randomness_max": 0.870448549316354, "train/policy_randomness_mean": 0.19753610733981547, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.2146407490995921, "train/post_ent_mag": 41.93841725179594, "train/post_ent_max": 41.93841725179594, "train/post_ent_mean": 22.939350241395438, "train/post_ent_min": 12.526871676858702, "train/post_ent_std": 4.0828398493326965, "train/prior_ent_mag": 76.36692458200672, "train/prior_ent_max": 76.36692458200672, "train/prior_ent_mean": 25.869983786317313, "train/prior_ent_min": 13.788556046681862, "train/prior_ent_std": 9.031112002455481, "train/rep_loss_mean": 2.9623014382575743, "train/rep_loss_std": 7.833949337266896, "train/reward_avg": 0.019512075335467786, "train/reward_loss_mean": 0.0362137270980774, "train/reward_loss_std": 0.17087620153138627, "train/reward_max_data": 1.0132420122895611, "train/reward_max_pred": 1.0135020344224694, "train/reward_neg_acc": 0.9962395802480445, "train/reward_neg_loss": 0.018917938641200192, "train/reward_pos_acc": 0.9887281653543586, "train/reward_pos_loss": 0.725600945895121, "train/reward_pred": 0.019337392750208918, "train/reward_rate": 0.0244408176369863, "train_stats/sum_log_reward": 4.266666571299235, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 2.0833333333333335, "train_stats/max_log_achievement_collect_sapling": 2.1666666666666665, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 3.1666666666666665, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.08333333333333333, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 2.1666666666666665, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 1.1666666666666667, "train_stats/max_log_achievement_wake_up": 1.75, "train_stats/mean_log_entropy": 0.5119937832156817, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 1.2451195289031602e-05, "report/cont_loss_std": 0.00036772715975530446, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.6845773643581197e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.2429632079147268e-05, "report/cont_pred": 0.9951050281524658, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 3.0348262786865234, "report/dyn_loss_std": 8.196083068847656, "report/image_loss_mean": 1.489689826965332, "report/image_loss_std": 4.533111095428467, "report/model_loss_mean": 3.3328206539154053, "report/model_loss_std": 8.79081916809082, "report/post_ent_mag": 41.576438903808594, "report/post_ent_max": 41.576438903808594, "report/post_ent_mean": 24.137325286865234, "report/post_ent_min": 14.100096702575684, "report/post_ent_std": 3.820998430252075, "report/prior_ent_mag": 76.25875854492188, "report/prior_ent_max": 76.25875854492188, "report/prior_ent_mean": 27.009429931640625, "report/prior_ent_min": 15.619779586791992, "report/prior_ent_std": 8.533185005187988, "report/rep_loss_mean": 3.0348262786865234, "report/rep_loss_std": 8.196083068847656, "report/reward_avg": 0.01621093787252903, "report/reward_loss_mean": 0.022222859784960747, "report/reward_loss_std": 0.12462840229272842, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0011696815490723, "report/reward_neg_acc": 0.9980080127716064, "report/reward_neg_loss": 0.009233514778316021, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6742879748344421, "report/reward_pred": 0.016933592036366463, "report/reward_rate": 0.01953125, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.0066261328756809235, "eval/cont_loss_std": 0.18989072740077972, "eval/cont_neg_acc": 0.5, "eval/cont_neg_loss": 1.696251630783081, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 1.5131833208670287e-07, "eval/cont_pred": 0.9975839853286743, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 24.48621368408203, "eval/dyn_loss_std": 13.884857177734375, "eval/image_loss_mean": 38.858924865722656, "eval/image_loss_std": 41.07364273071289, "eval/model_loss_mean": 53.749908447265625, "eval/model_loss_std": 46.845298767089844, "eval/post_ent_mag": 45.962242126464844, "eval/post_ent_max": 45.962242126464844, "eval/post_ent_mean": 27.643842697143555, "eval/post_ent_min": 18.670169830322266, "eval/post_ent_std": 2.8555402755737305, "eval/prior_ent_mag": 76.25875854492188, "eval/prior_ent_max": 76.25875854492188, "eval/prior_ent_mean": 37.46150207519531, "eval/prior_ent_min": 17.751049041748047, "eval/prior_ent_std": 8.562642097473145, "eval/rep_loss_mean": 24.48621368408203, "eval/rep_loss_std": 13.884857177734375, "eval/reward_avg": 0.01718749850988388, "eval/reward_loss_mean": 0.19263234734535217, "eval/reward_loss_std": 1.0496736764907837, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0011746883392334, "eval/reward_neg_acc": 0.9960119724273682, "eval/reward_neg_loss": 0.13858674466609955, "eval/reward_pos_acc": 0.761904776096344, "eval/reward_pos_loss": 2.773953437805176, "eval/reward_pred": 0.01422029361128807, "eval/reward_rate": 0.0205078125, "replay/size": 91913.0, "replay/inserts": 2191.0, "replay/samples": 35056.0, "replay/insert_wait_avg": 2.626195339131497e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.282866021369158e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 19288.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 6.705522537231445e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0350112915039, "timer/env.step_count": 274.0, "timer/env.step_total": 25.714528560638428, "timer/env.step_frac": 0.025713628293302628, "timer/env.step_avg": 0.09384864438189207, "timer/env.step_min": 0.023772478103637695, "timer/env.step_max": 1.8252720832824707, "timer/replay._sample_count": 35056.0, "timer/replay._sample_total": 17.035977363586426, "timer/replay._sample_frac": 0.017035380932898705, "timer/replay._sample_avg": 0.00048596466692110983, "timer/replay._sample_min": 0.0003418922424316406, "timer/replay._sample_max": 0.02560591697692871, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 274.0, "timer/agent.policy_total": 4.31269383430481, "timer/agent.policy_frac": 0.004312542846610084, "timer/agent.policy_avg": 0.01573975851936062, "timer/agent.policy_min": 0.009770870208740234, "timer/agent.policy_max": 0.03687310218811035, "timer/dataset_train_count": 2191.0, "timer/dataset_train_total": 0.42257189750671387, "timer/dataset_train_frac": 0.0004225571032367954, "timer/dataset_train_avg": 0.00019286713715504968, "timer/dataset_train_min": 9.250640869140625e-05, "timer/dataset_train_max": 0.03370165824890137, "timer/agent.train_count": 2191.0, "timer/agent.train_total": 967.8687613010406, "timer/agent.train_frac": 0.9678348761520641, "timer/agent.train_avg": 0.4417474948886539, "timer/agent.train_min": 0.4224364757537842, "timer/agent.train_max": 0.5684084892272949, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4770841598510742, "timer/agent.report_frac": 0.00047706745710326655, "timer/agent.report_avg": 0.2385420799255371, "timer/agent.report_min": 0.23415184020996094, "timer/agent.report_max": 0.24293231964111328, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0279159545898438e-05, "timer/dataset_eval_frac": 3.027809947053169e-08, "timer/dataset_eval_avg": 3.0279159545898438e-05, "timer/dataset_eval_min": 3.0279159545898438e-05, "timer/dataset_eval_max": 3.0279159545898438e-05, "fps": 2.1908956464387037}
{"step": 92496, "time": 42350.886024713516, "episode/length": 181.0, "episode/score": 2.0999999791383743, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 92592, "time": 42395.823575258255, "episode/length": 229.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 92632, "time": 42415.45712137222, "episode/length": 107.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9537037037037037, "episode/intrinsic_return": 0.0}
{"step": 93056, "time": 42608.76288533211, "episode/length": 159.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 93120, "time": 42639.309898376465, "episode/length": 151.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 93304, "time": 42723.86263513565, "episode/length": 140.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9574468085106383, "episode/intrinsic_return": 0.0}
{"step": 93528, "time": 42826.414610147476, "episode/length": 265.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9962406015037594, "episode/intrinsic_return": 0.0}
{"step": 93632, "time": 42874.897755622864, "episode/length": 259.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9961538461538462, "episode/intrinsic_return": 0.0}
{"step": 93672, "time": 42894.35797715187, "episode/length": 146.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 94056, "time": 43068.77838420868, "episode/length": 52.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 94096, "time": 43088.37362098694, "episode/length": 187.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 94136, "time": 43108.09435892105, "episode/length": 187.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 94448, "time": 43249.83928894997, "episode/length": 173.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 94488, "time": 43269.425859451294, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 94568, "time": 43307.21826338768, "episode/length": 157.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 94581, "time": 43315.07651305199, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.681429955267137, "train/action_min": 0.0, "train/action_std": 4.295351570103025, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.044021411897606014, "train/actor_opt_grad_steps": 91940.0, "train/actor_opt_loss": -9.270294207109627, "train/adv_mag": 0.7102302476283042, "train/adv_max": 0.6548109487179787, "train/adv_mean": 0.0032138395138808593, "train/adv_min": -0.5439497840843992, "train/adv_std": 0.05184401228405913, "train/cont_avg": 0.9945726526497696, "train/cont_loss_mean": 6.94958560949835e-05, "train/cont_loss_std": 0.002182923894410441, "train/cont_neg_acc": 0.9950844857000536, "train/cont_neg_loss": 0.018286627613962766, "train/cont_pos_acc": 0.9999999826954257, "train/cont_pos_loss": 3.5784365047383817e-06, "train/cont_pred": 0.9945853053150089, "train/cont_rate": 0.9945726526497696, "train/dyn_loss_mean": 2.9739347119485178, "train/dyn_loss_std": 7.832079770927605, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.3909007467432506, "train/extr_critic_critic_opt_grad_steps": 91940.0, "train/extr_critic_critic_opt_loss": 15598.278423819125, "train/extr_critic_mag": 13.133031739617273, "train/extr_critic_max": 13.133031739617273, "train/extr_critic_mean": 2.5581723660367977, "train/extr_critic_min": -0.6868712078041744, "train/extr_critic_std": 2.6254292748490786, "train/extr_return_normed_mag": 1.5780633284199623, "train/extr_return_normed_max": 1.5780633284199623, "train/extr_return_normed_mean": 0.32349283450759503, "train/extr_return_normed_min": -0.09616781812384381, "train/extr_return_normed_std": 0.3056775003946322, "train/extr_return_rate": 0.82319092640679, "train/extr_return_raw_mag": 13.59568624891993, "train/extr_return_raw_max": 13.59568624891993, "train/extr_return_raw_mean": 2.5863594052978374, "train/extr_return_raw_min": -1.0954743728110319, "train/extr_return_raw_std": 2.683907287461417, "train/extr_reward_mag": 1.0245196412785262, "train/extr_reward_max": 1.0245196412785262, "train/extr_reward_mean": 0.0282531117307975, "train/extr_reward_min": -0.6753257172448295, "train/extr_reward_std": 0.16945472654933755, "train/image_loss_mean": 1.618874774275837, "train/image_loss_std": 4.809499259368615, "train/model_loss_mean": 3.43854532483536, "train/model_loss_std": 8.64821393588721, "train/model_opt_grad_norm": 31.684282364383822, "train/model_opt_grad_steps": 91862.28571428571, "train/model_opt_loss": 8596.363294750865, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2511.5207373271887, "train/policy_entropy_mag": 2.4732973795332667, "train/policy_entropy_max": 2.4732973795332667, "train/policy_entropy_mean": 0.5682696462501579, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6101414852427997, "train/policy_logprob_mag": 7.438383963800246, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5686185780208781, "train/policy_logprob_min": -7.438383963800246, "train/policy_logprob_std": 1.113229249204908, "train/policy_randomness_mag": 0.8729654380253383, "train/policy_randomness_max": 0.8729654380253383, "train/policy_randomness_mean": 0.20057424765578064, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.21535317016087369, "train/post_ent_mag": 42.79769370083435, "train/post_ent_max": 42.79769370083435, "train/post_ent_mean": 23.23352806689003, "train/post_ent_min": 12.611942475841891, "train/post_ent_std": 4.095754977195494, "train/prior_ent_mag": 76.4820310882709, "train/prior_ent_max": 76.4820310882709, "train/prior_ent_mean": 26.156496223766133, "train/prior_ent_min": 13.839794752235237, "train/prior_ent_std": 9.005620635599584, "train/rep_loss_mean": 2.9739347119485178, "train/rep_loss_std": 7.832079770927605, "train/reward_avg": 0.019237831168408905, "train/reward_loss_mean": 0.035240227708481425, "train/reward_loss_std": 0.1664010400664971, "train/reward_max_data": 1.0129032288828204, "train/reward_max_pred": 1.0133417685460384, "train/reward_neg_acc": 0.9963211919854863, "train/reward_neg_loss": 0.018165373593173956, "train/reward_pos_acc": 0.9894151141017263, "train/reward_pos_loss": 0.7267224876562022, "train/reward_pred": 0.019062208873327085, "train/reward_rate": 0.024139544930875577, "train_stats/sum_log_reward": 3.8999999364217124, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 2.6, "train_stats/max_log_achievement_collect_sapling": 1.8, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 2.466666666666667, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.13333333333333333, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.8, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 1.0666666666666667, "train_stats/max_log_achievement_wake_up": 1.5333333333333334, "train_stats/mean_log_entropy": 0.5514432062705358, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 1.770587800820067e-07, "report/cont_loss_std": 6.156371910037706e-07, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 9.298692020820454e-06, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.502567101852037e-07, "report/cont_pred": 0.9970701932907104, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 2.664811611175537, "report/dyn_loss_std": 7.50267219543457, "report/image_loss_mean": 1.1372684240341187, "report/image_loss_std": 3.3571391105651855, "report/model_loss_mean": 2.752169609069824, "report/model_loss_std": 6.9879865646362305, "report/post_ent_mag": 39.05867004394531, "report/post_ent_max": 39.05867004394531, "report/post_ent_mean": 22.620311737060547, "report/post_ent_min": 12.114517211914062, "report/post_ent_std": 3.7343966960906982, "report/prior_ent_mag": 76.51161193847656, "report/prior_ent_max": 76.51161193847656, "report/prior_ent_mean": 25.217166900634766, "report/prior_ent_min": 14.001348495483398, "report/prior_ent_std": 8.478545188903809, "report/rep_loss_mean": 2.664811611175537, "report/rep_loss_std": 7.50267219543457, "report/reward_avg": 0.011328124441206455, "report/reward_loss_mean": 0.01601412147283554, "report/reward_loss_std": 0.09629010409116745, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0006499290466309, "report/reward_neg_acc": 0.998019814491272, "report/reward_neg_loss": 0.006896349601447582, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6737962961196899, "report/reward_pred": 0.011675233952701092, "report/reward_rate": 0.013671875, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.01037816796451807, "eval/cont_loss_std": 0.30864056944847107, "eval/cont_neg_acc": 0.6666666865348816, "eval/cont_neg_loss": 1.7711690664291382, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.2742939620457037e-07, "eval/cont_pred": 0.9956437945365906, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 22.282230377197266, "eval/dyn_loss_std": 12.603151321411133, "eval/image_loss_mean": 27.731887817382812, "eval/image_loss_std": 30.916940689086914, "eval/model_loss_mean": 41.276248931884766, "eval/model_loss_std": 35.54024124145508, "eval/post_ent_mag": 45.526580810546875, "eval/post_ent_max": 45.526580810546875, "eval/post_ent_mean": 28.007543563842773, "eval/post_ent_min": 13.830862045288086, "eval/post_ent_std": 3.8706214427948, "eval/prior_ent_mag": 76.51161193847656, "eval/prior_ent_max": 76.51161193847656, "eval/prior_ent_mean": 37.84858322143555, "eval/prior_ent_min": 17.112869262695312, "eval/prior_ent_std": 9.02638053894043, "eval/rep_loss_mean": 22.282230377197266, "eval/rep_loss_std": 12.603151321411133, "eval/reward_avg": 0.01777343824505806, "eval/reward_loss_mean": 0.1646418422460556, "eval/reward_loss_std": 0.987355649471283, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.000579833984375, "eval/reward_neg_acc": 0.9970029592514038, "eval/reward_neg_loss": 0.09379889816045761, "eval/reward_pos_acc": 0.6086956858634949, "eval/reward_pos_loss": 3.247849941253662, "eval/reward_pred": 0.009650787338614464, "eval/reward_rate": 0.0224609375, "replay/size": 94077.0, "replay/inserts": 2164.0, "replay/samples": 34624.0, "replay/insert_wait_avg": 2.68793811198744e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.744816557096245e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 19288.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 1.087784767150879e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2692353725433, "timer/env.step_count": 270.0, "timer/env.step_total": 30.35482120513916, "timer/env.step_frac": 0.030346650813301998, "timer/env.step_avg": 0.11242526372273763, "timer/env.step_min": 0.023313283920288086, "timer/env.step_max": 1.7824904918670654, "timer/replay._sample_count": 34624.0, "timer/replay._sample_total": 17.571892261505127, "timer/replay._sample_frac": 0.01756716255994877, "timer/replay._sample_avg": 0.0005075061304732303, "timer/replay._sample_min": 0.00035643577575683594, "timer/replay._sample_max": 0.02062368392944336, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 270.0, "timer/agent.policy_total": 4.34013819694519, "timer/agent.policy_frac": 0.00433896999274274, "timer/agent.policy_avg": 0.016074585914611816, "timer/agent.policy_min": 0.010185003280639648, "timer/agent.policy_max": 0.02375626564025879, "timer/dataset_train_count": 2164.0, "timer/dataset_train_total": 0.43012046813964844, "timer/dataset_train_frac": 0.00043000469566521564, "timer/dataset_train_avg": 0.00019876176901092811, "timer/dataset_train_min": 9.703636169433594e-05, "timer/dataset_train_max": 0.03138327598571777, "timer/agent.train_count": 2164.0, "timer/agent.train_total": 963.2284047603607, "timer/agent.train_frac": 0.9629691394053652, "timer/agent.train_avg": 0.4451147896304809, "timer/agent.train_min": 0.43250107765197754, "timer/agent.train_max": 0.5745236873626709, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47863316535949707, "timer/agent.report_frac": 0.00047850433506658183, "timer/agent.report_avg": 0.23931658267974854, "timer/agent.report_min": 0.23131799697875977, "timer/agent.report_max": 0.2473151683807373, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.075599670410156e-05, "timer/dataset_eval_frac": 3.074771833070194e-08, "timer/dataset_eval_avg": 3.075599670410156e-05, "timer/dataset_eval_min": 3.075599670410156e-05, "timer/dataset_eval_max": 3.075599670410156e-05, "fps": 2.1633887977288353}
{"step": 95072, "time": 43535.72267484665, "episode/length": 174.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 95504, "time": 43731.71167778969, "episode/length": 170.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 95640, "time": 43794.27329945564, "episode/length": 197.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 95792, "time": 43864.19999957085, "episode/length": 282.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9964664310954063, "episode/intrinsic_return": 0.0}
{"step": 95816, "time": 43876.44944000244, "episode/length": 214.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 95904, "time": 43917.498128175735, "episode/length": 181.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 96288, "time": 44091.3828599453, "episode/length": 224.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 96504, "time": 44190.15623831749, "episode/length": 178.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 96584, "time": 44228.2750210762, "episode/length": 134.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9925925925925926, "episode/intrinsic_return": 0.0}
{"step": 96773, "time": 44315.20659971237, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.472265234820919, "train/action_min": 0.0, "train/action_std": 4.161922871794331, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04808843794138464, "train/actor_opt_grad_steps": 94120.0, "train/actor_opt_loss": -4.4631548201384605, "train/adv_mag": 0.7921123028345848, "train/adv_max": 0.7173558436844447, "train/adv_mean": 0.004332278651566567, "train/adv_min": -0.62984962087788, "train/adv_std": 0.056810395375370436, "train/cont_avg": 0.9944795234018264, "train/cont_loss_mean": 1.039143715607948e-05, "train/cont_loss_std": 0.00031333543252417433, "train/cont_neg_acc": 1.0, "train/cont_neg_loss": 8.892082240118438e-05, "train/cont_pos_acc": 0.9999955095112596, "train/cont_pos_loss": 1.0007660270869794e-05, "train/cont_pred": 0.9944722519073312, "train/cont_rate": 0.9944795234018264, "train/dyn_loss_mean": 2.985637847691366, "train/dyn_loss_std": 7.828889396092663, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.435198270022597, "train/extr_critic_critic_opt_grad_steps": 94120.0, "train/extr_critic_critic_opt_loss": 16118.102525684932, "train/extr_critic_mag": 15.057828459021163, "train/extr_critic_max": 15.057828459021163, "train/extr_critic_mean": 3.33718263776335, "train/extr_critic_min": -0.6666168328289572, "train/extr_critic_std": 3.071848131750272, "train/extr_return_normed_mag": 1.6348957857584845, "train/extr_return_normed_max": 1.6348957857584845, "train/extr_return_normed_mean": 0.3750810283640204, "train/extr_return_normed_min": -0.08773956245415288, "train/extr_return_normed_std": 0.32841594313105493, "train/extr_return_rate": 0.807185579924823, "train/extr_return_raw_mag": 15.435432085707852, "train/extr_return_raw_max": 15.435432085707852, "train/extr_return_raw_mean": 3.3786648043758793, "train/extr_return_raw_min": -1.0489241731221273, "train/extr_return_raw_std": 3.1431410633810035, "train/extr_reward_mag": 1.0285892475685572, "train/extr_reward_max": 1.0285892475685572, "train/extr_reward_mean": 0.02842454825736344, "train/extr_reward_min": -0.6902042044896514, "train/extr_reward_std": 0.17016795988632663, "train/image_loss_mean": 1.571083209830332, "train/image_loss_std": 4.770391976452309, "train/model_loss_mean": 3.397749588369779, "train/model_loss_std": 8.586627113220354, "train/model_opt_grad_norm": 31.82796598136972, "train/model_opt_grad_steps": 94040.09132420091, "train/model_opt_loss": 6564.2580990029255, "train/model_opt_model_opt_grad_overflow": 0.0045662100456621, "train/model_opt_model_opt_grad_scale": 1923.5159817351598, "train/policy_entropy_mag": 2.475799211084026, "train/policy_entropy_max": 2.475799211084026, "train/policy_entropy_mean": 0.5374949668368249, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.5871149346436539, "train/policy_logprob_mag": 7.438383977707118, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.537918180499447, "train/policy_logprob_min": -7.438383977707118, "train/policy_logprob_std": 1.0934297066845307, "train/policy_randomness_mag": 0.873848475277696, "train/policy_randomness_max": 0.873848475277696, "train/policy_randomness_mean": 0.1897121364395368, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.20722580881423602, "train/post_ent_mag": 43.00974965204387, "train/post_ent_max": 43.00974965204387, "train/post_ent_mean": 23.402217960793134, "train/post_ent_min": 12.487807352248936, "train/post_ent_std": 4.1540677721641925, "train/prior_ent_mag": 76.55097794206175, "train/prior_ent_max": 76.55097794206175, "train/prior_ent_mean": 26.340833942639772, "train/prior_ent_min": 13.847049556366384, "train/prior_ent_std": 9.043618744366789, "train/rep_loss_mean": 2.985637847691366, "train/rep_loss_std": 7.828889396092663, "train/reward_avg": 0.019422891494482074, "train/reward_loss_mean": 0.035273297107246915, "train/reward_loss_std": 0.16428410357127995, "train/reward_max_data": 1.0173516023104594, "train/reward_max_pred": 1.0171601064673297, "train/reward_neg_acc": 0.9964526810058175, "train/reward_neg_loss": 0.018135890332752303, "train/reward_pos_acc": 0.9913287345132872, "train/reward_pos_loss": 0.7192162503934887, "train/reward_pred": 0.01930933567954729, "train/reward_rate": 0.02440068493150685, "train_stats/sum_log_reward": 3.877777682410346, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 1.6666666666666667, "train_stats/max_log_achievement_collect_sapling": 2.111111111111111, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 2.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 2.0, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 0.6666666666666666, "train_stats/max_log_achievement_wake_up": 1.5555555555555556, "train_stats/mean_log_entropy": 0.5069796641667684, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 1.7242059868749493e-07, "report/cont_loss_std": 1.3912360827816883e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 4.4265198084758595e-06, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 1.5573783684885711e-07, "report/cont_pred": 0.9960936307907104, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 2.964439868927002, "report/dyn_loss_std": 7.473403453826904, "report/image_loss_mean": 1.3587487936019897, "report/image_loss_std": 4.494941711425781, "report/model_loss_mean": 3.1690030097961426, "report/model_loss_std": 8.098172187805176, "report/post_ent_mag": 39.707366943359375, "report/post_ent_max": 39.707366943359375, "report/post_ent_mean": 23.787052154541016, "report/post_ent_min": 13.758611679077148, "report/post_ent_std": 4.12519645690918, "report/prior_ent_mag": 76.66853332519531, "report/prior_ent_max": 76.66853332519531, "report/prior_ent_mean": 26.98419189453125, "report/prior_ent_min": 14.004590034484863, "report/prior_ent_std": 9.025652885437012, "report/rep_loss_mean": 2.964439868927002, "report/rep_loss_std": 7.473403453826904, "report/reward_avg": 0.02089843899011612, "report/reward_loss_mean": 0.03159036114811897, "report/reward_loss_std": 0.1477060317993164, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0006334781646729, "report/reward_neg_acc": 0.9939939975738525, "report/reward_neg_loss": 0.01552019827067852, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6737539768218994, "report/reward_pred": 0.02180342935025692, "report/reward_rate": 0.0244140625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.0014284898061305285, "eval/cont_loss_std": 0.0456865020096302, "eval/cont_neg_acc": 0.6666666865348816, "eval/cont_neg_loss": 0.4875633418560028, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 8.217065783355793e-08, "eval/cont_pred": 0.9978206753730774, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 23.641387939453125, "eval/dyn_loss_std": 14.183725357055664, "eval/image_loss_mean": 44.969520568847656, "eval/image_loss_std": 54.18454360961914, "eval/model_loss_mean": 59.332664489746094, "eval/model_loss_std": 59.87349319458008, "eval/post_ent_mag": 45.421058654785156, "eval/post_ent_max": 45.421058654785156, "eval/post_ent_mean": 27.338457107543945, "eval/post_ent_min": 14.140786170959473, "eval/post_ent_std": 3.3731837272644043, "eval/prior_ent_mag": 76.66853332519531, "eval/prior_ent_max": 76.66853332519531, "eval/prior_ent_mean": 37.00648880004883, "eval/prior_ent_min": 17.866060256958008, "eval/prior_ent_std": 8.637847900390625, "eval/rep_loss_mean": 23.641387939453125, "eval/rep_loss_std": 14.183725357055664, "eval/reward_avg": 0.02714843675494194, "eval/reward_loss_mean": 0.1768883764743805, "eval/reward_loss_std": 1.1175999641418457, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.000053882598877, "eval/reward_neg_acc": 0.9959717988967896, "eval/reward_neg_loss": 0.09056034684181213, "eval/reward_pos_acc": 0.7096773982048035, "eval/reward_pos_loss": 2.9421706199645996, "eval/reward_pred": 0.01705305650830269, "eval/reward_rate": 0.0302734375, "replay/size": 96269.0, "replay/inserts": 2192.0, "replay/samples": 35072.0, "replay/insert_wait_avg": 2.6107487017220822e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.516181055646744e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 19288.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 8.493661880493164e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1173453330994, "timer/env.step_count": 274.0, "timer/env.step_total": 21.482799530029297, "timer/env.step_frac": 0.021480278919544415, "timer/env.step_avg": 0.07840437784682225, "timer/env.step_min": 0.023363828659057617, "timer/env.step_max": 2.0668768882751465, "timer/replay._sample_count": 35072.0, "timer/replay._sample_total": 17.17977213859558, "timer/replay._sample_frac": 0.01717775640904786, "timer/replay._sample_avg": 0.0004898429555940802, "timer/replay._sample_min": 0.0003466606140136719, "timer/replay._sample_max": 0.026150941848754883, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 274.0, "timer/agent.policy_total": 4.36318039894104, "timer/agent.policy_frac": 0.004362668460157381, "timer/agent.policy_avg": 0.015924016054529342, "timer/agent.policy_min": 0.009856224060058594, "timer/agent.policy_max": 0.03399777412414551, "timer/dataset_train_count": 2192.0, "timer/dataset_train_total": 0.3980898857116699, "timer/dataset_train_frac": 0.0003980431772024532, "timer/dataset_train_avg": 0.0001816103493210173, "timer/dataset_train_min": 9.489059448242188e-05, "timer/dataset_train_max": 0.0006439685821533203, "timer/agent.train_count": 2192.0, "timer/agent.train_total": 972.1611347198486, "timer/agent.train_frac": 0.972047069532686, "timer/agent.train_avg": 0.443504167299201, "timer/agent.train_min": 0.4345972537994385, "timer/agent.train_max": 0.5589935779571533, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47390031814575195, "timer/agent.report_frac": 0.00047384471467987047, "timer/agent.report_avg": 0.23695015907287598, "timer/agent.report_min": 0.23038125038146973, "timer/agent.report_max": 0.24351906776428223, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.075599670410156e-05, "timer/dataset_eval_frac": 3.075238805488166e-08, "timer/dataset_eval_avg": 3.075599670410156e-05, "timer/dataset_eval_min": 3.075599670410156e-05, "timer/dataset_eval_max": 3.075599670410156e-05, "fps": 2.1917153286234625}
{"step": 96792, "time": 44323.96219944954, "episode/length": 277.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9964028776978417, "episode/intrinsic_return": 0.0}
{"step": 97096, "time": 44462.13401007652, "episode/length": 181.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 97144, "time": 44485.08501839638, "episode/length": 168.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 97168, "time": 44497.35898947716, "episode/length": 168.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 97392, "time": 44599.17669129372, "episode/length": 137.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.0}
{"step": 97656, "time": 44719.38019967079, "episode/length": 143.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 97776, "time": 44774.55950307846, "episode/length": 148.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 97896, "time": 44829.888531684875, "episode/length": 248.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9799196787148594, "episode/intrinsic_return": 0.0}
{"step": 98168, "time": 44953.27547240257, "episode/length": 171.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 98352, "time": 45037.871453523636, "episode/length": 147.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 98384, "time": 45053.68461513519, "episode/length": 160.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 98552, "time": 45130.57618331909, "episode/length": 175.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 98760, "time": 45225.119143247604, "episode/length": 170.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 98784, "time": 45237.48745965958, "episode/length": 53.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 98953, "time": 45315.222537755966, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.575305343767918, "train/action_min": 0.0, "train/action_std": 4.240678335548541, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04159627478877339, "train/actor_opt_grad_steps": 96305.0, "train/actor_opt_loss": -17.55529213416467, "train/adv_mag": 0.7641286597065969, "train/adv_max": 0.6997653329317722, "train/adv_mean": 0.0010263177494572128, "train/adv_min": -0.5699885233279762, "train/adv_std": 0.050149879854069934, "train/cont_avg": 0.9944362815366973, "train/cont_loss_mean": 1.223078289059886e-05, "train/cont_loss_std": 0.0003748148225913412, "train/cont_neg_acc": 1.0, "train/cont_neg_loss": 0.00031481967724576287, "train/cont_pos_acc": 0.9999909622406741, "train/cont_pos_loss": 1.016281766866504e-05, "train/cont_pred": 0.9944322639649067, "train/cont_rate": 0.9944362815366973, "train/dyn_loss_mean": 2.9767223629382773, "train/dyn_loss_std": 7.840767891035167, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.2546487073285864, "train/extr_critic_critic_opt_grad_steps": 96305.0, "train/extr_critic_critic_opt_loss": 14846.978676892202, "train/extr_critic_mag": 15.63970246446242, "train/extr_critic_max": 15.63970246446242, "train/extr_critic_mean": 3.1225845310666145, "train/extr_critic_min": -0.6570484271836937, "train/extr_critic_std": 3.0081674057409304, "train/extr_return_normed_mag": 1.7368962053858905, "train/extr_return_normed_max": 1.7368962053858905, "train/extr_return_normed_mean": 0.3608815315256425, "train/extr_return_normed_min": -0.0956587664817178, "train/extr_return_normed_std": 0.33025292081570407, "train/extr_return_rate": 0.8527684643727924, "train/extr_return_raw_mag": 15.854281613586146, "train/extr_return_raw_max": 15.854281613586146, "train/extr_return_raw_mean": 3.1320095215368706, "train/extr_return_raw_min": -1.0939751141661898, "train/extr_return_raw_std": 3.056819705241317, "train/extr_reward_mag": 1.0365637650183581, "train/extr_reward_max": 1.0365637650183581, "train/extr_reward_mean": 0.027668644985987232, "train/extr_reward_min": -0.6889779660679879, "train/extr_reward_std": 0.1686905899315799, "train/image_loss_mean": 1.584026681173832, "train/image_loss_std": 4.709498465061188, "train/model_loss_mean": 3.4058801504450105, "train/model_loss_std": 8.540756820538721, "train/model_opt_grad_norm": 32.484178075002966, "train/model_opt_grad_steps": 96223.16972477065, "train/model_opt_loss": 6570.219634729788, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1926.605504587156, "train/policy_entropy_mag": 2.4811086064084953, "train/policy_entropy_max": 2.4811086064084953, "train/policy_entropy_mean": 0.5525504390307523, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.5961823247441458, "train/policy_logprob_mag": 7.438383968598252, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5518086005788331, "train/policy_logprob_min": -7.438383968598252, "train/policy_logprob_std": 1.1036912077063814, "train/policy_randomness_mag": 0.875722458876601, "train/policy_randomness_max": 0.875722458876601, "train/policy_randomness_mean": 0.19502605723405103, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.21042619843822008, "train/post_ent_mag": 43.53819024672202, "train/post_ent_max": 43.53819024672202, "train/post_ent_mean": 23.558780705163237, "train/post_ent_min": 12.733828754600035, "train/post_ent_std": 4.1633891796847005, "train/prior_ent_mag": 76.59694591137247, "train/prior_ent_max": 76.59694591137247, "train/prior_ent_mean": 26.489609954554005, "train/prior_ent_min": 13.932037165405553, "train/prior_ent_std": 9.015699097869593, "train/rep_loss_mean": 2.9767223629382773, "train/rep_loss_std": 7.840767891035167, "train/reward_avg": 0.019431801747804116, "train/reward_loss_mean": 0.03580781902024232, "train/reward_loss_std": 0.16402339463660476, "train/reward_max_data": 1.0243119324019196, "train/reward_max_pred": 1.0240455242471957, "train/reward_neg_acc": 0.9963363991418016, "train/reward_neg_loss": 0.018624530259280576, "train/reward_pos_acc": 0.9903874996058438, "train/reward_pos_loss": 0.7175692289794257, "train/reward_pred": 0.019255483570004547, "train/reward_rate": 0.02457085005733945, "train_stats/sum_log_reward": 4.385714215891702, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 2.7857142857142856, "train_stats/max_log_achievement_collect_sapling": 1.7857142857142858, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 3.2857142857142856, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.07142857142857142, "train_stats/max_log_achievement_make_wood_pickaxe": 0.07142857142857142, "train_stats/max_log_achievement_make_wood_sword": 0.07142857142857142, "train_stats/max_log_achievement_place_plant": 1.7142857142857142, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 1.2857142857142858, "train_stats/max_log_achievement_wake_up": 1.3571428571428572, "train_stats/mean_log_entropy": 0.4420617861407144, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 9.129078648584255e-07, "report/cont_loss_std": 2.272255915158894e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0001782140607247129, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 4.2931699084647335e-08, "report/cont_pred": 0.9951180219650269, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 2.981170177459717, "report/dyn_loss_std": 7.812562942504883, "report/image_loss_mean": 1.4245052337646484, "report/image_loss_std": 3.5284364223480225, "report/model_loss_mean": 3.2506103515625, "report/model_loss_std": 7.347654342651367, "report/post_ent_mag": 46.65289306640625, "report/post_ent_max": 46.65289306640625, "report/post_ent_mean": 24.237815856933594, "report/post_ent_min": 12.971208572387695, "report/post_ent_std": 4.544979572296143, "report/prior_ent_mag": 76.85504150390625, "report/prior_ent_max": 76.85504150390625, "report/prior_ent_mean": 27.137365341186523, "report/prior_ent_min": 14.177470207214355, "report/prior_ent_std": 9.108150482177734, "report/rep_loss_mean": 2.981170177459717, "report/rep_loss_std": 7.812562942504883, "report/reward_avg": 0.02490234375, "report/reward_loss_mean": 0.03740217536687851, "report/reward_loss_std": 0.18309208750724792, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0006396770477295, "report/reward_neg_acc": 0.9929577112197876, "report/reward_neg_loss": 0.01571768708527088, "report/reward_pos_acc": 0.9666666984558105, "report/reward_pos_loss": 0.7558815479278564, "report/reward_pred": 0.025286119431257248, "report/reward_rate": 0.029296875, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.01077286247164011, "eval/cont_loss_std": 0.3445587158203125, "eval/cont_neg_acc": 0.75, "eval/cont_neg_loss": 2.7578420639038086, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 4.2211915740608674e-08, "eval/cont_pred": 0.9970704317092896, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 22.958553314208984, "eval/dyn_loss_std": 13.699549674987793, "eval/image_loss_mean": 37.13209915161133, "eval/image_loss_std": 44.22282409667969, "eval/model_loss_mean": 51.04837417602539, "eval/model_loss_std": 49.6435546875, "eval/post_ent_mag": 46.65289306640625, "eval/post_ent_max": 46.65289306640625, "eval/post_ent_mean": 28.521800994873047, "eval/post_ent_min": 18.055410385131836, "eval/post_ent_std": 3.2844085693359375, "eval/prior_ent_mag": 76.85504150390625, "eval/prior_ent_max": 76.85504150390625, "eval/prior_ent_mean": 38.17684555053711, "eval/prior_ent_min": 18.17707061767578, "eval/prior_ent_std": 8.272754669189453, "eval/rep_loss_mean": 22.958553314208984, "eval/rep_loss_std": 13.699549674987793, "eval/reward_avg": 0.02578124962747097, "eval/reward_loss_mean": 0.13037288188934326, "eval/reward_loss_std": 0.9539111256599426, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0258662700653076, "eval/reward_neg_acc": 0.9969818592071533, "eval/reward_neg_loss": 0.03652399778366089, "eval/reward_pos_acc": 0.6333333849906921, "eval/reward_pos_loss": 3.2398993968963623, "eval/reward_pred": 0.015088928863406181, "eval/reward_rate": 0.029296875, "replay/size": 98449.0, "replay/inserts": 2180.0, "replay/samples": 34880.0, "replay/insert_wait_avg": 2.573280159486543e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.344495265855702e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 19288.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 7.599592208862305e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0038990974426, "timer/env.step_count": 273.0, "timer/env.step_total": 28.365283489227295, "timer/env.step_frac": 0.028365172890654218, "timer/env.step_avg": 0.10390213732317691, "timer/env.step_min": 0.023280620574951172, "timer/env.step_max": 1.6157476902008057, "timer/replay._sample_count": 34880.0, "timer/replay._sample_total": 16.862621068954468, "timer/replay._sample_frac": 0.016862555320208143, "timer/replay._sample_avg": 0.000483446704958557, "timer/replay._sample_min": 0.00034689903259277344, "timer/replay._sample_max": 0.009099721908569336, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 273.0, "timer/agent.policy_total": 4.317682981491089, "timer/agent.policy_frac": 0.004317666146490059, "timer/agent.policy_avg": 0.015815688576890436, "timer/agent.policy_min": 0.009813070297241211, "timer/agent.policy_max": 0.042200565338134766, "timer/dataset_train_count": 2180.0, "timer/dataset_train_total": 0.3942601680755615, "timer/dataset_train_frac": 0.00039425863082274233, "timer/dataset_train_avg": 0.00018085328810805575, "timer/dataset_train_min": 9.441375732421875e-05, "timer/dataset_train_max": 0.0011553764343261719, "timer/agent.train_count": 2180.0, "timer/agent.train_total": 965.0857965946198, "timer/agent.train_frac": 0.9650820336457304, "timer/agent.train_avg": 0.4426999066947797, "timer/agent.train_min": 0.4322974681854248, "timer/agent.train_max": 0.5637686252593994, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47446179389953613, "timer/agent.report_frac": 0.00047445994393398213, "timer/agent.report_avg": 0.23723089694976807, "timer/agent.report_min": 0.230438232421875, "timer/agent.report_max": 0.24402356147766113, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0279159545898438e-05, "timer/dataset_eval_frac": 3.027904148496522e-08, "timer/dataset_eval_avg": 3.0279159545898438e-05, "timer/dataset_eval_min": 3.0279159545898438e-05, "timer/dataset_eval_max": 3.0279159545898438e-05, "fps": 2.1799631605651806}
{"step": 99000, "time": 45336.42182826996, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 99296, "time": 45470.386585235596, "episode/length": 174.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 99616, "time": 45615.488045454025, "episode/length": 180.0, "episode/score": 6.1000000312924385, "episode/reward_rate": 0.988950276243094, "episode/intrinsic_return": 0.0}
{"step": 99624, "time": 45620.592334508896, "episode/length": 230.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 99696, "time": 45654.40417098999, "episode/length": 163.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 99768, "time": 45688.27640914917, "episode/length": 151.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 100032, "time": 45808.10882520676, "episode/length": 155.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 100048, "time": 45835.09919166565, "eval_episode/length": 150.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9602649006622517}
{"step": 100048, "time": 45836.89446377754, "eval_episode/length": 158.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9622641509433962}
{"step": 100048, "time": 45838.88915514946, "eval_episode/length": 171.0, "eval_episode/score": 4.099999971687794, "eval_episode/reward_rate": 0.9941860465116279}
{"step": 100048, "time": 45840.62427902222, "eval_episode/length": 178.0, "eval_episode/score": 5.100000016391277, "eval_episode/reward_rate": 0.994413407821229}
{"step": 100048, "time": 45842.422093868256, "eval_episode/length": 184.0, "eval_episode/score": 5.099999979138374, "eval_episode/reward_rate": 0.9945945945945946}
{"step": 100048, "time": 45844.234372377396, "eval_episode/length": 188.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9947089947089947}
{"step": 100048, "time": 45845.92217326164, "eval_episode/length": 192.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9948186528497409}
{"step": 100048, "time": 45848.71289539337, "eval_episode/length": 225.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9823008849557522}
{"step": 100096, "time": 45870.163982868195, "episode/length": 166.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 100544, "time": 46073.111877441406, "episode/length": 192.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 100632, "time": 46114.17514252663, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 100832, "time": 46205.24416542053, "episode/length": 150.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 101072, "time": 46314.27806353569, "episode/length": 162.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 101073, "time": 46316.93634366989, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.629704889261498, "train/action_min": 0.0, "train/action_std": 4.2158637834045125, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04511110558402988, "train/actor_opt_grad_steps": 98455.0, "train/actor_opt_loss": -20.051430595652114, "train/adv_mag": 0.859623134276777, "train/adv_max": 0.7736427691185249, "train/adv_mean": 0.0007405192714428559, "train/adv_min": -0.6214766741361258, "train/adv_std": 0.05376642945943014, "train/cont_avg": 0.9945690227004716, "train/cont_loss_mean": 5.7957376696401e-05, "train/cont_loss_std": 0.001817696817502759, "train/cont_neg_acc": 0.9993197282155355, "train/cont_neg_loss": 0.008129088505423472, "train/cont_pos_acc": 0.999999981443837, "train/cont_pos_loss": 2.9828010248422743e-06, "train/cont_pred": 0.9945713202908354, "train/cont_rate": 0.9945690227004716, "train/dyn_loss_mean": 2.9381446388532533, "train/dyn_loss_std": 7.779915739905159, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.3202866279291656, "train/extr_critic_critic_opt_grad_steps": 98455.0, "train/extr_critic_critic_opt_loss": 15087.293876216097, "train/extr_critic_mag": 15.422607219444131, "train/extr_critic_max": 15.422607219444131, "train/extr_critic_mean": 2.651008171855279, "train/extr_critic_min": -0.6677735436637446, "train/extr_critic_std": 2.654651162759313, "train/extr_return_normed_mag": 1.9124532848034266, "train/extr_return_normed_max": 1.9124532848034266, "train/extr_return_normed_mean": 0.3465650357165427, "train/extr_return_normed_min": -0.1090666873134532, "train/extr_return_normed_std": 0.32575305347453876, "train/extr_return_rate": 0.8546783319621716, "train/extr_return_raw_mag": 15.505378448738242, "train/extr_return_raw_max": 15.505378448738242, "train/extr_return_raw_mean": 2.6572243138304295, "train/extr_return_raw_min": -1.0974169910516378, "train/extr_return_raw_std": 2.692132402141139, "train/extr_reward_mag": 1.0272227402003307, "train/extr_reward_max": 1.0272227402003307, "train/extr_reward_mean": 0.029010451078098617, "train/extr_reward_min": -0.6910939492144674, "train/extr_reward_std": 0.17104306866256697, "train/image_loss_mean": 1.4897487247889896, "train/image_loss_std": 4.468028118025582, "train/model_loss_mean": 3.287537989751348, "train/model_loss_std": 8.278652141679007, "train/model_opt_grad_norm": 31.789802195890893, "train/model_opt_grad_steps": 98371.64622641509, "train/model_opt_loss": 8309.295518407282, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2523.5849056603774, "train/policy_entropy_mag": 2.4850081194121882, "train/policy_entropy_max": 2.4850081194121882, "train/policy_entropy_mean": 0.5660139438959787, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6075670076709874, "train/policy_logprob_mag": 7.438383968371265, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5667188655374185, "train/policy_logprob_min": -7.438383968371265, "train/policy_logprob_std": 1.114394316695771, "train/policy_randomness_mag": 0.8770988144964542, "train/policy_randomness_max": 0.8770988144964542, "train/policy_randomness_mean": 0.1997780830089776, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.21444449194197385, "train/post_ent_mag": 44.084581429103636, "train/post_ent_max": 44.084581429103636, "train/post_ent_mean": 23.8028435617123, "train/post_ent_min": 12.790792622656193, "train/post_ent_std": 4.209951984432508, "train/prior_ent_mag": 76.62895861211813, "train/prior_ent_max": 76.62895861211813, "train/prior_ent_mean": 26.685038206712257, "train/prior_ent_min": 14.138134600981227, "train/prior_ent_std": 8.976535848851475, "train/rep_loss_mean": 2.9381446388532533, "train/rep_loss_std": 7.779915739905159, "train/reward_avg": 0.019890551178557973, "train/reward_loss_mean": 0.034844538855876, "train/reward_loss_std": 0.15957702822842687, "train/reward_max_data": 1.013679248544405, "train/reward_max_pred": 1.0141052232598358, "train/reward_neg_acc": 0.9967235380186225, "train/reward_neg_loss": 0.017622247112053884, "train/reward_pos_acc": 0.9920304001502271, "train/reward_pos_loss": 0.7113175245950807, "train/reward_pred": 0.019730988599992585, "train/reward_rate": 0.024782576650943397, "train_stats/sum_log_reward": 4.433333237965901, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 4.0, "train_stats/max_log_achievement_collect_sapling": 2.0, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 2.25, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.08333333333333333, "train_stats/max_log_achievement_make_wood_pickaxe": 0.16666666666666666, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 2.0, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 0.8333333333333334, "train_stats/max_log_achievement_wake_up": 1.9166666666666667, "train_stats/mean_log_entropy": 0.48519263168176013, "eval_stats/sum_log_reward": 4.474999845027924, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 1.25, "eval_stats/max_log_achievement_collect_sapling": 1.875, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 3.75, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.125, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 1.5, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 1.5, "eval_stats/max_log_achievement_wake_up": 1.875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 4.116485001759429e-07, "report/cont_loss_std": 7.362526730503305e-07, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.2658781997743063e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 3.876815242165321e-07, "report/cont_pred": 0.9980465769767761, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 2.6153676509857178, "report/dyn_loss_std": 7.445601940155029, "report/image_loss_mean": 0.9534264206886292, "report/image_loss_std": 2.1708948612213135, "report/model_loss_mean": 2.5438015460968018, "report/model_loss_std": 6.156929016113281, "report/post_ent_mag": 36.59986114501953, "report/post_ent_max": 36.59986114501953, "report/post_ent_mean": 23.47943115234375, "report/post_ent_min": 13.872276306152344, "report/post_ent_std": 3.430438756942749, "report/prior_ent_mag": 76.16152954101562, "report/prior_ent_max": 76.16152954101562, "report/prior_ent_mean": 26.19865608215332, "report/prior_ent_min": 15.032907485961914, "report/prior_ent_std": 8.037554740905762, "report/rep_loss_mean": 2.6153676509857178, "report/rep_loss_std": 7.445601940155029, "report/reward_avg": 0.02041015587747097, "report/reward_loss_mean": 0.02115420065820217, "report/reward_loss_std": 0.11304382234811783, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0011849403381348, "report/reward_neg_acc": 0.9970029592514038, "report/reward_neg_loss": 0.006144149228930473, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6744177341461182, "report/reward_pred": 0.020480863749980927, "report/reward_rate": 0.0224609375, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 8.875551429810002e-06, "eval/cont_loss_std": 0.0002669759269338101, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00285802548751235, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 5.039071879764379e-07, "eval/cont_pred": 0.9970781803131104, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 27.092952728271484, "eval/dyn_loss_std": 13.368634223937988, "eval/image_loss_mean": 40.00764465332031, "eval/image_loss_std": 36.7462043762207, "eval/model_loss_mean": 56.36362838745117, "eval/model_loss_std": 41.99018096923828, "eval/post_ent_mag": 45.71459197998047, "eval/post_ent_max": 45.71459197998047, "eval/post_ent_mean": 27.928627014160156, "eval/post_ent_min": 18.27435874938965, "eval/post_ent_std": 2.9934659004211426, "eval/prior_ent_mag": 76.16152954101562, "eval/prior_ent_max": 76.16152954101562, "eval/prior_ent_mean": 39.24787902832031, "eval/prior_ent_min": 20.51829719543457, "eval/prior_ent_std": 7.7740631103515625, "eval/rep_loss_mean": 27.092952728271484, "eval/rep_loss_std": 13.368634223937988, "eval/reward_avg": 0.0234375, "eval/reward_loss_mean": 0.10020165145397186, "eval/reward_loss_std": 0.7107245326042175, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0006353855133057, "eval/reward_neg_acc": 0.9959879517555237, "eval/reward_neg_loss": 0.047255370765924454, "eval/reward_pos_acc": 0.8518518805503845, "eval/reward_pos_loss": 2.0552921295166016, "eval/reward_pred": 0.01963401399552822, "eval/reward_rate": 0.0263671875, "replay/size": 100569.0, "replay/inserts": 2120.0, "replay/samples": 33920.0, "replay/insert_wait_avg": 2.590215431069428e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.203932699167504e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 21096.0, "eval_replay/inserts": 1808.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0867298176858277e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.748603820800781e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1001.6961784362793, "timer/env.step_count": 265.0, "timer/env.step_total": 25.504422903060913, "timer/env.step_frac": 0.025461236103421273, "timer/env.step_avg": 0.09624310529456949, "timer/env.step_min": 0.02302074432373047, "timer/env.step_max": 2.0293338298797607, "timer/replay._sample_count": 33920.0, "timer/replay._sample_total": 16.339390993118286, "timer/replay._sample_frac": 0.01631172339962928, "timer/replay._sample_avg": 0.00048170374390089286, "timer/replay._sample_min": 0.000347137451171875, "timer/replay._sample_max": 0.010727167129516602, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 491.0, "timer/agent.policy_total": 7.671169996261597, "timer/agent.policy_frac": 0.007658180355880814, "timer/agent.policy_avg": 0.015623564147172295, "timer/agent.policy_min": 0.009330987930297852, "timer/agent.policy_max": 0.041924476623535156, "timer/dataset_train_count": 2120.0, "timer/dataset_train_total": 0.37998294830322266, "timer/dataset_train_frac": 0.0003793395207880335, "timer/dataset_train_avg": 0.00017923723976567105, "timer/dataset_train_min": 9.512901306152344e-05, "timer/dataset_train_max": 0.0006363391876220703, "timer/agent.train_count": 2120.0, "timer/agent.train_total": 937.9859850406647, "timer/agent.train_frac": 0.9363976874753871, "timer/agent.train_avg": 0.44244621935880407, "timer/agent.train_min": 0.4335365295410156, "timer/agent.train_max": 0.5519254207611084, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4741652011871338, "timer/agent.report_frac": 0.0004733622942710435, "timer/agent.report_avg": 0.2370826005935669, "timer/agent.report_min": 0.230452299118042, "timer/agent.report_max": 0.2437129020690918, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0517578125e-05, "timer/dataset_eval_frac": 3.0465902518107e-08, "timer/dataset_eval_avg": 3.0517578125e-05, "timer/dataset_eval_min": 3.0517578125e-05, "timer/dataset_eval_max": 3.0517578125e-05, "fps": 2.1163833629827944}
{"step": 101384, "time": 46456.72208714485, "episode/length": 210.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 101552, "time": 46533.814492464066, "episode/length": 241.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9958677685950413, "episode/intrinsic_return": 0.0}
{"step": 101880, "time": 46682.84845614433, "episode/length": 230.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9826839826839827, "episode/intrinsic_return": 0.0}
{"step": 101912, "time": 46698.781366825104, "episode/length": 134.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9925925925925926, "episode/intrinsic_return": 0.0}
{"step": 102048, "time": 46761.37199473381, "episode/length": 176.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 102048, "time": 46761.382239341736, "episode/length": 243.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 102080, "time": 46779.131583452225, "episode/length": 191.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 102240, "time": 46852.38627886772, "episode/length": 40.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 102432, "time": 46940.27282619476, "episode/length": 169.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 102752, "time": 47085.35143303871, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 103265, "time": 47317.18014240265, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.721598307291667, "train/action_min": 0.0, "train/action_std": 4.253941055846541, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04848372905629955, "train/actor_opt_grad_steps": 100610.0, "train/actor_opt_loss": -13.105953907415476, "train/adv_mag": 0.8211367493622923, "train/adv_max": 0.7212146858102111, "train/adv_mean": 0.0026115753377435797, "train/adv_min": -0.6364419873990969, "train/adv_std": 0.05685822975281711, "train/cont_avg": 0.9945285744863014, "train/cont_loss_mean": 3.43225979520282e-05, "train/cont_loss_std": 0.0010536642624184931, "train/cont_neg_acc": 0.9984344426355406, "train/cont_neg_loss": 0.004094746207509734, "train/cont_pos_acc": 0.9999954901873793, "train/cont_pos_loss": 1.0899378898923686e-05, "train/cont_pred": 0.9945301516959656, "train/cont_rate": 0.9945285744863014, "train/dyn_loss_mean": 3.0047466983533884, "train/dyn_loss_std": 7.831928124710849, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.2877357305457058, "train/extr_critic_critic_opt_grad_steps": 100610.0, "train/extr_critic_critic_opt_loss": 15312.451327946632, "train/extr_critic_mag": 13.968303231888166, "train/extr_critic_max": 13.968303231888166, "train/extr_critic_mean": 2.372578203405964, "train/extr_critic_min": -0.6924662285199449, "train/extr_critic_std": 2.359181204342951, "train/extr_return_normed_mag": 1.8666392004108865, "train/extr_return_normed_max": 1.8666392004108865, "train/extr_return_normed_mean": 0.34340580665085413, "train/extr_return_normed_min": -0.1275011471655543, "train/extr_return_normed_std": 0.31638040641943616, "train/extr_return_rate": 0.8093818790836421, "train/extr_return_raw_mag": 14.010604457768132, "train/extr_return_raw_max": 14.010604457768132, "train/extr_return_raw_mean": 2.3925692332934028, "train/extr_return_raw_min": -1.2034457957363565, "train/extr_return_raw_std": 2.4160200782018166, "train/extr_reward_mag": 1.0280612407754002, "train/extr_reward_max": 1.0280612407754002, "train/extr_reward_mean": 0.028719283329943817, "train/extr_reward_min": -0.7010006398370822, "train/extr_reward_std": 0.17064035336856972, "train/image_loss_mean": 1.563220852314065, "train/image_loss_std": 4.743433745484374, "train/model_loss_mean": 3.4014394631668856, "train/model_loss_std": 8.557117836660446, "train/model_opt_grad_norm": 31.740426215951302, "train/model_opt_grad_steps": 100524.12785388128, "train/model_opt_loss": 6922.1405380458045, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2031.9634703196348, "train/policy_entropy_mag": 2.4803202282892514, "train/policy_entropy_max": 2.4803202282892514, "train/policy_entropy_mean": 0.577766530726054, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6140483152376462, "train/policy_logprob_mag": 7.438383984239134, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5775229815206572, "train/policy_logprob_min": -7.438383984239134, "train/policy_logprob_std": 1.1183609701182744, "train/policy_randomness_mag": 0.8754441934089138, "train/policy_randomness_max": 0.8754441934089138, "train/policy_randomness_mean": 0.20392623115075778, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.2167321091781468, "train/post_ent_mag": 43.929209443532166, "train/post_ent_max": 43.929209443532166, "train/post_ent_mean": 24.071889990540946, "train/post_ent_min": 12.999643256130827, "train/post_ent_std": 4.207100715811394, "train/prior_ent_mag": 76.69327402332603, "train/prior_ent_max": 76.69327402332603, "train/prior_ent_mean": 27.0082524617513, "train/prior_ent_min": 14.21905203170428, "train/prior_ent_std": 8.979251809316139, "train/rep_loss_mean": 3.0047466983533884, "train/rep_loss_std": 7.831928124710849, "train/reward_avg": 0.02019477722800622, "train/reward_loss_mean": 0.03533626441337746, "train/reward_loss_std": 0.1631935239178405, "train/reward_max_data": 1.01598173897016, "train/reward_max_pred": 1.0155377943221837, "train/reward_neg_acc": 0.9964373549914252, "train/reward_neg_loss": 0.017678409304520856, "train/reward_pos_acc": 0.989752450762274, "train/reward_pos_loss": 0.7214320859952604, "train/reward_pred": 0.020000655540014237, "train/reward_rate": 0.025078481735159818, "train_stats/sum_log_reward": 4.0999999165534975, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 3.0, "train_stats/max_log_achievement_collect_sapling": 2.5, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 3.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.2, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 2.5, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 1.3, "train_stats/max_log_achievement_wake_up": 1.4, "train_stats/mean_log_entropy": 0.5736446589231491, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 1.4855420715775836e-07, "report/cont_loss_std": 2.474519362749561e-07, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 2.9402169730019523e-06, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.3485615113495442e-07, "report/cont_pred": 0.9951171875, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 2.767538070678711, "report/dyn_loss_std": 7.861626625061035, "report/image_loss_mean": 1.1946861743927002, "report/image_loss_std": 4.430544853210449, "report/model_loss_mean": 2.8865299224853516, "report/model_loss_std": 8.336978912353516, "report/post_ent_mag": 45.62787628173828, "report/post_ent_max": 45.62787628173828, "report/post_ent_mean": 23.91618537902832, "report/post_ent_min": 13.224885940551758, "report/post_ent_std": 4.431423664093018, "report/prior_ent_mag": 76.772216796875, "report/prior_ent_max": 76.772216796875, "report/prior_ent_mean": 26.695613861083984, "report/prior_ent_min": 13.725496292114258, "report/prior_ent_std": 8.94477367401123, "report/rep_loss_mean": 2.767538070678711, "report/rep_loss_std": 7.861626625061035, "report/reward_avg": 0.01953125, "report/reward_loss_mean": 0.03132088482379913, "report/reward_loss_std": 0.15172642469406128, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0012435913085938, "report/reward_neg_acc": 0.9969969987869263, "report/reward_neg_loss": 0.013240499421954155, "report/reward_pos_acc": 0.9599999785423279, "report/reward_pos_loss": 0.7538130879402161, "report/reward_pred": 0.018833070993423462, "report/reward_rate": 0.0244140625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.008241537027060986, "eval/cont_loss_std": 0.2522099018096924, "eval/cont_neg_acc": 0.6666666865348816, "eval/cont_neg_loss": 2.738335371017456, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.000219715730054304, "eval/cont_pred": 0.997981607913971, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 24.79334259033203, "eval/dyn_loss_std": 12.889679908752441, "eval/image_loss_mean": 48.288475036621094, "eval/image_loss_std": 56.30804443359375, "eval/model_loss_mean": 63.2997932434082, "eval/model_loss_std": 61.162803649902344, "eval/post_ent_mag": 40.9467658996582, "eval/post_ent_max": 40.9467658996582, "eval/post_ent_mean": 28.74295997619629, "eval/post_ent_min": 19.45252227783203, "eval/post_ent_std": 3.200005292892456, "eval/prior_ent_mag": 76.772216796875, "eval/prior_ent_max": 76.772216796875, "eval/prior_ent_mean": 39.10329055786133, "eval/prior_ent_min": 21.077590942382812, "eval/prior_ent_std": 8.082159996032715, "eval/rep_loss_mean": 24.79334259033203, "eval/rep_loss_std": 12.889679908752441, "eval/reward_avg": 0.02646484225988388, "eval/reward_loss_mean": 0.12707237899303436, "eval/reward_loss_std": 0.80507892370224, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.0012390613555908, "eval/reward_neg_acc": 0.9969818592071533, "eval/reward_neg_loss": 0.07760851085186005, "eval/reward_pos_acc": 0.8000000715255737, "eval/reward_pos_loss": 1.7659752368927002, "eval/reward_pred": 0.022388480603694916, "eval/reward_rate": 0.029296875, "replay/size": 102761.0, "replay/inserts": 2192.0, "replay/samples": 35072.0, "replay/insert_wait_avg": 2.5874724353316925e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.34194895646868e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 21096.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 8.940696716308594e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2337288856506, "timer/env.step_count": 274.0, "timer/env.step_total": 23.190150260925293, "timer/env.step_frac": 0.023184731319509874, "timer/env.step_avg": 0.08463558489388794, "timer/env.step_min": 0.023304224014282227, "timer/env.step_max": 3.297680139541626, "timer/replay._sample_count": 35072.0, "timer/replay._sample_total": 16.911993503570557, "timer/replay._sample_frac": 0.01690804160584749, "timer/replay._sample_avg": 0.00048220784396585755, "timer/replay._sample_min": 0.00036787986755371094, "timer/replay._sample_max": 0.02577376365661621, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 274.0, "timer/agent.policy_total": 4.39394736289978, "timer/agent.policy_frac": 0.004392920610460746, "timer/agent.policy_avg": 0.01603630424415978, "timer/agent.policy_min": 0.009344339370727539, "timer/agent.policy_max": 0.04970955848693848, "timer/dataset_train_count": 2192.0, "timer/dataset_train_total": 0.43595266342163086, "timer/dataset_train_frac": 0.0004358507925015895, "timer/dataset_train_avg": 0.00019888351433468561, "timer/dataset_train_min": 9.107589721679688e-05, "timer/dataset_train_max": 0.04386782646179199, "timer/agent.train_count": 2192.0, "timer/agent.train_total": 970.520590543747, "timer/agent.train_frac": 0.9702938048539848, "timer/agent.train_avg": 0.4427557438611984, "timer/agent.train_min": 0.4242055416107178, "timer/agent.train_max": 0.9066121578216553, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47774744033813477, "timer/agent.report_frac": 0.0004776358030541401, "timer/agent.report_avg": 0.23887372016906738, "timer/agent.report_min": 0.23250842094421387, "timer/agent.report_max": 0.2452390193939209, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9087066650390625e-05, "timer/dataset_eval_frac": 2.908026975134722e-08, "timer/dataset_eval_avg": 2.9087066650390625e-05, "timer/dataset_eval_min": 2.9087066650390625e-05, "timer/dataset_eval_max": 2.9087066650390625e-05, "fps": 2.191458309098115}
{"step": 103304, "time": 47334.94868826866, "episode/length": 177.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 103440, "time": 47397.57300686836, "episode/length": 149.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 103440, "time": 47397.580221414566, "episode/length": 173.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 103440, "time": 47397.59086847305, "episode/length": 235.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 103736, "time": 47535.36374425888, "episode/length": 206.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 104104, "time": 47701.96061325073, "episode/length": 256.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9961089494163424, "episode/intrinsic_return": 0.0}
{"step": 104240, "time": 47764.70876932144, "episode/length": 225.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9778761061946902, "episode/intrinsic_return": 0.0}
{"step": 104336, "time": 47809.13818144798, "episode/length": 197.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 104656, "time": 47954.29714226723, "episode/length": 168.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9526627218934911, "episode/intrinsic_return": 0.0}
{"step": 104704, "time": 47977.33169078827, "episode/length": 157.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9620253164556962, "episode/intrinsic_return": 0.0}
{"step": 105152, "time": 48179.67354631424, "episode/length": 213.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 105312, "time": 48252.97109603882, "episode/length": 233.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 105360, "time": 48276.15021300316, "episode/length": 156.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 105447, "time": 48317.28362607956, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.876909728443951, "train/action_min": 0.0, "train/action_std": 4.297693227409223, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04877719028485478, "train/actor_opt_grad_steps": 102795.0, "train/actor_opt_loss": -15.354729873051337, "train/adv_mag": 0.889732725849939, "train/adv_max": 0.8174791103656139, "train/adv_mean": 0.0026714124572358865, "train/adv_min": -0.6958780624997725, "train/adv_std": 0.059303102365464246, "train/cont_avg": 0.9943287700688074, "train/cont_loss_mean": 3.6993850865576716e-05, "train/cont_loss_std": 0.0011184346686927387, "train/cont_neg_acc": 0.9992319510279712, "train/cont_neg_loss": 0.005456046518665678, "train/cont_pos_acc": 0.9999999822279729, "train/cont_pos_loss": 5.320058117474945e-06, "train/cont_pred": 0.9943295230559253, "train/cont_rate": 0.9943287700688074, "train/dyn_loss_mean": 2.9863852076574204, "train/dyn_loss_std": 7.866712237716815, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.29519099133824, "train/extr_critic_critic_opt_grad_steps": 102795.0, "train/extr_critic_critic_opt_loss": 15261.46844090453, "train/extr_critic_mag": 15.439601416981548, "train/extr_critic_max": 15.439601416981548, "train/extr_critic_mean": 2.4852920781581775, "train/extr_critic_min": -0.6974652956385131, "train/extr_critic_std": 2.6421973169396775, "train/extr_return_normed_mag": 1.9084060755344705, "train/extr_return_normed_max": 1.9084060755344705, "train/extr_return_normed_mean": 0.3315056494753295, "train/extr_return_normed_min": -0.114932858256982, "train/extr_return_normed_std": 0.3286625063474025, "train/extr_return_rate": 0.7498880463455795, "train/extr_return_raw_mag": 15.553942046034226, "train/extr_return_raw_max": 15.553942046034226, "train/extr_return_raw_mean": 2.5076016111111423, "train/extr_return_raw_min": -1.1698879153903472, "train/extr_return_raw_std": 2.7144794868766713, "train/extr_reward_mag": 1.0284235597750462, "train/extr_reward_max": 1.0284235597750462, "train/extr_reward_mean": 0.029239066571014327, "train/extr_reward_min": -0.7023994282844963, "train/extr_reward_std": 0.1742674635227667, "train/image_loss_mean": 1.599477661859005, "train/image_loss_std": 4.80491442855345, "train/model_loss_mean": 3.4275931972976124, "train/model_loss_std": 8.637290477752686, "train/model_opt_grad_norm": 31.38650808859309, "train/model_opt_grad_steps": 102707.1743119266, "train/model_opt_loss": 6425.378625152308, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1880.7339449541284, "train/policy_entropy_mag": 2.523308488207126, "train/policy_entropy_max": 2.523308488207126, "train/policy_entropy_mean": 0.6055341911151868, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6484752581753862, "train/policy_logprob_mag": 7.438383946724988, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.6051648670653684, "train/policy_logprob_min": -7.438383946724988, "train/policy_logprob_std": 1.137351494316661, "train/policy_randomness_mag": 0.890617163356291, "train/policy_randomness_max": 0.890617163356291, "train/policy_randomness_mean": 0.21372699662359482, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.2288833084866541, "train/post_ent_mag": 44.281985939095875, "train/post_ent_max": 44.281985939095875, "train/post_ent_mean": 24.21032306251176, "train/post_ent_min": 12.897812077758509, "train/post_ent_std": 4.201521387887658, "train/prior_ent_mag": 76.7598694267623, "train/prior_ent_max": 76.7598694267623, "train/prior_ent_mean": 27.13189203804786, "train/prior_ent_min": 14.236642623166425, "train/prior_ent_std": 8.986611749054095, "train/rep_loss_mean": 2.9863852076574204, "train/rep_loss_std": 7.866712237716815, "train/reward_avg": 0.020050440675690086, "train/reward_loss_mean": 0.036247400173900324, "train/reward_loss_std": 0.16670923830445752, "train/reward_max_data": 1.014678902582291, "train/reward_max_pred": 1.0156459584148652, "train/reward_neg_acc": 0.9962643116985986, "train/reward_neg_loss": 0.01864727590566313, "train/reward_pos_acc": 0.9916276617334523, "train/reward_pos_loss": 0.7197636330346449, "train/reward_pred": 0.01986714963450891, "train/reward_rate": 0.02517112241972477, "train_stats/sum_log_reward": 4.407692212324876, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 2.4615384615384617, "train_stats/max_log_achievement_collect_sapling": 2.230769230769231, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 3.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.23076923076923078, "train_stats/max_log_achievement_make_wood_pickaxe": 0.15384615384615385, "train_stats/max_log_achievement_make_wood_sword": 0.07692307692307693, "train_stats/max_log_achievement_place_plant": 2.1538461538461537, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 1.2307692307692308, "train_stats/max_log_achievement_wake_up": 2.230769230769231, "train_stats/mean_log_entropy": 0.566943652354754, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 2.4526384549972136e-06, "report/cont_loss_std": 2.397155185462907e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00029393850127235055, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 7.346469601543504e-07, "report/cont_pred": 0.994141697883606, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 3.012237548828125, "report/dyn_loss_std": 8.368748664855957, "report/image_loss_mean": 1.5754145383834839, "report/image_loss_std": 5.364593505859375, "report/model_loss_mean": 3.412937641143799, "report/model_loss_std": 9.471660614013672, "report/post_ent_mag": 42.9884033203125, "report/post_ent_max": 42.9884033203125, "report/post_ent_mean": 24.68232536315918, "report/post_ent_min": 13.834514617919922, "report/post_ent_std": 4.5874247550964355, "report/prior_ent_mag": 76.32249450683594, "report/prior_ent_max": 76.32249450683594, "report/prior_ent_mean": 27.74826431274414, "report/prior_ent_min": 15.507562637329102, "report/prior_ent_std": 9.033554077148438, "report/rep_loss_mean": 3.012237548828125, "report/rep_loss_std": 8.368748664855957, "report/reward_avg": 0.01992187649011612, "report/reward_loss_mean": 0.03017805516719818, "report/reward_loss_std": 0.13652299344539642, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0012400150299072, "report/reward_neg_acc": 0.9989989995956421, "report/reward_neg_loss": 0.013094181194901466, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7128497362136841, "report/reward_pred": 0.019361604005098343, "report/reward_rate": 0.0244140625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.009196151979267597, "eval/cont_loss_std": 0.2940482199192047, "eval/cont_neg_acc": 0.6666666865348816, "eval/cont_neg_loss": 3.1387643814086914, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 5.557662348110171e-07, "eval/cont_pred": 0.9980484247207642, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 22.92465591430664, "eval/dyn_loss_std": 14.92840576171875, "eval/image_loss_mean": 35.90062713623047, "eval/image_loss_std": 50.81439208984375, "eval/model_loss_mean": 49.87870788574219, "eval/model_loss_std": 57.22809982299805, "eval/post_ent_mag": 46.03287124633789, "eval/post_ent_max": 46.03287124633789, "eval/post_ent_mean": 28.333919525146484, "eval/post_ent_min": 17.978267669677734, "eval/post_ent_std": 3.4232516288757324, "eval/prior_ent_mag": 76.32249450683594, "eval/prior_ent_max": 76.32249450683594, "eval/prior_ent_mean": 38.56147003173828, "eval/prior_ent_min": 21.854244232177734, "eval/prior_ent_std": 8.433362007141113, "eval/rep_loss_mean": 22.92465591430664, "eval/rep_loss_std": 14.92840576171875, "eval/reward_avg": 0.02089843899011612, "eval/reward_loss_mean": 0.21409134566783905, "eval/reward_loss_std": 1.1641550064086914, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0012271404266357, "eval/reward_neg_acc": 0.988988995552063, "eval/reward_neg_loss": 0.1722947508096695, "eval/reward_pos_acc": 0.8799999952316284, "eval/reward_pos_loss": 1.8842836618423462, "eval/reward_pred": 0.01955360174179077, "eval/reward_rate": 0.0244140625, "replay/size": 104943.0, "replay/inserts": 2182.0, "replay/samples": 34912.0, "replay/insert_wait_avg": 2.640086942370281e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.375869917060999e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 21096.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 7.599592208862305e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0905380249023, "timer/env.step_count": 272.0, "timer/env.step_total": 27.032410144805908, "timer/env.step_frac": 0.027029962905351274, "timer/env.step_avg": 0.09938386082649231, "timer/env.step_min": 0.023669004440307617, "timer/env.step_max": 4.916985034942627, "timer/replay._sample_count": 34912.0, "timer/replay._sample_total": 16.928182363510132, "timer/replay._sample_frac": 0.016926649858063768, "timer/replay._sample_avg": 0.0004848814838310647, "timer/replay._sample_min": 0.000347137451171875, "timer/replay._sample_max": 0.025714397430419922, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 272.0, "timer/agent.policy_total": 4.325185775756836, "timer/agent.policy_frac": 0.004324794217430281, "timer/agent.policy_avg": 0.01590141829322366, "timer/agent.policy_min": 0.009671688079833984, "timer/agent.policy_max": 0.05388951301574707, "timer/dataset_train_count": 2182.0, "timer/dataset_train_total": 0.382735013961792, "timer/dataset_train_frac": 0.0003827003650266131, "timer/dataset_train_avg": 0.00017540559759935472, "timer/dataset_train_min": 8.749961853027344e-05, "timer/dataset_train_max": 0.0006544589996337891, "timer/agent.train_count": 2182.0, "timer/agent.train_total": 966.6290457248688, "timer/agent.train_frac": 0.9665415369631261, "timer/agent.train_avg": 0.44300139584091147, "timer/agent.train_min": 0.433002233505249, "timer/agent.train_max": 0.5731456279754639, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4731910228729248, "timer/agent.report_frac": 0.0004731481849707714, "timer/agent.report_avg": 0.2365955114364624, "timer/agent.report_min": 0.23005032539367676, "timer/agent.report_max": 0.24314069747924805, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.075599670410156e-05, "timer/dataset_eval_frac": 3.075321236899427e-08, "timer/dataset_eval_avg": 3.075599670410156e-05, "timer/dataset_eval_min": 3.075599670410156e-05, "timer/dataset_eval_max": 3.075599670410156e-05, "fps": 2.181773633723853}
{"step": 105512, "time": 48346.80831837654, "episode/length": 221.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9819819819819819, "episode/intrinsic_return": 0.0}
{"step": 105544, "time": 48362.70856833458, "episode/length": 162.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9631901840490797, "episode/intrinsic_return": 0.0}
{"step": 105752, "time": 48457.28799057007, "episode/length": 176.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 105800, "time": 48480.25352478027, "episode/length": 142.0, "episode/score": 3.1000000312924385, "episode/reward_rate": 0.951048951048951, "episode/intrinsic_return": 0.0}
{"step": 106200, "time": 48661.79821419716, "episode/length": 186.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 106512, "time": 48803.57486176491, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 106984, "time": 49017.67799448967, "episode/length": 208.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 107112, "time": 49076.71727561951, "episode/length": 163.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 107144, "time": 49092.60910439491, "episode/length": 222.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 107160, "time": 49101.36088490486, "episode/length": 175.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 107216, "time": 49128.49749708176, "episode/length": 126.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.968503937007874, "episode/intrinsic_return": 0.0}
{"step": 107216, "time": 49128.50629854202, "episode/length": 212.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9812206572769953, "episode/intrinsic_return": 0.0}
{"step": 107352, "time": 49193.72385048866, "episode/length": 225.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9778761061946902, "episode/intrinsic_return": 0.0}
{"step": 107624, "time": 49317.57027101517, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.867873725541141, "train/action_min": 0.0, "train/action_std": 4.386192677217886, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0504357821538771, "train/actor_opt_grad_steps": 104975.0, "train/actor_opt_loss": -17.625936167229206, "train/adv_mag": 0.911892869877159, "train/adv_max": 0.8563784396429674, "train/adv_mean": 0.0023105371230085106, "train/adv_min": -0.750062252676815, "train/adv_std": 0.0643383883657532, "train/cont_avg": 0.9943646072247706, "train/cont_loss_mean": 2.7504292271649096e-05, "train/cont_loss_std": 0.0008172216958080666, "train/cont_neg_acc": 0.9985670198996862, "train/cont_neg_loss": 0.0036788235765083366, "train/cont_pos_acc": 0.9999999800406465, "train/cont_pos_loss": 3.3857277274058486e-06, "train/cont_pred": 0.9943738844963389, "train/cont_rate": 0.9943646072247706, "train/dyn_loss_mean": 3.0422007086080147, "train/dyn_loss_std": 7.856057352975967, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.3617035120452217, "train/extr_critic_critic_opt_grad_steps": 104975.0, "train/extr_critic_critic_opt_loss": 15612.424464234518, "train/extr_critic_mag": 16.103330809041996, "train/extr_critic_max": 16.103330809041996, "train/extr_critic_mean": 2.507167380884153, "train/extr_critic_min": -0.6758969962050062, "train/extr_critic_std": 2.9083338002546117, "train/extr_return_normed_mag": 1.869060974055474, "train/extr_return_normed_max": 1.869060974055474, "train/extr_return_normed_mean": 0.3119395710869667, "train/extr_return_normed_min": -0.10019132517568699, "train/extr_return_normed_std": 0.33800113508734136, "train/extr_return_rate": 0.6666726735206919, "train/extr_return_raw_mag": 16.28444437586933, "train/extr_return_raw_max": 16.28444437586933, "train/extr_return_raw_mean": 2.52759260376659, "train/extr_return_raw_min": -1.1052474590069656, "train/extr_return_raw_std": 2.9836692471023, "train/extr_reward_mag": 1.034960142516215, "train/extr_reward_max": 1.034960142516215, "train/extr_reward_mean": 0.030003813761841813, "train/extr_reward_min": -0.6967692916546393, "train/extr_reward_std": 0.17572181107937743, "train/image_loss_mean": 1.5915725105399385, "train/image_loss_std": 4.972762082694867, "train/model_loss_mean": 3.45350758745036, "train/model_loss_std": 8.797908623284156, "train/model_opt_grad_norm": 32.05552457231994, "train/model_opt_grad_steps": 104885.6743119266, "train/model_opt_loss": 8743.397808109949, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2534.4036697247707, "train/policy_entropy_mag": 2.550532695350297, "train/policy_entropy_max": 2.550532695350297, "train/policy_entropy_mean": 0.6268873659022357, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6758040769384541, "train/policy_logprob_mag": 7.4383839642236, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.6257736283704776, "train/policy_logprob_min": -7.4383839642236, "train/policy_logprob_std": 1.1488847584899413, "train/policy_randomness_mag": 0.9002261142665093, "train/policy_randomness_max": 0.9002261142665093, "train/policy_randomness_mean": 0.22126372930927013, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.23852918276546198, "train/post_ent_mag": 44.24767893169998, "train/post_ent_max": 44.24767893169998, "train/post_ent_mean": 24.531153678894043, "train/post_ent_min": 13.115340552198777, "train/post_ent_std": 4.25635619229133, "train/prior_ent_mag": 76.82620827211153, "train/prior_ent_max": 76.82620827211153, "train/prior_ent_mean": 27.499128770390783, "train/prior_ent_min": 14.508140375854772, "train/prior_ent_std": 8.987852654325852, "train/rep_loss_mean": 3.0422007086080147, "train/rep_loss_std": 7.856057352975967, "train/reward_avg": 0.02061801154696203, "train/reward_loss_mean": 0.03658713798525683, "train/reward_loss_std": 0.17013647441470295, "train/reward_max_data": 1.016972481110774, "train/reward_max_pred": 1.018058674597959, "train/reward_neg_acc": 0.9962815035373793, "train/reward_neg_loss": 0.018472307261267522, "train/reward_pos_acc": 0.9895921519043249, "train/reward_pos_loss": 0.7285519545778222, "train/reward_pred": 0.020409052240995502, "train/reward_rate": 0.025538453268348624, "train_stats/sum_log_reward": 4.253846113498394, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 1.7692307692307692, "train_stats/max_log_achievement_collect_sapling": 2.076923076923077, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 2.3846153846153846, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.9230769230769231, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 0.9230769230769231, "train_stats/max_log_achievement_wake_up": 2.3076923076923075, "train_stats/mean_log_entropy": 0.6603097938574277, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 6.425566425605211e-07, "report/cont_loss_std": 2.324808292542002e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 2.5576120606274344e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 4.7093908506212756e-07, "report/cont_pred": 0.9931638240814209, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 2.993156671524048, "report/dyn_loss_std": 7.731873512268066, "report/image_loss_mean": 1.1613869667053223, "report/image_loss_std": 5.416982173919678, "report/model_loss_mean": 2.990108013153076, "report/model_loss_std": 9.172853469848633, "report/post_ent_mag": 46.7920036315918, "report/post_ent_max": 46.7920036315918, "report/post_ent_mean": 25.256458282470703, "report/post_ent_min": 13.529752731323242, "report/post_ent_std": 4.07890510559082, "report/prior_ent_mag": 76.75714874267578, "report/prior_ent_max": 76.75714874267578, "report/prior_ent_mean": 28.14395523071289, "report/prior_ent_min": 13.863101959228516, "report/prior_ent_std": 8.986662864685059, "report/rep_loss_mean": 2.993156671524048, "report/rep_loss_std": 7.731873512268066, "report/reward_avg": 0.01650390774011612, "report/reward_loss_mean": 0.03282630443572998, "report/reward_loss_std": 0.15509995818138123, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.0965361595153809, "report/reward_neg_acc": 0.9990009665489197, "report/reward_neg_loss": 0.018138980492949486, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6720442175865173, "report/reward_pred": 0.017455361783504486, "report/reward_rate": 0.0224609375, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.01197139173746109, "eval/cont_loss_std": 0.3828696608543396, "eval/cont_neg_acc": 0.6666666865348816, "eval/cont_neg_loss": 4.0860490798950195, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 5.470340056490386e-07, "eval/cont_pred": 0.9980466961860657, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 25.996139526367188, "eval/dyn_loss_std": 14.47513484954834, "eval/image_loss_mean": 43.95515441894531, "eval/image_loss_std": 47.66887664794922, "eval/model_loss_mean": 59.695247650146484, "eval/model_loss_std": 53.538570404052734, "eval/post_ent_mag": 46.7920036315918, "eval/post_ent_max": 46.7920036315918, "eval/post_ent_mean": 28.019195556640625, "eval/post_ent_min": 16.108436584472656, "eval/post_ent_std": 3.1923460960388184, "eval/prior_ent_mag": 76.75714874267578, "eval/prior_ent_max": 76.75714874267578, "eval/prior_ent_mean": 38.524593353271484, "eval/prior_ent_min": 17.047584533691406, "eval/prior_ent_std": 8.18071174621582, "eval/rep_loss_mean": 25.996139526367188, "eval/rep_loss_std": 14.47513484954834, "eval/reward_avg": 0.03076171875, "eval/reward_loss_mean": 0.1304417997598648, "eval/reward_loss_std": 0.9241150617599487, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.062880277633667, "eval/reward_neg_acc": 0.9959554076194763, "eval/reward_neg_loss": 0.05944685637950897, "eval/reward_pos_acc": 0.8285714387893677, "eval/reward_pos_loss": 2.1365559101104736, "eval/reward_pred": 0.026087414473295212, "eval/reward_rate": 0.0341796875, "replay/size": 107120.0, "replay/inserts": 2177.0, "replay/samples": 34832.0, "replay/insert_wait_avg": 2.7022232525273096e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.543806970584924e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 21096.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 8.195638656616211e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2727751731873, "timer/env.step_count": 272.0, "timer/env.step_total": 28.151029586791992, "timer/env.step_frac": 0.028143352778863668, "timer/env.step_avg": 0.10349643230438232, "timer/env.step_min": 0.023314237594604492, "timer/env.step_max": 3.978586435317993, "timer/replay._sample_count": 34832.0, "timer/replay._sample_total": 17.209715843200684, "timer/replay._sample_frac": 0.01720502274014305, "timer/replay._sample_avg": 0.0004940777401010761, "timer/replay._sample_min": 0.00037217140197753906, "timer/replay._sample_max": 0.027775049209594727, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 272.0, "timer/agent.policy_total": 4.358661651611328, "timer/agent.policy_frac": 0.00435747304114787, "timer/agent.policy_avg": 0.016024491366218117, "timer/agent.policy_min": 0.009807586669921875, "timer/agent.policy_max": 0.025788545608520508, "timer/dataset_train_count": 2177.0, "timer/dataset_train_total": 0.38547182083129883, "timer/dataset_train_frac": 0.00038536670236232135, "timer/dataset_train_avg": 0.0001770656044241152, "timer/dataset_train_min": 8.96453857421875e-05, "timer/dataset_train_max": 0.0005114078521728516, "timer/agent.train_count": 2177.0, "timer/agent.train_total": 965.4907791614532, "timer/agent.train_frac": 0.9652274890659582, "timer/agent.train_avg": 0.44349599410264273, "timer/agent.train_min": 0.4330449104309082, "timer/agent.train_max": 0.5591537952423096, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47691845893859863, "timer/agent.report_frac": 0.00047678840289942407, "timer/agent.report_avg": 0.23845922946929932, "timer/agent.report_min": 0.229994535446167, "timer/agent.report_max": 0.24692392349243164, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.218650817871094e-05, "timer/dataset_eval_frac": 3.2177730892593935e-08, "timer/dataset_eval_avg": 3.218650817871094e-05, "timer/dataset_eval_min": 3.218650817871094e-05, "timer/dataset_eval_max": 3.218650817871094e-05, "fps": 2.176373674780544}
{"step": 107968, "time": 49472.130168676376, "episode/length": 181.0, "episode/score": 4.100000016391277, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 108032, "time": 49502.16664862633, "episode/length": 130.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9618320610687023, "episode/intrinsic_return": 0.0}
{"step": 108368, "time": 49654.2892100811, "episode/length": 156.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 108560, "time": 49741.862129449844, "episode/length": 174.0, "episode/score": 2.0999999940395355, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 108624, "time": 49772.03910636902, "episode/length": 81.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9512195121951219, "episode/intrinsic_return": 0.0}
{"step": 108672, "time": 49795.54838871956, "episode/length": 164.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 109136, "time": 50005.29233074188, "episode/length": 248.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 109464, "time": 50153.53929543495, "episode/length": 178.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 109632, "time": 50230.418833732605, "episode/length": 301.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9900662251655629, "episode/intrinsic_return": 0.0}
{"step": 109712, "time": 50267.713723659515, "episode/length": 311.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 109819, "time": 50317.885311841965, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.757378007723316, "train/action_min": 0.0, "train/action_std": 4.317013698081448, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04570187941261623, "train/actor_opt_grad_steps": 107160.0, "train/actor_opt_loss": -16.456296596080744, "train/adv_mag": 0.8404490270026742, "train/adv_max": 0.7836431915357233, "train/adv_mean": 0.0021496922340764734, "train/adv_min": -0.6627441520832446, "train/adv_std": 0.05886766649612553, "train/cont_avg": 0.9946891053082192, "train/cont_loss_mean": 4.99081417498542e-06, "train/cont_loss_std": 0.00011500553213412782, "train/cont_neg_acc": 1.0, "train/cont_neg_loss": 0.00013751378611407436, "train/cont_pos_acc": 0.9999999806761197, "train/cont_pos_loss": 4.294863466797372e-06, "train/cont_pred": 0.9946860031450175, "train/cont_rate": 0.9946891053082192, "train/dyn_loss_mean": 2.9491317598787075, "train/dyn_loss_std": 7.796411405415295, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.3673697160259228, "train/extr_critic_critic_opt_grad_steps": 107160.0, "train/extr_critic_critic_opt_loss": 15781.329694634704, "train/extr_critic_mag": 14.075737848673782, "train/extr_critic_max": 14.075737848673782, "train/extr_critic_mean": 2.2138624871702497, "train/extr_critic_min": -0.7089611411639, "train/extr_critic_std": 2.5870689126454534, "train/extr_return_normed_mag": 1.7991324543408607, "train/extr_return_normed_max": 1.7991324543408607, "train/extr_return_normed_mean": 0.3068030366342362, "train/extr_return_normed_min": -0.11446739435536132, "train/extr_return_normed_std": 0.32770474500035585, "train/extr_return_rate": 0.6512373099316201, "train/extr_return_raw_mag": 14.284417052247209, "train/extr_return_raw_max": 14.284417052247209, "train/extr_return_raw_mean": 2.231338525471622, "train/extr_return_raw_min": -1.175296758952206, "train/extr_return_raw_std": 2.6477939429348463, "train/extr_reward_mag": 1.027094894348214, "train/extr_reward_max": 1.026977234235093, "train/extr_reward_mean": 0.02831269981824372, "train/extr_reward_min": -0.6969746166168282, "train/extr_reward_std": 0.171265864617204, "train/image_loss_mean": 1.5440670586612126, "train/image_loss_std": 4.680443238449968, "train/model_loss_mean": 3.348411740777699, "train/model_loss_std": 8.485355773472895, "train/model_opt_grad_norm": 31.415525589514218, "train/model_opt_grad_steps": 107068.61187214612, "train/model_opt_loss": 8896.129502666596, "train/model_opt_model_opt_grad_overflow": 0.0045662100456621, "train/model_opt_model_opt_grad_scale": 2642.6940639269405, "train/policy_entropy_mag": 2.54355107268242, "train/policy_entropy_max": 2.54355107268242, "train/policy_entropy_mean": 0.6110714011268529, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6547841946828311, "train/policy_logprob_mag": 7.4383839581110704, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.6109247398158731, "train/policy_logprob_min": -7.4383839581110704, "train/policy_logprob_std": 1.1418342993139676, "train/policy_randomness_mag": 0.8977619085682037, "train/policy_randomness_max": 0.8977619085682037, "train/policy_randomness_mean": 0.21568139196803035, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.2311100874725542, "train/post_ent_mag": 44.29568916913037, "train/post_ent_max": 44.29568916913037, "train/post_ent_mean": 24.61322882839534, "train/post_ent_min": 13.13733569018917, "train/post_ent_std": 4.3083684487974265, "train/prior_ent_mag": 76.90090005256269, "train/prior_ent_max": 76.90090005256269, "train/prior_ent_mean": 27.497872217605103, "train/prior_ent_min": 14.529574128590763, "train/prior_ent_std": 8.928670517385822, "train/rep_loss_mean": 2.9491317598787075, "train/rep_loss_std": 7.796411405415295, "train/reward_avg": 0.019759114410677184, "train/reward_loss_mean": 0.03486062693473411, "train/reward_loss_std": 0.15655367916713567, "train/reward_max_data": 1.0118721489492617, "train/reward_max_pred": 1.011950089506907, "train/reward_neg_acc": 0.9966941075782253, "train/reward_neg_loss": 0.01785498414588369, "train/reward_pos_acc": 0.9927790284701133, "train/reward_pos_loss": 0.7085241699871951, "train/reward_pred": 0.019707856013027093, "train/reward_rate": 0.024694991438356163, "train_stats/sum_log_reward": 3.599999964237213, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 3.0, "train_stats/max_log_achievement_collect_sapling": 1.5, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 2.1, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.4, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 0.8, "train_stats/max_log_achievement_wake_up": 2.3, "train_stats/mean_log_entropy": 0.5991909146308899, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 7.888114851084538e-06, "report/cont_loss_std": 0.00020837353076785803, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.91111394087784e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 7.810866009094752e-06, "report/cont_pred": 0.9931565523147583, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 2.984567880630493, "report/dyn_loss_std": 8.02680492401123, "report/image_loss_mean": 1.216799020767212, "report/image_loss_std": 3.195374011993408, "report/model_loss_mean": 3.0463476181030273, "report/model_loss_std": 7.314272880554199, "report/post_ent_mag": 40.980247497558594, "report/post_ent_max": 40.980247497558594, "report/post_ent_mean": 24.61294937133789, "report/post_ent_min": 13.226194381713867, "report/post_ent_std": 4.228448390960693, "report/prior_ent_mag": 76.9433364868164, "report/prior_ent_max": 76.9433364868164, "report/prior_ent_mean": 27.59210777282715, "report/prior_ent_min": 15.941532135009766, "report/prior_ent_std": 9.00612735748291, "report/rep_loss_mean": 2.984567880630493, "report/rep_loss_std": 8.02680492401123, "report/reward_avg": 0.0234375, "report/reward_loss_mean": 0.03879990428686142, "report/reward_loss_std": 0.16823165118694305, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.08542799949646, "report/reward_neg_acc": 0.9969818592071533, "report/reward_neg_loss": 0.017642792314291, "report/reward_pos_acc": 0.9666666984558105, "report/reward_pos_loss": 0.7398054599761963, "report/reward_pred": 0.02259824238717556, "report/reward_rate": 0.029296875, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 6.663515250693308e-07, "eval/cont_loss_std": 6.027600534252997e-07, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 8.464232450933196e-06, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 6.51091454528796e-07, "eval/cont_pred": 0.9980462789535522, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 20.219886779785156, "eval/dyn_loss_std": 13.468673706054688, "eval/image_loss_mean": 29.704509735107422, "eval/image_loss_std": 36.255191802978516, "eval/model_loss_mean": 42.05120086669922, "eval/model_loss_std": 42.157249450683594, "eval/post_ent_mag": 48.15108108520508, "eval/post_ent_max": 48.15108108520508, "eval/post_ent_mean": 28.395505905151367, "eval/post_ent_min": 15.121474266052246, "eval/post_ent_std": 3.792349338531494, "eval/prior_ent_mag": 76.9433364868164, "eval/prior_ent_max": 76.9433364868164, "eval/prior_ent_mean": 36.80083084106445, "eval/prior_ent_min": 15.676138877868652, "eval/prior_ent_std": 8.828742027282715, "eval/rep_loss_mean": 20.219886779785156, "eval/rep_loss_std": 13.468673706054688, "eval/reward_avg": 0.02255859412252903, "eval/reward_loss_mean": 0.21475592255592346, "eval/reward_loss_std": 1.256043553352356, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0018236637115479, "eval/reward_neg_acc": 0.996990978717804, "eval/reward_neg_loss": 0.13767872750759125, "eval/reward_pos_acc": 0.6666666865348816, "eval/reward_pos_loss": 3.060903549194336, "eval/reward_pred": 0.015850264579057693, "eval/reward_rate": 0.0263671875, "replay/size": 109315.0, "replay/inserts": 2195.0, "replay/samples": 35120.0, "replay/insert_wait_avg": 2.6630106167804135e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.558927992210301e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 21096.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 8.493661880493164e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3031499385834, "timer/env.step_count": 275.0, "timer/env.step_total": 23.05789065361023, "timer/env.step_frac": 0.023050902773850045, "timer/env.step_avg": 0.0838468751040372, "timer/env.step_min": 0.02341914176940918, "timer/env.step_max": 1.9195749759674072, "timer/replay._sample_count": 35120.0, "timer/replay._sample_total": 17.339306831359863, "timer/replay._sample_frac": 0.01733405201455625, "timer/replay._sample_avg": 0.0004937160259498822, "timer/replay._sample_min": 0.0003685951232910156, "timer/replay._sample_max": 0.016098976135253906, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 275.0, "timer/agent.policy_total": 4.424582481384277, "timer/agent.policy_frac": 0.004423241575972182, "timer/agent.policy_avg": 0.01608939084139737, "timer/agent.policy_min": 0.010020017623901367, "timer/agent.policy_max": 0.033039093017578125, "timer/dataset_train_count": 2195.0, "timer/dataset_train_total": 0.3904688358306885, "timer/dataset_train_frac": 0.00039035050110025393, "timer/dataset_train_avg": 0.00017789013021899248, "timer/dataset_train_min": 9.131431579589844e-05, "timer/dataset_train_max": 0.0011577606201171875, "timer/agent.train_count": 2195.0, "timer/agent.train_total": 970.6884291172028, "timer/agent.train_frac": 0.9703942541586529, "timer/agent.train_avg": 0.4422270747686573, "timer/agent.train_min": 0.43366384506225586, "timer/agent.train_max": 0.5591731071472168, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4721086025238037, "timer/agent.report_frac": 0.00047196552620352165, "timer/agent.report_avg": 0.23605430126190186, "timer/agent.report_min": 0.22867441177368164, "timer/agent.report_max": 0.24343419075012207, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.765655517578125e-05, "timer/dataset_eval_frac": 2.764817363364227e-08, "timer/dataset_eval_avg": 2.765655517578125e-05, "timer/dataset_eval_min": 2.765655517578125e-05, "timer/dataset_eval_max": 2.765655517578125e-05, "fps": 2.194307023299769}
{"step": 109896, "time": 50352.658996105194, "episode/length": 166.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 110008, "time": 50404.57083630562, "episode/length": 166.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 110032, "time": 50431.91188287735, "eval_episode/length": 64.0, "eval_episode/score": 1.0999999716877937, "eval_episode/reward_rate": 0.9846153846153847}
{"step": 110032, "time": 50435.16596317291, "eval_episode/length": 111.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9553571428571429}
{"step": 110032, "time": 50438.668924331665, "eval_episode/length": 160.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9937888198757764}
{"step": 110032, "time": 50440.495462179184, "eval_episode/length": 166.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9940119760479041}
{"step": 110032, "time": 50442.04858875275, "eval_episode/length": 168.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9763313609467456}
{"step": 110032, "time": 50444.20886731148, "eval_episode/length": 185.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9946236559139785}
{"step": 110032, "time": 50445.82267475128, "eval_episode/length": 188.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9947089947089947}
{"step": 110032, "time": 50447.48142981529, "eval_episode/length": 191.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9739583333333334}
{"step": 110064, "time": 50461.840270996094, "episode/length": 211.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 110080, "time": 50470.67910075188, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 110560, "time": 50687.481746673584, "episode/length": 136.0, "episode/score": 2.0999999791383743, "episode/reward_rate": 0.9927007299270073, "episode/intrinsic_return": 0.0}
{"step": 110960, "time": 50868.32963967323, "episode/length": 165.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 111120, "time": 50941.63036966324, "episode/length": 175.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 111280, "time": 51015.07726216316, "episode/length": 151.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9605263157894737, "episode/intrinsic_return": 0.0}
{"step": 111288, "time": 51020.19593024254, "episode/length": 173.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 111520, "time": 51126.12748837471, "episode/length": 188.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 111864, "time": 51282.25142121315, "episode/length": 222.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 111939, "time": 51318.281844615936, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.763797688034345, "train/action_min": 0.0, "train/action_std": 4.235388176621131, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.049842407364609105, "train/actor_opt_grad_steps": 109315.0, "train/actor_opt_loss": -15.608190919711905, "train/adv_mag": 0.9942585747196989, "train/adv_max": 0.8974806084385458, "train/adv_mean": 0.003233514810315957, "train/adv_min": -0.801606666367009, "train/adv_std": 0.06412408866409985, "train/cont_avg": 0.9943340949292453, "train/cont_loss_mean": 2.2039465706903763e-05, "train/cont_loss_std": 0.0006643369215754922, "train/cont_neg_acc": 1.0, "train/cont_neg_loss": 0.00017800581539168493, "train/cont_pos_acc": 0.9999953348119304, "train/cont_pos_loss": 2.102844397790945e-05, "train/cont_pred": 0.9943285308918863, "train/cont_rate": 0.9943340949292453, "train/dyn_loss_mean": 2.96969041059602, "train/dyn_loss_std": 7.843489588431592, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.3557875386948854, "train/extr_critic_critic_opt_grad_steps": 109315.0, "train/extr_critic_critic_opt_loss": 15942.464908239976, "train/extr_critic_mag": 16.02981103591199, "train/extr_critic_max": 16.02981103591199, "train/extr_critic_mean": 2.2006218045387627, "train/extr_critic_min": -0.6810394626743389, "train/extr_critic_std": 2.7032942445773, "train/extr_return_normed_mag": 2.0347878809245126, "train/extr_return_normed_max": 2.0347878809245126, "train/extr_return_normed_mean": 0.3021808696102421, "train/extr_return_normed_min": -0.1079929345199522, "train/extr_return_normed_std": 0.34504050887980553, "train/extr_return_rate": 0.6392771920786714, "train/extr_return_raw_mag": 16.22758433953771, "train/extr_return_raw_max": 16.22758433953771, "train/extr_return_raw_mean": 2.2267794552839026, "train/extr_return_raw_min": -1.0837534289315063, "train/extr_return_raw_std": 2.7863143929895364, "train/extr_reward_mag": 1.0367805294270784, "train/extr_reward_max": 1.0367805294270784, "train/extr_reward_mean": 0.030606648129112315, "train/extr_reward_min": -0.7034864954228671, "train/extr_reward_std": 0.17698950545405442, "train/image_loss_mean": 1.5273348660963886, "train/image_loss_std": 4.729727088280444, "train/model_loss_mean": 3.3452544257325947, "train/model_loss_std": 8.535320623865667, "train/model_opt_grad_norm": 31.37067770058254, "train/model_opt_grad_steps": 109221.7924528302, "train/model_opt_loss": 5584.019072910525, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1668.632075471698, "train/policy_entropy_mag": 2.5453599578929396, "train/policy_entropy_max": 2.5453599578929396, "train/policy_entropy_mean": 0.614291953309527, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6597472367421636, "train/policy_logprob_mag": 7.438383952626642, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.6145519439904195, "train/policy_logprob_min": -7.438383952626642, "train/policy_logprob_std": 1.146701601878652, "train/policy_randomness_mag": 0.898400365743997, "train/policy_randomness_max": 0.898400365743997, "train/policy_randomness_mean": 0.21681810184469763, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.23286182377135978, "train/post_ent_mag": 44.58434157101613, "train/post_ent_max": 44.58434157101613, "train/post_ent_mean": 24.940643454497714, "train/post_ent_min": 13.149103596525372, "train/post_ent_std": 4.279500867960588, "train/prior_ent_mag": 76.95780401409797, "train/prior_ent_max": 76.95780401409797, "train/prior_ent_mean": 27.826655603804678, "train/prior_ent_min": 14.5848177918848, "train/prior_ent_std": 8.921706051196692, "train/rep_loss_mean": 2.96969041059602, "train/rep_loss_std": 7.843489588431592, "train/reward_avg": 0.02037192280579991, "train/reward_loss_mean": 0.0360832769107425, "train/reward_loss_std": 0.1622790305892814, "train/reward_max_data": 1.0150943432214126, "train/reward_max_pred": 1.015393760406746, "train/reward_neg_acc": 0.9963367002190284, "train/reward_neg_loss": 0.01834817656605803, "train/reward_pos_acc": 0.9918591177688455, "train/reward_pos_loss": 0.7155812250555686, "train/reward_pred": 0.020251926162086847, "train/reward_rate": 0.025432082841981132, "train_stats/sum_log_reward": 4.372727188197049, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 2.5454545454545454, "train_stats/max_log_achievement_collect_sapling": 2.1818181818181817, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 1.7272727272727273, "train_stats/max_log_achievement_defeat_zombie": 0.09090909090909091, "train_stats/max_log_achievement_eat_cow": 0.09090909090909091, "train_stats/max_log_achievement_make_wood_pickaxe": 0.2727272727272727, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 2.0, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 0.5454545454545454, "train_stats/max_log_achievement_wake_up": 1.4545454545454546, "train_stats/mean_log_entropy": 0.5933231521736492, "eval_stats/sum_log_reward": 3.3499999046325684, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 1.625, "eval_stats/max_log_achievement_collect_sapling": 1.75, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 1.25, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 1.5, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 0.25, "eval_stats/max_log_achievement_wake_up": 1.125, "eval_stats/mean_log_entropy": 0.0, "train_stats/max_log_achievement_defeat_skeleton": 0.16666666666666666, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 3.2454926213176805e-07, "report/cont_loss_std": 5.369932409848843e-07, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 4.720739980257349e-06, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 3.073093353123113e-07, "report/cont_pred": 0.9960935115814209, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 2.5378670692443848, "report/dyn_loss_std": 7.238924503326416, "report/image_loss_mean": 1.0934696197509766, "report/image_loss_std": 4.18784236907959, "report/model_loss_mean": 2.649735927581787, "report/model_loss_std": 7.7324724197387695, "report/post_ent_mag": 45.035377502441406, "report/post_ent_max": 45.035377502441406, "report/post_ent_mean": 24.77959632873535, "report/post_ent_min": 13.138450622558594, "report/post_ent_std": 4.470559597015381, "report/prior_ent_mag": 76.90831756591797, "report/prior_ent_max": 76.90831756591797, "report/prior_ent_mean": 27.128055572509766, "report/prior_ent_min": 13.97707748413086, "report/prior_ent_std": 8.650951385498047, "report/rep_loss_mean": 2.5378670692443848, "report/rep_loss_std": 7.238924503326416, "report/reward_avg": 0.02832031436264515, "report/reward_loss_mean": 0.03354577720165253, "report/reward_loss_std": 0.14334063231945038, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0006487369537354, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.01280568540096283, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6764886379241943, "report/reward_pred": 0.028069738298654556, "report/reward_rate": 0.03125, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.01246254239231348, "eval/cont_loss_std": 0.398486852645874, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 3.184477463946678e-05, "eval/cont_pos_acc": 0.999018669128418, "eval/cont_pos_loss": 0.012523535639047623, "eval/cont_pred": 0.9941372871398926, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 23.429893493652344, "eval/dyn_loss_std": 13.897987365722656, "eval/image_loss_mean": 32.272666931152344, "eval/image_loss_std": 34.32732009887695, "eval/model_loss_mean": 46.56420135498047, "eval/model_loss_std": 40.01955032348633, "eval/post_ent_mag": 45.28938674926758, "eval/post_ent_max": 45.28938674926758, "eval/post_ent_mean": 29.667373657226562, "eval/post_ent_min": 14.092816352844238, "eval/post_ent_std": 3.3152551651000977, "eval/prior_ent_mag": 76.90831756591797, "eval/prior_ent_max": 76.90831756591797, "eval/prior_ent_mean": 39.822792053222656, "eval/prior_ent_min": 17.157533645629883, "eval/prior_ent_std": 8.005556106567383, "eval/rep_loss_mean": 23.429893493652344, "eval/rep_loss_std": 13.897987365722656, "eval/reward_avg": 0.02373046800494194, "eval/reward_loss_mean": 0.22113800048828125, "eval/reward_loss_std": 1.2378994226455688, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0005862712860107, "eval/reward_neg_acc": 0.9939698576927185, "eval/reward_neg_loss": 0.12903477251529694, "eval/reward_pos_acc": 0.6206896305084229, "eval/reward_pos_loss": 3.3812308311462402, "eval/reward_pred": 0.01687835529446602, "eval/reward_rate": 0.0283203125, "replay/size": 111435.0, "replay/inserts": 2120.0, "replay/samples": 33920.0, "replay/insert_wait_avg": 2.5506289500110554e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.399691725676914e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 22632.0, "eval_replay/inserts": 1536.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.077074557542801e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.5367431640625e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3807945251465, "timer/env.step_count": 265.0, "timer/env.step_total": 24.097374200820923, "timer/env.step_frac": 0.024088201545551753, "timer/env.step_avg": 0.09093348755026763, "timer/env.step_min": 0.02386474609375, "timer/env.step_max": 1.8736488819122314, "timer/replay._sample_count": 33920.0, "timer/replay._sample_total": 16.602367639541626, "timer/replay._sample_frac": 0.016596047955341163, "timer/replay._sample_avg": 0.000489456593146864, "timer/replay._sample_min": 0.00035762786865234375, "timer/replay._sample_max": 0.011699438095092773, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 457.0, "timer/agent.policy_total": 7.207801580429077, "timer/agent.policy_frac": 0.007205057933814517, "timer/agent.policy_avg": 0.015771994705534087, "timer/agent.policy_min": 0.009595155715942383, "timer/agent.policy_max": 0.04080319404602051, "timer/dataset_train_count": 2120.0, "timer/dataset_train_total": 0.3727240562438965, "timer/dataset_train_frac": 0.00037258217898996997, "timer/dataset_train_avg": 0.00017581323407730965, "timer/dataset_train_min": 8.893013000488281e-05, "timer/dataset_train_max": 0.0018200874328613281, "timer/agent.train_count": 2120.0, "timer/agent.train_total": 939.3684849739075, "timer/agent.train_frac": 0.9390109147585146, "timer/agent.train_avg": 0.4430983419688243, "timer/agent.train_min": 0.4307739734649658, "timer/agent.train_max": 0.5802633762359619, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4763929843902588, "timer/agent.report_frac": 0.00047621164560280227, "timer/agent.report_avg": 0.2381964921951294, "timer/agent.report_min": 0.23033928871154785, "timer/agent.report_max": 0.24605369567871094, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.147125244140625e-05, "timer/dataset_eval_frac": 3.145927292251227e-08, "timer/dataset_eval_avg": 3.147125244140625e-05, "timer/dataset_eval_min": 3.147125244140625e-05, "timer/dataset_eval_max": 3.147125244140625e-05, "fps": 2.1191652220895087}
{"step": 112232, "time": 51450.386875629425, "episode/length": 208.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 112256, "time": 51462.71426963806, "episode/length": 389.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9769230769230769, "episode/intrinsic_return": 0.0}
{"step": 112448, "time": 51550.2346162796, "episode/length": 185.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 112496, "time": 51573.29212594032, "episode/length": 150.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 112608, "time": 51625.11387395859, "episode/length": 165.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 112752, "time": 51691.381172180176, "episode/length": 203.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 112888, "time": 51754.32054567337, "episode/length": 127.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9453125, "episode/intrinsic_return": 0.0}
{"step": 112936, "time": 51777.32601642609, "episode/length": 176.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 113384, "time": 51979.99037861824, "episode/length": 143.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 113672, "time": 52110.781569480896, "episode/length": 152.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9607843137254902, "episode/intrinsic_return": 0.0}
{"step": 113704, "time": 52126.654380083084, "episode/length": 180.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 113992, "time": 52257.20754337311, "episode/length": 186.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 114124, "time": 52318.33753204346, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.752243808415383, "train/action_min": 0.0, "train/action_std": 4.127885809772091, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04749371401421283, "train/actor_opt_grad_steps": 111470.0, "train/actor_opt_loss": -15.541333477927125, "train/adv_mag": 0.9294295921989771, "train/adv_max": 0.8609090794439185, "train/adv_mean": 0.002280207039088611, "train/adv_min": -0.7325553262614768, "train/adv_std": 0.060881089197990554, "train/cont_avg": 0.9945062785388128, "train/cont_loss_mean": 4.196623107746825e-05, "train/cont_loss_std": 0.0012630137139309537, "train/cont_neg_acc": 0.9984344426355406, "train/cont_neg_loss": 0.005910407354024478, "train/cont_pos_acc": 0.9999955024349091, "train/cont_pos_loss": 9.801423068138663e-06, "train/cont_pred": 0.9945155708757165, "train/cont_rate": 0.9945062785388128, "train/dyn_loss_mean": 3.0431728417470576, "train/dyn_loss_std": 7.8535132125088065, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.3474917866323637, "train/extr_critic_critic_opt_grad_steps": 111470.0, "train/extr_critic_critic_opt_loss": 15836.732230129852, "train/extr_critic_mag": 15.071413462564825, "train/extr_critic_max": 15.071413462564825, "train/extr_critic_mean": 2.1477581366012086, "train/extr_critic_min": -0.6755580727912519, "train/extr_critic_std": 2.6775432661788106, "train/extr_return_normed_mag": 1.893882450992114, "train/extr_return_normed_max": 1.893882450992114, "train/extr_return_normed_mean": 0.29218048796261825, "train/extr_return_normed_min": -0.1055822769800822, "train/extr_return_normed_std": 0.33442714524595707, "train/extr_return_rate": 0.630154261850331, "train/extr_return_raw_mag": 15.297895300878237, "train/extr_return_raw_max": 15.297895300878237, "train/extr_return_raw_mean": 2.166553231134807, "train/extr_return_raw_min": -1.085982674605226, "train/extr_return_raw_std": 2.7396429831578852, "train/extr_reward_mag": 1.0245138346876728, "train/extr_reward_max": 1.0245138346876728, "train/extr_reward_mean": 0.029642178540938792, "train/extr_reward_min": -0.6955480575561523, "train/extr_reward_std": 0.1745163094779672, "train/image_loss_mean": 1.6749298556210244, "train/image_loss_std": 5.014418839863991, "train/model_loss_mean": 3.536970755825304, "train/model_loss_std": 8.796809625407876, "train/model_opt_grad_norm": 30.605266571044922, "train/model_opt_grad_steps": 111375.3607305936, "train/model_opt_loss": 5712.50850032998, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1609.5890410958905, "train/policy_entropy_mag": 2.5657185125568684, "train/policy_entropy_max": 2.5657185125568684, "train/policy_entropy_mean": 0.6339828165154479, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6848471390602251, "train/policy_logprob_mag": 7.438383947224377, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.6339257349978843, "train/policy_logprob_min": -7.438383947224377, "train/policy_logprob_std": 1.1614600365564702, "train/policy_randomness_mag": 0.905586041544126, "train/policy_randomness_max": 0.905586041544126, "train/policy_randomness_mean": 0.2237681132745525, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.24172098601245445, "train/post_ent_mag": 44.37429482098584, "train/post_ent_max": 44.37429482098584, "train/post_ent_mean": 25.055305472247678, "train/post_ent_min": 13.191937215796344, "train/post_ent_std": 4.405504164630419, "train/prior_ent_mag": 76.92819673721104, "train/prior_ent_max": 76.92819673721104, "train/prior_ent_mean": 28.02386319582865, "train/prior_ent_min": 14.547631028580339, "train/prior_ent_std": 8.96413390494917, "train/rep_loss_mean": 3.0431728417470576, "train/rep_loss_std": 7.8535132125088065, "train/reward_avg": 0.020118079243916762, "train/reward_loss_mean": 0.036095215858185675, "train/reward_loss_std": 0.16520783380014167, "train/reward_max_data": 1.0155251178567268, "train/reward_max_pred": 1.0153875857183379, "train/reward_neg_acc": 0.9964533459105992, "train/reward_neg_loss": 0.018560064858735695, "train/reward_pos_acc": 0.990705233730682, "train/reward_pos_loss": 0.7172456503458763, "train/reward_pred": 0.019992748934554456, "train/reward_rate": 0.025096318493150686, "train_stats/sum_log_reward": 4.766666611035665, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 3.3333333333333335, "train_stats/max_log_achievement_collect_sapling": 1.6666666666666667, "train_stats/max_log_achievement_collect_stone": 0.08333333333333333, "train_stats/max_log_achievement_collect_wood": 4.333333333333333, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.08333333333333333, "train_stats/max_log_achievement_make_wood_pickaxe": 0.16666666666666666, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.6666666666666667, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 1.5833333333333333, "train_stats/max_log_achievement_wake_up": 2.0, "train_stats/mean_log_entropy": 0.6019542788465818, "report/cont_avg": 0.9990234375, "report/cont_loss_mean": 2.3190033004993893e-07, "report/cont_loss_std": 5.478671482705977e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0001753853284753859, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 6.068485447485727e-08, "report/cont_pred": 0.9990236163139343, "report/cont_rate": 0.9990234375, "report/dyn_loss_mean": 2.6714706420898438, "report/dyn_loss_std": 7.389685153961182, "report/image_loss_mean": 1.2641217708587646, "report/image_loss_std": 3.706143856048584, "report/model_loss_mean": 2.893852472305298, "report/model_loss_std": 7.193702697753906, "report/post_ent_mag": 40.38108444213867, "report/post_ent_max": 40.38108444213867, "report/post_ent_mean": 24.68075942993164, "report/post_ent_min": 12.667501449584961, "report/post_ent_std": 4.667647361755371, "report/prior_ent_mag": 77.07769775390625, "report/prior_ent_max": 77.07769775390625, "report/prior_ent_mean": 27.398149490356445, "report/prior_ent_min": 14.972304344177246, "report/prior_ent_std": 8.390820503234863, "report/rep_loss_mean": 2.6714706420898438, "report/rep_loss_std": 7.389685153961182, "report/reward_avg": 0.02587890625, "report/reward_loss_mean": 0.026847708970308304, "report/reward_loss_std": 0.12899522483348846, "report/reward_max_data": 1.0, "report/reward_max_pred": 0.9994674921035767, "report/reward_neg_acc": 0.99698805809021, "report/reward_neg_loss": 0.008658346720039845, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6738693714141846, "report/reward_pred": 0.026058999821543694, "report/reward_rate": 0.02734375, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 7.719395216554403e-05, "eval/cont_loss_std": 0.0022056614980101585, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.03523923084139824, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 8.383704880543519e-06, "eval/cont_pred": 0.9981050491333008, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 23.592126846313477, "eval/dyn_loss_std": 11.678635597229004, "eval/image_loss_mean": 38.031185150146484, "eval/image_loss_std": 39.841854095458984, "eval/model_loss_mean": 52.308677673339844, "eval/model_loss_std": 43.917686462402344, "eval/post_ent_mag": 46.930084228515625, "eval/post_ent_max": 46.930084228515625, "eval/post_ent_mean": 29.421981811523438, "eval/post_ent_min": 16.359363555908203, "eval/post_ent_std": 3.8196799755096436, "eval/prior_ent_mag": 77.07769775390625, "eval/prior_ent_max": 77.07769775390625, "eval/prior_ent_mean": 39.469017028808594, "eval/prior_ent_min": 20.232688903808594, "eval/prior_ent_std": 8.027414321899414, "eval/rep_loss_mean": 23.592126846313477, "eval/rep_loss_std": 11.678635597229004, "eval/reward_avg": 0.01982421986758709, "eval/reward_loss_mean": 0.12213771045207977, "eval/reward_loss_std": 0.8415126204490662, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0000121593475342, "eval/reward_neg_acc": 0.9970059990882874, "eval/reward_neg_loss": 0.049150753766298294, "eval/reward_pos_acc": 0.5454545617103577, "eval/reward_pos_loss": 3.446362018585205, "eval/reward_pred": 0.01158770639449358, "eval/reward_rate": 0.021484375, "replay/size": 113620.0, "replay/inserts": 2185.0, "replay/samples": 34960.0, "replay/insert_wait_avg": 2.592815687236306e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.328234220805921e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 22632.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 8.493661880493164e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0445084571838, "timer/env.step_count": 273.0, "timer/env.step_total": 25.39063811302185, "timer/env.step_frac": 0.025389508065189213, "timer/env.step_avg": 0.09300600041399945, "timer/env.step_min": 0.02318716049194336, "timer/env.step_max": 1.8915176391601562, "timer/replay._sample_count": 34960.0, "timer/replay._sample_total": 16.99691367149353, "timer/replay._sample_frac": 0.01699615719875856, "timer/replay._sample_avg": 0.00048618174117544423, "timer/replay._sample_min": 0.00033855438232421875, "timer/replay._sample_max": 0.021979808807373047, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 273.0, "timer/agent.policy_total": 4.404210567474365, "timer/agent.policy_frac": 0.004404014551581259, "timer/agent.policy_avg": 0.01613263944129804, "timer/agent.policy_min": 0.010209083557128906, "timer/agent.policy_max": 0.040640830993652344, "timer/dataset_train_count": 2185.0, "timer/dataset_train_total": 0.3798825740814209, "timer/dataset_train_frac": 0.00037986566684665245, "timer/dataset_train_avg": 0.00017385930163909424, "timer/dataset_train_min": 8.58306884765625e-05, "timer/dataset_train_max": 0.0004978179931640625, "timer/agent.train_count": 2185.0, "timer/agent.train_total": 968.124790430069, "timer/agent.train_frac": 0.9680817026070581, "timer/agent.train_avg": 0.44307770729064944, "timer/agent.train_min": 0.4321401119232178, "timer/agent.train_max": 0.583543062210083, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4728109836578369, "timer/agent.report_frac": 0.0004727899405070129, "timer/agent.report_avg": 0.23640549182891846, "timer/agent.report_min": 0.2300577163696289, "timer/agent.report_max": 0.242753267288208, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0279159545898438e-05, "timer/dataset_eval_frac": 3.0277811927202654e-08, "timer/dataset_eval_avg": 3.0279159545898438e-05, "timer/dataset_eval_min": 3.0279159545898438e-05, "timer/dataset_eval_max": 3.0279159545898438e-05, "fps": 2.1848746887552437}
{"step": 114200, "time": 52352.77263069153, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 114208, "time": 52357.76484918594, "episode/length": 181.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 114704, "time": 52582.50062537193, "episode/length": 226.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 114912, "time": 52677.11764883995, "episode/length": 190.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 115016, "time": 52725.09224271774, "episode/length": 167.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 115064, "time": 52748.212752342224, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 115440, "time": 52918.58863186836, "episode/length": 153.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 115504, "time": 52949.055290699005, "episode/length": 188.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 115832, "time": 53098.41699838638, "episode/length": 203.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 116136, "time": 53236.68763208389, "episode/length": 440.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 116216, "time": 53274.13519525528, "episode/length": 149.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 116310, "time": 53318.61721134186, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.630497901951341, "train/action_min": 0.0, "train/action_std": 4.066772450050807, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04671514532677659, "train/actor_opt_grad_steps": 113660.0, "train/actor_opt_loss": -8.240054974579104, "train/adv_mag": 0.9397260723593028, "train/adv_max": 0.8489924007899141, "train/adv_mean": 0.0030404123715667896, "train/adv_min": -0.7121408002017295, "train/adv_std": 0.056671161374681076, "train/cont_avg": 0.9946043807077626, "train/cont_loss_mean": 1.2791582865454098e-05, "train/cont_loss_std": 0.0003290715499956314, "train/cont_neg_acc": 0.9994292237442922, "train/cont_neg_loss": 0.0008513856282500509, "train/cont_pos_acc": 0.9999955018905744, "train/cont_pos_loss": 6.925100767111134e-06, "train/cont_pred": 0.9946027229365693, "train/cont_rate": 0.9946043807077626, "train/dyn_loss_mean": 2.993611159389966, "train/dyn_loss_std": 7.838597506692965, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.3510226724354644, "train/extr_critic_critic_opt_grad_steps": 113660.0, "train/extr_critic_critic_opt_loss": 15769.848681863585, "train/extr_critic_mag": 14.442862288592613, "train/extr_critic_max": 14.442862288592613, "train/extr_critic_mean": 2.083873890850642, "train/extr_critic_min": -0.668356799643878, "train/extr_critic_std": 2.5480979653798284, "train/extr_return_normed_mag": 1.958734355016386, "train/extr_return_normed_max": 1.958734355016386, "train/extr_return_normed_mean": 0.3061917780060746, "train/extr_return_normed_min": -0.122805889814956, "train/extr_return_normed_std": 0.34182097616533164, "train/extr_return_rate": 0.6463015817071749, "train/extr_return_raw_mag": 14.665895390183959, "train/extr_return_raw_max": 14.665895390183959, "train/extr_return_raw_mean": 2.106747871664561, "train/extr_return_raw_min": -1.1424002247313931, "train/extr_return_raw_std": 2.5963122817479314, "train/extr_reward_mag": 1.0310589902477176, "train/extr_reward_max": 1.0310589902477176, "train/extr_reward_mean": 0.030107850225888976, "train/extr_reward_min": -0.6911104765112541, "train/extr_reward_std": 0.1754109728145817, "train/image_loss_mean": 1.5512073470032923, "train/image_loss_std": 4.72900716953626, "train/model_loss_mean": 3.3830611814646963, "train/model_loss_std": 8.549142493504911, "train/model_opt_grad_norm": 29.518375753812048, "train/model_opt_grad_steps": 113563.61643835617, "train/model_opt_loss": 6588.823752764698, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1929.2237442922374, "train/policy_entropy_mag": 2.5496596495310464, "train/policy_entropy_max": 2.5496596495310464, "train/policy_entropy_mean": 0.6133438374626038, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6601127878716003, "train/policy_logprob_mag": 7.438383986416473, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.6130643384913875, "train/policy_logprob_min": -7.438383986416473, "train/policy_logprob_std": 1.146701630392031, "train/policy_randomness_mag": 0.8999179680597836, "train/policy_randomness_max": 0.8999179680597836, "train/policy_randomness_mean": 0.21648345826423332, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.23299084535744635, "train/post_ent_mag": 45.002703522982664, "train/post_ent_max": 45.002703522982664, "train/post_ent_mean": 25.26287705930945, "train/post_ent_min": 13.118964295409041, "train/post_ent_std": 4.382831657313865, "train/prior_ent_mag": 77.04500917756938, "train/prior_ent_max": 77.04500917756938, "train/prior_ent_mean": 28.18394362218848, "train/prior_ent_min": 14.53221826683985, "train/prior_ent_std": 8.918834555638979, "train/rep_loss_mean": 2.993611159389966, "train/rep_loss_std": 7.838597506692965, "train/reward_avg": 0.01982823184576549, "train/reward_loss_mean": 0.03567430804819549, "train/reward_loss_std": 0.16528686853848637, "train/reward_max_data": 1.01598173897016, "train/reward_max_pred": 1.0162557989494985, "train/reward_neg_acc": 0.996379520250782, "train/reward_neg_loss": 0.018226154388851362, "train/reward_pos_acc": 0.9882484111067367, "train/reward_pos_loss": 0.7269416543991054, "train/reward_pred": 0.019639518949709254, "train/reward_rate": 0.024663777111872145, "train_stats/sum_log_reward": 4.463636268268932, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 3.727272727272727, "train_stats/max_log_achievement_collect_sapling": 1.9090909090909092, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 2.6363636363636362, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.09090909090909091, "train_stats/max_log_achievement_make_wood_pickaxe": 0.2727272727272727, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.8181818181818181, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 1.0909090909090908, "train_stats/max_log_achievement_wake_up": 2.090909090909091, "train_stats/mean_log_entropy": 0.6517606296322562, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 8.374727826776507e-07, "report/cont_loss_std": 3.5332398056198144e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 3.368715988472104e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 6.762869020349171e-07, "report/cont_pred": 0.9951167106628418, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 2.714172601699829, "report/dyn_loss_std": 7.224756240844727, "report/image_loss_mean": 1.1749067306518555, "report/image_loss_std": 4.632212162017822, "report/model_loss_mean": 2.8372151851654053, "report/model_loss_std": 8.184561729431152, "report/post_ent_mag": 46.971126556396484, "report/post_ent_max": 46.971126556396484, "report/post_ent_mean": 25.857303619384766, "report/post_ent_min": 12.314167976379395, "report/post_ent_std": 4.758222579956055, "report/prior_ent_mag": 77.26830291748047, "report/prior_ent_max": 77.26830291748047, "report/prior_ent_mean": 28.724788665771484, "report/prior_ent_min": 13.248228073120117, "report/prior_ent_std": 8.925179481506348, "report/rep_loss_mean": 2.714172601699829, "report/rep_loss_std": 7.224756240844727, "report/reward_avg": 0.02255859412252903, "report/reward_loss_mean": 0.03380393981933594, "report/reward_loss_std": 0.1617349237203598, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.000647783279419, "report/reward_neg_acc": 0.9949849843978882, "report/reward_neg_loss": 0.014099243097007275, "report/reward_pos_acc": 0.9629629850387573, "report/reward_pos_loss": 0.7614181041717529, "report/reward_pred": 0.021834194660186768, "report/reward_rate": 0.0263671875, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.003713712329044938, "eval/cont_loss_std": 0.11875064671039581, "eval/cont_neg_acc": 0.6666666865348816, "eval/cont_neg_loss": 1.2673335075378418, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 8.240232887146703e-07, "eval/cont_pred": 0.9980243444442749, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 24.64431381225586, "eval/dyn_loss_std": 15.22185230255127, "eval/image_loss_mean": 49.916954040527344, "eval/image_loss_std": 56.2121696472168, "eval/model_loss_mean": 64.84625244140625, "eval/model_loss_std": 62.95225524902344, "eval/post_ent_mag": 46.971126556396484, "eval/post_ent_max": 46.971126556396484, "eval/post_ent_mean": 28.490144729614258, "eval/post_ent_min": 15.848604202270508, "eval/post_ent_std": 3.448894739151001, "eval/prior_ent_mag": 77.26830291748047, "eval/prior_ent_max": 77.26830291748047, "eval/prior_ent_mean": 38.62872314453125, "eval/prior_ent_min": 18.4444522857666, "eval/prior_ent_std": 8.741984367370605, "eval/rep_loss_mean": 24.64431381225586, "eval/rep_loss_std": 15.22185230255127, "eval/reward_avg": 0.02207031287252903, "eval/reward_loss_mean": 0.1390034258365631, "eval/reward_loss_std": 0.9350024461746216, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.00058913230896, "eval/reward_neg_acc": 0.9939939975738525, "eval/reward_neg_loss": 0.06706634908914566, "eval/reward_pos_acc": 0.6399999856948853, "eval/reward_pos_loss": 3.01360821723938, "eval/reward_pred": 0.015311378985643387, "eval/reward_rate": 0.0244140625, "replay/size": 115806.0, "replay/inserts": 2186.0, "replay/samples": 34976.0, "replay/insert_wait_avg": 2.649325574087857e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.261691678039327e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 22632.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 7.897615432739258e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2665326595306, "timer/env.step_count": 273.0, "timer/env.step_total": 23.584033727645874, "timer/env.step_frac": 0.023577749487369258, "timer/env.step_avg": 0.08638840193276877, "timer/env.step_min": 0.023473262786865234, "timer/env.step_max": 1.6600587368011475, "timer/replay._sample_count": 34976.0, "timer/replay._sample_total": 17.09252166748047, "timer/replay._sample_frac": 0.017087967166145704, "timer/replay._sample_avg": 0.000488692865607287, "timer/replay._sample_min": 0.00036334991455078125, "timer/replay._sample_max": 0.0298159122467041, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 273.0, "timer/agent.policy_total": 4.379906415939331, "timer/agent.policy_frac": 0.004378739338897943, "timer/agent.policy_avg": 0.016043613245199016, "timer/agent.policy_min": 0.009881258010864258, "timer/agent.policy_max": 0.037508487701416016, "timer/dataset_train_count": 2186.0, "timer/dataset_train_total": 0.3779177665710449, "timer/dataset_train_frac": 0.00037781706598363226, "timer/dataset_train_avg": 0.00017288095451557407, "timer/dataset_train_min": 8.7738037109375e-05, "timer/dataset_train_max": 0.0005981922149658203, "timer/agent.train_count": 2186.0, "timer/agent.train_total": 970.0908131599426, "timer/agent.train_frac": 0.9698323211720818, "timer/agent.train_avg": 0.44377438845377065, "timer/agent.train_min": 0.4324033260345459, "timer/agent.train_max": 0.5589337348937988, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4741485118865967, "timer/agent.report_frac": 0.0004740221694970841, "timer/agent.report_avg": 0.23707425594329834, "timer/agent.report_min": 0.2298448085784912, "timer/agent.report_max": 0.24430370330810547, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.956390380859375e-05, "timer/dataset_eval_frac": 2.9556026162335547e-08, "timer/dataset_eval_avg": 2.956390380859375e-05, "timer/dataset_eval_min": 2.956390380859375e-05, "timer/dataset_eval_max": 2.956390380859375e-05, "fps": 2.1853899363953833}
{"step": 116376, "time": 53348.69294667244, "episode/length": 163.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 116416, "time": 53369.0115571022, "episode/length": 213.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 116488, "time": 53403.77014708519, "episode/length": 196.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 116512, "time": 53416.63018155098, "episode/length": 125.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9603174603174603, "episode/intrinsic_return": 0.0}
{"step": 116736, "time": 53519.06270956993, "episode/length": 74.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9866666666666667, "episode/intrinsic_return": 0.0}
{"step": 117272, "time": 53761.257769823074, "episode/length": 228.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 117584, "time": 53902.993273973465, "episode/length": 38.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 117840, "time": 54019.54582738876, "episode/length": 177.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 117896, "time": 54046.07136797905, "episode/length": 189.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 117904, "time": 54051.12055897713, "episode/length": 258.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9768339768339769, "episode/intrinsic_return": 0.0}
{"step": 117912, "time": 54056.26287984848, "episode/length": 177.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 118208, "time": 54190.6903796196, "episode/length": 211.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 118272, "time": 54220.94068145752, "episode/length": 191.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 118485, "time": 54318.830367565155, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.425722183719758, "train/action_min": 0.0, "train/action_std": 3.956788467372068, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04676310870847944, "train/actor_opt_grad_steps": 115840.0, "train/actor_opt_loss": -8.34658741291767, "train/adv_mag": 0.7850351153705527, "train/adv_max": 0.7255089017927372, "train/adv_mean": 0.003593776158972784, "train/adv_min": -0.5688032177598795, "train/adv_std": 0.05584537449039622, "train/cont_avg": 0.9944376440092166, "train/cont_loss_mean": 0.00010611157229223037, "train/cont_loss_std": 0.0032684100583160445, "train/cont_neg_acc": 0.9979152959612657, "train/cont_neg_loss": 0.01559079065970422, "train/cont_pos_acc": 0.9999999848928319, "train/cont_pos_loss": 4.6798484536726636e-06, "train/cont_pred": 0.9944494688016479, "train/cont_rate": 0.9944376440092166, "train/dyn_loss_mean": 2.9866324064369025, "train/dyn_loss_std": 7.818742182946974, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.3295226868945882, "train/extr_critic_critic_opt_grad_steps": 115840.0, "train/extr_critic_critic_opt_loss": 15427.81622623848, "train/extr_critic_mag": 13.117641629161923, "train/extr_critic_max": 13.117641629161923, "train/extr_critic_mean": 2.488188301363299, "train/extr_critic_min": -0.6443443457651797, "train/extr_critic_std": 2.3820616039812292, "train/extr_return_normed_mag": 1.7976200569609893, "train/extr_return_normed_max": 1.7976200569609893, "train/extr_return_normed_mean": 0.3619722929967713, "train/extr_return_normed_min": -0.12921259054390516, "train/extr_return_normed_std": 0.32464029870000305, "train/extr_return_rate": 0.8240495815804477, "train/extr_return_raw_mag": 13.27286327819121, "train/extr_return_raw_max": 13.27286327819121, "train/extr_return_raw_mean": 2.515050256307224, "train/extr_return_raw_min": -1.1668981588381226, "train/extr_return_raw_std": 2.432652034517807, "train/extr_reward_mag": 1.0315656299415272, "train/extr_reward_max": 1.0315656299415272, "train/extr_reward_mean": 0.03010515558795171, "train/extr_reward_min": -0.6955501302596061, "train/extr_reward_std": 0.17699723398905196, "train/image_loss_mean": 1.5709898850884856, "train/image_loss_std": 4.805067980344394, "train/model_loss_mean": 3.3984557791239656, "train/model_loss_std": 8.592713714195286, "train/model_opt_grad_norm": 31.591606575223157, "train/model_opt_grad_steps": 115741.81105990784, "train/model_opt_loss": 6621.414472026209, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1952.7649769585253, "train/policy_entropy_mag": 2.516969452255882, "train/policy_entropy_max": 2.516969452255882, "train/policy_entropy_mean": 0.5730824638072247, "train/policy_entropy_min": 0.07937501384640619, "train/policy_entropy_std": 0.6215785349019661, "train/policy_logprob_mag": 7.438383985774308, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5738330107130762, "train/policy_logprob_min": -7.438383985774308, "train/policy_logprob_std": 1.1241341417286252, "train/policy_randomness_mag": 0.8883797641723387, "train/policy_randomness_max": 0.8883797641723387, "train/policy_randomness_mean": 0.2022729616972708, "train/policy_randomness_min": 0.028015896729472595, "train/policy_randomness_std": 0.21938994829006458, "train/post_ent_mag": 44.74601747363394, "train/post_ent_max": 44.74601747363394, "train/post_ent_mean": 25.55123785344137, "train/post_ent_min": 13.34128511666153, "train/post_ent_std": 4.41546372114788, "train/prior_ent_mag": 77.08095276300809, "train/prior_ent_max": 77.08095276300809, "train/prior_ent_mean": 28.463348415040752, "train/prior_ent_min": 14.669579040070284, "train/prior_ent_std": 8.904964983188611, "train/rep_loss_mean": 2.9866324064369025, "train/rep_loss_std": 7.818742182946974, "train/reward_avg": 0.019860220959298486, "train/reward_loss_mean": 0.03538034386795512, "train/reward_loss_std": 0.15909203928187146, "train/reward_max_data": 1.0138248880887362, "train/reward_max_pred": 1.0150809507765528, "train/reward_neg_acc": 0.9967217566230879, "train/reward_neg_loss": 0.018113187428409328, "train/reward_pos_acc": 0.9926760699342473, "train/reward_pos_loss": 0.7141925956247039, "train/reward_pred": 0.019741949556644336, "train/reward_rate": 0.02485059043778802, "train_stats/sum_log_reward": 3.946153787466196, "train_stats/max_log_achievement_collect_coal": 0.07692307692307693, "train_stats/max_log_achievement_collect_drink": 2.923076923076923, "train_stats/max_log_achievement_collect_sapling": 2.1538461538461537, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 2.3076923076923075, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.07692307692307693, "train_stats/max_log_achievement_make_wood_sword": 0.07692307692307693, "train_stats/max_log_achievement_place_plant": 1.7692307692307692, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 0.8461538461538461, "train_stats/max_log_achievement_wake_up": 2.230769230769231, "train_stats/mean_log_entropy": 0.5581939885249505, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 8.65019217144436e-07, "report/cont_loss_std": 3.180763997079339e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 2.1535759060498094e-06, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 8.599660077379667e-07, "report/cont_pred": 0.9960929155349731, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 3.345790386199951, "report/dyn_loss_std": 8.025521278381348, "report/image_loss_mean": 2.0639493465423584, "report/image_loss_std": 6.1498332023620605, "report/model_loss_mean": 4.106657028198242, "report/model_loss_std": 10.052384376525879, "report/post_ent_mag": 42.69852066040039, "report/post_ent_max": 42.69852066040039, "report/post_ent_mean": 25.97846031188965, "report/post_ent_min": 14.064321517944336, "report/post_ent_std": 4.142991542816162, "report/prior_ent_mag": 77.3628921508789, "report/prior_ent_max": 77.3628921508789, "report/prior_ent_mean": 29.408756256103516, "report/prior_ent_min": 14.951674461364746, "report/prior_ent_std": 8.681615829467773, "report/rep_loss_mean": 3.345790386199951, "report/rep_loss_std": 8.025521278381348, "report/reward_avg": 0.02324218675494194, "report/reward_loss_mean": 0.03523264080286026, "report/reward_loss_std": 0.16101759672164917, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0000007152557373, "report/reward_neg_acc": 0.99698805809021, "report/reward_neg_loss": 0.015765773132443428, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7276970744132996, "report/reward_pred": 0.022614076733589172, "report/reward_rate": 0.02734375, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 9.785927659322624e-07, "eval/cont_loss_std": 4.455895577848423e-06, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 4.6718640078324825e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 8.441949717052921e-07, "eval/cont_pred": 0.9970696568489075, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 27.284683227539062, "eval/dyn_loss_std": 14.196199417114258, "eval/image_loss_mean": 46.54425811767578, "eval/image_loss_std": 44.72536849975586, "eval/model_loss_mean": 63.046504974365234, "eval/model_loss_std": 50.89861297607422, "eval/post_ent_mag": 42.101680755615234, "eval/post_ent_max": 42.101680755615234, "eval/post_ent_mean": 29.182695388793945, "eval/post_ent_min": 18.8964900970459, "eval/post_ent_std": 3.8634133338928223, "eval/prior_ent_mag": 77.3628921508789, "eval/prior_ent_max": 77.3628921508789, "eval/prior_ent_mean": 40.212257385253906, "eval/prior_ent_min": 18.74679183959961, "eval/prior_ent_std": 8.546893119812012, "eval/rep_loss_mean": 27.284683227539062, "eval/rep_loss_std": 14.196199417114258, "eval/reward_avg": 0.01748047024011612, "eval/reward_loss_mean": 0.13143929839134216, "eval/reward_loss_std": 0.8075308799743652, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9994473457336426, "eval/reward_neg_acc": 0.9960079789161682, "eval/reward_neg_loss": 0.09704045951366425, "eval/reward_pos_acc": 0.8181818723678589, "eval/reward_pos_loss": 1.6981500387191772, "eval/reward_pred": 0.015096815302968025, "eval/reward_rate": 0.021484375, "replay/size": 117981.0, "replay/inserts": 2175.0, "replay/samples": 34800.0, "replay/insert_wait_avg": 2.588294018274066e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.3204780447072e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 22632.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 8.940696716308594e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2001204490662, "timer/env.step_count": 272.0, "timer/env.step_total": 28.297951221466064, "timer/env.step_frac": 0.02829228935581507, "timer/env.step_avg": 0.104036585373037, "timer/env.step_min": 0.023508071899414062, "timer/env.step_max": 2.1081326007843018, "timer/replay._sample_count": 34800.0, "timer/replay._sample_total": 16.99592351913452, "timer/replay._sample_frac": 0.016992522967807438, "timer/replay._sample_avg": 0.0004883886068716817, "timer/replay._sample_min": 0.0003638267517089844, "timer/replay._sample_max": 0.016707420349121094, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 272.0, "timer/agent.policy_total": 4.331197261810303, "timer/agent.policy_frac": 0.004330330674091199, "timer/agent.policy_avg": 0.015923519344890818, "timer/agent.policy_min": 0.009787797927856445, "timer/agent.policy_max": 0.01813650131225586, "timer/dataset_train_count": 2175.0, "timer/dataset_train_total": 0.3788149356842041, "timer/dataset_train_frac": 0.0003787391422369807, "timer/dataset_train_avg": 0.00017416778652147314, "timer/dataset_train_min": 8.606910705566406e-05, "timer/dataset_train_max": 0.0007507801055908203, "timer/agent.train_count": 2175.0, "timer/agent.train_total": 965.4520556926727, "timer/agent.train_frac": 0.965258887650611, "timer/agent.train_avg": 0.4438860026173208, "timer/agent.train_min": 0.43471288681030273, "timer/agent.train_max": 0.5712368488311768, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47681188583374023, "timer/agent.report_frac": 0.00047671648511666144, "timer/agent.report_avg": 0.23840594291687012, "timer/agent.report_min": 0.23120379447937012, "timer/agent.report_max": 0.24560809135437012, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.86102294921875e-05, "timer/dataset_eval_frac": 2.8604505145772413e-08, "timer/dataset_eval_avg": 2.86102294921875e-05, "timer/dataset_eval_min": 2.86102294921875e-05, "timer/dataset_eval_max": 2.86102294921875e-05, "fps": 2.1745367011998806}
{"step": 118744, "time": 54435.19911813736, "episode/length": 104.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9619047619047619, "episode/intrinsic_return": 0.0}
{"step": 119008, "time": 54555.339616537094, "episode/length": 177.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 119216, "time": 54650.41340517998, "episode/length": 171.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 119400, "time": 54734.66655564308, "episode/length": 185.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 119448, "time": 54757.79981303215, "episode/length": 54.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9090909090909091, "episode/intrinsic_return": 0.0}
{"step": 119552, "time": 54805.85666179657, "episode/length": 159.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 119648, "time": 54850.57180786133, "episode/length": 179.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 119664, "time": 54859.28156161308, "episode/length": 430.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9791183294663574, "episode/intrinsic_return": 0.0}
{"step": 120008, "time": 55015.25281953812, "episode/length": 263.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 120016, "time": 55037.8550927639, "eval_episode/length": 131.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9924242424242424}
{"step": 120016, "time": 55039.8038957119, "eval_episode/length": 141.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9929577464788732}
{"step": 120016, "time": 55041.699942827225, "eval_episode/length": 150.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9668874172185431}
{"step": 120016, "time": 55043.2816824913, "eval_episode/length": 152.0, "eval_episode/score": 4.0999999940395355, "eval_episode/reward_rate": 0.9934640522875817}
{"step": 120016, "time": 55043.28814649582, "eval_episode/length": 152.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9934640522875817}
{"step": 120016, "time": 55049.84259033203, "eval_episode/length": 199.0, "eval_episode/score": 4.099999971687794, "eval_episode/reward_rate": 0.995}
{"step": 120016, "time": 55051.992181777954, "eval_episode/length": 216.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9769585253456221}
{"step": 120016, "time": 55054.548684835434, "eval_episode/length": 241.0, "eval_episode/score": 4.099999979138374, "eval_episode/reward_rate": 0.9958677685950413}
{"step": 120056, "time": 55072.35998606682, "episode/length": 163.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9512195121951219, "episode/intrinsic_return": 0.0}
{"step": 120224, "time": 55149.157237529755, "episode/length": 125.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9523809523809523, "episode/intrinsic_return": 0.0}
{"step": 120598, "time": 55319.15670132637, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.340020491613596, "train/action_min": 0.0, "train/action_std": 3.948905147082433, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04761475013012852, "train/actor_opt_grad_steps": 117980.0, "train/actor_opt_loss": -15.899278822527112, "train/adv_mag": 0.8556828354772233, "train/adv_max": 0.7835869866807313, "train/adv_mean": 0.0024510690604919463, "train/adv_min": -0.6386934669944347, "train/adv_std": 0.058143521813561, "train/cont_avg": 0.9944090639810427, "train/cont_loss_mean": 3.858778286230593e-05, "train/cont_loss_std": 0.0011762198213862887, "train/cont_neg_acc": 0.9988151658767772, "train/cont_neg_loss": 0.0022453505072488437, "train/cont_pos_acc": 0.9999860155073952, "train/cont_pos_loss": 2.844208227959365e-05, "train/cont_pred": 0.9944018280901615, "train/cont_rate": 0.9944090639810427, "train/dyn_loss_mean": 3.0157891822652227, "train/dyn_loss_std": 7.8633616072306705, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.295660896041382, "train/extr_critic_critic_opt_grad_steps": 117980.0, "train/extr_critic_critic_opt_loss": 15163.4930529843, "train/extr_critic_mag": 14.279135062231271, "train/extr_critic_max": 14.279135062231271, "train/extr_critic_mean": 2.513414250730903, "train/extr_critic_min": -0.6379056942971397, "train/extr_critic_std": 2.4271715003732255, "train/extr_return_normed_mag": 1.9598022823650125, "train/extr_return_normed_max": 1.9598022823650125, "train/extr_return_normed_mean": 0.3627892272167296, "train/extr_return_normed_min": -0.1192753253531117, "train/extr_return_normed_std": 0.33171760816992174, "train/extr_return_rate": 0.8374102576084047, "train/extr_return_raw_mag": 14.480393775831466, "train/extr_return_raw_max": 14.480393775831466, "train/extr_return_raw_mean": 2.5317746242640706, "train/extr_return_raw_min": -1.0768881841293443, "train/extr_return_raw_std": 2.4822615096919343, "train/extr_reward_mag": 1.0297112668295043, "train/extr_reward_max": 1.0297112668295043, "train/extr_reward_mean": 0.03015829187098414, "train/extr_reward_min": -0.6824080299992132, "train/extr_reward_std": 0.17569994629841845, "train/image_loss_mean": 1.605200903958054, "train/image_loss_std": 4.866992969648533, "train/model_loss_mean": 3.4513710618584077, "train/model_loss_std": 8.67704487072913, "train/model_opt_grad_norm": 30.242154379026584, "train/model_opt_grad_steps": 117880.14218009479, "train/model_opt_loss": 7169.122225359153, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2097.1563981042655, "train/policy_entropy_mag": 2.5458359096852523, "train/policy_entropy_max": 2.5458359096852523, "train/policy_entropy_mean": 0.5508816952671485, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6166836626439298, "train/policy_logprob_mag": 7.438384004113798, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5503779221767497, "train/policy_logprob_min": -7.438384004113798, "train/policy_logprob_std": 1.1122386930113155, "train/policy_randomness_mag": 0.8985683556416588, "train/policy_randomness_max": 0.8985683556416588, "train/policy_randomness_mean": 0.19443706433637448, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.21766227208325084, "train/post_ent_mag": 45.16689512062977, "train/post_ent_max": 45.16689512062977, "train/post_ent_mean": 25.713509166410184, "train/post_ent_min": 13.37208414303748, "train/post_ent_std": 4.515565753548066, "train/prior_ent_mag": 77.11839041325719, "train/prior_ent_max": 77.11839041325719, "train/prior_ent_mean": 28.643023061526332, "train/prior_ent_min": 14.781493101074798, "train/prior_ent_std": 8.977863686909608, "train/rep_loss_mean": 3.0157891822652227, "train/rep_loss_std": 7.8633616072306705, "train/reward_avg": 0.020064887961469838, "train/reward_loss_mean": 0.036658056949869997, "train/reward_loss_std": 0.17094451302035724, "train/reward_max_data": 1.0156398141553618, "train/reward_max_pred": 1.0160938331866152, "train/reward_neg_acc": 0.9963348293191449, "train/reward_neg_loss": 0.01898213529460556, "train/reward_pos_acc": 0.9898866234232464, "train/reward_pos_loss": 0.7213133692176421, "train/reward_pred": 0.01995125402568429, "train/reward_rate": 0.02506664691943128, "train_stats/sum_log_reward": 3.1909090239893305, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 1.9090909090909092, "train_stats/max_log_achievement_collect_sapling": 1.5454545454545454, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 2.6363636363636362, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.3636363636363635, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 1.0909090909090908, "train_stats/max_log_achievement_wake_up": 2.6363636363636362, "train_stats/mean_log_entropy": 0.529590292410417, "eval_stats/sum_log_reward": 4.474999904632568, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 4.625, "eval_stats/max_log_achievement_collect_sapling": 1.625, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 3.25, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 1.625, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 1.25, "eval_stats/max_log_achievement_wake_up": 1.75, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.0001313741086050868, "report/cont_loss_std": 0.004196094814687967, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.02686937525868416, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.7683682074220997e-07, "report/cont_pred": 0.9952398538589478, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 3.5936543941497803, "report/dyn_loss_std": 8.607266426086426, "report/image_loss_mean": 2.218543291091919, "report/image_loss_std": 5.229183197021484, "report/model_loss_mean": 4.413778781890869, "report/model_loss_std": 9.45225715637207, "report/post_ent_mag": 47.3103141784668, "report/post_ent_max": 47.3103141784668, "report/post_ent_mean": 25.04693603515625, "report/post_ent_min": 12.103560447692871, "report/post_ent_std": 5.156765937805176, "report/prior_ent_mag": 77.51589965820312, "report/prior_ent_max": 77.51589965820312, "report/prior_ent_mean": 28.224000930786133, "report/prior_ent_min": 13.75056266784668, "report/prior_ent_std": 9.871053695678711, "report/rep_loss_mean": 3.5936543941497803, "report/rep_loss_std": 8.607266426086426, "report/reward_avg": 0.015234374441206455, "report/reward_loss_mean": 0.038911543786525726, "report/reward_loss_std": 0.17356175184249878, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0018031597137451, "report/reward_neg_acc": 0.9900299310684204, "report/reward_neg_loss": 0.023241281509399414, "report/reward_pos_acc": 0.9523809552192688, "report/reward_pos_loss": 0.7873530983924866, "report/reward_pred": 0.01446254551410675, "report/reward_rate": 0.0205078125, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.0007600582321174443, "eval/cont_loss_std": 0.024132564663887024, "eval/cont_neg_acc": 0.75, "eval/cont_neg_loss": 0.19426442682743073, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 1.2176125210316968e-06, "eval/cont_pred": 0.9966225028038025, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 23.758255004882812, "eval/dyn_loss_std": 13.495378494262695, "eval/image_loss_mean": 37.858848571777344, "eval/image_loss_std": 42.26872253417969, "eval/model_loss_mean": 52.353858947753906, "eval/model_loss_std": 47.7353515625, "eval/post_ent_mag": 47.3103141784668, "eval/post_ent_max": 47.3103141784668, "eval/post_ent_mean": 28.891284942626953, "eval/post_ent_min": 16.25048828125, "eval/post_ent_std": 3.166027069091797, "eval/prior_ent_mag": 77.51589965820312, "eval/prior_ent_max": 77.51589965820312, "eval/prior_ent_mean": 40.101837158203125, "eval/prior_ent_min": 17.013599395751953, "eval/prior_ent_std": 8.279801368713379, "eval/rep_loss_mean": 23.758255004882812, "eval/rep_loss_std": 13.495378494262695, "eval/reward_avg": 0.02578124962747097, "eval/reward_loss_mean": 0.2392956018447876, "eval/reward_loss_std": 1.2984833717346191, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0012168884277344, "eval/reward_neg_acc": 0.9939637184143066, "eval/reward_neg_loss": 0.13873793184757233, "eval/reward_pos_acc": 0.6000000238418579, "eval/reward_pos_loss": 3.5711066722869873, "eval/reward_pred": 0.01696588844060898, "eval/reward_rate": 0.029296875, "replay/size": 120094.0, "replay/inserts": 2113.0, "replay/samples": 33808.0, "replay/insert_wait_avg": 2.583789419236479e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.433796515692708e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 24568.0, "eval_replay/inserts": 1936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0844597146530782e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.08970832824707e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3097796440125, "timer/env.step_count": 264.0, "timer/env.step_total": 23.197205543518066, "timer/env.step_frac": 0.02319002174683669, "timer/env.step_avg": 0.08786820281635631, "timer/env.step_min": 0.023151159286499023, "timer/env.step_max": 1.6245462894439697, "timer/replay._sample_count": 33808.0, "timer/replay._sample_total": 16.417351961135864, "timer/replay._sample_frac": 0.01641226777466719, "timer/replay._sample_avg": 0.0004856055360014158, "timer/replay._sample_min": 0.00036597251892089844, "timer/replay._sample_max": 0.018416881561279297, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 506.0, "timer/agent.policy_total": 9.056469202041626, "timer/agent.policy_frac": 0.009053664561056893, "timer/agent.policy_avg": 0.017898160478343136, "timer/agent.policy_min": 0.00939631462097168, "timer/agent.policy_max": 0.11500859260559082, "timer/dataset_train_count": 2113.0, "timer/dataset_train_total": 0.3639335632324219, "timer/dataset_train_frac": 0.0003638208589362563, "timer/dataset_train_avg": 0.00017223547715684897, "timer/dataset_train_min": 8.368492126464844e-05, "timer/dataset_train_max": 0.0007855892181396484, "timer/agent.train_count": 2113.0, "timer/agent.train_total": 936.6088197231293, "timer/agent.train_frac": 0.936318767228735, "timer/agent.train_avg": 0.4432602081037053, "timer/agent.train_min": 0.43213558197021484, "timer/agent.train_max": 0.5602974891662598, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47057437896728516, "timer/agent.report_frac": 0.0004704286497476331, "timer/agent.report_avg": 0.23528718948364258, "timer/agent.report_min": 0.22886109352111816, "timer/agent.report_max": 0.241713285446167, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.170967102050781e-05, "timer/dataset_eval_frac": 3.1699851051933696e-08, "timer/dataset_eval_avg": 3.170967102050781e-05, "timer/dataset_eval_min": 3.170967102050781e-05, "timer/dataset_eval_max": 3.170967102050781e-05, "fps": 2.112318602516081}
{"step": 120992, "time": 55498.29229950905, "episode/length": 198.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.964824120603015, "episode/intrinsic_return": 0.0}
{"step": 121056, "time": 55528.933790683746, "episode/length": 173.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 121096, "time": 55549.161382198334, "episode/length": 180.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9668508287292817, "episode/intrinsic_return": 0.0}
{"step": 121104, "time": 55554.342381477356, "episode/length": 206.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 121368, "time": 55675.69356775284, "episode/length": 163.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 121408, "time": 55695.25913691521, "episode/length": 147.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 121576, "time": 55773.094633579254, "episode/length": 252.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9802371541501976, "episode/intrinsic_return": 0.0}
{"step": 121712, "time": 55836.18533182144, "episode/length": 212.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 122168, "time": 56045.062093257904, "episode/length": 94.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9473684210526315, "episode/intrinsic_return": 0.0}
{"step": 122304, "time": 56108.57676935196, "episode/length": 150.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 122368, "time": 56139.179171562195, "episode/length": 163.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 122744, "time": 56311.50056862831, "episode/length": 128.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9922480620155039, "episode/intrinsic_return": 0.0}
{"step": 122752, "time": 56316.60802054405, "episode/length": 219.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 122754, "time": 56319.55727529526, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.564507378472222, "train/action_min": 0.0, "train/action_std": 3.985616538259718, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04930756216937745, "train/actor_opt_grad_steps": 120115.0, "train/actor_opt_loss": -17.020423231370472, "train/adv_mag": 0.9233730273942152, "train/adv_max": 0.8555756845959911, "train/adv_mean": 0.002468465658879453, "train/adv_min": -0.7099402637945281, "train/adv_std": 0.06066028197744378, "train/cont_avg": 0.9943305121527778, "train/cont_loss_mean": 1.3105894383146642e-05, "train/cont_loss_std": 0.0004063373831846871, "train/cont_neg_acc": 1.0, "train/cont_neg_loss": 0.0002546716059383513, "train/cont_pos_acc": 0.9999954322421992, "train/cont_pos_loss": 1.1819951835268372e-05, "train/cont_pred": 0.9943228813785093, "train/cont_rate": 0.9943305121527778, "train/dyn_loss_mean": 3.002273459125448, "train/dyn_loss_std": 7.870177578043054, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.2844243377999023, "train/extr_critic_critic_opt_grad_steps": 120115.0, "train/extr_critic_critic_opt_loss": 15338.164035373264, "train/extr_critic_mag": 14.577612872476932, "train/extr_critic_max": 14.577612872476932, "train/extr_critic_mean": 2.518816457854377, "train/extr_critic_min": -0.6698695261169363, "train/extr_critic_std": 2.5341618397721537, "train/extr_return_normed_mag": 1.9589078095224168, "train/extr_return_normed_max": 1.9589078095224168, "train/extr_return_normed_mean": 0.35484696303804714, "train/extr_return_normed_min": -0.1343855897516564, "train/extr_return_normed_std": 0.33837388586942796, "train/extr_return_rate": 0.8381447554738434, "train/extr_return_raw_mag": 14.84588744463744, "train/extr_return_raw_max": 14.84588744463744, "train/extr_return_raw_mean": 2.5377657214800515, "train/extr_return_raw_min": -1.2131401159697108, "train/extr_return_raw_std": 2.5963617077580206, "train/extr_reward_mag": 1.0325125671095319, "train/extr_reward_max": 1.0325125671095319, "train/extr_reward_mean": 0.03070849200486447, "train/extr_reward_min": -0.6943215970639829, "train/extr_reward_std": 0.17810659027761883, "train/image_loss_mean": 1.5774028731717005, "train/image_loss_std": 4.895648259807516, "train/model_loss_mean": 3.4156175509647086, "train/model_loss_std": 8.696845244478297, "train/model_opt_grad_norm": 29.95437828258232, "train/model_opt_grad_steps": 120013.57870370371, "train/model_opt_loss": 8049.3583249692565, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2355.324074074074, "train/policy_entropy_mag": 2.5406148897276983, "train/policy_entropy_max": 2.5406148897276983, "train/policy_entropy_mean": 0.5595097737731757, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6289915562503867, "train/policy_logprob_mag": 7.438384042845832, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.560096663457376, "train/policy_logprob_min": -7.438384042845832, "train/policy_logprob_std": 1.1178328499749854, "train/policy_randomness_mag": 0.8967255627115568, "train/policy_randomness_max": 0.8967255627115568, "train/policy_randomness_mean": 0.19748239950449378, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.22200641836281176, "train/post_ent_mag": 45.11618040226124, "train/post_ent_max": 45.11618040226124, "train/post_ent_mean": 25.971682098176743, "train/post_ent_min": 13.539979647707057, "train/post_ent_std": 4.5042431829152285, "train/prior_ent_mag": 77.2503735224406, "train/prior_ent_max": 77.2503735224406, "train/prior_ent_mean": 28.88451139132182, "train/prior_ent_min": 14.859652987232915, "train/prior_ent_std": 8.941145729135584, "train/rep_loss_mean": 3.002273459125448, "train/rep_loss_std": 7.870177578043054, "train/reward_avg": 0.02061270233847339, "train/reward_loss_mean": 0.036837491362045206, "train/reward_loss_std": 0.16761635247342013, "train/reward_max_data": 1.013425929126916, "train/reward_max_pred": 1.014187197994303, "train/reward_neg_acc": 0.9962596570452055, "train/reward_neg_loss": 0.01880827414613493, "train/reward_pos_acc": 0.9916382467857113, "train/reward_pos_loss": 0.7214706438007178, "train/reward_pred": 0.020431238877656008, "train/reward_rate": 0.025661892361111112, "train_stats/sum_log_reward": 3.715384556696965, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 2.5384615384615383, "train_stats/max_log_achievement_collect_sapling": 2.076923076923077, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 2.769230769230769, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.07692307692307693, "train_stats/max_log_achievement_make_wood_pickaxe": 0.07692307692307693, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 2.0, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 1.1538461538461537, "train_stats/max_log_achievement_wake_up": 2.076923076923077, "train_stats/mean_log_entropy": 0.5178546355320857, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 4.770653276864323e-07, "report/cont_loss_std": 1.3993656466482207e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 7.931343861855567e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.2410877658908248e-08, "report/cont_pred": 0.9941411018371582, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 4.124375820159912, "report/dyn_loss_std": 8.845902442932129, "report/image_loss_mean": 2.7087812423706055, "report/image_loss_std": 7.282110691070557, "report/model_loss_mean": 5.221077919006348, "report/model_loss_std": 11.504424095153809, "report/post_ent_mag": 45.70622253417969, "report/post_ent_max": 45.70622253417969, "report/post_ent_mean": 26.05510139465332, "report/post_ent_min": 13.084903717041016, "report/post_ent_std": 4.238100528717041, "report/prior_ent_mag": 77.26785278320312, "report/prior_ent_max": 77.26785278320312, "report/prior_ent_mean": 29.782283782958984, "report/prior_ent_min": 15.515256881713867, "report/prior_ent_std": 9.42099380493164, "report/rep_loss_mean": 4.124375820159912, "report/rep_loss_std": 8.845902442932129, "report/reward_avg": 0.02158202975988388, "report/reward_loss_mean": 0.037670597434043884, "report/reward_loss_std": 0.1594969481229782, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0005428791046143, "report/reward_neg_acc": 0.99698805809021, "report/reward_neg_loss": 0.01773228496313095, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7469049692153931, "report/reward_pred": 0.02030712179839611, "report/reward_rate": 0.02734375, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.0027538184076547623, "eval/cont_loss_std": 0.08794569969177246, "eval/cont_neg_acc": 0.800000011920929, "eval/cont_neg_loss": 0.5638624429702759, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 5.870204518032551e-07, "eval/cont_pred": 0.9960383176803589, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 23.21485137939453, "eval/dyn_loss_std": 13.558835983276367, "eval/image_loss_mean": 33.523681640625, "eval/image_loss_std": 42.90312576293945, "eval/model_loss_mean": 47.62705612182617, "eval/model_loss_std": 48.59856033325195, "eval/post_ent_mag": 45.70622253417969, "eval/post_ent_max": 45.70622253417969, "eval/post_ent_mean": 29.46295928955078, "eval/post_ent_min": 18.977819442749023, "eval/post_ent_std": 3.3720362186431885, "eval/prior_ent_mag": 77.26785278320312, "eval/prior_ent_max": 77.26785278320312, "eval/prior_ent_mean": 39.338802337646484, "eval/prior_ent_min": 19.931594848632812, "eval/prior_ent_std": 7.991589546203613, "eval/rep_loss_mean": 23.21485137939453, "eval/rep_loss_std": 13.558835983276367, "eval/reward_avg": 0.02841796912252903, "eval/reward_loss_mean": 0.1717110127210617, "eval/reward_loss_std": 0.9703086614608765, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0004498958587646, "eval/reward_neg_acc": 0.9909090399742126, "eval/reward_neg_loss": 0.12897735834121704, "eval/reward_pos_acc": 0.8529411554336548, "eval/reward_pos_loss": 1.416014313697815, "eval/reward_pred": 0.028133148327469826, "eval/reward_rate": 0.033203125, "replay/size": 122250.0, "replay/inserts": 2156.0, "replay/samples": 34496.0, "replay/insert_wait_avg": 2.696253151973236e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.739157820013326e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 24568.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 8.046627044677734e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3919997215271, "timer/env.step_count": 270.0, "timer/env.step_total": 27.48625874519348, "timer/env.step_frac": 0.02747548836140699, "timer/env.step_avg": 0.10180095831553142, "timer/env.step_min": 0.023456573486328125, "timer/env.step_max": 2.077305793762207, "timer/replay._sample_count": 34496.0, "timer/replay._sample_total": 17.670111656188965, "timer/replay._sample_frac": 0.017663187691532602, "timer/replay._sample_avg": 0.0005122365391984278, "timer/replay._sample_min": 0.0003788471221923828, "timer/replay._sample_max": 0.02623605728149414, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 270.0, "timer/agent.policy_total": 4.4081871509552, "timer/agent.policy_frac": 0.004406459819932866, "timer/agent.policy_avg": 0.01632661907761185, "timer/agent.policy_min": 0.010677337646484375, "timer/agent.policy_max": 0.04275393486022949, "timer/dataset_train_count": 2156.0, "timer/dataset_train_total": 0.39247822761535645, "timer/dataset_train_frac": 0.0003923244365454823, "timer/dataset_train_avg": 0.00018203999425573118, "timer/dataset_train_min": 9.655952453613281e-05, "timer/dataset_train_max": 0.0006299018859863281, "timer/agent.train_count": 2156.0, "timer/agent.train_total": 966.1249287128448, "timer/agent.train_frac": 0.9657463564100663, "timer/agent.train_avg": 0.448109892723954, "timer/agent.train_min": 0.4381411075592041, "timer/agent.train_max": 0.5712854862213135, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47982311248779297, "timer/agent.report_frac": 0.0004796350956638581, "timer/agent.report_avg": 0.23991155624389648, "timer/agent.report_min": 0.23131513595581055, "timer/agent.report_max": 0.24850797653198242, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.24249267578125e-05, "timer/dataset_eval_frac": 3.241222117613738e-08, "timer/dataset_eval_avg": 3.24249267578125e-05, "timer/dataset_eval_min": 3.24249267578125e-05, "timer/dataset_eval_max": 3.24249267578125e-05, "fps": 2.1551271756108257}
{"step": 122768, "time": 56326.08592104912, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 122920, "time": 56397.66454744339, "episode/length": 226.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 123320, "time": 56580.81320023537, "episode/length": 217.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 123384, "time": 56611.53122830391, "episode/length": 151.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 123416, "time": 56627.5318672657, "episode/length": 138.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.0}
{"step": 123720, "time": 56767.349304914474, "episode/length": 168.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 123800, "time": 56805.106070518494, "episode/length": 131.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9924242424242424, "episode/intrinsic_return": 0.0}
{"step": 124160, "time": 56970.11449241638, "episode/length": 154.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 124344, "time": 57054.84025287628, "episode/length": 196.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 124664, "time": 57201.52013850212, "episode/length": 167.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 124704, "time": 57221.193276166916, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 124816, "time": 57273.452095508575, "episode/length": 257.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9806201550387597, "episode/intrinsic_return": 0.0}
{"step": 124896, "time": 57311.12364244461, "episode/length": 188.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 124911, "time": 57319.93468213081, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.462410255714699, "train/action_min": 0.0, "train/action_std": 4.020196702745226, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.047836941080512826, "train/actor_opt_grad_steps": 122275.0, "train/actor_opt_loss": -16.711028219925034, "train/adv_mag": 0.8736373537944423, "train/adv_max": 0.7935286408497227, "train/adv_mean": 0.0022979928062846332, "train/adv_min": -0.661526020616293, "train/adv_std": 0.05913582221708364, "train/cont_avg": 0.9941903573495371, "train/cont_loss_mean": 3.2188930522180784e-05, "train/cont_loss_std": 0.000973235804785983, "train/cont_neg_acc": 0.9980324076281654, "train/cont_neg_loss": 0.003244561619105205, "train/cont_pos_acc": 0.9999908826969288, "train/cont_pos_loss": 1.0642042982248426e-05, "train/cont_pred": 0.9941939385952773, "train/cont_rate": 0.9941903573495371, "train/dyn_loss_mean": 3.0270946103113667, "train/dyn_loss_std": 7.850775372098993, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.323074143241953, "train/extr_critic_critic_opt_grad_steps": 122275.0, "train/extr_critic_critic_opt_loss": 15442.7588885272, "train/extr_critic_mag": 13.63535992304484, "train/extr_critic_max": 13.63535992304484, "train/extr_critic_mean": 2.416729399451503, "train/extr_critic_min": -0.6581302875721896, "train/extr_critic_std": 2.517680710112607, "train/extr_return_normed_mag": 1.873939609086072, "train/extr_return_normed_max": 1.873939609086072, "train/extr_return_normed_mean": 0.34954275108046, "train/extr_return_normed_min": -0.11842758522403461, "train/extr_return_normed_std": 0.3391196808467309, "train/extr_return_rate": 0.7381299816899829, "train/extr_return_raw_mag": 14.009078039063347, "train/extr_return_raw_max": 14.009078039063347, "train/extr_return_raw_mean": 2.4341438153275736, "train/extr_return_raw_min": -1.11285434635701, "train/extr_return_raw_std": 2.5716452493711754, "train/extr_reward_mag": 1.033792996848071, "train/extr_reward_max": 1.033792996848071, "train/extr_reward_mean": 0.030669691351552803, "train/extr_reward_min": -0.6819881007627204, "train/extr_reward_std": 0.17707811489149375, "train/image_loss_mean": 1.600679797430833, "train/image_loss_std": 4.899490731733817, "train/model_loss_mean": 3.4532691052666418, "train/model_loss_std": 8.678960184256235, "train/model_opt_grad_norm": 31.182455376342492, "train/model_opt_grad_steps": 122171.25925925926, "train/model_opt_loss": 7366.864496301721, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2152.777777777778, "train/policy_entropy_mag": 2.560189461266553, "train/policy_entropy_max": 2.560189461266553, "train/policy_entropy_mean": 0.5722864419221878, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.645574553973145, "train/policy_logprob_mag": 7.438384027392776, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5725180299745666, "train/policy_logprob_min": -7.438384027392776, "train/policy_logprob_std": 1.1264251669247944, "train/policy_randomness_mag": 0.9036345291468832, "train/policy_randomness_max": 0.9036345291468832, "train/policy_randomness_mean": 0.20199200048766755, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.22785948830898162, "train/post_ent_mag": 45.58070336447822, "train/post_ent_max": 45.58070336447822, "train/post_ent_mean": 26.21178811567801, "train/post_ent_min": 13.422704387594152, "train/post_ent_std": 4.526842542268612, "train/prior_ent_mag": 77.16980863500524, "train/prior_ent_max": 77.16980863500524, "train/prior_ent_mean": 29.163091244520963, "train/prior_ent_min": 14.88108785947164, "train/prior_ent_std": 8.944188959068722, "train/rep_loss_mean": 3.0270946103113667, "train/rep_loss_std": 7.850775372098993, "train/reward_avg": 0.02039161950880144, "train/reward_loss_mean": 0.03630036735665743, "train/reward_loss_std": 0.1637725315436169, "train/reward_max_data": 1.0125000029802322, "train/reward_max_pred": 1.0136644580849894, "train/reward_neg_acc": 0.9965615920998432, "train/reward_neg_loss": 0.018478386647378404, "train/reward_pos_acc": 0.9914348721504211, "train/reward_pos_loss": 0.7154208211987106, "train/reward_pred": 0.020252983967549407, "train/reward_rate": 0.025598596643518517, "train_stats/sum_log_reward": 4.638461443094107, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 3.6153846153846154, "train_stats/max_log_achievement_collect_sapling": 1.6923076923076923, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 3.0, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.07692307692307693, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.6923076923076923, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 1.2307692307692308, "train_stats/max_log_achievement_wake_up": 2.0, "train_stats/mean_log_entropy": 0.5846393979512728, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 1.74589013113291e-06, "report/cont_loss_std": 2.712772402446717e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 9.813243195821997e-07, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.7503965636933572e-06, "report/cont_pred": 0.9941389560699463, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 3.0264828205108643, "report/dyn_loss_std": 7.847261905670166, "report/image_loss_mean": 1.346638798713684, "report/image_loss_std": 3.952467918395996, "report/model_loss_mean": 3.187992811203003, "report/model_loss_std": 7.984498023986816, "report/post_ent_mag": 47.005218505859375, "report/post_ent_max": 47.005218505859375, "report/post_ent_mean": 27.10669708251953, "report/post_ent_min": 14.09270191192627, "report/post_ent_std": 4.709348678588867, "report/prior_ent_mag": 77.15481567382812, "report/prior_ent_max": 77.15481567382812, "report/prior_ent_mean": 30.214595794677734, "report/prior_ent_min": 14.8739652633667, "report/prior_ent_std": 8.918113708496094, "report/rep_loss_mean": 3.0264828205108643, "report/rep_loss_std": 7.847261905670166, "report/reward_avg": 0.0068359375, "report/reward_loss_mean": 0.025462688878178596, "report/reward_loss_std": 0.12481341511011124, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0018327236175537, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.016477767378091812, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6736608743667603, "report/reward_pred": 0.007401211187243462, "report/reward_rate": 0.013671875, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.00031881063478067517, "eval/cont_loss_std": 0.01005052961409092, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0008120548445731401, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.00031687633600085974, "eval/cont_pred": 0.9958269000053406, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 21.082290649414062, "eval/dyn_loss_std": 12.31629753112793, "eval/image_loss_mean": 29.448009490966797, "eval/image_loss_std": 36.727760314941406, "eval/model_loss_mean": 42.35858154296875, "eval/model_loss_std": 41.783565521240234, "eval/post_ent_mag": 46.990543365478516, "eval/post_ent_max": 46.990543365478516, "eval/post_ent_mean": 29.963882446289062, "eval/post_ent_min": 17.36640739440918, "eval/post_ent_std": 3.8626809120178223, "eval/prior_ent_mag": 77.15481567382812, "eval/prior_ent_max": 77.15481567382812, "eval/prior_ent_mean": 39.68899154663086, "eval/prior_ent_min": 19.87543487548828, "eval/prior_ent_std": 8.478004455566406, "eval/rep_loss_mean": 21.082290649414062, "eval/rep_loss_std": 12.31629753112793, "eval/reward_avg": 0.02285156212747097, "eval/reward_loss_mean": 0.260879784822464, "eval/reward_loss_std": 1.4922962188720703, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0000498294830322, "eval/reward_neg_acc": 0.9929719567298889, "eval/reward_neg_loss": 0.13375787436962128, "eval/reward_pos_acc": 0.535714328289032, "eval/reward_pos_loss": 4.782788276672363, "eval/reward_pred": 0.015924837440252304, "eval/reward_rate": 0.02734375, "replay/size": 124407.0, "replay/inserts": 2157.0, "replay/samples": 34512.0, "replay/insert_wait_avg": 2.6164145507246575e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.403811537451251e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 24568.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 7.748603820800781e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3655731678009, "timer/env.step_count": 269.0, "timer/env.step_total": 26.724539041519165, "timer/env.step_frac": 0.02671477283738592, "timer/env.step_avg": 0.09934772877888165, "timer/env.step_min": 0.02373814582824707, "timer/env.step_max": 1.7393019199371338, "timer/replay._sample_count": 34512.0, "timer/replay._sample_total": 17.473276615142822, "timer/replay._sample_frac": 0.017466891188399447, "timer/replay._sample_avg": 0.0005062956830998731, "timer/replay._sample_min": 0.0003714561462402344, "timer/replay._sample_max": 0.013480186462402344, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 269.0, "timer/agent.policy_total": 4.354272365570068, "timer/agent.policy_frac": 0.004352681142136511, "timer/agent.policy_avg": 0.016186886117360848, "timer/agent.policy_min": 0.010155677795410156, "timer/agent.policy_max": 0.018291234970092773, "timer/dataset_train_count": 2157.0, "timer/dataset_train_total": 0.39868998527526855, "timer/dataset_train_frac": 0.0003985442881773306, "timer/dataset_train_avg": 0.00018483541273772302, "timer/dataset_train_min": 9.751319885253906e-05, "timer/dataset_train_max": 0.001157522201538086, "timer/agent.train_count": 2157.0, "timer/agent.train_total": 966.8530585765839, "timer/agent.train_frac": 0.9664997322078019, "timer/agent.train_avg": 0.44823971190384043, "timer/agent.train_min": 0.439394474029541, "timer/agent.train_max": 0.572420597076416, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4768393039703369, "timer/agent.report_frac": 0.00047666504801875274, "timer/agent.report_avg": 0.23841965198516846, "timer/agent.report_min": 0.23048734664916992, "timer/agent.report_max": 0.246351957321167, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0040740966796875e-05, "timer/dataset_eval_frac": 3.002976289124841e-08, "timer/dataset_eval_avg": 3.0040740966796875e-05, "timer/dataset_eval_min": 3.0040740966796875e-05, "timer/dataset_eval_max": 3.0040740966796875e-05, "fps": 2.156184519074376}
{"step": 124992, "time": 57356.69369196892, "episode/length": 40.0, "episode/score": 0.10000000149011612, "episode/reward_rate": 0.9024390243902439, "episode/intrinsic_return": 0.0}
{"step": 125088, "time": 57401.336250543594, "episode/length": 170.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 125336, "time": 57515.14487028122, "episode/length": 78.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9367088607594937, "episode/intrinsic_return": 0.0}
{"step": 125512, "time": 57596.2918241024, "episode/length": 213.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 125792, "time": 57724.14437031746, "episode/length": 203.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 125840, "time": 57747.384615659714, "episode/length": 186.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 126040, "time": 57839.01107668877, "episode/length": 152.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 126128, "time": 57880.03900384903, "episode/length": 141.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9647887323943662, "episode/intrinsic_return": 0.0}
{"step": 126248, "time": 57936.03317284584, "episode/length": 168.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 126304, "time": 57962.63619494438, "episode/length": 151.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 126416, "time": 58014.5556101799, "episode/length": 134.0, "episode/score": 2.0999999940395355, "episode/reward_rate": 0.9925925925925926, "episode/intrinsic_return": 0.0}
{"step": 126736, "time": 58160.7123105526, "episode/length": 152.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 126904, "time": 58237.918317079544, "episode/length": 60.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9180327868852459, "episode/intrinsic_return": 0.0}
{"step": 127082, "time": 58320.34958910942, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.53996086999568, "train/action_min": 0.0, "train/action_std": 4.019036111743769, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.047862768456477175, "train/actor_opt_grad_steps": 124440.0, "train/actor_opt_loss": -11.830006256150211, "train/adv_mag": 0.8609470259484058, "train/adv_max": 0.7547823270345064, "train/adv_mean": 0.00257535817183226, "train/adv_min": -0.6673611766457008, "train/adv_std": 0.05586199422929144, "train/cont_avg": 0.9945141489055299, "train/cont_loss_mean": 6.984680613253874e-05, "train/cont_loss_std": 0.0021606002778374617, "train/cont_neg_acc": 0.9993386246539928, "train/cont_neg_loss": 0.008385029909441578, "train/cont_pos_acc": 0.9999954497209892, "train/cont_pos_loss": 1.3937590256358092e-05, "train/cont_pred": 0.9945120707085605, "train/cont_rate": 0.9945141489055299, "train/dyn_loss_mean": 3.042675631386893, "train/dyn_loss_std": 7.881902791388024, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.3142560003539934, "train/extr_critic_critic_opt_grad_steps": 124440.0, "train/extr_critic_critic_opt_loss": 15290.062036470334, "train/extr_critic_mag": 12.926155529813283, "train/extr_critic_max": 12.926155529813283, "train/extr_critic_mean": 2.458820079328827, "train/extr_critic_min": -0.6415047645568848, "train/extr_critic_std": 2.4640412143847907, "train/extr_return_normed_mag": 1.8094423020490304, "train/extr_return_normed_max": 1.8094423020490304, "train/extr_return_normed_mean": 0.35771363575337667, "train/extr_return_normed_min": -0.11682477143640342, "train/extr_return_normed_std": 0.3364212179925585, "train/extr_return_rate": 0.7877691552935657, "train/extr_return_raw_mag": 13.299042128198158, "train/extr_return_raw_max": 13.299042128198158, "train/extr_return_raw_mean": 2.477985423830797, "train/extr_return_raw_min": -1.0608680396585422, "train/extr_return_raw_std": 2.5088697347772837, "train/extr_reward_mag": 1.0281669890276297, "train/extr_reward_max": 1.0281669890276297, "train/extr_reward_mean": 0.030845851607380376, "train/extr_reward_min": -0.685472553226805, "train/extr_reward_std": 0.17661997995206288, "train/image_loss_mean": 1.5939940848658163, "train/image_loss_std": 5.001882088898514, "train/model_loss_mean": 3.455573447838357, "train/model_loss_std": 8.823968280844975, "train/model_opt_grad_norm": 30.261373946194276, "train/model_opt_grad_steps": 124334.3732718894, "train/model_opt_loss": 5970.45034719722, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1728.110599078341, "train/policy_entropy_mag": 2.536306424075008, "train/policy_entropy_max": 2.536306424075008, "train/policy_entropy_mean": 0.5812647923621165, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6449401753564035, "train/policy_logprob_mag": 7.438384009945777, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5811453119675685, "train/policy_logprob_min": -7.438384009945777, "train/policy_logprob_std": 1.1285008527166833, "train/policy_randomness_mag": 0.8952048651633724, "train/policy_randomness_max": 0.8952048651633724, "train/policy_randomness_mean": 0.20516096412586177, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.227635580548493, "train/post_ent_mag": 45.18585822109802, "train/post_ent_max": 45.18585822109802, "train/post_ent_mean": 26.500367230534003, "train/post_ent_min": 13.719011851719447, "train/post_ent_std": 4.511108779687486, "train/prior_ent_mag": 77.19345117384388, "train/prior_ent_max": 77.19345117384388, "train/prior_ent_mean": 29.44457861025762, "train/prior_ent_min": 15.136108569835189, "train/prior_ent_std": 8.863055468704294, "train/rep_loss_mean": 3.042675631386893, "train/rep_loss_std": 7.881902791388024, "train/reward_avg": 0.020231494710089698, "train/reward_loss_mean": 0.03590413211299802, "train/reward_loss_std": 0.16293596500350582, "train/reward_max_data": 1.0124423992798626, "train/reward_max_pred": 1.0137349768168367, "train/reward_neg_acc": 0.9962950510912777, "train/reward_neg_loss": 0.018293890832764555, "train/reward_pos_acc": 0.9915713780486639, "train/reward_pos_loss": 0.7154619053761531, "train/reward_pred": 0.02009376686512737, "train/reward_rate": 0.025228614631336407, "train_stats/sum_log_reward": 3.25384614444696, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 2.1538461538461537, "train_stats/max_log_achievement_collect_sapling": 2.5384615384615383, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 1.0, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.07692307692307693, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 2.5384615384615383, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 0.3076923076923077, "train_stats/max_log_achievement_wake_up": 1.6153846153846154, "train_stats/mean_log_entropy": 0.49991148939499486, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 7.541756303908187e-07, "report/cont_loss_std": 9.385370503878221e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 4.4441736690714606e-07, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 7.553902605650364e-07, "report/cont_pred": 0.9960930943489075, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 2.990077018737793, "report/dyn_loss_std": 8.012923240661621, "report/image_loss_mean": 1.4614759683609009, "report/image_loss_std": 4.555382251739502, "report/model_loss_mean": 3.294544219970703, "report/model_loss_std": 8.366454124450684, "report/post_ent_mag": 41.58374786376953, "report/post_ent_max": 41.58374786376953, "report/post_ent_mean": 25.59972381591797, "report/post_ent_min": 13.409738540649414, "report/post_ent_std": 5.125486850738525, "report/prior_ent_mag": 77.17584228515625, "report/prior_ent_max": 77.17584228515625, "report/prior_ent_mean": 28.509117126464844, "report/prior_ent_min": 14.769329071044922, "report/prior_ent_std": 9.33184814453125, "report/rep_loss_mean": 2.990077018737793, "report/rep_loss_std": 8.012923240661621, "report/reward_avg": 0.01484375074505806, "report/reward_loss_mean": 0.03902117535471916, "report/reward_loss_std": 0.16716526448726654, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0018384456634521, "report/reward_neg_acc": 0.9990040063858032, "report/reward_neg_loss": 0.025518672540783882, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7168469429016113, "report/reward_pred": 0.014163054525852203, "report/reward_rate": 0.01953125, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 8.013316801225301e-07, "eval/cont_loss_std": 1.0105707588081714e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00015663218800909817, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 4.963789592693502e-07, "eval/cont_pred": 0.9980467557907104, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 23.416030883789062, "eval/dyn_loss_std": 13.16962718963623, "eval/image_loss_mean": 42.66951370239258, "eval/image_loss_std": 40.57210159301758, "eval/model_loss_mean": 56.8363037109375, "eval/model_loss_std": 46.069156646728516, "eval/post_ent_mag": 47.2835578918457, "eval/post_ent_max": 47.2835578918457, "eval/post_ent_mean": 29.57510757446289, "eval/post_ent_min": 19.464197158813477, "eval/post_ent_std": 3.7760114669799805, "eval/prior_ent_mag": 77.17584228515625, "eval/prior_ent_max": 77.17584228515625, "eval/prior_ent_mean": 40.53095245361328, "eval/prior_ent_min": 22.029682159423828, "eval/prior_ent_std": 8.515143394470215, "eval/rep_loss_mean": 23.416030883789062, "eval/rep_loss_std": 13.16962718963623, "eval/reward_avg": 0.02138671837747097, "eval/reward_loss_mean": 0.11717364192008972, "eval/reward_loss_std": 0.8406150937080383, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0017755031585693, "eval/reward_neg_acc": 0.999000072479248, "eval/reward_neg_loss": 0.051717888563871384, "eval/reward_pos_acc": 0.6666666865348816, "eval/reward_pos_loss": 2.844496488571167, "eval/reward_pred": 0.013077894225716591, "eval/reward_rate": 0.0234375, "replay/size": 126578.0, "replay/inserts": 2171.0, "replay/samples": 34736.0, "replay/insert_wait_avg": 2.620517795726156e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.358949780738722e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 24568.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4003093242645, "timer/env.step_count": 272.0, "timer/env.step_total": 26.651262998580933, "timer/env.step_frac": 0.026640598518589954, "timer/env.step_avg": 0.09798258455360637, "timer/env.step_min": 0.023894786834716797, "timer/env.step_max": 1.7336289882659912, "timer/replay._sample_count": 34736.0, "timer/replay._sample_total": 17.4249906539917, "timer/replay._sample_frac": 0.017418018058952493, "timer/replay._sample_avg": 0.0005016406798132111, "timer/replay._sample_min": 0.0003695487976074219, "timer/replay._sample_max": 0.011053800582885742, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 272.0, "timer/agent.policy_total": 4.439768552780151, "timer/agent.policy_frac": 0.004437991983208262, "timer/agent.policy_avg": 0.016322678502868202, "timer/agent.policy_min": 0.010543346405029297, "timer/agent.policy_max": 0.04202532768249512, "timer/dataset_train_count": 2171.0, "timer/dataset_train_total": 0.3969297409057617, "timer/dataset_train_frac": 0.00039677090981096746, "timer/dataset_train_avg": 0.00018283267660329882, "timer/dataset_train_min": 9.34600830078125e-05, "timer/dataset_train_max": 0.0004851818084716797, "timer/agent.train_count": 2171.0, "timer/agent.train_total": 966.9828672409058, "timer/agent.train_frac": 0.9665959298773797, "timer/agent.train_avg": 0.445408966946525, "timer/agent.train_min": 0.43505072593688965, "timer/agent.train_max": 0.5689873695373535, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47406005859375, "timer/agent.report_frac": 0.00047387036386860077, "timer/agent.report_avg": 0.237030029296875, "timer/agent.report_min": 0.22977566719055176, "timer/agent.report_max": 0.24428439140319824, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.361701965332031e-05, "timer/dataset_eval_frac": 3.360356783178869e-08, "timer/dataset_eval_avg": 3.361701965332031e-05, "timer/dataset_eval_min": 3.361701965332031e-05, "timer/dataset_eval_max": 3.361701965332031e-05, "fps": 2.1701017625049692}
{"step": 127168, "time": 58359.34426546097, "episode/length": 165.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 127336, "time": 58436.356154203415, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 127392, "time": 58463.032616853714, "episode/length": 199.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 127480, "time": 58503.93124461174, "episode/length": 92.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.956989247311828, "episode/intrinsic_return": 0.0}
{"step": 127552, "time": 58537.77379107475, "episode/length": 177.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 127560, "time": 58542.890910863876, "episode/length": 156.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 127728, "time": 58620.81653499603, "episode/length": 48.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.8979591836734694, "episode/intrinsic_return": 0.0}
{"step": 127816, "time": 58662.05760741234, "episode/length": 195.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 128160, "time": 58819.36483359337, "episode/length": 123.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9596774193548387, "episode/intrinsic_return": 0.0}
{"step": 128536, "time": 58990.526188611984, "episode/length": 203.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9656862745098039, "episode/intrinsic_return": 0.0}
{"step": 128752, "time": 59090.010335206985, "episode/length": 148.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 128808, "time": 59116.7645778656, "episode/length": 165.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 128872, "time": 59147.10779380798, "episode/length": 184.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 128904, "time": 59163.114505290985, "episode/length": 168.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 129072, "time": 59240.8541302681, "episode/length": 156.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 129152, "time": 59278.582787036896, "episode/length": 177.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 129240, "time": 59320.3538980484, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.578692966037327, "train/action_min": 0.0, "train/action_std": 4.1096623848985745, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.05015758339626094, "train/actor_opt_grad_steps": 126605.0, "train/actor_opt_loss": -11.625975926234215, "train/adv_mag": 0.8115622804120735, "train/adv_max": 0.7498481843482565, "train/adv_mean": 0.0027433917939808446, "train/adv_min": -0.623326289019099, "train/adv_std": 0.05904319006259794, "train/cont_avg": 0.9945294415509259, "train/cont_loss_mean": 7.90339073552999e-05, "train/cont_loss_std": 0.0024633705132904573, "train/cont_neg_acc": 0.9994186046511628, "train/cont_neg_loss": 0.0011938462270504346, "train/cont_pos_acc": 0.9999908675198201, "train/cont_pos_loss": 7.07485663198913e-05, "train/cont_pred": 0.9945212806816455, "train/cont_rate": 0.9945294415509259, "train/dyn_loss_mean": 3.0359305110242634, "train/dyn_loss_std": 7.867868606691007, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.3602738112763122, "train/extr_critic_critic_opt_grad_steps": 126605.0, "train/extr_critic_critic_opt_loss": 15158.295568395544, "train/extr_critic_mag": 12.83298823568556, "train/extr_critic_max": 12.83298823568556, "train/extr_critic_mean": 2.4399927181226237, "train/extr_critic_min": -0.6604200739551473, "train/extr_critic_std": 2.310834849322284, "train/extr_return_normed_mag": 1.7989589113880087, "train/extr_return_normed_max": 1.7989589113880087, "train/extr_return_normed_mean": 0.3577126254913984, "train/extr_return_normed_min": -0.12344618440019312, "train/extr_return_normed_std": 0.3195937947128658, "train/extr_return_rate": 0.8342611124670064, "train/extr_return_raw_mag": 13.136567480034298, "train/extr_return_raw_max": 13.136567480034298, "train/extr_return_raw_mean": 2.460382068046817, "train/extr_return_raw_min": -1.095743251343568, "train/extr_return_raw_std": 2.3659772210650973, "train/extr_reward_mag": 1.0257369412316217, "train/extr_reward_max": 1.0257369412316217, "train/extr_reward_mean": 0.029491488860609632, "train/extr_reward_min": -0.6901078113803157, "train/extr_reward_std": 0.17359395021641696, "train/image_loss_mean": 1.5857898413583085, "train/image_loss_std": 4.708804671411161, "train/model_loss_mean": 3.4435351303330175, "train/model_loss_std": 8.53240172068278, "train/model_opt_grad_norm": 30.21037956961879, "train/model_opt_grad_steps": 126498.10648148147, "train/model_opt_loss": 8900.449847186053, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2581.0185185185187, "train/policy_entropy_mag": 2.5332878033320108, "train/policy_entropy_max": 2.5332878033320108, "train/policy_entropy_mean": 0.5629742320764948, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6272148183650441, "train/policy_logprob_mag": 7.438384005316982, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5628165392963974, "train/policy_logprob_min": -7.438384005316982, "train/policy_logprob_std": 1.1174540707358607, "train/policy_randomness_mag": 0.8941394239664078, "train/policy_randomness_max": 0.8941394239664078, "train/policy_randomness_mean": 0.19870519948502383, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.22137930775406184, "train/post_ent_mag": 44.89051417951231, "train/post_ent_max": 44.89051417951231, "train/post_ent_mean": 26.665020024334943, "train/post_ent_min": 13.639676791650277, "train/post_ent_std": 4.549629736829687, "train/prior_ent_mag": 77.15784772237141, "train/prior_ent_max": 77.15784772237141, "train/prior_ent_mean": 29.60591642944901, "train/prior_ent_min": 14.991813756801465, "train/prior_ent_std": 8.8450120444651, "train/rep_loss_mean": 3.0359305110242634, "train/rep_loss_std": 7.867868606691007, "train/reward_avg": 0.02044948987248871, "train/reward_loss_mean": 0.03610792543946041, "train/reward_loss_std": 0.1647129183014234, "train/reward_max_data": 1.0129629660535742, "train/reward_max_pred": 1.0132515435969387, "train/reward_neg_acc": 0.9964373371115437, "train/reward_neg_loss": 0.01848118872968135, "train/reward_pos_acc": 0.9917899538521413, "train/reward_pos_loss": 0.7129203108725725, "train/reward_pred": 0.020322564894471457, "train/reward_rate": 0.025395146122685185, "train_stats/sum_log_reward": 4.037499934434891, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 1.875, "train_stats/max_log_achievement_collect_sapling": 2.5, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 2.6875, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.3125, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 2.375, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 0.9375, "train_stats/max_log_achievement_wake_up": 1.625, "train_stats/mean_log_entropy": 0.5075078178197145, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 1.8407977222523186e-06, "report/cont_loss_std": 5.93841468798928e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 3.5734756238525733e-06, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.835706711972307e-06, "report/cont_pred": 0.997068464756012, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 2.675633430480957, "report/dyn_loss_std": 7.588832378387451, "report/image_loss_mean": 1.3985093832015991, "report/image_loss_std": 3.2633090019226074, "report/model_loss_mean": 3.035754442214966, "report/model_loss_std": 7.225950717926025, "report/post_ent_mag": 47.82627868652344, "report/post_ent_max": 47.82627868652344, "report/post_ent_mean": 25.293241500854492, "report/post_ent_min": 12.465849876403809, "report/post_ent_std": 4.591296672821045, "report/prior_ent_mag": 76.71463012695312, "report/prior_ent_max": 76.71463012695312, "report/prior_ent_mean": 27.909740447998047, "report/prior_ent_min": 14.012884140014648, "report/prior_ent_std": 8.526993751525879, "report/rep_loss_mean": 2.675633430480957, "report/rep_loss_std": 7.588832378387451, "report/reward_avg": 0.014746093191206455, "report/reward_loss_mean": 0.031862977892160416, "report/reward_loss_std": 0.13571341335773468, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.099748134613037, "report/reward_neg_acc": 0.991044819355011, "report/reward_neg_loss": 0.019793836399912834, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6702571511268616, "report/reward_pred": 0.014977280050516129, "report/reward_rate": 0.0185546875, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 1.074370175047079e-06, "eval/cont_loss_std": 1.8974072872879333e-06, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 1.3233257050160319e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.038643745232548e-06, "eval/cont_pred": 0.9970692992210388, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 23.320411682128906, "eval/dyn_loss_std": 13.52847671508789, "eval/image_loss_mean": 27.868188858032227, "eval/image_loss_std": 30.906347274780273, "eval/model_loss_mean": 42.03089141845703, "eval/model_loss_std": 36.29023361206055, "eval/post_ent_mag": 46.997440338134766, "eval/post_ent_max": 46.997440338134766, "eval/post_ent_mean": 30.126216888427734, "eval/post_ent_min": 20.667556762695312, "eval/post_ent_std": 3.3512485027313232, "eval/prior_ent_mag": 76.71463012695312, "eval/prior_ent_max": 76.71463012695312, "eval/prior_ent_mean": 40.85176467895508, "eval/prior_ent_min": 21.23552703857422, "eval/prior_ent_std": 7.261802673339844, "eval/rep_loss_mean": 23.320411682128906, "eval/rep_loss_std": 13.52847671508789, "eval/reward_avg": 0.03056640550494194, "eval/reward_loss_mean": 0.17045608162879944, "eval/reward_loss_std": 1.1699472665786743, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.000058650970459, "eval/reward_neg_acc": 0.9949494004249573, "eval/reward_neg_loss": 0.06172933056950569, "eval/reward_pos_acc": 0.6764705777168274, "eval/reward_pos_loss": 3.3363230228424072, "eval/reward_pred": 0.019534580409526825, "eval/reward_rate": 0.033203125, "replay/size": 128736.0, "replay/inserts": 2158.0, "replay/samples": 34528.0, "replay/insert_wait_avg": 2.6746410479470465e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.295906819934863e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 24568.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 8.940696716308594e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 999.9917166233063, "timer/env.step_count": 269.0, "timer/env.step_total": 31.084351301193237, "timer/env.step_frac": 0.031084608786717195, "timer/env.step_avg": 0.11555520929811612, "timer/env.step_min": 0.02355337142944336, "timer/env.step_max": 2.0070981979370117, "timer/replay._sample_count": 34528.0, "timer/replay._sample_total": 17.436692476272583, "timer/replay._sample_frac": 0.017436836912161073, "timer/replay._sample_avg": 0.0005050015198179038, "timer/replay._sample_min": 0.0003414154052734375, "timer/replay._sample_max": 0.035053253173828125, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 269.0, "timer/agent.policy_total": 4.3767640590667725, "timer/agent.policy_frac": 0.004376800313752484, "timer/agent.policy_avg": 0.01627049836084302, "timer/agent.policy_min": 0.010227680206298828, "timer/agent.policy_max": 0.04301595687866211, "timer/dataset_train_count": 2158.0, "timer/dataset_train_total": 0.41370701789855957, "timer/dataset_train_frac": 0.0004137104448180161, "timer/dataset_train_avg": 0.00019170853470739554, "timer/dataset_train_min": 9.465217590332031e-05, "timer/dataset_train_max": 0.020262718200683594, "timer/agent.train_count": 2158.0, "timer/agent.train_total": 962.1600105762482, "timer/agent.train_frac": 0.9621679805760739, "timer/agent.train_avg": 0.4458572801558147, "timer/agent.train_min": 0.43500542640686035, "timer/agent.train_max": 0.5569174289703369, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4738144874572754, "timer/agent.report_frac": 0.0004738184122736687, "timer/agent.report_avg": 0.2369072437286377, "timer/agent.report_min": 0.22988295555114746, "timer/agent.report_max": 0.24393153190612793, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.075599670410156e-05, "timer/dataset_eval_frac": 3.0756251469718175e-08, "timer/dataset_eval_avg": 3.075599670410156e-05, "timer/dataset_eval_min": 3.075599670410156e-05, "timer/dataset_eval_max": 3.075599670410156e-05, "fps": 2.1579913089777967}
{"step": 129408, "time": 59396.529589653015, "episode/length": 155.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 129448, "time": 59416.004588365555, "episode/length": 67.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9411764705882353, "episode/intrinsic_return": 0.0}
{"step": 129984, "time": 59659.63146829605, "episode/length": 180.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 130000, "time": 59686.21630716324, "eval_episode/length": 140.0, "eval_episode/score": 5.099999971687794, "eval_episode/reward_rate": 0.9929078014184397}
{"step": 130000, "time": 59687.76476430893, "eval_episode/length": 143.0, "eval_episode/score": 5.099999971687794, "eval_episode/reward_rate": 0.9930555555555556}
{"step": 130000, "time": 59689.46122956276, "eval_episode/length": 147.0, "eval_episode/score": 4.099999979138374, "eval_episode/reward_rate": 0.9932432432432432}
{"step": 130000, "time": 59691.12191057205, "eval_episode/length": 150.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9668874172185431}
{"step": 130000, "time": 59693.60171532631, "eval_episode/length": 173.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9712643678160919}
{"step": 130000, "time": 59695.327820539474, "eval_episode/length": 175.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9659090909090909}
{"step": 130000, "time": 59697.760543346405, "eval_episode/length": 199.0, "eval_episode/score": 4.099999979138374, "eval_episode/reward_rate": 0.995}
{"step": 130000, "time": 59700.60655760765, "eval_episode/length": 232.0, "eval_episode/score": 4.099999971687794, "eval_episode/reward_rate": 0.9957081545064378}
{"step": 130168, "time": 59776.38348531723, "episode/length": 176.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 130328, "time": 59850.224422216415, "episode/length": 181.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 130368, "time": 59870.03437900543, "episode/length": 151.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9605263157894737, "episode/intrinsic_return": 0.0}
{"step": 130424, "time": 59896.935229063034, "episode/length": 201.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 130584, "time": 59970.759425640106, "episode/length": 188.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 130728, "time": 60037.407047986984, "episode/length": 159.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 130936, "time": 60132.8046875, "episode/length": 63.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.984375, "episode/intrinsic_return": 0.0}
{"step": 131240, "time": 60272.62235546112, "episode/length": 228.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 131342, "time": 60320.74695324898, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.693287876674107, "train/action_min": 0.0, "train/action_std": 4.163390957741511, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0491234277153299, "train/actor_opt_grad_steps": 128735.0, "train/actor_opt_loss": -15.599583400856881, "train/adv_mag": 0.8315777331590652, "train/adv_max": 0.754021229488509, "train/adv_mean": 0.0028162748193391878, "train/adv_min": -0.6553642954145159, "train/adv_std": 0.05885425174520129, "train/cont_avg": 0.9943870907738095, "train/cont_loss_mean": 2.0278380822397984e-05, "train/cont_loss_std": 0.00047906306066690396, "train/cont_neg_acc": 1.0, "train/cont_neg_loss": 0.0004511525104427554, "train/cont_pos_acc": 0.9999906338396527, "train/cont_pos_loss": 1.7653949135925425e-05, "train/cont_pred": 0.9943799237410228, "train/cont_rate": 0.9943870907738095, "train/dyn_loss_mean": 3.056195674623762, "train/dyn_loss_std": 7.867542929876418, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.2561694355238051, "train/extr_critic_critic_opt_grad_steps": 128735.0, "train/extr_critic_critic_opt_loss": 15025.53972749256, "train/extr_critic_mag": 13.17500578108288, "train/extr_critic_max": 13.17500578108288, "train/extr_critic_mean": 2.5333090714045934, "train/extr_critic_min": -0.6823852561769032, "train/extr_critic_std": 2.359935448283241, "train/extr_return_normed_mag": 1.925990485009693, "train/extr_return_normed_max": 1.925990485009693, "train/extr_return_normed_mean": 0.38482637015127, "train/extr_return_normed_min": -0.13921819401993638, "train/extr_return_normed_std": 0.336380410974934, "train/extr_return_rate": 0.8360522488753, "train/extr_return_raw_mag": 13.630635906401135, "train/extr_return_raw_max": 13.630635906401135, "train/extr_return_raw_mean": 2.553466660635812, "train/extr_return_raw_min": -1.2066444907869611, "train/extr_return_raw_std": 2.417953005291167, "train/extr_reward_mag": 1.0254467930112565, "train/extr_reward_max": 1.0254467930112565, "train/extr_reward_mean": 0.030490013478057725, "train/extr_reward_min": -0.6847337030229115, "train/extr_reward_std": 0.1766103635941233, "train/image_loss_mean": 1.5286619385083517, "train/image_loss_std": 4.6643708728608635, "train/model_loss_mean": 3.398473431950524, "train/model_loss_std": 8.495396371114822, "train/model_opt_grad_norm": 32.01824594679333, "train/model_opt_grad_steps": 128626.0380952381, "train/model_opt_loss": 8766.353592354912, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2583.3333333333335, "train/policy_entropy_mag": 2.507108701978411, "train/policy_entropy_max": 2.507108701978411, "train/policy_entropy_mean": 0.5466587429954892, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6126266987550826, "train/policy_logprob_mag": 7.438384035655431, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5473818837177186, "train/policy_logprob_min": -7.438384035655431, "train/policy_logprob_std": 1.1069178674902236, "train/policy_randomness_mag": 0.8848993511427017, "train/policy_randomness_max": 0.8848993511427017, "train/policy_randomness_mean": 0.19294654648928417, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.21623034193402246, "train/post_ent_mag": 45.6156129019601, "train/post_ent_max": 45.6156129019601, "train/post_ent_mean": 26.99169484093076, "train/post_ent_min": 13.67700510479155, "train/post_ent_std": 4.63182069119953, "train/prior_ent_mag": 77.25193517775763, "train/prior_ent_max": 77.25193517775763, "train/prior_ent_mean": 29.941380282810755, "train/prior_ent_min": 15.085211862836566, "train/prior_ent_std": 8.907942528951736, "train/rep_loss_mean": 3.056195674623762, "train/rep_loss_std": 7.867542929876418, "train/reward_avg": 0.020960751353275207, "train/reward_loss_mean": 0.036073828391021204, "train/reward_loss_std": 0.16337238677910396, "train/reward_max_data": 1.0090476212047395, "train/reward_max_pred": 1.0098658987454006, "train/reward_neg_acc": 0.9963524293331872, "train/reward_neg_loss": 0.01815246220545045, "train/reward_pos_acc": 0.9939121981461843, "train/reward_pos_loss": 0.7079067349433898, "train/reward_pred": 0.02087336326284068, "train/reward_rate": 0.02595796130952381, "train_stats/sum_log_reward": 4.099999969655817, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 3.3636363636363638, "train_stats/max_log_achievement_collect_sapling": 1.5454545454545454, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 2.090909090909091, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.09090909090909091, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.4545454545454546, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 0.7272727272727273, "train_stats/max_log_achievement_wake_up": 1.5454545454545454, "train_stats/mean_log_entropy": 0.4842568974603306, "eval_stats/sum_log_reward": 4.474999904632568, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 3.25, "eval_stats/max_log_achievement_collect_sapling": 2.375, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 3.0, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.375, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 1.0, "eval_stats/max_log_achievement_wake_up": 1.875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 1.825426079449244e-05, "report/cont_loss_std": 0.000358461489668116, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.5755074855405837e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 1.8271461158292368e-05, "report/cont_pred": 0.9931460618972778, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 2.8881537914276123, "report/dyn_loss_std": 7.191856861114502, "report/image_loss_mean": 1.3875114917755127, "report/image_loss_std": 2.8208420276641846, "report/model_loss_mean": 3.1536526679992676, "report/model_loss_std": 5.945220947265625, "report/post_ent_mag": 47.55181121826172, "report/post_ent_max": 47.55181121826172, "report/post_ent_mean": 27.112937927246094, "report/post_ent_min": 15.129000663757324, "report/post_ent_std": 4.876902103424072, "report/prior_ent_mag": 77.72069549560547, "report/prior_ent_max": 77.72069549560547, "report/prior_ent_mean": 29.849143981933594, "report/prior_ent_min": 16.00766372680664, "report/prior_ent_std": 9.355095863342285, "report/rep_loss_mean": 2.8881537914276123, "report/rep_loss_std": 7.191856861114502, "report/reward_avg": 0.02197265625, "report/reward_loss_mean": 0.03323056548833847, "report/reward_loss_std": 0.13936081528663635, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0012447834014893, "report/reward_neg_acc": 1.0000001192092896, "report/reward_neg_loss": 0.015315732918679714, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6704868674278259, "report/reward_pred": 0.022003179416060448, "report/reward_rate": 0.02734375, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.010718479752540588, "eval/cont_loss_std": 0.31421729922294617, "eval/cont_neg_acc": 0.6000000238418579, "eval/cont_neg_loss": 2.1935253143310547, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 7.94728930486599e-06, "eval/cont_pred": 0.9966853857040405, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 24.818496704101562, "eval/dyn_loss_std": 13.829558372497559, "eval/image_loss_mean": 32.77240753173828, "eval/image_loss_std": 36.366336822509766, "eval/model_loss_mean": 47.81822967529297, "eval/model_loss_std": 42.28849792480469, "eval/post_ent_mag": 45.572513580322266, "eval/post_ent_max": 45.572513580322266, "eval/post_ent_mean": 31.312868118286133, "eval/post_ent_min": 16.625694274902344, "eval/post_ent_std": 4.135341167449951, "eval/prior_ent_mag": 77.72069549560547, "eval/prior_ent_max": 77.72069549560547, "eval/prior_ent_mean": 42.8098258972168, "eval/prior_ent_min": 18.26205062866211, "eval/prior_ent_std": 8.105090141296387, "eval/rep_loss_mean": 24.818496704101562, "eval/rep_loss_std": 13.829558372497559, "eval/reward_avg": 0.02529296837747097, "eval/reward_loss_mean": 0.14400632679462433, "eval/reward_loss_std": 0.8901566863059998, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0016510486602783, "eval/reward_neg_acc": 0.9929577112197876, "eval/reward_neg_loss": 0.0650358572602272, "eval/reward_pos_acc": 0.6666666865348816, "eval/reward_pos_loss": 2.760561227798462, "eval/reward_pred": 0.02012946829199791, "eval/reward_rate": 0.029296875, "replay/size": 130838.0, "replay/inserts": 2102.0, "replay/samples": 33632.0, "replay/insert_wait_avg": 2.6257802598483217e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.257171520156932e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 26432.0, "eval_replay/inserts": 1864.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1593487129702588e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.152557373046875e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3781199455261, "timer/env.step_count": 263.0, "timer/env.step_total": 23.436119318008423, "timer/env.step_frac": 0.02342726100335401, "timer/env.step_avg": 0.08911071984033621, "timer/env.step_min": 0.02324819564819336, "timer/env.step_max": 1.6809093952178955, "timer/replay._sample_count": 33632.0, "timer/replay._sample_total": 16.885090589523315, "timer/replay._sample_frac": 0.016878708413217557, "timer/replay._sample_avg": 0.0005020543110586142, "timer/replay._sample_min": 0.0003559589385986328, "timer/replay._sample_max": 0.03422689437866211, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 496.0, "timer/agent.policy_total": 7.940516233444214, "timer/agent.policy_frac": 0.007937514900742333, "timer/agent.policy_avg": 0.016009105309363333, "timer/agent.policy_min": 0.009897947311401367, "timer/agent.policy_max": 0.027100563049316406, "timer/dataset_train_count": 2102.0, "timer/dataset_train_total": 0.38226938247680664, "timer/dataset_train_frac": 0.0003821248934329176, "timer/dataset_train_avg": 0.00018185983942759594, "timer/dataset_train_min": 9.942054748535156e-05, "timer/dataset_train_max": 0.0004878044128417969, "timer/agent.train_count": 2102.0, "timer/agent.train_total": 938.0725929737091, "timer/agent.train_frac": 0.937718023085901, "timer/agent.train_avg": 0.44627620978768273, "timer/agent.train_min": 0.4366011619567871, "timer/agent.train_max": 0.5745680332183838, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4761326313018799, "timer/agent.report_frac": 0.0004759526641064549, "timer/agent.report_avg": 0.23806631565093994, "timer/agent.report_min": 0.230574369430542, "timer/agent.report_max": 0.2455582618713379, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.361701965332031e-05, "timer/dataset_eval_frac": 3.360431319224662e-08, "timer/dataset_eval_avg": 3.361701965332031e-05, "timer/dataset_eval_min": 3.361701965332031e-05, "timer/dataset_eval_max": 3.361701965332031e-05, "fps": 2.1011782333480995}
{"step": 131464, "time": 60375.791994571686, "episode/length": 161.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 131800, "time": 60528.243191719055, "episode/length": 226.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 131872, "time": 60562.21523118019, "episode/length": 160.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 131904, "time": 60578.16376018524, "episode/length": 146.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 131968, "time": 60608.44095802307, "episode/length": 204.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9804878048780488, "episode/intrinsic_return": 0.0}
{"step": 131968, "time": 60608.4505405426, "episode/length": 199.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 132528, "time": 60864.58977818489, "episode/length": 198.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 132592, "time": 60895.14577627182, "episode/length": 168.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 132920, "time": 61044.350025177, "episode/length": 139.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 132984, "time": 61074.44863295555, "episode/length": 189.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 133232, "time": 61187.97966718674, "episode/length": 165.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 133344, "time": 61239.88112139702, "episode/length": 171.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 133519, "time": 61320.86760044098, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.665696948354695, "train/action_min": 0.0, "train/action_std": 4.135263608897336, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04938346863410989, "train/actor_opt_grad_steps": 130870.0, "train/actor_opt_loss": -17.25799510267473, "train/adv_mag": 0.843447799094811, "train/adv_max": 0.7867112704960432, "train/adv_mean": 0.0025353479433283294, "train/adv_min": -0.6450179565337396, "train/adv_std": 0.06051589500519537, "train/cont_avg": 0.994410642281106, "train/cont_loss_mean": 1.473799869713185e-05, "train/cont_loss_std": 0.0004283536798373698, "train/cont_neg_acc": 0.9994212962962963, "train/cont_neg_loss": 0.0017143191397526838, "train/cont_pos_acc": 0.9999999791246406, "train/cont_pos_loss": 2.2095720334120062e-06, "train/cont_pred": 0.9944136318523213, "train/cont_rate": 0.994410642281106, "train/dyn_loss_mean": 3.0773907839427896, "train/dyn_loss_std": 7.878451382509574, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.2814433184636902, "train/extr_critic_critic_opt_grad_steps": 130870.0, "train/extr_critic_critic_opt_loss": 14989.334326396889, "train/extr_critic_mag": 13.54488485749416, "train/extr_critic_max": 13.54488485749416, "train/extr_critic_mean": 2.452987197357389, "train/extr_critic_min": -0.6651554602082423, "train/extr_critic_std": 2.250736911175987, "train/extr_return_normed_mag": 1.993990799798394, "train/extr_return_normed_max": 1.993990799798394, "train/extr_return_normed_mean": 0.382436830533265, "train/extr_return_normed_min": -0.1262502582048491, "train/extr_return_normed_std": 0.3279169587770365, "train/extr_return_rate": 0.8351229929154919, "train/extr_return_raw_mag": 13.81769810953448, "train/extr_return_raw_max": 13.81769810953448, "train/extr_return_raw_mean": 2.4709015425449143, "train/extr_return_raw_min": -1.1081464037917177, "train/extr_return_raw_std": 2.307852027603009, "train/extr_reward_mag": 1.0256574241796397, "train/extr_reward_max": 1.0256574241796397, "train/extr_reward_mean": 0.029915025771041895, "train/extr_reward_min": -0.6857420271992134, "train/extr_reward_std": 0.17458534611534962, "train/image_loss_mean": 1.5865470896118796, "train/image_loss_std": 4.992939329367079, "train/model_loss_mean": 3.469220558069818, "train/model_loss_std": 8.790836703392767, "train/model_opt_grad_norm": 29.069147865893104, "train/model_opt_grad_steps": 130759.0138248848, "train/model_opt_loss": 9061.123555407547, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2615.2073732718895, "train/policy_entropy_mag": 2.4810550795172768, "train/policy_entropy_max": 2.4810550795172768, "train/policy_entropy_mean": 0.5428294461169001, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6116785676248612, "train/policy_logprob_mag": 7.43838406707834, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5424805302773753, "train/policy_logprob_min": -7.43838406707834, "train/policy_logprob_std": 1.1025158647567994, "train/policy_randomness_mag": 0.8757035649866552, "train/policy_randomness_max": 0.8757035649866552, "train/policy_randomness_mean": 0.19159497313785112, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.21589569156895036, "train/post_ent_mag": 45.35852985997354, "train/post_ent_max": 45.35852985997354, "train/post_ent_mean": 27.17252632879442, "train/post_ent_min": 13.911906611534857, "train/post_ent_std": 4.590403784255278, "train/prior_ent_mag": 77.24509577597341, "train/prior_ent_max": 77.24509577597341, "train/prior_ent_mean": 30.15784185383177, "train/prior_ent_min": 15.237095204366517, "train/prior_ent_std": 8.838974445096907, "train/rep_loss_mean": 3.0773907839427896, "train/rep_loss_std": 7.878451382509574, "train/reward_avg": 0.020144189109227488, "train/reward_loss_mean": 0.03622424417102392, "train/reward_loss_std": 0.16564626263857987, "train/reward_max_data": 1.0138248880887362, "train/reward_max_pred": 1.0145809282355593, "train/reward_neg_acc": 0.9963917045549313, "train/reward_neg_loss": 0.018749162754310027, "train/reward_pos_acc": 0.992215877029753, "train/reward_pos_loss": 0.7134104156823752, "train/reward_pred": 0.020058179089653603, "train/reward_rate": 0.02512060771889401, "train_stats/sum_log_reward": 4.099999924500783, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 3.0, "train_stats/max_log_achievement_collect_sapling": 1.6666666666666667, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 2.0, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.08333333333333333, "train_stats/max_log_achievement_make_wood_pickaxe": 0.16666666666666666, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.4166666666666667, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 0.75, "train_stats/max_log_achievement_wake_up": 2.0, "train_stats/mean_log_entropy": 0.5860831340154012, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 1.2183461876702495e-05, "report/cont_loss_std": 0.0003643479140009731, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.0073555131384637e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 1.2191734640509821e-05, "report/cont_pred": 0.9960818290710449, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 2.7159910202026367, "report/dyn_loss_std": 7.566092014312744, "report/image_loss_mean": 1.1601316928863525, "report/image_loss_std": 3.822810173034668, "report/model_loss_mean": 2.8162992000579834, "report/model_loss_std": 7.9171671867370605, "report/post_ent_mag": 47.280399322509766, "report/post_ent_max": 47.280399322509766, "report/post_ent_mean": 26.629104614257812, "report/post_ent_min": 14.334599494934082, "report/post_ent_std": 4.3418989181518555, "report/prior_ent_mag": 77.45089721679688, "report/prior_ent_max": 77.45089721679688, "report/prior_ent_mean": 29.198463439941406, "report/prior_ent_min": 14.004951477050781, "report/prior_ent_std": 8.508078575134277, "report/rep_loss_mean": 2.7159910202026367, "report/rep_loss_std": 7.566092014312744, "report/reward_avg": 0.01650390774011612, "report/reward_loss_mean": 0.026560649275779724, "report/reward_loss_std": 0.12435377389192581, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0018272399902344, "report/reward_neg_acc": 0.9950149655342102, "report/reward_neg_loss": 0.012743202038109303, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.686508297920227, "report/reward_pred": 0.016478605568408966, "report/reward_rate": 0.0205078125, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.0002006635768339038, "eval/cont_loss_std": 0.005584727972745895, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.05120549350976944, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 6.446307452279143e-07, "eval/cont_pred": 0.9962784647941589, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 25.204185485839844, "eval/dyn_loss_std": 15.518693923950195, "eval/image_loss_mean": 48.50299072265625, "eval/image_loss_std": 62.410892486572266, "eval/model_loss_mean": 63.809547424316406, "eval/model_loss_std": 69.1529541015625, "eval/post_ent_mag": 47.280399322509766, "eval/post_ent_max": 47.280399322509766, "eval/post_ent_mean": 30.53481674194336, "eval/post_ent_min": 18.78643798828125, "eval/post_ent_std": 3.7828025817871094, "eval/prior_ent_mag": 77.45089721679688, "eval/prior_ent_max": 77.45089721679688, "eval/prior_ent_mean": 40.611690521240234, "eval/prior_ent_min": 19.893579483032227, "eval/prior_ent_std": 8.464556694030762, "eval/rep_loss_mean": 25.204185485839844, "eval/rep_loss_std": 15.518693923950195, "eval/reward_avg": 0.01953125, "eval/reward_loss_mean": 0.18384265899658203, "eval/reward_loss_std": 1.0684775114059448, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0016210079193115, "eval/reward_neg_acc": 0.9940000176429749, "eval/reward_neg_loss": 0.13698670268058777, "eval/reward_pos_acc": 0.7916666865348816, "eval/reward_pos_loss": 2.1361751556396484, "eval/reward_pred": 0.017203031107783318, "eval/reward_rate": 0.0234375, "replay/size": 133015.0, "replay/inserts": 2177.0, "replay/samples": 34832.0, "replay/insert_wait_avg": 2.6540357583588724e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.308345351352788e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 26432.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 8.195638656616211e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1072754859924, "timer/env.step_count": 272.0, "timer/env.step_total": 25.65297794342041, "timer/env.step_frac": 0.02565022630292795, "timer/env.step_avg": 0.09431241890963386, "timer/env.step_min": 0.02363276481628418, "timer/env.step_max": 3.2763376235961914, "timer/replay._sample_count": 34832.0, "timer/replay._sample_total": 17.57414436340332, "timer/replay._sample_frac": 0.01757225929074792, "timer/replay._sample_avg": 0.0005045402033590756, "timer/replay._sample_min": 0.0003802776336669922, "timer/replay._sample_max": 0.03357529640197754, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 272.0, "timer/agent.policy_total": 4.4188361167907715, "timer/agent.policy_frac": 0.004418362134845465, "timer/agent.policy_avg": 0.01624572101761313, "timer/agent.policy_min": 0.010245084762573242, "timer/agent.policy_max": 0.04130673408508301, "timer/dataset_train_count": 2177.0, "timer/dataset_train_total": 0.39894890785217285, "timer/dataset_train_frac": 0.00039890611500482037, "timer/dataset_train_avg": 0.00018325627370334078, "timer/dataset_train_min": 9.560585021972656e-05, "timer/dataset_train_max": 0.0018029212951660156, "timer/agent.train_count": 2177.0, "timer/agent.train_total": 967.6646509170532, "timer/agent.train_frac": 0.9675608553560676, "timer/agent.train_avg": 0.44449455715069053, "timer/agent.train_min": 0.43463778495788574, "timer/agent.train_max": 0.5624878406524658, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4785330295562744, "timer/agent.report_frac": 0.000478481700199347, "timer/agent.report_avg": 0.2392665147781372, "timer/agent.report_min": 0.23099493980407715, "timer/agent.report_max": 0.24753808975219727, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.314018249511719e-05, "timer/dataset_eval_frac": 3.313662774727145e-08, "timer/dataset_eval_avg": 3.314018249511719e-05, "timer/dataset_eval_min": 3.314018249511719e-05, "timer/dataset_eval_max": 3.314018249511719e-05, "fps": 2.1767378150008527}
{"step": 133624, "time": 61368.42502331734, "episode/length": 206.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9806763285024155, "episode/intrinsic_return": 0.0}
{"step": 133672, "time": 61391.66066288948, "episode/length": 142.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 133928, "time": 61508.57608127594, "episode/length": 256.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.980544747081712, "episode/intrinsic_return": 0.0}
{"step": 134248, "time": 61654.3694357872, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 134320, "time": 61688.33125448227, "episode/length": 215.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 134368, "time": 61711.87637758255, "episode/length": 127.0, "episode/score": 5.099999964237213, "episode/reward_rate": 0.9609375, "episode/intrinsic_return": 0.0}
{"step": 134464, "time": 61756.73234128952, "episode/length": 184.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 134536, "time": 61790.53884387016, "episode/length": 162.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 134904, "time": 61958.149287462234, "episode/length": 153.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9545454545454546, "episode/intrinsic_return": 0.0}
{"step": 134936, "time": 61973.997824430466, "episode/length": 163.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 135703, "time": 62321.16561079025, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.6124565786422655, "train/action_min": 0.0, "train/action_std": 4.009533551185643, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04903214052319527, "train/actor_opt_grad_steps": 133050.0, "train/actor_opt_loss": -15.938730052276833, "train/adv_mag": 0.9020209319243148, "train/adv_max": 0.8250614312141453, "train/adv_mean": 0.0026541192398895483, "train/adv_min": -0.6743997410279975, "train/adv_std": 0.06046726993502003, "train/cont_avg": 0.994439390696347, "train/cont_loss_mean": 3.389639142394478e-05, "train/cont_loss_std": 0.0010400934548779467, "train/cont_neg_acc": 0.9986681889181268, "train/cont_neg_loss": 0.003911595707663131, "train/cont_pos_acc": 0.9999999820369564, "train/cont_pos_loss": 7.245645970731462e-06, "train/cont_pred": 0.9944444508313044, "train/cont_rate": 0.994439390696347, "train/dyn_loss_mean": 3.045377705195179, "train/dyn_loss_std": 7.872234971555945, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.288783383968214, "train/extr_critic_critic_opt_grad_steps": 133050.0, "train/extr_critic_critic_opt_loss": 15137.994292237443, "train/extr_critic_mag": 14.089568969865912, "train/extr_critic_max": 14.089568969865912, "train/extr_critic_mean": 2.5425711260538666, "train/extr_critic_min": -0.6799139834974455, "train/extr_critic_std": 2.4480453354038603, "train/extr_return_normed_mag": 1.973274375205715, "train/extr_return_normed_max": 1.973274375205715, "train/extr_return_normed_mean": 0.37867728243135423, "train/extr_return_normed_min": -0.12388491980969633, "train/extr_return_normed_std": 0.3414375370359856, "train/extr_return_rate": 0.8217112411102748, "train/extr_return_raw_mag": 14.272288342044778, "train/extr_return_raw_max": 14.272288342044778, "train/extr_return_raw_mean": 2.5620597279779442, "train/extr_return_raw_min": -1.126167487336076, "train/extr_return_raw_std": 2.5081833693534814, "train/extr_reward_mag": 1.0309000995061168, "train/extr_reward_max": 1.0309000995061168, "train/extr_reward_mean": 0.032194612530744786, "train/extr_reward_min": -0.6811911167075101, "train/extr_reward_std": 0.18038331802305022, "train/image_loss_mean": 1.526973306316219, "train/image_loss_std": 4.787573999465873, "train/model_loss_mean": 3.3903920443635007, "train/model_loss_std": 8.596778212072643, "train/model_opt_grad_norm": 29.781735538342677, "train/model_opt_grad_steps": 132936.85844748857, "train/model_opt_loss": 7192.222862487514, "train/model_opt_model_opt_grad_overflow": 0.0045662100456621, "train/model_opt_model_opt_grad_scale": 2111.8721461187215, "train/policy_entropy_mag": 2.5115298419238226, "train/policy_entropy_max": 2.5115298419238226, "train/policy_entropy_mean": 0.5209640566616842, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.5931694855973056, "train/policy_logprob_mag": 7.438384045204615, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5214934957354036, "train/policy_logprob_min": -7.438384045204615, "train/policy_logprob_std": 1.091174383413846, "train/policy_randomness_mag": 0.8864598173529046, "train/policy_randomness_max": 0.8864598173529046, "train/policy_randomness_mean": 0.18387744929556432, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.2093627994463324, "train/post_ent_mag": 45.574920880740095, "train/post_ent_max": 45.574920880740095, "train/post_ent_mean": 27.295786504876123, "train/post_ent_min": 13.635502758635777, "train/post_ent_std": 4.6335013772799, "train/prior_ent_mag": 77.27354535664598, "train/prior_ent_max": 77.27354535664598, "train/prior_ent_mean": 30.230884691351626, "train/prior_ent_min": 14.981355257774597, "train/prior_ent_std": 8.830043283227372, "train/rep_loss_mean": 3.045377705195179, "train/rep_loss_std": 7.872234971555945, "train/reward_avg": 0.02048730000759981, "train/reward_loss_mean": 0.03615822860775473, "train/reward_loss_std": 0.1654130787201668, "train/reward_max_data": 1.0168949811970263, "train/reward_max_pred": 1.017087835699456, "train/reward_neg_acc": 0.9963864115275205, "train/reward_neg_loss": 0.018274857313903773, "train/reward_pos_acc": 0.9906862029746243, "train/reward_pos_loss": 0.7199839405273194, "train/reward_pred": 0.02034026838532866, "train/reward_rate": 0.025537778253424657, "train_stats/sum_log_reward": 4.199999928474426, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 4.3, "train_stats/max_log_achievement_collect_sapling": 1.6, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 2.1, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.6, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 0.7, "train_stats/max_log_achievement_wake_up": 2.2, "train_stats/mean_log_entropy": 0.5019093602895737, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 1.7387068510288373e-05, "report/cont_loss_std": 0.00033857603557407856, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.002710322616621852, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 6.826535354775842e-06, "report/cont_pred": 0.9960975050926208, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 3.272035598754883, "report/dyn_loss_std": 8.106701850891113, "report/image_loss_mean": 1.1868071556091309, "report/image_loss_std": 4.519107818603516, "report/model_loss_mean": 3.1906676292419434, "report/model_loss_std": 8.495774269104004, "report/post_ent_mag": 41.03962707519531, "report/post_ent_max": 41.03962707519531, "report/post_ent_mean": 27.91600227355957, "report/post_ent_min": 17.041152954101562, "report/post_ent_std": 3.9736807346343994, "report/prior_ent_mag": 77.31190490722656, "report/prior_ent_max": 77.31190490722656, "report/prior_ent_mean": 31.151155471801758, "report/prior_ent_min": 18.61536407470703, "report/prior_ent_std": 8.238001823425293, "report/rep_loss_mean": 3.272035598754883, "report/rep_loss_std": 8.106701850891113, "report/reward_avg": 0.03339843824505806, "report/reward_loss_mean": 0.04062196612358093, "report/reward_loss_std": 0.17057713866233826, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0053963661193848, "report/reward_neg_acc": 0.9908907413482666, "report/reward_neg_loss": 0.01754976250231266, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6738258004188538, "report/reward_pred": 0.033832356333732605, "report/reward_rate": 0.03515625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 4.296288807381643e-06, "eval/cont_loss_std": 8.60359887155937e-06, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 2.039994114966248e-06, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 4.305136826587841e-06, "eval/cont_pred": 0.9960894584655762, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 23.66720199584961, "eval/dyn_loss_std": 12.648529052734375, "eval/image_loss_mean": 36.125946044921875, "eval/image_loss_std": 39.16911697387695, "eval/model_loss_mean": 50.506900787353516, "eval/model_loss_std": 43.813446044921875, "eval/post_ent_mag": 46.38311004638672, "eval/post_ent_max": 46.38311004638672, "eval/post_ent_mean": 30.944799423217773, "eval/post_ent_min": 20.6676025390625, "eval/post_ent_std": 3.593541383743286, "eval/prior_ent_mag": 77.31190490722656, "eval/prior_ent_max": 77.31190490722656, "eval/prior_ent_mean": 41.217708587646484, "eval/prior_ent_min": 22.45931053161621, "eval/prior_ent_std": 7.823740482330322, "eval/rep_loss_mean": 23.66720199584961, "eval/rep_loss_std": 12.648529052734375, "eval/reward_avg": 0.02968750149011612, "eval/reward_loss_mean": 0.18062728643417358, "eval/reward_loss_std": 1.0104581117630005, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0012414455413818, "eval/reward_neg_acc": 0.9919109344482422, "eval/reward_neg_loss": 0.09251056611537933, "eval/reward_pos_acc": 0.6857143044471741, "eval/reward_pos_loss": 2.6705539226531982, "eval/reward_pred": 0.020748555660247803, "eval/reward_rate": 0.0341796875, "replay/size": 135199.0, "replay/inserts": 2184.0, "replay/samples": 34944.0, "replay/insert_wait_avg": 2.6595024835495723e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.56936686816233e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 26432.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 7.599592208862305e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2869379520416, "timer/env.step_count": 273.0, "timer/env.step_total": 22.73277521133423, "timer/env.step_frac": 0.022726254186500375, "timer/env.step_avg": 0.08327023886935615, "timer/env.step_min": 0.02358555793762207, "timer/env.step_max": 2.0298221111297607, "timer/replay._sample_count": 34944.0, "timer/replay._sample_total": 17.468701362609863, "timer/replay._sample_frac": 0.01746369036706085, "timer/replay._sample_avg": 0.0004999056021809141, "timer/replay._sample_min": 0.00035071372985839844, "timer/replay._sample_max": 0.03479957580566406, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 273.0, "timer/agent.policy_total": 4.410439968109131, "timer/agent.policy_frac": 0.004409174808519381, "timer/agent.policy_avg": 0.016155457758641505, "timer/agent.policy_min": 0.010332584381103516, "timer/agent.policy_max": 0.026652097702026367, "timer/dataset_train_count": 2184.0, "timer/dataset_train_total": 0.4439702033996582, "timer/dataset_train_frac": 0.0004438428480418128, "timer/dataset_train_avg": 0.00020328306016467867, "timer/dataset_train_min": 9.799003601074219e-05, "timer/dataset_train_max": 0.04192495346069336, "timer/agent.train_count": 2184.0, "timer/agent.train_total": 970.9192640781403, "timer/agent.train_frac": 0.9706407504090497, "timer/agent.train_avg": 0.44456010259988105, "timer/agent.train_min": 0.4308600425720215, "timer/agent.train_max": 0.5684642791748047, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.475494384765625, "timer/agent.report_frac": 0.00047535798651848673, "timer/agent.report_avg": 0.2377471923828125, "timer/agent.report_min": 0.23117995262145996, "timer/agent.report_max": 0.24431443214416504, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.147125244140625e-05, "timer/dataset_eval_frac": 3.14622247350741e-08, "timer/dataset_eval_avg": 3.147125244140625e-05, "timer/dataset_eval_min": 3.147125244140625e-05, "timer/dataset_eval_max": 3.147125244140625e-05, "fps": 2.1833456346082283}
{"step": 135720, "time": 62329.0122628212, "episode/length": 183.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 135736, "time": 62337.65476298332, "episode/length": 176.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 136080, "time": 62493.87919783592, "episode/length": 268.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9851301115241635, "episode/intrinsic_return": 0.0}
{"step": 136336, "time": 62610.60700535774, "episode/length": 233.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 136376, "time": 62629.94618797302, "episode/length": 183.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 136456, "time": 62667.385436058044, "episode/length": 189.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 136488, "time": 62683.249365091324, "episode/length": 243.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 136600, "time": 62735.392832279205, "episode/length": 64.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9230769230769231, "episode/intrinsic_return": 0.0}
{"step": 136952, "time": 62895.69042086601, "episode/length": 322.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9752321981424149, "episode/intrinsic_return": 0.0}
{"step": 137184, "time": 63001.63097548485, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 137528, "time": 63157.45867919922, "episode/length": 143.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 137728, "time": 63248.70489501953, "episode/length": 173.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9597701149425287, "episode/intrinsic_return": 0.0}
{"step": 137744, "time": 63257.328491687775, "episode/length": 156.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9617834394904459, "episode/intrinsic_return": 0.0}
{"step": 137792, "time": 63280.434019804, "episode/length": 258.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9961389961389961, "episode/intrinsic_return": 0.0}
{"step": 137879, "time": 63321.369784116745, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.6739786033806165, "train/action_min": 0.0, "train/action_std": 4.112703100327523, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04881496729183307, "train/actor_opt_grad_steps": 135230.0, "train/actor_opt_loss": -13.275864772520066, "train/adv_mag": 0.9005483371046831, "train/adv_max": 0.8023008778347948, "train/adv_mean": 0.0032601375900295324, "train/adv_min": -0.6789784647078009, "train/adv_std": 0.05978625810228735, "train/cont_avg": 0.9944376440092166, "train/cont_loss_mean": 1.850120697424113e-05, "train/cont_loss_std": 0.0005165172354330021, "train/cont_neg_acc": 1.0, "train/cont_neg_loss": 0.0008691639262160355, "train/cont_pos_acc": 0.9999954475235829, "train/cont_pos_loss": 1.3822784364231268e-05, "train/cont_pred": 0.9944323191444995, "train/cont_rate": 0.9944376440092166, "train/dyn_loss_mean": 3.022588496933335, "train/dyn_loss_std": 7.85701829497166, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.3359903717919979, "train/extr_critic_critic_opt_grad_steps": 135230.0, "train/extr_critic_critic_opt_loss": 15367.94419642857, "train/extr_critic_mag": 14.017831705682289, "train/extr_critic_max": 14.017831705682289, "train/extr_critic_mean": 2.599560824956762, "train/extr_critic_min": -0.6625132214638495, "train/extr_critic_std": 2.50308624775179, "train/extr_return_normed_mag": 1.907602450265313, "train/extr_return_normed_max": 1.907602450265313, "train/extr_return_normed_mean": 0.37201361090356855, "train/extr_return_normed_min": -0.11271071262348632, "train/extr_return_normed_std": 0.33616321592286985, "train/extr_return_rate": 0.8170498351347611, "train/extr_return_raw_mag": 14.334147923553045, "train/extr_return_raw_max": 14.334147923553045, "train/extr_return_raw_mean": 2.6244603109799223, "train/extr_return_raw_min": -1.0734052207612772, "train/extr_return_raw_std": 2.5643651408533894, "train/extr_reward_mag": 1.0243254103418868, "train/extr_reward_max": 1.0243254103418868, "train/extr_reward_mean": 0.03170048838592894, "train/extr_reward_min": -0.6800714615852602, "train/extr_reward_std": 0.17939688292791217, "train/image_loss_mean": 1.5441007586668163, "train/image_loss_std": 4.774738039289202, "train/model_loss_mean": 3.394285231691352, "train/model_loss_std": 8.590035053991503, "train/model_opt_grad_norm": 30.092781141606345, "train/model_opt_grad_steps": 135115.55760368664, "train/model_opt_loss": 8341.86926438292, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2465.4377880184334, "train/policy_entropy_mag": 2.498496707133983, "train/policy_entropy_max": 2.498496707133983, "train/policy_entropy_mean": 0.5213091626145323, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.595949512198224, "train/policy_logprob_mag": 7.438384060486121, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5210794136271498, "train/policy_logprob_min": -7.438384060486121, "train/policy_logprob_std": 1.0902412421143, "train/policy_randomness_mag": 0.8818596939337419, "train/policy_randomness_max": 0.8818596939337419, "train/policy_randomness_mean": 0.18399925801199152, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.21034402678364433, "train/post_ent_mag": 45.57156934606315, "train/post_ent_max": 45.57156934606315, "train/post_ent_mean": 27.460370859242804, "train/post_ent_min": 13.731583278849378, "train/post_ent_std": 4.68510879459469, "train/prior_ent_mag": 77.29176467684557, "train/prior_ent_max": 77.29176467684557, "train/prior_ent_mean": 30.39481565589729, "train/prior_ent_min": 15.234015100013275, "train/prior_ent_std": 8.822705565509708, "train/rep_loss_mean": 3.022588496933335, "train/rep_loss_std": 7.85701829497166, "train/reward_avg": 0.020625269993246976, "train/reward_loss_mean": 0.03661288911571151, "train/reward_loss_std": 0.16499542266405123, "train/reward_max_data": 1.0124423992798626, "train/reward_max_pred": 1.013086531568782, "train/reward_neg_acc": 0.996290740329549, "train/reward_neg_loss": 0.01883335755751704, "train/reward_pos_acc": 0.9911883781033177, "train/reward_pos_loss": 0.7127483176745577, "train/reward_pred": 0.020537437139345065, "train/reward_rate": 0.025633640552995392, "train_stats/sum_log_reward": 4.7428571326392035, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 4.142857142857143, "train_stats/max_log_achievement_collect_sapling": 1.9285714285714286, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 2.9285714285714284, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.07142857142857142, "train_stats/max_log_achievement_make_wood_sword": 0.14285714285714285, "train_stats/max_log_achievement_place_plant": 1.9285714285714286, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 1.2142857142857142, "train_stats/max_log_achievement_wake_up": 2.5, "train_stats/mean_log_entropy": 0.544241651892662, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 9.167215466732159e-07, "report/cont_loss_std": 2.2004724087310024e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 4.733457899419591e-06, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 8.942260478761455e-07, "report/cont_pred": 0.9941397905349731, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 2.8911547660827637, "report/dyn_loss_std": 7.756804466247559, "report/image_loss_mean": 1.38214910030365, "report/image_loss_std": 4.402105331420898, "report/model_loss_mean": 3.1555864810943604, "report/model_loss_std": 8.365763664245605, "report/post_ent_mag": 46.49299621582031, "report/post_ent_max": 46.49299621582031, "report/post_ent_mean": 27.296600341796875, "report/post_ent_min": 12.03917121887207, "report/post_ent_std": 5.042106628417969, "report/prior_ent_mag": 77.27398681640625, "report/prior_ent_max": 77.27398681640625, "report/prior_ent_mean": 30.216785430908203, "report/prior_ent_min": 13.789838790893555, "report/prior_ent_std": 9.009352684020996, "report/rep_loss_mean": 2.8911547660827637, "report/rep_loss_std": 7.756804466247559, "report/reward_avg": 0.02451171912252903, "report/reward_loss_mean": 0.03874345123767853, "report/reward_loss_std": 0.154853954911232, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.0665621757507324, "report/reward_neg_acc": 0.9929577112197876, "report/reward_neg_loss": 0.01855866238474846, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7075327634811401, "report/reward_pred": 0.024128161370754242, "report/reward_rate": 0.029296875, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.0025555300526320934, "eval/cont_loss_std": 0.04889979213476181, "eval/cont_neg_acc": 0.800000011920929, "eval/cont_neg_loss": 0.5050326585769653, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 8.998943667393178e-05, "eval/cont_pred": 0.9966386556625366, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 24.533828735351562, "eval/dyn_loss_std": 13.414962768554688, "eval/image_loss_mean": 38.64049530029297, "eval/image_loss_std": 42.72698211669922, "eval/model_loss_mean": 53.52505111694336, "eval/model_loss_std": 47.85797119140625, "eval/post_ent_mag": 44.10818862915039, "eval/post_ent_max": 44.10818862915039, "eval/post_ent_mean": 31.355758666992188, "eval/post_ent_min": 18.62564468383789, "eval/post_ent_std": 4.078634738922119, "eval/prior_ent_mag": 77.27398681640625, "eval/prior_ent_max": 77.27398681640625, "eval/prior_ent_mean": 42.933326721191406, "eval/prior_ent_min": 25.88886260986328, "eval/prior_ent_std": 7.7666425704956055, "eval/rep_loss_mean": 24.533828735351562, "eval/rep_loss_std": 13.414962768554688, "eval/reward_avg": 0.01806640625, "eval/reward_loss_mean": 0.16170762479305267, "eval/reward_loss_std": 0.9995339512825012, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9993938207626343, "eval/reward_neg_acc": 0.9950049519538879, "eval/reward_neg_loss": 0.11944226920604706, "eval/reward_pos_acc": 0.782608687877655, "eval/reward_pos_loss": 2.001168966293335, "eval/reward_pred": 0.015273930504918098, "eval/reward_rate": 0.0224609375, "replay/size": 137375.0, "replay/inserts": 2176.0, "replay/samples": 34816.0, "replay/insert_wait_avg": 2.633670673650854e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.499885909697588e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 26432.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 9.08970832824707e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1928939819336, "timer/env.step_count": 272.0, "timer/env.step_total": 27.853661060333252, "timer/env.step_frac": 0.0278482892929215, "timer/env.step_avg": 0.1024031656629899, "timer/env.step_min": 0.023807287216186523, "timer/env.step_max": 1.5903055667877197, "timer/replay._sample_count": 34816.0, "timer/replay._sample_total": 17.15719509124756, "timer/replay._sample_frac": 0.01715388620983091, "timer/replay._sample_avg": 0.0004927962744498954, "timer/replay._sample_min": 0.0003769397735595703, "timer/replay._sample_max": 0.029266834259033203, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 272.0, "timer/agent.policy_total": 4.356669902801514, "timer/agent.policy_frac": 0.004355829689468088, "timer/agent.policy_avg": 0.016017168760299683, "timer/agent.policy_min": 0.009711742401123047, "timer/agent.policy_max": 0.02969074249267578, "timer/dataset_train_count": 2176.0, "timer/dataset_train_total": 0.46947288513183594, "timer/dataset_train_frac": 0.0004693823441024327, "timer/dataset_train_avg": 0.0002157504067701452, "timer/dataset_train_min": 9.560585021972656e-05, "timer/dataset_train_max": 0.06916570663452148, "timer/agent.train_count": 2176.0, "timer/agent.train_total": 965.7451384067535, "timer/agent.train_frac": 0.9655588879080735, "timer/agent.train_avg": 0.4438166996354566, "timer/agent.train_min": 0.43169736862182617, "timer/agent.train_max": 0.5607500076293945, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47301626205444336, "timer/agent.report_frac": 0.0004729250376607729, "timer/agent.report_avg": 0.23650813102722168, "timer/agent.report_min": 0.22914409637451172, "timer/agent.report_max": 0.24387216567993164, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 4.363059997558594e-05, "timer/dataset_eval_frac": 4.362218551852062e-08, "timer/dataset_eval_avg": 4.363059997558594e-05, "timer/dataset_eval_min": 4.363059997558594e-05, "timer/dataset_eval_max": 4.363059997558594e-05, "fps": 2.1755530843618995}
{"step": 138136, "time": 63436.62500786781, "episode/length": 209.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 138392, "time": 63553.09130239487, "episode/length": 150.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 138488, "time": 63597.592873334885, "episode/length": 191.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 138640, "time": 63666.90950226784, "episode/length": 138.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.0}
{"step": 138728, "time": 63707.64247465134, "episode/length": 265.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9962406015037594, "episode/intrinsic_return": 0.0}
{"step": 138872, "time": 63773.469353437424, "episode/length": 142.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 138960, "time": 63814.17167544365, "episode/length": 145.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9657534246575342, "episode/intrinsic_return": 0.0}
{"step": 139128, "time": 63890.39300107956, "episode/length": 172.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 139272, "time": 63957.047112226486, "episode/length": 141.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 139800, "time": 64193.98453593254, "episode/length": 175.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 140000, "time": 64284.59476995468, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 140040, "time": 64304.10969090462, "episode/length": 145.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 140075, "time": 64321.735892534256, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.6615148370916195, "train/action_min": 0.0, "train/action_std": 4.134640521352941, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.046306524468077856, "train/actor_opt_grad_steps": 137415.0, "train/actor_opt_loss": -12.575711878185922, "train/adv_mag": 0.7300571517510848, "train/adv_max": 0.6558207463134419, "train/adv_mean": 0.0027385981951572997, "train/adv_min": -0.595713409781456, "train/adv_std": 0.05473879694261334, "train/cont_avg": 0.9942915482954545, "train/cont_loss_mean": 1.8894160833388636e-05, "train/cont_loss_std": 0.0005621333963615365, "train/cont_neg_acc": 1.0, "train/cont_neg_loss": 0.0008719769519119195, "train/cont_pos_acc": 0.9999910308556124, "train/cont_pos_loss": 1.3603861466519747e-05, "train/cont_pred": 0.9942875704982064, "train/cont_rate": 0.9942915482954545, "train/dyn_loss_mean": 2.9907171791250056, "train/dyn_loss_std": 7.824162611094388, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.3283241667530754, "train/extr_critic_critic_opt_grad_steps": 137415.0, "train/extr_critic_critic_opt_loss": 15363.907879083807, "train/extr_critic_mag": 12.980561421134254, "train/extr_critic_max": 12.980561421134254, "train/extr_critic_mean": 2.778791517561132, "train/extr_critic_min": -0.6927827938036485, "train/extr_critic_std": 2.5970794477246026, "train/extr_return_normed_mag": 1.6662923634052276, "train/extr_return_normed_max": 1.6662923634052276, "train/extr_return_normed_mean": 0.3689161129295826, "train/extr_return_normed_min": -0.11294761128215627, "train/extr_return_normed_std": 0.32420569082552736, "train/extr_return_rate": 0.8247058911757036, "train/extr_return_raw_mag": 13.409776856682518, "train/extr_return_raw_max": 13.409776856682518, "train/extr_return_raw_mean": 2.8011668254028668, "train/extr_return_raw_min": -1.1376267714933916, "train/extr_return_raw_std": 2.650529528206045, "train/extr_reward_mag": 1.0282870054244995, "train/extr_reward_max": 1.0282870054244995, "train/extr_reward_mean": 0.031208810430358756, "train/extr_reward_min": -0.6772560807791623, "train/extr_reward_std": 0.1779557688331062, "train/image_loss_mean": 1.4608014686541124, "train/image_loss_std": 4.52476935711774, "train/model_loss_mean": 3.2923501177267593, "train/model_loss_std": 8.350815861875361, "train/model_opt_grad_norm": 28.999479428204623, "train/model_opt_grad_steps": 137298.45, "train/model_opt_loss": 8379.964173473012, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2545.4545454545455, "train/policy_entropy_mag": 2.511110246181488, "train/policy_entropy_max": 2.511110246181488, "train/policy_entropy_mean": 0.5185145699165085, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.596767921610312, "train/policy_logprob_mag": 7.4383840409192175, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5182269997217438, "train/policy_logprob_min": -7.4383840409192175, "train/policy_logprob_std": 1.0882162216034803, "train/policy_randomness_mag": 0.8863117212598974, "train/policy_randomness_max": 0.8863117212598974, "train/policy_randomness_mean": 0.18301288803870028, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.2106328897178173, "train/post_ent_mag": 46.2030816338279, "train/post_ent_max": 46.2030816338279, "train/post_ent_mean": 27.80063033537431, "train/post_ent_min": 13.862791494889693, "train/post_ent_std": 4.683354219523343, "train/prior_ent_mag": 77.27241859436035, "train/prior_ent_max": 77.27241859436035, "train/prior_ent_mean": 30.67585868835449, "train/prior_ent_min": 15.256003154407848, "train/prior_ent_std": 8.807440833611922, "train/rep_loss_mean": 2.9907171791250056, "train/rep_loss_std": 7.824162611094388, "train/reward_avg": 0.02102583434686742, "train/reward_loss_mean": 0.03709943471476436, "train/reward_loss_std": 0.1656109626658938, "train/reward_max_data": 1.0150000035762787, "train/reward_max_pred": 1.0163995612751353, "train/reward_neg_acc": 0.9965356940572913, "train/reward_neg_loss": 0.019083634607324547, "train/reward_pos_acc": 0.99329924502156, "train/reward_pos_loss": 0.7068328727375377, "train/reward_pred": 0.020928372152742337, "train/reward_rate": 0.026162997159090907, "train_stats/sum_log_reward": 4.5999999443689985, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 2.1666666666666665, "train_stats/max_log_achievement_collect_sapling": 1.8333333333333333, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 3.5, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.5, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.8333333333333333, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 1.4166666666666667, "train_stats/max_log_achievement_wake_up": 1.5833333333333333, "train_stats/mean_log_entropy": 0.47506603598594666, "report/cont_avg": 0.9912109375, "report/cont_loss_mean": 7.120499958546134e-07, "report/cont_loss_std": 2.272381152579328e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 9.05587603483582e-06, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 6.380653871929098e-07, "report/cont_pred": 0.9912104606628418, "report/cont_rate": 0.9912109375, "report/dyn_loss_mean": 2.9064013957977295, "report/dyn_loss_std": 8.268050193786621, "report/image_loss_mean": 1.626375675201416, "report/image_loss_std": 4.213191032409668, "report/model_loss_mean": 3.411745071411133, "report/model_loss_std": 8.440810203552246, "report/post_ent_mag": 46.727020263671875, "report/post_ent_max": 46.727020263671875, "report/post_ent_mean": 27.06728744506836, "report/post_ent_min": 10.351367950439453, "report/post_ent_std": 5.181917190551758, "report/prior_ent_mag": 76.93546295166016, "report/prior_ent_max": 76.93546295166016, "report/prior_ent_mean": 29.915931701660156, "report/prior_ent_min": 14.926932334899902, "report/prior_ent_std": 9.379910469055176, "report/rep_loss_mean": 2.9064013957977295, "report/rep_loss_std": 8.268050193786621, "report/reward_avg": 0.015527344308793545, "report/reward_loss_mean": 0.04152775555849075, "report/reward_loss_std": 0.17660854756832123, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0006499290466309, "report/reward_neg_acc": 0.9940000176429749, "report/reward_neg_loss": 0.026341183111071587, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.67430180311203, "report/reward_pred": 0.016145531088113785, "report/reward_rate": 0.0234375, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.005858144722878933, "eval/cont_loss_std": 0.1872422695159912, "eval/cont_neg_acc": 0.6666666865348816, "eval/cont_neg_loss": 1.9993431568145752, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 6.96345011874655e-07, "eval/cont_pred": 0.9980470538139343, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 22.681915283203125, "eval/dyn_loss_std": 14.363842010498047, "eval/image_loss_mean": 35.293296813964844, "eval/image_loss_std": 46.879364013671875, "eval/model_loss_mean": 49.070648193359375, "eval/model_loss_std": 52.89564895629883, "eval/post_ent_mag": 46.727020263671875, "eval/post_ent_max": 46.727020263671875, "eval/post_ent_mean": 31.16981315612793, "eval/post_ent_min": 17.83880043029785, "eval/post_ent_std": 3.8409359455108643, "eval/prior_ent_mag": 76.93546295166016, "eval/prior_ent_max": 76.93546295166016, "eval/prior_ent_mean": 41.98127746582031, "eval/prior_ent_min": 23.71310806274414, "eval/prior_ent_std": 8.026246070861816, "eval/rep_loss_mean": 22.681915283203125, "eval/rep_loss_std": 14.363842010498047, "eval/reward_avg": 0.02958984300494194, "eval/reward_loss_mean": 0.16234229505062103, "eval/reward_loss_std": 1.0516858100891113, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0012214183807373, "eval/reward_neg_acc": 0.9939393401145935, "eval/reward_neg_loss": 0.09253299236297607, "eval/reward_pos_acc": 0.8235294222831726, "eval/reward_pos_loss": 2.1950249671936035, "eval/reward_pred": 0.0254475437104702, "eval/reward_rate": 0.033203125, "replay/size": 139571.0, "replay/inserts": 2196.0, "replay/samples": 35136.0, "replay/insert_wait_avg": 2.6327013318004504e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.224756077556228e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 26432.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 7.301568984985352e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3537318706512, "timer/env.step_count": 275.0, "timer/env.step_total": 25.480063438415527, "timer/env.step_frac": 0.025471053515008207, "timer/env.step_avg": 0.09265477613969282, "timer/env.step_min": 0.023508071899414062, "timer/env.step_max": 1.99666166305542, "timer/replay._sample_count": 35136.0, "timer/replay._sample_total": 16.985652923583984, "timer/replay._sample_frac": 0.016979646681400375, "timer/replay._sample_avg": 0.00048342591426411613, "timer/replay._sample_min": 0.0003490447998046875, "timer/replay._sample_max": 0.014010906219482422, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 275.0, "timer/agent.policy_total": 4.384852886199951, "timer/agent.policy_frac": 0.004383302372452114, "timer/agent.policy_avg": 0.01594491958618164, "timer/agent.policy_min": 0.00977778434753418, "timer/agent.policy_max": 0.04322004318237305, "timer/dataset_train_count": 2196.0, "timer/dataset_train_total": 0.4391202926635742, "timer/dataset_train_frac": 0.00043896501674704986, "timer/dataset_train_avg": 0.00019996370339871321, "timer/dataset_train_min": 8.988380432128906e-05, "timer/dataset_train_max": 0.04654335975646973, "timer/agent.train_count": 2196.0, "timer/agent.train_total": 968.2174592018127, "timer/agent.train_frac": 0.9678750909353394, "timer/agent.train_avg": 0.4409004823323373, "timer/agent.train_min": 0.4288444519042969, "timer/agent.train_max": 0.5708725452423096, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4729125499725342, "timer/agent.report_frac": 0.0004727453248844212, "timer/agent.report_avg": 0.2364562749862671, "timer/agent.report_min": 0.2299060821533203, "timer/agent.report_max": 0.24300646781921387, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.075599670410156e-05, "timer/dataset_eval_frac": 3.074512117487497e-08, "timer/dataset_eval_avg": 3.075599670410156e-05, "timer/dataset_eval_min": 3.075599670410156e-05, "timer/dataset_eval_max": 3.075599670410156e-05, "fps": 2.195195199489451}
{"step": 140088, "time": 64345.39048242569, "eval_episode/length": 135.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9926470588235294}
{"step": 140088, "time": 64348.33463382721, "eval_episode/length": 158.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9622641509433962}
{"step": 140088, "time": 64351.062309503555, "eval_episode/length": 173.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9942528735632183}
{"step": 140088, "time": 64353.21339559555, "eval_episode/length": 177.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9662921348314607}
{"step": 140088, "time": 64355.682971954346, "eval_episode/length": 189.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 140088, "time": 64357.97978377342, "eval_episode/length": 200.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9800995024875622}
{"step": 140088, "time": 64360.32840204239, "eval_episode/length": 209.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9666666666666667}
{"step": 140088, "time": 64363.196056604385, "eval_episode/length": 55.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9107142857142857}
{"step": 140152, "time": 64391.83624124527, "episode/length": 109.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9454545454545454, "episode/intrinsic_return": 0.0}
{"step": 140320, "time": 64468.55336046219, "episode/length": 228.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9694323144104804, "episode/intrinsic_return": 0.0}
{"step": 140368, "time": 64491.49001407623, "episode/length": 204.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 140760, "time": 64668.18074011803, "episode/length": 224.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 140816, "time": 64694.75677275658, "episode/length": 210.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 141296, "time": 64911.00213050842, "episode/length": 161.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9567901234567902, "episode/intrinsic_return": 0.0}
{"step": 141344, "time": 64933.95142579079, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 141384, "time": 64953.429985284805, "episode/length": 153.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 141416, "time": 64969.27694439888, "episode/length": 136.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9635036496350365, "episode/intrinsic_return": 0.0}
{"step": 141464, "time": 64992.151163101196, "episode/length": 207.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 141856, "time": 65168.72924852371, "episode/length": 185.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 142056, "time": 65259.47614955902, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 142192, "time": 65322.1442322731, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.913844846329599, "train/action_min": 0.0, "train/action_std": 4.229291508782585, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04517670249882734, "train/actor_opt_grad_steps": 139575.0, "train/actor_opt_loss": -17.66643906820495, "train/adv_mag": 0.727772149274934, "train/adv_max": 0.6389019288263231, "train/adv_mean": 0.0012959243150053568, "train/adv_min": -0.5676535185215608, "train/adv_std": 0.05323282588835595, "train/cont_avg": 0.9944584684551887, "train/cont_loss_mean": 2.9368847951777195e-05, "train/cont_loss_std": 0.0008651515009117387, "train/cont_neg_acc": 0.9988862683750549, "train/cont_neg_loss": 0.0013892700424201325, "train/cont_pos_acc": 0.9999953390292402, "train/cont_pos_loss": 1.8239688131382672e-05, "train/cont_pred": 0.9944521818520888, "train/cont_rate": 0.9944584684551887, "train/dyn_loss_mean": 3.01714810672796, "train/dyn_loss_std": 7.864112698806907, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.2619966282597128, "train/extr_critic_critic_opt_grad_steps": 139575.0, "train/extr_critic_critic_opt_loss": 14866.998696381192, "train/extr_critic_mag": 13.036516900332469, "train/extr_critic_max": 13.036516900332469, "train/extr_critic_mean": 2.638492003926691, "train/extr_critic_min": -0.6596838944363144, "train/extr_critic_std": 2.401441696117509, "train/extr_return_normed_mag": 1.7768250776911683, "train/extr_return_normed_max": 1.7768250776911683, "train/extr_return_normed_mean": 0.37808600068092346, "train/extr_return_normed_min": -0.11466451181661126, "train/extr_return_normed_std": 0.32481433366829493, "train/extr_return_rate": 0.8260776400566101, "train/extr_return_raw_mag": 13.146540259415248, "train/extr_return_raw_max": 13.146540259415248, "train/extr_return_raw_mean": 2.6483006094986536, "train/extr_return_raw_min": -1.0493680761670166, "train/extr_return_raw_std": 2.44056839369378, "train/extr_reward_mag": 1.026847020635065, "train/extr_reward_max": 1.026847020635065, "train/extr_reward_mean": 0.029531851823810698, "train/extr_reward_min": -0.6721354936653713, "train/extr_reward_std": 0.17351144151586406, "train/image_loss_mean": 1.4860251200086665, "train/image_loss_std": 4.547732127162646, "train/model_loss_mean": 3.332397954643897, "train/model_loss_std": 8.387961506843567, "train/model_opt_grad_norm": 30.795088453112907, "train/model_opt_grad_steps": 139456.0896226415, "train/model_opt_loss": 6307.455811698482, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1910.377358490566, "train/policy_entropy_mag": 2.522303878136401, "train/policy_entropy_max": 2.522303878136401, "train/policy_entropy_mean": 0.5489165953026628, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6182910805603243, "train/policy_logprob_mag": 7.438384026851294, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.548497384308644, "train/policy_logprob_min": -7.438384026851294, "train/policy_logprob_std": 1.1041370427833412, "train/policy_randomness_mag": 0.8902625801428309, "train/policy_randomness_max": 0.8902625801428309, "train/policy_randomness_mean": 0.1937434716185309, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.21822962066474952, "train/post_ent_mag": 46.081171251692865, "train/post_ent_max": 46.081171251692865, "train/post_ent_mean": 27.982846862864942, "train/post_ent_min": 14.03380915353883, "train/post_ent_std": 4.727483438995649, "train/prior_ent_mag": 77.34209380959565, "train/prior_ent_max": 77.34209380959565, "train/prior_ent_mean": 30.895604781384737, "train/prior_ent_min": 15.453523604375011, "train/prior_ent_std": 8.804421739758185, "train/rep_loss_mean": 3.01714810672796, "train/rep_loss_std": 7.864112698806907, "train/reward_avg": 0.020344284147832473, "train/reward_loss_mean": 0.0360546152740014, "train/reward_loss_std": 0.16195724082161794, "train/reward_max_data": 1.0146226449957434, "train/reward_max_pred": 1.0154553376278788, "train/reward_neg_acc": 0.9963316655946228, "train/reward_neg_loss": 0.01844199264711999, "train/reward_pos_acc": 0.9905824464447094, "train/reward_pos_loss": 0.7141664975656653, "train/reward_pred": 0.020201590329514078, "train/reward_rate": 0.025362986438679246, "eval_stats/sum_log_reward": 3.474999975413084, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 2.5, "eval_stats/max_log_achievement_collect_sapling": 1.125, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 2.75, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.375, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 1.125, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 1.0, "eval_stats/max_log_achievement_wake_up": 2.125, "eval_stats/mean_log_entropy": 0.0, "train_stats/sum_log_reward": 4.099999913324912, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 2.6666666666666665, "train_stats/max_log_achievement_collect_sapling": 1.5, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 3.6666666666666665, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.4166666666666667, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.5, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 1.5, "train_stats/max_log_achievement_wake_up": 2.0833333333333335, "train_stats/mean_log_entropy": 0.5596157809098562, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 1.1959425592067419e-06, "report/cont_loss_std": 4.790380444319453e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 5.925108780502342e-06, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.168069275081507e-06, "report/cont_pred": 0.9941394925117493, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 2.7345619201660156, "report/dyn_loss_std": 7.570212364196777, "report/image_loss_mean": 1.1210956573486328, "report/image_loss_std": 4.612669944763184, "report/model_loss_mean": 2.7926173210144043, "report/model_loss_std": 8.277379035949707, "report/post_ent_mag": 48.08711624145508, "report/post_ent_max": 48.08711624145508, "report/post_ent_mean": 26.933013916015625, "report/post_ent_min": 13.922691345214844, "report/post_ent_std": 4.993873596191406, "report/prior_ent_mag": 77.11198425292969, "report/prior_ent_max": 77.11198425292969, "report/prior_ent_mean": 29.4742431640625, "report/prior_ent_min": 14.427375793457031, "report/prior_ent_std": 8.955501556396484, "report/rep_loss_mean": 2.7345619201660156, "report/rep_loss_std": 7.570212364196777, "report/reward_avg": 0.0146484375, "report/reward_loss_mean": 0.030783452093601227, "report/reward_loss_std": 0.13224036991596222, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.001840353012085, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.01797735132277012, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.673649787902832, "report/reward_pred": 0.014776326715946198, "report/reward_rate": 0.01953125, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.010250668041408062, "eval/cont_loss_std": 0.28446754813194275, "eval/cont_neg_acc": 0.6666666865348816, "eval/cont_neg_loss": 1.7396903038024902, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 5.750797572545707e-05, "eval/cont_pred": 0.9958324432373047, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 23.980262756347656, "eval/dyn_loss_std": 11.305685997009277, "eval/image_loss_mean": 36.119117736816406, "eval/image_loss_std": 33.658775329589844, "eval/model_loss_mean": 50.70819091796875, "eval/model_loss_std": 37.675201416015625, "eval/post_ent_mag": 48.08711624145508, "eval/post_ent_max": 48.08711624145508, "eval/post_ent_mean": 31.41324234008789, "eval/post_ent_min": 15.318878173828125, "eval/post_ent_std": 3.9467225074768066, "eval/prior_ent_mag": 77.11198425292969, "eval/prior_ent_max": 77.11198425292969, "eval/prior_ent_mean": 42.83513641357422, "eval/prior_ent_min": 18.639490127563477, "eval/prior_ent_std": 7.265706539154053, "eval/rep_loss_mean": 23.980262756347656, "eval/rep_loss_std": 11.305685997009277, "eval/reward_avg": 0.02109375037252903, "eval/reward_loss_mean": 0.19066080451011658, "eval/reward_loss_std": 1.0538285970687866, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0006530284881592, "eval/reward_neg_acc": 0.9969940185546875, "eval/reward_neg_loss": 0.12355078011751175, "eval/reward_pos_acc": 0.692307710647583, "eval/reward_pos_loss": 2.766653537750244, "eval/reward_pred": 0.017018252983689308, "eval/reward_rate": 0.025390625, "replay/size": 141688.0, "replay/inserts": 2117.0, "replay/samples": 33872.0, "replay/insert_wait_avg": 2.5832996539592066e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.269964727186402e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 28272.0, "eval_replay/inserts": 1840.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1111083238021187e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1920928955078125e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3932824134827, "timer/env.step_count": 264.0, "timer/env.step_total": 25.33385467529297, "timer/env.step_frac": 0.025323895232657087, "timer/env.step_avg": 0.0959615707397461, "timer/env.step_min": 0.02349567413330078, "timer/env.step_max": 1.9350993633270264, "timer/replay._sample_count": 33872.0, "timer/replay._sample_total": 16.394542932510376, "timer/replay._sample_frac": 0.016388097781862336, "timer/replay._sample_avg": 0.00048401461184785, "timer/replay._sample_min": 0.0003669261932373047, "timer/replay._sample_max": 0.010214805603027344, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 494.0, "timer/agent.policy_total": 7.923333168029785, "timer/agent.policy_frac": 0.007920218285467167, "timer/agent.policy_avg": 0.01603913596767163, "timer/agent.policy_min": 0.009686946868896484, "timer/agent.policy_max": 0.049688100814819336, "timer/dataset_train_count": 2117.0, "timer/dataset_train_total": 0.37314724922180176, "timer/dataset_train_frac": 0.00037300055466343336, "timer/dataset_train_avg": 0.00017626228116287282, "timer/dataset_train_min": 8.726119995117188e-05, "timer/dataset_train_max": 0.0008094310760498047, "timer/agent.train_count": 2117.0, "timer/agent.train_total": 933.3342018127441, "timer/agent.train_frac": 0.9329672821883047, "timer/agent.train_avg": 0.4408758629252452, "timer/agent.train_min": 0.4322805404663086, "timer/agent.train_max": 0.5682692527770996, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.474229097366333, "timer/agent.report_frac": 0.00047404266472305697, "timer/agent.report_avg": 0.2371145486831665, "timer/agent.report_min": 0.2302079200744629, "timer/agent.report_max": 0.24402117729187012, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7894973754882812e-05, "timer/dataset_eval_frac": 2.788400746512936e-08, "timer/dataset_eval_avg": 2.7894973754882812e-05, "timer/dataset_eval_min": 2.7894973754882812e-05, "timer/dataset_eval_max": 2.7894973754882812e-05, "fps": 2.116142252577875}
{"step": 142216, "time": 65333.11357998848, "episode/length": 174.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 142472, "time": 65449.66180610657, "episode/length": 135.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.0}
{"step": 142608, "time": 65512.241936683655, "episode/length": 148.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 142672, "time": 65542.90442824364, "episode/length": 150.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 142824, "time": 65612.56643104553, "episode/length": 190.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 143000, "time": 65693.43027973175, "episode/length": 142.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 143440, "time": 65892.284948349, "episode/length": 172.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 143584, "time": 65958.4761428833, "episode/length": 170.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 143960, "time": 66128.40885472298, "episode/length": 141.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 144056, "time": 66172.84503412247, "episode/length": 180.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 144160, "time": 66220.92229437828, "episode/length": 210.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 144216, "time": 66247.60921216011, "episode/length": 192.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 144378, "time": 66322.90571689606, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.779072332819667, "train/action_min": 0.0, "train/action_std": 4.222011691933378, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04814562948266848, "train/actor_opt_grad_steps": 141725.0, "train/actor_opt_loss": -17.67666137888344, "train/adv_mag": 0.7437498456020968, "train/adv_max": 0.6789933043882388, "train/adv_mean": 0.0018226810369081608, "train/adv_min": -0.5993806310339805, "train/adv_std": 0.056818027168922466, "train/cont_avg": 0.9942794939793578, "train/cont_loss_mean": 2.0935757102166596e-05, "train/cont_loss_std": 0.0006152165341880332, "train/cont_neg_acc": 1.0, "train/cont_neg_loss": 0.0007579670671125022, "train/cont_pos_acc": 0.9999954736014025, "train/cont_pos_loss": 1.7769383381523568e-05, "train/cont_pred": 0.9942733202505549, "train/cont_rate": 0.9942794939793578, "train/dyn_loss_mean": 3.05198332913425, "train/dyn_loss_std": 7.877928663831239, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.269000116564812, "train/extr_critic_critic_opt_grad_steps": 141725.0, "train/extr_critic_critic_opt_loss": 14972.692880053039, "train/extr_critic_mag": 12.020586009419292, "train/extr_critic_max": 12.020586009419292, "train/extr_critic_mean": 2.4410759172308336, "train/extr_critic_min": -0.6754998788921112, "train/extr_critic_std": 2.2408765313822196, "train/extr_return_normed_mag": 1.8115449925081446, "train/extr_return_normed_max": 1.8115449925081446, "train/extr_return_normed_mean": 0.38876164670384256, "train/extr_return_normed_min": -0.13713924096333324, "train/extr_return_normed_std": 0.3321491302836926, "train/extr_return_rate": 0.8128294444412266, "train/extr_return_raw_mag": 12.225988512739129, "train/extr_return_raw_max": 12.225988512739129, "train/extr_return_raw_mean": 2.453600083469251, "train/extr_return_raw_min": -1.1557593750297477, "train/extr_return_raw_std": 2.2811250008574318, "train/extr_reward_mag": 1.027927141670787, "train/extr_reward_max": 1.027927141670787, "train/extr_reward_mean": 0.030513108161132816, "train/extr_reward_min": -0.6723734468495081, "train/extr_reward_std": 0.1761473079955359, "train/image_loss_mean": 1.4986107811468456, "train/image_loss_std": 4.664622272920171, "train/model_loss_mean": 3.366785876247861, "train/model_loss_std": 8.483480718157708, "train/model_opt_grad_norm": 30.78264511178393, "train/model_opt_grad_steps": 141604.2385321101, "train/model_opt_loss": 7268.874200383458, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2184.6330275229357, "train/policy_entropy_mag": 2.5398901001029057, "train/policy_entropy_max": 2.5398901001029057, "train/policy_entropy_mean": 0.5334372275739635, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6100340527952264, "train/policy_logprob_mag": 7.43838404296735, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5340432050304675, "train/policy_logprob_min": -7.43838404296735, "train/policy_logprob_std": 1.1000335552823652, "train/policy_randomness_mag": 0.8964697461609447, "train/policy_randomness_max": 0.8964697461609447, "train/policy_randomness_mean": 0.1882799332705113, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.21531525097035487, "train/post_ent_mag": 46.217046282707, "train/post_ent_max": 46.217046282707, "train/post_ent_mean": 28.162418452971572, "train/post_ent_min": 14.035517635695431, "train/post_ent_std": 4.777839377385761, "train/prior_ent_mag": 77.37255152431104, "train/prior_ent_max": 77.37255152431104, "train/prior_ent_mean": 31.100984022158002, "train/prior_ent_min": 15.435470633550521, "train/prior_ent_std": 8.82205943448828, "train/rep_loss_mean": 3.05198332913425, "train/rep_loss_std": 7.877928663831239, "train/reward_avg": 0.020618011689010084, "train/reward_loss_mean": 0.03696416336359507, "train/reward_loss_std": 0.16761609802552319, "train/reward_max_data": 1.0119266083481115, "train/reward_max_pred": 1.0127611882096037, "train/reward_neg_acc": 0.9963736829407718, "train/reward_neg_loss": 0.01914919211973496, "train/reward_pos_acc": 0.9920818898655953, "train/reward_pos_loss": 0.7140502429336583, "train/reward_pred": 0.020536243401301186, "train/reward_rate": 0.025686281536697247, "train_stats/sum_log_reward": 4.099999914566676, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 3.5833333333333335, "train_stats/max_log_achievement_collect_sapling": 1.5833333333333333, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 2.8333333333333335, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.08333333333333333, "train_stats/max_log_achievement_make_wood_pickaxe": 0.25, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.5, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 1.0833333333333333, "train_stats/max_log_achievement_wake_up": 1.8333333333333333, "train_stats/mean_log_entropy": 0.5539863879481951, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 4.715713259884069e-07, "report/cont_loss_std": 5.661854061145277e-07, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 3.4741105991997756e-06, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 4.597966665187414e-07, "report/cont_pred": 0.9960933327674866, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 3.2442591190338135, "report/dyn_loss_std": 7.961160659790039, "report/image_loss_mean": 1.8041621446609497, "report/image_loss_std": 5.412606716156006, "report/model_loss_mean": 3.779808521270752, "report/model_loss_std": 8.981971740722656, "report/post_ent_mag": 48.56214141845703, "report/post_ent_max": 48.56214141845703, "report/post_ent_mean": 27.994892120361328, "report/post_ent_min": 13.068758010864258, "report/post_ent_std": 4.831230640411377, "report/prior_ent_mag": 77.33550262451172, "report/prior_ent_max": 77.33550262451172, "report/prior_ent_mean": 31.326553344726562, "report/prior_ent_min": 17.83437156677246, "report/prior_ent_std": 8.776055335998535, "report/rep_loss_mean": 3.2442591190338135, "report/rep_loss_std": 7.961160659790039, "report/reward_avg": 0.01669921725988388, "report/reward_loss_mean": 0.029090523719787598, "report/reward_loss_std": 0.13006895780563354, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0000555515289307, "report/reward_neg_acc": 0.9950149655342102, "report/reward_neg_loss": 0.015593242831528187, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6737464070320129, "report/reward_pred": 0.016818085685372353, "report/reward_rate": 0.0205078125, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.0009060993324965239, "eval/cont_loss_std": 0.028960874304175377, "eval/cont_neg_acc": 0.75, "eval/cont_neg_loss": 0.2318030297756195, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 6.211860750227061e-07, "eval/cont_pred": 0.9966833591461182, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 22.41910171508789, "eval/dyn_loss_std": 12.808629989624023, "eval/image_loss_mean": 31.429044723510742, "eval/image_loss_std": 33.20555877685547, "eval/model_loss_mean": 45.01927947998047, "eval/model_loss_std": 38.603790283203125, "eval/post_ent_mag": 48.56214141845703, "eval/post_ent_max": 48.56214141845703, "eval/post_ent_mean": 31.510631561279297, "eval/post_ent_min": 15.778712272644043, "eval/post_ent_std": 4.507259368896484, "eval/prior_ent_mag": 77.33550262451172, "eval/prior_ent_max": 77.33550262451172, "eval/prior_ent_mean": 43.50685119628906, "eval/prior_ent_min": 17.538917541503906, "eval/prior_ent_std": 8.948862075805664, "eval/rep_loss_mean": 22.41910171508789, "eval/rep_loss_std": 12.808629989624023, "eval/reward_avg": 0.02031249925494194, "eval/reward_loss_mean": 0.13787014782428741, "eval/reward_loss_std": 0.8213632702827454, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9999904632568359, "eval/reward_neg_acc": 0.9929929971694946, "eval/reward_neg_loss": 0.06907919049263, "eval/reward_pos_acc": 0.5999999642372131, "eval/reward_pos_loss": 2.8867571353912354, "eval/reward_pred": 0.015909012407064438, "eval/reward_rate": 0.0244140625, "replay/size": 143874.0, "replay/inserts": 2186.0, "replay/samples": 34976.0, "replay/insert_wait_avg": 2.642127208936574e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.203613959205117e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 28272.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 8.046627044677734e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1996564865112, "timer/env.step_count": 274.0, "timer/env.step_total": 25.405652046203613, "timer/env.step_frac": 0.02540058065551459, "timer/env.step_avg": 0.0927213578328599, "timer/env.step_min": 0.023758888244628906, "timer/env.step_max": 1.9210073947906494, "timer/replay._sample_count": 34976.0, "timer/replay._sample_total": 16.96915602684021, "timer/replay._sample_frac": 0.016965768701070392, "timer/replay._sample_avg": 0.0004851657143995943, "timer/replay._sample_min": 0.00036406517028808594, "timer/replay._sample_max": 0.012824058532714844, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 274.0, "timer/agent.policy_total": 4.371757984161377, "timer/agent.policy_frac": 0.004370885308557727, "timer/agent.policy_avg": 0.015955321110078018, "timer/agent.policy_min": 0.00977015495300293, "timer/agent.policy_max": 0.02588963508605957, "timer/dataset_train_count": 2186.0, "timer/dataset_train_total": 0.3797476291656494, "timer/dataset_train_frac": 0.0003796718252229981, "timer/dataset_train_avg": 0.00017371803712975728, "timer/dataset_train_min": 8.797645568847656e-05, "timer/dataset_train_max": 0.0005145072937011719, "timer/agent.train_count": 2186.0, "timer/agent.train_total": 968.3207278251648, "timer/agent.train_frac": 0.9681274349030169, "timer/agent.train_avg": 0.4429646513381358, "timer/agent.train_min": 0.43355751037597656, "timer/agent.train_max": 0.5489377975463867, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47328662872314453, "timer/agent.report_frac": 0.0004731921528404637, "timer/agent.report_avg": 0.23664331436157227, "timer/agent.report_min": 0.2299213409423828, "timer/agent.report_max": 0.24336528778076172, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9087066650390625e-05, "timer/dataset_eval_frac": 2.9081260388118217e-08, "timer/dataset_eval_avg": 2.9087066650390625e-05, "timer/dataset_eval_min": 2.9087066650390625e-05, "timer/dataset_eval_max": 2.9087066650390625e-05, "fps": 2.1855347675549366}
{"step": 144480, "time": 66368.93831682205, "episode/length": 391.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9770408163265306, "episode/intrinsic_return": 0.0}
{"step": 144688, "time": 66464.09513044357, "episode/length": 210.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 145184, "time": 66689.44977641106, "episode/length": 199.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 145240, "time": 66716.70626759529, "episode/length": 224.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 145328, "time": 66757.71894335747, "episode/length": 105.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9433962264150944, "episode/intrinsic_return": 0.0}
{"step": 145408, "time": 66795.1073846817, "episode/length": 180.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 145472, "time": 66825.33440589905, "episode/length": 176.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 145592, "time": 66880.85991191864, "episode/length": 171.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 145744, "time": 66950.39359402657, "episode/length": 197.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 146240, "time": 67174.42540454865, "episode/length": 193.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 146566, "time": 67322.74729299545, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.869975886932791, "train/action_min": 0.0, "train/action_std": 4.301897155639788, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04760080834501954, "train/actor_opt_grad_steps": 143910.0, "train/actor_opt_loss": -12.644089419560583, "train/adv_mag": 0.7894703144352185, "train/adv_max": 0.7083725413503168, "train/adv_mean": 0.00284672204701955, "train/adv_min": -0.5957906836107986, "train/adv_std": 0.05596715383673912, "train/cont_avg": 0.994644513413242, "train/cont_loss_mean": 4.182016707392559e-05, "train/cont_loss_std": 0.0012495553495212482, "train/cont_neg_acc": 0.997716894977169, "train/cont_neg_loss": 0.008228960200597418, "train/cont_pos_acc": 0.9999909969769656, "train/cont_pos_loss": 2.340438700344358e-05, "train/cont_pred": 0.9946414719433545, "train/cont_rate": 0.994644513413242, "train/dyn_loss_mean": 3.021904170240986, "train/dyn_loss_std": 7.847710517987813, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.3125204789584086, "train/extr_critic_critic_opt_grad_steps": 143910.0, "train/extr_critic_critic_opt_loss": 14977.162430436643, "train/extr_critic_mag": 11.510706474791924, "train/extr_critic_max": 11.510706474791924, "train/extr_critic_mean": 2.3477428639860456, "train/extr_critic_min": -0.6644633066708638, "train/extr_critic_std": 2.171272364925576, "train/extr_return_normed_mag": 1.8055625266680435, "train/extr_return_normed_max": 1.8055625266680435, "train/extr_return_normed_mean": 0.389492653684529, "train/extr_return_normed_min": -0.12559819399255867, "train/extr_return_normed_std": 0.3332577756686842, "train/extr_return_rate": 0.8255859803935709, "train/extr_return_raw_mag": 11.775037251651016, "train/extr_return_raw_max": 11.775037251651016, "train/extr_return_raw_mean": 2.366618782962294, "train/extr_return_raw_min": -1.0557164231391802, "train/extr_return_raw_std": 2.2152404910353223, "train/extr_reward_mag": 1.0280844386854129, "train/extr_reward_max": 1.0280844386854129, "train/extr_reward_mean": 0.029871859834380617, "train/extr_reward_min": -0.668828239723972, "train/extr_reward_std": 0.17397857106983933, "train/image_loss_mean": 1.5625851304019422, "train/image_loss_std": 4.771584185291099, "train/model_loss_mean": 3.4125748910860385, "train/model_loss_std": 8.563496080163407, "train/model_opt_grad_norm": 29.202102830965224, "train/model_opt_grad_steps": 143787.60273972602, "train/model_opt_loss": 8197.131905054937, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2402.9680365296804, "train/policy_entropy_mag": 2.5305621711086466, "train/policy_entropy_max": 2.5305621711086466, "train/policy_entropy_mean": 0.5350917334153772, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6072670192751166, "train/policy_logprob_mag": 7.438384034317922, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5351665854181873, "train/policy_logprob_min": -7.438384034317922, "train/policy_logprob_std": 1.0980118605644191, "train/policy_randomness_mag": 0.893177396086253, "train/policy_randomness_max": 0.893177396086253, "train/policy_randomness_mean": 0.18886390083456692, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.21433860873250657, "train/post_ent_mag": 46.680808864227714, "train/post_ent_max": 46.680808864227714, "train/post_ent_mean": 28.319630270134912, "train/post_ent_min": 14.14075952033474, "train/post_ent_std": 4.767810837863243, "train/prior_ent_mag": 77.46627570722745, "train/prior_ent_max": 77.46627570722745, "train/prior_ent_mean": 31.233665379215047, "train/prior_ent_min": 15.661141151706921, "train/prior_ent_std": 8.75986720220139, "train/rep_loss_mean": 3.021904170240986, "train/rep_loss_std": 7.847710517987813, "train/reward_avg": 0.02049933992045587, "train/reward_loss_mean": 0.03680542087582148, "train/reward_loss_std": 0.17260581299186298, "train/reward_max_data": 1.0141552545164274, "train/reward_max_pred": 1.0144165667224692, "train/reward_neg_acc": 0.9961241959981179, "train/reward_neg_loss": 0.018825914549160765, "train/reward_pos_acc": 0.98983003886323, "train/reward_pos_loss": 0.7275912843338431, "train/reward_pred": 0.020318199699685045, "train/reward_rate": 0.025399543378995432, "train_stats/sum_log_reward": 4.999999976158142, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 4.1, "train_stats/max_log_achievement_collect_sapling": 2.1, "train_stats/max_log_achievement_collect_stone": 0.3, "train_stats/max_log_achievement_collect_wood": 3.6, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.1, "train_stats/max_log_achievement_make_wood_pickaxe": 0.4, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 2.0, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 1.1, "train_stats/max_log_achievement_wake_up": 2.3, "train_stats/mean_log_entropy": 0.6151996433734894, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 3.546376490248804e-07, "report/cont_loss_std": 5.983756182104116e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 7.047386316116899e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 7.966031034811749e-08, "report/cont_pred": 0.9960940480232239, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 2.822138547897339, "report/dyn_loss_std": 7.384212493896484, "report/image_loss_mean": 1.116512417793274, "report/image_loss_std": 2.7134997844696045, "report/model_loss_mean": 2.8452038764953613, "report/model_loss_std": 6.651688575744629, "report/post_ent_mag": 48.67411804199219, "report/post_ent_max": 48.67411804199219, "report/post_ent_mean": 28.61046600341797, "report/post_ent_min": 13.612198829650879, "report/post_ent_std": 4.185829162597656, "report/prior_ent_mag": 77.4400634765625, "report/prior_ent_max": 77.4400634765625, "report/prior_ent_mean": 31.29237937927246, "report/prior_ent_min": 14.1047945022583, "report/prior_ent_std": 8.166606903076172, "report/rep_loss_mean": 2.822138547897339, "report/rep_loss_std": 7.384212493896484, "report/reward_avg": 0.02167968824505806, "report/reward_loss_mean": 0.03540804982185364, "report/reward_loss_std": 0.18688273429870605, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.00120210647583, "report/reward_neg_acc": 0.9959879517555237, "report/reward_neg_loss": 0.014715554192662239, "report/reward_pos_acc": 0.9629629850387573, "report/reward_pos_loss": 0.799497663974762, "report/reward_pred": 0.02169390767812729, "report/reward_rate": 0.0263671875, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.00013939407654106617, "eval/cont_loss_std": 0.003352975705638528, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.023766828700900078, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.360912875725262e-07, "eval/cont_pred": 0.994274377822876, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 22.398624420166016, "eval/dyn_loss_std": 12.433721542358398, "eval/image_loss_mean": 33.41792297363281, "eval/image_loss_std": 42.716087341308594, "eval/model_loss_mean": 47.03996276855469, "eval/model_loss_std": 47.49359130859375, "eval/post_ent_mag": 48.67411804199219, "eval/post_ent_max": 48.67411804199219, "eval/post_ent_mean": 31.375871658325195, "eval/post_ent_min": 19.201488494873047, "eval/post_ent_std": 3.8855366706848145, "eval/prior_ent_mag": 77.4400634765625, "eval/prior_ent_max": 77.4400634765625, "eval/prior_ent_mean": 41.44375991821289, "eval/prior_ent_min": 22.93747329711914, "eval/prior_ent_std": 7.986748218536377, "eval/rep_loss_mean": 22.398624420166016, "eval/rep_loss_std": 12.433721542358398, "eval/reward_avg": 0.02109374850988388, "eval/reward_loss_mean": 0.1827240288257599, "eval/reward_loss_std": 1.1794384717941284, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0006494522094727, "eval/reward_neg_acc": 0.9909819960594177, "eval/reward_neg_loss": 0.10736250877380371, "eval/reward_pos_acc": 0.7692307829856873, "eval/reward_pos_loss": 3.0754470825195312, "eval/reward_pred": 0.02088925801217556, "eval/reward_rate": 0.025390625, "replay/size": 146062.0, "replay/inserts": 2188.0, "replay/samples": 35008.0, "replay/insert_wait_avg": 2.6290333903031983e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.321795881121424e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 28272.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 9.08970832824707e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3794474601746, "timer/env.step_count": 273.0, "timer/env.step_total": 22.68943428993225, "timer/env.step_frac": 0.022680828107312277, "timer/env.step_avg": 0.08311148091550274, "timer/env.step_min": 0.023294448852539062, "timer/env.step_max": 2.014026403427124, "timer/replay._sample_count": 35008.0, "timer/replay._sample_total": 17.034250736236572, "timer/replay._sample_frac": 0.017027789584726262, "timer/replay._sample_avg": 0.0004865816595131562, "timer/replay._sample_min": 0.0003676414489746094, "timer/replay._sample_max": 0.030474185943603516, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 273.0, "timer/agent.policy_total": 4.354165554046631, "timer/agent.policy_frac": 0.004352514003662567, "timer/agent.policy_avg": 0.01594932437379718, "timer/agent.policy_min": 0.009721517562866211, "timer/agent.policy_max": 0.04513144493103027, "timer/dataset_train_count": 2188.0, "timer/dataset_train_total": 0.3779919147491455, "timer/dataset_train_frac": 0.0003778485410799021, "timer/dataset_train_avg": 0.00017275681661295498, "timer/dataset_train_min": 8.749961853027344e-05, "timer/dataset_train_max": 0.0005736351013183594, "timer/agent.train_count": 2188.0, "timer/agent.train_total": 970.6398222446442, "timer/agent.train_frac": 0.9702716551294259, "timer/agent.train_avg": 0.44361966281747905, "timer/agent.train_min": 0.43457770347595215, "timer/agent.train_max": 0.5723006725311279, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.475111722946167, "timer/agent.report_frac": 0.00047493151139041303, "timer/agent.report_avg": 0.2375558614730835, "timer/agent.report_min": 0.2293405532836914, "timer/agent.report_max": 0.24577116966247559, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 4.57763671875e-05, "timer/dataset_eval_frac": 4.5759004049633246e-08, "timer/dataset_eval_avg": 4.57763671875e-05, "timer/dataset_eval_min": 4.57763671875e-05, "timer/dataset_eval_max": 4.57763671875e-05, "fps": 2.18714292894581}
{"step": 146576, "time": 67327.49105978012, "episode/length": 137.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.0}
{"step": 146592, "time": 67336.14866352081, "episode/length": 175.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 146664, "time": 67370.06381440163, "episode/length": 177.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 146696, "time": 67386.05018043518, "episode/length": 170.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 147080, "time": 67561.12451601028, "episode/length": 208.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9808612440191388, "episode/intrinsic_return": 0.0}
{"step": 147344, "time": 67681.96566295624, "episode/length": 218.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 147608, "time": 67803.36976265907, "episode/length": 170.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 147792, "time": 67888.04512381554, "episode/length": 140.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9716312056737588, "episode/intrinsic_return": 0.0}
{"step": 148008, "time": 67986.6176764965, "episode/length": 178.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 148096, "time": 68027.67836141586, "episode/length": 187.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 148184, "time": 68068.83440041542, "episode/length": 185.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 148296, "time": 68120.46424627304, "episode/length": 151.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 148743, "time": 68322.99282598495, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.792627737062786, "train/action_min": 0.0, "train/action_std": 4.287639369658374, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04968516938730117, "train/actor_opt_grad_steps": 146095.0, "train/actor_opt_loss": -17.466964384284587, "train/adv_mag": 0.865061836505155, "train/adv_max": 0.7823842860963366, "train/adv_mean": 0.0021499815789832884, "train/adv_min": -0.6118909221723539, "train/adv_std": 0.057822950731176846, "train/cont_avg": 0.9942750143348624, "train/cont_loss_mean": 1.8509761749523694e-05, "train/cont_loss_std": 0.0005714831032275376, "train/cont_neg_acc": 0.9995412845677192, "train/cont_neg_loss": 0.0017603656092923293, "train/cont_pos_acc": 0.9999999833216361, "train/cont_pos_loss": 2.778998117113851e-06, "train/cont_pred": 0.994278540851873, "train/cont_rate": 0.9942750143348624, "train/dyn_loss_mean": 3.0874948085994895, "train/dyn_loss_std": 7.898255897224496, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.2614860911981776, "train/extr_critic_critic_opt_grad_steps": 146095.0, "train/extr_critic_critic_opt_loss": 14940.83110396359, "train/extr_critic_mag": 12.539978410125872, "train/extr_critic_max": 12.539978410125872, "train/extr_critic_mean": 2.4755721595309197, "train/extr_critic_min": -0.6585131200081712, "train/extr_critic_std": 2.216723509337924, "train/extr_return_normed_mag": 1.9639580627100184, "train/extr_return_normed_max": 1.9639580627100184, "train/extr_return_normed_mean": 0.3989341356065295, "train/extr_return_normed_min": -0.13197992742061615, "train/extr_return_normed_std": 0.3380175971109933, "train/extr_return_rate": 0.8311756813744886, "train/extr_return_raw_mag": 12.975880124153347, "train/extr_return_raw_max": 12.975880124153347, "train/extr_return_raw_mean": 2.489891931551312, "train/extr_return_raw_min": -1.064634455726781, "train/extr_return_raw_std": 2.2638716112583057, "train/extr_reward_mag": 1.0198922857232051, "train/extr_reward_max": 1.0198922857232051, "train/extr_reward_mean": 0.031850008178639026, "train/extr_reward_min": -0.6741270663541391, "train/extr_reward_std": 0.17960477193151045, "train/image_loss_mean": 1.59223102703007, "train/image_loss_std": 4.922672827309425, "train/model_loss_mean": 3.4816003436342293, "train/model_loss_std": 8.751910459010974, "train/model_opt_grad_norm": 30.585836589883225, "train/model_opt_grad_steps": 145970.21100917432, "train/model_opt_loss": 6465.0764193753585, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1840.5963302752293, "train/policy_entropy_mag": 2.5370717562666725, "train/policy_entropy_max": 2.5370717562666725, "train/policy_entropy_mean": 0.5295668454892045, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6030640429859861, "train/policy_logprob_mag": 7.438384069215267, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5307368637498365, "train/policy_logprob_min": -7.438384069215267, "train/policy_logprob_std": 1.098472142711692, "train/policy_randomness_mag": 0.8954749913937455, "train/policy_randomness_max": 0.8954749913937455, "train/policy_randomness_mean": 0.18691385646752262, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.21285514266939337, "train/post_ent_mag": 46.73647439589194, "train/post_ent_max": 46.73647439589194, "train/post_ent_mean": 28.597581137210952, "train/post_ent_min": 13.958020533990423, "train/post_ent_std": 4.863253036770252, "train/prior_ent_mag": 77.44496634247106, "train/prior_ent_max": 77.44496634247106, "train/prior_ent_mean": 31.570865876084074, "train/prior_ent_min": 15.453667710680481, "train/prior_ent_std": 8.8176745274745, "train/rep_loss_mean": 3.0874948085994895, "train/rep_loss_std": 7.898255897224496, "train/reward_avg": 0.020696405411074193, "train/reward_loss_mean": 0.036853928648687286, "train/reward_loss_std": 0.1668537384189597, "train/reward_max_data": 1.0096330298196285, "train/reward_max_pred": 1.0098661091349541, "train/reward_neg_acc": 0.9961879491259199, "train/reward_neg_loss": 0.018681964901096505, "train/reward_pos_acc": 0.9885446494872417, "train/reward_pos_loss": 0.7252100222154495, "train/reward_pred": 0.020551526921143363, "train/reward_rate": 0.02578483371559633, "train_stats/sum_log_reward": 3.933333247900009, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 2.3333333333333335, "train_stats/max_log_achievement_collect_sapling": 1.6666666666666667, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 2.5833333333333335, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.08333333333333333, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.6666666666666667, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 1.0833333333333333, "train_stats/max_log_achievement_wake_up": 1.5833333333333333, "train_stats/mean_log_entropy": 0.5035143171747526, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 1.4505545209431148e-07, "report/cont_loss_std": 2.6991003210241615e-07, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 2.713330559345195e-06, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.375090903366072e-07, "report/cont_pred": 0.9970701932907104, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 3.101954460144043, "report/dyn_loss_std": 7.827328681945801, "report/image_loss_mean": 1.521213173866272, "report/image_loss_std": 4.23502254486084, "report/model_loss_mean": 3.4153099060058594, "report/model_loss_std": 8.085210800170898, "report/post_ent_mag": 44.551025390625, "report/post_ent_max": 44.551025390625, "report/post_ent_mean": 27.612262725830078, "report/post_ent_min": 12.200845718383789, "report/post_ent_std": 4.157674789428711, "report/prior_ent_mag": 77.38002014160156, "report/prior_ent_max": 77.38002014160156, "report/prior_ent_mean": 30.72887420654297, "report/prior_ent_min": 13.672979354858398, "report/prior_ent_std": 8.19323444366455, "report/rep_loss_mean": 3.101954460144043, "report/rep_loss_std": 7.827328681945801, "report/reward_avg": 0.01972656324505806, "report/reward_loss_mean": 0.0329236201941967, "report/reward_loss_std": 0.16867998242378235, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0072710514068604, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.015968821942806244, "report/reward_pos_acc": 0.95652174949646, "report/reward_pos_loss": 0.7708259224891663, "report/reward_pred": 0.01888241618871689, "report/reward_rate": 0.0224609375, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.002243687165901065, "eval/cont_loss_std": 0.07175711542367935, "eval/cont_neg_acc": 0.800000011920929, "eval/cont_neg_loss": 0.459473580121994, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.6447800987862138e-07, "eval/cont_pred": 0.9959955215454102, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 20.33407974243164, "eval/dyn_loss_std": 12.657849311828613, "eval/image_loss_mean": 32.0821533203125, "eval/image_loss_std": 41.161739349365234, "eval/model_loss_mean": 44.42279052734375, "eval/model_loss_std": 46.11687469482422, "eval/post_ent_mag": 48.01366424560547, "eval/post_ent_max": 48.01366424560547, "eval/post_ent_mean": 32.50241470336914, "eval/post_ent_min": 19.7648868560791, "eval/post_ent_std": 3.9523582458496094, "eval/prior_ent_mag": 77.38002014160156, "eval/prior_ent_max": 77.38002014160156, "eval/prior_ent_mean": 42.94334411621094, "eval/prior_ent_min": 20.841650009155273, "eval/prior_ent_std": 8.00864315032959, "eval/rep_loss_mean": 20.33407974243164, "eval/rep_loss_std": 12.657849311828613, "eval/reward_avg": 0.02294921875, "eval/reward_loss_mean": 0.13794174790382385, "eval/reward_loss_std": 0.8989707827568054, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0000591278076172, "eval/reward_neg_acc": 0.9989960789680481, "eval/reward_neg_loss": 0.08887188136577606, "eval/reward_pos_acc": 0.8571429252624512, "eval/reward_pos_loss": 1.883427381515503, "eval/reward_pred": 0.019855424761772156, "eval/reward_rate": 0.02734375, "replay/size": 148239.0, "replay/inserts": 2177.0, "replay/samples": 34832.0, "replay/insert_wait_avg": 2.6173475525715398e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.663796568990138e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 28272.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2332563400269, "timer/env.step_count": 272.0, "timer/env.step_total": 24.66658616065979, "timer/env.step_frac": 0.024660833864810473, "timer/env.step_avg": 0.09068597853183746, "timer/env.step_min": 0.02371978759765625, "timer/env.step_max": 1.5891211032867432, "timer/replay._sample_count": 34832.0, "timer/replay._sample_total": 17.554315328598022, "timer/replay._sample_frac": 0.017550221628134383, "timer/replay._sample_avg": 0.0005039709269808803, "timer/replay._sample_min": 0.0003802776336669922, "timer/replay._sample_max": 0.04883289337158203, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 272.0, "timer/agent.policy_total": 4.417840003967285, "timer/agent.policy_frac": 0.004416809755089218, "timer/agent.policy_avg": 0.01624205883811502, "timer/agent.policy_min": 0.010092020034790039, "timer/agent.policy_max": 0.04024028778076172, "timer/dataset_train_count": 2177.0, "timer/dataset_train_total": 0.3859543800354004, "timer/dataset_train_frac": 0.00038586437472360564, "timer/dataset_train_avg": 0.00017728726689729003, "timer/dataset_train_min": 8.940696716308594e-05, "timer/dataset_train_max": 0.0005128383636474609, "timer/agent.train_count": 2177.0, "timer/agent.train_total": 968.7748606204987, "timer/agent.train_frac": 0.9685489404395149, "timer/agent.train_avg": 0.44500452945360525, "timer/agent.train_min": 0.43491411209106445, "timer/agent.train_max": 0.5688095092773438, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47286391258239746, "timer/agent.report_frac": 0.00047275363979864366, "timer/agent.report_avg": 0.23643195629119873, "timer/agent.report_min": 0.22727680206298828, "timer/agent.report_max": 0.24558711051940918, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.266334533691406e-05, "timer/dataset_eval_frac": 3.265572818127759e-08, "timer/dataset_eval_avg": 3.266334533691406e-05, "timer/dataset_eval_min": 3.266334533691406e-05, "timer/dataset_eval_max": 3.266334533691406e-05, "fps": 2.176465540526649}
{"step": 148968, "time": 68424.26294755936, "episode/length": 202.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9704433497536946, "episode/intrinsic_return": 0.0}
{"step": 149032, "time": 68454.63549566269, "episode/length": 410.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9781021897810219, "episode/intrinsic_return": 0.0}
{"step": 149144, "time": 68506.5544295311, "episode/length": 191.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 149288, "time": 68572.53675222397, "episode/length": 186.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 149416, "time": 68631.45932984352, "episode/length": 153.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 149424, "time": 68636.58459806442, "episode/length": 165.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.963855421686747, "episode/intrinsic_return": 0.0}
{"step": 149496, "time": 68670.39522147179, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 150072, "time": 68949.89613223076, "eval_episode/length": 160.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9937888198757764}
{"step": 150072, "time": 68952.00841903687, "eval_episode/length": 166.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9940119760479041}
{"step": 150072, "time": 68954.23017597198, "eval_episode/length": 168.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9704142011834319}
{"step": 150072, "time": 68956.13553881645, "eval_episode/length": 169.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9941176470588236}
{"step": 150072, "time": 68958.71320009232, "eval_episode/length": 184.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9945945945945946}
{"step": 150072, "time": 68960.21220612526, "eval_episode/length": 185.0, "eval_episode/score": 4.0999999940395355, "eval_episode/reward_rate": 0.9946236559139785}
{"step": 150072, "time": 68963.12264585495, "eval_episode/length": 219.0, "eval_episode/score": 3.0999999791383743, "eval_episode/reward_rate": 0.9954545454545455}
{"step": 150072, "time": 68966.1384665966, "eval_episode/length": 254.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.996078431372549}
{"step": 150264, "time": 69052.338555336, "episode/length": 139.0, "episode/score": 5.099999964237213, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 150272, "time": 69057.50586938858, "episode/length": 246.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9838056680161943, "episode/intrinsic_return": 0.0}
{"step": 150376, "time": 69105.87774181366, "episode/length": 167.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 150392, "time": 69114.57828259468, "episode/length": 177.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 150632, "time": 69223.85211610794, "episode/length": 45.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8913043478260869, "episode/intrinsic_return": 0.0}
{"step": 150720, "time": 69264.73654961586, "episode/length": 161.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 150800, "time": 69302.45759797096, "episode/length": 188.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 150842, "time": 69323.26187586784, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.508256022135416, "train/action_min": 0.0, "train/action_std": 4.142108757155282, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.048359603408191884, "train/actor_opt_grad_steps": 148235.0, "train/actor_opt_loss": -16.86656284417425, "train/adv_mag": 0.7813838618142265, "train/adv_max": 0.7206556860889707, "train/adv_mean": 0.001735159364445627, "train/adv_min": -0.5542582865981829, "train/adv_std": 0.05510233445536523, "train/cont_avg": 0.9942847842261905, "train/cont_loss_mean": 5.423307585846801e-05, "train/cont_loss_std": 0.0017087730275047789, "train/cont_neg_acc": 0.996666666723433, "train/cont_neg_loss": 0.02014009502326341, "train/cont_pos_acc": 0.9999953119527726, "train/cont_pos_loss": 1.2083424981422838e-05, "train/cont_pred": 0.9942838441757929, "train/cont_rate": 0.9942847842261905, "train/dyn_loss_mean": 3.185639304206485, "train/dyn_loss_std": 7.920014070329212, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1738443360442208, "train/extr_critic_critic_opt_grad_steps": 148235.0, "train/extr_critic_critic_opt_loss": 14812.449837239583, "train/extr_critic_mag": 11.222052238101051, "train/extr_critic_max": 11.222052238101051, "train/extr_critic_mean": 2.2981711512520198, "train/extr_critic_min": -0.6528405791237241, "train/extr_critic_std": 2.202368938922882, "train/extr_return_normed_mag": 1.7576685854366847, "train/extr_return_normed_max": 1.7576685854366847, "train/extr_return_normed_mean": 0.37152653975146155, "train/extr_return_normed_min": -0.12643748612276146, "train/extr_return_normed_std": 0.3336090657682646, "train/extr_return_rate": 0.8157664103167398, "train/extr_return_raw_mag": 11.633981579825992, "train/extr_return_raw_max": 11.633981579825992, "train/extr_return_raw_mean": 2.309769288698832, "train/extr_return_raw_min": -1.0402464673632668, "train/extr_return_raw_std": 2.2452759924389065, "train/extr_reward_mag": 1.0236141738437472, "train/extr_reward_max": 1.0236141738437472, "train/extr_reward_mean": 0.03119656480405302, "train/extr_reward_min": -0.673963072754088, "train/extr_reward_std": 0.17792612278745287, "train/image_loss_mean": 1.630317797547295, "train/image_loss_std": 5.152931275821867, "train/model_loss_mean": 3.5785091241200764, "train/model_loss_std": 8.974667617252894, "train/model_opt_grad_norm": 29.41283975328718, "train/model_opt_grad_steps": 148108.86666666667, "train/model_opt_loss": 7260.13756859189, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2029.7619047619048, "train/policy_entropy_mag": 2.5217185213452296, "train/policy_entropy_max": 2.5217185213452296, "train/policy_entropy_mean": 0.528958505817822, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6126070110570817, "train/policy_logprob_mag": 7.4383840765271865, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5289580345153808, "train/policy_logprob_min": -7.4383840765271865, "train/policy_logprob_std": 1.0942324854078747, "train/policy_randomness_mag": 0.8900559782981873, "train/policy_randomness_max": 0.8900559782981873, "train/policy_randomness_mean": 0.18669913914941605, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.21622339274202074, "train/post_ent_mag": 47.05706274850028, "train/post_ent_max": 47.05706274850028, "train/post_ent_mean": 28.794453003292993, "train/post_ent_min": 13.974052774338496, "train/post_ent_std": 4.874265162150065, "train/prior_ent_mag": 77.52372036888485, "train/prior_ent_max": 77.52372036888485, "train/prior_ent_mean": 31.86768394651867, "train/prior_ent_min": 15.519306841350737, "train/prior_ent_std": 8.797270229884557, "train/rep_loss_mean": 3.185639304206485, "train/rep_loss_std": 7.920014070329212, "train/reward_avg": 0.021285342061448664, "train/reward_loss_mean": 0.036753531288178196, "train/reward_loss_std": 0.1633358054217838, "train/reward_max_data": 1.014285717691694, "train/reward_max_pred": 1.0143508281026568, "train/reward_neg_acc": 0.9961156104292188, "train/reward_neg_loss": 0.018404528831264803, "train/reward_pos_acc": 0.9923901847430638, "train/reward_pos_loss": 0.7138006005968366, "train/reward_pred": 0.02111754068173468, "train/reward_rate": 0.02637183779761905, "train_stats/sum_log_reward": 4.314285593373435, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 4.0, "train_stats/max_log_achievement_collect_sapling": 1.7857142857142858, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 2.7857142857142856, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.14285714285714285, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.7142857142857142, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 1.2857142857142858, "train_stats/max_log_achievement_wake_up": 1.9285714285714286, "train_stats/mean_log_entropy": 0.5480771171195167, "eval_stats/sum_log_reward": 4.724999904632568, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 4.25, "eval_stats/max_log_achievement_collect_sapling": 1.75, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 4.625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.125, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 1.75, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.0, "eval_stats/max_log_achievement_wake_up": 2.125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 9.42528544101151e-08, "report/cont_loss_std": 2.6402378239254176e-07, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.4961029819460236e-06, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 8.737429624261495e-08, "report/cont_pred": 0.9951171875, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 2.887606382369995, "report/dyn_loss_std": 8.069835662841797, "report/image_loss_mean": 1.2690603733062744, "report/image_loss_std": 3.6055479049682617, "report/model_loss_mean": 3.030752182006836, "report/model_loss_std": 7.7011284828186035, "report/post_ent_mag": 49.21214294433594, "report/post_ent_max": 49.21214294433594, "report/post_ent_mean": 27.536937713623047, "report/post_ent_min": 13.610174179077148, "report/post_ent_std": 5.351664066314697, "report/prior_ent_mag": 77.81634521484375, "report/prior_ent_max": 77.81634521484375, "report/prior_ent_mean": 30.475582122802734, "report/prior_ent_min": 14.148210525512695, "report/prior_ent_std": 8.772435188293457, "report/rep_loss_mean": 2.887606382369995, "report/rep_loss_std": 8.069835662841797, "report/reward_avg": 0.01503906212747097, "report/reward_loss_mean": 0.029127832502126694, "report/reward_loss_std": 0.1482120156288147, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0012431144714355, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.015611277893185616, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6747041344642639, "report/reward_pred": 0.015259938314557076, "report/reward_rate": 0.0205078125, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.005892071407288313, "eval/cont_loss_std": 0.1872442066669464, "eval/cont_neg_acc": 0.800000011920929, "eval/cont_neg_loss": 1.2066811323165894, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 7.549932234951484e-08, "eval/cont_pred": 0.9961285591125488, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 20.83893585205078, "eval/dyn_loss_std": 12.291264533996582, "eval/image_loss_mean": 33.41722869873047, "eval/image_loss_std": 39.93194580078125, "eval/model_loss_mean": 46.03676986694336, "eval/model_loss_std": 44.82192611694336, "eval/post_ent_mag": 49.21214294433594, "eval/post_ent_max": 49.21214294433594, "eval/post_ent_mean": 31.95858383178711, "eval/post_ent_min": 17.49993896484375, "eval/post_ent_std": 4.824391841888428, "eval/prior_ent_mag": 77.81634521484375, "eval/prior_ent_max": 77.81634521484375, "eval/prior_ent_mean": 42.038902282714844, "eval/prior_ent_min": 18.811080932617188, "eval/prior_ent_std": 8.35129451751709, "eval/rep_loss_mean": 20.83893585205078, "eval/rep_loss_std": 12.291264533996582, "eval/reward_avg": 0.01923828199505806, "eval/reward_loss_mean": 0.11028727889060974, "eval/reward_loss_std": 0.7824962139129639, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0012352466583252, "eval/reward_neg_acc": 0.999000072479248, "eval/reward_neg_loss": 0.059307996183633804, "eval/reward_pos_acc": 0.8333333730697632, "eval/reward_pos_loss": 2.234424352645874, "eval/reward_pred": 0.014636506326496601, "eval/reward_rate": 0.0234375, "replay/size": 150338.0, "replay/inserts": 2099.0, "replay/samples": 33584.0, "replay/insert_wait_avg": 2.5681963189548965e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.627846911840634e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 30312.0, "eval_replay/inserts": 2040.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.11694429434982e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.301568984985352e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2515184879303, "timer/env.step_count": 263.0, "timer/env.step_total": 28.522212266921997, "timer/env.step_frac": 0.02851504020712583, "timer/env.step_avg": 0.10844947630008364, "timer/env.step_min": 0.023618698120117188, "timer/env.step_max": 1.7030341625213623, "timer/replay._sample_count": 33584.0, "timer/replay._sample_total": 16.532270193099976, "timer/replay._sample_frac": 0.016528113067093, "timer/replay._sample_avg": 0.0004922662634915428, "timer/replay._sample_min": 0.00034308433532714844, "timer/replay._sample_max": 0.010254859924316406, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 518.0, "timer/agent.policy_total": 8.194306135177612, "timer/agent.policy_frac": 0.00819224563394301, "timer/agent.policy_avg": 0.015819123813084195, "timer/agent.policy_min": 0.009477615356445312, "timer/agent.policy_max": 0.04914212226867676, "timer/dataset_train_count": 2099.0, "timer/dataset_train_total": 0.3663749694824219, "timer/dataset_train_frac": 0.0003662828425757024, "timer/dataset_train_avg": 0.00017454738898638487, "timer/dataset_train_min": 8.845329284667969e-05, "timer/dataset_train_max": 0.0010020732879638672, "timer/agent.train_count": 2099.0, "timer/agent.train_total": 930.0729124546051, "timer/agent.train_frac": 0.9298390407450583, "timer/agent.train_avg": 0.4431028644376394, "timer/agent.train_min": 0.43312835693359375, "timer/agent.train_max": 0.5622918605804443, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.473691463470459, "timer/agent.report_frac": 0.0004735723512687423, "timer/agent.report_avg": 0.2368457317352295, "timer/agent.report_min": 0.23056340217590332, "timer/agent.report_max": 0.24312806129455566, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0279159545898438e-05, "timer/dataset_eval_frac": 3.027154569249855e-08, "timer/dataset_eval_avg": 3.0279159545898438e-05, "timer/dataset_eval_min": 3.0279159545898438e-05, "timer/dataset_eval_max": 3.0279159545898438e-05, "fps": 2.098444888486117}
{"step": 150864, "time": 69333.40422797203, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 151024, "time": 69406.77337503433, "episode/length": 200.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 151592, "time": 69663.513610363, "episode/length": 164.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 151720, "time": 69722.50062465668, "episode/length": 165.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 151904, "time": 69806.79729485512, "episode/length": 158.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 152032, "time": 69865.68137860298, "episode/length": 163.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 152248, "time": 69964.22278094292, "episode/length": 172.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 152328, "time": 70001.85383176804, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 152424, "time": 70046.58772826195, "episode/length": 103.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9423076923076923, "episode/intrinsic_return": 0.0}
{"step": 152568, "time": 70112.90376067162, "episode/length": 220.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 153031, "time": 70323.42280387878, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.432650910120577, "train/action_min": 0.0, "train/action_std": 4.169136032121911, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04811912098023445, "train/actor_opt_grad_steps": 150380.0, "train/actor_opt_loss": -16.18599321948339, "train/adv_mag": 0.7149412238706737, "train/adv_max": 0.6358917804613505, "train/adv_mean": 0.0017322057882080265, "train/adv_min": -0.5728278866369431, "train/adv_std": 0.05510517175747379, "train/cont_avg": 0.9942298087899544, "train/cont_loss_mean": 3.827364238052232e-05, "train/cont_loss_std": 0.0011897944157473028, "train/cont_neg_acc": 0.9985866497640741, "train/cont_neg_loss": 0.004658520505943392, "train/cont_pos_acc": 0.9999954910038813, "train/cont_pos_loss": 9.766787771798927e-06, "train/cont_pred": 0.9942325334570724, "train/cont_rate": 0.9942298087899544, "train/dyn_loss_mean": 3.0561789530052987, "train/dyn_loss_std": 7.90572495221003, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1448716885967343, "train/extr_critic_critic_opt_grad_steps": 150380.0, "train/extr_critic_critic_opt_loss": 14825.235761807933, "train/extr_critic_mag": 10.72950414979839, "train/extr_critic_max": 10.72950414979839, "train/extr_critic_mean": 2.1865475390055407, "train/extr_critic_min": -0.6443034230846248, "train/extr_critic_std": 2.1045209174831165, "train/extr_return_normed_mag": 1.7309438703266997, "train/extr_return_normed_max": 1.7309438703266997, "train/extr_return_normed_mean": 0.36169970749992214, "train/extr_return_normed_min": -0.12279219107200566, "train/extr_return_normed_std": 0.32470211971840357, "train/extr_return_rate": 0.8051715133941337, "train/extr_return_raw_mag": 11.233786789793946, "train/extr_return_raw_max": 11.233786789793946, "train/extr_return_raw_mean": 2.1980038244430333, "train/extr_return_raw_min": -0.999757903895966, "train/extr_return_raw_std": 2.142432149142435, "train/extr_reward_mag": 1.0219711201376023, "train/extr_reward_max": 1.0219711201376023, "train/extr_reward_mean": 0.03224884429053493, "train/extr_reward_min": -0.6823842035580988, "train/extr_reward_std": 0.18048580528394273, "train/image_loss_mean": 1.5345921927391122, "train/image_loss_std": 4.871700886722024, "train/model_loss_mean": 3.4052552371264593, "train/model_loss_std": 8.692136540260488, "train/model_opt_grad_norm": 27.97291157779084, "train/model_opt_grad_steps": 150251.71689497717, "train/model_opt_loss": 6667.298568377212, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1952.054794520548, "train/policy_entropy_mag": 2.5242299467461295, "train/policy_entropy_max": 2.5242299467461295, "train/policy_entropy_mean": 0.5428232324722151, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6268135618129277, "train/policy_logprob_mag": 7.4383840952834035, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5436237457136041, "train/policy_logprob_min": -7.4383840952834035, "train/policy_logprob_std": 1.1054413960948926, "train/policy_randomness_mag": 0.8909423985437716, "train/policy_randomness_max": 0.8909423985437716, "train/policy_randomness_mean": 0.1915927799461095, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.22123768190815024, "train/post_ent_mag": 46.88241233999871, "train/post_ent_max": 46.88241233999871, "train/post_ent_mean": 29.00526615473778, "train/post_ent_min": 13.950970257798286, "train/post_ent_std": 4.82321929387306, "train/prior_ent_mag": 77.51159922281902, "train/prior_ent_max": 77.51159922281902, "train/prior_ent_mean": 31.960468658029217, "train/prior_ent_min": 15.393305878660994, "train/prior_ent_std": 8.754200780772727, "train/rep_loss_mean": 3.0561789530052987, "train/rep_loss_std": 7.90572495221003, "train/reward_avg": 0.020918503831051392, "train/reward_loss_mean": 0.03691741490745109, "train/reward_loss_std": 0.16578004822203013, "train/reward_max_data": 1.0132420122895611, "train/reward_max_pred": 1.01386059745806, "train/reward_neg_acc": 0.9962380286221091, "train/reward_neg_loss": 0.018825126120812136, "train/reward_pos_acc": 0.9914399238481914, "train/reward_pos_loss": 0.7155953626654464, "train/reward_pred": 0.020821354766567685, "train/reward_rate": 0.026086258561643837, "train_stats/sum_log_reward": 5.1, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 2.6, "train_stats/max_log_achievement_collect_sapling": 1.3, "train_stats/max_log_achievement_collect_stone": 0.5, "train_stats/max_log_achievement_collect_wood": 4.5, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.1, "train_stats/max_log_achievement_eat_cow": 0.1, "train_stats/max_log_achievement_make_wood_pickaxe": 0.4, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.3, "train_stats/max_log_achievement_place_stone": 0.2, "train_stats/max_log_achievement_place_table": 1.8, "train_stats/max_log_achievement_wake_up": 1.9, "train_stats/mean_log_entropy": 0.4329606994986534, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 6.782976242902805e-07, "report/cont_loss_std": 3.047353175134049e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 5.340385541785508e-06, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 6.554217861776124e-07, "report/cont_pred": 0.9951165914535522, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 2.8826088905334473, "report/dyn_loss_std": 7.676549911499023, "report/image_loss_mean": 1.283221960067749, "report/image_loss_std": 4.273434162139893, "report/model_loss_mean": 3.0497336387634277, "report/model_loss_std": 8.148530960083008, "report/post_ent_mag": 44.6046142578125, "report/post_ent_max": 44.6046142578125, "report/post_ent_mean": 29.530529022216797, "report/post_ent_min": 15.034612655639648, "report/post_ent_std": 4.6789960861206055, "report/prior_ent_mag": 77.14509582519531, "report/prior_ent_max": 77.14509582519531, "report/prior_ent_mean": 32.46668243408203, "report/prior_ent_min": 16.410480499267578, "report/prior_ent_std": 8.474231719970703, "report/rep_loss_mean": 2.8826088905334473, "report/rep_loss_std": 7.676549911499023, "report/reward_avg": 0.02089843712747097, "report/reward_loss_mean": 0.036945659667253494, "report/reward_loss_std": 0.18127577006816864, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.093780755996704, "report/reward_neg_acc": 0.9989989995956421, "report/reward_neg_loss": 0.021075380966067314, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6711219549179077, "report/reward_pred": 0.021146269515156746, "report/reward_rate": 0.0244140625, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.000395097304135561, "eval/cont_loss_std": 0.012621758505702019, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.4040941894054413, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 4.7456759943997895e-07, "eval/cont_pred": 0.9993476867675781, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 26.244319915771484, "eval/dyn_loss_std": 12.444927215576172, "eval/image_loss_mean": 49.101646423339844, "eval/image_loss_std": 47.24580764770508, "eval/model_loss_mean": 65.01960754394531, "eval/model_loss_std": 51.54708480834961, "eval/post_ent_mag": 47.97589874267578, "eval/post_ent_max": 47.97589874267578, "eval/post_ent_mean": 31.20861053466797, "eval/post_ent_min": 19.921077728271484, "eval/post_ent_std": 3.474057197570801, "eval/prior_ent_mag": 77.14509582519531, "eval/prior_ent_max": 77.14509582519531, "eval/prior_ent_mean": 43.53829574584961, "eval/prior_ent_min": 22.969369888305664, "eval/prior_ent_std": 7.238347053527832, "eval/rep_loss_mean": 26.244319915771484, "eval/rep_loss_std": 12.444927215576172, "eval/reward_avg": 0.02587890625, "eval/reward_loss_mean": 0.17097525298595428, "eval/reward_loss_std": 1.0807104110717773, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0000431537628174, "eval/reward_neg_acc": 0.9909639358520508, "eval/reward_neg_loss": 0.06605364382266998, "eval/reward_pos_acc": 0.535714328289032, "eval/reward_pos_loss": 3.9031872749328613, "eval/reward_pred": 0.016810325905680656, "eval/reward_rate": 0.02734375, "replay/size": 152527.0, "replay/inserts": 2189.0, "replay/samples": 35024.0, "replay/insert_wait_avg": 2.6102967870023057e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.641516252868847e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 30312.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 8.791685104370117e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1525964736938, "timer/env.step_count": 273.0, "timer/env.step_total": 22.123339653015137, "timer/env.step_frac": 0.02211996422447625, "timer/env.step_avg": 0.08103787418686863, "timer/env.step_min": 0.0231168270111084, "timer/env.step_max": 1.587951421737671, "timer/replay._sample_count": 35024.0, "timer/replay._sample_total": 17.33591079711914, "timer/replay._sample_frac": 0.017333265801880174, "timer/replay._sample_avg": 0.0004949723274645712, "timer/replay._sample_min": 0.0003466606140136719, "timer/replay._sample_max": 0.03070855140686035, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 273.0, "timer/agent.policy_total": 4.371880054473877, "timer/agent.policy_frac": 0.004371213022780836, "timer/agent.policy_avg": 0.016014212653750463, "timer/agent.policy_min": 0.009514093399047852, "timer/agent.policy_max": 0.018050432205200195, "timer/dataset_train_count": 2189.0, "timer/dataset_train_total": 0.3831660747528076, "timer/dataset_train_frac": 0.00038310761388188396, "timer/dataset_train_avg": 0.0001750416056431282, "timer/dataset_train_min": 8.869171142578125e-05, "timer/dataset_train_max": 0.0006074905395507812, "timer/agent.train_count": 2189.0, "timer/agent.train_total": 971.5529601573944, "timer/agent.train_frac": 0.9714047272214908, "timer/agent.train_avg": 0.4438341526529897, "timer/agent.train_min": 0.4322693347930908, "timer/agent.train_max": 0.5708878040313721, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.473858118057251, "timer/agent.report_frac": 0.000473785820011831, "timer/agent.report_avg": 0.2369290590286255, "timer/agent.report_min": 0.22942543029785156, "timer/agent.report_max": 0.24443268775939941, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.147125244140625e-05, "timer/dataset_eval_frac": 3.1466450771978784e-08, "timer/dataset_eval_avg": 3.147125244140625e-05, "timer/dataset_eval_min": 3.147125244140625e-05, "timer/dataset_eval_max": 3.147125244140625e-05, "fps": 2.1886385423297035}
{"step": 153088, "time": 70349.31416845322, "episode/length": 170.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 153440, "time": 70509.42297673225, "episode/length": 175.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 153472, "time": 70525.30443620682, "episode/length": 152.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.0}
{"step": 153504, "time": 70541.12581133842, "episode/length": 199.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.99, "episode/intrinsic_return": 0.0}
{"step": 153560, "time": 70567.82804727554, "episode/length": 153.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 153872, "time": 70710.38875699043, "episode/length": 436.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9794050343249427, "episode/intrinsic_return": 0.0}
{"step": 153896, "time": 70722.71008133888, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 154504, "time": 70997.59468317032, "episode/length": 176.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 154544, "time": 71017.09719777107, "episode/length": 264.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 154576, "time": 71032.97504615784, "episode/length": 133.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9925373134328358, "episode/intrinsic_return": 0.0}
{"step": 154824, "time": 71146.35611915588, "episode/length": 168.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 155112, "time": 71278.35323905945, "episode/length": 208.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 155144, "time": 71294.37162542343, "episode/length": 158.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 155203, "time": 71323.6777639389, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.550861130112327, "train/action_min": 0.0, "train/action_std": 4.279207827308761, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04778551784974913, "train/actor_opt_grad_steps": 152560.0, "train/actor_opt_loss": -14.90398490047812, "train/adv_mag": 0.7098707212006441, "train/adv_max": 0.6317329859266633, "train/adv_mean": 0.002101598199007958, "train/adv_min": -0.5695971935850135, "train/adv_std": 0.054076959906909874, "train/cont_avg": 0.9943656394009217, "train/cont_loss_mean": 1.0427133945014323e-05, "train/cont_loss_std": 0.0002817511924056199, "train/cont_neg_acc": 0.9992319510279712, "train/cont_neg_loss": 0.0010754622687601796, "train/cont_pos_acc": 0.9999999821460741, "train/cont_pos_loss": 3.6520690306745917e-06, "train/cont_pred": 0.9943669240595558, "train/cont_rate": 0.9943656394009217, "train/dyn_loss_mean": 3.0875075577590874, "train/dyn_loss_std": 7.9039676530020575, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1682439784300491, "train/extr_critic_critic_opt_grad_steps": 152560.0, "train/extr_critic_critic_opt_loss": 14831.258825064804, "train/extr_critic_mag": 10.590127123116348, "train/extr_critic_max": 10.590127123116348, "train/extr_critic_mean": 2.1770843937649706, "train/extr_critic_min": -0.6622102013381396, "train/extr_critic_std": 2.183181752257633, "train/extr_return_normed_mag": 1.6879661775404406, "train/extr_return_normed_max": 1.6879661775404406, "train/extr_return_normed_mean": 0.3604779797627629, "train/extr_return_normed_min": -0.13251021389381676, "train/extr_return_normed_std": 0.33297515766961233, "train/extr_return_rate": 0.7811921384477396, "train/extr_return_raw_mag": 11.041219419048678, "train/extr_return_raw_max": 11.041219419048678, "train/extr_return_raw_mean": 2.191108193815029, "train/extr_return_raw_min": -1.0968731367093627, "train/extr_return_raw_std": 2.2215084282483923, "train/extr_reward_mag": 1.0231052532723421, "train/extr_reward_max": 1.0231052532723421, "train/extr_reward_mean": 0.03099034465677727, "train/extr_reward_min": -0.676919308675599, "train/extr_reward_std": 0.1782530530394497, "train/image_loss_mean": 1.5696168486973108, "train/image_loss_std": 4.947263207303764, "train/model_loss_mean": 3.4586572460315193, "train/model_loss_std": 8.775316451551728, "train/model_opt_grad_norm": 29.5336090782271, "train/model_opt_grad_steps": 152430.05529953918, "train/model_opt_loss": 8679.202290196572, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2511.5207373271887, "train/policy_entropy_mag": 2.543257159571494, "train/policy_entropy_max": 2.543257159571494, "train/policy_entropy_mean": 0.5629274196888444, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6406756134077152, "train/policy_logprob_mag": 7.438384093447215, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5635599905994081, "train/policy_logprob_min": -7.438384093447215, "train/policy_logprob_std": 1.117834558684705, "train/policy_randomness_mag": 0.8976581698189133, "train/policy_randomness_max": 0.8976581698189133, "train/policy_randomness_mean": 0.1986886758683464, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.22613037793043023, "train/post_ent_mag": 47.20551503968129, "train/post_ent_max": 47.20551503968129, "train/post_ent_mean": 29.059721116096743, "train/post_ent_min": 13.866477241164528, "train/post_ent_std": 4.847408270506265, "train/prior_ent_mag": 77.5607404577018, "train/prior_ent_max": 77.5607404577018, "train/prior_ent_mean": 32.03571032159339, "train/prior_ent_min": 15.433580750144571, "train/prior_ent_std": 8.750745278899021, "train/rep_loss_mean": 3.0875075577590874, "train/rep_loss_std": 7.9039676530020575, "train/reward_avg": 0.020927689158387722, "train/reward_loss_mean": 0.0365254364066547, "train/reward_loss_std": 0.1657427499577197, "train/reward_max_data": 1.0101382512650732, "train/reward_max_pred": 1.0106851818374774, "train/reward_neg_acc": 0.9966091129087633, "train/reward_neg_loss": 0.01827629253671672, "train/reward_pos_acc": 0.9891081883610668, "train/reward_pos_loss": 0.7243900112292734, "train/reward_pred": 0.02074831951847343, "train/reward_rate": 0.025926159274193547, "train_stats/sum_log_reward": 5.023076827709492, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 3.6923076923076925, "train_stats/max_log_achievement_collect_sapling": 1.6153846153846154, "train_stats/max_log_achievement_collect_stone": 0.23076923076923078, "train_stats/max_log_achievement_collect_wood": 5.153846153846154, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.23076923076923078, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.6153846153846154, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 2.230769230769231, "train_stats/max_log_achievement_wake_up": 2.1538461538461537, "train_stats/mean_log_entropy": 0.5272090916450207, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 1.8191309436588199e-06, "report/cont_loss_std": 8.51513868838083e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.2118657650717068e-06, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.8227101463708095e-06, "report/cont_pred": 0.9941388368606567, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 2.9008145332336426, "report/dyn_loss_std": 8.143563270568848, "report/image_loss_mean": 1.5548213720321655, "report/image_loss_std": 3.3327670097351074, "report/model_loss_mean": 3.3372623920440674, "report/model_loss_std": 7.133528709411621, "report/post_ent_mag": 43.177101135253906, "report/post_ent_max": 43.177101135253906, "report/post_ent_mean": 28.5584659576416, "report/post_ent_min": 12.460329055786133, "report/post_ent_std": 4.387518882751465, "report/prior_ent_mag": 77.44852447509766, "report/prior_ent_max": 77.44852447509766, "report/prior_ent_mean": 31.456790924072266, "report/prior_ent_min": 14.1661376953125, "report/prior_ent_std": 8.458894729614258, "report/rep_loss_mean": 2.9008145332336426, "report/rep_loss_std": 8.143563270568848, "report/reward_avg": 0.02617187425494194, "report/reward_loss_mean": 0.04195025563240051, "report/reward_loss_std": 0.15695664286613464, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.001235008239746, "report/reward_neg_acc": 0.9989908933639526, "report/reward_neg_loss": 0.02087746001780033, "report/reward_pos_acc": 0.9999999403953552, "report/reward_pos_loss": 0.6747726202011108, "report/reward_pred": 0.02627733163535595, "report/reward_rate": 0.0322265625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.0019623050466179848, "eval/cont_loss_std": 0.06241457536816597, "eval/cont_neg_acc": 0.75, "eval/cont_neg_loss": 0.5019917488098145, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 1.4053168797545368e-06, "eval/cont_pred": 0.9969459772109985, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 23.352933883666992, "eval/dyn_loss_std": 13.478850364685059, "eval/image_loss_mean": 41.82562255859375, "eval/image_loss_std": 45.38037872314453, "eval/model_loss_mean": 56.04601287841797, "eval/model_loss_std": 51.360328674316406, "eval/post_ent_mag": 48.51719284057617, "eval/post_ent_max": 48.51719284057617, "eval/post_ent_mean": 31.329578399658203, "eval/post_ent_min": 15.350958824157715, "eval/post_ent_std": 3.9438180923461914, "eval/prior_ent_mag": 77.44852447509766, "eval/prior_ent_max": 77.44852447509766, "eval/prior_ent_mean": 41.75337219238281, "eval/prior_ent_min": 18.37869644165039, "eval/prior_ent_std": 8.124896049499512, "eval/rep_loss_mean": 23.352933883666992, "eval/rep_loss_std": 13.478850364685059, "eval/reward_avg": 0.02255859412252903, "eval/reward_loss_mean": 0.20666547119617462, "eval/reward_loss_std": 1.2408303022384644, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0006310939788818, "eval/reward_neg_acc": 0.9979940056800842, "eval/reward_neg_loss": 0.13781194388866425, "eval/reward_pos_acc": 0.7777777910232544, "eval/reward_pos_loss": 2.749145746231079, "eval/reward_pred": 0.018817812204360962, "eval/reward_rate": 0.0263671875, "replay/size": 154699.0, "replay/inserts": 2172.0, "replay/samples": 34752.0, "replay/insert_wait_avg": 2.6865997806218885e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.789698643798547e-07, "replay/sample_wait_frac": 0.9999712246777164, "eval_replay/size": 30312.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 8.195638656616211e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2415721416473, "timer/env.step_count": 272.0, "timer/env.step_total": 27.148528337478638, "timer/env.step_frac": 0.02714197159327232, "timer/env.step_avg": 0.09981076594661265, "timer/env.step_min": 0.02368950843811035, "timer/env.step_max": 2.0878946781158447, "timer/replay._sample_count": 34752.0, "timer/replay._sample_total": 17.1094913482666, "timer/replay._sample_frac": 0.017105359170018253, "timer/replay._sample_avg": 0.0004923311276550012, "timer/replay._sample_min": 0.0003407001495361328, "timer/replay._sample_max": 0.010037899017333984, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 272.0, "timer/agent.policy_total": 4.359203338623047, "timer/agent.policy_frac": 0.004358150530865684, "timer/agent.policy_avg": 0.01602648286258473, "timer/agent.policy_min": 0.009790182113647461, "timer/agent.policy_max": 0.04269123077392578, "timer/dataset_train_count": 2172.0, "timer/dataset_train_total": 0.3760416507720947, "timer/dataset_train_frac": 0.00037595083152456926, "timer/dataset_train_avg": 0.00017313151508844142, "timer/dataset_train_min": 8.916854858398438e-05, "timer/dataset_train_max": 0.0004978179931640625, "timer/agent.train_count": 2172.0, "timer/agent.train_total": 966.6098980903625, "timer/agent.train_frac": 0.96637644846207, "timer/agent.train_avg": 0.4450321814412351, "timer/agent.train_min": 0.4343862533569336, "timer/agent.train_max": 0.562098503112793, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4741971492767334, "timer/agent.report_frac": 0.00047408262412190646, "timer/agent.report_avg": 0.2370985746383667, "timer/agent.report_min": 0.23015356063842773, "timer/agent.report_max": 0.24404358863830566, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.075599670410156e-05, "timer/dataset_eval_frac": 3.074856870650654e-08, "timer/dataset_eval_avg": 3.075599670410156e-05, "timer/dataset_eval_min": 3.075599670410156e-05, "timer/dataset_eval_max": 3.075599670410156e-05, "fps": 2.1714485381236126}
{"step": 155312, "time": 71373.09834885597, "episode/length": 91.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9456521739130435, "episode/intrinsic_return": 0.0}
{"step": 155504, "time": 71461.1113038063, "episode/length": 242.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9958847736625515, "episode/intrinsic_return": 0.0}
{"step": 155664, "time": 71535.58435082436, "episode/length": 220.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 155808, "time": 71602.05777430534, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 156120, "time": 71745.22208738327, "episode/length": 196.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 156256, "time": 71808.14701676369, "episode/length": 178.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 156320, "time": 71838.56213998795, "episode/length": 150.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9735099337748344, "episode/intrinsic_return": 0.0}
{"step": 156424, "time": 71887.7004609108, "episode/length": 138.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.0}
{"step": 156632, "time": 71983.0582845211, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 156832, "time": 72074.79712748528, "episode/length": 165.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 157048, "time": 72173.95624399185, "episode/length": 172.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 157375, "time": 72323.68846726418, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.580204695600519, "train/action_min": 0.0, "train/action_std": 4.370988995248821, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04692817060491456, "train/actor_opt_grad_steps": 154730.0, "train/actor_opt_loss": -15.125637273634634, "train/adv_mag": 0.664638000973908, "train/adv_max": 0.5962119482903986, "train/adv_mean": 0.001947328452444901, "train/adv_min": -0.5329153256207567, "train/adv_std": 0.05275803400967528, "train/cont_avg": 0.9945591517857143, "train/cont_loss_mean": 0.00010957801569654297, "train/cont_loss_std": 0.0034546334063900483, "train/cont_neg_acc": 0.9976446493979423, "train/cont_neg_loss": 0.017574114688067487, "train/cont_pos_acc": 0.9999909189439589, "train/cont_pos_loss": 1.3325471806511449e-05, "train/cont_pred": 0.9945648224672414, "train/cont_rate": 0.9945591517857143, "train/dyn_loss_mean": 3.0943725339828, "train/dyn_loss_std": 7.8954933667512535, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.188984485265846, "train/extr_critic_critic_opt_grad_steps": 154730.0, "train/extr_critic_critic_opt_loss": 14944.90881516417, "train/extr_critic_mag": 10.366277525501866, "train/extr_critic_max": 10.366277525501866, "train/extr_critic_mean": 2.1911241991728683, "train/extr_critic_min": -0.6731376631468672, "train/extr_critic_std": 2.1871924026770526, "train/extr_return_normed_mag": 1.6371547132043796, "train/extr_return_normed_max": 1.6371547132043796, "train/extr_return_normed_mean": 0.36232449993285165, "train/extr_return_normed_min": -0.1204623694656082, "train/extr_return_normed_std": 0.3319228171340881, "train/extr_return_rate": 0.7759607016765577, "train/extr_return_raw_mag": 10.740873982829433, "train/extr_return_raw_max": 10.740873982829433, "train/extr_return_raw_mean": 2.204157256310986, "train/extr_return_raw_min": -1.0280172094222038, "train/extr_return_raw_std": 2.2218281865669285, "train/extr_reward_mag": 1.0308554617490637, "train/extr_reward_max": 1.0308554617490637, "train/extr_reward_mean": 0.03354720124107902, "train/extr_reward_min": -0.6717850722475536, "train/extr_reward_std": 0.18393842429609342, "train/image_loss_mean": 1.6023520689955504, "train/image_loss_std": 5.107270490189302, "train/model_loss_mean": 3.4957610912586685, "train/model_loss_std": 8.91446880041729, "train/model_opt_grad_norm": 29.495116879863122, "train/model_opt_grad_steps": 154598.06451612903, "train/model_opt_loss": 6854.75615076865, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1958.5253456221199, "train/policy_entropy_mag": 2.539064986365182, "train/policy_entropy_max": 2.539064986365182, "train/policy_entropy_mean": 0.5545147311302924, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6406517984680317, "train/policy_logprob_mag": 7.438384108829059, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.555212976883084, "train/policy_logprob_min": -7.438384108829059, "train/policy_logprob_std": 1.1131837565778038, "train/policy_randomness_mag": 0.8961785166494308, "train/policy_randomness_max": 0.8961785166494308, "train/policy_randomness_mean": 0.19571936645540775, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.22612197072275222, "train/post_ent_mag": 46.92692033266692, "train/post_ent_max": 46.92692033266692, "train/post_ent_mean": 29.310083424440727, "train/post_ent_min": 14.34118722221269, "train/post_ent_std": 4.794163823677098, "train/prior_ent_mag": 77.49023609776651, "train/prior_ent_max": 77.49023609776651, "train/prior_ent_mean": 32.27843137820196, "train/prior_ent_min": 15.796265918538317, "train/prior_ent_std": 8.656621693466116, "train/rep_loss_mean": 3.0943725339828, "train/rep_loss_std": 7.8954933667512535, "train/reward_avg": 0.021584281333065527, "train/reward_loss_mean": 0.03667592101897787, "train/reward_loss_std": 0.16532673532237654, "train/reward_max_data": 1.017972354515357, "train/reward_max_pred": 1.0164571121541037, "train/reward_neg_acc": 0.9962548168573512, "train/reward_neg_loss": 0.018223991696958854, "train/reward_pos_acc": 0.9923695707650778, "train/reward_pos_loss": 0.7159297784901983, "train/reward_pred": 0.021430057040007982, "train/reward_rate": 0.02646619383640553, "train_stats/sum_log_reward": 4.827272653579712, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 1.7272727272727273, "train_stats/max_log_achievement_collect_sapling": 1.4545454545454546, "train_stats/max_log_achievement_collect_stone": 0.6363636363636364, "train_stats/max_log_achievement_collect_wood": 4.0, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.45454545454545453, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.4545454545454546, "train_stats/max_log_achievement_place_stone": 0.18181818181818182, "train_stats/max_log_achievement_place_table": 1.4545454545454546, "train_stats/max_log_achievement_wake_up": 2.0, "train_stats/mean_log_entropy": 0.47806271097876807, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 2.1060961898911046e-06, "report/cont_loss_std": 2.7363303161109798e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 2.2165208974911366e-06, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.1055543584225234e-06, "report/cont_pred": 0.9951151013374329, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 2.933741569519043, "report/dyn_loss_std": 7.578502655029297, "report/image_loss_mean": 1.6905542612075806, "report/image_loss_std": 5.300208568572998, "report/model_loss_mean": 3.485138177871704, "report/model_loss_std": 8.71146297454834, "report/post_ent_mag": 44.01568603515625, "report/post_ent_max": 44.01568603515625, "report/post_ent_mean": 28.38701820373535, "report/post_ent_min": 15.364419937133789, "report/post_ent_std": 4.633615970611572, "report/prior_ent_mag": 77.11378479003906, "report/prior_ent_max": 77.11378479003906, "report/prior_ent_mean": 31.416006088256836, "report/prior_ent_min": 16.892597198486328, "report/prior_ent_std": 8.42985725402832, "report/rep_loss_mean": 2.933741569519043, "report/rep_loss_std": 7.578502655029297, "report/reward_avg": 0.02138671651482582, "report/reward_loss_mean": 0.03433670103549957, "report/reward_loss_std": 0.14542055130004883, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0006473064422607, "report/reward_neg_acc": 0.9989960789680481, "report/reward_neg_loss": 0.015509857796132565, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7040345668792725, "report/reward_pred": 0.020808681845664978, "report/reward_rate": 0.02734375, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 7.789896699250676e-06, "eval/cont_loss_std": 0.00012723472900688648, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.001901521347463131, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.225552862000768e-06, "eval/cont_pred": 0.9970736503601074, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 23.014997482299805, "eval/dyn_loss_std": 12.209609985351562, "eval/image_loss_mean": 33.55711364746094, "eval/image_loss_std": 35.90956115722656, "eval/model_loss_mean": 47.47489929199219, "eval/model_loss_std": 40.717384338378906, "eval/post_ent_mag": 48.466373443603516, "eval/post_ent_max": 48.466373443603516, "eval/post_ent_mean": 31.72568130493164, "eval/post_ent_min": 19.317283630371094, "eval/post_ent_std": 3.848806142807007, "eval/prior_ent_mag": 77.11378479003906, "eval/prior_ent_max": 77.11378479003906, "eval/prior_ent_mean": 43.63169860839844, "eval/prior_ent_min": 21.849775314331055, "eval/prior_ent_std": 7.266980171203613, "eval/rep_loss_mean": 23.014997482299805, "eval/rep_loss_std": 12.209609985351562, "eval/reward_avg": 0.03388671949505806, "eval/reward_loss_mean": 0.10878194123506546, "eval/reward_loss_std": 0.7096667885780334, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0000584125518799, "eval/reward_neg_acc": 0.9969604015350342, "eval/reward_neg_loss": 0.021776972338557243, "eval/reward_pos_acc": 0.675675630569458, "eval/reward_pos_loss": 2.4296982288360596, "eval/reward_pred": 0.021350566297769547, "eval/reward_rate": 0.0361328125, "replay/size": 156871.0, "replay/inserts": 2172.0, "replay/samples": 34752.0, "replay/insert_wait_avg": 2.6155791449502906e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.54559951153469e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 30312.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 1.0281801223754883e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 999.999703168869, "timer/env.step_count": 271.0, "timer/env.step_total": 24.350881576538086, "timer/env.step_frac": 0.02435088880463995, "timer/env.step_avg": 0.08985565157394128, "timer/env.step_min": 0.02352166175842285, "timer/env.step_max": 1.932220697402954, "timer/replay._sample_count": 34752.0, "timer/replay._sample_total": 17.10883116722107, "timer/replay._sample_frac": 0.017108836245656282, "timer/replay._sample_avg": 0.0004923121307326505, "timer/replay._sample_min": 0.00037789344787597656, "timer/replay._sample_max": 0.011413097381591797, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 271.0, "timer/agent.policy_total": 4.318648338317871, "timer/agent.policy_frac": 0.004318649620227522, "timer/agent.policy_avg": 0.015935971728110225, "timer/agent.policy_min": 0.00971221923828125, "timer/agent.policy_max": 0.01812887191772461, "timer/dataset_train_count": 2172.0, "timer/dataset_train_total": 0.3808023929595947, "timer/dataset_train_frac": 0.00038080250599363324, "timer/dataset_train_avg": 0.00017532338534051323, "timer/dataset_train_min": 8.988380432128906e-05, "timer/dataset_train_max": 0.0009620189666748047, "timer/agent.train_count": 2172.0, "timer/agent.train_total": 969.1009037494659, "timer/agent.train_frac": 0.9691011914088686, "timer/agent.train_avg": 0.446179053291651, "timer/agent.train_min": 0.4338345527648926, "timer/agent.train_max": 0.5618548393249512, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4762904644012451, "timer/agent.report_frac": 0.00047629060577912433, "timer/agent.report_avg": 0.23814523220062256, "timer/agent.report_min": 0.23054838180541992, "timer/agent.report_max": 0.2457420825958252, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.765655517578125e-05, "timer/dataset_eval_frac": 2.765656338511024e-08, "timer/dataset_eval_avg": 2.765655517578125e-05, "timer/dataset_eval_min": 2.765655517578125e-05, "timer/dataset_eval_max": 2.765655517578125e-05, "fps": 2.171972570606448}
{"step": 157512, "time": 72385.4504263401, "episode/length": 173.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 157752, "time": 72494.59576153755, "episode/length": 242.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9958847736625515, "episode/intrinsic_return": 0.0}
{"step": 157936, "time": 72578.44907331467, "episode/length": 188.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 157992, "time": 72605.04635453224, "episode/length": 208.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 158056, "time": 72635.15389466286, "episode/length": 125.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9920634920634921, "episode/intrinsic_return": 0.0}
{"step": 158240, "time": 72719.28858733177, "episode/length": 247.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9798387096774194, "episode/intrinsic_return": 0.0}
{"step": 158248, "time": 72724.34356737137, "episode/length": 176.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 158408, "time": 72797.5071823597, "episode/length": 58.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9322033898305084, "episode/intrinsic_return": 0.0}
{"step": 158616, "time": 72892.15141153336, "episode/length": 137.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.0}
{"step": 159032, "time": 73080.68011331558, "episode/length": 159.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 159056, "time": 73092.94576787949, "episode/length": 302.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9900990099009901, "episode/intrinsic_return": 0.0}
{"step": 159288, "time": 73198.54697966576, "episode/length": 153.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 159536, "time": 73311.03185200691, "episode/length": 160.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 159560, "time": 73323.78673696518, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.515348808950485, "train/action_min": 0.0, "train/action_std": 4.337847643246934, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04897555530275384, "train/actor_opt_grad_steps": 156910.0, "train/actor_opt_loss": -14.830723803881641, "train/adv_mag": 0.7108024454007954, "train/adv_max": 0.6301887047617403, "train/adv_mean": 0.0025543854814992243, "train/adv_min": -0.5728605967950603, "train/adv_std": 0.05512990753196146, "train/cont_avg": 0.994408176369863, "train/cont_loss_mean": 1.1455663480046289e-05, "train/cont_loss_std": 0.0003381877033356033, "train/cont_neg_acc": 0.9992389651738345, "train/cont_neg_loss": 0.0008934409493148031, "train/cont_pos_acc": 0.9999999812204544, "train/cont_pos_loss": 6.305857481705079e-06, "train/cont_pred": 0.9944062992318036, "train/cont_rate": 0.994408176369863, "train/dyn_loss_mean": 3.075071527533335, "train/dyn_loss_std": 7.866741191306615, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1710104765413014, "train/extr_critic_critic_opt_grad_steps": 156910.0, "train/extr_critic_critic_opt_loss": 15049.290364583334, "train/extr_critic_mag": 10.22053833094906, "train/extr_critic_max": 10.22053833094906, "train/extr_critic_mean": 2.1841624191362565, "train/extr_critic_min": -0.6359695582629339, "train/extr_critic_std": 2.0803120158034374, "train/extr_return_normed_mag": 1.6570714146034902, "train/extr_return_normed_max": 1.6570714146034902, "train/extr_return_normed_mean": 0.3711507793975203, "train/extr_return_normed_min": -0.11883215749100463, "train/extr_return_normed_std": 0.3279534725293721, "train/extr_return_rate": 0.7935258914890899, "train/extr_return_raw_mag": 10.50347590555339, "train/extr_return_raw_max": 10.50347590555339, "train/extr_return_raw_mean": 2.20065076982594, "train/extr_return_raw_min": -0.9606269753142579, "train/extr_return_raw_std": 2.1172288726998247, "train/extr_reward_mag": 1.023083853395018, "train/extr_reward_max": 1.023083853395018, "train/extr_reward_mean": 0.03380270634850138, "train/extr_reward_min": -0.6804863268926263, "train/extr_reward_std": 0.1839234183912408, "train/image_loss_mean": 1.502164233492934, "train/image_loss_std": 4.646226443656503, "train/model_loss_mean": 3.383800524010506, "train/model_loss_std": 8.481334612249784, "train/model_opt_grad_norm": 29.15770248953066, "train/model_opt_grad_steps": 156776.44292237444, "train/model_opt_loss": 8812.424505921803, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2625.5707762557076, "train/policy_entropy_mag": 2.550559330204306, "train/policy_entropy_max": 2.550559330204306, "train/policy_entropy_mean": 0.5366736243576764, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6209596598257213, "train/policy_logprob_mag": 7.43838411705679, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5370364963463997, "train/policy_logprob_min": -7.43838411705679, "train/policy_logprob_std": 1.1015477958879514, "train/policy_randomness_mag": 0.9002355135739122, "train/policy_randomness_max": 0.9002355135739122, "train/policy_randomness_mean": 0.18942223741039294, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.21917151248074013, "train/post_ent_mag": 47.44827185156139, "train/post_ent_max": 47.44827185156139, "train/post_ent_mean": 29.412593310282112, "train/post_ent_min": 14.034841332805755, "train/post_ent_std": 4.870975389872512, "train/prior_ent_mag": 77.52323512943913, "train/prior_ent_max": 77.52323512943913, "train/prior_ent_mean": 32.359646662185185, "train/prior_ent_min": 15.695859347304253, "train/prior_ent_std": 8.678291601677463, "train/rep_loss_mean": 3.075071527533335, "train/rep_loss_std": 7.866741191306615, "train/reward_avg": 0.02107591311272965, "train/reward_loss_mean": 0.03658193769996569, "train/reward_loss_std": 0.1641098736832131, "train/reward_max_data": 1.0105022856089623, "train/reward_max_pred": 1.0108118481832007, "train/reward_neg_acc": 0.996018568402556, "train/reward_neg_loss": 0.01843249036815681, "train/reward_pos_acc": 0.9904998761333831, "train/reward_pos_loss": 0.715545361989165, "train/reward_pred": 0.02090286007831426, "train/reward_rate": 0.02600599315068493, "train_stats/sum_log_reward": 4.5615383845109205, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 2.769230769230769, "train_stats/max_log_achievement_collect_sapling": 1.9230769230769231, "train_stats/max_log_achievement_collect_stone": 0.23076923076923078, "train_stats/max_log_achievement_collect_wood": 2.769230769230769, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.15384615384615385, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.6923076923076923, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 1.0769230769230769, "train_stats/max_log_achievement_wake_up": 1.6153846153846154, "train_stats/mean_log_entropy": 0.562094156558697, "report/cont_avg": 0.990234375, "report/cont_loss_mean": 2.957269771286519e-07, "report/cont_loss_std": 3.064730208279798e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 2.5678848487586947e-06, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.733191308834648e-07, "report/cont_pred": 0.9902341365814209, "report/cont_rate": 0.990234375, "report/dyn_loss_mean": 3.2040467262268066, "report/dyn_loss_std": 8.135221481323242, "report/image_loss_mean": 1.6317259073257446, "report/image_loss_std": 4.73708963394165, "report/model_loss_mean": 3.596940517425537, "report/model_loss_std": 8.537867546081543, "report/post_ent_mag": 49.52867889404297, "report/post_ent_max": 49.52867889404297, "report/post_ent_mean": 30.255123138427734, "report/post_ent_min": 12.725168228149414, "report/post_ent_std": 4.798396110534668, "report/prior_ent_mag": 77.65209197998047, "report/prior_ent_max": 77.65209197998047, "report/prior_ent_mean": 33.07150650024414, "report/prior_ent_min": 13.359245300292969, "report/prior_ent_std": 9.029549598693848, "report/rep_loss_mean": 3.2040467262268066, "report/rep_loss_std": 8.135221481323242, "report/reward_avg": 0.01982421800494194, "report/reward_loss_mean": 0.04278642684221268, "report/reward_loss_std": 0.16731789708137512, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.0937652587890625, "report/reward_neg_acc": 0.9889668822288513, "report/reward_neg_loss": 0.025768408551812172, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6711925864219666, "report/reward_pred": 0.020290633663535118, "report/reward_rate": 0.0263671875, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.0018881508149206638, "eval/cont_loss_std": 0.05065397918224335, "eval/cont_neg_acc": 0.8333333730697632, "eval/cont_neg_loss": 0.3222132921218872, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.8353941300119914e-07, "eval/cont_pred": 0.9952100515365601, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 22.3468074798584, "eval/dyn_loss_std": 12.404220581054688, "eval/image_loss_mean": 32.686126708984375, "eval/image_loss_std": 39.20417022705078, "eval/model_loss_mean": 46.31928253173828, "eval/model_loss_std": 44.04399490356445, "eval/post_ent_mag": 49.52867889404297, "eval/post_ent_max": 49.52867889404297, "eval/post_ent_mean": 33.01166915893555, "eval/post_ent_min": 18.331283569335938, "eval/post_ent_std": 4.371659755706787, "eval/prior_ent_mag": 77.65209197998047, "eval/prior_ent_max": 77.65209197998047, "eval/prior_ent_mean": 43.588321685791016, "eval/prior_ent_min": 18.992748260498047, "eval/prior_ent_std": 8.31534481048584, "eval/rep_loss_mean": 22.3468074798584, "eval/rep_loss_std": 12.404220581054688, "eval/reward_avg": 0.013769530691206455, "eval/reward_loss_mean": 0.22318482398986816, "eval/reward_loss_std": 1.1814777851104736, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0000131130218506, "eval/reward_neg_acc": 0.9900398850440979, "eval/reward_neg_loss": 0.16538415849208832, "eval/reward_pos_acc": 0.6000000238418579, "eval/reward_pos_loss": 3.1247785091400146, "eval/reward_pred": 0.010996289551258087, "eval/reward_rate": 0.01953125, "replay/size": 159056.0, "replay/inserts": 2185.0, "replay/samples": 34960.0, "replay/insert_wait_avg": 2.678362673971146e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.71300470801731e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 30312.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 9.387731552124023e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0852448940277, "timer/env.step_count": 273.0, "timer/env.step_total": 26.10610604286194, "timer/env.step_frac": 0.0261038808203077, "timer/env.step_avg": 0.09562676206176535, "timer/env.step_min": 0.02342534065246582, "timer/env.step_max": 1.6265053749084473, "timer/replay._sample_count": 34960.0, "timer/replay._sample_total": 17.16429901123047, "timer/replay._sample_frac": 0.017162835967097237, "timer/replay._sample_avg": 0.0004909696513509859, "timer/replay._sample_min": 0.0003762245178222656, "timer/replay._sample_max": 0.03477215766906738, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 273.0, "timer/agent.policy_total": 4.339403867721558, "timer/agent.policy_frac": 0.0043390339872291335, "timer/agent.policy_avg": 0.01589525226271633, "timer/agent.policy_min": 0.009721040725708008, "timer/agent.policy_max": 0.0377500057220459, "timer/dataset_train_count": 2185.0, "timer/dataset_train_total": 0.3902907371520996, "timer/dataset_train_frac": 0.0003902574696954519, "timer/dataset_train_avg": 0.0001786227629986726, "timer/dataset_train_min": 9.274482727050781e-05, "timer/dataset_train_max": 0.0008795261383056641, "timer/agent.train_count": 2185.0, "timer/agent.train_total": 967.5249989032745, "timer/agent.train_frac": 0.9674425293673807, "timer/agent.train_avg": 0.44280320315939337, "timer/agent.train_min": 0.43178272247314453, "timer/agent.train_max": 0.845130205154419, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4719243049621582, "timer/agent.report_frac": 0.00047188407925382887, "timer/agent.report_avg": 0.2359621524810791, "timer/agent.report_min": 0.22939372062683105, "timer/agent.report_max": 0.24253058433532715, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8133392333984375e-05, "timer/dataset_eval_frac": 2.8130994310355496e-08, "timer/dataset_eval_avg": 2.8133392333984375e-05, "timer/dataset_eval_min": 2.8133392333984375e-05, "timer/dataset_eval_max": 2.8133392333984375e-05, "fps": 2.184784615331798}
{"step": 159728, "time": 73400.00759530067, "episode/length": 185.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 159824, "time": 73444.88392710686, "episode/length": 228.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9781659388646288, "episode/intrinsic_return": 0.0}
{"step": 160056, "time": 73569.17140388489, "eval_episode/length": 136.0, "eval_episode/score": 5.100000023841858, "eval_episode/reward_rate": 0.9927007299270073}
{"step": 160056, "time": 73571.4522163868, "eval_episode/length": 156.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9745222929936306}
{"step": 160056, "time": 73571.45996189117, "eval_episode/length": 156.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9936305732484076}
{"step": 160056, "time": 73574.74067664146, "eval_episode/length": 159.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.96875}
{"step": 160056, "time": 73576.81430363655, "eval_episode/length": 171.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9709302325581395}
{"step": 160056, "time": 73578.41037583351, "eval_episode/length": 173.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.9942528735632183}
{"step": 160056, "time": 73581.27639818192, "eval_episode/length": 207.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9951923076923077}
{"step": 160056, "time": 73583.46816825867, "eval_episode/length": 222.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9820627802690582}
{"step": 160080, "time": 73594.32027101517, "episode/length": 208.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 160176, "time": 73638.69349741936, "episode/length": 194.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 160336, "time": 73712.30630493164, "episode/length": 162.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 160544, "time": 73807.93009233475, "episode/length": 156.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 160816, "time": 73932.8923561573, "episode/length": 219.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 160824, "time": 73938.0972442627, "episode/length": 160.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 160952, "time": 73998.20199346542, "episode/length": 140.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9645390070921985, "episode/intrinsic_return": 0.0}
{"step": 161392, "time": 74199.042958498, "episode/length": 163.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 161520, "time": 74258.63978338242, "episode/length": 167.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 161659, "time": 74323.81835365295, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.347331799958882, "train/action_min": 0.0, "train/action_std": 4.212080128455276, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04852595074218141, "train/actor_opt_grad_steps": 159050.0, "train/actor_opt_loss": -12.310809094815305, "train/adv_mag": 0.6546527846007826, "train/adv_max": 0.5943865289813594, "train/adv_mean": 0.002677475418227766, "train/adv_min": -0.5312582416967913, "train/adv_std": 0.05398311669176275, "train/cont_avg": 0.994397615131579, "train/cont_loss_mean": 2.893524311160767e-06, "train/cont_loss_std": 3.302636603563408e-05, "train/cont_neg_acc": 1.0, "train/cont_neg_loss": 1.2375797262747641e-05, "train/cont_pos_acc": 0.9999999783255837, "train/cont_pos_loss": 2.8367264724775497e-06, "train/cont_pred": 0.9943949523154628, "train/cont_rate": 0.994397615131579, "train/dyn_loss_mean": 3.1406362809632955, "train/dyn_loss_std": 7.9529250706211805, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1515789342839182, "train/extr_critic_critic_opt_grad_steps": 159050.0, "train/extr_critic_critic_opt_loss": 15035.96636232805, "train/extr_critic_mag": 9.616442744241377, "train/extr_critic_max": 9.616442744241377, "train/extr_critic_mean": 2.1646978045194345, "train/extr_critic_min": -0.6661519622118279, "train/extr_critic_std": 2.0475959926130667, "train/extr_return_normed_mag": 1.623606128555736, "train/extr_return_normed_max": 1.623606128555736, "train/extr_return_normed_mean": 0.3707772185357564, "train/extr_return_normed_min": -0.1291134619113931, "train/extr_return_normed_std": 0.32395507395267487, "train/extr_return_rate": 0.7715526351518038, "train/extr_return_raw_mag": 10.245147257900694, "train/extr_return_raw_max": 10.245147257900694, "train/extr_return_raw_mean": 2.1819247674713864, "train/extr_return_raw_min": -1.0343632047826594, "train/extr_return_raw_std": 2.0843309454940724, "train/extr_reward_mag": 1.0254759856958708, "train/extr_reward_max": 1.0254759856958708, "train/extr_reward_mean": 0.033818974743405596, "train/extr_reward_min": -0.6845880262018961, "train/extr_reward_std": 0.18450348820697748, "train/image_loss_mean": 1.6054890697652644, "train/image_loss_std": 4.974361885107305, "train/model_loss_mean": 3.5268167388496217, "train/model_loss_std": 8.823465094041596, "train/model_opt_grad_norm": 29.226612742130573, "train/model_opt_grad_steps": 158914.11961722487, "train/model_opt_loss": 6724.771503065192, "train/model_opt_model_opt_grad_overflow": 0.004784688995215311, "train/model_opt_model_opt_grad_scale": 1895.933014354067, "train/policy_entropy_mag": 2.553736990148371, "train/policy_entropy_max": 2.553736990148371, "train/policy_entropy_mean": 0.5268572831267946, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6114693278330935, "train/policy_logprob_mag": 7.438384140507456, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5267530333197288, "train/policy_logprob_min": -7.438384140507456, "train/policy_logprob_std": 1.0934692387375535, "train/policy_randomness_mag": 0.9013570903590992, "train/policy_randomness_max": 0.9013570903590992, "train/policy_randomness_mean": 0.18595750137949674, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.21582183983337366, "train/post_ent_mag": 47.44806627337442, "train/post_ent_max": 47.44806627337442, "train/post_ent_mean": 29.637775503277208, "train/post_ent_min": 14.214096192537882, "train/post_ent_std": 4.837995800675388, "train/prior_ent_mag": 77.56701572545978, "train/prior_ent_max": 77.56701572545978, "train/prior_ent_mean": 32.66067420922968, "train/prior_ent_min": 15.99940943375729, "train/prior_ent_std": 8.659741787248821, "train/rep_loss_mean": 3.1406362809632955, "train/rep_loss_std": 7.9529250706211805, "train/reward_avg": 0.020885354219868993, "train/reward_loss_mean": 0.03694302683170332, "train/reward_loss_std": 0.16981323081197922, "train/reward_max_data": 1.0110047873127403, "train/reward_max_pred": 1.0113433422654439, "train/reward_neg_acc": 0.9963312739390505, "train/reward_neg_loss": 0.01858122938459641, "train/reward_pos_acc": 0.9897612598524139, "train/reward_pos_loss": 0.7272108026098406, "train/reward_pred": 0.02069021032846858, "train/reward_rate": 0.025941985645933013, "train_stats/sum_log_reward": 5.28181808645075, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 5.0, "train_stats/max_log_achievement_collect_sapling": 1.6363636363636365, "train_stats/max_log_achievement_collect_stone": 0.18181818181818182, "train_stats/max_log_achievement_collect_wood": 5.363636363636363, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.8181818181818182, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.6363636363636365, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 2.0, "train_stats/max_log_achievement_wake_up": 1.7272727272727273, "train_stats/mean_log_entropy": 0.4962769421664151, "eval_stats/sum_log_reward": 4.724999904632568, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 2.25, "eval_stats/max_log_achievement_collect_sapling": 1.875, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 3.25, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.25, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 1.875, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 1.25, "eval_stats/max_log_achievement_wake_up": 1.625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 3.531118409227929e-06, "report/cont_loss_std": 4.0490791434422135e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0006215905887074769, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 1.107355615204142e-06, "report/cont_pred": 0.9960950613021851, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 3.6025171279907227, "report/dyn_loss_std": 8.378732681274414, "report/image_loss_mean": 2.3860301971435547, "report/image_loss_std": 5.2898173332214355, "report/model_loss_mean": 4.573448657989502, "report/model_loss_std": 9.100809097290039, "report/post_ent_mag": 49.59247589111328, "report/post_ent_max": 49.59247589111328, "report/post_ent_mean": 29.417240142822266, "report/post_ent_min": 15.072099685668945, "report/post_ent_std": 4.746530532836914, "report/prior_ent_mag": 77.63587951660156, "report/prior_ent_max": 77.63587951660156, "report/prior_ent_mean": 32.7188720703125, "report/prior_ent_min": 17.660390853881836, "report/prior_ent_std": 9.155803680419922, "report/rep_loss_mean": 3.6025171279907227, "report/rep_loss_std": 8.378732681274414, "report/reward_avg": 0.01777343824505806, "report/reward_loss_mean": 0.02590487338602543, "report/reward_loss_std": 0.1289490908384323, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0006420612335205, "report/reward_neg_acc": 0.9970059990882874, "report/reward_neg_loss": 0.011640142649412155, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6755985021591187, "report/reward_pred": 0.018504604697227478, "report/reward_rate": 0.021484375, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 6.771914286218816e-06, "eval/cont_loss_std": 0.00012792072084266692, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0028959624469280243, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.1179208740941249e-06, "eval/cont_pred": 0.9980514049530029, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 22.497535705566406, "eval/dyn_loss_std": 12.101848602294922, "eval/image_loss_mean": 39.19443130493164, "eval/image_loss_std": 43.8284912109375, "eval/model_loss_mean": 52.887142181396484, "eval/model_loss_std": 48.32396697998047, "eval/post_ent_mag": 44.875152587890625, "eval/post_ent_max": 44.875152587890625, "eval/post_ent_mean": 31.56035041809082, "eval/post_ent_min": 15.784857749938965, "eval/post_ent_std": 4.2315263748168945, "eval/prior_ent_mag": 77.63587951660156, "eval/prior_ent_max": 77.63587951660156, "eval/prior_ent_mean": 42.7133674621582, "eval/prior_ent_min": 17.376506805419922, "eval/prior_ent_std": 8.315537452697754, "eval/rep_loss_mean": 22.497535705566406, "eval/rep_loss_std": 12.101848602294922, "eval/reward_avg": 0.03105468675494194, "eval/reward_loss_mean": 0.19418293237686157, "eval/reward_loss_std": 1.2401655912399292, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0084302425384521, "eval/reward_neg_acc": 0.9959554076194763, "eval/reward_neg_loss": 0.1262640655040741, "eval/reward_pos_acc": 0.800000011920929, "eval/reward_pos_loss": 2.113375663757324, "eval/reward_pred": 0.023812633007764816, "eval/reward_rate": 0.0341796875, "replay/size": 161155.0, "replay/inserts": 2099.0, "replay/samples": 33584.0, "replay/insert_wait_avg": 2.580804447721106e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.050176630479032e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 32096.0, "eval_replay/inserts": 1784.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.123133261642114e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.791685104370117e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0156280994415, "timer/env.step_count": 263.0, "timer/env.step_total": 23.884032011032104, "timer/env.step_frac": 0.023883658754838055, "timer/env.step_avg": 0.09081380992787873, "timer/env.step_min": 0.02383875846862793, "timer/env.step_max": 1.9548227787017822, "timer/replay._sample_count": 33584.0, "timer/replay._sample_total": 17.368288278579712, "timer/replay._sample_frac": 0.017368016849485288, "timer/replay._sample_avg": 0.0005171596081044459, "timer/replay._sample_min": 0.0003650188446044922, "timer/replay._sample_max": 0.026238679885864258, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 486.0, "timer/agent.policy_total": 7.814242362976074, "timer/agent.policy_frac": 0.007814120243127866, "timer/agent.policy_avg": 0.016078687989662704, "timer/agent.policy_min": 0.009662866592407227, "timer/agent.policy_max": 0.02529430389404297, "timer/dataset_train_count": 2099.0, "timer/dataset_train_total": 0.38524389266967773, "timer/dataset_train_frac": 0.00038523787213390337, "timer/dataset_train_avg": 0.0001835368712099465, "timer/dataset_train_min": 9.894371032714844e-05, "timer/dataset_train_max": 0.0005216598510742188, "timer/agent.train_count": 2099.0, "timer/agent.train_total": 937.4716229438782, "timer/agent.train_frac": 0.9374569722730933, "timer/agent.train_avg": 0.44662773842014203, "timer/agent.train_min": 0.43408894538879395, "timer/agent.train_max": 0.5550987720489502, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.478595495223999, "timer/agent.report_frac": 0.00047858801580289654, "timer/agent.report_avg": 0.2392977476119995, "timer/agent.report_min": 0.23092079162597656, "timer/agent.report_max": 0.24767470359802246, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.4809112548828125e-05, "timer/dataset_eval_frac": 3.48085685570573e-08, "timer/dataset_eval_avg": 3.4809112548828125e-05, "timer/dataset_eval_min": 3.4809112548828125e-05, "timer/dataset_eval_max": 3.4809112548828125e-05, "fps": 2.098940951672427}
{"step": 161688, "time": 74337.24611616135, "episode/length": 168.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 161784, "time": 74382.20377278328, "episode/length": 256.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.980544747081712, "episode/intrinsic_return": 0.0}
{"step": 162208, "time": 74576.03694796562, "episode/length": 207.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 162280, "time": 74610.24128007889, "episode/length": 165.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 162424, "time": 74676.98738050461, "episode/length": 199.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.965, "episode/intrinsic_return": 0.0}
{"step": 162672, "time": 74790.88193249702, "episode/length": 231.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 163128, "time": 74999.54095888138, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 163136, "time": 75004.77340269089, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 163136, "time": 75004.91071367264, "episode/length": 57.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 163184, "time": 75029.76805472374, "episode/length": 207.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9663461538461539, "episode/intrinsic_return": 0.0}
{"step": 163344, "time": 75103.83140039444, "episode/length": 132.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9924812030075187, "episode/intrinsic_return": 0.0}
{"step": 163528, "time": 75189.10057091713, "episode/length": 266.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9962546816479401, "episode/intrinsic_return": 0.0}
{"step": 163800, "time": 75314.38381814957, "episode/length": 198.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 163817, "time": 75324.08910822868, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.530118589048032, "train/action_min": 0.0, "train/action_std": 4.304394334554672, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.049376392952614916, "train/actor_opt_grad_steps": 161175.0, "train/actor_opt_loss": -19.926087179945576, "train/adv_mag": 0.6913599956918646, "train/adv_max": 0.6153189083216367, "train/adv_mean": 0.0014499331659862946, "train/adv_min": -0.5676797915388037, "train/adv_std": 0.05573907577329212, "train/cont_avg": 0.9946424696180556, "train/cont_loss_mean": 3.892770394788282e-05, "train/cont_loss_std": 0.0011963711605799984, "train/cont_neg_acc": 0.9972810116079118, "train/cont_neg_loss": 0.00980043799160268, "train/cont_pos_acc": 0.9999999793039428, "train/cont_pos_loss": 2.236901429469245e-06, "train/cont_pred": 0.9946526694628928, "train/cont_rate": 0.9946424696180556, "train/dyn_loss_mean": 3.0844926138718924, "train/dyn_loss_std": 7.886426053665303, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1193743168755814, "train/extr_critic_critic_opt_grad_steps": 161175.0, "train/extr_critic_critic_opt_loss": 14953.516217267072, "train/extr_critic_mag": 10.07562079694536, "train/extr_critic_max": 10.07562079694536, "train/extr_critic_mean": 2.229148883510519, "train/extr_critic_min": -0.6744473184700366, "train/extr_critic_std": 2.104274301617234, "train/extr_return_normed_mag": 1.6646469643822424, "train/extr_return_normed_max": 1.6646469643822424, "train/extr_return_normed_mean": 0.37760032313289466, "train/extr_return_normed_min": -0.12258702250956385, "train/extr_return_normed_std": 0.32908209703034824, "train/extr_return_rate": 0.7586157911077693, "train/extr_return_raw_mag": 10.610366717532829, "train/extr_return_raw_max": 10.610366717532829, "train/extr_return_raw_mean": 2.238594529253465, "train/extr_return_raw_min": -1.0171592696397393, "train/extr_return_raw_std": 2.1414519537378243, "train/extr_reward_mag": 1.0265869868022424, "train/extr_reward_max": 1.0265869868022424, "train/extr_reward_mean": 0.03560219949145836, "train/extr_reward_min": -0.6716696310926367, "train/extr_reward_std": 0.18819086074277205, "train/image_loss_mean": 1.5871174258214455, "train/image_loss_std": 4.946074376503627, "train/model_loss_mean": 3.4750612609916263, "train/model_loss_std": 8.741895028838405, "train/model_opt_grad_norm": 28.610152394683272, "train/model_opt_grad_steps": 161037.69444444444, "train/model_opt_loss": 9235.85562246817, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2662.037037037037, "train/policy_entropy_mag": 2.5507534201498383, "train/policy_entropy_max": 2.5507534201498383, "train/policy_entropy_mean": 0.5534087088372972, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6364740199512906, "train/policy_logprob_mag": 7.43838412673385, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5527014090783067, "train/policy_logprob_min": -7.43838412673385, "train/policy_logprob_std": 1.1094509313503902, "train/policy_randomness_mag": 0.9003040202789836, "train/policy_randomness_max": 0.9003040202789836, "train/policy_randomness_mean": 0.19532898937662443, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.22464740076274783, "train/post_ent_mag": 47.553888161977135, "train/post_ent_max": 47.553888161977135, "train/post_ent_mean": 29.78358159241853, "train/post_ent_min": 14.51423395121539, "train/post_ent_std": 4.9043179739404605, "train/prior_ent_mag": 77.6319763748734, "train/prior_ent_max": 77.6319763748734, "train/prior_ent_mean": 32.740629275639854, "train/prior_ent_min": 16.114279261341803, "train/prior_ent_std": 8.665559128478721, "train/rep_loss_mean": 3.0844926138718924, "train/rep_loss_std": 7.886426053665303, "train/reward_avg": 0.022190122084726614, "train/reward_loss_mean": 0.037209335136813695, "train/reward_loss_std": 0.16956833905229965, "train/reward_max_data": 1.0175925967869934, "train/reward_max_pred": 1.0155977849607114, "train/reward_neg_acc": 0.9962025282007677, "train/reward_neg_loss": 0.01834882328209157, "train/reward_pos_acc": 0.9909359434688533, "train/reward_pos_loss": 0.7169879131295063, "train/reward_pred": 0.02204914540656049, "train/reward_rate": 0.02699562355324074, "train_stats/sum_log_reward": 4.715384520017183, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 3.230769230769231, "train_stats/max_log_achievement_collect_sapling": 2.3846153846153846, "train_stats/max_log_achievement_collect_stone": 0.3076923076923077, "train_stats/max_log_achievement_collect_wood": 3.769230769230769, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.07692307692307693, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.3076923076923077, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 2.3846153846153846, "train_stats/max_log_achievement_place_stone": 0.07692307692307693, "train_stats/max_log_achievement_place_table": 1.5384615384615385, "train_stats/max_log_achievement_wake_up": 2.1538461538461537, "train_stats/mean_log_entropy": 0.5405706900816697, "report/cont_avg": 0.98828125, "report/cont_loss_mean": 6.143019390947302e-07, "report/cont_loss_std": 6.319333806459326e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 3.9410624594893306e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.5426657284933754e-07, "report/cont_pred": 0.9882816076278687, "report/cont_rate": 0.98828125, "report/dyn_loss_mean": 4.25602912902832, "report/dyn_loss_std": 9.573071479797363, "report/image_loss_mean": 2.407216787338257, "report/image_loss_std": 7.361545562744141, "report/model_loss_mean": 5.010517597198486, "report/model_loss_std": 11.730327606201172, "report/post_ent_mag": 41.32904815673828, "report/post_ent_max": 41.32904815673828, "report/post_ent_mean": 30.368961334228516, "report/post_ent_min": 13.236966133117676, "report/post_ent_std": 5.040884971618652, "report/prior_ent_mag": 77.27399444580078, "report/prior_ent_max": 77.27399444580078, "report/prior_ent_mean": 33.82239532470703, "report/prior_ent_min": 14.579706192016602, "report/prior_ent_std": 9.51488971710205, "report/rep_loss_mean": 4.25602912902832, "report/rep_loss_std": 9.573071479797363, "report/reward_avg": 0.02216796949505806, "report/reward_loss_mean": 0.04968252032995224, "report/reward_loss_std": 0.22867469489574432, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0012187957763672, "report/reward_neg_acc": 0.9949596524238586, "report/reward_neg_loss": 0.022202003747224808, "report/reward_pos_acc": 0.96875, "report/reward_pos_loss": 0.901578426361084, "report/reward_pred": 0.019697025418281555, "report/reward_rate": 0.03125, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.006444577127695084, "eval/cont_loss_std": 0.20599666237831116, "eval/cont_neg_acc": 0.75, "eval/cont_neg_loss": 1.649753212928772, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 2.2966467838614335e-07, "eval/cont_pred": 0.9970725774765015, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 21.50147247314453, "eval/dyn_loss_std": 12.148061752319336, "eval/image_loss_mean": 37.54894256591797, "eval/image_loss_std": 41.68927764892578, "eval/model_loss_mean": 50.5802001953125, "eval/model_loss_std": 46.84933853149414, "eval/post_ent_mag": 48.81632614135742, "eval/post_ent_max": 48.81632614135742, "eval/post_ent_mean": 33.679649353027344, "eval/post_ent_min": 20.386804580688477, "eval/post_ent_std": 4.000040054321289, "eval/prior_ent_mag": 77.27399444580078, "eval/prior_ent_max": 77.27399444580078, "eval/prior_ent_mean": 44.70807647705078, "eval/prior_ent_min": 21.283788681030273, "eval/prior_ent_std": 7.1235032081604, "eval/rep_loss_mean": 21.50147247314453, "eval/rep_loss_std": 12.148061752319336, "eval/reward_avg": 0.02314453199505806, "eval/reward_loss_mean": 0.12393271178007126, "eval/reward_loss_std": 0.7209854125976562, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0006444454193115, "eval/reward_neg_acc": 0.9959840178489685, "eval/reward_neg_loss": 0.06815680116415024, "eval/reward_pos_acc": 0.7142857313156128, "eval/reward_pos_loss": 2.107961416244507, "eval/reward_pred": 0.016217485070228577, "eval/reward_rate": 0.02734375, "replay/size": 163313.0, "replay/inserts": 2158.0, "replay/samples": 34528.0, "replay/insert_wait_avg": 2.6852472497977186e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.065823165214758e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 32096.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 9.387731552124023e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2619054317474, "timer/env.step_count": 270.0, "timer/env.step_total": 27.34087896347046, "timer/env.step_frac": 0.027333720113702817, "timer/env.step_avg": 0.10126251467952022, "timer/env.step_min": 0.023881196975708008, "timer/env.step_max": 3.1162407398223877, "timer/replay._sample_count": 34528.0, "timer/replay._sample_total": 17.841268062591553, "timer/replay._sample_frac": 0.01783659656106832, "timer/replay._sample_avg": 0.0005167188386987822, "timer/replay._sample_min": 0.00035190582275390625, "timer/replay._sample_max": 0.03947186470031738, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 270.0, "timer/agent.policy_total": 4.361517906188965, "timer/agent.policy_frac": 0.004360375900056279, "timer/agent.policy_avg": 0.016153770022922093, "timer/agent.policy_min": 0.010582208633422852, "timer/agent.policy_max": 0.018654584884643555, "timer/dataset_train_count": 2158.0, "timer/dataset_train_total": 0.39767980575561523, "timer/dataset_train_frac": 0.00039757567852587866, "timer/dataset_train_avg": 0.00018428165234273181, "timer/dataset_train_min": 9.369850158691406e-05, "timer/dataset_train_max": 0.00045371055603027344, "timer/agent.train_count": 2158.0, "timer/agent.train_total": 966.0861496925354, "timer/agent.train_frac": 0.9658331927331966, "timer/agent.train_avg": 0.44767662172962713, "timer/agent.train_min": 0.4364452362060547, "timer/agent.train_max": 0.6053619384765625, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47823452949523926, "timer/agent.report_frac": 0.0004781093100699629, "timer/agent.report_avg": 0.23911726474761963, "timer/agent.report_min": 0.23149776458740234, "timer/agent.report_max": 0.24673676490783691, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0517578125e-05, "timer/dataset_eval_frac": 3.050958749831382e-08, "timer/dataset_eval_avg": 3.0517578125e-05, "timer/dataset_eval_min": 3.0517578125e-05, "timer/dataset_eval_max": 3.0517578125e-05, "fps": 2.157407965599635}
{"step": 163888, "time": 75357.16119408607, "episode/length": 182.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 164496, "time": 75633.43208241463, "episode/length": 169.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 164600, "time": 75681.87734293938, "episode/length": 156.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 164640, "time": 75701.76278352737, "episode/length": 188.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 164664, "time": 75714.5801486969, "episode/length": 184.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 165176, "time": 75946.93846607208, "episode/length": 205.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 165288, "time": 75998.9294166565, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 165392, "time": 76047.2655377388, "episode/length": 198.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 165472, "time": 76084.71210193634, "episode/length": 291.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9965753424657534, "episode/intrinsic_return": 0.0}
{"step": 165896, "time": 76277.77127194405, "episode/length": 161.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 165944, "time": 76301.02071714401, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 165991, "time": 76324.27048659325, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.546979431712299, "train/action_min": 0.0, "train/action_std": 4.3284863342932605, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.049651425998282, "train/actor_opt_grad_steps": 163345.0, "train/actor_opt_loss": -12.46495437129922, "train/adv_mag": 0.6013119004735159, "train/adv_max": 0.5432184128039473, "train/adv_mean": 0.0026154450474511134, "train/adv_min": -0.507185529404824, "train/adv_std": 0.05536712542039539, "train/cont_avg": 0.9944094036697247, "train/cont_loss_mean": 2.9177388992534417e-05, "train/cont_loss_std": 0.0009158666241473588, "train/cont_neg_acc": 1.0, "train/cont_neg_loss": 0.0006413621488680943, "train/cont_pos_acc": 0.9999864492394509, "train/cont_pos_loss": 2.518572826979202e-05, "train/cont_pred": 0.9944007735733592, "train/cont_rate": 0.9944094036697247, "train/dyn_loss_mean": 3.132552597500862, "train/dyn_loss_std": 7.921535660367494, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1333335017392394, "train/extr_critic_critic_opt_grad_steps": 163345.0, "train/extr_critic_critic_opt_loss": 15051.913856436353, "train/extr_critic_mag": 9.17020200151916, "train/extr_critic_max": 9.17020200151916, "train/extr_critic_mean": 2.102222413644878, "train/extr_critic_min": -0.6721294155908287, "train/extr_critic_std": 2.0079272498778247, "train/extr_return_normed_mag": 1.6091237664222717, "train/extr_return_normed_max": 1.6091237664222717, "train/extr_return_normed_mean": 0.3752533281478313, "train/extr_return_normed_min": -0.12831123805510888, "train/extr_return_normed_std": 0.32767825471151857, "train/extr_return_rate": 0.77166867748313, "train/extr_return_raw_mag": 9.82426038357096, "train/extr_return_raw_max": 9.82426038357096, "train/extr_return_raw_mean": 2.1185353245210212, "train/extr_return_raw_min": -1.0256829267248102, "train/extr_return_raw_std": 2.0461325924330893, "train/extr_reward_mag": 1.0232548473078176, "train/extr_reward_max": 1.0232548473078176, "train/extr_reward_mean": 0.03466581975306393, "train/extr_reward_min": -0.6743114880465586, "train/extr_reward_std": 0.185847948382207, "train/image_loss_mean": 1.588089682093454, "train/image_loss_std": 4.911939182412734, "train/model_loss_mean": 3.50506646698768, "train/model_loss_std": 8.73958290170092, "train/model_opt_grad_norm": 29.57990068033201, "train/model_opt_grad_steps": 163205.36697247706, "train/model_opt_loss": 6838.897281751721, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1949.5412844036698, "train/policy_entropy_mag": 2.5441604918296186, "train/policy_entropy_max": 2.5441604918296186, "train/policy_entropy_mean": 0.5319880881440748, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6167112475414889, "train/policy_logprob_mag": 7.4383841370223855, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.531542053736678, "train/policy_logprob_min": -7.4383841370223855, "train/policy_logprob_std": 1.0986979286605065, "train/policy_randomness_mag": 0.8979770065447606, "train/policy_randomness_max": 0.8979770065447606, "train/policy_randomness_mean": 0.1877684496138074, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.2176720070729562, "train/post_ent_mag": 47.9144440222224, "train/post_ent_max": 47.9144440222224, "train/post_ent_mean": 29.858072972078936, "train/post_ent_min": 14.253248337211959, "train/post_ent_std": 4.935600109056595, "train/prior_ent_mag": 77.71066627152469, "train/prior_ent_max": 77.71066627152469, "train/prior_ent_mean": 32.89237780089772, "train/prior_ent_min": 15.818117019233354, "train/prior_ent_std": 8.702537427254773, "train/rep_loss_mean": 3.132552597500862, "train/rep_loss_std": 7.921535660367494, "train/reward_avg": 0.02160174146277505, "train/reward_loss_mean": 0.03741603926541882, "train/reward_loss_std": 0.16515534668477302, "train/reward_max_data": 1.010091745525325, "train/reward_max_pred": 1.0121115407812487, "train/reward_neg_acc": 0.9960323749879084, "train/reward_neg_loss": 0.018827307189669493, "train/reward_pos_acc": 0.9915945182699676, "train/reward_pos_loss": 0.7152029787181714, "train/reward_pred": 0.021449643268395182, "train/reward_rate": 0.026644925458715597, "train_stats/sum_log_reward": 5.28181808645075, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 4.7272727272727275, "train_stats/max_log_achievement_collect_sapling": 2.1818181818181817, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 4.7272727272727275, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.09090909090909091, "train_stats/max_log_achievement_make_wood_pickaxe": 0.2727272727272727, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 2.1818181818181817, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 1.9090909090909092, "train_stats/max_log_achievement_wake_up": 2.272727272727273, "train_stats/mean_log_entropy": 0.5110381028868936, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 9.14290012588026e-08, "report/cont_loss_std": 1.392678655065538e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.7769154510460794e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 4.6884323090523594e-09, "report/cont_pred": 0.9951173067092896, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 2.814502239227295, "report/dyn_loss_std": 7.916860580444336, "report/image_loss_mean": 1.1132159233093262, "report/image_loss_std": 2.9770967960357666, "report/model_loss_mean": 2.8363914489746094, "report/model_loss_std": 6.982656478881836, "report/post_ent_mag": 41.42765426635742, "report/post_ent_max": 41.42765426635742, "report/post_ent_mean": 29.588726043701172, "report/post_ent_min": 16.87778663635254, "report/post_ent_std": 4.415767192840576, "report/prior_ent_mag": 77.87342834472656, "report/prior_ent_max": 77.87342834472656, "report/prior_ent_mean": 32.490638732910156, "report/prior_ent_min": 18.704301834106445, "report/prior_ent_std": 8.195599555969238, "report/rep_loss_mean": 2.814502239227295, "report/rep_loss_std": 7.916860580444336, "report/reward_avg": 0.01982421800494194, "report/reward_loss_mean": 0.03447409346699715, "report/reward_loss_std": 0.1505003720521927, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0024116039276123, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.018451714888215065, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6747282147407532, "report/reward_pred": 0.020021289587020874, "report/reward_rate": 0.0244140625, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 8.223271663609921e-08, "eval/cont_loss_std": 1.5053165043354966e-06, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 2.68739113380434e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.980280910946931e-08, "eval/cont_pred": 0.998046875, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 22.59921646118164, "eval/dyn_loss_std": 13.502657890319824, "eval/image_loss_mean": 42.291568756103516, "eval/image_loss_std": 42.513973236083984, "eval/model_loss_mean": 55.94994354248047, "eval/model_loss_std": 48.187828063964844, "eval/post_ent_mag": 49.41328430175781, "eval/post_ent_max": 49.41328430175781, "eval/post_ent_mean": 32.73231506347656, "eval/post_ent_min": 17.43181610107422, "eval/post_ent_std": 4.035775661468506, "eval/prior_ent_mag": 77.87342834472656, "eval/prior_ent_max": 77.87342834472656, "eval/prior_ent_mean": 44.228946685791016, "eval/prior_ent_min": 19.654150009155273, "eval/prior_ent_std": 7.4321675300598145, "eval/rep_loss_mean": 22.59921646118164, "eval/rep_loss_std": 13.502657890319824, "eval/reward_avg": 0.02109374850988388, "eval/reward_loss_mean": 0.09884504228830338, "eval/reward_loss_std": 0.8039861917495728, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0024168491363525, "eval/reward_neg_acc": 0.999000072479248, "eval/reward_neg_loss": 0.029356209561228752, "eval/reward_pos_acc": 0.6666666865348816, "eval/reward_pos_loss": 2.994213104248047, "eval/reward_pred": 0.013004161417484283, "eval/reward_rate": 0.0234375, "replay/size": 165487.0, "replay/inserts": 2174.0, "replay/samples": 34784.0, "replay/insert_wait_avg": 2.552745752413556e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.799668057642624e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 32096.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 8.940696716308594e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1688618659973, "timer/env.step_count": 271.0, "timer/env.step_total": 24.096237421035767, "timer/env.step_frac": 0.024092169172393395, "timer/env.step_avg": 0.08891600524367442, "timer/env.step_min": 0.023455142974853516, "timer/env.step_max": 2.030592203140259, "timer/replay._sample_count": 34784.0, "timer/replay._sample_total": 17.9662868976593, "timer/replay._sample_frac": 0.017963253589138858, "timer/replay._sample_avg": 0.0005165100879041888, "timer/replay._sample_min": 0.0003998279571533203, "timer/replay._sample_max": 0.03822016716003418, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 271.0, "timer/agent.policy_total": 4.4074623584747314, "timer/agent.policy_frac": 0.0044067182318111835, "timer/agent.policy_avg": 0.016263698739759157, "timer/agent.policy_min": 0.010340213775634766, "timer/agent.policy_max": 0.0363001823425293, "timer/dataset_train_count": 2174.0, "timer/dataset_train_total": 0.4048891067504883, "timer/dataset_train_frac": 0.0004048207479635927, "timer/dataset_train_avg": 0.00018624153944364686, "timer/dataset_train_min": 9.632110595703125e-05, "timer/dataset_train_max": 0.0008747577667236328, "timer/agent.train_count": 2174.0, "timer/agent.train_total": 969.2003047466278, "timer/agent.train_frac": 0.9690366714060743, "timer/agent.train_avg": 0.4458143076111443, "timer/agent.train_min": 0.4319291114807129, "timer/agent.train_max": 0.6481430530548096, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4754822254180908, "timer/agent.report_frac": 0.0004754019481580261, "timer/agent.report_avg": 0.2377411127090454, "timer/agent.report_min": 0.23095965385437012, "timer/agent.report_max": 0.2445225715637207, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9325485229492188e-05, "timer/dataset_eval_frac": 2.932053410939044e-08, "timer/dataset_eval_avg": 2.9325485229492188e-05, "timer/dataset_eval_min": 2.9325485229492188e-05, "timer/dataset_eval_max": 2.9325485229492188e-05, "fps": 2.1736047616805063}
{"step": 166000, "time": 76328.58496499062, "episode/length": 169.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 166360, "time": 76492.24748849869, "episode/length": 44.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.8888888888888888, "episode/intrinsic_return": 0.0}
{"step": 166536, "time": 76573.10377597809, "episode/length": 155.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 166560, "time": 76585.49393725395, "episode/length": 145.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9657534246575342, "episode/intrinsic_return": 0.0}
{"step": 166592, "time": 76601.32888889313, "episode/length": 176.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 166816, "time": 76703.84368014336, "episode/length": 167.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 167016, "time": 76795.81314730644, "episode/length": 293.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9965986394557823, "episode/intrinsic_return": 0.0}
{"step": 167216, "time": 76887.58016395569, "episode/length": 158.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 167248, "time": 76903.42067956924, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 167712, "time": 77114.1299290657, "episode/length": 168.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 167728, "time": 77122.86470532417, "episode/length": 63.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.984375, "episode/intrinsic_return": 0.0}
{"step": 167760, "time": 77138.80353283882, "episode/length": 145.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 167816, "time": 77165.54418540001, "episode/length": 159.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 167880, "time": 77196.27734446526, "episode/length": 20.0, "episode/score": 1.0999999791383743, "episode/reward_rate": 0.9523809523809523, "episode/intrinsic_return": 0.0}
{"step": 168160, "time": 77324.41939663887, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.51664065875216, "train/action_min": 0.0, "train/action_std": 4.260174744689519, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.049192143612742975, "train/actor_opt_grad_steps": 165520.0, "train/actor_opt_loss": -14.938576414425802, "train/adv_mag": 0.6567628908267219, "train/adv_max": 0.5928159823066078, "train/adv_mean": 0.0026342262601649416, "train/adv_min": -0.5343526235785901, "train/adv_std": 0.0553727908411883, "train/cont_avg": 0.9943431379608295, "train/cont_loss_mean": 1.7006852640716253e-05, "train/cont_loss_std": 0.0005324335628743443, "train/cont_neg_acc": 1.0, "train/cont_neg_loss": 0.00011438065427561341, "train/cont_pos_acc": 0.9999954598839931, "train/cont_pos_loss": 1.61866632810002e-05, "train/cont_pred": 0.9943379383482691, "train/cont_rate": 0.9943431379608295, "train/dyn_loss_mean": 3.1173486017411753, "train/dyn_loss_std": 7.924800973883422, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1754293073706912, "train/extr_critic_critic_opt_grad_steps": 165520.0, "train/extr_critic_critic_opt_loss": 14957.782906105991, "train/extr_critic_mag": 9.908639413420506, "train/extr_critic_max": 9.908639413420506, "train/extr_critic_mean": 2.19103303153394, "train/extr_critic_min": -0.6706911407857447, "train/extr_critic_std": 2.0319787609961724, "train/extr_return_normed_mag": 1.7060460901480117, "train/extr_return_normed_max": 1.7060460901480117, "train/extr_return_normed_mean": 0.3864837157012131, "train/extr_return_normed_min": -0.12166768456659009, "train/extr_return_normed_std": 0.3300055478987057, "train/extr_return_rate": 0.7969674481774256, "train/extr_return_raw_mag": 10.493400329818375, "train/extr_return_raw_max": 10.493400329818375, "train/extr_return_raw_mean": 2.207566767244295, "train/extr_return_raw_min": -0.9825450854916726, "train/extr_return_raw_std": 2.0721988908706175, "train/extr_reward_mag": 1.0254862396398448, "train/extr_reward_max": 1.0254862396398448, "train/extr_reward_mean": 0.035531684181176575, "train/extr_reward_min": -0.6693354163851056, "train/extr_reward_std": 0.18884208798408508, "train/image_loss_mean": 1.5653181125491447, "train/image_loss_std": 4.91054495798278, "train/model_loss_mean": 3.4734566486376224, "train/model_loss_std": 8.731339419492379, "train/model_opt_grad_norm": 30.080748085622435, "train/model_opt_grad_steps": 165378.64976958526, "train/model_opt_loss": 7707.323290565596, "train/model_opt_model_opt_grad_overflow": 0.004608294930875576, "train/model_opt_model_opt_grad_scale": 2217.7419354838707, "train/policy_entropy_mag": 2.5548522834953626, "train/policy_entropy_max": 2.5548522834953626, "train/policy_entropy_mean": 0.5258808303538556, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6160324294171575, "train/policy_logprob_mag": 7.438384093447215, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5254722620759692, "train/policy_logprob_min": -7.438384093447215, "train/policy_logprob_std": 1.0962903620460616, "train/policy_randomness_mag": 0.9017507389943171, "train/policy_randomness_max": 0.9017507389943171, "train/policy_randomness_mean": 0.18561285438900169, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.21743241378239223, "train/post_ent_mag": 48.12649481637137, "train/post_ent_max": 48.12649481637137, "train/post_ent_mean": 30.138159659601026, "train/post_ent_min": 14.549462379947785, "train/post_ent_std": 4.873738607503302, "train/prior_ent_mag": 77.72214842062392, "train/prior_ent_max": 77.72214842062392, "train/prior_ent_mean": 33.11504246232696, "train/prior_ent_min": 16.154069153394566, "train/prior_ent_std": 8.673882378960535, "train/rep_loss_mean": 3.1173486017411753, "train/rep_loss_std": 7.924800973883422, "train/reward_avg": 0.02200820836054015, "train/reward_loss_mean": 0.037712360590627665, "train/reward_loss_std": 0.17199382271772157, "train/reward_max_data": 1.011059910470989, "train/reward_max_pred": 1.0112702703695693, "train/reward_neg_acc": 0.9963355361041935, "train/reward_neg_loss": 0.018614828569411133, "train/reward_pos_acc": 0.9901800073236914, "train/reward_pos_loss": 0.7244549676569926, "train/reward_pred": 0.021809902050734117, "train/reward_rate": 0.027037730414746542, "train_stats/sum_log_reward": 4.385714224406651, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 2.7142857142857144, "train_stats/max_log_achievement_collect_sapling": 2.0, "train_stats/max_log_achievement_collect_stone": 0.5714285714285714, "train_stats/max_log_achievement_collect_wood": 3.0714285714285716, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.07142857142857142, "train_stats/max_log_achievement_make_wood_pickaxe": 0.21428571428571427, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.8571428571428572, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 1.2857142857142858, "train_stats/max_log_achievement_wake_up": 1.5714285714285714, "train_stats/mean_log_entropy": 0.47260251321962904, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 3.1984487236513814e-07, "report/cont_loss_std": 4.636557605408598e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 5.2547136874636635e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.2021919459925812e-08, "report/cont_pred": 0.9941408634185791, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 2.7926135063171387, "report/dyn_loss_std": 7.567594528198242, "report/image_loss_mean": 1.2846362590789795, "report/image_loss_std": 3.4555888175964355, "report/model_loss_mean": 2.995110034942627, "report/model_loss_std": 7.237098693847656, "report/post_ent_mag": 49.51659393310547, "report/post_ent_max": 49.51659393310547, "report/post_ent_mean": 29.25365447998047, "report/post_ent_min": 14.446792602539062, "report/post_ent_std": 4.795684814453125, "report/prior_ent_mag": 77.6952133178711, "report/prior_ent_max": 77.6952133178711, "report/prior_ent_mean": 31.872018814086914, "report/prior_ent_min": 14.934120178222656, "report/prior_ent_std": 8.72461986541748, "report/rep_loss_mean": 2.7926135063171387, "report/rep_loss_std": 7.567594528198242, "report/reward_avg": 0.02324218675494194, "report/reward_loss_mean": 0.034905433654785156, "report/reward_loss_std": 0.15912851691246033, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0006494522094727, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.01484941691160202, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7230344414710999, "report/reward_pred": 0.023077290505170822, "report/reward_rate": 0.0283203125, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.0007687551551498473, "eval/cont_loss_std": 0.02392795868217945, "eval/cont_neg_acc": 0.6666666865348816, "eval/cont_neg_loss": 0.262397825717926, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.1691722257012316e-08, "eval/cont_pred": 0.9976134896278381, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 22.36876106262207, "eval/dyn_loss_std": 13.251988410949707, "eval/image_loss_mean": 36.724021911621094, "eval/image_loss_std": 43.36998748779297, "eval/model_loss_mean": 50.33289337158203, "eval/model_loss_std": 49.05852127075195, "eval/post_ent_mag": 49.51659393310547, "eval/post_ent_max": 49.51659393310547, "eval/post_ent_mean": 32.759849548339844, "eval/post_ent_min": 16.49066925048828, "eval/post_ent_std": 4.238728046417236, "eval/prior_ent_mag": 77.6952133178711, "eval/prior_ent_max": 77.6952133178711, "eval/prior_ent_mean": 44.47386932373047, "eval/prior_ent_min": 18.089759826660156, "eval/prior_ent_std": 7.512373447418213, "eval/rep_loss_mean": 22.36876106262207, "eval/rep_loss_std": 13.251988410949707, "eval/reward_avg": 0.02119140699505806, "eval/reward_loss_mean": 0.1868455857038498, "eval/reward_loss_std": 1.1041033267974854, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.001237154006958, "eval/reward_neg_acc": 0.9969940185546875, "eval/reward_neg_loss": 0.10716122388839722, "eval/reward_pos_acc": 0.7307692766189575, "eval/reward_pos_loss": 3.2454991340637207, "eval/reward_pred": 0.014351384714245796, "eval/reward_rate": 0.025390625, "replay/size": 167656.0, "replay/inserts": 2169.0, "replay/samples": 34704.0, "replay/insert_wait_avg": 2.644478642704191e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.036396658876735e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 32096.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 8.046627044677734e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1310186386108, "timer/env.step_count": 271.0, "timer/env.step_total": 28.229197025299072, "timer/env.step_frac": 0.02822549895885137, "timer/env.step_avg": 0.1041667786911405, "timer/env.step_min": 0.02411818504333496, "timer/env.step_max": 1.6718058586120605, "timer/replay._sample_count": 34704.0, "timer/replay._sample_total": 17.919443607330322, "timer/replay._sample_frac": 0.017917096133787013, "timer/replay._sample_avg": 0.0005163509568732804, "timer/replay._sample_min": 0.00038504600524902344, "timer/replay._sample_max": 0.008852005004882812, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 271.0, "timer/agent.policy_total": 4.406785488128662, "timer/agent.policy_frac": 0.004406208192729815, "timer/agent.policy_avg": 0.016261201063205395, "timer/agent.policy_min": 0.009696245193481445, "timer/agent.policy_max": 0.04169201850891113, "timer/dataset_train_count": 2169.0, "timer/dataset_train_total": 0.40353822708129883, "timer/dataset_train_frac": 0.000403485362978342, "timer/dataset_train_avg": 0.00018604805305730697, "timer/dataset_train_min": 9.870529174804688e-05, "timer/dataset_train_max": 0.0005033016204833984, "timer/agent.train_count": 2169.0, "timer/agent.train_total": 965.1039052009583, "timer/agent.train_frac": 0.9649774751658718, "timer/agent.train_avg": 0.4449533910562279, "timer/agent.train_min": 0.43151092529296875, "timer/agent.train_max": 0.5659224987030029, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47304749488830566, "timer/agent.report_frac": 0.00047298552496874164, "timer/agent.report_avg": 0.23652374744415283, "timer/agent.report_min": 0.2289881706237793, "timer/agent.report_max": 0.24405932426452637, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.1948089599609375e-05, "timer/dataset_eval_frac": 3.194390435274916e-08, "timer/dataset_eval_avg": 3.1948089599609375e-05, "timer/dataset_eval_min": 3.1948089599609375e-05, "timer/dataset_eval_max": 3.1948089599609375e-05, "fps": 2.1686885892730996}
{"step": 168248, "time": 77364.2549290657, "episode/length": 153.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 168488, "time": 77473.8801074028, "episode/length": 208.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9569377990430622, "episode/intrinsic_return": 0.0}
{"step": 168496, "time": 77478.93080449104, "episode/length": 155.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 168944, "time": 77683.13525056839, "episode/length": 151.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 168992, "time": 77706.40131664276, "episode/length": 146.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 169072, "time": 77743.96299791336, "episode/length": 148.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 169072, "time": 77743.97085475922, "episode/length": 163.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 169240, "time": 77823.19270396233, "episode/length": 334.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9940298507462687, "episode/intrinsic_return": 0.0}
{"step": 169608, "time": 77990.97442436218, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 169648, "time": 78010.61315369606, "episode/length": 143.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 169960, "time": 78153.85656833649, "episode/length": 183.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 170040, "time": 78215.92897200584, "eval_episode/length": 151.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9671052631578947}
{"step": 170040, "time": 78217.54470038414, "eval_episode/length": 153.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9935064935064936}
{"step": 170040, "time": 78219.40668654442, "eval_episode/length": 162.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9693251533742331}
{"step": 170040, "time": 78221.2943046093, "eval_episode/length": 171.0, "eval_episode/score": 3.0999999716877937, "eval_episode/reward_rate": 0.9941860465116279}
{"step": 170040, "time": 78223.40636634827, "eval_episode/length": 183.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9945652173913043}
{"step": 170040, "time": 78225.09060525894, "eval_episode/length": 185.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9946236559139785}
{"step": 170040, "time": 78226.7788105011, "eval_episode/length": 188.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9682539682539683}
{"step": 170040, "time": 78229.82765746117, "eval_episode/length": 225.0, "eval_episode/score": 4.099999979138374, "eval_episode/reward_rate": 0.995575221238938}
{"step": 170248, "time": 78324.8392944336, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.283611297607422, "train/action_min": 0.0, "train/action_std": 4.086294326644677, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.05185945056235561, "train/actor_opt_grad_steps": 167645.0, "train/actor_opt_loss": -10.998301075278924, "train/adv_mag": 0.630107749110231, "train/adv_max": 0.5563249815828525, "train/adv_mean": 0.003546598295158149, "train/adv_min": -0.5276238193305639, "train/adv_std": 0.05646718078507827, "train/cont_avg": 0.9943706805889423, "train/cont_loss_mean": 7.23174045993766e-06, "train/cont_loss_std": 0.0001620100789204971, "train/cont_neg_acc": 1.0, "train/cont_neg_loss": 0.00041166080145920705, "train/cont_pos_acc": 0.9999999805138662, "train/cont_pos_loss": 4.249833815195281e-06, "train/cont_pred": 0.9943689878743428, "train/cont_rate": 0.9943706805889423, "train/dyn_loss_mean": 3.1025349302933765, "train/dyn_loss_std": 7.8970322494323435, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.2468518932851462, "train/extr_critic_critic_opt_grad_steps": 167645.0, "train/extr_critic_critic_opt_loss": 15552.8955078125, "train/extr_critic_mag": 9.463566789260277, "train/extr_critic_max": 9.463566789260277, "train/extr_critic_mean": 2.2795875450739493, "train/extr_critic_min": -0.6987554322068508, "train/extr_critic_std": 2.0505972023193655, "train/extr_return_normed_mag": 1.6188153767815003, "train/extr_return_normed_max": 1.6188153767815003, "train/extr_return_normed_mean": 0.39689890438547504, "train/extr_return_normed_min": -0.1290225902428994, "train/extr_return_normed_std": 0.32563859761620945, "train/extr_return_rate": 0.7657627603755548, "train/extr_return_raw_mag": 10.152659684419632, "train/extr_return_raw_max": 10.152659684419632, "train/extr_return_raw_mean": 2.302369455878551, "train/extr_return_raw_min": -1.0759073438552709, "train/extr_return_raw_std": 2.091657864359709, "train/extr_reward_mag": 1.0282376248102922, "train/extr_reward_max": 1.0282376248102922, "train/extr_reward_mean": 0.036539627731634446, "train/extr_reward_min": -0.6673741655854079, "train/extr_reward_std": 0.19120475069548076, "train/image_loss_mean": 1.5611268760493169, "train/image_loss_std": 5.035199822141574, "train/model_loss_mean": 3.459673753151527, "train/model_loss_std": 8.848199401910488, "train/model_opt_grad_norm": 30.25780228009591, "train/model_opt_grad_steps": 167501.47115384616, "train/model_opt_loss": 5758.574349036584, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1664.6634615384614, "train/policy_entropy_mag": 2.507968848714462, "train/policy_entropy_max": 2.507968848714462, "train/policy_entropy_mean": 0.4716415633089267, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.5655856824551637, "train/policy_logprob_mag": 7.4383841294508715, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.4716734499312364, "train/policy_logprob_min": -7.4383841294508715, "train/policy_logprob_std": 1.0592212711389248, "train/policy_randomness_mag": 0.8852029437055955, "train/policy_randomness_max": 0.8852029437055955, "train/policy_randomness_mean": 0.16646877515058106, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.19962692704911417, "train/post_ent_mag": 47.487988416965194, "train/post_ent_max": 47.487988416965194, "train/post_ent_mean": 30.18962147602668, "train/post_ent_min": 14.312096586594215, "train/post_ent_std": 4.934432272727673, "train/prior_ent_mag": 77.64834910172682, "train/prior_ent_max": 77.64834910172682, "train/prior_ent_mean": 33.17781252127428, "train/prior_ent_min": 15.866981286268969, "train/prior_ent_std": 8.686507215866676, "train/rep_loss_mean": 3.1025349302933765, "train/rep_loss_std": 7.8970322494323435, "train/reward_avg": 0.022014441792494975, "train/reward_loss_mean": 0.03701868852098974, "train/reward_loss_std": 0.16338719366691434, "train/reward_max_data": 1.0120192336348386, "train/reward_max_pred": 1.013626988690633, "train/reward_neg_acc": 0.9962755705301578, "train/reward_neg_loss": 0.018307047441619664, "train/reward_pos_acc": 0.9920991596121055, "train/reward_pos_loss": 0.7102544003954301, "train/reward_pred": 0.021897220630377818, "train/reward_rate": 0.027066744290865384, "train_stats/sum_log_reward": 5.281818173148415, "train_stats/max_log_achievement_collect_coal": 0.09090909090909091, "train_stats/max_log_achievement_collect_drink": 2.6363636363636362, "train_stats/max_log_achievement_collect_sapling": 2.272727272727273, "train_stats/max_log_achievement_collect_stone": 1.2727272727272727, "train_stats/max_log_achievement_collect_wood": 5.090909090909091, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.5454545454545454, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 2.090909090909091, "train_stats/max_log_achievement_place_stone": 0.2727272727272727, "train_stats/max_log_achievement_place_table": 1.9090909090909092, "train_stats/max_log_achievement_wake_up": 1.8181818181818181, "train_stats/mean_log_entropy": 0.417218880219893, "train_stats/max_log_achievement_place_furnace": 0.5, "eval_stats/sum_log_reward": 4.599999964237213, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 2.375, "eval_stats/max_log_achievement_collect_sapling": 1.125, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 5.75, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.875, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.125, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.0, "eval_stats/max_log_achievement_wake_up": 1.75, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 6.207143314895802e-07, "report/cont_loss_std": 5.677008516613569e-07, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.0658677638275549e-06, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 6.172091957523662e-07, "report/cont_pred": 0.992186963558197, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 3.2089273929595947, "report/dyn_loss_std": 7.997620582580566, "report/image_loss_mean": 1.5584499835968018, "report/image_loss_std": 8.932404518127441, "report/model_loss_mean": 3.5260069370269775, "report/model_loss_std": 11.664424896240234, "report/post_ent_mag": 50.23106384277344, "report/post_ent_max": 50.23106384277344, "report/post_ent_mean": 30.408082962036133, "report/post_ent_min": 14.485538482666016, "report/post_ent_std": 5.1831159591674805, "report/prior_ent_mag": 78.18877410888672, "report/prior_ent_max": 78.18877410888672, "report/prior_ent_mean": 33.50588607788086, "report/prior_ent_min": 15.653265953063965, "report/prior_ent_std": 9.152804374694824, "report/rep_loss_mean": 3.2089273929595947, "report/rep_loss_std": 7.997620582580566, "report/reward_avg": 0.01806640625, "report/reward_loss_mean": 0.042199742048978806, "report/reward_loss_std": 0.22178596258163452, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0006508827209473, "report/reward_neg_acc": 0.9969940185546875, "report/reward_neg_loss": 0.019548490643501282, "report/reward_pos_acc": 0.9230769872665405, "report/reward_pos_loss": 0.911659300327301, "report/reward_pred": 0.016248753294348717, "report/reward_rate": 0.025390625, "eval/cont_avg": 0.9921875, "eval/cont_loss_mean": 8.811880434222985e-06, "eval/cont_loss_std": 0.0002518763649277389, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 3.1580239010509104e-06, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 8.856398380885366e-06, "eval/cont_pred": 0.9921787977218628, "eval/cont_rate": 0.9921875, "eval/dyn_loss_mean": 21.646400451660156, "eval/dyn_loss_std": 12.813434600830078, "eval/image_loss_mean": 31.892669677734375, "eval/image_loss_std": 38.818843841552734, "eval/model_loss_mean": 45.08009338378906, "eval/model_loss_std": 43.887325286865234, "eval/post_ent_mag": 50.23106384277344, "eval/post_ent_max": 50.23106384277344, "eval/post_ent_mean": 33.115089416503906, "eval/post_ent_min": 17.459808349609375, "eval/post_ent_std": 4.3834638595581055, "eval/prior_ent_mag": 78.18877410888672, "eval/prior_ent_max": 78.18877410888672, "eval/prior_ent_mean": 44.020225524902344, "eval/prior_ent_min": 18.825334548950195, "eval/prior_ent_std": 8.108776092529297, "eval/rep_loss_mean": 21.646400451660156, "eval/rep_loss_std": 12.813434600830078, "eval/reward_avg": 0.0205078125, "eval/reward_loss_mean": 0.19957414269447327, "eval/reward_loss_std": 1.1414533853530884, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0001518726348877, "eval/reward_neg_acc": 0.9929789304733276, "eval/reward_neg_loss": 0.11835166811943054, "eval/reward_pos_acc": 0.6666666865348816, "eval/reward_pos_loss": 3.198789596557617, "eval/reward_pred": 0.015155147761106491, "eval/reward_rate": 0.0263671875, "replay/size": 169744.0, "replay/inserts": 2088.0, "replay/samples": 33408.0, "replay/insert_wait_avg": 2.6543478399400966e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.025859621749527e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 33904.0, "eval_replay/inserts": 1808.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2341590054267276e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.791685104370117e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4061443805695, "timer/env.step_count": 261.0, "timer/env.step_total": 23.463592767715454, "timer/env.step_frac": 0.023454067030189645, "timer/env.step_avg": 0.08989882286481017, "timer/env.step_min": 0.02390122413635254, "timer/env.step_max": 3.0915446281433105, "timer/replay._sample_count": 33408.0, "timer/replay._sample_total": 17.43586277961731, "timer/replay._sample_frac": 0.017428784176863717, "timer/replay._sample_avg": 0.0005219068121293496, "timer/replay._sample_min": 0.0003981590270996094, "timer/replay._sample_max": 0.03905916213989258, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 487.0, "timer/agent.policy_total": 9.163540363311768, "timer/agent.policy_frac": 0.009159820153829263, "timer/agent.policy_avg": 0.018816304647457427, "timer/agent.policy_min": 0.009760379791259766, "timer/agent.policy_max": 0.12944316864013672, "timer/dataset_train_count": 2088.0, "timer/dataset_train_total": 0.39432239532470703, "timer/dataset_train_frac": 0.0003941623085180701, "timer/dataset_train_avg": 0.00018885172189880606, "timer/dataset_train_min": 9.799003601074219e-05, "timer/dataset_train_max": 0.0011467933654785156, "timer/agent.train_count": 2088.0, "timer/agent.train_total": 932.1364200115204, "timer/agent.train_frac": 0.9317579917391249, "timer/agent.train_avg": 0.44642548851126457, "timer/agent.train_min": 0.4357414245605469, "timer/agent.train_max": 0.5653643608093262, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.46875762939453125, "timer/agent.report_frac": 0.00046856732340921014, "timer/agent.report_avg": 0.23437881469726562, "timer/agent.report_min": 0.22442317008972168, "timer/agent.report_max": 0.24433445930480957, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.2901763916015625e-05, "timer/dataset_eval_frac": 3.2888406474540104e-08, "timer/dataset_eval_avg": 3.2901763916015625e-05, "timer/dataset_eval_min": 3.2901763916015625e-05, "timer/dataset_eval_max": 3.2901763916015625e-05, "fps": 2.087125278235413}
{"step": 170336, "time": 78365.40632152557, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 170344, "time": 78370.50106215477, "episode/length": 174.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 170392, "time": 78393.84460377693, "episode/length": 164.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 170624, "time": 78501.13897037506, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 170744, "time": 78557.03953003883, "episode/length": 49.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.92, "episode/intrinsic_return": 0.0}
{"step": 170936, "time": 78646.14797115326, "episode/length": 160.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 171008, "time": 78680.43784022331, "episode/length": 241.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9834710743801653, "episode/intrinsic_return": 0.0}
{"step": 171352, "time": 78838.0763809681, "episode/length": 217.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 171704, "time": 78998.98411369324, "episode/length": 43.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9090909090909091, "episode/intrinsic_return": 0.0}
{"step": 171800, "time": 79043.90470409393, "episode/length": 182.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 171944, "time": 79110.84728169441, "episode/length": 247.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 171984, "time": 79130.4029340744, "episode/length": 169.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 172104, "time": 79187.22878527641, "episode/length": 213.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 172216, "time": 79240.1997256279, "episode/length": 183.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 172392, "time": 79321.10614705086, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 172396, "time": 79325.0657453537, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.505105094022529, "train/action_min": 0.0, "train/action_std": 4.362277704061464, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0491989784809046, "train/actor_opt_grad_steps": 169760.0, "train/actor_opt_loss": -12.801317769843479, "train/adv_mag": 0.5766433916812719, "train/adv_max": 0.5122482237427733, "train/adv_mean": 0.0027140325201608626, "train/adv_min": -0.4705901168113531, "train/adv_std": 0.05317137251759684, "train/cont_avg": 0.9942768895348837, "train/cont_loss_mean": 3.2646839759052476e-05, "train/cont_loss_std": 0.0010054032082110966, "train/cont_neg_acc": 0.9995348838872687, "train/cont_neg_loss": 0.0032739779898562586, "train/cont_pos_acc": 0.9999999819799911, "train/cont_pos_loss": 1.6903369072121338e-06, "train/cont_pred": 0.994281945949377, "train/cont_rate": 0.9942768895348837, "train/dyn_loss_mean": 3.151962497622468, "train/dyn_loss_std": 7.941877631253974, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1141532021899556, "train/extr_critic_critic_opt_grad_steps": 169760.0, "train/extr_critic_critic_opt_loss": 14949.858680050873, "train/extr_critic_mag": 9.5129010178322, "train/extr_critic_max": 9.5129010178322, "train/extr_critic_mean": 2.4024316820987437, "train/extr_critic_min": -0.6662957507510517, "train/extr_critic_std": 2.0224549570748973, "train/extr_return_normed_mag": 1.6036668356074844, "train/extr_return_normed_max": 1.6036668356074844, "train/extr_return_normed_mean": 0.4093821867953899, "train/extr_return_normed_min": -0.12713144747323768, "train/extr_return_normed_std": 0.31922886641912684, "train/extr_return_rate": 0.8140489170717639, "train/extr_return_raw_mag": 10.120788789349932, "train/extr_return_raw_max": 10.120788789349932, "train/extr_return_raw_mean": 2.4199235189792723, "train/extr_return_raw_min": -1.039695055817449, "train/extr_return_raw_std": 2.058763947043308, "train/extr_reward_mag": 1.0285319539003595, "train/extr_reward_max": 1.0285319539003595, "train/extr_reward_mean": 0.03634279735039833, "train/extr_reward_min": -0.6734843803006549, "train/extr_reward_std": 0.18952496148819148, "train/image_loss_mean": 1.6347098636072734, "train/image_loss_std": 5.195870406128639, "train/model_loss_mean": 3.5640897540159004, "train/model_loss_std": 8.99523904933486, "train/model_opt_grad_norm": 29.60832292423692, "train/model_opt_grad_steps": 169615.31627906975, "train/model_opt_loss": 9017.164155614098, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2534.8837209302324, "train/policy_entropy_mag": 2.5111442698988804, "train/policy_entropy_max": 2.5111442698988804, "train/policy_entropy_mean": 0.4725471741931383, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.5646231102388959, "train/policy_logprob_mag": 7.438384140369504, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.47256604502367416, "train/policy_logprob_min": -7.438384140369504, "train/policy_logprob_std": 1.0583798791086951, "train/policy_randomness_mag": 0.8863237272861392, "train/policy_randomness_max": 0.8863237272861392, "train/policy_randomness_mean": 0.1667884150909823, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.19928718216197436, "train/post_ent_mag": 47.9294935536939, "train/post_ent_max": 47.9294935536939, "train/post_ent_mean": 30.511824434857036, "train/post_ent_min": 14.595122585740201, "train/post_ent_std": 4.8769012728402785, "train/prior_ent_mag": 77.67131156034247, "train/prior_ent_max": 77.67131156034247, "train/prior_ent_mean": 33.53828734464424, "train/prior_ent_min": 16.327252924719524, "train/prior_ent_std": 8.604930968617284, "train/rep_loss_mean": 3.151962497622468, "train/rep_loss_std": 7.941877631253974, "train/reward_avg": 0.02235328847499088, "train/reward_loss_mean": 0.03816976652069147, "train/reward_loss_std": 0.16860098741775334, "train/reward_max_data": 1.0130232589189396, "train/reward_max_pred": 1.0127786065256872, "train/reward_neg_acc": 0.9961051846659461, "train/reward_neg_loss": 0.01926570017497207, "train/reward_pos_acc": 0.9931139860042306, "train/reward_pos_loss": 0.7084895117338313, "train/reward_pred": 0.022265336341982665, "train/reward_rate": 0.027439135174418604, "train_stats/sum_log_reward": 4.966666682561239, "train_stats/max_log_achievement_collect_coal": 0.06666666666666667, "train_stats/max_log_achievement_collect_drink": 2.466666666666667, "train_stats/max_log_achievement_collect_sapling": 1.6666666666666667, "train_stats/max_log_achievement_collect_stone": 0.06666666666666667, "train_stats/max_log_achievement_collect_wood": 4.533333333333333, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.4666666666666667, "train_stats/max_log_achievement_make_wood_sword": 0.06666666666666667, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 1.6666666666666667, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 1.7333333333333334, "train_stats/max_log_achievement_wake_up": 1.6666666666666667, "train_stats/mean_log_entropy": 0.44812133610248567, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 5.238359790382674e-07, "report/cont_loss_std": 7.727994670858607e-07, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 2.763893917290261e-06, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 5.150513970875181e-07, "report/cont_pred": 0.9960932731628418, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 2.9817981719970703, "report/dyn_loss_std": 7.687607765197754, "report/image_loss_mean": 1.0469735860824585, "report/image_loss_std": 3.716524600982666, "report/model_loss_mean": 2.8646230697631836, "report/model_loss_std": 7.61482572555542, "report/post_ent_mag": 50.47637939453125, "report/post_ent_max": 50.47637939453125, "report/post_ent_mean": 29.685474395751953, "report/post_ent_min": 18.165714263916016, "report/post_ent_std": 3.8452980518341064, "report/prior_ent_mag": 77.63914489746094, "report/prior_ent_max": 77.63914489746094, "report/prior_ent_mean": 32.747562408447266, "report/prior_ent_min": 21.828754425048828, "report/prior_ent_std": 7.867954254150391, "report/rep_loss_mean": 2.9817981719970703, "report/rep_loss_std": 7.687607765197754, "report/reward_avg": 0.01904296875, "report/reward_loss_mean": 0.028570132330060005, "report/reward_loss_std": 0.16301164031028748, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0024325847625732, "report/reward_neg_acc": 0.9970029592514038, "report/reward_neg_loss": 0.013743949122726917, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6738314628601074, "report/reward_pred": 0.019834060221910477, "report/reward_rate": 0.0224609375, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.00020792191207874566, "eval/cont_loss_std": 0.006592420395463705, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.10553343594074249, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.805430883905501e-06, "eval/cont_pred": 0.9982309937477112, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 21.475322723388672, "eval/dyn_loss_std": 12.739888191223145, "eval/image_loss_mean": 30.13237762451172, "eval/image_loss_std": 42.92680740356445, "eval/model_loss_mean": 43.20566177368164, "eval/model_loss_std": 47.81791305541992, "eval/post_ent_mag": 50.47637939453125, "eval/post_ent_max": 50.47637939453125, "eval/post_ent_mean": 33.01487350463867, "eval/post_ent_min": 17.681690216064453, "eval/post_ent_std": 4.2813005447387695, "eval/prior_ent_mag": 77.63914489746094, "eval/prior_ent_max": 77.63914489746094, "eval/prior_ent_mean": 44.36219787597656, "eval/prior_ent_min": 25.227148056030273, "eval/prior_ent_std": 7.168818473815918, "eval/rep_loss_mean": 21.475322723388672, "eval/rep_loss_std": 12.739888191223145, "eval/reward_avg": 0.02373046800494194, "eval/reward_loss_mean": 0.18788522481918335, "eval/reward_loss_std": 1.235367774963379, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0006494522094727, "eval/reward_neg_acc": 0.9919759631156921, "eval/reward_neg_loss": 0.09677258878946304, "eval/reward_pos_acc": 0.6666666865348816, "eval/reward_pos_loss": 3.5523037910461426, "eval/reward_pred": 0.01951698586344719, "eval/reward_rate": 0.0263671875, "replay/size": 171892.0, "replay/inserts": 2148.0, "replay/samples": 34368.0, "replay/insert_wait_avg": 2.6940855456020136e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.603407683097228e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 33904.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 7.599592208862305e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2186725139618, "timer/env.step_count": 269.0, "timer/env.step_total": 31.101696014404297, "timer/env.step_frac": 0.031094896415233796, "timer/env.step_avg": 0.11561968778588957, "timer/env.step_min": 0.023961544036865234, "timer/env.step_max": 1.9735641479492188, "timer/replay._sample_count": 34368.0, "timer/replay._sample_total": 17.891138315200806, "timer/replay._sample_frac": 0.017887226870333266, "timer/replay._sample_avg": 0.0005205754863594276, "timer/replay._sample_min": 0.0004019737243652344, "timer/replay._sample_max": 0.011392354965209961, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 269.0, "timer/agent.policy_total": 4.555126190185547, "timer/agent.policy_frac": 0.0045541303270580195, "timer/agent.policy_avg": 0.016933554610355193, "timer/agent.policy_min": 0.010225057601928711, "timer/agent.policy_max": 0.0509343147277832, "timer/dataset_train_count": 2148.0, "timer/dataset_train_total": 0.4138944149017334, "timer/dataset_train_frac": 0.0004138039273566511, "timer/dataset_train_avg": 0.00019268827509391685, "timer/dataset_train_min": 0.00010061264038085938, "timer/dataset_train_max": 0.0005240440368652344, "timer/agent.train_count": 2148.0, "timer/agent.train_total": 962.1026334762573, "timer/agent.train_frac": 0.9618922940701525, "timer/agent.train_avg": 0.44790625394611605, "timer/agent.train_min": 0.4355320930480957, "timer/agent.train_max": 0.6779088973999023, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4732694625854492, "timer/agent.report_frac": 0.0004731659941879789, "timer/agent.report_avg": 0.2366347312927246, "timer/agent.report_min": 0.2291548252105713, "timer/agent.report_max": 0.24411463737487793, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.266334533691406e-05, "timer/dataset_eval_frac": 3.265620432261838e-08, "timer/dataset_eval_avg": 3.266334533691406e-05, "timer/dataset_eval_min": 3.266334533691406e-05, "timer/dataset_eval_max": 3.266334533691406e-05, "fps": 2.1475026024578305}
{"step": 172496, "time": 79370.60745835304, "episode/length": 194.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 172800, "time": 79509.534689188, "episode/length": 37.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.868421052631579, "episode/intrinsic_return": 0.0}
{"step": 172816, "time": 79518.29440522194, "episode/length": 138.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.0}
{"step": 173408, "time": 79788.59457588196, "episode/length": 182.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 173440, "time": 79804.55607628822, "episode/length": 152.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 173784, "time": 79961.01011919975, "episode/length": 209.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 173816, "time": 79976.93114757538, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 173904, "time": 80017.92715859413, "episode/length": 57.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 174040, "time": 80081.10376858711, "episode/length": 152.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 174336, "time": 80215.81042647362, "episode/length": 191.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 174575, "time": 80325.19452309608, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.603140174795728, "train/action_min": 0.0, "train/action_std": 4.404016109781527, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04616234555772138, "train/actor_opt_grad_steps": 171925.0, "train/actor_opt_loss": -12.922095578454366, "train/adv_mag": 0.5750401449312857, "train/adv_max": 0.5212168376380151, "train/adv_mean": 0.002239267508662958, "train/adv_min": -0.46325453480175877, "train/adv_std": 0.050611856214086946, "train/cont_avg": 0.9944138833142202, "train/cont_loss_mean": 1.1377237412811612e-05, "train/cont_loss_std": 0.0003453351294845557, "train/cont_neg_acc": 1.0, "train/cont_neg_loss": 0.0006093373245100541, "train/cont_pos_acc": 0.9999954697735812, "train/cont_pos_loss": 8.307260269657465e-06, "train/cont_pred": 0.9944117706303203, "train/cont_rate": 0.9944138833142202, "train/dyn_loss_mean": 3.137690025732058, "train/dyn_loss_std": 7.928013924064986, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0627752476875936, "train/extr_critic_critic_opt_grad_steps": 171925.0, "train/extr_critic_critic_opt_loss": 14581.352601777522, "train/extr_critic_mag": 9.859629495428242, "train/extr_critic_max": 9.859629495428242, "train/extr_critic_mean": 2.46623256665851, "train/extr_critic_min": -0.664211236555642, "train/extr_critic_std": 2.110074340750318, "train/extr_return_normed_mag": 1.6059969942504113, "train/extr_return_normed_max": 1.6059969942504113, "train/extr_return_normed_mean": 0.4070105536268392, "train/extr_return_normed_min": -0.1195554348785396, "train/extr_return_normed_std": 0.3233328264104117, "train/extr_return_rate": 0.8379438276137781, "train/extr_return_raw_mag": 10.434689248373749, "train/extr_return_raw_max": 10.434689248373749, "train/extr_return_raw_mean": 2.4810613535959787, "train/extr_return_raw_min": -1.0110049634625058, "train/extr_return_raw_std": 2.1447103898459616, "train/extr_reward_mag": 1.0299689682251816, "train/extr_reward_max": 1.0299689682251816, "train/extr_reward_mean": 0.03514846012748163, "train/extr_reward_min": -0.6695168619855828, "train/extr_reward_std": 0.18768280997462228, "train/image_loss_mean": 1.5732155018443361, "train/image_loss_std": 4.849341069886444, "train/model_loss_mean": 3.492558864278531, "train/model_loss_std": 8.702232638630298, "train/model_opt_grad_norm": 29.673359501746393, "train/model_opt_grad_steps": 171778.15596330276, "train/model_opt_loss": 8702.015789626936, "train/model_opt_model_opt_grad_overflow": 0.0045871559633027525, "train/model_opt_model_opt_grad_scale": 2488.532110091743, "train/policy_entropy_mag": 2.499783816687558, "train/policy_entropy_max": 2.499783816687558, "train/policy_entropy_mean": 0.4908577039701129, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.5768456862333717, "train/policy_logprob_mag": 7.438384130460407, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.4902142000581146, "train/policy_logprob_min": -7.438384130460407, "train/policy_logprob_std": 1.070055040197635, "train/policy_randomness_mag": 0.8823139888977786, "train/policy_randomness_max": 0.8823139888977786, "train/policy_randomness_mean": 0.17325122770639734, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.20360121629927136, "train/post_ent_mag": 48.14059350249964, "train/post_ent_max": 48.14059350249964, "train/post_ent_mean": 30.67687685555274, "train/post_ent_min": 14.512576562548997, "train/post_ent_std": 4.896695399503096, "train/prior_ent_mag": 77.72562299955875, "train/prior_ent_max": 77.72562299955875, "train/prior_ent_mean": 33.69091217670966, "train/prior_ent_min": 16.182468602416712, "train/prior_ent_std": 8.582783462804391, "train/rep_loss_mean": 3.137690025732058, "train/rep_loss_std": 7.928013924064986, "train/reward_avg": 0.021310116728306364, "train/reward_loss_mean": 0.03671798203140497, "train/reward_loss_std": 0.16235512354915296, "train/reward_max_data": 1.011467892642415, "train/reward_max_pred": 1.0121047228848168, "train/reward_neg_acc": 0.9959753254138002, "train/reward_neg_loss": 0.01845048357136633, "train/reward_pos_acc": 0.9922437596758571, "train/reward_pos_loss": 0.71038674952787, "train/reward_pred": 0.021172246227143417, "train/reward_rate": 0.026344789277522936, "train_stats/sum_log_reward": 5.200000047683716, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 2.9, "train_stats/max_log_achievement_collect_sapling": 1.9, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 6.0, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.1, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.1, "train_stats/max_log_achievement_make_wood_sword": 0.1, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 1.8, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 2.0, "train_stats/max_log_achievement_wake_up": 1.6, "train_stats/mean_log_entropy": 0.4309355169534683, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 1.0007995854266483e-07, "report/cont_loss_std": 2.88301151840642e-07, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 6.297260597420973e-07, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 9.748110585405811e-08, "report/cont_pred": 0.9951171875, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 3.195246696472168, "report/dyn_loss_std": 7.766304016113281, "report/image_loss_mean": 2.0266761779785156, "report/image_loss_std": 6.224048614501953, "report/model_loss_mean": 3.984795331954956, "report/model_loss_std": 9.76093578338623, "report/post_ent_mag": 48.947574615478516, "report/post_ent_max": 48.947574615478516, "report/post_ent_mean": 31.392494201660156, "report/post_ent_min": 16.269983291625977, "report/post_ent_std": 4.525776386260986, "report/prior_ent_mag": 77.83356475830078, "report/prior_ent_max": 77.83356475830078, "report/prior_ent_mean": 34.7338981628418, "report/prior_ent_min": 18.049213409423828, "report/prior_ent_std": 8.41645336151123, "report/rep_loss_mean": 3.195246696472168, "report/rep_loss_std": 7.766304016113281, "report/reward_avg": 0.02041015587747097, "report/reward_loss_mean": 0.04097145050764084, "report/reward_loss_std": 0.16696156561374664, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0006077289581299, "report/reward_neg_acc": 0.9929789304733276, "report/reward_neg_loss": 0.023815874010324478, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6744570136070251, "report/reward_pred": 0.02128460817039013, "report/reward_rate": 0.0263671875, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.0001455465389881283, "eval/cont_loss_std": 0.004638229496777058, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.02969960868358612, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 5.315167754815775e-07, "eval/cont_pred": 0.9952515363693237, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 22.47834014892578, "eval/dyn_loss_std": 12.820088386535645, "eval/image_loss_mean": 41.652366638183594, "eval/image_loss_std": 44.307437896728516, "eval/model_loss_mean": 55.265254974365234, "eval/model_loss_std": 49.185245513916016, "eval/post_ent_mag": 48.947574615478516, "eval/post_ent_max": 48.947574615478516, "eval/post_ent_mean": 32.64250564575195, "eval/post_ent_min": 18.00406837463379, "eval/post_ent_std": 4.29342794418335, "eval/prior_ent_mag": 77.83356475830078, "eval/prior_ent_max": 77.83356475830078, "eval/prior_ent_mean": 43.87847900390625, "eval/prior_ent_min": 20.93421173095703, "eval/prior_ent_std": 7.844548225402832, "eval/rep_loss_mean": 22.47834014892578, "eval/rep_loss_std": 12.820088386535645, "eval/reward_avg": 0.02294921875, "eval/reward_loss_mean": 0.12573949992656708, "eval/reward_loss_std": 0.7895438075065613, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0006122589111328, "eval/reward_neg_acc": 0.9909639358520508, "eval/reward_neg_loss": 0.0691496953368187, "eval/reward_pos_acc": 0.785714328289032, "eval/reward_pos_loss": 2.138719320297241, "eval/reward_pred": 0.022180277854204178, "eval/reward_rate": 0.02734375, "replay/size": 174071.0, "replay/inserts": 2179.0, "replay/samples": 34864.0, "replay/insert_wait_avg": 2.5518118870154388e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.886673781564335e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 33904.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 1.087784767150879e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1146204471588, "timer/env.step_count": 272.0, "timer/env.step_total": 23.099200010299683, "timer/env.step_frac": 0.023096552673104464, "timer/env.step_avg": 0.08492352944963119, "timer/env.step_min": 0.023291826248168945, "timer/env.step_max": 2.040701389312744, "timer/replay._sample_count": 34864.0, "timer/replay._sample_total": 18.177335023880005, "timer/replay._sample_frac": 0.018175251768395087, "timer/replay._sample_avg": 0.0005213783565821479, "timer/replay._sample_min": 0.0003840923309326172, "timer/replay._sample_max": 0.011371850967407227, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 272.0, "timer/agent.policy_total": 4.45756721496582, "timer/agent.policy_frac": 0.004457056345174524, "timer/agent.policy_avg": 0.016388114760903752, "timer/agent.policy_min": 0.009820938110351562, "timer/agent.policy_max": 0.019354581832885742, "timer/dataset_train_count": 2179.0, "timer/dataset_train_total": 0.40694165229797363, "timer/dataset_train_frac": 0.0004068950138095441, "timer/dataset_train_avg": 0.0001867561506645129, "timer/dataset_train_min": 9.870529174804688e-05, "timer/dataset_train_max": 0.0008740425109863281, "timer/agent.train_count": 2179.0, "timer/agent.train_total": 970.1879861354828, "timer/agent.train_frac": 0.9700767954994043, "timer/agent.train_avg": 0.4452446012553845, "timer/agent.train_min": 0.4338979721069336, "timer/agent.train_max": 0.6063988208770752, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47533607482910156, "timer/agent.report_frac": 0.0004752815978398308, "timer/agent.report_avg": 0.23766803741455078, "timer/agent.report_min": 0.22876572608947754, "timer/agent.report_max": 0.24657034873962402, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.314018249511719e-05, "timer/dataset_eval_frac": 3.313638438792142e-08, "timer/dataset_eval_avg": 3.314018249511719e-05, "timer/dataset_eval_min": 3.314018249511719e-05, "timer/dataset_eval_max": 3.314018249511719e-05, "fps": 2.178722712957829}
{"step": 175000, "time": 80516.92728972435, "episode/length": 399.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9975, "episode/intrinsic_return": 0.0}
{"step": 175056, "time": 80543.5332980156, "episode/length": 205.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 175280, "time": 80645.90365338326, "episode/length": 186.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 175368, "time": 80687.02862119675, "episode/length": 128.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9534883720930233, "episode/intrinsic_return": 0.0}
{"step": 175552, "time": 80771.23226070404, "episode/length": 445.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9798206278026906, "episode/intrinsic_return": 0.0}
{"step": 175752, "time": 80862.6938135624, "episode/length": 213.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 175800, "time": 80885.78796982765, "episode/length": 247.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 175848, "time": 80908.85195279121, "episode/length": 242.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9958847736625515, "episode/intrinsic_return": 0.0}
{"step": 176320, "time": 81122.70723080635, "episode/length": 164.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 176352, "time": 81138.60520124435, "episode/length": 161.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 176760, "time": 81325.4480330944, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.481802883757848, "train/action_min": 0.0, "train/action_std": 4.335490344321891, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.045901483171470636, "train/actor_opt_grad_steps": 174110.0, "train/actor_opt_loss": -14.581633163709618, "train/adv_mag": 0.5767072607937469, "train/adv_max": 0.5099469423294067, "train/adv_mean": 0.0020293428792476052, "train/adv_min": -0.4786607542810919, "train/adv_std": 0.050160032173950375, "train/cont_avg": 0.9946088398972602, "train/cont_loss_mean": 5.329095838991371e-06, "train/cont_loss_std": 0.00012440069007376084, "train/cont_neg_acc": 1.0, "train/cont_neg_loss": 0.00048554612173168165, "train/cont_pos_acc": 0.999999982581291, "train/cont_pos_loss": 2.7668954061356525e-06, "train/cont_pred": 0.9946084430772965, "train/cont_rate": 0.9946088398972602, "train/dyn_loss_mean": 3.1884565669107654, "train/dyn_loss_std": 7.950515082982033, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1122468734440738, "train/extr_critic_critic_opt_grad_steps": 174110.0, "train/extr_critic_critic_opt_loss": 14690.456625463756, "train/extr_critic_mag": 9.922102623334213, "train/extr_critic_max": 9.922102623334213, "train/extr_critic_mean": 2.4663563166579157, "train/extr_critic_min": -0.6513796925000405, "train/extr_critic_std": 2.1814856714309623, "train/extr_return_normed_mag": 1.5694465239842732, "train/extr_return_normed_max": 1.5694465239842732, "train/extr_return_normed_mean": 0.39011416465180104, "train/extr_return_normed_min": -0.11365813386018418, "train/extr_return_normed_std": 0.3213480791272638, "train/extr_return_rate": 0.8279383525456467, "train/extr_return_raw_mag": 10.61422706412398, "train/extr_return_raw_max": 10.61422706412398, "train/extr_return_raw_mean": 2.4803526167455874, "train/extr_return_raw_min": -0.9946263114066973, "train/extr_return_raw_std": 2.2168712621410145, "train/extr_reward_mag": 1.027717595775378, "train/extr_reward_max": 1.027717595775378, "train/extr_reward_mean": 0.03640706597329819, "train/extr_reward_min": -0.6776964158227999, "train/extr_reward_std": 0.19039241840305937, "train/image_loss_mean": 1.6312188402702819, "train/image_loss_std": 5.052408059438069, "train/model_loss_mean": 3.5815084503121573, "train/model_loss_std": 8.869532972710317, "train/model_opt_grad_norm": 29.107899548256235, "train/model_opt_grad_steps": 173960.28310502283, "train/model_opt_loss": 4525.83180606093, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1275.6849315068494, "train/policy_entropy_mag": 2.5213251288078693, "train/policy_entropy_max": 2.5213251288078693, "train/policy_entropy_mean": 0.5019054834701154, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.590608750984549, "train/policy_logprob_mag": 7.438384108347435, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5015702442219269, "train/policy_logprob_min": -7.438384108347435, "train/policy_logprob_std": 1.0784032584325363, "train/policy_randomness_mag": 0.8899171254406236, "train/policy_randomness_max": 0.8899171254406236, "train/policy_randomness_mean": 0.17715061340293928, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.20845897271208566, "train/post_ent_mag": 48.18140684850684, "train/post_ent_max": 48.18140684850684, "train/post_ent_mean": 30.53079336854421, "train/post_ent_min": 14.443208472369468, "train/post_ent_std": 4.966837403981109, "train/prior_ent_mag": 77.74043507336482, "train/prior_ent_max": 77.74043507336482, "train/prior_ent_mean": 33.596360106446426, "train/prior_ent_min": 16.024314893435125, "train/prior_ent_std": 8.636597720455361, "train/rep_loss_mean": 3.1884565669107654, "train/rep_loss_std": 7.950515082982033, "train/reward_avg": 0.022101972469013846, "train/reward_loss_mean": 0.037210343490656654, "train/reward_loss_std": 0.1691884702607377, "train/reward_max_data": 1.0141552545164274, "train/reward_max_pred": 1.0146435580841482, "train/reward_neg_acc": 0.9962151929668096, "train/reward_neg_loss": 0.018278454538842994, "train/reward_pos_acc": 0.9903587217200293, "train/reward_pos_loss": 0.7199601013910825, "train/reward_pred": 0.021947694525598936, "train/reward_rate": 0.0269736372716895, "train_stats/sum_log_reward": 5.599999952316284, "train_stats/max_log_achievement_collect_coal": 0.1, "train_stats/max_log_achievement_collect_drink": 3.8, "train_stats/max_log_achievement_collect_sapling": 1.5, "train_stats/max_log_achievement_collect_stone": 0.7, "train_stats/max_log_achievement_collect_wood": 6.9, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.8, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 1.5, "train_stats/max_log_achievement_place_stone": 0.3, "train_stats/max_log_achievement_place_table": 2.7, "train_stats/max_log_achievement_wake_up": 3.1, "train_stats/mean_log_entropy": 0.5690775364637375, "report/cont_avg": 0.9990234375, "report/cont_loss_mean": 1.7294894405495143e-06, "report/cont_loss_std": 3.6720205116580473e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 5.727019470214145e-06, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.7255817965633469e-06, "report/cont_pred": 0.9990216493606567, "report/cont_rate": 0.9990234375, "report/dyn_loss_mean": 3.195791244506836, "report/dyn_loss_std": 7.6134934425354, "report/image_loss_mean": 2.234292984008789, "report/image_loss_std": 5.781003475189209, "report/model_loss_mean": 4.179713249206543, "report/model_loss_std": 9.405288696289062, "report/post_ent_mag": 47.157691955566406, "report/post_ent_max": 47.157691955566406, "report/post_ent_mean": 32.367427825927734, "report/post_ent_min": 15.759366989135742, "report/post_ent_std": 5.3527326583862305, "report/prior_ent_mag": 77.66886901855469, "report/prior_ent_max": 77.66886901855469, "report/prior_ent_mean": 35.37845230102539, "report/prior_ent_min": 20.72858428955078, "report/prior_ent_std": 7.643984317779541, "report/rep_loss_mean": 3.195791244506836, "report/rep_loss_std": 7.6134934425354, "report/reward_avg": 0.01513671875, "report/reward_loss_mean": 0.027943477034568787, "report/reward_loss_std": 0.14869658648967743, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0006513595581055, "report/reward_neg_acc": 0.995029866695404, "report/reward_neg_loss": 0.014485787600278854, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7800788879394531, "report/reward_pred": 0.014595395885407925, "report/reward_rate": 0.017578125, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 4.1057635826291516e-05, "eval/cont_loss_std": 0.0011854185722768307, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.006330564152449369, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 3.987854597653495e-06, "eval/cont_pred": 0.9941730499267578, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 18.0655517578125, "eval/dyn_loss_std": 12.330881118774414, "eval/image_loss_mean": 21.367290496826172, "eval/image_loss_std": 29.217914581298828, "eval/model_loss_mean": 32.30356979370117, "eval/model_loss_std": 34.02191162109375, "eval/post_ent_mag": 52.021732330322266, "eval/post_ent_max": 52.021732330322266, "eval/post_ent_mean": 34.14281463623047, "eval/post_ent_min": 14.868252754211426, "eval/post_ent_std": 5.141364097595215, "eval/prior_ent_mag": 77.66886901855469, "eval/prior_ent_max": 77.66886901855469, "eval/prior_ent_mean": 44.092498779296875, "eval/prior_ent_min": 16.532028198242188, "eval/prior_ent_std": 8.434244155883789, "eval/rep_loss_mean": 18.0655517578125, "eval/rep_loss_std": 12.330881118774414, "eval/reward_avg": 0.03476562350988388, "eval/reward_loss_mean": 0.0969046801328659, "eval/reward_loss_std": 0.5669256448745728, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.000650405883789, "eval/reward_neg_acc": 0.9918699860572815, "eval/reward_neg_loss": 0.06450505554676056, "eval/reward_pos_acc": 0.925000011920929, "eval/reward_pos_loss": 0.8939353823661804, "eval/reward_pred": 0.03448761999607086, "eval/reward_rate": 0.0390625, "replay/size": 176256.0, "replay/inserts": 2185.0, "replay/samples": 34960.0, "replay/insert_wait_avg": 2.61725768344626e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.178452878031087e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 33904.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 9.834766387939453e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2409934997559, "timer/env.step_count": 273.0, "timer/env.step_total": 22.20311212539673, "timer/env.step_frac": 0.02219776260889886, "timer/env.step_avg": 0.08133008104540926, "timer/env.step_min": 0.02373528480529785, "timer/env.step_max": 1.618360996246338, "timer/replay._sample_count": 34960.0, "timer/replay._sample_total": 18.20092225074768, "timer/replay._sample_frac": 0.01819653700361174, "timer/replay._sample_avg": 0.0005206213458451854, "timer/replay._sample_min": 0.0003612041473388672, "timer/replay._sample_max": 0.02579188346862793, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 273.0, "timer/agent.policy_total": 4.4789793491363525, "timer/agent.policy_frac": 0.004477900204294562, "timer/agent.policy_avg": 0.016406517762404222, "timer/agent.policy_min": 0.009917020797729492, "timer/agent.policy_max": 0.04126572608947754, "timer/dataset_train_count": 2185.0, "timer/dataset_train_total": 0.40799427032470703, "timer/dataset_train_frac": 0.000407895970047349, "timer/dataset_train_avg": 0.0001867250665101634, "timer/dataset_train_min": 0.00010061264038085938, "timer/dataset_train_max": 0.0008630752563476562, "timer/agent.train_count": 2185.0, "timer/agent.train_total": 971.1352031230927, "timer/agent.train_frac": 0.9709012222396279, "timer/agent.train_avg": 0.4444554705368845, "timer/agent.train_min": 0.433117151260376, "timer/agent.train_max": 0.5769996643066406, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4837334156036377, "timer/agent.report_frac": 0.00048361686708229857, "timer/agent.report_avg": 0.24186670780181885, "timer/agent.report_min": 0.23836827278137207, "timer/agent.report_max": 0.24536514282226562, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.123283386230469e-05, "timer/dataset_eval_frac": 3.1225308765864244e-08, "timer/dataset_eval_avg": 3.123283386230469e-05, "timer/dataset_eval_min": 3.123283386230469e-05, "timer/dataset_eval_max": 3.123283386230469e-05, "fps": 2.18444379102867}
{"step": 176808, "time": 81347.65883660316, "episode/length": 190.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 176816, "time": 81352.78026103973, "episode/length": 180.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 177088, "time": 81477.9708955288, "episode/length": 160.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 177288, "time": 81570.81267619133, "episode/length": 191.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 177320, "time": 81586.84626984596, "episode/length": 183.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 177584, "time": 81708.8809838295, "episode/length": 153.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 177720, "time": 81772.57308912277, "episode/length": 270.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.985239852398524, "episode/intrinsic_return": 0.0}
{"step": 177968, "time": 81886.82017159462, "episode/length": 205.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 178032, "time": 81917.5281252861, "episode/length": 152.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9607843137254902, "episode/intrinsic_return": 0.0}
{"step": 178192, "time": 81991.65730118752, "episode/length": 137.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9637681159420289, "episode/intrinsic_return": 0.0}
{"step": 178440, "time": 82105.14106535912, "episode/length": 202.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 178544, "time": 82153.80545949936, "episode/length": 156.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 178656, "time": 82206.17891740799, "episode/length": 166.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 178915, "time": 82325.73336172104, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.392720067223837, "train/action_min": 0.0, "train/action_std": 4.183173306043758, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04871747433099636, "train/actor_opt_grad_steps": 176280.0, "train/actor_opt_loss": -13.848115218344123, "train/adv_mag": 0.6748997887899709, "train/adv_max": 0.6054642108290694, "train/adv_mean": 0.0024502590693246443, "train/adv_min": -0.5569226346736731, "train/adv_std": 0.054329391101072, "train/cont_avg": 0.9943450218023255, "train/cont_loss_mean": 1.6373878559753648e-05, "train/cont_loss_std": 0.000454770402769306, "train/cont_neg_acc": 1.0, "train/cont_neg_loss": 0.0005041296719148937, "train/cont_pos_acc": 0.999990834191788, "train/cont_pos_loss": 1.371721403244052e-05, "train/cont_pred": 0.99433640879254, "train/cont_rate": 0.9943450218023255, "train/dyn_loss_mean": 3.076773111210313, "train/dyn_loss_std": 7.924310455765835, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1170041023298751, "train/extr_critic_critic_opt_grad_steps": 176280.0, "train/extr_critic_critic_opt_loss": 14973.540570494186, "train/extr_critic_mag": 11.353765807040903, "train/extr_critic_max": 11.353765807040903, "train/extr_critic_mean": 2.5022280410278674, "train/extr_critic_min": -0.6694408045258633, "train/extr_critic_std": 2.2831453062767206, "train/extr_return_normed_mag": 1.7412955139958581, "train/extr_return_normed_max": 1.7412955139958581, "train/extr_return_normed_mean": 0.3941832344199336, "train/extr_return_normed_min": -0.11627980325111123, "train/extr_return_normed_std": 0.3333772919205732, "train/extr_return_rate": 0.7989268824111584, "train/extr_return_raw_mag": 11.920759396220362, "train/extr_return_raw_max": 11.920759396220362, "train/extr_return_raw_mean": 2.5193540079649104, "train/extr_return_raw_min": -1.0426153510115868, "train/extr_return_raw_std": 2.3267555015031682, "train/extr_reward_mag": 1.032415479283, "train/extr_reward_max": 1.032415479283, "train/extr_reward_mean": 0.03657395135351392, "train/extr_reward_min": -0.6818787657937339, "train/extr_reward_std": 0.192994455611983, "train/image_loss_mean": 1.5582412872203562, "train/image_loss_std": 4.946127968056257, "train/model_loss_mean": 3.4413108969843664, "train/model_loss_std": 8.762665358255076, "train/model_opt_grad_norm": 28.947898385691087, "train/model_opt_grad_steps": 176129.0, "train/model_opt_loss": 5812.996906795058, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1700.5813953488373, "train/policy_entropy_mag": 2.5285066460454186, "train/policy_entropy_max": 2.5285066460454186, "train/policy_entropy_mean": 0.4750750494557758, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.5749037796674773, "train/policy_logprob_mag": 7.438384142587351, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.47488403777743493, "train/policy_logprob_min": -7.438384142587351, "train/policy_logprob_std": 1.0624292545540388, "train/policy_randomness_mag": 0.8924518851346748, "train/policy_randomness_max": 0.8924518851346748, "train/policy_randomness_mean": 0.16768064342958983, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.20291580599407816, "train/post_ent_mag": 48.55064131271008, "train/post_ent_max": 48.55064131271008, "train/post_ent_mean": 30.855093720901845, "train/post_ent_min": 14.3984960777815, "train/post_ent_std": 5.023536534642064, "train/prior_ent_mag": 77.82469794694768, "train/prior_ent_max": 77.82469794694768, "train/prior_ent_mean": 33.808159584222835, "train/prior_ent_min": 15.940268968981366, "train/prior_ent_std": 8.641965477965599, "train/rep_loss_mean": 3.076773111210313, "train/rep_loss_std": 7.924310455765835, "train/reward_avg": 0.021627452663080984, "train/reward_loss_mean": 0.03698937640806963, "train/reward_loss_std": 0.16370341011951137, "train/reward_max_data": 1.014418608088826, "train/reward_max_pred": 1.0146362315776736, "train/reward_neg_acc": 0.9962859126024468, "train/reward_neg_loss": 0.01847808331597683, "train/reward_pos_acc": 0.9921185925949452, "train/reward_pos_loss": 0.7112706359042678, "train/reward_pred": 0.02152735910724935, "train/reward_rate": 0.026716933139534885, "train_stats/sum_log_reward": 4.715384520017183, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 3.076923076923077, "train_stats/max_log_achievement_collect_sapling": 1.6153846153846154, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 5.461538461538462, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.46153846153846156, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 1.6153846153846154, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 2.3846153846153846, "train_stats/max_log_achievement_wake_up": 1.8461538461538463, "train_stats/mean_log_entropy": 0.4754111056144421, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 2.216701614088379e-05, "report/cont_loss_std": 0.0006985545041970909, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0032114600762724876, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 2.1514674131140055e-07, "report/cont_pred": 0.9931856393814087, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 3.271636486053467, "report/dyn_loss_std": 7.478242874145508, "report/image_loss_mean": 1.1910772323608398, "report/image_loss_std": 3.16780161857605, "report/model_loss_mean": 3.186901092529297, "report/model_loss_std": 7.135983943939209, "report/post_ent_mag": 45.7283935546875, "report/post_ent_max": 45.7283935546875, "report/post_ent_mean": 32.192420959472656, "report/post_ent_min": 16.284744262695312, "report/post_ent_std": 5.081974983215332, "report/prior_ent_mag": 77.51233673095703, "report/prior_ent_max": 77.51233673095703, "report/prior_ent_mean": 35.177616119384766, "report/prior_ent_min": 19.456485748291016, "report/prior_ent_std": 8.890467643737793, "report/rep_loss_mean": 3.271636486053467, "report/rep_loss_std": 7.478242874145508, "report/reward_avg": 0.02236328274011612, "report/reward_loss_mean": 0.03281982243061066, "report/reward_loss_std": 0.13903893530368805, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0018305778503418, "report/reward_neg_acc": 0.9919759631156921, "report/reward_neg_loss": 0.01518537662923336, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.683988094329834, "report/reward_pred": 0.022812243551015854, "report/reward_rate": 0.0263671875, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.0003115306608378887, "eval/cont_loss_std": 0.00478618498891592, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.03971611708402634, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.00015700282528996468, "eval/cont_pred": 0.9960953593254089, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 21.340110778808594, "eval/dyn_loss_std": 13.795919418334961, "eval/image_loss_mean": 34.66401672363281, "eval/image_loss_std": 37.68280029296875, "eval/model_loss_mean": 47.614524841308594, "eval/model_loss_std": 44.0360107421875, "eval/post_ent_mag": 49.70555114746094, "eval/post_ent_max": 49.70555114746094, "eval/post_ent_mean": 33.73405075073242, "eval/post_ent_min": 18.13104248046875, "eval/post_ent_std": 4.39103364944458, "eval/prior_ent_mag": 77.51233673095703, "eval/prior_ent_max": 77.51233673095703, "eval/prior_ent_mean": 45.14330291748047, "eval/prior_ent_min": 23.44879913330078, "eval/prior_ent_std": 7.664584159851074, "eval/rep_loss_mean": 21.340110778808594, "eval/rep_loss_std": 13.795919418334961, "eval/reward_avg": 0.02646484225988388, "eval/reward_loss_mean": 0.14613428711891174, "eval/reward_loss_std": 1.033687949180603, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0012426376342773, "eval/reward_neg_acc": 0.9919517040252686, "eval/reward_neg_loss": 0.06243203952908516, "eval/reward_pos_acc": 0.8333333730697632, "eval/reward_pos_loss": 2.919468879699707, "eval/reward_pred": 0.021526556462049484, "eval/reward_rate": 0.029296875, "replay/size": 178411.0, "replay/inserts": 2155.0, "replay/samples": 34480.0, "replay/insert_wait_avg": 2.642297412845762e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.169086239454088e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 33904.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 1.296401023864746e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2712647914886, "timer/env.step_count": 270.0, "timer/env.step_total": 27.557153940200806, "timer/env.step_frac": 0.027549680681815073, "timer/env.step_avg": 0.10206353311185483, "timer/env.step_min": 0.023855209350585938, "timer/env.step_max": 2.013988494873047, "timer/replay._sample_count": 34480.0, "timer/replay._sample_total": 18.01955485343933, "timer/replay._sample_frac": 0.018014668108251208, "timer/replay._sample_avg": 0.0005226088994616975, "timer/replay._sample_min": 0.00038623809814453125, "timer/replay._sample_max": 0.02051520347595215, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 270.0, "timer/agent.policy_total": 4.523865699768066, "timer/agent.policy_frac": 0.00452263886707881, "timer/agent.policy_avg": 0.016755058147289136, "timer/agent.policy_min": 0.0101776123046875, "timer/agent.policy_max": 0.05162501335144043, "timer/dataset_train_count": 2155.0, "timer/dataset_train_total": 0.4060814380645752, "timer/dataset_train_frac": 0.0004059713123411826, "timer/dataset_train_avg": 0.00018843686221093977, "timer/dataset_train_min": 9.799003601074219e-05, "timer/dataset_train_max": 0.0006318092346191406, "timer/agent.train_count": 2155.0, "timer/agent.train_total": 965.827844619751, "timer/agent.train_frac": 0.9655659205816358, "timer/agent.train_avg": 0.4481799743015086, "timer/agent.train_min": 0.4357278347015381, "timer/agent.train_max": 0.5918176174163818, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47536373138427734, "timer/agent.report_frac": 0.0004752348169107599, "timer/agent.report_avg": 0.23768186569213867, "timer/agent.report_min": 0.23100042343139648, "timer/agent.report_max": 0.24436330795288086, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8371810913085938e-05, "timer/dataset_eval_frac": 2.836411672687626e-08, "timer/dataset_eval_avg": 2.8371810913085938e-05, "timer/dataset_eval_min": 2.8371810913085938e-05, "timer/dataset_eval_max": 2.8371810913085938e-05, "fps": 2.154385823674897}
{"step": 179000, "time": 82364.53478646278, "episode/length": 176.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 179224, "time": 82467.69996285439, "episode/length": 187.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 179464, "time": 82578.18764591217, "episode/length": 178.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 179656, "time": 82666.79686665535, "episode/length": 182.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 179664, "time": 82671.85888409615, "episode/length": 152.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 179760, "time": 82717.14111828804, "episode/length": 223.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.0}
{"step": 179832, "time": 82751.42347431183, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 180024, "time": 82853.71651697159, "eval_episode/length": 34.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 180024, "time": 82855.42706155777, "eval_episode/length": 36.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.972972972972973}
{"step": 180024, "time": 82858.6899945736, "eval_episode/length": 83.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9404761904761905}
{"step": 180024, "time": 82862.90710306168, "eval_episode/length": 152.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9673202614379085}
{"step": 180024, "time": 82864.96497678757, "eval_episode/length": 164.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9939393939393939}
{"step": 180024, "time": 82866.70153236389, "eval_episode/length": 171.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9767441860465116}
{"step": 180024, "time": 82868.8457019329, "eval_episode/length": 152.0, "eval_episode/score": 2.099999964237213, "eval_episode/reward_rate": 0.9738562091503268}
{"step": 180024, "time": 82871.13406586647, "eval_episode/length": 208.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9952153110047847}
{"step": 180192, "time": 82947.28512430191, "episode/length": 191.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 180288, "time": 82992.9670290947, "episode/length": 77.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9358974358974359, "episode/intrinsic_return": 0.0}
{"step": 180312, "time": 83005.39515399933, "episode/length": 105.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9716981132075472, "episode/intrinsic_return": 0.0}
{"step": 180472, "time": 83079.25556993484, "episode/length": 183.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.967391304347826, "episode/intrinsic_return": 0.0}
{"step": 180808, "time": 83233.34027528763, "episode/length": 130.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9541984732824428, "episode/intrinsic_return": 0.0}
{"step": 180992, "time": 83318.26159358025, "episode/length": 166.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9580838323353293, "episode/intrinsic_return": 0.0}
{"step": 181005, "time": 83326.12383699417, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.358657763905502, "train/action_min": 0.0, "train/action_std": 4.084281265450437, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.05060708872153999, "train/actor_opt_grad_steps": 178400.0, "train/actor_opt_loss": -15.77508692165311, "train/adv_mag": 0.7470996117477782, "train/adv_max": 0.6972789580456948, "train/adv_mean": 0.0021458580884680042, "train/adv_min": -0.5595435165047076, "train/adv_std": 0.05689356976932886, "train/cont_avg": 0.9944116327751196, "train/cont_loss_mean": 7.82076791645473e-06, "train/cont_loss_std": 0.00022847648005123512, "train/cont_neg_acc": 1.0, "train/cont_neg_loss": 0.0006576481783816487, "train/cont_pos_acc": 0.9999952678475084, "train/cont_pos_loss": 4.4375350170318854e-06, "train/cont_pred": 0.9944114000603342, "train/cont_rate": 0.9944116327751196, "train/dyn_loss_mean": 3.1406250844161474, "train/dyn_loss_std": 7.9406316086436, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1665407787099409, "train/extr_critic_critic_opt_grad_steps": 178400.0, "train/extr_critic_critic_opt_loss": 15222.183565714713, "train/extr_critic_mag": 12.054784733712959, "train/extr_critic_max": 12.054784733712959, "train/extr_critic_mean": 2.4019011584195225, "train/extr_critic_min": -0.6852743893719175, "train/extr_critic_std": 2.2444362589046714, "train/extr_return_normed_mag": 1.8225965921958667, "train/extr_return_normed_max": 1.8225965921958667, "train/extr_return_normed_mean": 0.38635592027144, "train/extr_return_normed_min": -0.12275985781655928, "train/extr_return_normed_std": 0.33295711582642423, "train/extr_return_rate": 0.7781608632306733, "train/extr_return_raw_mag": 12.312154674073726, "train/extr_return_raw_max": 12.312154674073726, "train/extr_return_raw_mean": 2.416687684196034, "train/extr_return_raw_min": -1.0903862244204472, "train/extr_return_raw_std": 2.293774443950379, "train/extr_reward_mag": 1.0311066841965086, "train/extr_reward_max": 1.0311066841965086, "train/extr_reward_mean": 0.036092202727232826, "train/extr_reward_min": -0.6759517073060908, "train/extr_reward_std": 0.1922255788693588, "train/image_loss_mean": 1.5454238496328656, "train/image_loss_std": 4.735624072654396, "train/model_loss_mean": 3.46748357754575, "train/model_loss_std": 8.604863842138263, "train/model_opt_grad_norm": 28.212011766205563, "train/model_opt_grad_steps": 178247.62679425837, "train/model_opt_loss": 8878.036934154456, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2571.7703349282297, "train/policy_entropy_mag": 2.533956996561808, "train/policy_entropy_max": 2.533956996561808, "train/policy_entropy_mean": 0.49939912087038946, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.6028885523383127, "train/policy_logprob_mag": 7.438384124536833, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.49935901008154215, "train/policy_logprob_min": -7.438384124536833, "train/policy_logprob_std": 1.0803665379017735, "train/policy_randomness_mag": 0.8943756202761637, "train/policy_randomness_max": 0.8943756202761637, "train/policy_randomness_mean": 0.17626597447115838, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.2127932024201708, "train/post_ent_mag": 48.60076579408783, "train/post_ent_max": 48.60076579408783, "train/post_ent_mean": 30.885025599356474, "train/post_ent_min": 14.20788988998632, "train/post_ent_std": 5.0087555789491205, "train/prior_ent_mag": 77.7438977620248, "train/prior_ent_max": 77.7438977620248, "train/prior_ent_mean": 33.89669769688656, "train/prior_ent_min": 15.735044958488793, "train/prior_ent_std": 8.632900616769016, "train/rep_loss_mean": 3.1406250844161474, "train/rep_loss_std": 7.9406316086436, "train/reward_avg": 0.021432509612399, "train/reward_loss_mean": 0.03767685723183543, "train/reward_loss_std": 0.167464635838447, "train/reward_max_data": 1.0143540704079221, "train/reward_max_pred": 1.0154223864158374, "train/reward_neg_acc": 0.9955667690797285, "train/reward_neg_loss": 0.019225483766921826, "train/reward_pos_acc": 0.9918733176432157, "train/reward_pos_loss": 0.7137371803584852, "train/reward_pred": 0.02132312998812842, "train/reward_rate": 0.026568107057416267, "train_stats/sum_log_reward": 4.946153860825759, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 2.076923076923077, "train_stats/max_log_achievement_collect_sapling": 1.5384615384615385, "train_stats/max_log_achievement_collect_stone": 0.46153846153846156, "train_stats/max_log_achievement_collect_wood": 4.923076923076923, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.46153846153846156, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 1.4615384615384615, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 1.8461538461538463, "train_stats/max_log_achievement_wake_up": 1.9230769230769231, "train_stats/mean_log_entropy": 0.4189881682395935, "eval_stats/sum_log_reward": 4.350000023841858, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 1.625, "eval_stats/max_log_achievement_collect_sapling": 1.25, "eval_stats/max_log_achievement_collect_stone": 0.125, "eval_stats/max_log_achievement_collect_wood": 3.375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.375, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.25, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 1.125, "eval_stats/max_log_achievement_wake_up": 1.5, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.014123156666755676, "report/cont_loss_std": 0.45168358087539673, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 7.707354825470247e-07, "report/cont_pos_acc": 0.999018669128418, "report/cont_pos_loss": 0.014192451722919941, "report/cont_pred": 0.994139552116394, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 3.076528549194336, "report/dyn_loss_std": 8.29606819152832, "report/image_loss_mean": 2.078859329223633, "report/image_loss_std": 6.3904547691345215, "report/model_loss_mean": 3.989591360092163, "report/model_loss_std": 10.589057922363281, "report/post_ent_mag": 47.24971389770508, "report/post_ent_max": 47.24971389770508, "report/post_ent_mean": 30.337156295776367, "report/post_ent_min": 15.34020709991455, "report/post_ent_std": 4.7574849128723145, "report/prior_ent_mag": 77.80353546142578, "report/prior_ent_max": 77.80353546142578, "report/prior_ent_mean": 33.39313507080078, "report/prior_ent_min": 16.501705169677734, "report/prior_ent_std": 8.285209655761719, "report/rep_loss_mean": 3.076528549194336, "report/rep_loss_std": 8.29606819152832, "report/reward_avg": 0.01884765550494194, "report/reward_loss_mean": 0.05069153755903244, "report/reward_loss_std": 0.22861842811107635, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.109553575515747, "report/reward_neg_acc": 0.9989979863166809, "report/reward_neg_loss": 0.028885770589113235, "report/reward_pos_acc": 0.9230769872665405, "report/reward_pos_loss": 0.8876975178718567, "report/reward_pred": 0.016899537295103073, "report/reward_rate": 0.025390625, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 1.4298386759037385e-06, "eval/cont_loss_std": 8.430277375737205e-06, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00013397140719462186, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.1704617008945206e-06, "eval/cont_pred": 0.9980459809303284, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 21.275197982788086, "eval/dyn_loss_std": 13.37377643585205, "eval/image_loss_mean": 32.74000549316406, "eval/image_loss_std": 45.368377685546875, "eval/model_loss_mean": 45.64899444580078, "eval/model_loss_std": 50.85009002685547, "eval/post_ent_mag": 45.15241622924805, "eval/post_ent_max": 45.15241622924805, "eval/post_ent_mean": 33.0693473815918, "eval/post_ent_min": 18.42046356201172, "eval/post_ent_std": 4.189789772033691, "eval/prior_ent_mag": 77.80353546142578, "eval/prior_ent_max": 77.80353546142578, "eval/prior_ent_mean": 43.690330505371094, "eval/prior_ent_min": 19.65390968322754, "eval/prior_ent_std": 8.001279830932617, "eval/rep_loss_mean": 21.275197982788086, "eval/rep_loss_std": 13.37377643585205, "eval/reward_avg": 0.015234374441206455, "eval/reward_loss_mean": 0.1438659280538559, "eval/reward_loss_std": 0.8638696670532227, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0209200382232666, "eval/reward_neg_acc": 0.9930348992347717, "eval/reward_neg_loss": 0.10207899659872055, "eval/reward_pos_acc": 0.7894737124443054, "eval/reward_pos_loss": 2.354174852371216, "eval/reward_pred": 0.01824001595377922, "eval/reward_rate": 0.0185546875, "replay/size": 180501.0, "replay/inserts": 2090.0, "replay/samples": 33440.0, "replay/insert_wait_avg": 2.614048679479572e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.975828704651464e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 35576.0, "eval_replay/inserts": 1672.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1430402691854815e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.046627044677734e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3766462802887, "timer/env.step_count": 261.0, "timer/env.step_total": 26.175515174865723, "timer/env.step_frac": 0.026165659976364327, "timer/env.step_avg": 0.10028933017189932, "timer/env.step_min": 0.023842334747314453, "timer/env.step_max": 1.7383389472961426, "timer/replay._sample_count": 33440.0, "timer/replay._sample_total": 17.478681325912476, "timer/replay._sample_frac": 0.01747210052424119, "timer/replay._sample_avg": 0.0005226878386935549, "timer/replay._sample_min": 0.0003876686096191406, "timer/replay._sample_max": 0.025673627853393555, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 470.0, "timer/agent.policy_total": 7.5476438999176025, "timer/agent.policy_frac": 0.007544802178241654, "timer/agent.policy_avg": 0.016058816808335326, "timer/agent.policy_min": 0.009727954864501953, "timer/agent.policy_max": 0.05013728141784668, "timer/dataset_train_count": 2090.0, "timer/dataset_train_total": 0.3917572498321533, "timer/dataset_train_frac": 0.00039160975147593515, "timer/dataset_train_avg": 0.00018744366020677193, "timer/dataset_train_min": 0.00010251998901367188, "timer/dataset_train_max": 0.0007789134979248047, "timer/agent.train_count": 2090.0, "timer/agent.train_total": 936.6785085201263, "timer/agent.train_frac": 0.9363258448735166, "timer/agent.train_avg": 0.44817153517709396, "timer/agent.train_min": 0.43699193000793457, "timer/agent.train_max": 0.5804653167724609, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4761834144592285, "timer/agent.report_frac": 0.00047600412927453523, "timer/agent.report_avg": 0.23809170722961426, "timer/agent.report_min": 0.2307891845703125, "timer/agent.report_max": 0.24539422988891602, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 0.00010228157043457031, "timer/dataset_eval_frac": 1.0224306096597215e-07, "timer/dataset_eval_avg": 0.00010228157043457031, "timer/dataset_eval_min": 0.00010228157043457031, "timer/dataset_eval_max": 0.00010228157043457031, "fps": 2.0891866216429493}
{"step": 181088, "time": 83363.73271608353, "episode/length": 156.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 181184, "time": 83408.48860239983, "episode/length": 244.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 181672, "time": 83630.14893317223, "episode/length": 172.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9826589595375722, "episode/intrinsic_return": 0.0}
{"step": 181784, "time": 83682.02834105492, "episode/length": 163.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 181968, "time": 83766.52596020699, "episode/length": 206.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 182264, "time": 83901.35707139969, "episode/length": 181.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 182416, "time": 83971.5471060276, "episode/length": 177.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 182432, "time": 83980.28135681152, "episode/length": 167.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 182640, "time": 84075.23371124268, "episode/length": 305.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 182792, "time": 84145.36850976944, "episode/length": 200.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 182936, "time": 84211.68909716606, "episode/length": 143.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 183187, "time": 84326.3787829876, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.345372751218464, "train/action_min": 0.0, "train/action_std": 4.116315714809873, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0509010498676825, "train/actor_opt_grad_steps": 180535.0, "train/actor_opt_loss": -12.551979887337689, "train/adv_mag": 0.6455462998753294, "train/adv_max": 0.5801767745149244, "train/adv_mean": 0.0031141730635690984, "train/adv_min": -0.5379448884397472, "train/adv_std": 0.056673685481788916, "train/cont_avg": 0.9944318018922018, "train/cont_loss_mean": 2.5626367871656482e-05, "train/cont_loss_std": 0.0007743231939608187, "train/cont_neg_acc": 0.9971712540595903, "train/cont_neg_loss": 0.0038229022214394666, "train/cont_pos_acc": 0.9999999808608939, "train/cont_pos_loss": 6.120360319215218e-06, "train/cont_pred": 0.9944397952031652, "train/cont_rate": 0.9944318018922018, "train/dyn_loss_mean": 3.1264614512067324, "train/dyn_loss_std": 7.9201432389950535, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.134343715435868, "train/extr_critic_critic_opt_grad_steps": 180535.0, "train/extr_critic_critic_opt_loss": 15395.957376182627, "train/extr_critic_mag": 10.451572020119483, "train/extr_critic_max": 10.451572020119483, "train/extr_critic_mean": 2.4433503145471627, "train/extr_critic_min": -0.6901894955460085, "train/extr_critic_std": 2.194320826902302, "train/extr_return_normed_mag": 1.658045237764306, "train/extr_return_normed_max": 1.658045237764306, "train/extr_return_normed_mean": 0.40133559430411103, "train/extr_return_normed_min": -0.12587369674252807, "train/extr_return_normed_std": 0.33274394137050034, "train/extr_return_rate": 0.7896801359062895, "train/extr_return_raw_mag": 10.902276708445418, "train/extr_return_raw_max": 10.902276708445418, "train/extr_return_raw_mean": 2.464262452147423, "train/extr_return_raw_min": -1.0766680068379149, "train/extr_return_raw_std": 2.234919998623909, "train/extr_reward_mag": 1.0241537296443903, "train/extr_reward_max": 1.0241537296443903, "train/extr_reward_mean": 0.03750913309941598, "train/extr_reward_min": -0.6694191152896356, "train/extr_reward_std": 0.19449061613290683, "train/image_loss_mean": 1.5431095337102172, "train/image_loss_std": 4.921606554897553, "train/model_loss_mean": 3.4568473166282025, "train/model_loss_std": 8.737578282662488, "train/model_opt_grad_norm": 28.714046698012112, "train/model_opt_grad_steps": 180380.25229357797, "train/model_opt_loss": 7522.2801323286985, "train/model_opt_model_opt_grad_overflow": 0.0045871559633027525, "train/model_opt_model_opt_grad_scale": 2167.4311926605506, "train/policy_entropy_mag": 2.537169938787408, "train/policy_entropy_max": 2.537169938787408, "train/policy_entropy_mean": 0.48632238518207443, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.5922489274259007, "train/policy_logprob_mag": 7.438384161082976, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.48624212069248934, "train/policy_logprob_min": -7.438384161082976, "train/policy_logprob_std": 1.071288074922124, "train/policy_randomness_mag": 0.8955096471200296, "train/policy_randomness_max": 0.8955096471200296, "train/policy_randomness_mean": 0.17165046038294057, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.2090378835660602, "train/post_ent_mag": 48.71031122470121, "train/post_ent_max": 48.71031122470121, "train/post_ent_mean": 31.057503525270235, "train/post_ent_min": 14.269027950566842, "train/post_ent_std": 5.027919407284588, "train/prior_ent_mag": 77.7363440487363, "train/prior_ent_max": 77.7363440487363, "train/prior_ent_mean": 34.06702318978966, "train/prior_ent_min": 16.062879046168895, "train/prior_ent_std": 8.606646095940826, "train/rep_loss_mean": 3.1264614512067324, "train/rep_loss_std": 7.9201432389950535, "train/reward_avg": 0.022447050489280203, "train/reward_loss_mean": 0.0378352986272732, "train/reward_loss_std": 0.16822436622796802, "train/reward_max_data": 1.010091745525325, "train/reward_max_pred": 1.0111101592352632, "train/reward_neg_acc": 0.9964781214884662, "train/reward_neg_loss": 0.018767798913283906, "train/reward_pos_acc": 0.9925535083363909, "train/reward_pos_loss": 0.7135558456455896, "train/reward_pred": 0.02233320201208832, "train/reward_rate": 0.02750053755733945, "train_stats/sum_log_reward": 6.190909038890492, "train_stats/max_log_achievement_collect_coal": 0.18181818181818182, "train_stats/max_log_achievement_collect_drink": 2.5454545454545454, "train_stats/max_log_achievement_collect_sapling": 1.7272727272727273, "train_stats/max_log_achievement_collect_stone": 1.3636363636363635, "train_stats/max_log_achievement_collect_wood": 5.0, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.18181818181818182, "train_stats/max_log_achievement_eat_cow": 0.2727272727272727, "train_stats/max_log_achievement_make_wood_pickaxe": 1.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 1.6363636363636365, "train_stats/max_log_achievement_place_stone": 0.09090909090909091, "train_stats/max_log_achievement_place_table": 1.8181818181818181, "train_stats/max_log_achievement_wake_up": 2.090909090909091, "train_stats/mean_log_entropy": 0.5374609096483751, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 3.286366450083733e-07, "report/cont_loss_std": 1.0015020279752207e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 7.026002094789874e-06, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.891629833357001e-07, "report/cont_pred": 0.9941405057907104, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 3.3534350395202637, "report/dyn_loss_std": 8.502225875854492, "report/image_loss_mean": 2.4310483932495117, "report/image_loss_std": 6.226241588592529, "report/model_loss_mean": 4.476729393005371, "report/model_loss_std": 10.19992446899414, "report/post_ent_mag": 47.3248291015625, "report/post_ent_max": 47.3248291015625, "report/post_ent_mean": 31.371417999267578, "report/post_ent_min": 13.620636940002441, "report/post_ent_std": 5.9765143394470215, "report/prior_ent_mag": 77.28311157226562, "report/prior_ent_max": 77.28311157226562, "report/prior_ent_mean": 34.54743957519531, "report/prior_ent_min": 15.335128784179688, "report/prior_ent_std": 9.23900032043457, "report/rep_loss_mean": 3.3534350395202637, "report/rep_loss_std": 8.502225875854492, "report/reward_avg": 0.02021484449505806, "report/reward_loss_mean": 0.03361942619085312, "report/reward_loss_std": 0.14203278720378876, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0006213188171387, "report/reward_neg_acc": 0.9989989995956421, "report/reward_neg_loss": 0.01688750460743904, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7022269368171692, "report/reward_pred": 0.019580576568841934, "report/reward_rate": 0.0244140625, "eval/cont_avg": 0.9931640625, "eval/cont_loss_mean": 7.135607302188873e-05, "eval/cont_loss_std": 0.0022388759534806013, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.010401466861367226, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 2.5401803327440575e-07, "eval/cont_pred": 0.9932326078414917, "eval/cont_rate": 0.9931640625, "eval/dyn_loss_mean": 19.493438720703125, "eval/dyn_loss_std": 11.6646146774292, "eval/image_loss_mean": 19.95538330078125, "eval/image_loss_std": 20.147239685058594, "eval/model_loss_mean": 31.80047607421875, "eval/model_loss_std": 25.153156280517578, "eval/post_ent_mag": 48.41066360473633, "eval/post_ent_max": 48.41066360473633, "eval/post_ent_mean": 33.35095977783203, "eval/post_ent_min": 19.914281845092773, "eval/post_ent_std": 4.335274696350098, "eval/prior_ent_mag": 77.28311157226562, "eval/prior_ent_max": 77.28311157226562, "eval/prior_ent_mean": 43.69575500488281, "eval/prior_ent_min": 22.765159606933594, "eval/prior_ent_std": 8.186671257019043, "eval/rep_loss_mean": 19.493438720703125, "eval/rep_loss_std": 11.6646146774292, "eval/reward_avg": 0.02724609337747097, "eval/reward_loss_mean": 0.148957759141922, "eval/reward_loss_std": 0.9958842992782593, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0000569820404053, "eval/reward_neg_acc": 0.9959595203399658, "eval/reward_neg_loss": 0.047461457550525665, "eval/reward_pos_acc": 0.6764705777168274, "eval/reward_pos_loss": 3.1042912006378174, "eval/reward_pred": 0.018300501629710197, "eval/reward_rate": 0.033203125, "replay/size": 182683.0, "replay/inserts": 2182.0, "replay/samples": 34912.0, "replay/insert_wait_avg": 2.7144971405225103e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.904171397334168e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 35576.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 7.748603820800781e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2416396141052, "timer/env.step_count": 273.0, "timer/env.step_total": 23.653608322143555, "timer/env.step_frac": 0.02364789405414991, "timer/env.step_avg": 0.08664325392726577, "timer/env.step_min": 0.023738622665405273, "timer/env.step_max": 1.591686487197876, "timer/replay._sample_count": 34912.0, "timer/replay._sample_total": 17.787879467010498, "timer/replay._sample_frac": 0.017783582249058426, "timer/replay._sample_avg": 0.0005095061717177617, "timer/replay._sample_min": 0.00038743019104003906, "timer/replay._sample_max": 0.03746438026428223, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 273.0, "timer/agent.policy_total": 4.40508246421814, "timer/agent.policy_frac": 0.004404018278940704, "timer/agent.policy_avg": 0.01613583320226425, "timer/agent.policy_min": 0.009744882583618164, "timer/agent.policy_max": 0.033507347106933594, "timer/dataset_train_count": 2182.0, "timer/dataset_train_total": 0.44625353813171387, "timer/dataset_train_frac": 0.00044614573164928343, "timer/dataset_train_avg": 0.0002045158286579807, "timer/dataset_train_min": 9.965896606445312e-05, "timer/dataset_train_max": 0.039366722106933594, "timer/agent.train_count": 2182.0, "timer/agent.train_total": 969.9414391517639, "timer/agent.train_frac": 0.9697071194976135, "timer/agent.train_avg": 0.44451944965708706, "timer/agent.train_min": 0.43233728408813477, "timer/agent.train_max": 0.563481330871582, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4744749069213867, "timer/agent.report_frac": 0.0004743602826857317, "timer/agent.report_avg": 0.23723745346069336, "timer/agent.report_min": 0.23097848892211914, "timer/agent.report_max": 0.24349641799926758, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9087066650390625e-05, "timer/dataset_eval_frac": 2.908003976080466e-08, "timer/dataset_eval_avg": 2.9087066650390625e-05, "timer/dataset_eval_min": 2.9087066650390625e-05, "timer/dataset_eval_max": 2.9087066650390625e-05, "fps": 2.181444791286195}
{"step": 183232, "time": 84346.81817173958, "episode/length": 194.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 183232, "time": 84346.82714629173, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 183560, "time": 84497.47420835495, "episode/length": 142.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.972027972027972, "episode/intrinsic_return": 0.0}
{"step": 183720, "time": 84571.54569935799, "episode/length": 181.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 183976, "time": 84689.17148423195, "episode/length": 166.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 184176, "time": 84780.78656959534, "episode/length": 172.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 184208, "time": 84796.59375095367, "episode/length": 158.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9622641509433962, "episode/intrinsic_return": 0.0}
{"step": 184496, "time": 84928.06750679016, "episode/length": 257.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9961240310077519, "episode/intrinsic_return": 0.0}
{"step": 184584, "time": 84969.44880151749, "episode/length": 46.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 184736, "time": 85039.7630264759, "episode/length": 146.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9659863945578231, "episode/intrinsic_return": 0.0}
{"step": 184752, "time": 85048.55617189407, "episode/length": 189.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 184776, "time": 85060.88520550728, "episode/length": 192.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 185120, "time": 85218.28726887703, "episode/length": 174.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 185354, "time": 85326.68189692497, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.3451782789098505, "train/action_min": 0.0, "train/action_std": 4.08606460127413, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04592166834163226, "train/actor_opt_grad_steps": 182710.0, "train/actor_opt_loss": -13.99875789331401, "train/adv_mag": 0.5832233869809709, "train/adv_max": 0.5227310428146943, "train/adv_mean": 0.002355417561489572, "train/adv_min": -0.46424303516264886, "train/adv_std": 0.05122205637361048, "train/cont_avg": 0.9943251368087558, "train/cont_loss_mean": 3.91904238729255e-06, "train/cont_loss_std": 5.755377708011275e-05, "train/cont_neg_acc": 1.0, "train/cont_neg_loss": 0.0001248023648815207, "train/cont_pos_acc": 0.9999999804980194, "train/cont_pos_loss": 3.4006405781282252e-06, "train/cont_pred": 0.9943223936217171, "train/cont_rate": 0.9943251368087558, "train/dyn_loss_mean": 3.1216654711604668, "train/dyn_loss_std": 7.973813037169144, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1220051327608698, "train/extr_critic_critic_opt_grad_steps": 182710.0, "train/extr_critic_critic_opt_loss": 14956.197279125865, "train/extr_critic_mag": 10.367803797743838, "train/extr_critic_max": 10.367803797743838, "train/extr_critic_mean": 2.554828948139595, "train/extr_critic_min": -0.6705670873140959, "train/extr_critic_std": 2.3076404294660016, "train/extr_return_normed_mag": 1.613871841386716, "train/extr_return_normed_max": 1.613871841386716, "train/extr_return_normed_mean": 0.3985200671281683, "train/extr_return_normed_min": -0.12505058027494886, "train/extr_return_normed_std": 0.33685592407455095, "train/extr_return_rate": 0.8111172543692698, "train/extr_return_raw_mag": 11.038543235321749, "train/extr_return_raw_max": 11.038543235321749, "train/extr_return_raw_mean": 2.5712155147631597, "train/extr_return_raw_min": -1.072466766779324, "train/extr_return_raw_std": 2.3448220980332195, "train/extr_reward_mag": 1.0283711824548958, "train/extr_reward_max": 1.0283711824548958, "train/extr_reward_mean": 0.03799415005516896, "train/extr_reward_min": -0.6754989931660313, "train/extr_reward_std": 0.19431314950439788, "train/image_loss_mean": 1.599121161869594, "train/image_loss_std": 5.006364789426601, "train/model_loss_mean": 3.510082329473188, "train/model_loss_std": 8.861902166621476, "train/model_opt_grad_norm": 28.1683443702311, "train/model_opt_grad_steps": 182553.39170506914, "train/model_opt_loss": 7511.728731638825, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2148.6175115207375, "train/policy_entropy_mag": 2.543778708453552, "train/policy_entropy_max": 2.543778708453552, "train/policy_entropy_mean": 0.4875539099016497, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.5907572288117651, "train/policy_logprob_mag": 7.438384157171996, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.48834245257113934, "train/policy_logprob_min": -7.438384157171996, "train/policy_logprob_std": 1.0751529838632328, "train/policy_randomness_mag": 0.8978422520347454, "train/policy_randomness_max": 0.8978422520347454, "train/policy_randomness_mean": 0.17208513339406334, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.20851137691653818, "train/post_ent_mag": 48.38195064210672, "train/post_ent_max": 48.38195064210672, "train/post_ent_mean": 31.092268684492684, "train/post_ent_min": 14.239819772781864, "train/post_ent_std": 5.063835511009814, "train/prior_ent_mag": 77.80343427526236, "train/prior_ent_max": 77.80343427526236, "train/prior_ent_mean": 34.0938648012926, "train/prior_ent_min": 16.040924494167626, "train/prior_ent_std": 8.638571519456152, "train/rep_loss_mean": 3.1216654711604668, "train/rep_loss_std": 7.973813037169144, "train/reward_avg": 0.022161218153166882, "train/reward_loss_mean": 0.0379579640015067, "train/reward_loss_std": 0.16819874362050113, "train/reward_max_data": 1.0119815696769046, "train/reward_max_pred": 1.0122221263322961, "train/reward_neg_acc": 0.996024618225713, "train/reward_neg_loss": 0.019015548950327293, "train/reward_pos_acc": 0.9924221475552853, "train/reward_pos_loss": 0.7121188330210848, "train/reward_pred": 0.02207921495583887, "train/reward_rate": 0.027334749423963134, "train_stats/sum_log_reward": 4.176923018235427, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 3.769230769230769, "train_stats/max_log_achievement_collect_sapling": 1.3846153846153846, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 4.076923076923077, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.23076923076923078, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 1.2307692307692308, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 1.4615384615384615, "train_stats/max_log_achievement_wake_up": 1.6153846153846154, "train_stats/mean_log_entropy": 0.4726826365177448, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 4.304244612285402e-06, "report/cont_loss_std": 3.7648696888936684e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.9206408978789113e-06, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 4.313591489335522e-06, "report/cont_pred": 0.9960894584655762, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 3.543130874633789, "report/dyn_loss_std": 8.325446128845215, "report/image_loss_mean": 1.9560316801071167, "report/image_loss_std": 7.217866897583008, "report/model_loss_mean": 4.115279197692871, "report/model_loss_std": 11.19552230834961, "report/post_ent_mag": 43.78324508666992, "report/post_ent_max": 43.78324508666992, "report/post_ent_mean": 30.8892765045166, "report/post_ent_min": 17.14890480041504, "report/post_ent_std": 4.656575679779053, "report/prior_ent_mag": 77.94522094726562, "report/prior_ent_max": 77.94522094726562, "report/prior_ent_mean": 34.548545837402344, "report/prior_ent_min": 20.412307739257812, "report/prior_ent_std": 8.20622444152832, "report/rep_loss_mean": 3.543130874633789, "report/rep_loss_std": 8.325446128845215, "report/reward_avg": 0.02919922024011612, "report/reward_loss_mean": 0.033364735543727875, "report/reward_loss_std": 0.14158238470554352, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0009739398956299, "report/reward_neg_acc": 0.9979797005653381, "report/reward_neg_loss": 0.011275885626673698, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.676539957523346, "report/reward_pred": 0.029230015352368355, "report/reward_rate": 0.033203125, "eval/cont_avg": 0.9931640625, "eval/cont_loss_mean": 1.2621158930414822e-05, "eval/cont_loss_std": 0.00023238315770868212, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 6.287032010732219e-05, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 1.2275291737751104e-05, "eval/cont_pred": 0.993152379989624, "eval/cont_rate": 0.9931640625, "eval/dyn_loss_mean": 21.295095443725586, "eval/dyn_loss_std": 13.37729263305664, "eval/image_loss_mean": 37.1138916015625, "eval/image_loss_std": 50.049896240234375, "eval/model_loss_mean": 50.030235290527344, "eval/model_loss_std": 55.69057846069336, "eval/post_ent_mag": 50.200565338134766, "eval/post_ent_max": 50.200565338134766, "eval/post_ent_mean": 32.1614990234375, "eval/post_ent_min": 17.27998161315918, "eval/post_ent_std": 4.377833843231201, "eval/prior_ent_mag": 77.94522094726562, "eval/prior_ent_max": 77.94522094726562, "eval/prior_ent_mean": 43.05113983154297, "eval/prior_ent_min": 18.124204635620117, "eval/prior_ent_std": 8.956291198730469, "eval/rep_loss_mean": 21.295095443725586, "eval/rep_loss_std": 13.37729263305664, "eval/reward_avg": 0.0341796875, "eval/reward_loss_mean": 0.13927951455116272, "eval/reward_loss_std": 0.8890899419784546, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.000053882598877, "eval/reward_neg_acc": 0.9959350228309631, "eval/reward_neg_loss": 0.05427027493715286, "eval/reward_pos_acc": 0.824999988079071, "eval/reward_pos_loss": 2.2305068969726562, "eval/reward_pred": 0.027353372424840927, "eval/reward_rate": 0.0390625, "replay/size": 184850.0, "replay/inserts": 2167.0, "replay/samples": 34672.0, "replay/insert_wait_avg": 2.712492685357601e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.705282493841279e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 35576.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 7.599592208862305e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2892889976501, "timer/env.step_count": 271.0, "timer/env.step_total": 26.98097801208496, "timer/env.step_frac": 0.02697317496933464, "timer/env.step_avg": 0.09956080447263824, "timer/env.step_min": 0.023794174194335938, "timer/env.step_max": 3.1853349208831787, "timer/replay._sample_count": 34672.0, "timer/replay._sample_total": 17.526005268096924, "timer/replay._sample_frac": 0.017520936653894426, "timer/replay._sample_avg": 0.0005054800781061642, "timer/replay._sample_min": 0.00034332275390625, "timer/replay._sample_max": 0.03760576248168945, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 271.0, "timer/agent.policy_total": 4.362724304199219, "timer/agent.policy_frac": 0.004361462581060855, "timer/agent.policy_avg": 0.016098613668631804, "timer/agent.policy_min": 0.009653329849243164, "timer/agent.policy_max": 0.04177594184875488, "timer/dataset_train_count": 2167.0, "timer/dataset_train_total": 0.402057409286499, "timer/dataset_train_frac": 0.00040194113213926807, "timer/dataset_train_avg": 0.00018553641406852747, "timer/dataset_train_min": 9.608268737792969e-05, "timer/dataset_train_max": 0.0005826950073242188, "timer/agent.train_count": 2167.0, "timer/agent.train_total": 966.7246487140656, "timer/agent.train_frac": 0.9664450667894101, "timer/agent.train_avg": 0.4461119744873399, "timer/agent.train_min": 0.43340325355529785, "timer/agent.train_max": 0.5886275768280029, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47530579566955566, "timer/agent.report_frac": 0.0004751683346982957, "timer/agent.report_avg": 0.23765289783477783, "timer/agent.report_min": 0.23094964027404785, "timer/agent.report_max": 0.2443561553955078, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 4.029273986816406e-05, "timer/dataset_eval_frac": 4.028108699288363e-08, "timer/dataset_eval_avg": 4.029273986816406e-05, "timer/dataset_eval_min": 4.029273986816406e-05, "timer/dataset_eval_max": 4.029273986816406e-05, "fps": 2.1663428497711066}
{"step": 185408, "time": 85351.6799788475, "episode/length": 178.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 185720, "time": 85495.95624566078, "episode/length": 152.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 185824, "time": 85544.82365703583, "episode/length": 205.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 186000, "time": 85626.82281255722, "episode/length": 176.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 186072, "time": 85661.24102497101, "episode/length": 161.0, "episode/score": 3.1000000163912773, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 186128, "time": 85688.30156040192, "episode/length": 171.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 186160, "time": 85704.47548866272, "episode/length": 177.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 186488, "time": 85855.83941149712, "episode/length": 134.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9925925925925926, "episode/intrinsic_return": 0.0}
{"step": 186544, "time": 85882.8250901699, "episode/length": 177.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 186784, "time": 85993.62248969078, "episode/length": 132.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9624060150375939, "episode/intrinsic_return": 0.0}
{"step": 187120, "time": 86148.48333930969, "episode/length": 130.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9923664122137404, "episode/intrinsic_return": 0.0}
{"step": 187368, "time": 86262.92861104012, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 187400, "time": 86278.95227074623, "episode/length": 158.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9622641509433962, "episode/intrinsic_return": 0.0}
{"step": 187472, "time": 86313.25241160393, "episode/length": 163.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 187498, "time": 86327.05920529366, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.300208831501898, "train/action_min": 0.0, "train/action_std": 4.024690643649235, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0497207079674596, "train/actor_opt_grad_steps": 184865.0, "train/actor_opt_loss": -12.43684469633431, "train/adv_mag": 0.6797486629998573, "train/adv_max": 0.5927348884745179, "train/adv_mean": 0.002106369910949053, "train/adv_min": -0.5501856670897698, "train/adv_std": 0.055142328352014595, "train/cont_avg": 0.9944144275700935, "train/cont_loss_mean": 4.746010096441772e-06, "train/cont_loss_std": 0.00010948031332144803, "train/cont_neg_acc": 1.0, "train/cont_neg_loss": 0.00046575055949012504, "train/cont_pos_acc": 0.9999999824528382, "train/cont_pos_loss": 2.449275262780281e-06, "train/cont_pred": 0.994414361559342, "train/cont_rate": 0.9944144275700935, "train/dyn_loss_mean": 3.1684952406125646, "train/dyn_loss_std": 8.016916357468222, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1681311222437387, "train/extr_critic_critic_opt_grad_steps": 184865.0, "train/extr_critic_critic_opt_loss": 15312.408668589369, "train/extr_critic_mag": 10.451787819372159, "train/extr_critic_max": 10.451787819372159, "train/extr_critic_mean": 2.319476233464535, "train/extr_critic_min": -0.678075370944549, "train/extr_critic_std": 2.0837774627676633, "train/extr_return_normed_mag": 1.6832371794174765, "train/extr_return_normed_max": 1.6832371794174765, "train/extr_return_normed_mean": 0.3846061088353674, "train/extr_return_normed_min": -0.13494986793565972, "train/extr_return_normed_std": 0.32155906966077946, "train/extr_return_rate": 0.8196681952365091, "train/extr_return_raw_mag": 10.868828742303581, "train/extr_return_raw_max": 10.868828742303581, "train/extr_return_raw_mean": 2.333159340876285, "train/extr_return_raw_min": -1.0846204963799948, "train/extr_return_raw_std": 2.1159776983974137, "train/extr_reward_mag": 1.0281768836707712, "train/extr_reward_max": 1.0281768836707712, "train/extr_reward_mean": 0.03635493753843497, "train/extr_reward_min": -0.678831419098043, "train/extr_reward_std": 0.18992033670438785, "train/image_loss_mean": 1.6229250188742843, "train/image_loss_std": 5.06096302014645, "train/model_loss_mean": 3.561698324212404, "train/model_loss_std": 8.948453631356498, "train/model_opt_grad_norm": 28.82004768603316, "train/model_opt_grad_steps": 184706.78504672897, "train/model_opt_loss": 8372.910563531323, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2353.9719626168226, "train/policy_entropy_mag": 2.555409985167958, "train/policy_entropy_max": 2.555409985167958, "train/policy_entropy_mean": 0.4945769305819663, "train/policy_entropy_min": 0.0793750137090683, "train/policy_entropy_std": 0.5949459680329974, "train/policy_logprob_mag": 7.438384122937639, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.49290249406177306, "train/policy_logprob_min": -7.438384122937639, "train/policy_logprob_std": 1.0744754471511484, "train/policy_randomness_mag": 0.9019475827150256, "train/policy_randomness_max": 0.9019475827150256, "train/policy_randomness_mean": 0.17456395206885916, "train/policy_randomness_min": 0.028015896677970886, "train/policy_randomness_std": 0.20998981880528905, "train/post_ent_mag": 48.778905262456874, "train/post_ent_max": 48.778905262456874, "train/post_ent_mean": 31.268618503463603, "train/post_ent_min": 14.235840494387618, "train/post_ent_std": 5.095879975880418, "train/prior_ent_mag": 77.86768469409408, "train/prior_ent_max": 77.86768469409408, "train/prior_ent_mean": 34.287840477774076, "train/prior_ent_min": 16.145426950722097, "train/prior_ent_std": 8.660534649251778, "train/rep_loss_mean": 3.1684952406125646, "train/rep_loss_std": 8.016916357468222, "train/reward_avg": 0.02179559709277944, "train/reward_loss_mean": 0.0376714039768014, "train/reward_loss_std": 0.1716762949303489, "train/reward_max_data": 1.013551405100065, "train/reward_max_pred": 1.013673709374722, "train/reward_neg_acc": 0.9960742392272592, "train/reward_neg_loss": 0.018705991444952576, "train/reward_pos_acc": 0.9897349741414329, "train/reward_pos_loss": 0.7234567005500615, "train/reward_pred": 0.021610297891528945, "train/reward_rate": 0.02691935601635514, "train_stats/sum_log_reward": 5.457142863954816, "train_stats/max_log_achievement_collect_coal": 0.07142857142857142, "train_stats/max_log_achievement_collect_drink": 1.7857142857142858, "train_stats/max_log_achievement_collect_sapling": 1.9285714285714286, "train_stats/max_log_achievement_collect_stone": 0.7142857142857143, "train_stats/max_log_achievement_collect_wood": 5.714285714285714, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.07142857142857142, "train_stats/max_log_achievement_make_wood_pickaxe": 0.7857142857142857, "train_stats/max_log_achievement_make_wood_sword": 0.07142857142857142, "train_stats/max_log_achievement_place_furnace": 0.07142857142857142, "train_stats/max_log_achievement_place_plant": 1.6428571428571428, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 2.0, "train_stats/max_log_achievement_wake_up": 1.5714285714285714, "train_stats/mean_log_entropy": 0.45211905453886303, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 3.8053781281632837e-07, "report/cont_loss_std": 5.472502380143851e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 7.35810972400941e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.135945109671411e-08, "report/cont_pred": 0.9951175451278687, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 3.392338752746582, "report/dyn_loss_std": 7.987992763519287, "report/image_loss_mean": 1.3925127983093262, "report/image_loss_std": 5.925765514373779, "report/model_loss_mean": 3.4597511291503906, "report/model_loss_std": 9.441934585571289, "report/post_ent_mag": 45.33997344970703, "report/post_ent_max": 45.33997344970703, "report/post_ent_mean": 30.988513946533203, "report/post_ent_min": 11.39967155456543, "report/post_ent_std": 4.916444301605225, "report/prior_ent_mag": 77.93898010253906, "report/prior_ent_max": 77.93898010253906, "report/prior_ent_mean": 34.29803466796875, "report/prior_ent_min": 12.995378494262695, "report/prior_ent_std": 8.483449935913086, "report/rep_loss_mean": 3.392338752746582, "report/rep_loss_std": 7.987992763519287, "report/reward_avg": 0.02558593824505806, "report/reward_loss_mean": 0.03183506429195404, "report/reward_loss_std": 0.13557153940200806, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0023975372314453, "report/reward_neg_acc": 0.998992919921875, "report/reward_neg_loss": 0.011796356178820133, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6737200617790222, "report/reward_pred": 0.025917939841747284, "report/reward_rate": 0.0302734375, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 6.530581595143303e-05, "eval/cont_loss_std": 0.0020105435978621244, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.011141138151288033, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.586543423888088e-08, "eval/cont_pred": 0.9942039251327515, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 20.530574798583984, "eval/dyn_loss_std": 12.623367309570312, "eval/image_loss_mean": 31.754390716552734, "eval/image_loss_std": 38.11479568481445, "eval/model_loss_mean": 44.23411560058594, "eval/model_loss_std": 42.92264938354492, "eval/post_ent_mag": 50.857765197753906, "eval/post_ent_max": 50.857765197753906, "eval/post_ent_mean": 33.251102447509766, "eval/post_ent_min": 14.780390739440918, "eval/post_ent_std": 5.397729873657227, "eval/prior_ent_mag": 77.93898010253906, "eval/prior_ent_max": 77.93898010253906, "eval/prior_ent_mean": 43.02305603027344, "eval/prior_ent_min": 16.190027236938477, "eval/prior_ent_std": 9.741999626159668, "eval/rep_loss_mean": 20.530574798583984, "eval/rep_loss_std": 12.623367309570312, "eval/reward_avg": 0.02695312350988388, "eval/reward_loss_mean": 0.16131606698036194, "eval/reward_loss_std": 0.8966836333274841, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0017566680908203, "eval/reward_neg_acc": 0.9969727396965027, "eval/reward_neg_loss": 0.10210944712162018, "eval/reward_pos_acc": 0.7878787517547607, "eval/reward_pos_loss": 1.9393082857131958, "eval/reward_pred": 0.02126605249941349, "eval/reward_rate": 0.0322265625, "replay/size": 186994.0, "replay/inserts": 2144.0, "replay/samples": 34304.0, "replay/insert_wait_avg": 2.7153474181445677e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.406030017048565e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 35576.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 7.450580596923828e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3667283058167, "timer/env.step_count": 268.0, "timer/env.step_total": 28.200643301010132, "timer/env.step_frac": 0.02819030511817369, "timer/env.step_avg": 0.1052262809739184, "timer/env.step_min": 0.02385234832763672, "timer/env.step_max": 1.7293124198913574, "timer/replay._sample_count": 34304.0, "timer/replay._sample_total": 17.72540807723999, "timer/replay._sample_frac": 0.017718910051375932, "timer/replay._sample_avg": 0.000516715487326259, "timer/replay._sample_min": 0.00037479400634765625, "timer/replay._sample_max": 0.01108860969543457, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 268.0, "timer/agent.policy_total": 4.395423173904419, "timer/agent.policy_frac": 0.004393811838732723, "timer/agent.policy_avg": 0.016400832738449323, "timer/agent.policy_min": 0.009821414947509766, "timer/agent.policy_max": 0.019161701202392578, "timer/dataset_train_count": 2144.0, "timer/dataset_train_total": 0.45680689811706543, "timer/dataset_train_frac": 0.0004566394355105116, "timer/dataset_train_avg": 0.000213062918897885, "timer/dataset_train_min": 9.393692016601562e-05, "timer/dataset_train_max": 0.06179666519165039, "timer/agent.train_count": 2144.0, "timer/agent.train_total": 965.3385026454926, "timer/agent.train_frac": 0.9649846154723213, "timer/agent.train_avg": 0.45025116727868125, "timer/agent.train_min": 0.44033145904541016, "timer/agent.train_max": 0.5825121402740479, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4792029857635498, "timer/agent.report_frac": 0.00047902731288865426, "timer/agent.report_avg": 0.2396014928817749, "timer/agent.report_min": 0.23189473152160645, "timer/agent.report_max": 0.24730825424194336, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0517578125e-05, "timer/dataset_eval_frac": 3.050639056807039e-08, "timer/dataset_eval_avg": 3.0517578125e-05, "timer/dataset_eval_min": 3.0517578125e-05, "timer/dataset_eval_max": 3.0517578125e-05, "fps": 2.143186605175045}
