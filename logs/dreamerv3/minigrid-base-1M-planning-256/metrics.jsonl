{"step": 1560, "time": 112.41716241836548, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 1560, "time": 137.64716958999634, "eval_episode/length": 248.0, "eval_episode/score": 0.22499999403953552, "eval_episode/reward_rate": 0.004016064257028112}
{"step": 1560, "time": 138.37951970100403, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 138.38679122924805, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 138.3926112651825, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 138.39834332466125, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 138.4038209915161, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 138.4093954563141, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 138.4150550365448, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1561, "time": 255.5699622631073, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.8477783203125, "train/action_min": 0.0, "train/action_std": 1.8604637384414673, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0009735355852171779, "train/actor_opt_grad_steps": 1.0, "train/actor_opt_loss": -1.876652717590332, "train/adv_mag": 0.0, "train/adv_max": 0.0, "train/adv_mean": 0.0, "train/adv_min": 0.0, "train/adv_std": 0.0, "train/cont_avg": 1.0, "train/cont_loss_mean": 0.6058731079101562, "train/cont_loss_std": 0.25267910957336426, "train/cont_neg_acc": NaN, "train/cont_neg_loss": NaN, "train/cont_pos_acc": 0.6865234375, "train/cont_pos_loss": 0.6058731079101562, "train/cont_pred": 0.5622031688690186, "train/cont_rate": 1.0, "train/dyn_loss_mean": 10.959893226623535, "train/dyn_loss_std": 0.37231549620628357, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 10.561108589172363, "train/extr_critic_critic_opt_grad_steps": 1.0, "train/extr_critic_critic_opt_loss": 41942.328125, "train/extr_critic_mag": 0.0, "train/extr_critic_max": 0.0, "train/extr_critic_mean": 0.0, "train/extr_critic_min": 0.0, "train/extr_critic_std": 0.0, "train/extr_return_normed_mag": 0.0, "train/extr_return_normed_max": 0.0, "train/extr_return_normed_mean": 0.0, "train/extr_return_normed_min": 0.0, "train/extr_return_normed_std": 0.0, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.0, "train/extr_return_raw_max": 0.0, "train/extr_return_raw_mean": 0.0, "train/extr_return_raw_min": 0.0, "train/extr_return_raw_std": 0.0, "train/extr_reward_mag": 0.0, "train/extr_reward_max": 0.0, "train/extr_reward_mean": 0.0, "train/extr_reward_min": 0.0, "train/extr_reward_std": 0.0, "train/image_loss_mean": 5009.8857421875, "train/image_loss_std": 40.452640533447266, "train/model_loss_mean": 5022.60888671875, "train/model_loss_std": 40.44712448120117, "train/model_opt_grad_norm": NaN, "train/model_opt_grad_steps": 0.0, "train/model_opt_loss": 50226088.0, "train/model_opt_model_opt_grad_overflow": 1.0, "train/model_opt_model_opt_grad_scale": 5000.0, "train/policy_entropy_mag": 1.9281190633773804, "train/policy_entropy_max": 1.9281190633773804, "train/policy_entropy_mean": 1.6448346376419067, "train/policy_entropy_min": 0.7513943314552307, "train/policy_entropy_std": 0.13966503739356995, "train/policy_logprob_mag": 4.666419506072998, "train/policy_logprob_max": -0.18753115832805634, "train/policy_logprob_mean": -1.6623716354370117, "train/policy_logprob_min": -4.666419506072998, "train/policy_logprob_std": 0.7254135012626648, "train/policy_randomness_mag": 0.9908572435379028, "train/policy_randomness_max": 0.9908572435379028, "train/policy_randomness_mean": 0.8452778458595276, "train/policy_randomness_min": 0.3861403167247772, "train/policy_randomness_std": 0.07177364081144333, "train/post_ent_mag": 105.59013366699219, "train/post_ent_max": 105.59013366699219, "train/post_ent_mean": 105.30010986328125, "train/post_ent_min": 104.98181915283203, "train/post_ent_std": 0.10508428514003754, "train/prior_ent_mag": 106.34150695800781, "train/prior_ent_max": 106.34150695800781, "train/prior_ent_mean": 105.59564208984375, "train/prior_ent_min": 104.84276580810547, "train/prior_ent_std": 0.2704421877861023, "train/rep_loss_mean": 10.959893226623535, "train/rep_loss_std": 0.37231549620628357, "train/reward_avg": 0.0, "train/reward_loss_mean": 5.541262626647949, "train/reward_loss_std": 9.5367431640625e-07, "train/reward_max_data": 0.0, "train/reward_max_pred": 0.0, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 5.541262626647949, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0, "train/reward_rate": 0.0, "train/params_agent/wm/model_opt": 181559683.0, "train/params_agent/task_behavior/critic/critic_opt": 9708799.0, "train/params_agent/task_behavior/ac/actor_opt": 9454599.0, "report/cont_avg": 1.0, "report/cont_loss_mean": 0.6169277429580688, "report/cont_loss_std": 0.2541811168193817, "report/cont_neg_acc": NaN, "report/cont_neg_loss": NaN, "report/cont_pos_acc": 0.6640625, "report/cont_pos_loss": 0.6169277429580688, "report/cont_pred": 0.5561898350715637, "report/cont_rate": 1.0, "report/dyn_loss_mean": 10.982178688049316, "report/dyn_loss_std": 0.36208435893058777, "report/image_loss_mean": 5010.4814453125, "report/image_loss_std": 40.743492126464844, "report/model_loss_mean": 5023.22900390625, "report/model_loss_std": 40.76059341430664, "report/post_ent_mag": 105.64698791503906, "report/post_ent_max": 105.64698791503906, "report/post_ent_mean": 105.31442260742188, "report/post_ent_min": 104.98839569091797, "report/post_ent_std": 0.10418285429477692, "report/prior_ent_mag": 106.36053466796875, "report/prior_ent_max": 106.36053466796875, "report/prior_ent_mean": 105.56534576416016, "report/prior_ent_min": 104.44042205810547, "report/prior_ent_std": 0.29569822549819946, "report/rep_loss_mean": 10.982178688049316, "report/rep_loss_std": 0.36208435893058777, "report/reward_avg": 0.0, "report/reward_loss_mean": 5.541262626647949, "report/reward_loss_std": 9.5367431640625e-07, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.0, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 5.541262626647949, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.6399570107460022, "eval/cont_loss_std": 0.2720051109790802, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 0.6201171875, "eval/cont_pos_loss": 0.6399570107460022, "eval/cont_pred": 0.545677661895752, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 11.018305778503418, "eval/dyn_loss_std": 0.36838623881340027, "eval/image_loss_mean": 4999.6923828125, "eval/image_loss_std": 38.903350830078125, "eval/model_loss_mean": 5012.484375, "eval/model_loss_std": 38.924522399902344, "eval/post_ent_mag": 105.61581420898438, "eval/post_ent_max": 105.61581420898438, "eval/post_ent_mean": 105.28802490234375, "eval/post_ent_min": 104.86507415771484, "eval/post_ent_std": 0.11441554874181747, "eval/prior_ent_mag": 106.41375732421875, "eval/prior_ent_max": 106.41375732421875, "eval/prior_ent_mean": 105.58525848388672, "eval/prior_ent_min": 104.7955322265625, "eval/prior_ent_std": 0.26616087555885315, "eval/rep_loss_mean": 11.018305778503418, "eval/rep_loss_std": 0.36838623881340027, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 5.541262626647949, "eval/reward_loss_std": 9.5367431640625e-07, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 5.541262626647949, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0, "eval/reward_rate": 0.0, "replay/size": 1057.0, "replay/inserts": 1057.0, "replay/samples": 112.0, "replay/insert_wait_avg": 1.4440451687873256e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.706029074532645e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 3368.0, "eval_replay/inserts": 3368.0, "eval_replay/samples": 112.0, "eval_replay/insert_wait_avg": 1.2432028165622449e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 145.20135140419006, "timer/env.step_count": 196.0, "timer/env.step_total": 1.3454031944274902, "timer/env.step_frac": 0.009265775982224543, "timer/env.step_avg": 0.006864302012385155, "timer/env.step_min": 0.006261110305786133, "timer/env.step_max": 0.01711130142211914, "timer/replay._sample_count": 112.0, "timer/replay._sample_total": 0.09654521942138672, "timer/replay._sample_frac": 0.0006649057910806794, "timer/replay._sample_avg": 0.0008620108876909528, "timer/replay._sample_min": 0.000370025634765625, "timer/replay._sample_max": 0.006886720657348633, "timer/agent.save_count": 1.0, "timer/agent.save_total": 2.1836109161376953, "timer/agent.save_frac": 0.015038502706901687, "timer/agent.save_avg": 2.1836109161376953, "timer/agent.save_min": 2.1836109161376953, "timer/agent.save_max": 2.1836109161376953, "timer/agent.policy_count": 290.0, "timer/agent.policy_total": 24.153650522232056, "timer/agent.policy_frac": 0.16634590717407782, "timer/agent.policy_avg": 0.08328845007666226, "timer/agent.policy_min": 0.009032487869262695, "timer/agent.policy_max": 19.091557025909424, "timer/dataset_train_count": 1.0, "timer/dataset_train_total": 3.123283386230469e-05, "timer/dataset_train_frac": 2.151001596077666e-07, "timer/dataset_train_avg": 3.123283386230469e-05, "timer/dataset_train_min": 3.123283386230469e-05, "timer/dataset_train_max": 3.123283386230469e-05, "timer/agent.train_count": 1.0, "timer/agent.train_total": 91.22046232223511, "timer/agent.train_frac": 0.628234251541565, "timer/agent.train_avg": 91.22046232223511, "timer/agent.train_min": 91.22046232223511, "timer/agent.train_max": 91.22046232223511, "timer/agent.report_count": 2.0, "timer/agent.report_total": 23.57001566886902, "timer/agent.report_frac": 0.1623264208007148, "timer/agent.report_avg": 11.78500783443451, "timer/agent.report_min": 0.2480156421661377, "timer/agent.report_max": 23.32200002670288, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.6716461181640625e-05, "timer/dataset_eval_frac": 2.528658364854661e-07, "timer/dataset_eval_avg": 3.6716461181640625e-05, "timer/dataset_eval_min": 3.6716461181640625e-05, "timer/dataset_eval_max": 3.6716461181640625e-05}
{"step": 1808, "time": 283.7515015602112, "episode/length": 225.0, "episode/score": 0.296875, "episode/reward_rate": 0.004424778761061947, "episode/intrinsic_return": 0.0}
{"step": 2312, "time": 341.5061764717102, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 2312, "time": 341.513710975647, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 2312, "time": 341.5209951400757, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 2312, "time": 341.52741742134094, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 2312, "time": 341.53387093544006, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 2312, "time": 341.5397696495056, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 2312, "time": 341.5467026233673, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 3160, "time": 438.72220730781555, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 3672, "time": 497.4383361339569, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 4120, "time": 548.8008282184601, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4624, "time": 606.3923547267914, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4624, "time": 606.4000065326691, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4624, "time": 606.4074325561523, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4624, "time": 606.4211716651917, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4624, "time": 606.4279310703278, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 5472, "time": 703.7423131465912, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 5984, "time": 762.4065320491791, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 6432, "time": 813.8434088230133, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 6936, "time": 871.4903440475464, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 6936, "time": 871.5252504348755, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 6936, "time": 871.5322685241699, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 6936, "time": 871.5412812232971, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 6936, "time": 871.5485479831696, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 7184, "time": 899.9594914913177, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 7784, "time": 968.6542146205902, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 8296, "time": 1027.8876857757568, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 9248, "time": 1136.797280073166, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 9248, "time": 1136.805758714676, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 9248, "time": 1136.8149633407593, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 9248, "time": 1136.8207955360413, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 9248, "time": 1136.827533006668, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 9496, "time": 1165.1802673339844, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 10077, "time": 1232.5841295719147, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.002242540529636, "train/action_min": 0.0, "train/action_std": 1.9987689989833204, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0004522584887968044, "train/actor_opt_grad_steps": 1070.0, "train/actor_opt_loss": 9.890103971174625, "train/adv_mag": 0.001391545395625746, "train/adv_max": 0.0013915378534890823, "train/adv_mean": 0.0008157898247745178, "train/adv_min": 9.825227987117217e-05, "train/adv_std": 0.00037914858232029604, "train/cont_avg": 0.9971161605046949, "train/cont_loss_mean": 0.02236335439501781, "train/cont_loss_std": 0.2918694607979553, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.886146618769719, "train/cont_pos_acc": 0.9987896012028618, "train/cont_pos_loss": 0.005518797975609276, "train/cont_pred": 0.9951985025070083, "train/cont_rate": 0.9971161605046949, "train/dyn_loss_mean": 1.0632947174036447, "train/dyn_loss_std": 0.00424339295993501, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 3.977380826299739, "train/extr_critic_critic_opt_grad_steps": 1070.0, "train/extr_critic_critic_opt_loss": 9415.31387429394, "train/extr_critic_mag": 0.012791303401821656, "train/extr_critic_max": 0.012791296126137316, "train/extr_critic_mean": 0.012759093530932944, "train/extr_critic_min": 0.012729799803433844, "train/extr_critic_std": 8.186096917628341e-06, "train/extr_return_normed_mag": 0.0025390681892772694, "train/extr_return_normed_max": 0.0025390621326245124, "train/extr_return_normed_mean": 0.0019842114595200154, "train/extr_return_normed_min": 0.0012783491224155341, "train/extr_return_normed_std": 0.0003789496852630785, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.014129748774609534, "train/extr_return_raw_max": 0.01412973691695447, "train/extr_return_raw_mean": 0.013574886832835299, "train/extr_return_raw_min": 0.012869023907870872, "train/extr_return_raw_std": 0.0003789496839671803, "train/extr_reward_mag": 0.00016747394078214404, "train/extr_reward_max": 0.00016747226177806586, "train/extr_reward_mean": 0.00016725570052728586, "train/extr_reward_min": 0.00016660981334990738, "train/extr_reward_std": 9.162850521727864e-08, "train/image_loss_mean": 24.62676127779652, "train/image_loss_std": 0.361373476893969, "train/model_loss_mean": 25.390042777912157, "train/model_loss_std": 0.6988768465991871, "train/model_opt_grad_norm": 102.9387979912308, "train/model_opt_grad_steps": 1060.0, "train/model_opt_loss": 483.700676465818, "train/model_opt_model_opt_grad_overflow": 0.004694835680751174, "train/model_opt_model_opt_grad_scale": 16.000953638497652, "train/policy_entropy_mag": 1.9457961942108584, "train/policy_entropy_max": 1.9457961942108584, "train/policy_entropy_mean": 1.9413846266661452, "train/policy_entropy_min": 1.8949980931662618, "train/policy_entropy_std": 0.002734278066372368, "train/policy_logprob_mag": 2.3259455653983103, "train/policy_logprob_max": -1.553754811835401, "train/policy_logprob_mean": -1.9412618164725146, "train/policy_logprob_min": -2.3259455653983103, "train/policy_logprob_std": 0.08359342136643302, "train/policy_randomness_mag": 0.999941497901236, "train/policy_randomness_max": 0.999941497901236, "train/policy_randomness_mean": 0.9976743999781184, "train/policy_randomness_min": 0.9738364362380874, "train/policy_randomness_std": 0.001405141048817655, "train/post_ent_mag": 77.93065568091164, "train/post_ent_max": 77.93065568091164, "train/post_ent_mean": 77.87324523925781, "train/post_ent_min": 77.7990414256781, "train/post_ent_std": 0.018386899259710956, "train/prior_ent_mag": 83.02544173836148, "train/prior_ent_max": 83.02544173836148, "train/prior_ent_mean": 82.90236312794573, "train/prior_ent_min": 82.68923785429045, "train/prior_ent_std": 0.04770992189086099, "train/rep_loss_mean": 1.0632947174036447, "train/rep_loss_std": 0.00424339295993501, "train/reward_avg": 0.0002820941782447164, "train/reward_loss_mean": 0.10294181081147191, "train/reward_loss_std": 0.14468294674204418, "train/reward_max_data": 0.23237969729822006, "train/reward_max_pred": 0.00016750640152765552, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.09770806670651286, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 8.756801879051888, "train/reward_pred": 0.00016714091371185203, "train/reward_rate": 0.0006006088615023474, "train_stats/mean_log_entropy": 1.9201519922776655, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.025716956704854965, "report/cont_loss_std": 0.364276647567749, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.842748641967773, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.002905073342844844, "report/cont_pred": 0.997098982334137, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.25981420278549194, "report/image_loss_std": 0.07265419512987137, "report/model_loss_mean": 0.8949511051177979, "report/model_loss_std": 0.5715693831443787, "report/post_ent_mag": 62.526275634765625, "report/post_ent_max": 62.526275634765625, "report/post_ent_mean": 62.4051399230957, "report/post_ent_min": 62.38096237182617, "report/post_ent_std": 0.01790565438568592, "report/prior_ent_mag": 71.51229095458984, "report/prior_ent_max": 71.51229095458984, "report/prior_ent_mean": 71.39144134521484, "report/prior_ent_min": 71.29216003417969, "report/prior_ent_std": 0.031759653240442276, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0004608154413290322, "report/reward_loss_mean": 0.009419922716915607, "report/reward_loss_std": 0.27885571122169495, "report/reward_max_data": 0.47187501192092896, "report/reward_max_pred": 0.0001531839370727539, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0007014223374426365, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 8.928444862365723, "report/reward_pred": 0.0001530477311462164, "report/reward_rate": 0.0009765625, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.0029050735756754875, "eval/cont_loss_std": 2.3283064365386963e-10, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0029050735756754875, "eval/cont_pred": 0.997098982334137, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2631489038467407, "eval/image_loss_std": 0.07774728536605835, "eval/model_loss_mean": 0.8667554259300232, "eval/model_loss_std": 0.07774730026721954, "eval/post_ent_mag": 62.52700424194336, "eval/post_ent_max": 62.52700424194336, "eval/post_ent_mean": 62.4044303894043, "eval/post_ent_min": 62.37914276123047, "eval/post_ent_std": 0.016122164204716682, "eval/prior_ent_mag": 71.51123046875, "eval/prior_ent_max": 71.51123046875, "eval/prior_ent_mean": 71.3878402709961, "eval/prior_ent_min": 71.29216003417969, "eval/prior_ent_std": 0.027387307956814766, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.000701426062732935, "eval/reward_loss_std": 8.814537721946181e-08, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0001531839370727539, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.000701426062732935, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00015305052511394024, "eval/reward_rate": 0.0, "replay/size": 9573.0, "replay/inserts": 8516.0, "replay/samples": 34064.0, "replay/insert_wait_avg": 1.6378818850609102e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.577964877679125e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 3368.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 9.238719940185547e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 977.0032324790955, "timer/env.step_count": 1064.0, "timer/env.step_total": 11.09454083442688, "timer/env.step_frac": 0.011355684879644721, "timer/env.step_avg": 0.01042720003235609, "timer/env.step_min": 0.009346723556518555, "timer/env.step_max": 0.03664875030517578, "timer/replay._sample_count": 34064.0, "timer/replay._sample_total": 18.48689317703247, "timer/replay._sample_frac": 0.01892203890679351, "timer/replay._sample_avg": 0.0005427105794103003, "timer/replay._sample_min": 0.0003199577331542969, "timer/replay._sample_max": 0.028357982635498047, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1064.0, "timer/agent.policy_total": 11.478070259094238, "timer/agent.policy_frac": 0.01174824184559679, "timer/agent.policy_avg": 0.010787660017945712, "timer/agent.policy_min": 0.009835958480834961, "timer/agent.policy_max": 0.04035449028015137, "timer/dataset_train_count": 2129.0, "timer/dataset_train_total": 0.3849802017211914, "timer/dataset_train_frac": 0.00039404189149336175, "timer/dataset_train_avg": 0.0001808267739413769, "timer/dataset_train_min": 8.630752563476562e-05, "timer/dataset_train_max": 0.0008137226104736328, "timer/agent.train_count": 2129.0, "timer/agent.train_total": 951.4768486022949, "timer/agent.train_frac": 0.9738727743898773, "timer/agent.train_avg": 0.4469125639278041, "timer/agent.train_min": 0.4360389709472656, "timer/agent.train_max": 0.595221996307373, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47627711296081543, "timer/agent.report_frac": 0.00048748775554435656, "timer/agent.report_avg": 0.23813855648040771, "timer/agent.report_min": 0.22953104972839355, "timer/agent.report_max": 0.24674606323242188, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.5762786865234375e-05, "timer/dataset_eval_frac": 3.6604573737681644e-08, "timer/dataset_eval_avg": 3.5762786865234375e-05, "timer/dataset_eval_min": 3.5762786865234375e-05, "timer/dataset_eval_max": 3.5762786865234375e-05, "fps": 8.716348619998953}
{"step": 10088, "time": 1239.3457815647125, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 1239.3531584739685, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 1239.3623487949371, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 1239.3690807819366, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 1239.3755505084991, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 1239.3820133209229, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 1239.3881816864014, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 1239.3948605060577, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10096, "time": 1240.3182888031006, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 10608, "time": 1298.9620130062103, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 11560, "time": 1408.0395877361298, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 11560, "time": 1408.0472955703735, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 11560, "time": 1408.055147409439, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 11560, "time": 1408.0626611709595, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 11560, "time": 1408.069096326828, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 11808, "time": 1436.4327909946442, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 12408, "time": 1505.0254182815552, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 12920, "time": 1563.531686782837, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 13872, "time": 1672.3214738368988, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 13872, "time": 1672.3366537094116, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 13872, "time": 1672.3433167934418, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 13872, "time": 1672.3497774600983, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 13872, "time": 1672.3566241264343, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 14120, "time": 1700.6443090438843, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 14720, "time": 1769.0340631008148, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 15232, "time": 1827.296637058258, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 15592, "time": 1868.2338404655457, "episode/length": 214.0, "episode/score": 0.33125001192092896, "episode/reward_rate": 0.004651162790697674, "episode/intrinsic_return": 0.0}
{"step": 16184, "time": 1935.4658515453339, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 16184, "time": 1935.4749114513397, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 16184, "time": 1935.4816691875458, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 16184, "time": 1935.4882867336273, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 16200, "time": 1937.3196291923523, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 16432, "time": 1964.03186917305, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 17544, "time": 2090.434872865677, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 17904, "time": 2131.455412387848, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 18496, "time": 2198.693375110626, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 18496, "time": 2198.7232036590576, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 18496, "time": 2198.7293434143066, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 18496, "time": 2198.7365984916687, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 18512, "time": 2200.536777496338, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 18744, "time": 2226.788769006729, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 18789, "time": 2232.8129613399506, "eval_stats/mean_log_entropy": 0.0, "train_stats/mean_log_entropy": 1.9380505446231726, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.999981998847926, "train/action_min": 0.0, "train/action_std": 1.9999243460492604, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00011195582083605734, "train/actor_opt_grad_steps": 3220.0, "train/actor_opt_loss": -1.741966650383504, "train/adv_mag": 0.00046726444967880776, "train/adv_max": 0.00044083171245139864, "train/adv_mean": 0.00020701621518873366, "train/adv_min": -6.448005407636617e-05, "train/adv_std": 0.00011418704126563464, "train/cont_avg": 0.9964942756336406, "train/cont_loss_mean": 0.02340806201250563, "train/cont_loss_std": 0.3244075283519752, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.68250626269902, "train/cont_pos_acc": 0.9999999857168593, "train/cont_pos_loss": 0.003476040474834427, "train/cont_pred": 0.9965301996551901, "train/cont_rate": 0.9964942756336406, "train/dyn_loss_mean": 1.0006090583889167, "train/dyn_loss_std": 6.164994379587327e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.06934335681047582, "train/extr_critic_critic_opt_grad_steps": 3220.0, "train/extr_critic_critic_opt_loss": 10036.561469434044, "train/extr_critic_mag": 0.0336480860336585, "train/extr_critic_max": 0.0336480860336585, "train/extr_critic_mean": 0.033569089476070645, "train/extr_critic_min": 0.03351089481933875, "train/extr_critic_std": 1.932037588183343e-05, "train/extr_return_normed_mag": 0.0008406486053208602, "train/extr_return_normed_max": 0.0008060894477339934, "train/extr_return_normed_mean": 0.0006250720989650005, "train/extr_return_normed_min": 0.00039376389698773484, "train/extr_return_normed_std": 0.00011001065470627677, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.0339571365889179, "train/extr_return_raw_max": 0.0339571365889179, "train/extr_return_raw_mean": 0.033776120862103826, "train/extr_return_raw_min": 0.03354481103817164, "train/extr_return_raw_std": 0.00011001065473037628, "train/extr_reward_mag": 0.0001337017331804548, "train/extr_reward_max": 0.0001337017331804548, "train/extr_reward_mean": 0.00013357333827941905, "train/extr_reward_min": 0.00013338036251507596, "train/extr_reward_std": 5.163006115111786e-08, "train/image_loss_mean": 0.2679356366807964, "train/image_loss_std": 0.08598210887494175, "train/model_loss_mean": 0.895080330459753, "train/model_loss_std": 0.3998744836600695, "train/model_opt_grad_norm": 76.59388606339556, "train/model_opt_grad_steps": 3210.0, "train/model_opt_loss": 64.96183376048567, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 72.72465437788019, "train/policy_entropy_mag": 1.94589303440762, "train/policy_entropy_max": 1.94589303440762, "train/policy_entropy_mean": 1.945058490823491, "train/policy_entropy_min": 1.9302550004923948, "train/policy_entropy_std": 0.0005961886960111799, "train/policy_logprob_mag": 2.181484806922174, "train/policy_logprob_max": -1.7226695772689609, "train/policy_logprob_mean": -1.9450386411034017, "train/policy_logprob_min": -2.181484806922174, "train/policy_logprob_std": 0.04105737032840878, "train/policy_randomness_mag": 0.99999126338739, "train/policy_randomness_max": 0.99999126338739, "train/policy_randomness_mean": 0.9995623901143053, "train/policy_randomness_min": 0.9919549028994301, "train/policy_randomness_std": 0.0003063804102516497, "train/post_ent_mag": 59.26751995526151, "train/post_ent_max": 59.26751995526151, "train/post_ent_mean": 59.18883544289022, "train/post_ent_min": 59.17066589918005, "train/post_ent_std": 0.01209588913882177, "train/prior_ent_mag": 57.00654034241004, "train/prior_ent_max": 57.00654034241004, "train/prior_ent_mean": 56.97343291884743, "train/prior_ent_min": 56.92903483518258, "train/prior_ent_std": 0.01119565635850902, "train/rep_loss_mean": 1.0006090583889167, "train/rep_loss_std": 6.164994379587327e-05, "train/reward_avg": 0.00015703192724275493, "train/reward_loss_mean": 0.0033711749236292553, "train/reward_loss_std": 0.08536628276984178, "train/reward_max_data": 0.14470046291702904, "train/reward_max_pred": 0.0001337566683369298, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.0004817192012997782, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.308512655893962, "train/reward_pred": 0.0001336169399080738, "train/reward_rate": 0.0003105198732718894, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.03726472705602646, "report/cont_loss_std": 0.44928598403930664, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.889491081237793, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0027722243685275316, "report/cont_pred": 0.9972315430641174, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.25172722339630127, "report/image_loss_std": 0.09571560472249985, "report/model_loss_mean": 0.8985736966133118, "report/model_loss_std": 0.6425614356994629, "report/post_ent_mag": 58.12250900268555, "report/post_ent_max": 58.12250900268555, "report/post_ent_mean": 58.08548355102539, "report/post_ent_min": 58.06429672241211, "report/post_ent_std": 0.006781192496418953, "report/prior_ent_mag": 54.156829833984375, "report/prior_ent_max": 54.156829833984375, "report/prior_ent_mean": 54.1451530456543, "report/prior_ent_min": 54.12980651855469, "report/prior_ent_std": 0.0037571501452475786, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0003234863397665322, "report/reward_loss_mean": 0.009581748396158218, "report/reward_loss_std": 0.2967959940433502, "report/reward_max_data": 0.33125001192092896, "report/reward_max_pred": 9.620189666748047e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00030233620782382786, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 9.502416610717773, "report/reward_pred": 9.594089351594448e-05, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.008520974777638912, "eval/cont_loss_std": 0.18387016654014587, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.889491081237793, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0027722246013581753, "eval/cont_pred": 0.9972315430641174, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2655617594718933, "eval/image_loss_std": 0.10100708901882172, "eval/model_loss_mean": 0.8839640617370605, "eval/model_loss_std": 0.5078703761100769, "eval/post_ent_mag": 58.12253952026367, "eval/post_ent_max": 58.12253952026367, "eval/post_ent_mean": 58.0859375, "eval/post_ent_min": 58.069091796875, "eval/post_ent_std": 0.005963549483567476, "eval/prior_ent_mag": 54.162635803222656, "eval/prior_ent_max": 54.162635803222656, "eval/prior_ent_mean": 54.14539337158203, "eval/prior_ent_min": 54.12971496582031, "eval/prior_ent_std": 0.00379017717204988, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0007232666248455644, "eval/reward_loss_mean": 0.00988130271434784, "eval/reward_loss_std": 0.3063772916793823, "eval/reward_max_data": 0.7406250238418579, "eval/reward_max_pred": 9.620189666748047e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0003023315512109548, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 9.80916690826416, "eval/reward_pred": 9.593844879418612e-05, "eval/reward_rate": 0.0009765625, "replay/size": 18285.0, "replay/inserts": 8712.0, "replay/samples": 34848.0, "replay/insert_wait_avg": 1.6537141756140057e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.736288811549667e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 5680.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2305574846102704e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.450580596923828e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2211451530457, "timer/env.step_count": 1089.0, "timer/env.step_total": 11.162009954452515, "timer/env.step_frac": 0.01115954207581224, "timer/env.step_avg": 0.010249779572500013, "timer/env.step_min": 0.009183406829833984, "timer/env.step_max": 0.03665614128112793, "timer/replay._sample_count": 34848.0, "timer/replay._sample_total": 18.765204191207886, "timer/replay._sample_frac": 0.01876105527476785, "timer/replay._sample_avg": 0.0005384872644400794, "timer/replay._sample_min": 0.0003495216369628906, "timer/replay._sample_max": 0.034752845764160156, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1378.0, "timer/agent.policy_total": 14.336977005004883, "timer/agent.policy_frac": 0.014333807153028299, "timer/agent.policy_avg": 0.010404192311324298, "timer/agent.policy_min": 0.009239912033081055, "timer/agent.policy_max": 0.03564333915710449, "timer/dataset_train_count": 2178.0, "timer/dataset_train_total": 0.394420862197876, "timer/dataset_train_frac": 0.0003943336572208988, "timer/dataset_train_avg": 0.00018109314150499355, "timer/dataset_train_min": 9.72747802734375e-05, "timer/dataset_train_max": 0.005352020263671875, "timer/agent.train_count": 2178.0, "timer/agent.train_total": 969.019495010376, "timer/agent.train_frac": 0.9688052484254415, "timer/agent.train_avg": 0.44491253214434157, "timer/agent.train_min": 0.43302202224731445, "timer/agent.train_max": 0.6029336452484131, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47680234909057617, "timer/agent.report_frac": 0.00047669692987506256, "timer/agent.report_avg": 0.23840117454528809, "timer/agent.report_min": 0.23088645935058594, "timer/agent.report_max": 0.24591588973999023, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0994415283203125e-05, "timer/dataset_eval_frac": 3.0987562533944045e-08, "timer/dataset_eval_avg": 3.0994415283203125e-05, "timer/dataset_eval_min": 3.0994415283203125e-05, "timer/dataset_eval_max": 3.0994415283203125e-05, "fps": 8.709971078931519}
{"step": 19856, "time": 2354.0002222061157, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 20072, "time": 2384.8129460811615, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 2384.820486307144, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 2384.8263425827026, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 2384.832074403763, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 2384.837849855423, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 2384.8433017730713, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 2384.8489458560944, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 2384.854655265808, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20216, "time": 2401.163547039032, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 20808, "time": 2468.5530183315277, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 20808, "time": 2468.561536550522, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 20808, "time": 2468.5694987773895, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 20808, "time": 2468.576448917389, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 20824, "time": 2470.3823931217194, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 21056, "time": 2496.8252420425415, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 22064, "time": 2611.2658767700195, "episode/length": 275.0, "episode/score": 0.140625, "episode/reward_rate": 0.0036231884057971015, "episode/intrinsic_return": 0.0}
{"step": 22528, "time": 2664.0638155937195, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 23120, "time": 2731.4095997810364, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 23120, "time": 2731.4170110225677, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 23120, "time": 2731.425328016281, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 23120, "time": 2731.431440114975, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 23136, "time": 2733.243134498596, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 23368, "time": 2759.523987531662, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 24376, "time": 2874.0383410453796, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 24840, "time": 2927.2860243320465, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 25432, "time": 2994.441430091858, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 25432, "time": 2994.4619193077087, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 25432, "time": 2994.4684960842133, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 25432, "time": 2994.4751274585724, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 25448, "time": 2996.304614305496, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 25680, "time": 3022.655548810959, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 26688, "time": 3137.1780366897583, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 27152, "time": 3189.7246828079224, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 27525, "time": 3233.1593096256256, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.9991541474921517, "train/action_min": 0.0, "train/action_std": 2.0000342185094477, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 4.8325540417232275e-05, "train/actor_opt_grad_steps": 5400.0, "train/actor_opt_loss": -5.517356502138861, "train/adv_mag": 0.0002737477693927887, "train/adv_max": 0.00017511546951995047, "train/adv_mean": 9.196715126985027e-06, "train/adv_min": -0.00017066529556496502, "train/adv_std": 6.129738012265124e-05, "train/cont_avg": 0.9962631992009132, "train/cont_loss_mean": 0.024684551449441542, "train/cont_loss_std": 0.333166313570282, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.677813521055418, "train/cont_pos_acc": 0.9999999820369564, "train/cont_pos_loss": 0.0034804953630061045, "train/cont_pred": 0.9965257100318665, "train/cont_rate": 0.9962631992009132, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.022066419487011078, "train/extr_critic_critic_opt_grad_steps": 5400.0, "train/extr_critic_critic_opt_loss": 10617.490724885845, "train/extr_critic_mag": 0.03758954239762537, "train/extr_critic_max": 0.03758954239762537, "train/extr_critic_mean": 0.03750225085101715, "train/extr_critic_min": 0.03744797619510459, "train/extr_critic_std": 2.1333899785607605e-05, "train/extr_return_normed_mag": 0.00033839410978909497, "train/extr_return_normed_max": 0.0002129495858329616, "train/extr_return_normed_mean": 9.705931019287321e-05, "train/extr_return_normed_min": -1.605901203743399e-05, "train/extr_return_normed_std": 5.4152854095648196e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.03762733830844975, "train/extr_return_raw_max": 0.03762733830844975, "train/extr_return_raw_mean": 0.03751145008968436, "train/extr_return_raw_min": 0.03739832971057935, "train/extr_return_raw_std": 5.415285452872237e-05, "train/extr_reward_mag": 0.00011419487870447168, "train/extr_reward_max": 0.00011419487870447168, "train/extr_reward_mean": 0.00011413686257732828, "train/extr_reward_min": 0.00011401252659488486, "train/extr_reward_std": 2.8781025429479218e-08, "train/image_loss_mean": 0.25906580325947504, "train/image_loss_std": 0.08608032939913066, "train/model_loss_mean": 0.886968538369218, "train/model_loss_std": 0.4071159581037145, "train/model_opt_grad_norm": 61.376511630402305, "train/model_opt_grad_steps": 5390.0, "train/model_opt_loss": 292.71495007379957, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 330.33675799086757, "train/policy_entropy_mag": 1.94589795859437, "train/policy_entropy_max": 1.94589795859437, "train/policy_entropy_mean": 1.9453308467995631, "train/policy_entropy_min": 1.935853885189039, "train/policy_entropy_std": 0.00039904048404822205, "train/policy_logprob_mag": 2.1366165446364174, "train/policy_logprob_max": -1.7660215537842006, "train/policy_logprob_mean": -1.945308251468014, "train/policy_logprob_min": -2.1366165446364174, "train/policy_logprob_std": 0.034001155786182236, "train/policy_randomness_mag": 0.9999937929519235, "train/policy_randomness_max": 0.9999937929519235, "train/policy_randomness_mean": 0.9997023564495452, "train/policy_randomness_min": 0.9948321624433614, "train/policy_randomness_std": 0.00020506624955009907, "train/post_ent_mag": 57.37264932780505, "train/post_ent_max": 57.37264932780505, "train/post_ent_mean": 57.35596720377604, "train/post_ent_min": 57.327149029736105, "train/post_ent_std": 0.007217603861077872, "train/prior_ent_mag": 54.17409396933638, "train/prior_ent_max": 54.17409396933638, "train/prior_ent_mean": 54.161934038275454, "train/prior_ent_min": 54.13843149681614, "train/prior_ent_std": 0.004437255346722323, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0001381094621698538, "train/reward_loss_mean": 0.003218162519916824, "train/reward_loss_std": 0.0842577524030805, "train/reward_max_data": 0.12304509366483993, "train/reward_max_pred": 0.00011411322850614922, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.0003378983356056471, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.221592903137207, "train/reward_pred": 0.00011402414633241826, "train/reward_rate": 0.00031214326484018263, "train_stats/mean_log_entropy": 1.9385331869125366, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.042194806039333344, "report/cont_loss_std": 0.4670216143131256, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.671418190002441, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0034489217214286327, "report/cont_pred": 0.9965570569038391, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.25384366512298584, "report/image_loss_std": 0.08693654835224152, "report/model_loss_mean": 0.9139304161071777, "report/model_loss_std": 0.7703679203987122, "report/post_ent_mag": 56.72291564941406, "report/post_ent_max": 56.72291564941406, "report/post_ent_mean": 56.708885192871094, "report/post_ent_min": 56.670963287353516, "report/post_ent_std": 0.010589387267827988, "report/prior_ent_mag": 54.193397521972656, "report/prior_ent_max": 54.193397521972656, "report/prior_ent_mean": 54.180110931396484, "report/prior_ent_min": 54.147735595703125, "report/prior_ent_std": 0.006837664172053337, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00079345703125, "report/reward_loss_mean": 0.017891928553581238, "report/reward_loss_std": 0.39853155612945557, "report/reward_max_data": 0.671875, "report/reward_max_pred": 0.00010895729064941406, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0003264276892878115, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 8.993867874145508, "report/reward_pred": 0.0001088930293917656, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.008984047919511795, "eval/cont_loss_std": 0.17703750729560852, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.671417713165283, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.00344892218708992, "eval/cont_pred": 0.9965570569038391, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2626250684261322, "eval/image_loss_std": 0.09273354709148407, "eval/model_loss_mean": 0.8817769289016724, "eval/model_loss_std": 0.506830096244812, "eval/post_ent_mag": 56.72071838378906, "eval/post_ent_max": 56.72071838378906, "eval/post_ent_mean": 56.7094841003418, "eval/post_ent_min": 56.66804885864258, "eval/post_ent_std": 0.009821976535022259, "eval/prior_ent_mag": 54.192626953125, "eval/prior_ent_max": 54.192626953125, "eval/prior_ent_mean": 54.18092346191406, "eval/prior_ent_min": 54.14787673950195, "eval/prior_ent_std": 0.00587302353233099, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0007232666248455644, "eval/reward_loss_mean": 0.010167770087718964, "eval/reward_loss_std": 0.31476911902427673, "eval/reward_max_data": 0.7406250238418579, "eval/reward_max_pred": 0.00010895729064941406, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00032643068698234856, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 10.077859878540039, "eval/reward_pred": 0.00010889500845223665, "eval/reward_rate": 0.0009765625, "replay/size": 27021.0, "replay/inserts": 8736.0, "replay/samples": 34944.0, "replay/insert_wait_avg": 1.6711679570404165e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.799775390834598e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 7992.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1573407064259671e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.387731552124023e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3296077251434, "timer/env.step_count": 1092.0, "timer/env.step_total": 11.049622058868408, "timer/env.step_frac": 0.011045981218127124, "timer/env.step_avg": 0.010118701519110264, "timer/env.step_min": 0.009217977523803711, "timer/env.step_max": 0.025847911834716797, "timer/replay._sample_count": 34944.0, "timer/replay._sample_total": 18.445050477981567, "timer/replay._sample_frac": 0.018438972850086468, "timer/replay._sample_avg": 0.000527845995821359, "timer/replay._sample_min": 0.0003635883331298828, "timer/replay._sample_max": 0.027756452560424805, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1381.0, "timer/agent.policy_total": 14.673132419586182, "timer/agent.policy_frac": 0.01466829763537086, "timer/agent.policy_avg": 0.010625005372618524, "timer/agent.policy_min": 0.008988142013549805, "timer/agent.policy_max": 0.08629608154296875, "timer/dataset_train_count": 2184.0, "timer/dataset_train_total": 0.3850209712982178, "timer/dataset_train_frac": 0.0003848941072271135, "timer/dataset_train_avg": 0.000176291653524825, "timer/dataset_train_min": 9.274482727050781e-05, "timer/dataset_train_max": 0.0009565353393554688, "timer/agent.train_count": 2184.0, "timer/agent.train_total": 968.7798051834106, "timer/agent.train_frac": 0.9684605930904311, "timer/agent.train_avg": 0.44358049687885104, "timer/agent.train_min": 0.43356847763061523, "timer/agent.train_max": 0.5836935043334961, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4772300720214844, "timer/agent.report_frac": 0.0004770728251328646, "timer/agent.report_avg": 0.2386150360107422, "timer/agent.report_min": 0.23078489303588867, "timer/agent.report_max": 0.2464451789855957, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9087066650390625e-05, "timer/dataset_eval_frac": 2.907748248753501e-08, "timer/dataset_eval_avg": 2.9087066650390625e-05, "timer/dataset_eval_min": 2.9087066650390625e-05, "timer/dataset_eval_max": 2.9087066650390625e-05, "fps": 8.73301041831683}
{"step": 27744, "time": 3257.855127096176, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 27744, "time": 3257.8644750118256, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 27744, "time": 3257.8702976703644, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 27744, "time": 3257.8767330646515, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 27760, "time": 3259.700920820236, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 27992, "time": 3286.072961807251, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 29000, "time": 3400.2011811733246, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 29464, "time": 3452.6235859394073, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 30016, "time": 3515.327219247818, "episode/length": 283.0, "episode/score": 0.11562500149011612, "episode/reward_rate": 0.0035211267605633804, "episode/intrinsic_return": 0.0}
{"step": 30056, "time": 3519.8963491916656, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 30056, "time": 3519.9053604602814, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 30056, "time": 3519.9114468097687, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 30056, "time": 3525.116755247116, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 3525.123610019684, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 3525.129173517227, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 3525.1344487667084, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 3525.139754295349, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 3525.1452074050903, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 3525.150493621826, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 3525.1558554172516, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30072, "time": 3526.964804649353, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 30304, "time": 3553.2897663116455, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 31312, "time": 3667.753881931305, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 31776, "time": 3720.563775062561, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 32328, "time": 3783.5572118759155, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 32368, "time": 3788.144040107727, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 32368, "time": 3788.1509709358215, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 32368, "time": 3788.1576952934265, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 32384, "time": 3789.9735205173492, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 32616, "time": 3816.4623386859894, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 33624, "time": 3931.713534593582, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 34088, "time": 3984.532978773117, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 34640, "time": 4047.236878156662, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 34680, "time": 4051.798757791519, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 34680, "time": 4051.805990934372, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 34680, "time": 4051.813378572464, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 34696, "time": 4053.6345365047455, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 34928, "time": 4080.0116522312164, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 35936, "time": 4194.838096380234, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 36265, "time": 4233.157393455505, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.0001433486238533, "train/action_min": 0.0, "train/action_std": 1.9995096205571377, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 7.575156768817837e-05, "train/actor_opt_grad_steps": 7585.0, "train/actor_opt_loss": -8.194647536912095, "train/adv_mag": 0.0003514601891740746, "train/adv_max": 7.537509733383808e-05, "train/adv_mean": -0.00013091750339198153, "train/adv_min": -0.00033381152385418566, "train/adv_std": 8.072454216669422e-05, "train/cont_avg": 0.9964566012041285, "train/cont_loss_mean": 0.023577397608052972, "train/cont_loss_std": 0.32802094847557706, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.684997123507311, "train/cont_pos_acc": 0.9999999846887151, "train/cont_pos_loss": 0.003439470759268269, "train/cont_pred": 0.9965665668522546, "train/cont_rate": 0.9964566012041285, "train/dyn_loss_mean": 1.0005200685711082, "train/dyn_loss_std": 7.457351376123111e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.0125939531877654, "train/extr_critic_critic_opt_grad_steps": 7585.0, "train/extr_critic_critic_opt_loss": 10183.124068233945, "train/extr_critic_mag": 0.03470988339240398, "train/extr_critic_max": 0.03470988339240398, "train/extr_critic_mean": 0.034626549793356054, "train/extr_critic_min": 0.03456780232420755, "train/extr_critic_std": 2.1847599175867348e-05, "train/extr_return_normed_mag": 0.00037022985073677993, "train/extr_return_normed_max": -5.7536254235363885e-06, "train/extr_return_normed_mean": -0.00017085929175247007, "train/extr_return_normed_min": -0.0003028386827865872, "train/extr_return_normed_std": 7.475171712109982e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.03466072302619252, "train/extr_return_raw_max": 0.03466072302619252, "train/extr_return_raw_mean": 0.034495619014589064, "train/extr_return_raw_min": 0.034363637968829464, "train/extr_return_raw_std": 7.475171745485935e-05, "train/extr_reward_mag": 8.336666527144405e-05, "train/extr_reward_max": 8.336666527144405e-05, "train/extr_reward_mean": 8.333622193051536e-05, "train/extr_reward_min": 8.328737468894468e-05, "train/extr_reward_std": 2.1875242340273176e-08, "train/image_loss_mean": 0.25081086377485085, "train/image_loss_std": 0.08713541860017207, "train/model_loss_mean": 0.8777714327934685, "train/model_loss_std": 0.4021714618856754, "train/model_opt_grad_norm": 53.51187590502818, "train/model_opt_grad_steps": 7575.0, "train/model_opt_loss": 1298.052320287862, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1479.3577981651376, "train/policy_entropy_mag": 1.9458984754501132, "train/policy_entropy_max": 1.9458984754501132, "train/policy_entropy_mean": 1.9453382705329756, "train/policy_entropy_min": 1.9357661522856546, "train/policy_entropy_std": 0.00039719942815114804, "train/policy_logprob_mag": 2.135009351126645, "train/policy_logprob_max": -1.7652478480557783, "train/policy_logprob_mean": -1.945337675580191, "train/policy_logprob_min": -2.135009351126645, "train/policy_logprob_std": 0.03355531307330372, "train/policy_randomness_mag": 0.9999940611353708, "train/policy_randomness_max": 0.9999940611353708, "train/policy_randomness_mean": 0.9997061635922948, "train/policy_randomness_min": 0.9947870751039698, "train/policy_randomness_std": 0.00020412013791512202, "train/post_ent_mag": 57.33469079393859, "train/post_ent_max": 57.33469079393859, "train/post_ent_mean": 57.31549315496322, "train/post_ent_min": 57.243391806926205, "train/post_ent_std": 0.017011563970767165, "train/prior_ent_mag": 54.318267017329504, "train/prior_ent_max": 54.318267017329504, "train/prior_ent_mean": 54.29890023677721, "train/prior_ent_min": 54.24585251414448, "train/prior_ent_std": 0.011214598323380865, "train/rep_loss_mean": 1.0005200685711082, "train/rep_loss_std": 7.457351376123111e-05, "train/reward_avg": 0.00012925174367643994, "train/reward_loss_mean": 0.0030711088414996043, "train/reward_loss_std": 0.08394662005512915, "train/reward_max_data": 0.11864965757645599, "train/reward_max_pred": 8.338416388275426e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00024781539692295666, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.242068076133728, "train/reward_pred": 8.331699704819726e-05, "train/reward_rate": 0.0003046158256880734, "train_stats/mean_log_entropy": 1.9386270776871712, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.02559707686305046, "report/cont_loss_std": 0.35453012585639954, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.6869893074035645, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0033955422695726156, "report/cont_pred": 0.9966104030609131, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.24275486171245575, "report/image_loss_std": 0.08627819269895554, "report/model_loss_mean": 0.8685340881347656, "report/model_loss_std": 0.36102768778800964, "report/post_ent_mag": 53.84941101074219, "report/post_ent_max": 53.84941101074219, "report/post_ent_mean": 53.822784423828125, "report/post_ent_min": 53.81703567504883, "report/post_ent_std": 0.004506315104663372, "report/prior_ent_mag": 51.364715576171875, "report/prior_ent_max": 51.364715576171875, "report/prior_ent_mean": 51.34907150268555, "report/prior_ent_min": 51.31964874267578, "report/prior_ent_std": 0.007227568421512842, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.00018215179443359375, "report/reward_loss_std": 0.0, "report/reward_max_data": 0.0, "report/reward_max_pred": 5.555152893066406e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00018215179443359375, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 5.5532786063849926e-05, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.0033955422695726156, "eval/cont_loss_std": 6.984919309616089e-10, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0033955422695726156, "eval/cont_pred": 0.9966104030609131, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2410610020160675, "eval/image_loss_std": 0.08735187351703644, "eval/model_loss_mean": 0.8446387052536011, "eval/model_loss_std": 0.08735186606645584, "eval/post_ent_mag": 53.849544525146484, "eval/post_ent_max": 53.849544525146484, "eval/post_ent_mean": 53.82255554199219, "eval/post_ent_min": 53.81611633300781, "eval/post_ent_std": 0.004196720663458109, "eval/prior_ent_mag": 51.368804931640625, "eval/prior_ent_max": 51.368804931640625, "eval/prior_ent_mean": 51.349517822265625, "eval/prior_ent_min": 51.317562103271484, "eval/prior_ent_std": 0.007172430865466595, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00018215179443359375, "eval/reward_loss_std": 0.0, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 5.555152893066406e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00018215179443359375, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 5.5531389079988e-05, "eval/reward_rate": 0.0, "replay/size": 35761.0, "replay/inserts": 8740.0, "replay/samples": 34960.0, "replay/insert_wait_avg": 1.5831648348670802e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.957268717087106e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 10304.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0523622836208673e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.599592208862305e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 999.9907472133636, "timer/env.step_count": 1093.0, "timer/env.step_total": 11.12895655632019, "timer/env.step_frac": 0.011129059531133495, "timer/env.step_avg": 0.010182027956377118, "timer/env.step_min": 0.009265661239624023, "timer/env.step_max": 0.03530478477478027, "timer/replay._sample_count": 34960.0, "timer/replay._sample_total": 17.461074829101562, "timer/replay._sample_frac": 0.017461236394196326, "timer/replay._sample_avg": 0.0004994586621596557, "timer/replay._sample_min": 0.00035119056701660156, "timer/replay._sample_max": 0.025629520416259766, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1382.0, "timer/agent.policy_total": 13.982506036758423, "timer/agent.policy_frac": 0.013982635415100532, "timer/agent.policy_avg": 0.010117587580867166, "timer/agent.policy_min": 0.008682489395141602, "timer/agent.policy_max": 0.03717184066772461, "timer/dataset_train_count": 2185.0, "timer/dataset_train_total": 0.4374558925628662, "timer/dataset_train_frac": 0.00043745994028635563, "timer/dataset_train_avg": 0.00020020864648186097, "timer/dataset_train_min": 9.083747863769531e-05, "timer/dataset_train_max": 0.042807817459106445, "timer/agent.train_count": 2185.0, "timer/agent.train_total": 969.5462477207184, "timer/agent.train_frac": 0.9695552188082902, "timer/agent.train_avg": 0.4437282598264157, "timer/agent.train_min": 0.43364429473876953, "timer/agent.train_max": 0.8167555332183838, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4759085178375244, "timer/agent.report_frac": 0.0004759129213582432, "timer/agent.report_avg": 0.2379542589187622, "timer/agent.report_min": 0.23023724555969238, "timer/agent.report_max": 0.24567127227783203, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.1948089599609375e-05, "timer/dataset_eval_frac": 3.194838521120111e-08, "timer/dataset_eval_avg": 3.1948089599609375e-05, "timer/dataset_eval_min": 3.1948089599609375e-05, "timer/dataset_eval_max": 3.1948089599609375e-05, "fps": 8.73997490304524}
{"step": 36400, "time": 4248.408146381378, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 36952, "time": 4310.991144895554, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 36992, "time": 4315.515604734421, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 36992, "time": 4315.522850036621, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 36992, "time": 4315.528635025024, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 37008, "time": 4317.356328725815, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 37240, "time": 4343.627850055695, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 38248, "time": 4458.100051164627, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 38712, "time": 4510.891962051392, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 39264, "time": 4573.686544418335, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 39304, "time": 4578.213032722473, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 39304, "time": 4578.220669746399, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 39304, "time": 4578.227095603943, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 39320, "time": 4580.053555727005, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 39552, "time": 4606.341874599457, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 40040, "time": 4666.687991857529, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 4666.695355892181, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 4666.72372341156, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 4666.729533910751, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 4666.735060214996, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 4666.740569829941, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 4666.746126651764, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 4666.751841545105, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40560, "time": 4725.830038547516, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 41024, "time": 4778.7613480091095, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 41576, "time": 4841.447448253632, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 41616, "time": 4845.986238241196, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 41616, "time": 4845.993428707123, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 41616, "time": 4845.999639749527, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 41632, "time": 4847.815034151077, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 41864, "time": 4874.455406665802, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 42872, "time": 4989.596475839615, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 42920, "time": 4995.104157924652, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 43336, "time": 5042.548287153244, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 43888, "time": 5105.749518632889, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 43928, "time": 5110.30676984787, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 43928, "time": 5110.313859701157, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 43944, "time": 5112.203763961792, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 44176, "time": 5138.628271102905, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 44993, "time": 5233.234867572784, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.998533756361095, "train/action_min": 0.0, "train/action_std": 2.001143056865132, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00012948353299038024, "train/actor_opt_grad_steps": 9765.0, "train/actor_opt_loss": -8.137399737031087, "train/adv_mag": 0.00039209011907971234, "train/adv_max": 0.00015790010332514387, "train/adv_mean": -0.00012836946135026965, "train/adv_min": -0.0003774207461317745, "train/adv_std": 8.82099328368436e-05, "train/cont_avg": 0.9966223480504587, "train/cont_loss_mean": 0.022611923165482665, "train/cont_loss_std": 0.31697158355347227, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.664174939984473, "train/cont_pos_acc": 0.9999999838684677, "train/cont_pos_loss": 0.003511856808839793, "train/cont_pred": 0.9964944014855481, "train/cont_rate": 0.9966223480504587, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.00978676028792114, "train/extr_critic_critic_opt_grad_steps": 9765.0, "train/extr_critic_critic_opt_loss": 9097.265074003728, "train/extr_critic_mag": 0.02834138738999673, "train/extr_critic_max": 0.02834138738999673, "train/extr_critic_mean": 0.028227634839030034, "train/extr_critic_min": 0.02809453283974884, "train/extr_critic_std": 3.9822539445077555e-05, "train/extr_return_normed_mag": 0.0003836180570475552, "train/extr_return_normed_max": 6.788905812512844e-05, "train/extr_return_normed_mean": -0.0001462773690718612, "train/extr_return_normed_min": -0.0003146085067899949, "train/extr_return_normed_std": 7.785528764376535e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.028313433700198426, "train/extr_return_raw_max": 0.028313433700198426, "train/extr_return_raw_mean": 0.028099268649217732, "train/extr_return_raw_min": 0.027930936135283305, "train/extr_return_raw_std": 7.785528781064511e-05, "train/extr_reward_mag": 6.45523771233515e-05, "train/extr_reward_max": 6.45523771233515e-05, "train/extr_reward_mean": 6.44729561076303e-05, "train/extr_reward_min": 6.44019984324044e-05, "train/extr_reward_std": 3.700939386858777e-08, "train/image_loss_mean": 0.23876414359162706, "train/image_loss_std": 0.0869202679279474, "train/model_loss_mean": 0.8633547772508149, "train/model_loss_std": 0.3705918507291636, "train/model_opt_grad_norm": 46.82781120615268, "train/model_opt_grad_steps": 9753.899082568807, "train/model_opt_loss": 2415.7797308405607, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2798.1651376146788, "train/policy_entropy_mag": 1.9458447098731995, "train/policy_entropy_max": 1.9458447098731995, "train/policy_entropy_mean": 1.9425510271973567, "train/policy_entropy_min": 1.908688430392414, "train/policy_entropy_std": 0.0025649439378474933, "train/policy_logprob_mag": 2.313730117377885, "train/policy_logprob_max": -1.6062884956871697, "train/policy_logprob_mean": -1.9425937309177643, "train/policy_logprob_min": -2.313730117377885, "train/policy_logprob_std": 0.06988230108394536, "train/policy_randomness_mag": 0.999966429461033, "train/policy_randomness_max": 0.999966429461033, "train/policy_randomness_mean": 0.9982738120293398, "train/policy_randomness_min": 0.9808718794529591, "train/policy_randomness_std": 0.0013181205120401183, "train/post_ent_mag": 54.59461397643483, "train/post_ent_max": 54.59461397643483, "train/post_ent_mean": 54.541560356770084, "train/post_ent_min": 54.5165515864661, "train/post_ent_std": 0.014312748635965272, "train/prior_ent_mag": 51.4823944896733, "train/prior_ent_max": 51.4823944896733, "train/prior_ent_mean": 51.39892907098893, "train/prior_ent_min": 51.35311415436071, "train/prior_ent_std": 0.01921493207625703, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 7.044241123233597e-05, "train/reward_loss_mean": 0.001978692908369757, "train/reward_loss_std": 0.05359544332982806, "train/reward_max_data": 0.06535263902960567, "train/reward_max_pred": 6.458901484078224e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00019838610130528826, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.167756679730537, "train/reward_pred": 6.449941242404214e-05, "train/reward_rate": 0.0001926247133027523, "train_stats/mean_log_entropy": 1.9373916772104078, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.031171027570962906, "report/cont_loss_std": 0.3972715735435486, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.702561855316162, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.003342807525768876, "report/cont_pred": 0.9966626167297363, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.21621522307395935, "report/image_loss_std": 0.09038886427879333, "report/model_loss_mean": 0.8476037383079529, "report/model_loss_std": 0.4053853154182434, "report/post_ent_mag": 53.16318130493164, "report/post_ent_max": 53.16318130493164, "report/post_ent_mean": 53.08763122558594, "report/post_ent_min": 53.017547607421875, "report/post_ent_std": 0.02812196873128414, "report/prior_ent_mag": 55.50997543334961, "report/prior_ent_max": 55.50997543334961, "report/prior_ent_mean": 54.22643280029297, "report/prior_ent_min": 53.32831573486328, "report/prior_ent_std": 0.47242075204849243, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.000217437744140625, "report/reward_loss_std": 0.0, "report/reward_max_data": 0.0, "report/reward_max_pred": 7.474422454833984e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.000217437744140625, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 7.462780922651291e-05, "report/reward_rate": 0.0, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.008908452466130257, "eval/cont_loss_std": 0.1780136227607727, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.702561855316162, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.003342808224260807, "eval/cont_pred": 0.9966625571250916, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.19978973269462585, "eval/image_loss_std": 0.09362620115280151, "eval/model_loss_mean": 0.8189446926116943, "eval/model_loss_std": 0.5132749676704407, "eval/post_ent_mag": 53.168312072753906, "eval/post_ent_max": 53.168312072753906, "eval/post_ent_mean": 53.08790588378906, "eval/post_ent_min": 53.02171325683594, "eval/post_ent_std": 0.027758263051509857, "eval/prior_ent_mag": 55.82829284667969, "eval/prior_ent_max": 55.82829284667969, "eval/prior_ent_mean": 54.25843811035156, "eval/prior_ent_min": 53.37444305419922, "eval/prior_ent_std": 0.47898411750793457, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0007232666248455644, "eval/reward_loss_mean": 0.01024643238633871, "eval/reward_loss_std": 0.32077109813690186, "eval/reward_max_data": 0.7406250238418579, "eval/reward_max_pred": 7.474422454833984e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.000217437744140625, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 10.26990795135498, "eval/reward_pred": 7.462815847247839e-05, "eval/reward_rate": 0.0009765625, "replay/size": 44489.0, "replay/inserts": 8728.0, "replay/samples": 34912.0, "replay/insert_wait_avg": 1.4863464397426923e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.293510611837441e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 12616.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0229724501243512e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.748603820800781e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0637617111206, "timer/env.step_count": 1091.0, "timer/env.step_total": 11.024338960647583, "timer/env.step_frac": 0.011023636074748686, "timer/env.step_avg": 0.010104801980428582, "timer/env.step_min": 0.008912801742553711, "timer/env.step_max": 0.05693221092224121, "timer/replay._sample_count": 34912.0, "timer/replay._sample_total": 18.196091175079346, "timer/replay._sample_frac": 0.018194931035142824, "timer/replay._sample_avg": 0.000521198761889303, "timer/replay._sample_min": 0.00033783912658691406, "timer/replay._sample_max": 0.011988162994384766, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1380.0, "timer/agent.policy_total": 13.958389520645142, "timer/agent.policy_frac": 0.013957499566589811, "timer/agent.policy_avg": 0.010114775014960248, "timer/agent.policy_min": 0.008570671081542969, "timer/agent.policy_max": 0.03732562065124512, "timer/dataset_train_count": 2182.0, "timer/dataset_train_total": 0.3799569606781006, "timer/dataset_train_frac": 0.0003799327355167733, "timer/dataset_train_avg": 0.00017413242927502318, "timer/dataset_train_min": 9.179115295410156e-05, "timer/dataset_train_max": 0.0011093616485595703, "timer/agent.train_count": 2182.0, "timer/agent.train_total": 969.8713881969452, "timer/agent.train_frac": 0.9698095514804816, "timer/agent.train_avg": 0.44448734564479614, "timer/agent.train_min": 0.4324839115142822, "timer/agent.train_max": 0.5892355442047119, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47811174392700195, "timer/agent.report_frac": 0.00047808126064776833, "timer/agent.report_avg": 0.23905587196350098, "timer/agent.report_min": 0.2312920093536377, "timer/agent.report_max": 0.24681973457336426, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.956390380859375e-05, "timer/dataset_eval_frac": 2.9562018883685548e-08, "timer/dataset_eval_avg": 2.956390380859375e-05, "timer/dataset_eval_min": 2.956390380859375e-05, "timer/dataset_eval_max": 2.956390380859375e-05, "fps": 8.727331583543801}
{"step": 45184, "time": 5254.808001756668, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 45232, "time": 5260.2939212322235, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 45648, "time": 5307.988329172134, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 46200, "time": 5371.375684976578, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 46240, "time": 5375.948573589325, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 46240, "time": 5375.955787181854, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 46256, "time": 5377.7954313755035, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 46488, "time": 5404.428874969482, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 47496, "time": 5519.895182609558, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 47544, "time": 5525.391159534454, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 47960, "time": 5573.200248241425, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 48512, "time": 5636.423428535461, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 48552, "time": 5640.997065782547, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 48552, "time": 5641.004440307617, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 48568, "time": 5642.856816530228, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 48800, "time": 5669.424465417862, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 49808, "time": 5785.135548591614, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 49856, "time": 5790.635363101959, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 50024, "time": 5812.633540630341, "eval_episode/length": 152.0, "eval_episode/score": 0.5249999761581421, "eval_episode/reward_rate": 0.006535947712418301}
{"step": 50024, "time": 5815.002924203873, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 5815.0108115673065, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 5815.016333580017, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 5815.021740198135, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 5815.027112483978, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 5815.032505750656, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 5815.037997245789, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50272, "time": 5843.484877109528, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 50384, "time": 5856.223125696182, "episode/length": 228.0, "episode/score": 0.2874999940395355, "episode/reward_rate": 0.004366812227074236, "episode/intrinsic_return": 0.0}
{"step": 50824, "time": 5906.570550441742, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 50864, "time": 5911.147584915161, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 50880, "time": 5912.994477272034, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 51112, "time": 5939.565563201904, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 52120, "time": 6054.910681724548, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 52168, "time": 6060.375109672546, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 52584, "time": 6107.858497142792, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 52696, "time": 6120.668081045151, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 53136, "time": 6171.010015487671, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 53176, "time": 6175.584993600845, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 53192, "time": 6177.406656503677, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 53424, "time": 6203.94895863533, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 53673, "time": 6233.45196390152, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.3328626782114057, "train/action_min": 0.0, "train/action_std": 1.9455315627260692, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.003337453191713398, "train/actor_opt_grad_steps": 11940.0, "train/actor_opt_loss": 10.649042156743839, "train/adv_mag": 0.04274626958617417, "train/adv_max": 0.04241645874343984, "train/adv_mean": 0.004960542614469629, "train/adv_min": -0.003976010344064181, "train/adv_std": 0.005935424196013209, "train/cont_avg": 0.9964447724654378, "train/cont_loss_mean": 0.023200821215158096, "train/cont_loss_std": 0.3202339261227444, "train/cont_neg_acc": 0.001557632445174957, "train/cont_neg_loss": 5.549231049056365, "train/cont_pos_acc": 0.9999954766392158, "train/cont_pos_loss": 0.0034979349721120114, "train/cont_pred": 0.9965038697840432, "train/cont_rate": 0.9964447724654378, "train/dyn_loss_mean": 1.0000007690921906, "train/dyn_loss_std": 1.663933784383336e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.5886848109212601, "train/extr_critic_critic_opt_grad_steps": 11940.0, "train/extr_critic_critic_opt_loss": 9879.925628240208, "train/extr_critic_mag": 0.04764853754351216, "train/extr_critic_max": 0.04764853754351216, "train/extr_critic_mean": 0.04591791642495015, "train/extr_critic_min": 0.043576202634292814, "train/extr_critic_std": 0.0007542421408120997, "train/extr_return_normed_mag": 0.04930357201548491, "train/extr_return_normed_max": 0.04924721071659695, "train/extr_return_normed_mean": 0.011283023769217936, "train/extr_return_normed_min": 0.002773679501037993, "train/extr_return_normed_std": 0.006116613032259953, "train/extr_return_rate": 0.0010398666049549056, "train/extr_return_raw_mag": 0.08884264528751373, "train/extr_return_raw_max": 0.08884264528751373, "train/extr_return_raw_mean": 0.05087846026579905, "train/extr_return_raw_min": 0.04236911401186945, "train/extr_return_raw_std": 0.006116612967882817, "train/extr_reward_mag": 0.020761037202474707, "train/extr_reward_max": 0.020761037202474707, "train/extr_reward_mean": 0.0008070794274275538, "train/extr_reward_min": 4.3141127731393556e-05, "train/extr_reward_std": 0.0020646629030981103, "train/image_loss_mean": 0.1906828816447939, "train/image_loss_std": 0.09729778258481883, "train/model_loss_mean": 0.815627225807735, "train/model_loss_std": 0.36933650615440533, "train/model_opt_grad_norm": 40.81599823560583, "train/model_opt_grad_steps": 11926.990783410138, "train/model_opt_loss": 2310.125465217274, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2834.1013824884794, "train/policy_entropy_mag": 1.8410238071520757, "train/policy_entropy_max": 1.8410238071520757, "train/policy_entropy_mean": 1.4441745034011277, "train/policy_entropy_min": 1.1723018217196661, "train/policy_entropy_std": 0.1207437585966344, "train/policy_logprob_mag": 4.285752916116319, "train/policy_logprob_max": -0.6833542437648855, "train/policy_logprob_mean": -1.4438846832321537, "train/policy_logprob_min": -4.285752916116319, "train/policy_logprob_std": 0.4701231263474935, "train/policy_randomness_mag": 0.9460991376556009, "train/policy_randomness_max": 0.9460991376556009, "train/policy_randomness_mean": 0.7421589259933766, "train/policy_randomness_min": 0.6024439990142798, "train/policy_randomness_std": 0.062050022009957566, "train/post_ent_mag": 54.15077019616756, "train/post_ent_max": 54.15077019616756, "train/post_ent_mean": 54.004855564662385, "train/post_ent_min": 53.87285262428671, "train/post_ent_std": 0.05135245081294792, "train/prior_ent_mag": 56.289401252148885, "train/prior_ent_max": 56.289401252148885, "train/prior_ent_mean": 53.74714447935605, "train/prior_ent_min": 51.89269748810799, "train/prior_ent_std": 0.8165823841973934, "train/rep_loss_mean": 1.0000007690921906, "train/rep_loss_std": 1.663933784383336e-05, "train/reward_avg": 8.975262051552303e-05, "train/reward_loss_mean": 0.00174303887592208, "train/reward_loss_std": 0.046091420996054934, "train/reward_max_data": 0.08443260484714113, "train/reward_max_pred": 0.004542439763996459, "train/reward_neg_acc": 0.9999954997119815, "train/reward_neg_loss": 0.00019273079996716665, "train/reward_pos_acc": 0.025, "train/reward_pos_loss": 7.4462904810905455, "train/reward_pred": 6.601587849913792e-05, "train/reward_rate": 0.00020701324884792627, "train_stats/mean_log_entropy": 1.603395314887166, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9990234375, "report/cont_loss_mean": 0.0032922488171607256, "report/cont_loss_std": 0.04827535152435303, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 1.5439257621765137, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.001786252949386835, "report/cont_pred": 0.9980136156082153, "report/cont_rate": 0.9990234375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.1563560664653778, "report/image_loss_std": 0.10856623202562332, "report/model_loss_mean": 0.759658694267273, "report/model_loss_std": 0.11884976178407669, "report/post_ent_mag": 50.22238540649414, "report/post_ent_max": 50.22238540649414, "report/post_ent_mean": 50.129798889160156, "report/post_ent_min": 50.04429626464844, "report/post_ent_std": 0.03298252820968628, "report/prior_ent_mag": 52.9217414855957, "report/prior_ent_max": 52.9217414855957, "report/prior_ent_mean": 51.10528564453125, "report/prior_ent_min": 49.82630157470703, "report/prior_ent_std": 0.5812587141990662, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 1.0311603546142578e-05, "report/reward_loss_std": 5.304980732034892e-06, "report/reward_max_data": 0.0, "report/reward_max_pred": 3.421306610107422e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 1.0311603546142578e-05, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 3.5730190575122833e-06, "report/reward_rate": 0.0, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.00814905297011137, "eval/cont_loss_std": 0.19357863068580627, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.197349548339844, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.002099003177136183, "eval/cont_pred": 0.9979166984558105, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2200538069009781, "eval/image_loss_std": 0.1391642689704895, "eval/model_loss_mean": 0.8410516977310181, "eval/model_loss_std": 0.625420868396759, "eval/post_ent_mag": 50.22673797607422, "eval/post_ent_max": 50.22673797607422, "eval/post_ent_mean": 50.12959289550781, "eval/post_ent_min": 50.03837585449219, "eval/post_ent_std": 0.035765089094638824, "eval/prior_ent_mag": 53.01011657714844, "eval/prior_ent_max": 53.01011657714844, "eval/prior_ent_mean": 51.18731689453125, "eval/prior_ent_min": 49.94792175292969, "eval/prior_ent_std": 0.5931388139724731, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0007232666248455644, "eval/reward_loss_mean": 0.0128488102927804, "eval/reward_loss_std": 0.41055697202682495, "eval/reward_max_data": 0.7406250238418579, "eval/reward_max_pred": 0.00023233890533447266, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 1.2636417523026466e-05, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 13.144254684448242, "eval/reward_pred": 4.409928806126118e-06, "eval/reward_rate": 0.0009765625, "replay/size": 53169.0, "replay/inserts": 8680.0, "replay/samples": 34720.0, "replay/insert_wait_avg": 1.579605489282564e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.555850090519074e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 14928.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0809271393350252e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.748603820800781e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2028911113739, "timer/env.step_count": 1085.0, "timer/env.step_total": 11.050052642822266, "timer/env.step_frac": 0.011047811140141793, "timer/env.step_avg": 0.010184380315965223, "timer/env.step_min": 0.009056806564331055, "timer/env.step_max": 0.040262460708618164, "timer/replay._sample_count": 34720.0, "timer/replay._sample_total": 18.979585647583008, "timer/replay._sample_frac": 0.018975735639489975, "timer/replay._sample_avg": 0.0005466470520617226, "timer/replay._sample_min": 0.0003654956817626953, "timer/replay._sample_max": 0.026186227798461914, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1374.0, "timer/agent.policy_total": 14.137151002883911, "timer/agent.policy_frac": 0.014134283282440263, "timer/agent.policy_avg": 0.010289047309231376, "timer/agent.policy_min": 0.008857488632202148, "timer/agent.policy_max": 0.036659955978393555, "timer/dataset_train_count": 2170.0, "timer/dataset_train_total": 0.39000630378723145, "timer/dataset_train_frac": 0.00038992719102608924, "timer/dataset_train_avg": 0.00017972640727522186, "timer/dataset_train_min": 9.584426879882812e-05, "timer/dataset_train_max": 0.0011911392211914062, "timer/agent.train_count": 2170.0, "timer/agent.train_total": 969.6387569904327, "timer/agent.train_frac": 0.9694420658122874, "timer/agent.train_avg": 0.44683813686195056, "timer/agent.train_min": 0.43369555473327637, "timer/agent.train_max": 0.594566822052002, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4802823066711426, "timer/agent.report_frac": 0.0004801848814268849, "timer/agent.report_avg": 0.2401411533355713, "timer/agent.report_min": 0.23307228088378906, "timer/agent.report_max": 0.24721002578735352, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0994415283203125e-05, "timer/dataset_eval_frac": 3.098812806746012e-08, "timer/dataset_eval_avg": 3.0994415283203125e-05, "timer/dataset_eval_min": 3.0994415283203125e-05, "timer/dataset_eval_max": 3.0994415283203125e-05, "fps": 8.678123095679878}
{"step": 54432, "time": 6320.5199608802795, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 54480, "time": 6326.043680906296, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 54832, "time": 6366.445362329483, "episode/length": 280.0, "episode/score": 0.125, "episode/reward_rate": 0.0035587188612099642, "episode/intrinsic_return": 0.0}
{"step": 55008, "time": 6386.698111534119, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 55448, "time": 6437.308070659637, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 55488, "time": 6441.903456687927, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 55504, "time": 6443.743895292282, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 55736, "time": 6470.435693502426, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 56744, "time": 6586.264180421829, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 56792, "time": 6591.777171611786, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 57144, "time": 6632.106382369995, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 57320, "time": 6652.310721874237, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 57760, "time": 6703.103669881821, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 57800, "time": 6707.6833074092865, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 57816, "time": 6709.511654376984, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 58048, "time": 6736.072843551636, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 59056, "time": 6851.684857368469, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 59104, "time": 6857.183357477188, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 59456, "time": 6897.403429508209, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 59632, "time": 6917.608105182648, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 60008, "time": 6966.1966342926025, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 6966.203060388565, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 6966.208623170853, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 6966.214067697525, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 6966.219388246536, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 6966.224590063095, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 6966.229892730713, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 6966.235285997391, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60072, "time": 6973.581695318222, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 60112, "time": 6978.158440113068, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 60128, "time": 6979.997142076492, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 60360, "time": 7006.484659433365, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 61368, "time": 7121.6258726119995, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 61416, "time": 7127.096776723862, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 61768, "time": 7167.250647544861, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 61944, "time": 7187.354817390442, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 62345, "time": 7233.850785017014, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.6150999288954493, "train/action_min": 0.0, "train/action_std": 1.8194525538501651, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.005107010192718477, "train/actor_opt_grad_steps": 14110.0, "train/actor_opt_loss": -12.282589979534153, "train/adv_mag": 0.20478530289940022, "train/adv_max": 0.12695159697862266, "train/adv_mean": 0.000371022022775619, "train/adv_min": -0.12848663124071288, "train/adv_std": 0.013045821549727105, "train/cont_avg": 0.996561779953917, "train/cont_loss_mean": 0.009336620630253287, "train/cont_loss_std": 0.16251078850164805, "train/cont_neg_acc": 0.5311724274503111, "train/cont_neg_loss": 2.0867081852334604, "train/cont_pos_acc": 0.9998012174109709, "train/cont_pos_loss": 0.0017928320246996478, "train/cont_pred": 0.9966227901146708, "train/cont_rate": 0.996561779953917, "train/dyn_loss_mean": 1.0002015482994817, "train/dyn_loss_std": 0.0008743840533891835, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.33562729374209443, "train/extr_critic_critic_opt_grad_steps": 14110.0, "train/extr_critic_critic_opt_loss": 7551.089835874496, "train/extr_critic_mag": 0.16094028290515672, "train/extr_critic_max": 0.16094028290515672, "train/extr_critic_mean": 0.15092386394601814, "train/extr_critic_min": 0.14375712300225887, "train/extr_critic_std": 0.002872429595517707, "train/extr_return_normed_mag": 0.20795140604269668, "train/extr_return_normed_max": 0.1380710650561592, "train/extr_return_normed_mean": 0.008011904129631769, "train/extr_return_normed_min": -0.11795912082156827, "train/extr_return_normed_std": 0.01360369531474235, "train/extr_return_rate": 0.00046472976717578616, "train/extr_return_raw_mag": 0.28135403104916146, "train/extr_return_raw_max": 0.28135403104916146, "train/extr_return_raw_mean": 0.15129487724622823, "train/extr_return_raw_min": 0.025323844278737698, "train/extr_return_raw_std": 0.013603695385020724, "train/extr_reward_mag": 0.11889733422187067, "train/extr_reward_max": 0.11889733422187067, "train/extr_reward_mean": 0.0006286506397212322, "train/extr_reward_min": 1.8359329293949812e-06, "train/extr_reward_std": 0.005248962038070705, "train/image_loss_mean": 0.12388974459077906, "train/image_loss_std": 0.09798623806869929, "train/model_loss_mean": 0.733797410116767, "train/model_loss_std": 0.21107138796336092, "train/model_opt_grad_norm": 37.41320568735149, "train/model_opt_grad_steps": 14095.396313364055, "train/model_opt_loss": 2321.855665637601, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3168.2027649769584, "train/policy_entropy_mag": 1.52269805301719, "train/policy_entropy_max": 1.52269805301719, "train/policy_entropy_mean": 0.6987188498270677, "train/policy_entropy_min": 0.06808357507265109, "train/policy_entropy_std": 0.2923017979217564, "train/policy_logprob_mag": 6.550401133875693, "train/policy_logprob_max": -0.009162615658500777, "train/policy_logprob_mean": -0.6988192365466175, "train/policy_logprob_min": -6.550401133875693, "train/policy_logprob_std": 0.8302749431078336, "train/policy_randomness_mag": 0.7825120514438998, "train/policy_randomness_max": 0.7825120514438998, "train/policy_randomness_mean": 0.35907048052219753, "train/policy_randomness_min": 0.03498803848220456, "train/policy_randomness_std": 0.15021341829667992, "train/post_ent_mag": 46.49826635193715, "train/post_ent_max": 46.49826635193715, "train/post_ent_mean": 46.30338359428441, "train/post_ent_min": 46.17540262811195, "train/post_ent_std": 0.0581003452913003, "train/prior_ent_mag": 49.48576307516493, "train/prior_ent_max": 49.48576307516493, "train/prior_ent_mean": 47.67628544047132, "train/prior_ent_min": 46.29690295100762, "train/prior_ent_std": 0.5096202808591078, "train/rep_loss_mean": 1.0002015482994817, "train/rep_loss_std": 0.0008743840533891835, "train/reward_avg": 4.913752078704218e-05, "train/reward_loss_mean": 0.0004500950625475307, "train/reward_loss_std": 0.012008371441925821, "train/reward_max_data": 0.046918203719475304, "train/reward_max_pred": 0.041067551357954875, "train/reward_neg_acc": 0.9999504880421722, "train/reward_neg_loss": 0.00010885154520508684, "train/reward_pos_acc": 0.75, "train/reward_pos_loss": 2.794401886562506, "train/reward_pred": 5.9177999788131305e-05, "train/reward_rate": 0.00012150777649769585, "train_stats/mean_log_entropy": 0.5909675412944385, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.0012272357707843184, "report/cont_loss_std": 0.010066275484859943, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0051189931109547615, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0012196197640150785, "report/cont_pred": 0.9968875646591187, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.11072391271591187, "report/image_loss_std": 0.09517236799001694, "report/model_loss_mean": 0.7119567394256592, "report/model_loss_std": 0.09674030542373657, "report/post_ent_mag": 44.67804718017578, "report/post_ent_max": 44.67804718017578, "report/post_ent_mean": 44.40621566772461, "report/post_ent_min": 44.279388427734375, "report/post_ent_std": 0.07072339951992035, "report/prior_ent_mag": 46.9764518737793, "report/prior_ent_max": 46.9764518737793, "report/prior_ent_mean": 45.68146514892578, "report/prior_ent_min": 44.378562927246094, "report/prior_ent_std": 0.4488387405872345, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 5.57582825422287e-06, "report/reward_loss_std": 1.738844730425626e-05, "report/reward_max_data": 0.0, "report/reward_max_pred": 7.87973403930664e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 5.57582825422287e-06, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 2.069748006761074e-06, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.0008584087481722236, "eval/cont_loss_std": 0.0061673386953771114, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0008584087481722236, "eval/cont_pred": 0.99916011095047, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2511405944824219, "eval/image_loss_std": 0.15268947184085846, "eval/model_loss_mean": 0.8520231246948242, "eval/model_loss_std": 0.15276959538459778, "eval/post_ent_mag": 44.678314208984375, "eval/post_ent_max": 44.678314208984375, "eval/post_ent_mean": 44.407447814941406, "eval/post_ent_min": 44.26287841796875, "eval/post_ent_std": 0.07225047796964645, "eval/prior_ent_mag": 47.94428253173828, "eval/prior_ent_max": 47.94428253173828, "eval/prior_ent_mean": 45.781761169433594, "eval/prior_ent_min": 44.1138916015625, "eval/prior_ent_std": 0.5787678360939026, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 2.4110078811645508e-05, "eval/reward_loss_std": 0.0004988794680684805, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.003969907760620117, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 2.4110078811645508e-05, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 6.770947948098183e-06, "eval/reward_rate": 0.0, "replay/size": 61841.0, "replay/inserts": 8672.0, "replay/samples": 34688.0, "replay/insert_wait_avg": 1.5465865715843285e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.648598334006278e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 17240.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0686555948224447e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0728836059570312e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3822906017303, "timer/env.step_count": 1084.0, "timer/env.step_total": 10.926507234573364, "timer/env.step_frac": 0.010922331729804079, "timer/env.step_avg": 0.010079803721931149, "timer/env.step_min": 0.008967161178588867, "timer/env.step_max": 0.03541207313537598, "timer/replay._sample_count": 34688.0, "timer/replay._sample_total": 18.917696475982666, "timer/replay._sample_frac": 0.018910467182104616, "timer/replay._sample_avg": 0.0005453671723934118, "timer/replay._sample_min": 0.00036597251892089844, "timer/replay._sample_max": 0.026119470596313477, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1373.0, "timer/agent.policy_total": 14.39224910736084, "timer/agent.policy_frac": 0.01438674918835668, "timer/agent.policy_avg": 0.010482337295965653, "timer/agent.policy_min": 0.008767843246459961, "timer/agent.policy_max": 0.08355021476745605, "timer/dataset_train_count": 2168.0, "timer/dataset_train_total": 0.4479365348815918, "timer/dataset_train_frac": 0.0004477653583932976, "timer/dataset_train_avg": 0.00020661279284206263, "timer/dataset_train_min": 9.584426879882812e-05, "timer/dataset_train_max": 0.04149174690246582, "timer/agent.train_count": 2168.0, "timer/agent.train_total": 969.6649188995361, "timer/agent.train_frac": 0.9692943667728087, "timer/agent.train_avg": 0.4472624164665757, "timer/agent.train_min": 0.43678760528564453, "timer/agent.train_max": 0.6051120758056641, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4760932922363281, "timer/agent.report_frac": 0.0004759113557977499, "timer/agent.report_avg": 0.23804664611816406, "timer/agent.report_min": 0.23142147064208984, "timer/agent.report_max": 0.24467182159423828, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0279159545898438e-05, "timer/dataset_eval_frac": 3.026758853126589e-08, "timer/dataset_eval_avg": 3.0279159545898438e-05, "timer/dataset_eval_min": 3.0279159545898438e-05, "timer/dataset_eval_max": 3.0279159545898438e-05, "fps": 8.668553999378505}
{"step": 62384, "time": 7238.143354177475, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 62424, "time": 7242.7544548511505, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 62440, "time": 7244.597756624222, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 62672, "time": 7270.987148523331, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 63680, "time": 7386.005279302597, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 63728, "time": 7391.570205450058, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 64080, "time": 7431.718640565872, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 64256, "time": 7451.853123664856, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 64696, "time": 7501.910544872284, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 64736, "time": 7506.471199512482, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 64752, "time": 7508.30224442482, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 64984, "time": 7534.799337387085, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 65992, "time": 7650.274870872498, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 66040, "time": 7655.776636838913, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 66392, "time": 7695.974943399429, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 66568, "time": 7716.123023509979, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 67008, "time": 7766.439101219177, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 67048, "time": 7770.992945432663, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 67064, "time": 7772.812404632568, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 67296, "time": 7799.314858675003, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 68304, "time": 7914.263382434845, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 68352, "time": 7919.73513674736, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 68432, "time": 7928.837712049484, "episode/length": 232.0, "episode/score": 0.2750000059604645, "episode/reward_rate": 0.004291845493562232, "episode/intrinsic_return": 0.0}
{"step": 68704, "time": 7959.8918998241425, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 68816, "time": 7972.717224597931, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.0}
{"step": 69112, "time": 8006.428701877594, "episode/length": 255.0, "episode/score": 0.203125, "episode/reward_rate": 0.00390625, "episode/intrinsic_return": 0.0}
{"step": 69320, "time": 8030.120482444763, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 69360, "time": 8034.659164905548, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 70072, "time": 8115.925749778748, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 70096, "time": 8119.4984431266785, "eval_episode/length": 46.0, "eval_episode/score": 0.856249988079071, "eval_episode/reward_rate": 0.02127659574468085}
{"step": 70096, "time": 8122.760013103485, "eval_episode/length": 237.0, "eval_episode/score": 0.2593750059604645, "eval_episode/reward_rate": 0.004201680672268907}
{"step": 70096, "time": 8123.670736789703, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 8123.681706428528, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 8123.695516347885, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 8123.705101490021, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 8123.716026306152, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 8123.728622913361, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70616, "time": 8182.848436594009, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 70664, "time": 8188.305597066879, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 70744, "time": 8197.399519443512, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 71057, "time": 8233.980173826218, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.4395228394674597, "train/action_min": 0.0, "train/action_std": 1.885470407271604, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0028724731568251353, "train/actor_opt_grad_steps": 16285.0, "train/actor_opt_loss": -14.68118920011463, "train/adv_mag": 0.15672587049663614, "train/adv_max": 0.08474609190854457, "train/adv_mean": 0.0017531924921459327, "train/adv_min": -0.11984016999192194, "train/adv_std": 0.010401704548879467, "train/cont_avg": 0.9965865108944955, "train/cont_loss_mean": 0.003969501971452467, "train/cont_loss_std": 0.0841658351071918, "train/cont_neg_acc": 0.8132621333977886, "train/cont_neg_loss": 0.7907500142063216, "train/cont_pos_acc": 0.9998606708618479, "train/cont_pos_loss": 0.0010327102783709602, "train/cont_pred": 0.9964423097601725, "train/cont_rate": 0.9965865108944955, "train/dyn_loss_mean": 1.0000071104513395, "train/dyn_loss_std": 0.00021812103424729794, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.20854976749551749, "train/extr_critic_critic_opt_grad_steps": 16285.0, "train/extr_critic_critic_opt_loss": 10216.915482547305, "train/extr_critic_mag": 0.14255820775250777, "train/extr_critic_max": 0.14255820775250777, "train/extr_critic_mean": 0.12673032246188287, "train/extr_critic_min": 0.11668310963779414, "train/extr_critic_std": 0.0038764187379915337, "train/extr_return_normed_mag": 0.16469465749799658, "train/extr_return_normed_max": 0.09929573864018151, "train/extr_return_normed_mean": 0.009843740801927297, "train/extr_return_normed_min": -0.10812500399460487, "train/extr_return_normed_std": 0.011645158011051869, "train/extr_return_rate": 0.0005575664439374781, "train/extr_return_raw_mag": 0.2179355164391732, "train/extr_return_raw_max": 0.2179355164391732, "train/extr_return_raw_mean": 0.12848352596437165, "train/extr_return_raw_min": 0.01051477418033355, "train/extr_return_raw_std": 0.011645158054841119, "train/extr_reward_mag": 0.10456043591193102, "train/extr_reward_max": 0.10456043591193102, "train/extr_reward_mean": 0.0006748295825852142, "train/extr_reward_min": 6.857268307187142e-07, "train/extr_reward_std": 0.00487018468588244, "train/image_loss_mean": 0.09454532822064303, "train/image_loss_std": 0.09401444882291173, "train/model_loss_mean": 0.6987751629374442, "train/model_loss_std": 0.14717800375245033, "train/model_opt_grad_norm": 34.18291112479814, "train/model_opt_grad_steps": 16268.518348623853, "train/model_opt_loss": 1931.9993403723481, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2763.761467889908, "train/policy_entropy_mag": 1.723958886544639, "train/policy_entropy_max": 1.723958886544639, "train/policy_entropy_mean": 1.069920515316889, "train/policy_entropy_min": 0.24361957708766702, "train/policy_entropy_std": 0.2120324135031722, "train/policy_logprob_mag": 6.548238857076802, "train/policy_logprob_max": -0.057324059059792154, "train/policy_logprob_mean": -1.069561925708154, "train/policy_logprob_min": -6.548238857076802, "train/policy_logprob_std": 0.7425250389160366, "train/policy_randomness_mag": 0.8859396664374465, "train/policy_randomness_max": 0.8859396664374465, "train/policy_randomness_mean": 0.5498304130560762, "train/policy_randomness_min": 0.12519570352902654, "train/policy_randomness_std": 0.10896311247499164, "train/post_ent_mag": 43.05852188320335, "train/post_ent_max": 43.05852188320335, "train/post_ent_mean": 42.748373626569, "train/post_ent_min": 42.573270465255874, "train/post_ent_std": 0.08302568299097753, "train/prior_ent_mag": 45.90714048683097, "train/prior_ent_max": 45.90714048683097, "train/prior_ent_mean": 44.140550665899156, "train/prior_ent_min": 42.40116294370879, "train/prior_ent_std": 0.5500623008253378, "train/rep_loss_mean": 1.0000071104513395, "train/rep_loss_std": 0.00021812103424729794, "train/reward_avg": 5.3615746122502955e-05, "train/reward_loss_mean": 0.00025604467693750467, "train/reward_loss_std": 0.007190837007819019, "train/reward_max_data": 0.05225057448815862, "train/reward_max_pred": 0.04734664936678125, "train/reward_neg_acc": 0.9999955203555045, "train/reward_neg_loss": 4.417106362358661e-05, "train/reward_pos_acc": 0.8214285714285714, "train/reward_pos_loss": 1.5389829277992249, "train/reward_pred": 5.614669211721475e-05, "train/reward_rate": 0.00013886897935779817, "train_stats/mean_log_entropy": 1.191110028885305, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.0012619076296687126, "report/cont_loss_std": 0.014482182450592518, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.13604174554347992, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0006005738396197557, "report/cont_pred": 0.9950958490371704, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.09417663514614105, "report/image_loss_std": 0.09418047219514847, "report/model_loss_mean": 0.6955589056015015, "report/model_loss_std": 0.09695188701152802, "report/post_ent_mag": 41.28741455078125, "report/post_ent_max": 41.28741455078125, "report/post_ent_mean": 40.90050506591797, "report/post_ent_min": 40.691219329833984, "report/post_ent_std": 0.10061100125312805, "report/prior_ent_mag": 43.94379425048828, "report/prior_ent_max": 43.94379425048828, "report/prior_ent_mean": 42.16333770751953, "report/prior_ent_min": 40.01275634765625, "report/prior_ent_std": 0.7352743744850159, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.00012030219659209251, "report/reward_loss_std": 0.0008330880664288998, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.004262089729309082, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00012030219659209251, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 4.0371203795075417e-05, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.03174379840493202, "eval/cont_loss_std": 0.5783109664916992, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 10.609439849853516, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0006633972516283393, "eval/cont_pred": 0.9993613958358765, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.20402787625789642, "eval/image_loss_std": 0.12082067877054214, "eval/model_loss_mean": 0.8360916376113892, "eval/model_loss_std": 0.586122453212738, "eval/post_ent_mag": 41.28529739379883, "eval/post_ent_max": 41.28529739379883, "eval/post_ent_mean": 40.890743255615234, "eval/post_ent_min": 40.686988830566406, "eval/post_ent_std": 0.09983137995004654, "eval/prior_ent_mag": 43.86279296875, "eval/prior_ent_max": 43.86279296875, "eval/prior_ent_mean": 42.07829284667969, "eval/prior_ent_min": 40.00547409057617, "eval/prior_ent_std": 0.6837031841278076, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0003199400380253792, "eval/reward_loss_std": 0.0024213329888880253, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.01376330852508545, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0003199400380253792, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00010135304182767868, "eval/reward_rate": 0.0, "replay/size": 70553.0, "replay/inserts": 8712.0, "replay/samples": 34848.0, "replay/insert_wait_avg": 1.5495839307240329e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.593708371108995e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 19552.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0466905613671537e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.08970832824707e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1187844276428, "timer/env.step_count": 1089.0, "timer/env.step_total": 10.930839538574219, "timer/env.step_frac": 0.010929541279268961, "timer/env.step_avg": 0.01003750187196898, "timer/env.step_min": 0.008876562118530273, "timer/env.step_max": 0.03597211837768555, "timer/replay._sample_count": 34848.0, "timer/replay._sample_total": 18.525577783584595, "timer/replay._sample_frac": 0.018523377494790865, "timer/replay._sample_avg": 0.0005316109327245349, "timer/replay._sample_min": 0.0003693103790283203, "timer/replay._sample_max": 0.03378653526306152, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1378.0, "timer/agent.policy_total": 13.903050184249878, "timer/agent.policy_frac": 0.01390139891453638, "timer/agent.policy_avg": 0.010089296214985397, "timer/agent.policy_min": 0.008733034133911133, "timer/agent.policy_max": 0.03592538833618164, "timer/dataset_train_count": 2178.0, "timer/dataset_train_total": 0.3732588291168213, "timer/dataset_train_frac": 0.0003732144970464016, "timer/dataset_train_avg": 0.00017137687287273706, "timer/dataset_train_min": 8.96453857421875e-05, "timer/dataset_train_max": 0.0005671977996826172, "timer/agent.train_count": 2178.0, "timer/agent.train_total": 970.0927629470825, "timer/agent.train_frac": 0.9699775447196066, "timer/agent.train_avg": 0.44540530897478536, "timer/agent.train_min": 0.435361385345459, "timer/agent.train_max": 0.5905084609985352, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47609663009643555, "timer/agent.report_frac": 0.0004760400839475288, "timer/agent.report_avg": 0.23804831504821777, "timer/agent.report_min": 0.23044586181640625, "timer/agent.report_max": 0.2456507682800293, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 0.0001227855682373047, "timer/dataset_eval_frac": 1.2277098495612553e-07, "timer/dataset_eval_avg": 0.0001227855682373047, "timer/dataset_eval_min": 0.0001227855682373047, "timer/dataset_eval_max": 0.0001227855682373047, "fps": 8.710850408923971}
{"step": 71128, "time": 8241.926056146622, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 71424, "time": 8275.528533220291, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 71632, "time": 8299.194890260696, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 71672, "time": 8303.734418869019, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 71760, "time": 8313.752169847488, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 72384, "time": 8384.62653207779, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 72496, "time": 8397.373646974564, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 72976, "time": 8451.935158491135, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 73056, "time": 8461.000446081161, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 73440, "time": 8504.648839712143, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 73576, "time": 8520.045993328094, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 73736, "time": 8538.565707206726, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 73952, "time": 8563.091392040253, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 73984, "time": 8566.726881980896, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 74040, "time": 8573.083055734634, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 74072, "time": 8576.705321073532, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 74144, "time": 8584.855957746506, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 74272, "time": 8599.43974518776, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 74424, "time": 8616.661706447601, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 74520, "time": 8627.61498427391, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 74696, "time": 8647.596362113953, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 74808, "time": 8660.41284608841, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 74968, "time": 8678.622854709625, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 75368, "time": 8724.448660373688, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 76296, "time": 8830.20465350151, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 76384, "time": 8840.30791258812, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 76424, "time": 8844.854701757431, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 76456, "time": 8848.50065612793, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 76832, "time": 8891.33032989502, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 77008, "time": 8911.30422782898, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 77120, "time": 8924.082902431488, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 77680, "time": 8987.75007033348, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 77728, "time": 8993.183624267578, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 78608, "time": 9093.19590139389, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 78696, "time": 9103.226255893707, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 78736, "time": 9107.752602100372, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 78768, "time": 9111.393659114838, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 79144, "time": 9154.068743944168, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 79432, "time": 9186.76863527298, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 79648, "time": 9211.320809602737, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 79841, "time": 9234.567136526108, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.92163613059304, "train/action_min": 0.0, "train/action_std": 1.5965422635728663, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.008473532215628604, "train/actor_opt_grad_steps": 18475.0, "train/actor_opt_loss": 4.974746144359762, "train/adv_mag": 0.3836642581630837, "train/adv_max": 0.28372408497062596, "train/adv_mean": 0.010852748647762795, "train/adv_min": -0.2729241453111172, "train/adv_std": 0.0299316821556369, "train/cont_avg": 0.9962491122159091, "train/cont_loss_mean": 0.0047130944544650525, "train/cont_loss_std": 0.10311030151814603, "train/cont_neg_acc": 0.7775313545307613, "train/cont_neg_loss": 1.0193840786095731, "train/cont_pos_acc": 0.9999331615187905, "train/cont_pos_loss": 0.0008770862069716465, "train/cont_pred": 0.9963251693682237, "train/cont_rate": 0.9962491122159091, "train/dyn_loss_mean": 1.0000057437203147, "train/dyn_loss_std": 0.0001837385016187909, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8937640208666298, "train/extr_critic_critic_opt_grad_steps": 18475.0, "train/extr_critic_critic_opt_loss": 5864.385035844282, "train/extr_critic_mag": 0.3321454541249709, "train/extr_critic_max": 0.3321454541249709, "train/extr_critic_mean": 0.31216201050715014, "train/extr_critic_min": 0.29456620920788157, "train/extr_critic_std": 0.005912106083071029, "train/extr_return_normed_mag": 0.398001930591735, "train/extr_return_normed_max": 0.31420491859316824, "train/extr_return_normed_mean": 0.031151073219701755, "train/extr_return_normed_min": -0.25067106878215617, "train/extr_return_normed_std": 0.03154006679542363, "train/extr_return_rate": 0.0304681599777475, "train/extr_return_raw_mag": 0.6060685897415334, "train/extr_return_raw_max": 0.6060685897415334, "train/extr_return_raw_mean": 0.3230147604915229, "train/extr_return_raw_min": 0.04119260263713923, "train/extr_return_raw_std": 0.031540066926655445, "train/extr_reward_mag": 0.30217135656963695, "train/extr_reward_max": 0.30217135656963695, "train/extr_reward_mean": 0.002203396911570301, "train/extr_reward_min": -0.00010412335395812989, "train/extr_reward_std": 0.014666240343517116, "train/image_loss_mean": 0.07880233871665868, "train/image_loss_std": 0.088522911274975, "train/model_loss_mean": 0.6847104885361411, "train/model_loss_std": 0.17729029760441997, "train/model_opt_grad_norm": 33.163743170824915, "train/model_opt_grad_steps": 18456.677272727273, "train/model_opt_loss": 2045.0163973721592, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3000.0, "train/policy_entropy_mag": 1.544626691124656, "train/policy_entropy_max": 1.544626691124656, "train/policy_entropy_mean": 0.2107205168428746, "train/policy_entropy_min": 0.06469712257385254, "train/policy_entropy_std": 0.23818481557748533, "train/policy_logprob_mag": 6.5510267626155505, "train/policy_logprob_max": -0.008609955393793908, "train/policy_logprob_mean": -0.21070613309063696, "train/policy_logprob_min": -6.5510267626155505, "train/policy_logprob_std": 0.7375292913480238, "train/policy_randomness_mag": 0.7937811434268951, "train/policy_randomness_max": 0.7937811434268951, "train/policy_randomness_mean": 0.1082889317280867, "train/policy_randomness_min": 0.03324774596840143, "train/policy_randomness_std": 0.12240278910506855, "train/post_ent_mag": 40.78484205766158, "train/post_ent_max": 40.78484205766158, "train/post_ent_mean": 40.38066407983953, "train/post_ent_min": 40.13188740123402, "train/post_ent_std": 0.11146301061592319, "train/prior_ent_mag": 43.233625238591976, "train/prior_ent_max": 43.233625238591976, "train/prior_ent_mean": 40.805280737443404, "train/prior_ent_min": 38.64699771187522, "train/prior_ent_std": 0.7690051718191667, "train/rep_loss_mean": 1.0000057437203147, "train/rep_loss_std": 0.0001837385016187909, "train/reward_avg": 0.0001500632535846142, "train/reward_loss_mean": 0.001191584004184485, "train/reward_loss_std": 0.03035384850554692, "train/reward_max_data": 0.11535511301322417, "train/reward_max_pred": 0.05420928489078175, "train/reward_neg_acc": 0.9999778053977273, "train/reward_neg_loss": 0.00013345864930339635, "train/reward_pos_acc": 0.43790849692681255, "train/reward_pos_loss": 3.4320566946384954, "train/reward_pred": 9.906640890139071e-05, "train/reward_rate": 0.00029740767045454547, "train_stats/mean_log_entropy": 0.1957527047023177, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.0038423447404056787, "report/cont_loss_std": 0.10600034892559052, "report/cont_neg_acc": 0.5, "report/cont_neg_loss": 1.6989076137542725, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0005251916591078043, "report/cont_pred": 0.9984729290008545, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.06587469577789307, "report/image_loss_std": 0.0805613249540329, "report/model_loss_mean": 0.6704779863357544, "report/model_loss_std": 0.13587868213653564, "report/post_ent_mag": 40.22987365722656, "report/post_ent_max": 40.22987365722656, "report/post_ent_mean": 39.79550552368164, "report/post_ent_min": 39.5048713684082, "report/post_ent_std": 0.1325005292892456, "report/prior_ent_mag": 42.596439361572266, "report/prior_ent_max": 42.596439361572266, "report/prior_ent_mean": 39.9281005859375, "report/prior_ent_min": 37.418304443359375, "report/prior_ent_std": 0.7939579486846924, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0001220703125, "report/reward_loss_mean": 0.0007608994492329657, "report/reward_loss_std": 0.021642539650201797, "report/reward_max_data": 0.125, "report/reward_max_pred": 0.10802209377288818, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 8.451297617284581e-05, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6927042603492737, "report/reward_pred": 0.00014726514928042889, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.05496572330594063, "eval/cont_loss_std": 0.8318752646446228, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 13.294923782348633, "eval/cont_pos_acc": 0.9980391263961792, "eval/cont_pos_loss": 0.0030443244613707066, "eval/cont_pred": 0.9982001781463623, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.22205503284931183, "eval/image_loss_std": 0.14793545007705688, "eval/model_loss_mean": 0.877030074596405, "eval/model_loss_std": 0.8369362354278564, "eval/post_ent_mag": 40.232608795166016, "eval/post_ent_max": 40.232608795166016, "eval/post_ent_mean": 39.74195861816406, "eval/post_ent_min": 39.461212158203125, "eval/post_ent_std": 0.13013018667697906, "eval/prior_ent_mag": 42.49170684814453, "eval/prior_ent_max": 42.49170684814453, "eval/prior_ent_mean": 39.678062438964844, "eval/prior_ent_min": 37.39008712768555, "eval/prior_ent_std": 0.7828813791275024, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 9.327195584774017e-06, "eval/reward_loss_std": 5.695584331988357e-05, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0005954504013061523, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 9.327195584774017e-06, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 4.200148396193981e-06, "eval/reward_rate": 0.0, "replay/size": 79337.0, "replay/inserts": 8784.0, "replay/samples": 35136.0, "replay/insert_wait_avg": 1.5468436729278286e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.617099037587316e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 19552.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 1.2069940567016602e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1197636127472, "timer/env.step_count": 1098.0, "timer/env.step_total": 11.099688529968262, "timer/env.step_frac": 0.011098359350356897, "timer/env.step_avg": 0.01010900594714778, "timer/env.step_min": 0.008967876434326172, "timer/env.step_max": 0.034694671630859375, "timer/replay._sample_count": 35136.0, "timer/replay._sample_total": 18.991184949874878, "timer/replay._sample_frac": 0.01898891076931901, "timer/replay._sample_avg": 0.0005405050361417031, "timer/replay._sample_min": 0.00035452842712402344, "timer/replay._sample_max": 0.02539801597595215, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1098.0, "timer/agent.policy_total": 11.367795705795288, "timer/agent.policy_frac": 0.01136643442054503, "timer/agent.policy_avg": 0.010353183702910098, "timer/agent.policy_min": 0.009434938430786133, "timer/agent.policy_max": 0.0367283821105957, "timer/dataset_train_count": 2196.0, "timer/dataset_train_total": 0.36925697326660156, "timer/dataset_train_frac": 0.00036921275501318885, "timer/dataset_train_avg": 0.00016814980567695883, "timer/dataset_train_min": 8.678436279296875e-05, "timer/dataset_train_max": 0.0011959075927734375, "timer/agent.train_count": 2196.0, "timer/agent.train_total": 974.7932121753693, "timer/agent.train_frac": 0.9746764813986972, "timer/agent.train_avg": 0.44389490536219, "timer/agent.train_min": 0.4327373504638672, "timer/agent.train_max": 0.5765957832336426, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47294092178344727, "timer/agent.report_frac": 0.00047288428745277054, "timer/agent.report_avg": 0.23647046089172363, "timer/agent.report_min": 0.2288370132446289, "timer/agent.report_max": 0.24410390853881836, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9087066650390625e-05, "timer/dataset_eval_frac": 2.9083583495359585e-08, "timer/dataset_eval_avg": 2.9087066650390625e-05, "timer/dataset_eval_min": 2.9087066650390625e-05, "timer/dataset_eval_max": 2.9087066650390625e-05, "fps": 8.782832700811689}
{"step": 79992, "time": 9251.493624448776, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 80040, "time": 9256.952048301697, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 80080, "time": 9266.62379860878, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 9266.631302595139, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 9266.636636018753, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 9266.642073392868, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 9266.647341489792, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 9266.652793169022, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 9266.658920764923, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 9266.665045022964, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 81008, "time": 9372.114400148392, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 81048, "time": 9376.664160013199, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 81080, "time": 9380.311004638672, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 81456, "time": 9423.060967683792, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 81664, "time": 9446.735615253448, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 81744, "time": 9455.811155796051, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 81960, "time": 9480.729284763336, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 82304, "time": 9519.79934310913, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 82352, "time": 9525.334555625916, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 82376, "time": 9528.121012687683, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 83096, "time": 9610.567732095718, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 83320, "time": 9636.179663658142, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 83392, "time": 9644.465067386627, "episode/length": 215.0, "episode/score": 0.328125, "episode/reward_rate": 0.004629629629629629, "episode/intrinsic_return": 0.0}
{"step": 83392, "time": 9644.47206735611, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 84056, "time": 9720.416061401367, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 84272, "time": 9745.086622953415, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 84616, "time": 9784.402650117874, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 84664, "time": 9789.887692213058, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 85328, "time": 9865.855883598328, "episode/length": 278.0, "episode/score": 0.13124999403953552, "episode/reward_rate": 0.0035842293906810036, "episode/intrinsic_return": 0.0}
{"step": 85328, "time": 9865.86938738823, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 85632, "time": 9900.60795044899, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 85704, "time": 9908.860169410706, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 85704, "time": 9908.86750292778, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 86056, "time": 9949.194475412369, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 86368, "time": 9984.91662144661, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 86672, "time": 10019.605988264084, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 86928, "time": 10048.84063410759, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 86976, "time": 10054.336398363113, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 87200, "time": 10080.032005310059, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 87640, "time": 10130.29150557518, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 87640, "time": 10130.301656723022, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 87800, "time": 10148.512851715088, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 87808, "time": 10149.432915687561, "episode/length": 20.0, "episode/score": 0.9375, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.0}
{"step": 87944, "time": 10164.978062152863, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 88545, "time": 10234.574273586273, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.6974881079889115, "train/action_min": 0.0, "train/action_std": 1.4111245878830483, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.01078457104188094, "train/actor_opt_grad_steps": 20660.0, "train/actor_opt_loss": -2.701265838289041, "train/adv_mag": 0.5040922626372306, "train/adv_max": 0.31144699344437243, "train/adv_mean": 0.006354608546220845, "train/adv_min": -0.41877705188390846, "train/adv_std": 0.036934465504667724, "train/cont_avg": 0.996498775921659, "train/cont_loss_mean": 0.005392618018322118, "train/cont_loss_std": 0.11298547162806341, "train/cont_neg_acc": 0.7166554960706424, "train/cont_neg_loss": 1.1973660974656928, "train/cont_pos_acc": 0.9999096503455518, "train/cont_pos_loss": 0.0010877800463620479, "train/cont_pred": 0.9965492830298464, "train/cont_rate": 0.996498775921659, "train/dyn_loss_mean": 1.0000160146968156, "train/dyn_loss_std": 0.00042517179666030165, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.5689182286815984, "train/extr_critic_critic_opt_grad_steps": 20660.0, "train/extr_critic_critic_opt_loss": 9560.471644810268, "train/extr_critic_mag": 0.5241722939750566, "train/extr_critic_max": 0.5241722939750566, "train/extr_critic_mean": 0.4847855616000391, "train/extr_critic_min": 0.4520996177251438, "train/extr_critic_std": 0.012796431322783781, "train/extr_return_normed_mag": 0.5142316358155369, "train/extr_return_normed_max": 0.36816949187885234, "train/extr_return_normed_mean": 0.035059068643827046, "train/extr_return_normed_min": -0.37585214645631854, "train/extr_return_normed_std": 0.04023692709681351, "train/extr_return_rate": 0.6003267484334363, "train/extr_return_raw_mag": 0.824250607995943, "train/extr_return_raw_max": 0.824250607995943, "train/extr_return_raw_mean": 0.4911402108207826, "train/extr_return_raw_min": 0.08022897103415107, "train/extr_return_raw_std": 0.04023692716870131, "train/extr_reward_mag": 0.3611294146507017, "train/extr_reward_max": 0.3611294146507017, "train/extr_reward_mean": 0.003026716647842217, "train/extr_reward_min": -1.8542263365011612e-05, "train/extr_reward_std": 0.01807455635066764, "train/image_loss_mean": 0.07297863303104304, "train/image_loss_std": 0.08829125113064243, "train/model_loss_mean": 0.6797866527385975, "train/model_loss_std": 0.18606383370638993, "train/model_opt_grad_norm": 30.200140357017517, "train/model_opt_grad_steps": 20639.90783410138, "train/model_opt_loss": 1888.845476985527, "train/model_opt_model_opt_grad_overflow": 0.004608294930875576, "train/model_opt_model_opt_grad_scale": 2776.4976958525344, "train/policy_entropy_mag": 1.3306492446205034, "train/policy_entropy_max": 1.3306492446205034, "train/policy_entropy_mean": 0.13881980456102827, "train/policy_entropy_min": 0.06468694605585616, "train/policy_entropy_std": 0.16831438061416423, "train/policy_logprob_mag": 6.55107920070947, "train/policy_logprob_max": -0.008608308088566576, "train/policy_logprob_mean": -0.13878824448530575, "train/policy_logprob_min": -6.55107920070947, "train/policy_logprob_std": 0.6699858096338087, "train/policy_randomness_mag": 0.6838184803861627, "train/policy_randomness_max": 0.6838184803861627, "train/policy_randomness_mean": 0.07133927191114096, "train/policy_randomness_min": 0.03324251649429172, "train/policy_randomness_std": 0.08649648648733917, "train/post_ent_mag": 40.426791037282634, "train/post_ent_max": 40.426791037282634, "train/post_ent_mean": 39.91881345054521, "train/post_ent_min": 39.56884229457873, "train/post_ent_std": 0.15659036562876769, "train/prior_ent_mag": 42.23323744672784, "train/prior_ent_max": 42.23323744672784, "train/prior_ent_mean": 39.49908638879451, "train/prior_ent_min": 37.48594067832841, "train/prior_ent_std": 0.7687607212550079, "train/rep_loss_mean": 1.0000160146968156, "train/rep_loss_std": 0.00042517179666030165, "train/reward_avg": 0.00018330235700128377, "train/reward_loss_mean": 0.0014057664400769167, "train/reward_loss_std": 0.037719350110538695, "train/reward_max_data": 0.16638824951401504, "train/reward_max_pred": 0.08178508116902294, "train/reward_neg_acc": 0.999923473129624, "train/reward_neg_loss": 0.00024210356743491258, "train/reward_pos_acc": 0.4410256413313059, "train/reward_pos_loss": 3.449713949056772, "train/reward_pred": 0.00016407988920447326, "train/reward_rate": 0.0003375216013824885, "train_stats/mean_log_entropy": 0.13287626765668392, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.006814178079366684, "report/cont_loss_std": 0.19965335726737976, "report/cont_neg_acc": 0.800000011920929, "report/cont_neg_loss": 1.2789033651351929, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0005723261274397373, "report/cont_pred": 0.9955267310142517, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.08162471652030945, "report/image_loss_std": 0.10042315721511841, "report/model_loss_mean": 0.689349353313446, "report/model_loss_std": 0.23104996979236603, "report/post_ent_mag": 40.78705978393555, "report/post_ent_max": 40.78705978393555, "report/post_ent_mean": 40.24872589111328, "report/post_ent_min": 39.82215881347656, "report/post_ent_std": 0.19330696761608124, "report/prior_ent_mag": 41.57151794433594, "report/prior_ent_max": 41.57151794433594, "report/prior_ent_mean": 39.006195068359375, "report/prior_ent_min": 37.32509231567383, "report/prior_ent_std": 0.7208139896392822, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0004241943242959678, "report/reward_loss_mean": 0.0009104675846174359, "report/reward_loss_std": 0.02501502074301243, "report/reward_max_data": 0.43437498807907104, "report/reward_max_pred": 0.37460947036743164, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00012928625801578164, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.8000589609146118, "report/reward_pred": 0.000429541221819818, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.01332871988415718, "eval/cont_loss_std": 0.4170287549495697, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 13.351564407348633, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0002903649292420596, "eval/cont_pred": 0.9997120499610901, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.26848646998405457, "eval/image_loss_std": 0.1531883031129837, "eval/model_loss_mean": 0.8818287253379822, "eval/model_loss_std": 0.43679139018058777, "eval/post_ent_mag": 40.77959060668945, "eval/post_ent_max": 40.77959060668945, "eval/post_ent_mean": 40.16404724121094, "eval/post_ent_min": 39.85365295410156, "eval/post_ent_std": 0.15705010294914246, "eval/prior_ent_mag": 41.57151794433594, "eval/prior_ent_max": 41.57151794433594, "eval/prior_ent_mean": 38.85755920410156, "eval/prior_ent_min": 37.5100212097168, "eval/prior_ent_std": 0.6794239282608032, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 1.3500917702913284e-05, "eval/reward_loss_std": 0.00013223063433542848, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.001015782356262207, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 1.3500917702913284e-05, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 6.0729216784238815e-06, "eval/reward_rate": 0.0, "replay/size": 88041.0, "replay/inserts": 8704.0, "replay/samples": 34816.0, "replay/insert_wait_avg": 1.5369561665198382e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.655882440945681e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 21864.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0547340947451476e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.599592208862305e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4399576187134, "timer/env.step_count": 1088.0, "timer/env.step_total": 10.999980211257935, "timer/env.step_frac": 0.010995142814407895, "timer/env.step_avg": 0.010110275929465014, "timer/env.step_min": 0.008951663970947266, "timer/env.step_max": 0.0413966178894043, "timer/replay._sample_count": 34816.0, "timer/replay._sample_total": 19.326195001602173, "timer/replay._sample_frac": 0.019317696034056, "timer/replay._sample_avg": 0.0005550952148897683, "timer/replay._sample_min": 0.00038743019104003906, "timer/replay._sample_max": 0.013016223907470703, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1377.0, "timer/agent.policy_total": 14.006346702575684, "timer/agent.policy_frac": 0.01400018721354767, "timer/agent.policy_avg": 0.010171638854448571, "timer/agent.policy_min": 0.008580446243286133, "timer/agent.policy_max": 0.03643608093261719, "timer/dataset_train_count": 2176.0, "timer/dataset_train_total": 0.36380958557128906, "timer/dataset_train_frac": 0.0003636495951613558, "timer/dataset_train_avg": 0.00016719190513386447, "timer/dataset_train_min": 8.916854858398438e-05, "timer/dataset_train_max": 0.0006685256958007812, "timer/agent.train_count": 2176.0, "timer/agent.train_total": 969.6126410961151, "timer/agent.train_frac": 0.9691862402257756, "timer/agent.train_avg": 0.4455940446213764, "timer/agent.train_min": 0.43500566482543945, "timer/agent.train_max": 0.6064474582672119, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4759542942047119, "timer/agent.report_frac": 0.0004757449865733043, "timer/agent.report_avg": 0.23797714710235596, "timer/agent.report_min": 0.23059558868408203, "timer/agent.report_max": 0.24535870552062988, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.266334533691406e-05, "timer/dataset_eval_frac": 3.264898116890557e-08, "timer/dataset_eval_avg": 3.266334533691406e-05, "timer/dataset_eval_min": 3.266334533691406e-05, "timer/dataset_eval_max": 3.266334533691406e-05, "fps": 8.700040542581045}
{"step": 88680, "time": 10249.922024965286, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 89184, "time": 10307.560727119446, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 89240, "time": 10313.967918872833, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 89288, "time": 10319.44839334488, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 89512, "time": 10345.039860010147, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 89616, "time": 10356.918436288834, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 89936, "time": 10393.574149370193, "episode/length": 266.0, "episode/score": 0.16875000298023224, "episode/reward_rate": 0.003745318352059925, "episode/intrinsic_return": 0.0}
{"step": 90064, "time": 10409.308386564255, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 90064, "time": 10410.845475435257, "eval_episode/length": 85.0, "eval_episode/score": 0.734375, "eval_episode/reward_rate": 0.011627906976744186}
{"step": 90064, "time": 10411.81987285614, "eval_episode/length": 53.0, "eval_episode/score": 0.8343750238418579, "eval_episode/reward_rate": 0.018518518518518517}
{"step": 90064, "time": 10413.877588033676, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 90064, "time": 10413.938622951508, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 10413.945034265518, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 10413.950642347336, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 10413.95638680458, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 10413.962070941925, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 10413.96756362915, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 10413.973133325577, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90120, "time": 10420.739639282227, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 90256, "time": 10436.261818647385, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 90512, "time": 10465.400404930115, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 90992, "time": 10520.383126735687, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 91552, "time": 10584.529270648956, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 91600, "time": 10589.997975111008, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 91824, "time": 10615.460842370987, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 91928, "time": 10627.237874031067, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 92056, "time": 10641.801838636398, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 92248, "time": 10663.675312757492, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 92360, "time": 10676.37389588356, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 92432, "time": 10684.55182647705, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 92824, "time": 10729.201304197311, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 93304, "time": 10783.863737821579, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 93864, "time": 10847.65604543686, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 94240, "time": 10890.210029125214, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 94368, "time": 10904.822016477585, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 94560, "time": 10926.54897403717, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 94672, "time": 10939.39387345314, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 94744, "time": 10947.627055883408, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 95136, "time": 10992.32679605484, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 95320, "time": 11013.186657905579, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 95616, "time": 11046.742801904678, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 96176, "time": 11110.420063972473, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 96552, "time": 11153.28629732132, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 96680, "time": 11167.841002464294, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 96984, "time": 11202.464781045914, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 97056, "time": 11210.669676542282, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 97261, "time": 11234.978157520294, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.773475576978211, "train/action_min": 0.0, "train/action_std": 1.5893988718680285, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0034788898104233584, "train/actor_opt_grad_steps": 22835.0, "train/actor_opt_loss": -5.264014443673125, "train/adv_mag": 0.39199977347610193, "train/adv_max": 0.15046112922900315, "train/adv_mean": -0.0009663140362263137, "train/adv_min": -0.3545830385127199, "train/adv_std": 0.01237906978055493, "train/cont_avg": 0.9964162844036697, "train/cont_loss_mean": 0.005825153498327223, "train/cont_loss_std": 0.11652820447188537, "train/cont_neg_acc": 0.7005606590334429, "train/cont_neg_loss": 1.2819882332662453, "train/cont_pos_acc": 0.9999189871713656, "train/cont_pos_loss": 0.0012690988885945803, "train/cont_pred": 0.9963419604192086, "train/cont_rate": 0.9964162844036697, "train/dyn_loss_mean": 1.0000071711496477, "train/dyn_loss_std": 0.00021382429691509453, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.1742623805692163, "train/extr_critic_critic_opt_grad_steps": 22835.0, "train/extr_critic_critic_opt_loss": 13373.5870350129, "train/extr_critic_mag": 0.5283135547550446, "train/extr_critic_max": 0.5283135547550446, "train/extr_critic_mean": 0.47258150140079885, "train/extr_critic_min": 0.4468848803721437, "train/extr_critic_std": 0.009111798641810177, "train/extr_return_normed_mag": 0.3968457050553156, "train/extr_return_normed_max": 0.19534108958659915, "train/extr_return_normed_mean": 0.013327790924633369, "train/extr_return_normed_min": -0.33517964922506877, "train/extr_return_normed_std": 0.01593591225624016, "train/extr_return_rate": 0.045453461657491576, "train/extr_return_raw_mag": 0.6536285257940992, "train/extr_return_raw_max": 0.6536285257940992, "train/extr_return_raw_mean": 0.4716152528283793, "train/extr_return_raw_min": 0.12310778725584713, "train/extr_return_raw_std": 0.015935912181478027, "train/extr_reward_mag": 0.22309772847989284, "train/extr_reward_max": 0.22309772847989284, "train/extr_reward_mean": 0.00047729933810325013, "train/extr_reward_min": 3.915314280658687e-07, "train/extr_reward_std": 0.004728021930156643, "train/image_loss_mean": 0.06635503611023273, "train/image_loss_std": 0.08609790395979487, "train/model_loss_mean": 0.6735162740453667, "train/model_loss_std": 0.18376803070033362, "train/model_opt_grad_norm": 28.841073989868164, "train/model_opt_grad_steps": 22813.596330275228, "train/model_opt_loss": 3111.3184786455345, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 4621.559633027523, "train/policy_entropy_mag": 1.3023490211285582, "train/policy_entropy_max": 1.3023490211285582, "train/policy_entropy_mean": 0.11003519809984286, "train/policy_entropy_min": 0.06468665839061824, "train/policy_entropy_std": 0.14199524007122452, "train/policy_logprob_mag": 6.551080071598018, "train/policy_logprob_max": -0.0086082573980093, "train/policy_logprob_mean": -0.11031528384587087, "train/policy_logprob_min": -6.551080071598018, "train/policy_logprob_std": 0.6501223986301947, "train/policy_randomness_mag": 0.6692750434809869, "train/policy_randomness_max": 0.6692750434809869, "train/policy_randomness_mean": 0.056546908982713286, "train/policy_randomness_min": 0.03324236847255208, "train/policy_randomness_std": 0.0729711226982261, "train/post_ent_mag": 39.48868422551986, "train/post_ent_max": 39.48868422551986, "train/post_ent_mean": 38.796438374650585, "train/post_ent_min": 38.28192472895351, "train/post_ent_std": 0.24808764587575144, "train/prior_ent_mag": 41.4350375429206, "train/prior_ent_max": 41.4350375429206, "train/prior_ent_mean": 38.3725581212875, "train/prior_ent_min": 36.53222229283884, "train/prior_ent_std": 0.8050779806911399, "train/rep_loss_mean": 1.0000071711496477, "train/rep_loss_std": 0.00021382429691509453, "train/reward_avg": 0.0001806836612517262, "train/reward_loss_mean": 0.0013317583374990955, "train/reward_loss_std": 0.03392475846820562, "train/reward_max_data": 0.15989105492283445, "train/reward_max_pred": 0.08770818010382696, "train/reward_neg_acc": 0.9999148517573645, "train/reward_neg_loss": 0.0002920761589514793, "train/reward_pos_acc": 0.46153846153846156, "train/reward_pos_loss": 2.9987713052676273, "train/reward_pred": 0.00019574180403467985, "train/reward_rate": 0.00034941227064220185, "train_stats/mean_log_entropy": 0.10034034869500569, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.00045274803414940834, "report/cont_loss_std": 0.0016578981885686517, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 9.573608258506283e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.00045379699440672994, "report/cont_pred": 0.9966195821762085, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.05598899722099304, "report/image_loss_std": 0.08814319223165512, "report/model_loss_mean": 0.656522274017334, "report/model_loss_std": 0.08873556554317474, "report/post_ent_mag": 39.148834228515625, "report/post_ent_max": 39.148834228515625, "report/post_ent_mean": 38.33972930908203, "report/post_ent_min": 37.76898193359375, "report/post_ent_std": 0.2575930953025818, "report/prior_ent_mag": 40.73466491699219, "report/prior_ent_max": 40.73466491699219, "report/prior_ent_mean": 36.61341857910156, "report/prior_ent_min": 34.786773681640625, "report/prior_ent_std": 0.9441959261894226, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 8.053658530116081e-05, "report/reward_loss_std": 0.0008118907571770251, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.007571220397949219, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 8.053658530116081e-05, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 3.0841678380966187e-05, "report/reward_rate": 0.0, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.025113213807344437, "eval/cont_loss_std": 0.504037618637085, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 11.29688835144043, "eval/cont_pos_acc": 0.9990215301513672, "eval/cont_pos_loss": 0.0030549466609954834, "eval/cont_pred": 0.9983962178230286, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2449745088815689, "eval/image_loss_std": 0.16174601018428802, "eval/model_loss_mean": 0.8701448440551758, "eval/model_loss_std": 0.5260247588157654, "eval/post_ent_mag": 39.165306091308594, "eval/post_ent_max": 39.165306091308594, "eval/post_ent_mean": 38.29330825805664, "eval/post_ent_min": 37.79066467285156, "eval/post_ent_std": 0.2501783072948456, "eval/prior_ent_mag": 40.73466491699219, "eval/prior_ent_max": 40.73466491699219, "eval/prior_ent_mean": 36.53105163574219, "eval/prior_ent_min": 34.38904571533203, "eval/prior_ent_std": 1.009663462638855, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 5.707377567887306e-05, "eval/reward_loss_std": 0.0004819933383259922, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.003587007522583008, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 5.707377567887306e-05, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 2.1790037862956524e-05, "eval/reward_rate": 0.0, "replay/size": 96757.0, "replay/inserts": 8716.0, "replay/samples": 34864.0, "replay/insert_wait_avg": 1.5647108262698002e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.646436152954942e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 24176.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1066045728109288e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.98377799987793e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3969678878784, "timer/env.step_count": 1089.0, "timer/env.step_total": 11.016040325164795, "timer/env.step_frac": 0.011011669046161524, "timer/env.step_avg": 0.010115739508874927, "timer/env.step_min": 0.008849143981933594, "timer/env.step_max": 0.04194808006286621, "timer/replay._sample_count": 34864.0, "timer/replay._sample_total": 18.982670545578003, "timer/replay._sample_frac": 0.018975138025113972, "timer/replay._sample_avg": 0.0005444777003665099, "timer/replay._sample_min": 0.0003757476806640625, "timer/replay._sample_max": 0.030606985092163086, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1378.0, "timer/agent.policy_total": 14.422799825668335, "timer/agent.policy_frac": 0.014417076709177712, "timer/agent.policy_avg": 0.010466473022981376, "timer/agent.policy_min": 0.008936882019042969, "timer/agent.policy_max": 0.08180403709411621, "timer/dataset_train_count": 2179.0, "timer/dataset_train_total": 0.37005615234375, "timer/dataset_train_frac": 0.000369909310226163, "timer/dataset_train_avg": 0.00016982843154830196, "timer/dataset_train_min": 8.702278137207031e-05, "timer/dataset_train_max": 0.005437612533569336, "timer/agent.train_count": 2179.0, "timer/agent.train_total": 969.5653796195984, "timer/agent.train_frac": 0.969180646025573, "timer/agent.train_avg": 0.44495887086718605, "timer/agent.train_min": 0.4317619800567627, "timer/agent.train_max": 0.578209638595581, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4734773635864258, "timer/agent.report_frac": 0.00047328948286005977, "timer/agent.report_avg": 0.2367386817932129, "timer/agent.report_min": 0.2299058437347412, "timer/agent.report_max": 0.24357151985168457, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7179718017578125e-05, "timer/dataset_eval_frac": 2.716893282369919e-08, "timer/dataset_eval_avg": 2.7179718017578125e-05, "timer/dataset_eval_min": 2.7179718017578125e-05, "timer/dataset_eval_max": 2.7179718017578125e-05, "fps": 8.712426803344494}
{"step": 97448, "time": 11256.072962999344, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 97600, "time": 11273.414719343185, "episode/length": 247.0, "episode/score": 0.22812500596046448, "episode/reward_rate": 0.004032258064516129, "episode/intrinsic_return": 0.0}
{"step": 97632, "time": 11277.083844423294, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 98184, "time": 11340.081531763077, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 98488, "time": 11375.364238500595, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 98864, "time": 11418.373983860016, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 98992, "time": 11432.965303182602, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 99096, "time": 11444.925156116486, "episode/length": 263.0, "episode/score": 0.17812499403953552, "episode/reward_rate": 0.003787878787878788, "episode/intrinsic_return": 0.0}
{"step": 99120, "time": 11447.661137580872, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 99760, "time": 11520.507534503937, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 99912, "time": 11537.882853269577, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 99944, "time": 11541.518708229065, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 100048, "time": 11554.941773891449, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 100048, "time": 11556.32953619957, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 100048, "time": 11556.564271688461, "eval_episode/length": 181.0, "eval_episode/score": 0.43437498807907104, "eval_episode/reward_rate": 0.005494505494505495}
{"step": 100048, "time": 11558.441008806229, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 11558.449647903442, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 11558.45530128479, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 11558.460852861404, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 11558.466434001923, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 11558.47169971466, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100496, "time": 11609.490404367447, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 100800, "time": 11644.083890914917, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 101304, "time": 11701.418551921844, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 101408, "time": 11713.227796792984, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 101432, "time": 11715.966801166534, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 102072, "time": 11789.043361663818, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 102128, "time": 11795.4151699543, "episode/length": 276.0, "episode/score": 0.13750000298023224, "episode/reward_rate": 0.0036101083032490976, "episode/intrinsic_return": 0.0}
{"step": 102256, "time": 11810.02926158905, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 102808, "time": 11872.845999479294, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 103112, "time": 11907.486300945282, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 103184, "time": 11915.658828735352, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 103352, "time": 11934.832645654678, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 103616, "time": 11964.853247642517, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 103720, "time": 11976.696065425873, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 103744, "time": 11979.410246133804, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 103968, "time": 12004.964498758316, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 104120, "time": 12022.295413255692, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 104440, "time": 12058.698073863983, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 104664, "time": 12084.154774188995, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 105120, "time": 12135.985365867615, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 105424, "time": 12170.592797994614, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 105496, "time": 12178.802864074707, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 105664, "time": 12197.97507762909, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 105981, "time": 12234.99709033966, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.1746915764764907, "train/action_min": 0.0, "train/action_std": 1.0588341828333128, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.002875958753850123, "train/actor_opt_grad_steps": 25015.0, "train/actor_opt_loss": -5.609585041846704, "train/adv_mag": 0.31663229692419737, "train/adv_max": 0.12339143263637473, "train/adv_mean": -0.0020818554380172658, "train/adv_min": -0.28999720500149856, "train/adv_std": 0.009123195552826781, "train/cont_avg": 0.9963042932912844, "train/cont_loss_mean": 0.00668072674734253, "train/cont_loss_std": 0.12985400843098674, "train/cont_neg_acc": 0.6620296964904776, "train/cont_neg_loss": 1.3792374201519426, "train/cont_pos_acc": 0.9999370610495226, "train/cont_pos_loss": 0.0014426338138195489, "train/cont_pred": 0.996289496301511, "train/cont_rate": 0.9963042932912844, "train/dyn_loss_mean": 1.0000177906193863, "train/dyn_loss_std": 0.0002460379637841887, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.10303090073578401, "train/extr_critic_critic_opt_grad_steps": 25015.0, "train/extr_critic_critic_opt_loss": 7871.322290263045, "train/extr_critic_mag": 0.4595304049483133, "train/extr_critic_max": 0.4595304049483133, "train/extr_critic_mean": 0.4048127779446611, "train/extr_critic_min": 0.38547264435969364, "train/extr_critic_std": 0.0067698522780620315, "train/extr_return_normed_mag": 0.3230424643656529, "train/extr_return_normed_max": 0.1548153085446139, "train/extr_return_normed_mean": 0.0058565690809316935, "train/extr_return_normed_min": -0.27781925876753044, "train/extr_return_normed_std": 0.012008050999202586, "train/extr_return_rate": 0.0016921111333147631, "train/extr_return_raw_mag": 0.5516896526747888, "train/extr_return_raw_max": 0.5516896526747888, "train/extr_return_raw_mean": 0.4027309328864474, "train/extr_return_raw_min": 0.11905508522593647, "train/extr_return_raw_std": 0.012008050979978037, "train/extr_reward_mag": 0.23456755909351035, "train/extr_reward_max": 0.23456755909351035, "train/extr_reward_mean": 0.0002765027178561426, "train/extr_reward_min": -9.069202143117922e-06, "train/extr_reward_std": 0.004559897542353068, "train/image_loss_mean": 0.06326677554517711, "train/image_loss_std": 0.08563396385913595, "train/model_loss_mean": 0.6720386841975221, "train/model_loss_std": 0.20391989878694947, "train/model_opt_grad_norm": 26.949804117920202, "train/model_opt_grad_steps": 24991.674311926607, "train/model_opt_loss": 2067.011764666356, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3073.394495412844, "train/policy_entropy_mag": 1.328247170929515, "train/policy_entropy_max": 1.328247170929515, "train/policy_entropy_mean": 0.12170594465841941, "train/policy_entropy_min": 0.0646869411367342, "train/policy_entropy_std": 0.15602649806426205, "train/policy_logprob_mag": 6.551079393526829, "train/policy_logprob_max": -0.008608255227771373, "train/policy_logprob_mean": -0.12167137116193771, "train/policy_logprob_min": -6.551079393526829, "train/policy_logprob_std": 0.6581905839640066, "train/policy_randomness_mag": 0.6825840585275528, "train/policy_randomness_max": 0.6825840585275528, "train/policy_randomness_mean": 0.06254448721168238, "train/policy_randomness_min": 0.03324251374178523, "train/policy_randomness_std": 0.08018176370394339, "train/post_ent_mag": 39.862369834829906, "train/post_ent_max": 39.862369834829906, "train/post_ent_mean": 39.02899336158683, "train/post_ent_min": 38.41153302323927, "train/post_ent_std": 0.31212785067634846, "train/prior_ent_mag": 41.063076071782945, "train/prior_ent_max": 41.063076071782945, "train/prior_ent_mean": 38.54398923401439, "train/prior_ent_min": 36.97510990527792, "train/prior_ent_std": 0.6474926321331514, "train/rep_loss_mean": 1.0000177906193863, "train/rep_loss_std": 0.0002460379637841887, "train/reward_avg": 0.00033206764769894197, "train/reward_loss_mean": 0.0020804856409886935, "train/reward_loss_std": 0.04965044337833715, "train/reward_max_data": 0.23911984087130345, "train/reward_max_pred": 0.15061307773677582, "train/reward_neg_acc": 0.999878965386557, "train/reward_neg_loss": 0.00036846504610716984, "train/reward_pos_acc": 0.48389513171120974, "train/reward_pos_loss": 2.9032169767979825, "train/reward_pred": 0.0002875885559852585, "train/reward_rate": 0.0005689148509174311, "train_stats/mean_log_entropy": 0.11560038839067732, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.012421337887644768, "report/cont_loss_std": 0.18924947082996368, "report/cont_neg_acc": 0.5714285969734192, "report/cont_neg_loss": 1.5129083395004272, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0020935034845024347, "report/cont_pred": 0.9940784573554993, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.06488089263439178, "report/image_loss_std": 0.08924981206655502, "report/model_loss_mean": 0.6898568868637085, "report/model_loss_std": 0.46472811698913574, "report/post_ent_mag": 40.229461669921875, "report/post_ent_max": 40.229461669921875, "report/post_ent_mean": 39.28178405761719, "report/post_ent_min": 38.562740325927734, "report/post_ent_std": 0.34798696637153625, "report/prior_ent_mag": 40.087890625, "report/prior_ent_max": 40.087890625, "report/prior_ent_mean": 37.822486877441406, "report/prior_ent_min": 36.30261993408203, "report/prior_ent_std": 0.6476293802261353, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0007141113746911287, "report/reward_loss_mean": 0.01255468837916851, "report/reward_loss_std": 0.27406078577041626, "report/reward_max_data": 0.4000000059604645, "report/reward_max_pred": 0.08927392959594727, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00048486172454431653, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 6.18023681640625, "report/reward_pred": 0.0002793100429698825, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.04052450507879257, "eval/cont_loss_std": 0.7391247153282166, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 13.674480438232422, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.00046390783973038197, "eval/cont_pred": 0.9995392560958862, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.21098704636096954, "eval/image_loss_std": 0.14491817355155945, "eval/model_loss_mean": 0.8515552282333374, "eval/model_loss_std": 0.7556305527687073, "eval/post_ent_mag": 39.97386169433594, "eval/post_ent_max": 39.97386169433594, "eval/post_ent_mean": 39.07341766357422, "eval/post_ent_min": 38.47260284423828, "eval/post_ent_std": 0.2394561916589737, "eval/prior_ent_mag": 40.087890625, "eval/prior_ent_max": 40.087890625, "eval/prior_ent_mean": 37.64194869995117, "eval/prior_ent_min": 35.68822479248047, "eval/prior_ent_std": 0.6514700651168823, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 4.3682754039764404e-05, "eval/reward_loss_std": 0.0003785488661378622, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.00285494327545166, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 4.3682754039764404e-05, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 2.1818210370838642e-05, "eval/reward_rate": 0.0, "replay/size": 105477.0, "replay/inserts": 8720.0, "replay/samples": 34880.0, "replay/insert_wait_avg": 1.5362960482956072e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.396170852381155e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 26488.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0861863726975596e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.599592208862305e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0009233951569, "timer/env.step_count": 1090.0, "timer/env.step_total": 10.901445865631104, "timer/env.step_frac": 0.010901435799298084, "timer/env.step_avg": 0.01000132648223037, "timer/env.step_min": 0.008782386779785156, "timer/env.step_max": 0.03719186782836914, "timer/replay._sample_count": 34880.0, "timer/replay._sample_total": 18.7118399143219, "timer/replay._sample_frac": 0.0187118226359155, "timer/replay._sample_avg": 0.000536463300295926, "timer/replay._sample_min": 0.0003559589385986328, "timer/replay._sample_max": 0.03379416465759277, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1379.0, "timer/agent.policy_total": 13.91148567199707, "timer/agent.policy_frac": 0.013911472826210438, "timer/agent.policy_avg": 0.010088096934008028, "timer/agent.policy_min": 0.008777856826782227, "timer/agent.policy_max": 0.036496639251708984, "timer/dataset_train_count": 2180.0, "timer/dataset_train_total": 0.37930822372436523, "timer/dataset_train_frac": 0.0003793078734733119, "timer/dataset_train_avg": 0.00017399459803869966, "timer/dataset_train_min": 9.179115295410156e-05, "timer/dataset_train_max": 0.0011131763458251953, "timer/agent.train_count": 2180.0, "timer/agent.train_total": 969.9867124557495, "timer/agent.train_frac": 0.9699858167755441, "timer/agent.train_avg": 0.44494803323658233, "timer/agent.train_min": 0.43515610694885254, "timer/agent.train_max": 0.5726029872894287, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47179222106933594, "timer/agent.report_frac": 0.0004717917854190862, "timer/agent.report_avg": 0.23589611053466797, "timer/agent.report_min": 0.22852158546447754, "timer/agent.report_max": 0.2432706356048584, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9802322387695312e-05, "timer/dataset_eval_frac": 2.9802294868400567e-08, "timer/dataset_eval_avg": 2.9802322387695312e-05, "timer/dataset_eval_min": 2.9802322387695312e-05, "timer/dataset_eval_max": 2.9802322387695312e-05, "fps": 8.719866864310712}
{"step": 106032, "time": 12240.635833263397, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 106432, "time": 12286.309740543365, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 106752, "time": 12323.200782060623, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 106896, "time": 12339.60491490364, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 106976, "time": 12348.737038850784, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 107432, "time": 12400.659772634506, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 107736, "time": 12435.380537748337, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 107808, "time": 12443.56819820404, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 107976, "time": 12462.790135622025, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 108744, "time": 12550.271821022034, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 109064, "time": 12586.730817079544, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 109208, "time": 12603.085983037949, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 109288, "time": 12612.221886873245, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 109744, "time": 12664.066608905792, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 110032, "time": 12701.978027820587, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 12701.985951185226, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 12701.991458177567, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 12701.997386932373, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 12702.002913475037, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 12702.009402036667, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 12702.014591217041, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 12702.020834445953, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110048, "time": 12703.85310792923, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 110120, "time": 12712.028863430023, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 110288, "time": 12731.209933519363, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 110976, "time": 12809.510205745697, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 111056, "time": 12818.638103246689, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 111376, "time": 12855.019119501114, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 111520, "time": 12871.375611782074, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 111600, "time": 12880.439888954163, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 112360, "time": 12966.865127325058, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 112360, "time": 12966.906450748444, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 112432, "time": 12975.104840755463, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 112600, "time": 12994.195002555847, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 112744, "time": 13010.57772564888, "episode/length": 210.0, "episode/score": 0.34375, "episode/reward_rate": 0.004739336492890996, "episode/intrinsic_return": 0.0}
{"step": 112856, "time": 13023.327992200851, "episode/length": 234.0, "episode/score": 0.26875001192092896, "episode/reward_rate": 0.00425531914893617, "episode/intrinsic_return": 0.0}
{"step": 113504, "time": 13097.204175949097, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 113800, "time": 13130.922217130661, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 113832, "time": 13134.535273551941, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 113912, "time": 13143.615451574326, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 114192, "time": 13175.52280831337, "episode/length": 228.0, "episode/score": 0.2874999940395355, "episode/reward_rate": 0.004366812227074236, "episode/intrinsic_return": 0.0}
{"step": 114232, "time": 13180.067739009857, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 114705, "time": 13235.241651773453, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.4361320285622132, "train/action_min": 0.0, "train/action_std": 1.7048505971191126, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0035809227537765345, "train/actor_opt_grad_steps": 27195.0, "train/actor_opt_loss": -7.1693420885814305, "train/adv_mag": 0.3045295550735719, "train/adv_max": 0.14373162006019452, "train/adv_mean": -0.0009742042663712058, "train/adv_min": -0.2624283184152131, "train/adv_std": 0.009937355604552485, "train/cont_avg": 0.9962102207568807, "train/cont_loss_mean": 0.007417281007943162, "train/cont_loss_std": 0.14167686163046217, "train/cont_neg_acc": 0.607838694924532, "train/cont_neg_loss": 1.5702009329949993, "train/cont_pos_acc": 0.9999505385346369, "train/cont_pos_loss": 0.0014193236392360915, "train/cont_pred": 0.9963180299745787, "train/cont_rate": 0.9962102207568807, "train/dyn_loss_mean": 1.0000488719808946, "train/dyn_loss_std": 0.0007122656982765884, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.13132286093137954, "train/extr_critic_critic_opt_grad_steps": 27195.0, "train/extr_critic_critic_opt_loss": 6371.609706493693, "train/extr_critic_mag": 0.4314062644582276, "train/extr_critic_max": 0.4314062644582276, "train/extr_critic_mean": 0.35121265258810935, "train/extr_critic_min": 0.33258371451579105, "train/extr_critic_std": 0.009028657726140334, "train/extr_return_normed_mag": 0.31382512020955394, "train/extr_return_normed_max": 0.18674621355096135, "train/extr_return_normed_mean": 0.01098389292374456, "train/extr_return_normed_min": -0.2417060129959649, "train/extr_return_normed_std": 0.013801969933844761, "train/extr_return_rate": 0.0024778408222936453, "train/extr_return_raw_mag": 0.5260007483970135, "train/extr_return_raw_max": 0.5260007483970135, "train/extr_return_raw_mean": 0.3502384457019491, "train/extr_return_raw_min": 0.09754852171337933, "train/extr_return_raw_std": 0.01380196997870204, "train/extr_reward_mag": 0.22131285481496688, "train/extr_reward_max": 0.22131285481496688, "train/extr_reward_mean": 0.0002554008699983928, "train/extr_reward_min": 2.3349709467056693e-07, "train/extr_reward_std": 0.00413500121687838, "train/image_loss_mean": 0.06323443477922076, "train/image_loss_std": 0.08692025080528282, "train/model_loss_mean": 0.6729011800857859, "train/model_loss_std": 0.2197126149447686, "train/model_opt_grad_norm": 25.981691933553154, "train/model_opt_grad_steps": 27170.34862385321, "train/model_opt_loss": 2369.7715935663346, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3520.6422018348626, "train/policy_entropy_mag": 1.5194576639647877, "train/policy_entropy_max": 1.5194576639647877, "train/policy_entropy_mean": 0.21886312448923742, "train/policy_entropy_min": 0.06468804450620205, "train/policy_entropy_std": 0.2262333722426257, "train/policy_logprob_mag": 6.551074021453157, "train/policy_logprob_max": -0.008608527028711017, "train/policy_logprob_mean": -0.21892174705863, "train/policy_logprob_min": -6.551074021453157, "train/policy_logprob_std": 0.7363679933985439, "train/policy_randomness_mag": 0.7808468210587808, "train/policy_randomness_max": 0.7808468210587808, "train/policy_randomness_mean": 0.11247340396661824, "train/policy_randomness_min": 0.03324308085742347, "train/policy_randomness_std": 0.11626096209938373, "train/post_ent_mag": 39.2227549596664, "train/post_ent_max": 39.2227549596664, "train/post_ent_mean": 38.22036464936143, "train/post_ent_min": 37.48301724775122, "train/post_ent_std": 0.37102719991032135, "train/prior_ent_mag": 39.74167087099968, "train/prior_ent_max": 39.74167087099968, "train/prior_ent_mean": 37.17159486473153, "train/prior_ent_min": 35.3669419594861, "train/prior_ent_std": 0.6995096488283314, "train/rep_loss_mean": 1.0000488719808946, "train/rep_loss_std": 0.0007122656982765884, "train/reward_avg": 0.000328035966691843, "train/reward_loss_mean": 0.0022201205362403476, "train/reward_loss_std": 0.056882756768080724, "train/reward_max_data": 0.2713302749149296, "train/reward_max_pred": 0.11683256637065782, "train/reward_neg_acc": 0.9999417293509212, "train/reward_neg_loss": 0.00034465689438773286, "train/reward_pos_acc": 0.34587813673480866, "train/reward_pos_loss": 3.5908386938033567, "train/reward_pred": 0.0002514944916992628, "train/reward_rate": 0.0005509962729357798, "train_stats/mean_log_entropy": 0.19084550527965322, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.0012307928409427404, "report/cont_loss_std": 0.013302188366651535, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.03369101509451866, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.001167269772849977, "report/cont_pred": 0.9970231056213379, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.05055058002471924, "report/image_loss_std": 0.07386370748281479, "report/model_loss_mean": 0.6534228324890137, "report/model_loss_std": 0.0910523310303688, "report/post_ent_mag": 37.8193359375, "report/post_ent_max": 37.8193359375, "report/post_ent_mean": 36.715545654296875, "report/post_ent_min": 35.92274475097656, "report/post_ent_std": 0.37005501985549927, "report/prior_ent_mag": 37.971221923828125, "report/prior_ent_max": 37.971221923828125, "report/prior_ent_mean": 35.39643096923828, "report/prior_ent_min": 33.937225341796875, "report/prior_ent_std": 0.7235524654388428, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0007507324335165322, "report/reward_loss_mean": 0.001641381997615099, "report/reward_loss_std": 0.043359700590372086, "report/reward_max_data": 0.768750011920929, "report/reward_max_pred": 0.595984935760498, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0002882604021579027, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 1.3858847618103027, "report/reward_pred": 0.0007207599701359868, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.04166039079427719, "eval/cont_loss_std": 0.747093915939331, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 13.817709922790527, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0011822885135188699, "eval/cont_pred": 0.9990247488021851, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.26430976390838623, "eval/image_loss_std": 0.1605791598558426, "eval/model_loss_mean": 0.9209914207458496, "eval/model_loss_std": 1.1170631647109985, "eval/post_ent_mag": 37.539730072021484, "eval/post_ent_max": 37.539730072021484, "eval/post_ent_mean": 36.53891372680664, "eval/post_ent_min": 35.968597412109375, "eval/post_ent_std": 0.29453614354133606, "eval/prior_ent_mag": 38.13444137573242, "eval/prior_ent_max": 38.13444137573242, "eval/prior_ent_mean": 35.23351287841797, "eval/prior_ent_min": 33.551910400390625, "eval/prior_ent_std": 0.7098156809806824, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0005126952892169356, "eval/reward_loss_mean": 0.015021204948425293, "eval/reward_loss_std": 0.47767698764801025, "eval/reward_max_data": 0.5249999761581421, "eval/reward_max_pred": 0.010172128677368164, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 8.653639088151976e-05, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 15.293188095092773, "eval/reward_pred": 4.024314694106579e-05, "eval/reward_rate": 0.0009765625, "replay/size": 114201.0, "replay/inserts": 8724.0, "replay/samples": 34896.0, "replay/insert_wait_avg": 1.5328587440655134e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.113271872421188e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 28800.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0658712948069853e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.897615432739258e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2316746711731, "timer/env.step_count": 1091.0, "timer/env.step_total": 10.889413595199585, "timer/env.step_frac": 0.01088689137821944, "timer/env.step_avg": 0.009981130701374505, "timer/env.step_min": 0.008851051330566406, "timer/env.step_max": 0.03843975067138672, "timer/replay._sample_count": 34896.0, "timer/replay._sample_total": 17.833175897598267, "timer/replay._sample_frac": 0.017829045359377304, "timer/replay._sample_avg": 0.0005110378237505234, "timer/replay._sample_min": 0.0003578662872314453, "timer/replay._sample_max": 0.02038288116455078, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1380.0, "timer/agent.policy_total": 13.905008554458618, "timer/agent.policy_frac": 0.013901787862326896, "timer/agent.policy_avg": 0.010076093155404796, "timer/agent.policy_min": 0.008720636367797852, "timer/agent.policy_max": 0.03455948829650879, "timer/dataset_train_count": 2181.0, "timer/dataset_train_total": 0.3759157657623291, "timer/dataset_train_frac": 0.0003758286957728185, "timer/dataset_train_avg": 0.00017235936073467634, "timer/dataset_train_min": 8.96453857421875e-05, "timer/dataset_train_max": 0.0015115737915039062, "timer/agent.train_count": 2181.0, "timer/agent.train_total": 970.1066191196442, "timer/agent.train_frac": 0.9698819220442778, "timer/agent.train_avg": 0.4447990000548575, "timer/agent.train_min": 0.4348258972167969, "timer/agent.train_max": 0.576286792755127, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.475630521774292, "timer/agent.report_frac": 0.00047552035575223697, "timer/agent.report_avg": 0.237815260887146, "timer/agent.report_min": 0.23165249824523926, "timer/agent.report_max": 0.24397802352905273, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.457069396972656e-05, "timer/dataset_eval_frac": 3.456268667065728e-08, "timer/dataset_eval_avg": 3.457069396972656e-05, "timer/dataset_eval_min": 3.457069396972656e-05, "timer/dataset_eval_max": 3.457069396972656e-05, "fps": 8.721868811735145}
{"step": 114912, "time": 13258.614146232605, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 115056, "time": 13274.999578475952, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 115144, "time": 13285.005855083466, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 115272, "time": 13299.536514520645, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 115288, "time": 13301.424205303192, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 115816, "time": 13361.396600723267, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 116112, "time": 13395.129106760025, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 116224, "time": 13407.949581384659, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 116344, "time": 13421.714584350586, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 116544, "time": 13444.555094003677, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 116936, "time": 13489.532241106033, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 117192, "time": 13518.815910816193, "episode/length": 266.0, "episode/score": 0.16875000298023224, "episode/reward_rate": 0.003745318352059925, "episode/intrinsic_return": 0.0}
{"step": 117456, "time": 13548.982052087784, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 117584, "time": 13563.551280975342, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 117632, "time": 13569.020108938217, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 117944, "time": 13604.721540689468, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 118128, "time": 13625.686046123505, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 118240, "time": 13638.570153713226, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 118424, "time": 13659.576535224915, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 118488, "time": 13666.938975811005, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 118536, "time": 13672.405944347382, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 118856, "time": 13709.03694844246, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 119312, "time": 13761.133216142654, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 119568, "time": 13790.418526649475, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 119768, "time": 13813.288002490997, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 120016, "time": 13844.230135440826, "eval_episode/length": 148.0, "eval_episode/score": 0.5375000238418579, "eval_episode/reward_rate": 0.006711409395973154}
{"step": 120016, "time": 13844.67140674591, "eval_episode/length": 174.0, "eval_episode/score": 0.45625001192092896, "eval_episode/reward_rate": 0.005714285714285714}
{"step": 120016, "time": 13845.445770025253, "eval_episode/length": 70.0, "eval_episode/score": 0.78125, "eval_episode/reward_rate": 0.014084507042253521}
{"step": 120016, "time": 13846.610214710236, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 13846.617781877518, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 13846.623522520065, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 13846.628892660141, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 13846.634381532669, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 13846.640150308609, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120256, "time": 13874.01795387268, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 120552, "time": 13907.813777685165, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 120736, "time": 13928.755207538605, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 120832, "time": 13939.759150266647, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 120848, "time": 13941.60067987442, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 121168, "time": 13978.158171653748, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 121472, "time": 14012.894982337952, "episode/length": 269.0, "episode/score": 0.15937499701976776, "episode/reward_rate": 0.003703703703703704, "episode/intrinsic_return": 0.0}
{"step": 121880, "time": 14059.743399620056, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 122448, "time": 14124.767384529114, "episode/length": 236.0, "episode/score": 0.26249998807907104, "episode/reward_rate": 0.004219409282700422, "episode/intrinsic_return": 0.0}
{"step": 122568, "time": 14138.460196733475, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 123032, "time": 14191.920344114304, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 123048, "time": 14193.776732683182, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 123080, "time": 14197.450505971909, "episode/length": 238.0, "episode/score": 0.2562499940395355, "episode/reward_rate": 0.0041841004184100415, "episode/intrinsic_return": 0.0}
{"step": 123144, "time": 14204.868112802505, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 123160, "time": 14206.734498023987, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 123405, "time": 14235.66059422493, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.160255642112242, "train/action_min": 0.0, "train/action_std": 1.8438121206169829, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.006070197085954607, "train/actor_opt_grad_steps": 29375.0, "train/actor_opt_loss": -3.9011951466390027, "train/adv_mag": 0.43024095182025107, "train/adv_max": 0.3376397413944979, "train/adv_mean": 0.0021495298554936857, "train/adv_min": -0.3039952532960734, "train/adv_std": 0.019553559360205443, "train/cont_avg": 0.9962326189793578, "train/cont_loss_mean": 0.007694886694021455, "train/cont_loss_std": 0.14558701751883987, "train/cont_neg_acc": 0.6141694432774255, "train/cont_neg_loss": 1.6241121642693586, "train/cont_pos_acc": 0.9999100650669238, "train/cont_pos_loss": 0.0015207610644160882, "train/cont_pred": 0.9962542978448605, "train/cont_rate": 0.9962326189793578, "train/dyn_loss_mean": 1.0000030808492537, "train/dyn_loss_std": 9.111156649759398e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.38074863440604934, "train/extr_critic_critic_opt_grad_steps": 29375.0, "train/extr_critic_critic_opt_loss": 4772.32096988783, "train/extr_critic_mag": 0.40784789553476036, "train/extr_critic_max": 0.40784789553476036, "train/extr_critic_mean": 0.37046025324305265, "train/extr_critic_min": 0.3417064974067408, "train/extr_critic_std": 0.009621564958911014, "train/extr_return_normed_mag": 0.44072168081178575, "train/extr_return_normed_max": 0.3724784223584954, "train/extr_return_normed_mean": 0.019679881170137845, "train/extr_return_normed_min": -0.2820550137703572, "train/extr_return_normed_std": 0.02277869305684479, "train/extr_return_rate": 0.0049425413429354205, "train/extr_return_raw_mag": 0.7254083066358479, "train/extr_return_raw_max": 0.7254083066358479, "train/extr_return_raw_mean": 0.3726097838867695, "train/extr_return_raw_min": 0.0708748690032084, "train/extr_return_raw_std": 0.02277869300985145, "train/extr_reward_mag": 0.45412025867252176, "train/extr_reward_max": 0.45412025867252176, "train/extr_reward_mean": 0.0009034483541153842, "train/extr_reward_min": -2.9063006059839092e-05, "train/extr_reward_std": 0.009970935866568578, "train/image_loss_mean": 0.0627665489980387, "train/image_loss_std": 0.08670980454243105, "train/model_loss_mean": 0.6727554191143141, "train/model_loss_std": 0.22454836390434055, "train/model_opt_grad_norm": 24.854842640938013, "train/model_opt_grad_steps": 29348.697247706423, "train/model_opt_loss": 2623.128171588303, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3899.0825688073396, "train/policy_entropy_mag": 1.463029616469637, "train/policy_entropy_max": 1.463029616469637, "train/policy_entropy_mean": 0.1515017899966568, "train/policy_entropy_min": 0.06468743947120982, "train/policy_entropy_std": 0.19500665428168182, "train/policy_logprob_mag": 6.551078739516232, "train/policy_logprob_max": -0.008608432102162358, "train/policy_logprob_mean": -0.15124957943591502, "train/policy_logprob_min": -6.551078739516232, "train/policy_logprob_std": 0.6917479981523041, "train/policy_randomness_mag": 0.7518485388077727, "train/policy_randomness_max": 0.7518485388077727, "train/policy_randomness_mean": 0.07785652362562101, "train/policy_randomness_min": 0.03324276982986052, "train/policy_randomness_std": 0.10021360303967371, "train/post_ent_mag": 38.60987630021681, "train/post_ent_max": 38.60987630021681, "train/post_ent_mean": 37.625279855290685, "train/post_ent_min": 36.92303113324927, "train/post_ent_std": 0.3416412731102847, "train/prior_ent_mag": 38.538820844177806, "train/prior_ent_max": 38.538820844177806, "train/prior_ent_mean": 36.40177585006854, "train/prior_ent_min": 34.96177739834567, "train/prior_ent_std": 0.5764722714730359, "train/rep_loss_mean": 1.0000030808492537, "train/rep_loss_std": 9.111156649759398e-05, "train/reward_avg": 0.00032471823098203124, "train/reward_loss_mean": 0.0022921126593254642, "train/reward_loss_std": 0.05621761534084809, "train/reward_max_data": 0.26209862355928903, "train/reward_max_pred": 0.1380506928907622, "train/reward_neg_acc": 0.9998789621055673, "train/reward_neg_loss": 0.00042114598467161583, "train/reward_pos_acc": 0.4326241140035873, "train/reward_pos_loss": 3.312619993185743, "train/reward_pred": 0.00030057854179310004, "train/reward_rate": 0.0005644352064220183, "train_stats/mean_log_entropy": 0.12563274148851633, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.0009677576599642634, "report/cont_loss_std": 0.004544925410300493, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 5.145766772329807e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0009695508633740246, "report/cont_pred": 0.9970898628234863, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.05174598470330238, "report/image_loss_std": 0.07436059415340424, "report/model_loss_mean": 0.6529107093811035, "report/model_loss_std": 0.07503678649663925, "report/post_ent_mag": 39.774986267089844, "report/post_ent_max": 39.774986267089844, "report/post_ent_mean": 38.84406280517578, "report/post_ent_min": 38.17486572265625, "report/post_ent_std": 0.30624374747276306, "report/prior_ent_mag": 39.58561706542969, "report/prior_ent_max": 39.58561706542969, "report/prior_ent_mean": 38.100345611572266, "report/prior_ent_min": 36.95372009277344, "report/prior_ent_std": 0.4261462092399597, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.00019689276814460754, "report/reward_loss_std": 0.0016815902199596167, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.014142751693725586, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00019689276814460754, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 8.997751865535975e-05, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.03509550541639328, "eval/cont_loss_std": 0.6238957047462463, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 11.53126049041748, "eval/cont_pos_acc": 0.999020516872406, "eval/cont_pos_loss": 0.0013163713738322258, "eval/cont_pred": 0.9990087151527405, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.19207128882408142, "eval/image_loss_std": 0.15586033463478088, "eval/model_loss_mean": 0.8413454294204712, "eval/model_loss_std": 0.9935207962989807, "eval/post_ent_mag": 39.53614044189453, "eval/post_ent_max": 39.53614044189453, "eval/post_ent_mean": 38.68479919433594, "eval/post_ent_min": 38.130611419677734, "eval/post_ent_std": 0.24831858277320862, "eval/prior_ent_mag": 39.66592025756836, "eval/prior_ent_max": 39.66592025756836, "eval/prior_ent_mean": 37.96400833129883, "eval/prior_ent_min": 36.89116287231445, "eval/prior_ent_std": 0.4334067404270172, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0005126952892169356, "eval/reward_loss_mean": 0.014178555458784103, "eval/reward_loss_std": 0.4522106349468231, "eval/reward_max_data": 0.5249999761581421, "eval/reward_max_pred": 0.0018028020858764648, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 4.0069702663458884e-05, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 14.477848052978516, "eval/reward_pred": 1.6858684830367565e-05, "eval/reward_rate": 0.0009765625, "replay/size": 122901.0, "replay/inserts": 8700.0, "replay/samples": 34800.0, "replay/insert_wait_avg": 1.527440959009631e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.04163792489589e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 31112.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0442156280200787e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.152557373046875e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4086730480194, "timer/env.step_count": 1087.0, "timer/env.step_total": 10.741329431533813, "timer/env.step_frac": 0.010736941532911153, "timer/env.step_avg": 0.009881627811898632, "timer/env.step_min": 0.008656501770019531, "timer/env.step_max": 0.03527545928955078, "timer/replay._sample_count": 34800.0, "timer/replay._sample_total": 17.090219497680664, "timer/replay._sample_frac": 0.01708323803872134, "timer/replay._sample_avg": 0.0004910982614276053, "timer/replay._sample_min": 0.00034308433532714844, "timer/replay._sample_max": 0.039847612380981445, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1376.0, "timer/agent.policy_total": 13.864172220230103, "timer/agent.policy_frac": 0.013858508621270844, "timer/agent.policy_avg": 0.010075706555399784, "timer/agent.policy_min": 0.008696317672729492, "timer/agent.policy_max": 0.042201995849609375, "timer/dataset_train_count": 2175.0, "timer/dataset_train_total": 0.3709263801574707, "timer/dataset_train_frac": 0.0003707748544675665, "timer/dataset_train_avg": 0.0001705408644402164, "timer/dataset_train_min": 9.131431579589844e-05, "timer/dataset_train_max": 0.0008368492126464844, "timer/agent.train_count": 2175.0, "timer/agent.train_total": 970.6357009410858, "timer/agent.train_frac": 0.9702391903338642, "timer/agent.train_avg": 0.446269287789005, "timer/agent.train_min": 0.43645429611206055, "timer/agent.train_max": 0.6013960838317871, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4753994941711426, "timer/agent.report_frac": 0.00047520529057660767, "timer/agent.report_avg": 0.2376997470855713, "timer/agent.report_min": 0.23102903366088867, "timer/agent.report_max": 0.2443704605102539, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8371810913085938e-05, "timer/dataset_eval_frac": 2.8360220855186544e-08, "timer/dataset_eval_avg": 2.8371810913085938e-05, "timer/dataset_eval_min": 2.8371810913085938e-05, "timer/dataset_eval_max": 2.8371810913085938e-05, "fps": 8.69633241658107}
{"step": 123464, "time": 14242.308853387833, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 123528, "time": 14249.686298847198, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 123784, "time": 14279.11556816101, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 124192, "time": 14325.99309706688, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 124760, "time": 14391.364832162857, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 125360, "time": 14460.06607556343, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 125392, "time": 14463.721829414368, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 125472, "time": 14473.042394638062, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 125776, "time": 14508.16201043129, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 125840, "time": 14515.546071767807, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 126096, "time": 14545.11391711235, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 126504, "time": 14591.914633512497, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 127072, "time": 14657.248143672943, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 127672, "time": 14726.426932096481, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 127704, "time": 14730.112420082092, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 127784, "time": 14739.303985118866, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 128088, "time": 14774.420463323593, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 128104, "time": 14776.250205993652, "episode/length": 199.0, "episode/score": 0.37812501192092896, "episode/reward_rate": 0.005, "episode/intrinsic_return": 0.0}
{"step": 128120, "time": 14778.099719285965, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 128152, "time": 14781.750960111618, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 128408, "time": 14811.217952013016, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 129984, "time": 14993.180168628693, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 130000, "time": 14995.881464481354, "eval_episode/length": 48.0, "eval_episode/score": 0.8500000238418579, "eval_episode/reward_rate": 0.02040816326530612}
{"step": 130000, "time": 14995.939877033234, "eval_episode/length": 51.0, "eval_episode/score": 0.840624988079071, "eval_episode/reward_rate": 0.019230769230769232}
{"step": 130000, "time": 14998.340075016022, "eval_episode/length": 102.0, "eval_episode/score": 0.6812499761581421, "eval_episode/reward_rate": 0.009708737864077669}
{"step": 130000, "time": 14998.847691774368, "eval_episode/length": 28.0, "eval_episode/score": 0.9125000238418579, "eval_episode/reward_rate": 0.034482758620689655}
{"step": 130000, "time": 14999.520283460617, "eval_episode/length": 37.0, "eval_episode/score": 0.8843749761581421, "eval_episode/reward_rate": 0.02631578947368421}
{"step": 130000, "time": 15000.450298547745, "eval_episode/length": 53.0, "eval_episode/score": 0.8343750238418579, "eval_episode/reward_rate": 0.018518518518518517}
{"step": 130000, "time": 15000.675308942795, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 15000.681668281555, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 15000.689638137817, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 15000.69573545456, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 15000.701055526733, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 15000.706398487091, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130016, "time": 15002.526477098465, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 130096, "time": 15011.71777844429, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 130400, "time": 15046.425613641739, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 130416, "time": 15048.248367547989, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 130432, "time": 15050.077860593796, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 130464, "time": 15053.79330945015, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 130720, "time": 15083.294877767563, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 132041, "time": 15235.96789431572, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.4397899486400463, "train/action_min": 0.0, "train/action_std": 1.1096813267579786, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.007864564950944408, "train/actor_opt_grad_steps": 31545.0, "train/actor_opt_loss": -5.7320519115913795, "train/adv_mag": 0.45373159660785284, "train/adv_max": 0.3621568489405844, "train/adv_mean": 0.0023877285873284025, "train/adv_min": -0.34325270189179313, "train/adv_std": 0.02514226191582296, "train/cont_avg": 0.9963152850115741, "train/cont_loss_mean": 0.007799811800160333, "train/cont_loss_std": 0.14502462462513466, "train/cont_neg_acc": 0.5574294591529502, "train/cont_neg_loss": 1.7249078940193427, "train/cont_pos_acc": 0.9999319555030929, "train/cont_pos_loss": 0.0015622244190362162, "train/cont_pred": 0.9964301343317385, "train/cont_rate": 0.9963152850115741, "train/dyn_loss_mean": 1.000000371977135, "train/dyn_loss_std": 1.1906592623779068e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.20725325875294706, "train/extr_critic_critic_opt_grad_steps": 31545.0, "train/extr_critic_critic_opt_loss": 12406.416063096789, "train/extr_critic_mag": 0.5836554517348608, "train/extr_critic_max": 0.5836554517348608, "train/extr_critic_mean": 0.4645316146866039, "train/extr_critic_min": 0.4255219444080635, "train/extr_critic_std": 0.015245262443958954, "train/extr_return_normed_mag": 0.4991617934019477, "train/extr_return_normed_max": 0.4369855897018203, "train/extr_return_normed_mean": 0.028336650422783417, "train/extr_return_normed_min": -0.2908254205076783, "train/extr_return_normed_std": 0.03024375656429954, "train/extr_return_rate": 0.2014853482016608, "train/extr_return_raw_mag": 0.8755682528846793, "train/extr_return_raw_max": 0.8755682528846793, "train/extr_return_raw_mean": 0.46691934226287735, "train/extr_return_raw_min": 0.14775724336504936, "train/extr_return_raw_std": 0.030243756450040057, "train/extr_reward_mag": 0.43855724345754693, "train/extr_reward_max": 0.43855724345754693, "train/extr_reward_mean": 0.0019476347074045305, "train/extr_reward_min": 2.588386888857241e-07, "train/extr_reward_std": 0.014763105069290659, "train/image_loss_mean": 0.06242213503423112, "train/image_loss_std": 0.08858909547604897, "train/model_loss_mean": 0.6730037240518464, "train/model_loss_std": 0.23136273071307828, "train/model_opt_grad_norm": 24.198667226014315, "train/model_opt_grad_steps": 31517.203703703704, "train/model_opt_loss": 3459.505226417824, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5162.037037037037, "train/policy_entropy_mag": 1.3341497149732378, "train/policy_entropy_max": 1.3341497149732378, "train/policy_entropy_mean": 0.14648133671532074, "train/policy_entropy_min": 0.06468656431469652, "train/policy_entropy_std": 0.17843052248160043, "train/policy_logprob_mag": 6.55108016508597, "train/policy_logprob_max": -0.008608143500707767, "train/policy_logprob_mean": -0.14637715783384112, "train/policy_logprob_min": -6.55108016508597, "train/policy_logprob_std": 0.6768901016977098, "train/policy_randomness_mag": 0.6856173679784492, "train/policy_randomness_max": 0.6856173679784492, "train/policy_randomness_mean": 0.07527652043090374, "train/policy_randomness_min": 0.03324232043491469, "train/policy_randomness_std": 0.09169515518954506, "train/post_ent_mag": 39.511152002546524, "train/post_ent_max": 39.511152002546524, "train/post_ent_mean": 38.59401870656897, "train/post_ent_min": 37.90807381382695, "train/post_ent_std": 0.31871226498926125, "train/prior_ent_mag": 39.297224044799805, "train/prior_ent_max": 39.297224044799805, "train/prior_ent_mean": 37.575059219642924, "train/prior_ent_min": 36.11554504323889, "train/prior_ent_std": 0.5054151204725107, "train/rep_loss_mean": 1.000000371977135, "train/rep_loss_std": 1.1906592623779068e-05, "train/reward_avg": 0.00038863287988567244, "train/reward_loss_mean": 0.0027815315487613487, "train/reward_loss_std": 0.06688045604608271, "train/reward_max_data": 0.29246238425925924, "train/reward_max_pred": 0.1453562389921259, "train/reward_neg_acc": 0.9998823972763838, "train/reward_neg_loss": 0.00042201860868671146, "train/reward_pos_acc": 0.41743827224881563, "train/reward_pos_loss": 3.2494588870969086, "train/reward_pred": 0.00030927519967210374, "train/reward_rate": 0.0007098162615740741, "train_stats/mean_log_entropy": 0.1502029985703271, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.005923462565988302, "report/cont_loss_std": 0.1559968739748001, "report/cont_neg_acc": 0.5, "report/cont_neg_loss": 2.4851927757263184, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0010716640390455723, "report/cont_pred": 0.9980637431144714, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.05854935944080353, "report/image_loss_std": 0.08081496506929398, "report/model_loss_mean": 0.6646559834480286, "report/model_loss_std": 0.17802198231220245, "report/post_ent_mag": 39.77838134765625, "report/post_ent_max": 39.77838134765625, "report/post_ent_mean": 38.915626525878906, "report/post_ent_min": 38.20915985107422, "report/post_ent_std": 0.32924890518188477, "report/prior_ent_mag": 39.211402893066406, "report/prior_ent_max": 39.211402893066406, "report/prior_ent_mean": 37.625274658203125, "report/prior_ent_min": 35.763248443603516, "report/prior_ent_std": 0.51105135679245, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.00018312223255634308, "report/reward_loss_std": 0.001669438206590712, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.016141891479492188, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00018312223255634308, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 9.169138502329588e-05, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.03785599768161774, "eval/cont_loss_std": 0.6875930428504944, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 12.721357345581055, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0005881215329281986, "eval/cont_pred": 0.999457597732544, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.26587265729904175, "eval/image_loss_std": 0.18064622581005096, "eval/model_loss_mean": 0.9037540555000305, "eval/model_loss_std": 0.7037530541419983, "eval/post_ent_mag": 39.569644927978516, "eval/post_ent_max": 39.569644927978516, "eval/post_ent_mean": 38.687232971191406, "eval/post_ent_min": 38.08026123046875, "eval/post_ent_std": 0.27566784620285034, "eval/prior_ent_mag": 39.211402893066406, "eval/prior_ent_max": 39.211402893066406, "eval/prior_ent_mean": 37.41806411743164, "eval/prior_ent_min": 35.897499084472656, "eval/prior_ent_std": 0.5086268782615662, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 2.5365501642227173e-05, "eval/reward_loss_std": 0.0005981209687888622, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.007152676582336426, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 2.5365501642227173e-05, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 9.990646503865719e-06, "eval/reward_rate": 0.0, "replay/size": 131537.0, "replay/inserts": 8636.0, "replay/samples": 34544.0, "replay/insert_wait_avg": 1.5922087439236236e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.234758776390425e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 33424.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0682431059312655e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.599592208862305e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2939603328705, "timer/env.step_count": 1080.0, "timer/env.step_total": 10.856966972351074, "timer/env.step_frac": 0.010853776392629796, "timer/env.step_avg": 0.010052747196621366, "timer/env.step_min": 0.008971691131591797, "timer/env.step_max": 0.03544044494628906, "timer/replay._sample_count": 34544.0, "timer/replay._sample_total": 18.06939435005188, "timer/replay._sample_frac": 0.01806408422583985, "timer/replay._sample_avg": 0.0005230834399621318, "timer/replay._sample_min": 0.0003933906555175781, "timer/replay._sample_max": 0.016118764877319336, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1369.0, "timer/agent.policy_total": 14.626195430755615, "timer/agent.policy_frac": 0.014621897172995444, "timer/agent.policy_avg": 0.010683853492151655, "timer/agent.policy_min": 0.00873112678527832, "timer/agent.policy_max": 0.07625246047973633, "timer/dataset_train_count": 2159.0, "timer/dataset_train_total": 0.375577449798584, "timer/dataset_train_frac": 0.00037546707737153793, "timer/dataset_train_avg": 0.00017395898554820936, "timer/dataset_train_min": 9.322166442871094e-05, "timer/dataset_train_max": 0.0006668567657470703, "timer/agent.train_count": 2159.0, "timer/agent.train_total": 969.4248478412628, "timer/agent.train_frac": 0.969139959136277, "timer/agent.train_avg": 0.44901567755500826, "timer/agent.train_min": 0.4361879825592041, "timer/agent.train_max": 1.0356760025024414, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4716048240661621, "timer/agent.report_frac": 0.00047146623169575566, "timer/agent.report_avg": 0.23580241203308105, "timer/agent.report_min": 0.22574853897094727, "timer/agent.report_max": 0.24585628509521484, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9087066650390625e-05, "timer/dataset_eval_frac": 2.9078518719348505e-08, "timer/dataset_eval_avg": 2.9087066650390625e-05, "timer/dataset_eval_min": 2.9087066650390625e-05, "timer/dataset_eval_max": 2.9087066650390625e-05, "fps": 8.633351369037344}
{"step": 132296, "time": 15265.07109451294, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 132328, "time": 15268.759510040283, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 132408, "time": 15277.957193613052, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 132712, "time": 15313.09281206131, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 132728, "time": 15314.943232059479, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 132744, "time": 15316.778408765793, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 132776, "time": 15320.46714425087, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 133032, "time": 15349.860602855682, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 134608, "time": 15531.431526899338, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 134640, "time": 15535.138495445251, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 134720, "time": 15544.372293949127, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 135016, "time": 15578.51755952835, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 135024, "time": 15579.452131032944, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 135040, "time": 15581.386705160141, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 135056, "time": 15583.237065792084, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 135088, "time": 15586.951694965363, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 135160, "time": 15595.264489412308, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 135344, "time": 15616.572924137115, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 136440, "time": 15742.759045362473, "episode/length": 214.0, "episode/score": 0.33125001192092896, "episode/reward_rate": 0.004651162790697674, "episode/intrinsic_return": 0.0}
{"step": 137192, "time": 15829.416704416275, "episode/length": 230.0, "episode/score": 0.28125, "episode/reward_rate": 0.004329004329004329, "episode/intrinsic_return": 0.0}
{"step": 137240, "time": 15834.939794540405, "episode/length": 268.0, "episode/score": 0.16249999403953552, "episode/reward_rate": 0.0037174721189591076, "episode/intrinsic_return": 0.0}
{"step": 137328, "time": 15845.025416135788, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 137336, "time": 15845.945798158646, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 137352, "time": 15847.770233869553, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 137368, "time": 15849.614341020584, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 137472, "time": 15861.55972456932, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 138752, "time": 16008.402483940125, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 139504, "time": 16095.13125038147, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 139552, "time": 16100.639060258865, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 139640, "time": 16110.774689912796, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 139648, "time": 16111.693379878998, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 139664, "time": 16113.531294584274, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 139672, "time": 16114.452682971954, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 139680, "time": 16115.39388179779, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 139784, "time": 16127.401224136353, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 140088, "time": 16163.021646499634, "eval_episode/length": 38.0, "eval_episode/score": 0.8812500238418579, "eval_episode/reward_rate": 0.02564102564102564}
{"step": 140088, "time": 16163.581421136856, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 140088, "time": 16164.191927194595, "eval_episode/length": 103.0, "eval_episode/score": 0.6781250238418579, "eval_episode/reward_rate": 0.009615384615384616}
{"step": 140088, "time": 16164.653157949448, "eval_episode/length": 59.0, "eval_episode/score": 0.815625011920929, "eval_episode/reward_rate": 0.016666666666666666}
{"step": 140088, "time": 16164.762526988983, "eval_episode/length": 135.0, "eval_episode/score": 0.578125, "eval_episode/reward_rate": 0.007352941176470588}
{"step": 140088, "time": 16167.073422670364, "eval_episode/length": 165.0, "eval_episode/score": 0.484375, "eval_episode/reward_rate": 0.006024096385542169}
{"step": 140088, "time": 16167.408784151077, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 16167.417303323746, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 16167.423118591309, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 16167.428753137589, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140376, "time": 16200.461977481842, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 140681, "time": 16236.258742570877, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.102818806966146, "train/action_min": 0.0, "train/action_std": 1.5936092375605195, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00472531823713022, "train/actor_opt_grad_steps": 33705.0, "train/actor_opt_loss": -6.735281786363986, "train/adv_mag": 0.36711261918147403, "train/adv_max": 0.2222192367469823, "train/adv_mean": -0.0009574235793344862, "train/adv_min": -0.3204833601635915, "train/adv_std": 0.014975959179638367, "train/cont_avg": 0.9964373553240741, "train/cont_loss_mean": 0.008423434342451705, "train/cont_loss_std": 0.15563175155289677, "train/cont_neg_acc": 0.5602950051708041, "train/cont_neg_loss": 1.8759956334613135, "train/cont_pos_acc": 0.9998956143304154, "train/cont_pos_loss": 0.0016777430484782802, "train/cont_pred": 0.9964490844695656, "train/cont_rate": 0.9964373553240741, "train/dyn_loss_mean": 1.0000015767636123, "train/dyn_loss_std": 3.207326281645456e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.2011862624462487, "train/extr_critic_critic_opt_grad_steps": 33705.0, "train/extr_critic_critic_opt_loss": 8265.208767361111, "train/extr_critic_mag": 0.5405771533648173, "train/extr_critic_max": 0.5405771533648173, "train/extr_critic_mean": 0.40829888234535855, "train/extr_critic_min": 0.3645612514681286, "train/extr_critic_std": 0.016191651813979087, "train/extr_return_normed_mag": 0.39965273150139385, "train/extr_return_normed_max": 0.2925707424680392, "train/extr_return_normed_mean": 0.017055037288399275, "train/extr_return_normed_min": -0.28501672891003116, "train/extr_return_normed_std": 0.021910267963970977, "train/extr_return_rate": 0.015938465274403926, "train/extr_return_raw_mag": 0.6828571504188908, "train/extr_return_raw_max": 0.6828571504188908, "train/extr_return_raw_mean": 0.40734146783749264, "train/extr_return_raw_min": 0.10526967848892566, "train/extr_return_raw_std": 0.02191026797690601, "train/extr_reward_mag": 0.35042144634105543, "train/extr_reward_max": 0.35042144634105543, "train/extr_reward_mean": 0.0003788171025176039, "train/extr_reward_min": 1.3245476616753473e-07, "train/extr_reward_std": 0.007316802670646683, "train/image_loss_mean": 0.06295083401103814, "train/image_loss_std": 0.08854562230408192, "train/model_loss_mean": 0.6739369423853027, "train/model_loss_std": 0.23812397176192868, "train/model_opt_grad_norm": 23.735250963105095, "train/model_opt_grad_steps": 33674.9537037037, "train/model_opt_loss": 2784.1055156566476, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 4155.092592592592, "train/policy_entropy_mag": 1.4259416676229901, "train/policy_entropy_max": 1.4259416676229901, "train/policy_entropy_mean": 0.14007126733108802, "train/policy_entropy_min": 0.06468659901508579, "train/policy_entropy_std": 0.17578781354758474, "train/policy_logprob_mag": 6.551080116519222, "train/policy_logprob_max": -0.008608156642704099, "train/policy_logprob_mean": -0.1398871858017864, "train/policy_logprob_min": -6.551080116519222, "train/policy_logprob_std": 0.6756808815730942, "train/policy_randomness_mag": 0.7327891025278304, "train/policy_randomness_max": 0.7327891025278304, "train/policy_randomness_mean": 0.07198239649059596, "train/policy_randomness_min": 0.03324233881991218, "train/policy_randomness_std": 0.09033707139530668, "train/post_ent_mag": 39.321507930755615, "train/post_ent_max": 39.321507930755615, "train/post_ent_mean": 38.34048944049411, "train/post_ent_min": 37.54346496087533, "train/post_ent_std": 0.3570552019885293, "train/prior_ent_mag": 39.19315477653786, "train/prior_ent_max": 39.19315477653786, "train/prior_ent_mean": 37.22504651104963, "train/prior_ent_min": 35.71065309312608, "train/prior_ent_std": 0.5465806155569024, "train/rep_loss_mean": 1.0000015767636123, "train/rep_loss_std": 3.207326281645456e-05, "train/reward_avg": 0.00033363059726441324, "train/reward_loss_mean": 0.002561704712947917, "train/reward_loss_std": 0.06407482552121682, "train/reward_max_data": 0.27433449150649486, "train/reward_max_pred": 0.1272011426863847, "train/reward_neg_acc": 0.9999140186442269, "train/reward_neg_loss": 0.0004209418677284568, "train/reward_pos_acc": 0.318481848676606, "train/reward_pos_loss": 3.561245811752754, "train/reward_pred": 0.000281805459828185, "train/reward_rate": 0.0006013093171296296, "train_stats/mean_log_entropy": 0.10186682475937738, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.008566020056605339, "report/cont_loss_std": 0.2175668627023697, "report/cont_neg_acc": 0.6666666865348816, "report/cont_neg_loss": 2.488945484161377, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0012779317330569029, "report/cont_pred": 0.9972050189971924, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.047091562300920486, "report/image_loss_std": 0.07768838852643967, "report/model_loss_mean": 0.6581692695617676, "report/model_loss_std": 0.24951861798763275, "report/post_ent_mag": 39.930328369140625, "report/post_ent_max": 39.930328369140625, "report/post_ent_mean": 38.7217903137207, "report/post_ent_min": 38.033912658691406, "report/post_ent_std": 0.35484349727630615, "report/prior_ent_mag": 40.1070671081543, "report/prior_ent_max": 40.1070671081543, "report/prior_ent_mean": 37.939998626708984, "report/prior_ent_min": 36.702980041503906, "report/prior_ent_std": 0.5690248608589172, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0004302978632040322, "report/reward_loss_mean": 0.002511680591851473, "report/reward_loss_std": 0.0744035542011261, "report/reward_max_data": 0.44062501192092896, "report/reward_max_pred": 0.09965729713439941, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00018644286319613457, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 2.381229877471924, "report/reward_pred": 0.00018067366909235716, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.027744460850954056, "eval/cont_loss_std": 0.5010435581207275, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 8.883224487304688, "eval/cont_pos_acc": 0.999020516872406, "eval/cont_pos_loss": 0.0017244399059563875, "eval/cont_pred": 0.998721718788147, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.24001815915107727, "eval/image_loss_std": 0.18396542966365814, "eval/model_loss_mean": 0.8678205013275146, "eval/model_loss_std": 0.5333994030952454, "eval/post_ent_mag": 39.65540313720703, "eval/post_ent_max": 39.65540313720703, "eval/post_ent_mean": 38.6506233215332, "eval/post_ent_min": 37.98171615600586, "eval/post_ent_std": 0.28779909014701843, "eval/prior_ent_mag": 40.1070671081543, "eval/prior_ent_max": 40.1070671081543, "eval/prior_ent_mean": 37.890769958496094, "eval/prior_ent_min": 36.3209342956543, "eval/prior_ent_std": 0.5854782462120056, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 5.786679685115814e-05, "eval/reward_loss_std": 0.000480311835417524, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.003350973129272461, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 5.786679685115814e-05, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 2.4239649064838886e-05, "eval/reward_rate": 0.0, "replay/size": 140177.0, "replay/inserts": 8640.0, "replay/samples": 34560.0, "replay/insert_wait_avg": 1.570637579317446e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.419191576816418e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 35736.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0995922616608829e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.748603820800781e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2782726287842, "timer/env.step_count": 1080.0, "timer/env.step_total": 10.923999309539795, "timer/env.step_frac": 0.010920960305206817, "timer/env.step_avg": 0.01011481417549981, "timer/env.step_min": 0.008887767791748047, "timer/env.step_max": 0.035704612731933594, "timer/replay._sample_count": 34560.0, "timer/replay._sample_total": 18.231858491897583, "timer/replay._sample_frac": 0.018226786476110587, "timer/replay._sample_avg": 0.0005275422017331476, "timer/replay._sample_min": 0.0003657341003417969, "timer/replay._sample_max": 0.010050535202026367, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1369.0, "timer/agent.policy_total": 14.131780624389648, "timer/agent.policy_frac": 0.014127849230645171, "timer/agent.policy_avg": 0.010322703158794484, "timer/agent.policy_min": 0.008637428283691406, "timer/agent.policy_max": 0.038524627685546875, "timer/dataset_train_count": 2160.0, "timer/dataset_train_total": 0.36647820472717285, "timer/dataset_train_frac": 0.0003663762522443367, "timer/dataset_train_avg": 0.0001696658355218393, "timer/dataset_train_min": 8.96453857421875e-05, "timer/dataset_train_max": 0.0008792877197265625, "timer/agent.train_count": 2160.0, "timer/agent.train_total": 969.9755790233612, "timer/agent.train_frac": 0.9697057364589297, "timer/agent.train_avg": 0.4490627680663709, "timer/agent.train_min": 0.4369184970855713, "timer/agent.train_max": 0.5844390392303467, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4744133949279785, "timer/agent.report_frac": 0.000474281415391734, "timer/agent.report_avg": 0.23720669746398926, "timer/agent.report_min": 0.23156023025512695, "timer/agent.report_max": 0.24285316467285156, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8848648071289062e-05, "timer/dataset_eval_frac": 2.8840622515445918e-08, "timer/dataset_eval_avg": 2.8848648071289062e-05, "timer/dataset_eval_min": 2.8848648071289062e-05, "timer/dataset_eval_max": 2.8848648071289062e-05, "fps": 8.637481928166151}
{"step": 141816, "time": 16366.084693431854, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 141864, "time": 16371.575489521027, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 141960, "time": 16382.620165109634, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 141976, "time": 16384.45410633087, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 141984, "time": 16385.37546157837, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 141992, "time": 16386.297049045563, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 142096, "time": 16398.30426979065, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 142472, "time": 16441.45589208603, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 142688, "time": 16466.360633134842, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 142912, "time": 16492.02816414833, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 144176, "time": 16637.13184428215, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 144272, "time": 16648.13620853424, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 144288, "time": 16649.988255739212, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 144296, "time": 16650.910608291626, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 144408, "time": 16663.803890943527, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 144784, "time": 16706.981865167618, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 145000, "time": 16731.801497220993, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 145224, "time": 16757.429581165314, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 146088, "time": 16855.860360622406, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 146488, "time": 16901.36125946045, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 146584, "time": 16912.237450122833, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 146600, "time": 16914.06537795067, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 146608, "time": 16914.97587299347, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 146720, "time": 16927.675501585007, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 147312, "time": 16994.875375270844, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 147536, "time": 17020.624439954758, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 148400, "time": 17118.498862028122, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 148800, "time": 17163.682297229767, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 148896, "time": 17174.599212408066, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 148912, "time": 17176.412121772766, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 148920, "time": 17177.333847522736, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 149032, "time": 17190.03902578354, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 149433, "time": 17236.527674913406, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.724411430708859, "train/action_min": 0.0, "train/action_std": 1.9739475080726343, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.007236532511300655, "train/actor_opt_grad_steps": 35875.0, "train/actor_opt_loss": -3.275233786108844, "train/adv_mag": 0.43054576300152947, "train/adv_max": 0.2488873007647488, "train/adv_mean": 0.004900209884933723, "train/adv_min": -0.3703704253522628, "train/adv_std": 0.02047648510912758, "train/cont_avg": 0.9962550172018348, "train/cont_loss_mean": 0.008395672754310883, "train/cont_loss_std": 0.15220661223716522, "train/cont_neg_acc": 0.5595625765794932, "train/cont_neg_loss": 1.8248720539580803, "train/cont_pos_acc": 0.999842638269477, "train/cont_pos_loss": 0.0017363966995083359, "train/cont_pred": 0.996239568662206, "train/cont_rate": 0.9962550172018348, "train/dyn_loss_mean": 1.0000062869229447, "train/dyn_loss_std": 0.00020107889930832994, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.26284118223115116, "train/extr_critic_critic_opt_grad_steps": 35875.0, "train/extr_critic_critic_opt_loss": 8901.695109796086, "train/extr_critic_mag": 0.595078923286648, "train/extr_critic_max": 0.595078923286648, "train/extr_critic_mean": 0.49764702722020104, "train/extr_critic_min": 0.43248742873515555, "train/extr_critic_std": 0.015942802604655266, "train/extr_return_normed_mag": 0.4661854091314001, "train/extr_return_normed_max": 0.32169026327789374, "train/extr_return_normed_mean": 0.038303182787852524, "train/extr_return_normed_min": -0.3341852630223703, "train/extr_return_normed_std": 0.02675084939756251, "train/extr_return_rate": 0.4002144425194107, "train/extr_return_raw_mag": 0.7859342929420121, "train/extr_return_raw_max": 0.7859342929420121, "train/extr_return_raw_mean": 0.5025472362107093, "train/extr_return_raw_min": 0.13005876636833225, "train/extr_return_raw_std": 0.02675084930357583, "train/extr_reward_mag": 0.3351402758458339, "train/extr_reward_max": 0.3351402758458339, "train/extr_reward_mean": 0.0007735880222167457, "train/extr_reward_min": 2.061555144983694e-07, "train/extr_reward_std": 0.009577166688157725, "train/image_loss_mean": 0.06172721665523468, "train/image_loss_std": 0.08824542944037586, "train/model_loss_mean": 0.6726383443819274, "train/model_loss_std": 0.23110542771056158, "train/model_opt_grad_norm": 21.852112577595843, "train/model_opt_grad_steps": 35843.56880733945, "train/model_opt_loss": 3201.6973188207785, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 4759.174311926606, "train/policy_entropy_mag": 1.3363065982083662, "train/policy_entropy_max": 1.3363065982083662, "train/policy_entropy_mean": 0.15019553151289258, "train/policy_entropy_min": 0.06468655623563933, "train/policy_entropy_std": 0.1881467994610104, "train/policy_logprob_mag": 6.551080172215033, "train/policy_logprob_max": -0.008608146715875066, "train/policy_logprob_mean": -0.1498885081927164, "train/policy_logprob_min": -6.551080172215033, "train/policy_logprob_std": 0.6819158918266996, "train/policy_randomness_mag": 0.6867257843323804, "train/policy_randomness_max": 0.6867257843323804, "train/policy_randomness_mean": 0.07718523897640749, "train/policy_randomness_min": 0.033242315993806636, "train/policy_randomness_std": 0.0966883337962518, "train/post_ent_mag": 39.88906566374892, "train/post_ent_max": 39.88906566374892, "train/post_ent_mean": 38.83366731766167, "train/post_ent_min": 38.0056385950211, "train/post_ent_std": 0.3785179670250744, "train/prior_ent_mag": 40.44210776932743, "train/prior_ent_max": 40.44210776932743, "train/prior_ent_mean": 38.31072305101867, "train/prior_ent_min": 36.649723350454906, "train/prior_ent_std": 0.574895342282199, "train/rep_loss_mean": 1.0000062869229447, "train/rep_loss_std": 0.00020107889930832994, "train/reward_avg": 0.0003773680537802364, "train/reward_loss_mean": 0.0025116587458221123, "train/reward_loss_std": 0.06077117502791893, "train/reward_max_data": 0.3072677761863131, "train/reward_max_pred": 0.1568013303870455, "train/reward_neg_acc": 0.9998699716471751, "train/reward_neg_loss": 0.00045589080650851755, "train/reward_pos_acc": 0.4392523372841773, "train/reward_pos_loss": 3.1031122873319643, "train/reward_pred": 0.00032542706808981, "train/reward_rate": 0.0006495484518348624, "train_stats/mean_log_entropy": 0.1285537804942578, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.010648119263350964, "report/cont_loss_std": 0.19914373755455017, "report/cont_neg_acc": 0.5, "report/cont_neg_loss": 1.6306174993515015, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0011001672828570008, "report/cont_pred": 0.9957848787307739, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.06405778974294662, "report/image_loss_std": 0.09096725285053253, "report/model_loss_mean": 0.6802141666412354, "report/model_loss_std": 0.2796720266342163, "report/post_ent_mag": 40.84775924682617, "report/post_ent_max": 40.84775924682617, "report/post_ent_mean": 39.81566619873047, "report/post_ent_min": 39.113853454589844, "report/post_ent_std": 0.3700603246688843, "report/prior_ent_mag": 40.99814987182617, "report/prior_ent_max": 40.99814987182617, "report/prior_ent_mean": 38.606788635253906, "report/prior_ent_min": 37.131370544433594, "report/prior_ent_std": 0.5595118403434753, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0008422851678915322, "report/reward_loss_mean": 0.005508274771273136, "report/reward_loss_std": 0.10405532270669937, "report/reward_max_data": 0.46875, "report/reward_max_pred": 0.4713456630706787, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0004167164443060756, "report/reward_pos_acc": 0.6666666865348816, "report/reward_pos_loss": 1.738335371017456, "report/reward_pred": 0.0009599054465070367, "report/reward_rate": 0.0029296875, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.05624041706323624, "eval/cont_loss_std": 0.7353277206420898, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 9.44385051727295, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0009106963989324868, "eval/cont_pred": 0.9990993738174438, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.24522477388381958, "eval/image_loss_std": 0.17707966268062592, "eval/model_loss_mean": 0.912153959274292, "eval/model_loss_std": 0.9444635510444641, "eval/post_ent_mag": 40.819400787353516, "eval/post_ent_max": 40.819400787353516, "eval/post_ent_mean": 39.753761291503906, "eval/post_ent_min": 38.87556457519531, "eval/post_ent_std": 0.3403688967227936, "eval/prior_ent_mag": 40.78520965576172, "eval/prior_ent_max": 40.78520965576172, "eval/prior_ent_mean": 38.57713317871094, "eval/prior_ent_min": 37.37281036376953, "eval/prior_ent_std": 0.5634013414382935, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0007232666248455644, "eval/reward_loss_mean": 0.010688750073313713, "eval/reward_loss_std": 0.3331845700740814, "eval/reward_max_data": 0.7406250238418579, "eval/reward_max_pred": 0.011939764022827148, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0002718582400120795, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 10.667169570922852, "eval/reward_pred": 0.00011283473577350378, "eval/reward_rate": 0.0009765625, "replay/size": 148929.0, "replay/inserts": 8752.0, "replay/samples": 35008.0, "replay/insert_wait_avg": 1.5790599791615711e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.364633314352367e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 35736.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 8.046627044677734e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2556104660034, "timer/env.step_count": 1094.0, "timer/env.step_total": 10.896223306655884, "timer/env.step_frac": 0.01089343882968025, "timer/env.step_avg": 0.009959984741001722, "timer/env.step_min": 0.008718013763427734, "timer/env.step_max": 0.034899234771728516, "timer/replay._sample_count": 35008.0, "timer/replay._sample_total": 18.16492533683777, "timer/replay._sample_frac": 0.018160283378340678, "timer/replay._sample_avg": 0.0005188792657917552, "timer/replay._sample_min": 0.00037169456481933594, "timer/replay._sample_max": 0.026810646057128906, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1094.0, "timer/agent.policy_total": 11.468770027160645, "timer/agent.policy_frac": 0.011465839238649732, "timer/agent.policy_avg": 0.010483336405082855, "timer/agent.policy_min": 0.00935053825378418, "timer/agent.policy_max": 0.03560996055603027, "timer/dataset_train_count": 2188.0, "timer/dataset_train_total": 0.3687748908996582, "timer/dataset_train_frac": 0.00036868065226632594, "timer/dataset_train_avg": 0.00016854428286090412, "timer/dataset_train_min": 8.893013000488281e-05, "timer/dataset_train_max": 0.0008165836334228516, "timer/agent.train_count": 2188.0, "timer/agent.train_total": 975.0525319576263, "timer/agent.train_frac": 0.9748033620159997, "timer/agent.train_avg": 0.4456364405656428, "timer/agent.train_min": 0.4325599670410156, "timer/agent.train_max": 0.5649313926696777, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4728989601135254, "timer/agent.report_frac": 0.00047277811307972487, "timer/agent.report_avg": 0.2364494800567627, "timer/agent.report_min": 0.22937297821044922, "timer/agent.report_max": 0.24352598190307617, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.981590270996094e-05, "timer/dataset_eval_frac": 3.9805727949290214e-08, "timer/dataset_eval_avg": 3.981590270996094e-05, "timer/dataset_eval_min": 3.981590270996094e-05, "timer/dataset_eval_max": 3.981590270996094e-05, "fps": 8.749647650199993}
{"step": 149624, "time": 17257.99828338623, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 149848, "time": 17283.492859601974, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 150072, "time": 17311.75534415245, "eval_episode/length": 157.0, "eval_episode/score": 0.5093749761581421, "eval_episode/reward_rate": 0.006329113924050633}
{"step": 150072, "time": 17314.018356084824, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 17314.026365995407, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 17314.0321559906, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 17314.037776470184, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 17314.04327893257, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 17314.048634052277, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 17314.05415081978, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150712, "time": 17386.8659927845, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 151112, "time": 17432.32109975815, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 151208, "time": 17443.277789354324, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 151224, "time": 17445.086906909943, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 151232, "time": 17445.995740413666, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 151344, "time": 17458.741886615753, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 151936, "time": 17526.09442973137, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 152160, "time": 17551.59180378914, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 153024, "time": 17649.91844177246, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 153424, "time": 17695.47568655014, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 153520, "time": 17706.363308668137, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 153536, "time": 17708.17422604561, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 153544, "time": 17709.087346076965, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 153656, "time": 17721.910702228546, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 154248, "time": 17789.119217395782, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 154472, "time": 17814.61752486229, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 155336, "time": 17912.799920082092, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 155736, "time": 17958.78834581375, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 155832, "time": 17969.70938515663, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 155848, "time": 17971.547797203064, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 155856, "time": 17972.463558912277, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 155968, "time": 17985.333535194397, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 156560, "time": 18052.62352180481, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 156784, "time": 18078.08602952957, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 157648, "time": 18176.290755987167, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 158048, "time": 18221.74697113037, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 158144, "time": 18232.653905153275, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 158160, "time": 18234.494827508926, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 158168, "time": 18235.40756392479, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 158173, "time": 18236.840738534927, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 1.281498321115154, "train/action_min": 0.0, "train/action_std": 1.8681845539781057, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0033603039565900145, "train/actor_opt_grad_steps": 38060.0, "train/actor_opt_loss": -9.177751397433346, "train/adv_mag": 0.3703366130182188, "train/adv_max": 0.11884941181091413, "train/adv_mean": -0.004295631355556051, "train/adv_min": -0.33149722041604723, "train/adv_std": 0.008862081899192848, "train/cont_avg": 0.996174015410959, "train/cont_loss_mean": 0.008561152418901012, "train/cont_loss_std": 0.1562364096668247, "train/cont_neg_acc": 0.5642747506155946, "train/cont_neg_loss": 1.832489080387712, "train/cont_pos_acc": 0.9998881071125536, "train/cont_pos_loss": 0.0017766312232247213, "train/cont_pred": 0.9961526222424965, "train/cont_rate": 0.996174015410959, "train/dyn_loss_mean": 1.6948610288367423, "train/dyn_loss_std": 0.007288309207601264, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.09985870800882612, "train/extr_critic_critic_opt_grad_steps": 38060.0, "train/extr_critic_critic_opt_loss": 10992.280964611871, "train/extr_critic_mag": 0.5522080485679243, "train/extr_critic_max": 0.5522080485679243, "train/extr_critic_mean": 0.4993602149018414, "train/extr_critic_min": 0.478503196751146, "train/extr_critic_std": 0.006738923688857182, "train/extr_return_normed_mag": 0.38229828678309646, "train/extr_return_normed_max": 0.15252948705464192, "train/extr_return_normed_mean": 0.0032027898666817474, "train/extr_return_normed_min": -0.3174529941114661, "train/extr_return_normed_std": 0.011503434327503318, "train/extr_return_rate": 0.48355750263328123, "train/extr_return_raw_mag": 0.6443912499843667, "train/extr_return_raw_max": 0.6443912499843667, "train/extr_return_raw_mean": 0.4950645736091213, "train/extr_return_raw_min": 0.17440876909042602, "train/extr_return_raw_std": 0.011503434314745474, "train/extr_reward_mag": 0.20594467311144965, "train/extr_reward_max": 0.20594467311144965, "train/extr_reward_mean": 0.00011822852879190805, "train/extr_reward_min": 1.9487180666292095e-07, "train/extr_reward_std": 0.0033446855115272065, "train/image_loss_mean": 0.06456724360381087, "train/image_loss_std": 0.09117154811070935, "train/model_loss_mean": 1.0923902904061966, "train/model_loss_std": 0.2366358197579101, "train/model_opt_grad_norm": 21.95144530953882, "train/model_opt_grad_steps": 38026.42465753425, "train/model_opt_loss": 4287.196578909818, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 4805.936073059361, "train/policy_entropy_mag": 1.2331288421535056, "train/policy_entropy_max": 1.2331288421535056, "train/policy_entropy_mean": 0.13600454098421688, "train/policy_entropy_min": 0.0646864941267118, "train/policy_entropy_std": 0.1638980298962223, "train/policy_logprob_mag": 6.55108026391295, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.1362824456332481, "train/policy_logprob_min": -6.55108026391295, "train/policy_logprob_std": 0.6685971255716123, "train/policy_randomness_mag": 0.6337029033055589, "train/policy_randomness_max": 0.6337029033055589, "train/policy_randomness_mean": 0.06989251313620506, "train/policy_randomness_min": 0.03324228254695461, "train/policy_randomness_std": 0.08422693072660872, "train/post_ent_mag": 40.649042155644665, "train/post_ent_max": 40.649042155644665, "train/post_ent_mean": 39.574413961471485, "train/post_ent_min": 38.744688687259206, "train/post_ent_std": 0.3801080280549178, "train/prior_ent_mag": 41.1461583316054, "train/prior_ent_max": 41.1461583316054, "train/prior_ent_mean": 38.956763576699174, "train/prior_ent_min": 37.48498075302333, "train/prior_ent_std": 0.5410714427085772, "train/rep_loss_mean": 1.6948610288367423, "train/rep_loss_std": 0.007288309207601264, "train/reward_avg": 0.0003571810776773908, "train/reward_loss_mean": 0.002345231337766227, "train/reward_loss_std": 0.058658571396348363, "train/reward_max_data": 0.2870005698508868, "train/reward_max_pred": 0.158649141385675, "train/reward_neg_acc": 0.9998348924122988, "train/reward_neg_loss": 0.00041831363383300503, "train/reward_pos_acc": 0.45714285771052043, "train/reward_pos_loss": 3.061216148450261, "train/reward_pred": 0.0003114956990309638, "train/reward_rate": 0.000633204908675799, "train_stats/mean_log_entropy": 0.1441322906363395, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.006828015670180321, "report/cont_loss_std": 0.1700180023908615, "report/cont_neg_acc": 0.75, "report/cont_neg_loss": 1.361156702041626, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0015169231919571757, "report/cont_pred": 0.9956396818161011, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.05325037240982056, "report/image_loss_std": 0.08582054078578949, "report/model_loss_mean": 0.6602249145507812, "report/model_loss_std": 0.1932634562253952, "report/post_ent_mag": 43.73240280151367, "report/post_ent_max": 43.73240280151367, "report/post_ent_mean": 42.21418762207031, "report/post_ent_min": 41.28028869628906, "report/post_ent_std": 0.46016693115234375, "report/prior_ent_mag": 44.53598403930664, "report/prior_ent_max": 44.53598403930664, "report/prior_ent_mean": 43.19817352294922, "report/prior_ent_min": 41.398529052734375, "report/prior_ent_std": 0.476579487323761, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.0001465529203414917, "report/reward_loss_std": 0.001142009743489325, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.007906794548034668, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0001465529203414917, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 6.295111961662769e-05, "report/reward_rate": 0.0, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.01846221461892128, "eval/cont_loss_std": 0.40259647369384766, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 8.688843727111816, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0014947367599233985, "eval/cont_pred": 0.9985287189483643, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.225480318069458, "eval/image_loss_std": 0.17147180438041687, "eval/model_loss_mean": 0.844150960445404, "eval/model_loss_std": 0.4429404139518738, "eval/post_ent_mag": 43.61481475830078, "eval/post_ent_max": 43.61481475830078, "eval/post_ent_mean": 42.217987060546875, "eval/post_ent_min": 41.343994140625, "eval/post_ent_std": 0.43798404932022095, "eval/prior_ent_mag": 44.44328308105469, "eval/prior_ent_max": 44.44328308105469, "eval/prior_ent_mean": 43.240264892578125, "eval/prior_ent_min": 41.22071075439453, "eval/prior_ent_std": 0.5317614674568176, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00020842626690864563, "eval/reward_loss_std": 0.0019287476316094398, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.013059139251708984, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00020842626690864563, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 8.231296669691801e-05, "eval/reward_rate": 0.0, "replay/size": 157669.0, "replay/inserts": 8740.0, "replay/samples": 34960.0, "replay/insert_wait_avg": 1.5678067501949772e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.348488888424103e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 38048.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0558684391958902e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.493661880493164e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2978596687317, "timer/env.step_count": 1092.0, "timer/env.step_total": 10.799020290374756, "timer/env.step_frac": 0.010795804655576354, "timer/env.step_avg": 0.009889212720123403, "timer/env.step_min": 0.008589506149291992, "timer/env.step_max": 0.0355372428894043, "timer/replay._sample_count": 34960.0, "timer/replay._sample_total": 18.212643146514893, "timer/replay._sample_frac": 0.018207219950012055, "timer/replay._sample_avg": 0.0005209566117424169, "timer/replay._sample_min": 0.00033855438232421875, "timer/replay._sample_max": 0.021180152893066406, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1381.0, "timer/agent.policy_total": 13.952024459838867, "timer/agent.policy_frac": 0.013947869951915477, "timer/agent.policy_avg": 0.01010284175223669, "timer/agent.policy_min": 0.008719921112060547, "timer/agent.policy_max": 0.0369420051574707, "timer/dataset_train_count": 2185.0, "timer/dataset_train_total": 0.3760099411010742, "timer/dataset_train_frac": 0.0003758979762543902, "timer/dataset_train_avg": 0.00017208692956570903, "timer/dataset_train_min": 9.202957153320312e-05, "timer/dataset_train_max": 0.0008068084716796875, "timer/agent.train_count": 2185.0, "timer/agent.train_total": 970.4103722572327, "timer/agent.train_frac": 0.9701214122147609, "timer/agent.train_avg": 0.4441237401634932, "timer/agent.train_min": 0.4339559078216553, "timer/agent.train_max": 0.5780987739562988, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47390198707580566, "timer/agent.report_frac": 0.0004737608728191697, "timer/agent.report_avg": 0.23695099353790283, "timer/agent.report_min": 0.22949433326721191, "timer/agent.report_max": 0.24440765380859375, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.218650817871094e-05, "timer/dataset_eval_frac": 3.217692397079619e-08, "timer/dataset_eval_avg": 3.218650817871094e-05, "timer/dataset_eval_min": 3.218650817871094e-05, "timer/dataset_eval_max": 3.218650817871094e-05, "fps": 8.737280173913147}
{"step": 158280, "time": 18248.810837745667, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 158872, "time": 18316.270877361298, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 159096, "time": 18341.786894083023, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 159960, "time": 18440.093495845795, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 160056, "time": 18455.85201191902, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 18455.859520435333, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 18455.865031719208, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 18455.87045764923, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 18455.87592434883, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 18455.881319761276, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 18455.887437343597, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 18455.89337682724, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160360, "time": 18490.39928507805, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 160456, "time": 18501.36285495758, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 160472, "time": 18503.174201011658, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 160480, "time": 18504.098801851273, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 160592, "time": 18516.79835820198, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 161184, "time": 18584.252096891403, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 161408, "time": 18609.674723148346, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 162272, "time": 18708.034561872482, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 162672, "time": 18753.472088098526, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 162768, "time": 18764.447835445404, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 162784, "time": 18766.2776556015, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 162792, "time": 18767.183656215668, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 162904, "time": 18779.9485309124, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 163496, "time": 18847.081592321396, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 163720, "time": 18872.572276115417, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 164584, "time": 18971.297830343246, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 164984, "time": 19016.740877628326, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 165080, "time": 19027.68046951294, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 165096, "time": 19029.49720263481, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 165104, "time": 19030.408181905746, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 165216, "time": 19043.188901662827, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 165808, "time": 19110.518727064133, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 166032, "time": 19136.015021324158, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 166896, "time": 19234.171529769897, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 166913, "time": 19236.97036910057, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.5330844144208715, "train/action_min": 0.0, "train/action_std": 1.8722785847996353, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.002404558174087828, "train/actor_opt_grad_steps": 40245.0, "train/actor_opt_loss": -6.162834725248704, "train/adv_mag": 0.24137565432065125, "train/adv_max": 0.10817894066145661, "train/adv_mean": -0.0028805264331605456, "train/adv_min": -0.20409046626145685, "train/adv_std": 0.005913829745472742, "train/cont_avg": 0.9963714879587156, "train/cont_loss_mean": 0.008174319496034397, "train/cont_loss_std": 0.1510760925834093, "train/cont_neg_acc": 0.5552816980741393, "train/cont_neg_loss": 1.801209250077531, "train/cont_pos_acc": 0.9998786337331894, "train/cont_pos_loss": 0.0017461035902069351, "train/cont_pred": 0.9963113184368938, "train/cont_rate": 0.9963714879587156, "train/dyn_loss_mean": 1.0000027543907866, "train/dyn_loss_std": 8.181388903897332e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.05364135542987, "train/extr_critic_critic_opt_grad_steps": 40245.0, "train/extr_critic_critic_opt_loss": 9413.42169693413, "train/extr_critic_mag": 0.4119315459093916, "train/extr_critic_max": 0.4119315459093916, "train/extr_critic_mean": 0.3237549293478695, "train/extr_critic_min": 0.306002621256977, "train/extr_critic_std": 0.00455388502771069, "train/extr_return_normed_mag": 0.25887269075583974, "train/extr_return_normed_max": 0.14340018132411012, "train/extr_return_normed_mean": 0.0007494294208812989, "train/extr_return_normed_min": -0.18256499727658176, "train/extr_return_normed_std": 0.007784169517594193, "train/extr_return_rate": 0.00018933965104825392, "train/extr_return_raw_mag": 0.4635251249195239, "train/extr_return_raw_max": 0.4635251249195239, "train/extr_return_raw_mean": 0.3208743899787238, "train/extr_return_raw_min": 0.1375599464555399, "train/extr_return_raw_std": 0.007784169514390101, "train/extr_reward_mag": 0.17472922801971436, "train/extr_reward_max": 0.17472922801971436, "train/extr_reward_mean": 8.640007635589127e-05, "train/extr_reward_min": 1.4491037491264692e-07, "train/extr_reward_std": 0.0028309089299801355, "train/image_loss_mean": 0.06587370869558339, "train/image_loss_std": 0.09241800919311856, "train/model_loss_mean": 0.6761202508703285, "train/model_loss_std": 0.2257770508391048, "train/model_opt_grad_norm": 20.903380831447215, "train/model_opt_grad_steps": 40209.83027522936, "train/model_opt_loss": 2831.0311105710653, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 4208.715596330275, "train/policy_entropy_mag": 1.348523203932911, "train/policy_entropy_max": 1.348523203932911, "train/policy_entropy_mean": 0.14886680341095004, "train/policy_entropy_min": 0.06468660295556444, "train/policy_entropy_std": 0.1837429105210195, "train/policy_logprob_mag": 6.551080231272846, "train/policy_logprob_max": -0.008608215620929222, "train/policy_logprob_mean": -0.1488594560448183, "train/policy_logprob_min": -6.551080231272846, "train/policy_logprob_std": 0.6848212573506417, "train/policy_randomness_mag": 0.6930038781341062, "train/policy_randomness_max": 0.6930038781341062, "train/policy_randomness_mean": 0.07650240806332968, "train/policy_randomness_min": 0.033242340088574164, "train/policy_randomness_std": 0.09442518251614833, "train/post_ent_mag": 43.399330104162935, "train/post_ent_max": 43.399330104162935, "train/post_ent_mean": 42.15914675511351, "train/post_ent_min": 41.25211169741569, "train/post_ent_std": 0.4297823400125591, "train/prior_ent_mag": 44.623997977020544, "train/prior_ent_max": 44.623997977020544, "train/prior_ent_mean": 43.331265248289895, "train/prior_ent_min": 41.34215648896104, "train/prior_ent_std": 0.5371522236307826, "train/rep_loss_mean": 1.0000027543907866, "train/rep_loss_std": 8.181388903897332e-05, "train/reward_avg": 0.0003441346896646241, "train/reward_loss_mean": 0.002070547900575965, "train/reward_loss_std": 0.051759302730398644, "train/reward_max_data": 0.276462155915455, "train/reward_max_pred": 0.13259145590143467, "train/reward_neg_acc": 0.999923802023634, "train/reward_neg_loss": 0.00033657805694570475, "train/reward_pos_acc": 0.43000000059604643, "train/reward_pos_loss": 2.9564877274632453, "train/reward_pred": 0.00027555409058450014, "train/reward_rate": 0.0005913130733944954, "train_stats/mean_log_entropy": 0.10361215152910777, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.014511527493596077, "report/cont_loss_std": 0.26128461956977844, "report/cont_neg_acc": 0.5, "report/cont_neg_loss": 2.962371587753296, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0029512911569327116, "report/cont_pred": 0.9951884746551514, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07916730642318726, "report/image_loss_std": 0.10859039425849915, "report/model_loss_mean": 0.6943831443786621, "report/model_loss_std": 0.28496384620666504, "report/post_ent_mag": 42.801353454589844, "report/post_ent_max": 42.801353454589844, "report/post_ent_mean": 41.781036376953125, "report/post_ent_min": 40.65100860595703, "report/post_ent_std": 0.42879214882850647, "report/prior_ent_mag": 44.60914993286133, "report/prior_ent_max": 44.60914993286133, "report/prior_ent_mean": 43.419273376464844, "report/prior_ent_min": 41.3807373046875, "report/prior_ent_std": 0.5215850472450256, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.0007042991928756237, "report/reward_loss_std": 0.005338272079825401, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.06149101257324219, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0007042991928756237, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00036474945954978466, "report/reward_rate": 0.0, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.02967812307178974, "eval/cont_loss_std": 0.5474894642829895, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 12.066415786743164, "eval/cont_pos_acc": 0.9970645904541016, "eval/cont_pos_loss": 0.006122868042439222, "eval/cont_pred": 0.9971989393234253, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.19203639030456543, "eval/image_loss_std": 0.19188234210014343, "eval/model_loss_mean": 0.8220728039741516, "eval/model_loss_std": 0.5735133290290833, "eval/post_ent_mag": 42.68575668334961, "eval/post_ent_max": 42.68575668334961, "eval/post_ent_mean": 41.388916015625, "eval/post_ent_min": 40.565982818603516, "eval/post_ent_std": 0.4192819595336914, "eval/prior_ent_mag": 44.64552307128906, "eval/prior_ent_max": 44.64552307128906, "eval/prior_ent_mean": 43.033329010009766, "eval/prior_ent_min": 41.48724365234375, "eval/prior_ent_std": 0.5471217036247253, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0003583035431802273, "eval/reward_loss_std": 0.007379388902336359, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.10936641693115234, "eval/reward_neg_acc": 0.9990234375, "eval/reward_neg_loss": 0.0003583035431802273, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00016102544032037258, "eval/reward_rate": 0.0, "replay/size": 166409.0, "replay/inserts": 8740.0, "replay/samples": 34960.0, "replay/insert_wait_avg": 1.5312255929209274e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.386133927229612e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 40360.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.157959439762736e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.685754776000977e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1166698932648, "timer/env.step_count": 1093.0, "timer/env.step_total": 10.685243844985962, "timer/env.step_frac": 0.010683997344156178, "timer/env.step_avg": 0.009776069391569955, "timer/env.step_min": 0.008649826049804688, "timer/env.step_max": 0.03514838218688965, "timer/replay._sample_count": 34960.0, "timer/replay._sample_total": 18.071691274642944, "timer/replay._sample_frac": 0.018069583098311526, "timer/replay._sample_avg": 0.0005169248076270865, "timer/replay._sample_min": 0.00034809112548828125, "timer/replay._sample_max": 0.02241683006286621, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1382.0, "timer/agent.policy_total": 13.840965986251831, "timer/agent.policy_frac": 0.013839351350606903, "timer/agent.policy_avg": 0.010015170757056317, "timer/agent.policy_min": 0.00868988037109375, "timer/agent.policy_max": 0.03577685356140137, "timer/dataset_train_count": 2185.0, "timer/dataset_train_total": 0.39643073081970215, "timer/dataset_train_frac": 0.0003963844846841822, "timer/dataset_train_avg": 0.00018143282875043577, "timer/dataset_train_min": 9.274482727050781e-05, "timer/dataset_train_max": 0.016027450561523438, "timer/agent.train_count": 2185.0, "timer/agent.train_total": 970.5243542194366, "timer/agent.train_frac": 0.9704111364557234, "timer/agent.train_avg": 0.4441759058212525, "timer/agent.train_min": 0.43494510650634766, "timer/agent.train_max": 0.585263729095459, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47394442558288574, "timer/agent.report_frac": 0.000473889136987854, "timer/agent.report_avg": 0.23697221279144287, "timer/agent.report_min": 0.2300276756286621, "timer/agent.report_max": 0.24391674995422363, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.86102294921875e-05, "timer/dataset_eval_frac": 2.860689192915949e-08, "timer/dataset_eval_avg": 2.86102294921875e-05, "timer/dataset_eval_min": 2.86102294921875e-05, "timer/dataset_eval_max": 2.86102294921875e-05, "fps": 8.738867290283036}
{"step": 167296, "time": 19280.71174812317, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 167392, "time": 19291.71999168396, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 167408, "time": 19293.571715831757, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 167416, "time": 19294.492346286774, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 167528, "time": 19307.414479017258, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 168120, "time": 19375.30127620697, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 168344, "time": 19401.059508562088, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 169208, "time": 19500.11958861351, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 169608, "time": 19545.96060848236, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 169704, "time": 19556.93732357025, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 169720, "time": 19558.78082895279, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 169728, "time": 19559.69592809677, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 169840, "time": 19572.63982629776, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 170040, "time": 19601.152114629745, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 19601.158509016037, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 19601.164052248, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 19601.16952562332, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 19601.174998044968, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 19601.180601119995, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 19601.186205625534, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 19601.19177556038, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170432, "time": 19646.055846214294, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 170656, "time": 19671.803572416306, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 171520, "time": 19770.86843943596, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 171920, "time": 19816.706990480423, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 172016, "time": 19827.67332959175, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 172032, "time": 19829.794949769974, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 172040, "time": 19830.834553718567, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 172152, "time": 19843.74005126953, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 172744, "time": 19911.546509742737, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 172968, "time": 19937.23465871811, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 173832, "time": 20036.116072177887, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 174232, "time": 20081.945392131805, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 174328, "time": 20092.914710760117, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 174344, "time": 20094.745408296585, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 174352, "time": 20095.661375761032, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 174464, "time": 20108.48784327507, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 175056, "time": 20176.36079621315, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 175280, "time": 20202.03501033783, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 175581, "time": 20237.34268760681, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.1625343709497407, "train/action_min": 0.0, "train/action_std": 2.2253928415236937, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.002087189141051492, "train/actor_opt_grad_steps": 42420.0, "train/actor_opt_loss": -6.655761854989188, "train/adv_mag": 0.21754297524827965, "train/adv_max": 0.1493720739805204, "train/adv_mean": -0.0019852339464705437, "train/adv_min": -0.1610370869598081, "train/adv_std": 0.005876106718632345, "train/cont_avg": 0.9960532474078341, "train/cont_loss_mean": 0.009779881654320121, "train/cont_loss_std": 0.1708757128643756, "train/cont_neg_acc": 0.540856333606154, "train/cont_neg_loss": 1.9638909493528403, "train/cont_pos_acc": 0.9998464142122576, "train/cont_pos_loss": 0.0018374070062190466, "train/cont_pred": 0.9962051557505736, "train/cont_rate": 0.9960532474078341, "train/dyn_loss_mean": 1.0000006636166903, "train/dyn_loss_std": 1.8299949633854566e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.03617975997313651, "train/extr_critic_critic_opt_grad_steps": 42420.0, "train/extr_critic_critic_opt_loss": 9918.618700721847, "train/extr_critic_mag": 0.3536191349205334, "train/extr_critic_max": 0.3536191349205334, "train/extr_critic_mean": 0.21785927883216313, "train/extr_critic_min": 0.19082627483227285, "train/extr_critic_std": 0.004966944632601113, "train/extr_return_normed_mag": 0.25944318289306306, "train/extr_return_normed_max": 0.20976491636394906, "train/extr_return_normed_mean": 0.00040763504472410934, "train/extr_return_normed_min": -0.12613427096522897, "train/extr_return_normed_std": 0.008107590749816892, "train/extr_return_rate": 0.0002889185057175646, "train/extr_return_raw_mag": 0.42523129538456966, "train/extr_return_raw_max": 0.42523129538456966, "train/extr_return_raw_mean": 0.21587402507456765, "train/extr_return_raw_min": 0.08933210853607423, "train/extr_return_raw_std": 0.008107590673637281, "train/extr_reward_mag": 0.23997020556630078, "train/extr_reward_max": 0.23997020556630078, "train/extr_reward_mean": 0.00013231502581232985, "train/extr_reward_min": 4.12013673562608e-08, "train/extr_reward_std": 0.0040312140440640215, "train/image_loss_mean": 0.06525809393363065, "train/image_loss_std": 0.09185132521638123, "train/model_loss_mean": 0.6768959046508859, "train/model_loss_std": 0.23562191450788128, "train/model_opt_grad_norm": 20.96753729763119, "train/model_opt_grad_steps": 42382.70506912442, "train/model_opt_loss": 2612.2918470532113, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3870.967741935484, "train/policy_entropy_mag": 1.3425003976865848, "train/policy_entropy_max": 1.3425003976865848, "train/policy_entropy_mean": 0.23715295165365194, "train/policy_entropy_min": 0.06468672737959892, "train/policy_entropy_std": 0.23956455496324372, "train/policy_logprob_mag": 6.55108006429013, "train/policy_logprob_max": -0.008608300457729997, "train/policy_logprob_mean": -0.23776434602275973, "train/policy_logprob_min": -6.55108006429013, "train/policy_logprob_std": 0.7522731231104943, "train/policy_randomness_mag": 0.6899087722949718, "train/policy_randomness_max": 0.6899087722949718, "train/policy_randomness_mean": 0.12187251561935047, "train/policy_randomness_min": 0.033242403001691886, "train/policy_randomness_std": 0.12311183462082516, "train/post_ent_mag": 42.742554431686756, "train/post_ent_max": 42.742554431686756, "train/post_ent_mean": 41.402489024922595, "train/post_ent_min": 40.38243285851544, "train/post_ent_std": 0.47125102105777933, "train/prior_ent_mag": 44.23989771478187, "train/prior_ent_max": 44.23989771478187, "train/prior_ent_mean": 42.83743027717836, "train/prior_ent_min": 40.84441059305921, "train/prior_ent_std": 0.5781730410690131, "train/rep_loss_mean": 1.0000006636166903, "train/rep_loss_std": 1.8299949633854566e-05, "train/reward_avg": 0.0003031506525335966, "train/reward_loss_mean": 0.001857509964101729, "train/reward_loss_std": 0.047652977893331776, "train/reward_max_data": 0.2545362906315909, "train/reward_max_pred": 0.15054208397315944, "train/reward_neg_acc": 0.9998513935348405, "train/reward_neg_loss": 0.0003437293719040007, "train/reward_pos_acc": 0.5035087729755201, "train/reward_pos_loss": 2.7274830231541083, "train/reward_pred": 0.00026587339027995063, "train/reward_rate": 0.0005490351382488479, "train_stats/mean_log_entropy": 0.2658154728912538, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.012262921780347824, "report/cont_loss_std": 0.22683462500572205, "report/cont_neg_acc": 0.3333333432674408, "report/cont_neg_loss": 3.4158987998962402, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0022620356176048517, "report/cont_pred": 0.9968734979629517, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07138790190219879, "report/image_loss_std": 0.0907750055193901, "report/model_loss_mean": 0.6847860813140869, "report/model_loss_std": 0.24422414600849152, "report/post_ent_mag": 43.045108795166016, "report/post_ent_max": 43.045108795166016, "report/post_ent_mean": 41.92937088012695, "report/post_ent_min": 40.7104377746582, "report/post_ent_std": 0.47359156608581543, "report/prior_ent_mag": 43.90290832519531, "report/prior_ent_max": 43.90290832519531, "report/prior_ent_mean": 42.68218231201172, "report/prior_ent_min": 41.132713317871094, "report/prior_ent_std": 0.5473483204841614, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.0011352160945534706, "report/reward_loss_std": 0.0150890639051795, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.2376500368118286, "report/reward_neg_acc": 0.9990234375, "report/reward_neg_loss": 0.0011352160945534706, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0005637712310999632, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.041010819375514984, "eval/cont_loss_std": 0.6907983422279358, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 12.671880722045898, "eval/cont_pos_acc": 0.9980410933494568, "eval/cont_pos_loss": 0.003897589398548007, "eval/cont_pred": 0.9979186654090881, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.22901543974876404, "eval/image_loss_std": 0.1736510545015335, "eval/model_loss_mean": 0.8703155517578125, "eval/model_loss_std": 0.7109969258308411, "eval/post_ent_mag": 42.810569763183594, "eval/post_ent_max": 42.810569763183594, "eval/post_ent_mean": 41.49229431152344, "eval/post_ent_min": 40.72522735595703, "eval/post_ent_std": 0.4216006398200989, "eval/prior_ent_mag": 43.721710205078125, "eval/prior_ent_max": 43.721710205078125, "eval/prior_ent_mean": 42.14599609375, "eval/prior_ent_min": 40.23069763183594, "eval/prior_ent_std": 0.5966728329658508, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0002892776392400265, "eval/reward_loss_std": 0.00349837401881814, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.029468178749084473, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0002892776392400265, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00011900952085852623, "eval/reward_rate": 0.0, "replay/size": 175077.0, "replay/inserts": 8668.0, "replay/samples": 34672.0, "replay/insert_wait_avg": 1.5723853822011907e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.495070912071126e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 42672.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.106398328365339e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.791685104370117e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3566403388977, "timer/env.step_count": 1083.0, "timer/env.step_total": 10.582440376281738, "timer/env.step_frac": 0.01057866759668497, "timer/env.step_avg": 0.009771413089826167, "timer/env.step_min": 0.008726358413696289, "timer/env.step_max": 0.03439044952392578, "timer/replay._sample_count": 34672.0, "timer/replay._sample_total": 18.858251333236694, "timer/replay._sample_frac": 0.018851528117860002, "timer/replay._sample_avg": 0.0005439043416369605, "timer/replay._sample_min": 0.00033402442932128906, "timer/replay._sample_max": 0.013525247573852539, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1372.0, "timer/agent.policy_total": 14.436146020889282, "timer/agent.policy_frac": 0.014430999344392466, "timer/agent.policy_avg": 0.010521972318432422, "timer/agent.policy_min": 0.008714437484741211, "timer/agent.policy_max": 0.08709549903869629, "timer/dataset_train_count": 2167.0, "timer/dataset_train_total": 0.38592028617858887, "timer/dataset_train_frac": 0.0003857827005055397, "timer/dataset_train_avg": 0.00017808965675061785, "timer/dataset_train_min": 9.584426879882812e-05, "timer/dataset_train_max": 0.001524209976196289, "timer/agent.train_count": 2167.0, "timer/agent.train_total": 969.9658050537109, "timer/agent.train_frac": 0.9696199994485056, "timer/agent.train_avg": 0.4476076626920678, "timer/agent.train_min": 0.4381415843963623, "timer/agent.train_max": 0.6078686714172363, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47653627395629883, "timer/agent.report_frac": 0.00047636638248820873, "timer/agent.report_avg": 0.23826813697814941, "timer/agent.report_min": 0.2291860580444336, "timer/agent.report_max": 0.24735021591186523, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.1948089599609375e-05, "timer/dataset_eval_frac": 3.1936699684210725e-08, "timer/dataset_eval_avg": 3.1948089599609375e-05, "timer/dataset_eval_min": 3.1948089599609375e-05, "timer/dataset_eval_max": 3.1948089599609375e-05, "fps": 8.664780478207922}
{"step": 176144, "time": 20301.730041503906, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 176544, "time": 20347.552946329117, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 176640, "time": 20358.631296396255, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 176656, "time": 20360.46266746521, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 176664, "time": 20361.38197159767, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 176776, "time": 20374.19014120102, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 177368, "time": 20442.203072309494, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 177592, "time": 20467.832226753235, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 178456, "time": 20567.09063720703, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 178856, "time": 20612.971752405167, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 178952, "time": 20623.997599363327, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 178968, "time": 20625.841791152954, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 178976, "time": 20626.75982451439, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 179088, "time": 20639.54288959503, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 179616, "time": 20700.053554296494, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 179680, "time": 20707.389907836914, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 179904, "time": 20733.136630296707, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 180024, "time": 20751.935109376907, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 20751.942438840866, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 20751.948100328445, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 20751.95404958725, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 20751.959373235703, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 20751.96480369568, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 20751.970414161682, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 20751.976687669754, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180424, "time": 20798.24783182144, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 180768, "time": 20837.79307436943, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 181264, "time": 20894.606776714325, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 181288, "time": 20897.363541841507, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 181400, "time": 20910.18078136444, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 181928, "time": 20970.572538137436, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 181992, "time": 20977.885724782944, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 182216, "time": 21003.615433454514, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 182736, "time": 21063.11959338188, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 183080, "time": 21102.45974254608, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 183576, "time": 21159.67190861702, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 183600, "time": 21162.495383262634, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 183712, "time": 21175.217057704926, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 184240, "time": 21235.525680541992, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 184249, "time": 21237.42228269577, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.4557413549467166, "train/action_min": 0.0, "train/action_std": 2.1819202801049578, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.001974038786977993, "train/actor_opt_grad_steps": 44590.0, "train/actor_opt_loss": -7.020080783400118, "train/adv_mag": 0.32727086660774074, "train/adv_max": 0.26155987375068224, "train/adv_mean": -0.0007500910254379478, "train/adv_min": -0.2512229973544723, "train/adv_std": 0.01331552239735761, "train/cont_avg": 0.9962377592165899, "train/cont_loss_mean": 0.008640975011126375, "train/cont_loss_std": 0.1545735539102386, "train/cont_neg_acc": 0.5691866996550115, "train/cont_neg_loss": 1.7927520262848837, "train/cont_pos_acc": 0.9998599315568599, "train/cont_pos_loss": 0.0019142279996373582, "train/cont_pred": 0.9961231916730854, "train/cont_rate": 0.9962377592165899, "train/dyn_loss_mean": 1.0000000181286017, "train/dyn_loss_std": 5.75164851758303e-07, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.07224048324753338, "train/extr_critic_critic_opt_grad_steps": 44590.0, "train/extr_critic_critic_opt_loss": 7200.678039832049, "train/extr_critic_mag": 0.5024123554405528, "train/extr_critic_max": 0.5024123554405528, "train/extr_critic_mean": 0.14970510889033567, "train/extr_critic_min": 0.1348743235460624, "train/extr_critic_std": 0.01956882465293863, "train/extr_return_normed_mag": 0.44695706229468096, "train/extr_return_normed_max": 0.42855822837435154, "train/extr_return_normed_mean": 0.004879668055508677, "train/extr_return_normed_min": -0.10243134894129317, "train/extr_return_normed_std": 0.024969950646659883, "train/extr_return_rate": 0.0033725160309532013, "train/extr_return_raw_mag": 0.5726335834934965, "train/extr_return_raw_max": 0.5726335834934965, "train/extr_return_raw_mean": 0.1489550291049865, "train/extr_return_raw_min": 0.0416440051478175, "train/extr_return_raw_std": 0.024969950737860826, "train/extr_reward_mag": 0.48061405788368894, "train/extr_reward_max": 0.48061405788368894, "train/extr_reward_mean": 0.0004743102255673255, "train/extr_reward_min": 1.5931195377754176e-07, "train/extr_reward_std": 0.009688800810659218, "train/image_loss_mean": 0.06549751022100998, "train/image_loss_std": 0.09211095443107016, "train/model_loss_mean": 0.6761076054814774, "train/model_loss_std": 0.22696128082440195, "train/model_opt_grad_norm": 19.872695791007185, "train/model_opt_grad_steps": 44551.124423963134, "train/model_opt_loss": 3053.7577224942397, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 4516.129032258064, "train/policy_entropy_mag": 1.5211039314621604, "train/policy_entropy_max": 1.5211039314621604, "train/policy_entropy_mean": 0.2760417500536563, "train/policy_entropy_min": 0.06468680092403965, "train/policy_entropy_std": 0.2572068545950173, "train/policy_logprob_mag": 6.5510793677123464, "train/policy_logprob_max": -0.00860837513091652, "train/policy_logprob_mean": -0.2760126836563585, "train/policy_logprob_min": -6.5510793677123464, "train/policy_logprob_std": 0.7795812737557196, "train/policy_randomness_mag": 0.7816928350431029, "train/policy_randomness_max": 0.7816928350431029, "train/policy_randomness_mean": 0.14185740661373886, "train/policy_randomness_min": 0.033242441439134185, "train/policy_randomness_std": 0.13217818476088036, "train/post_ent_mag": 42.29990726242417, "train/post_ent_max": 42.29990726242417, "train/post_ent_mean": 41.015808931693506, "train/post_ent_min": 40.03677628336963, "train/post_ent_std": 0.46811044010149166, "train/prior_ent_mag": 43.65803446967481, "train/prior_ent_max": 43.65803446967481, "train/prior_ent_mean": 42.06967050578737, "train/prior_ent_min": 39.96937525876656, "train/prior_ent_std": 0.6284354664213646, "train/rep_loss_mean": 1.0000000181286017, "train/rep_loss_std": 5.75164851758303e-07, "train/reward_avg": 0.00030925416693140746, "train/reward_loss_mean": 0.001969086653273982, "train/reward_loss_std": 0.050486895813009046, "train/reward_max_data": 0.24925115216986923, "train/reward_max_pred": 0.14809579179034255, "train/reward_neg_acc": 0.999914437395087, "train/reward_neg_loss": 0.00033270743468852526, "train/reward_pos_acc": 0.5192982460323133, "train/reward_pos_loss": 2.9239098392034832, "train/reward_pred": 0.0002680233033794549, "train/reward_rate": 0.0005625360023041474, "train_stats/mean_log_entropy": 0.2905127526290955, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.00798864383250475, "report/cont_loss_std": 0.15758077800273895, "report/cont_neg_acc": 0.6000000238418579, "report/cont_neg_loss": 1.1401034593582153, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0024336145725101233, "report/cont_pred": 0.9942266941070557, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.10508333146572113, "report/image_loss_std": 0.11844257265329361, "report/model_loss_mean": 0.7133516073226929, "report/model_loss_std": 0.19577565789222717, "report/post_ent_mag": 42.11762237548828, "report/post_ent_max": 42.11762237548828, "report/post_ent_mean": 41.05500793457031, "report/post_ent_min": 39.977447509765625, "report/post_ent_std": 0.3973883092403412, "report/prior_ent_mag": 43.22482681274414, "report/prior_ent_max": 43.22482681274414, "report/prior_ent_mean": 41.640830993652344, "report/prior_ent_min": 39.472007751464844, "report/prior_ent_std": 0.6904500126838684, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.0002795732580125332, "report/reward_loss_std": 0.0033106058835983276, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.027939796447753906, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0002795732580125332, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00010287412442266941, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.03566696494817734, "eval/cont_loss_std": 0.6103474497795105, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 10.716998100280762, "eval/cont_pos_acc": 0.9980410933494568, "eval/cont_pos_loss": 0.004282054491341114, "eval/cont_pred": 0.997168779373169, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.22530439496040344, "eval/image_loss_std": 0.2095528393983841, "eval/model_loss_mean": 0.8611388206481934, "eval/model_loss_std": 0.6470385789871216, "eval/post_ent_mag": 42.13764953613281, "eval/post_ent_max": 42.13764953613281, "eval/post_ent_mean": 40.80284881591797, "eval/post_ent_min": 39.98713302612305, "eval/post_ent_std": 0.40204179286956787, "eval/prior_ent_mag": 43.020774841308594, "eval/prior_ent_max": 43.020774841308594, "eval/prior_ent_mean": 41.27497863769531, "eval/prior_ent_min": 39.349151611328125, "eval/prior_ent_std": 0.6587549448013306, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00016744853928685188, "eval/reward_loss_std": 0.0019817438442260027, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.022154808044433594, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00016744853928685188, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 6.684032268822193e-05, "eval/reward_rate": 0.0, "replay/size": 183745.0, "replay/inserts": 8668.0, "replay/samples": 34672.0, "replay/insert_wait_avg": 1.6129836543232382e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.47980530161873e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 44984.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1011390950028047e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.387731552124023e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0678377151489, "timer/env.step_count": 1084.0, "timer/env.step_total": 10.588526487350464, "timer/env.step_frac": 0.010587808234631391, "timer/env.step_avg": 0.00976801336471445, "timer/env.step_min": 0.008669137954711914, "timer/env.step_max": 0.03496241569519043, "timer/replay._sample_count": 34672.0, "timer/replay._sample_total": 18.510295867919922, "timer/replay._sample_frac": 0.018509040256919292, "timer/replay._sample_avg": 0.0005338687086963522, "timer/replay._sample_min": 0.00035643577575683594, "timer/replay._sample_max": 0.011578083038330078, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1373.0, "timer/agent.policy_total": 13.932724475860596, "timer/agent.policy_frac": 0.013931779375779784, "timer/agent.policy_avg": 0.010147650747167222, "timer/agent.policy_min": 0.008758306503295898, "timer/agent.policy_max": 0.03517270088195801, "timer/dataset_train_count": 2167.0, "timer/dataset_train_total": 0.38483691215515137, "timer/dataset_train_frac": 0.00038481080746920806, "timer/dataset_train_avg": 0.00017758971488470297, "timer/dataset_train_min": 9.560585021972656e-05, "timer/dataset_train_max": 0.0012118816375732422, "timer/agent.train_count": 2167.0, "timer/agent.train_total": 970.3849005699158, "timer/agent.train_frac": 0.9703190763408114, "timer/agent.train_avg": 0.4478010616381706, "timer/agent.train_min": 0.43625593185424805, "timer/agent.train_max": 1.130204439163208, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4727509021759033, "timer/agent.report_frac": 0.0004727188340102962, "timer/agent.report_avg": 0.23637545108795166, "timer/agent.report_min": 0.22918391227722168, "timer/agent.report_max": 0.24356698989868164, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.1948089599609375e-05, "timer/dataset_eval_frac": 3.194592246122128e-08, "timer/dataset_eval_avg": 3.1948089599609375e-05, "timer/dataset_eval_min": 3.1948089599609375e-05, "timer/dataset_eval_max": 3.1948089599609375e-05, "fps": 8.667294805282294}
{"step": 184304, "time": 21243.494476556778, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 184528, "time": 21268.91060781479, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 185048, "time": 21328.249745607376, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 185392, "time": 21367.43099474907, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 185888, "time": 21423.877667188644, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 185912, "time": 21426.578583955765, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 186024, "time": 21439.37943816185, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 186552, "time": 21499.561656713486, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 186616, "time": 21506.82395005226, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 186840, "time": 21532.28037762642, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 187360, "time": 21591.44018125534, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 187704, "time": 21630.593466043472, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 188200, "time": 21686.87635564804, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 188224, "time": 21689.590927124023, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 188336, "time": 21702.310963392258, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 188864, "time": 21762.821296691895, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 188928, "time": 21770.130717515945, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 189152, "time": 21795.55911540985, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 189672, "time": 21854.89525938034, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 190008, "time": 21897.98566508293, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 21897.992971897125, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 21897.99890613556, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 21898.004287719727, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 21898.009417772293, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 21898.014541387558, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 21898.01968050003, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 21898.024953842163, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190016, "time": 21898.92691397667, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 190512, "time": 21955.48898267746, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 190536, "time": 21958.231758594513, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 190648, "time": 21971.07107234001, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 191176, "time": 22031.39370894432, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 191240, "time": 22038.677114486694, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 191464, "time": 22064.23671078682, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 191984, "time": 22123.314021110535, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 192328, "time": 22162.50607275963, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 192824, "time": 22219.17932486534, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 192848, "time": 22221.937903881073, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 192960, "time": 22234.642993927002, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 192977, "time": 22237.426278352737, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.6226829038847477, "train/action_min": 0.0, "train/action_std": 2.1137751925975903, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0036300964934650997, "train/actor_opt_grad_steps": 46765.0, "train/actor_opt_loss": -14.343166432796268, "train/adv_mag": 0.39245372542410817, "train/adv_max": 0.31177637356957166, "train/adv_mean": 0.0017903536875386544, "train/adv_min": -0.28730360025522905, "train/adv_std": 0.01756260171212222, "train/cont_avg": 0.9963804472477065, "train/cont_loss_mean": 0.008603129302815817, "train/cont_loss_std": 0.15797473180188942, "train/cont_neg_acc": 0.5662544822251355, "train/cont_neg_loss": 1.8649317160730048, "train/cont_pos_acc": 0.999869574647431, "train/cont_pos_loss": 0.001726833059064779, "train/cont_pred": 0.9963583959898817, "train/cont_rate": 0.9963804472477065, "train/dyn_loss_mean": 1.0000080389714023, "train/dyn_loss_std": 0.00010691810946208943, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.13296813765591983, "train/extr_critic_critic_opt_grad_steps": 46765.0, "train/extr_critic_critic_opt_loss": 12828.768290388474, "train/extr_critic_mag": 0.564084091317763, "train/extr_critic_max": 0.564084091317763, "train/extr_critic_mean": 0.10763689315100329, "train/extr_critic_min": 0.09139866621122447, "train/extr_critic_std": 0.02250505183127051, "train/extr_return_normed_mag": 0.5263980671831774, "train/extr_return_normed_max": 0.5191578311042502, "train/extr_return_normed_mean": 0.012204985099430393, "train/extr_return_normed_min": -0.0839051132628677, "train/extr_return_normed_std": 0.02959247762999506, "train/extr_return_rate": 0.003943281942832181, "train/extr_return_raw_mag": 0.6163800985578003, "train/extr_return_raw_max": 0.6163800985578003, "train/extr_return_raw_mean": 0.10942725888496145, "train/extr_return_raw_min": 0.013317154942575944, "train/extr_return_raw_std": 0.02959247787777813, "train/extr_reward_mag": 0.5479109418501548, "train/extr_reward_max": 0.5479109418501548, "train/extr_reward_mean": 0.0008285061620205744, "train/extr_reward_min": -4.2297424526389586e-05, "train/extr_reward_std": 0.011615151336519133, "train/image_loss_mean": 0.06955602777045254, "train/image_loss_std": 0.09607904587248596, "train/model_loss_mean": 0.6796285906516084, "train/model_loss_std": 0.22135236305654596, "train/model_opt_grad_norm": 20.113074055505454, "train/model_opt_grad_steps": 46724.692660550456, "train/model_opt_loss": 3026.3707415379517, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 4449.54128440367, "train/policy_entropy_mag": 1.6746579003990243, "train/policy_entropy_max": 1.6746579003990243, "train/policy_entropy_mean": 0.8782490042439841, "train/policy_entropy_min": 0.06469047500179448, "train/policy_entropy_std": 0.40723994005163877, "train/policy_logprob_mag": 6.551039971342874, "train/policy_logprob_max": -0.008608920662023059, "train/policy_logprob_mean": -0.877377773130979, "train/policy_logprob_min": -6.551039971342874, "train/policy_logprob_std": 0.8475744513743514, "train/policy_randomness_mag": 0.8606039703985967, "train/policy_randomness_max": 0.8606039703985967, "train/policy_randomness_mean": 0.45133073363077203, "train/policy_randomness_min": 0.033244329889159686, "train/policy_randomness_std": 0.20927994189049126, "train/post_ent_mag": 41.69959838237237, "train/post_ent_max": 41.69959838237237, "train/post_ent_mean": 40.576571140814266, "train/post_ent_min": 39.729825781026015, "train/post_ent_std": 0.410129018469688, "train/prior_ent_mag": 42.996892754091036, "train/prior_ent_max": 42.996892754091036, "train/prior_ent_mean": 41.37004252092554, "train/prior_ent_min": 39.23259257395333, "train/prior_ent_std": 0.6395755962494316, "train/rep_loss_mean": 1.0000080389714023, "train/rep_loss_std": 0.00010691810946208943, "train/reward_avg": 0.00027218040005718314, "train/reward_loss_mean": 0.001464587268221978, "train/reward_loss_std": 0.03672187235390601, "train/reward_max_data": 0.23643922040221887, "train/reward_max_pred": 0.14298485123783078, "train/reward_neg_acc": 0.9998924535348874, "train/reward_neg_loss": 0.000292451220173111, "train/reward_pos_acc": 0.5833333336881229, "train/reward_pos_loss": 2.480840533616997, "train/reward_pred": 0.0002567601500190111, "train/reward_rate": 0.0004793219610091743, "train_stats/mean_log_entropy": 0.7828410770143232, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.005278364289551973, "report/cont_loss_std": 0.13539496064186096, "report/cont_neg_acc": 0.6666666865348816, "report/cont_neg_loss": 1.4446630477905273, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0010490267304703593, "report/cont_pred": 0.9969985485076904, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.05401568114757538, "report/image_loss_std": 0.08096377551555634, "report/model_loss_mean": 0.6593944430351257, "report/model_loss_std": 0.1571856290102005, "report/post_ent_mag": 41.83698272705078, "report/post_ent_max": 41.83698272705078, "report/post_ent_mean": 40.888023376464844, "report/post_ent_min": 40.204010009765625, "report/post_ent_std": 0.3480672538280487, "report/prior_ent_mag": 42.89219665527344, "report/prior_ent_max": 42.89219665527344, "report/prior_ent_mean": 41.24738311767578, "report/prior_ent_min": 39.081871032714844, "report/prior_ent_std": 0.5802592039108276, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.00010037794709205627, "report/reward_loss_std": 0.0011108694598078728, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.012868046760559082, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00010037794709205627, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 4.8954272642731667e-05, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.02540270984172821, "eval/cont_loss_std": 0.4313100278377533, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 7.727173805236816, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.002772631822153926, "eval/cont_pred": 0.9973757266998291, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.14481733739376068, "eval/image_loss_std": 0.14221951365470886, "eval/model_loss_mean": 0.7769211530685425, "eval/model_loss_std": 0.5641123056411743, "eval/post_ent_mag": 42.05364990234375, "eval/post_ent_max": 42.05364990234375, "eval/post_ent_mean": 41.059104919433594, "eval/post_ent_min": 40.106178283691406, "eval/post_ent_std": 0.4373973608016968, "eval/prior_ent_mag": 42.9330940246582, "eval/prior_ent_max": 42.9330940246582, "eval/prior_ent_mean": 41.4720458984375, "eval/prior_ent_min": 39.31040573120117, "eval/prior_ent_std": 0.6029553413391113, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.000762939453125, "eval/reward_loss_mean": 0.0067010316997766495, "eval/reward_loss_std": 0.1970311850309372, "eval/reward_max_data": 0.78125, "eval/reward_max_pred": 0.15327894687652588, "eval/reward_neg_acc": 0.9990224838256836, "eval/reward_neg_loss": 0.0005478192470036447, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 6.3014373779296875, "eval/reward_pred": 0.00029182969592511654, "eval/reward_rate": 0.0009765625, "replay/size": 192473.0, "replay/inserts": 8728.0, "replay/samples": 34912.0, "replay/insert_wait_avg": 1.5629965924648492e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.440473484840009e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 47296.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0393688835487234e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 999.9914019107819, "timer/env.step_count": 1091.0, "timer/env.step_total": 10.71092414855957, "timer/env.step_frac": 0.010711016242832843, "timer/env.step_avg": 0.00981752900876221, "timer/env.step_min": 0.008694887161254883, "timer/env.step_max": 0.03442120552062988, "timer/replay._sample_count": 34912.0, "timer/replay._sample_total": 18.302331924438477, "timer/replay._sample_frac": 0.018302489290874312, "timer/replay._sample_avg": 0.0005242418630968858, "timer/replay._sample_min": 0.0003604888916015625, "timer/replay._sample_max": 0.02606678009033203, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1380.0, "timer/agent.policy_total": 13.921607971191406, "timer/agent.policy_frac": 0.013921727671447996, "timer/agent.policy_avg": 0.010088121718254642, "timer/agent.policy_min": 0.008699178695678711, "timer/agent.policy_max": 0.03792285919189453, "timer/dataset_train_count": 2182.0, "timer/dataset_train_total": 0.38431406021118164, "timer/dataset_train_frac": 0.0003843173646061706, "timer/dataset_train_avg": 0.0001761292668245562, "timer/dataset_train_min": 9.441375732421875e-05, "timer/dataset_train_max": 0.0005402565002441406, "timer/agent.train_count": 2182.0, "timer/agent.train_total": 970.2127556800842, "timer/agent.train_frac": 0.9702210977276439, "timer/agent.train_avg": 0.4446437927039799, "timer/agent.train_min": 0.4321146011352539, "timer/agent.train_max": 0.5858817100524902, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4717705249786377, "timer/agent.report_frac": 0.0004717745813385789, "timer/agent.report_avg": 0.23588526248931885, "timer/agent.report_min": 0.22826266288757324, "timer/agent.report_max": 0.24350786209106445, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.765655517578125e-05, "timer/dataset_eval_frac": 2.7656792971354707e-08, "timer/dataset_eval_avg": 2.765655517578125e-05, "timer/dataset_eval_min": 2.765655517578125e-05, "timer/dataset_eval_max": 2.765655517578125e-05, "fps": 8.727958013532438}
{"step": 193488, "time": 22295.2480301857, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 193552, "time": 22302.601088762283, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 193776, "time": 22327.916610479355, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 194296, "time": 22386.86133480072, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 194640, "time": 22425.852834939957, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 195136, "time": 22482.059678792953, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 195160, "time": 22484.791216135025, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 195272, "time": 22497.457709550858, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 195800, "time": 22557.242473602295, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 195864, "time": 22564.452033996582, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 196088, "time": 22589.801953315735, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 196608, "time": 22648.990667819977, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 196952, "time": 22687.958134174347, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 197448, "time": 22744.09547185898, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 197472, "time": 22746.81116080284, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 197584, "time": 22759.480879068375, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 198112, "time": 22819.17171239853, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 198176, "time": 22826.36806821823, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 198400, "time": 22851.659519910812, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 198920, "time": 22910.37985253334, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 199264, "time": 22949.30297279358, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 199760, "time": 23005.39952158928, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 199784, "time": 23008.109508514404, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 199896, "time": 23020.72482609749, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 200096, "time": 23048.836042881012, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 23048.842556476593, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 23048.84889936447, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 23048.854677677155, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 23048.86028432846, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 23048.865826368332, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 23048.871278762817, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 23048.877072811127, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200424, "time": 23086.0297935009, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 200488, "time": 23093.268150806427, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 200712, "time": 23118.54508304596, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 201232, "time": 23177.36825156212, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 201432, "time": 23199.92539167404, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 201536, "time": 23211.718859434128, "episode/length": 283.0, "episode/score": 0.11562500149011612, "episode/reward_rate": 0.0035211267605633804, "episode/intrinsic_return": 0.0}
{"step": 201757, "time": 23237.66126680374, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.3586445201526987, "train/action_min": 0.0, "train/action_std": 1.8710208502682772, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.004926998800576918, "train/actor_opt_grad_steps": 48955.0, "train/actor_opt_loss": -5.647745023837143, "train/adv_mag": 0.2767180329358036, "train/adv_max": 0.23738041587851264, "train/adv_mean": 0.0012842429146210385, "train/adv_min": -0.19460567500103604, "train/adv_std": 0.0176310424502431, "train/cont_avg": 0.9961159446022727, "train/cont_loss_mean": 0.00811543463999194, "train/cont_loss_std": 0.1507609184979546, "train/cont_neg_acc": 0.5892967443775248, "train/cont_neg_loss": 1.7509606158415172, "train/cont_pos_acc": 0.999919735843485, "train/cont_pos_loss": 0.001673506722065874, "train/cont_pred": 0.9960881449959494, "train/cont_rate": 0.9961159446022727, "train/dyn_loss_mean": 1.0001040182330392, "train/dyn_loss_std": 0.000664034839825366, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.19215525585988705, "train/extr_critic_critic_opt_grad_steps": 48955.0, "train/extr_critic_critic_opt_loss": 8642.87372824929, "train/extr_critic_mag": 0.39860616543076255, "train/extr_critic_max": 0.39860616543076255, "train/extr_critic_mean": 0.1777292158115994, "train/extr_critic_min": 0.1495726699178869, "train/extr_critic_std": 0.021185305951671167, "train/extr_return_normed_mag": 0.3550274093720046, "train/extr_return_normed_max": 0.3455947053703395, "train/extr_return_normed_mean": 0.025919055241287094, "train/extr_return_normed_min": -0.11236210858280009, "train/extr_return_normed_std": 0.027364142050712623, "train/extr_return_rate": 0.003258463690045491, "train/extr_return_raw_mag": 0.49868907779455185, "train/extr_return_raw_max": 0.49868907779455185, "train/extr_return_raw_mean": 0.1790134352039207, "train/extr_return_raw_min": 0.04073226343501698, "train/extr_return_raw_std": 0.027364142012613064, "train/extr_reward_mag": 0.38834903131831777, "train/extr_reward_max": 0.38834903131831777, "train/extr_reward_mean": 0.0009904402263983187, "train/extr_reward_min": 3.522092645818537e-08, "train/extr_reward_std": 0.011591777453279726, "train/image_loss_mean": 0.06782427596097643, "train/image_loss_std": 0.09389410493048754, "train/model_loss_mean": 0.6776410742239518, "train/model_loss_std": 0.2196144691583785, "train/model_opt_grad_norm": 19.505111360549925, "train/model_opt_grad_steps": 48912.8, "train/model_opt_loss": 3449.898397549716, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5113.636363636364, "train/policy_entropy_mag": 1.2157430358908392, "train/policy_entropy_max": 1.2157430358908392, "train/policy_entropy_mean": 0.13752519180151548, "train/policy_entropy_min": 0.0646866198290478, "train/policy_entropy_std": 0.16071573343466627, "train/policy_logprob_mag": 6.55108014236797, "train/policy_logprob_max": -0.008608217613602226, "train/policy_logprob_mean": -0.13724400780417703, "train/policy_logprob_min": -6.55108014236797, "train/policy_logprob_std": 0.6691192022778771, "train/policy_randomness_mag": 0.6247683667323806, "train/policy_randomness_max": 0.6247683667323806, "train/policy_randomness_mean": 0.0706739721650427, "train/policy_randomness_min": 0.03324234912341291, "train/policy_randomness_std": 0.08259155381132256, "train/post_ent_mag": 41.92733631134033, "train/post_ent_max": 41.92733631134033, "train/post_ent_mean": 40.75302070270885, "train/post_ent_min": 39.89555535749955, "train/post_ent_std": 0.42907066358761353, "train/prior_ent_mag": 43.34865710518577, "train/prior_ent_max": 43.34865710518577, "train/prior_ent_mean": 41.496576083790174, "train/prior_ent_min": 39.086944649436255, "train/prior_ent_std": 0.7193242582407865, "train/rep_loss_mean": 1.0001040182330392, "train/rep_loss_std": 0.000664034839825366, "train/reward_avg": 0.00026586359381326475, "train/reward_loss_mean": 0.001638927316525951, "train/reward_loss_std": 0.042392121112987464, "train/reward_max_data": 0.22254261394793337, "train/reward_max_pred": 0.15017197836529125, "train/reward_neg_acc": 0.9998578808524392, "train/reward_neg_loss": 0.0003243905628881872, "train/reward_pos_acc": 0.568273092608854, "train/reward_pos_loss": 2.808456792170743, "train/reward_pred": 0.000258529079887508, "train/reward_rate": 0.0004705255681818182, "train_stats/mean_log_entropy": 0.14967695673306783, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.007460009306669235, "report/cont_loss_std": 0.19636553525924683, "report/cont_neg_acc": 0.8333333730697632, "report/cont_neg_loss": 1.0643048286437988, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0012310619931668043, "report/cont_pred": 0.9939913749694824, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.0628124326467514, "report/image_loss_std": 0.09652014821767807, "report/model_loss_mean": 0.6704006195068359, "report/model_loss_std": 0.22335661947727203, "report/post_ent_mag": 43.46479034423828, "report/post_ent_max": 43.46479034423828, "report/post_ent_mean": 42.018455505371094, "report/post_ent_min": 41.10054016113281, "report/post_ent_std": 0.5145455002784729, "report/prior_ent_mag": 45.42207336425781, "report/prior_ent_max": 45.42207336425781, "report/prior_ent_mean": 43.45142364501953, "report/prior_ent_min": 40.28651428222656, "report/prior_ent_std": 0.859970211982727, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.00012818863615393639, "report/reward_loss_std": 0.0009035701514221728, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.008553862571716309, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00012818863615393639, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 6.074074190109968e-05, "report/reward_rate": 0.0, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.041590411216020584, "eval/cont_loss_std": 0.639678418636322, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 10.193437576293945, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.0017792410217225552, "eval/cont_pred": 0.9982985258102417, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.18602058291435242, "eval/image_loss_std": 0.15880556404590607, "eval/model_loss_mean": 0.8393885493278503, "eval/model_loss_std": 0.9119463562965393, "eval/post_ent_mag": 43.58640670776367, "eval/post_ent_max": 43.58640670776367, "eval/post_ent_mean": 42.07875061035156, "eval/post_ent_min": 41.08633804321289, "eval/post_ent_std": 0.5245015621185303, "eval/prior_ent_mag": 45.38018798828125, "eval/prior_ent_max": 45.38018798828125, "eval/prior_ent_mean": 43.597816467285156, "eval/prior_ent_min": 40.983760833740234, "eval/prior_ent_std": 0.7969391345977783, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0006652831798419356, "eval/reward_loss_mean": 0.011777571402490139, "eval/reward_loss_std": 0.3679594099521637, "eval/reward_max_data": 0.6812499761581421, "eval/reward_max_pred": 0.017325639724731445, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00027343511465005577, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 11.780509948730469, "eval/reward_pred": 0.00012190139386802912, "eval/reward_rate": 0.0009765625, "replay/size": 201253.0, "replay/inserts": 8780.0, "replay/samples": 35120.0, "replay/insert_wait_avg": 1.554364223958148e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.372035524025051e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 49608.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0860832504747648e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.685754776000977e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.216245174408, "timer/env.step_count": 1097.0, "timer/env.step_total": 10.706638813018799, "timer/env.step_frac": 0.010704324054596693, "timer/env.step_avg": 0.009759925991812943, "timer/env.step_min": 0.008696317672729492, "timer/env.step_max": 0.03524041175842285, "timer/replay._sample_count": 35120.0, "timer/replay._sample_total": 18.665456771850586, "timer/replay._sample_frac": 0.01866142132954048, "timer/replay._sample_avg": 0.0005314765595629437, "timer/replay._sample_min": 0.0003802776336669922, "timer/replay._sample_max": 0.03789401054382324, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1386.0, "timer/agent.policy_total": 14.259125471115112, "timer/agent.policy_frac": 0.014256042670681424, "timer/agent.policy_avg": 0.010287969315378868, "timer/agent.policy_min": 0.008773088455200195, "timer/agent.policy_max": 0.07130670547485352, "timer/dataset_train_count": 2195.0, "timer/dataset_train_total": 0.38891029357910156, "timer/dataset_train_frac": 0.00038882621178711925, "timer/dataset_train_avg": 0.00017718008819093465, "timer/dataset_train_min": 9.34600830078125e-05, "timer/dataset_train_max": 0.0008335113525390625, "timer/agent.train_count": 2195.0, "timer/agent.train_total": 969.9768178462982, "timer/agent.train_frac": 0.9697671103883772, "timer/agent.train_avg": 0.4419028782898853, "timer/agent.train_min": 0.42806172370910645, "timer/agent.train_max": 0.5696797370910645, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47078585624694824, "timer/agent.report_frac": 0.0004706840730874724, "timer/agent.report_avg": 0.23539292812347412, "timer/agent.report_min": 0.2256937026977539, "timer/agent.report_max": 0.24509215354919434, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0994415283203125e-05, "timer/dataset_eval_frac": 3.0987714339511274e-08, "timer/dataset_eval_avg": 3.0994415283203125e-05, "timer/dataset_eval_min": 3.0994415283203125e-05, "timer/dataset_eval_max": 3.0994415283203125e-05, "fps": 8.777960548719186}
{"step": 202072, "time": 23273.098193883896, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 202096, "time": 23275.81959962845, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 202208, "time": 23288.449727535248, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 202712, "time": 23345.328410863876, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 202736, "time": 23348.0363779068, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 202800, "time": 23355.320383787155, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 203024, "time": 23380.515975236893, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 203200, "time": 23400.40158891678, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 203552, "time": 23440.251953840256, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 203744, "time": 23462.043540239334, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 203744, "time": 23462.049281597137, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 203848, "time": 23473.962922096252, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 204408, "time": 23537.365888834, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 204520, "time": 23550.050480127335, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 205024, "time": 23607.353989124298, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 205048, "time": 23610.0772960186, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 205360, "time": 23645.367463111877, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 205512, "time": 23662.586963891983, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 205560, "time": 23668.033540725708, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 205672, "time": 23680.702839374542, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 206056, "time": 23724.364765405655, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 206056, "time": 23724.372652053833, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 206160, "time": 23736.146439552307, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 206320, "time": 23754.31738758087, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 207336, "time": 23869.328053236008, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 207360, "time": 23872.06981778145, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 207512, "time": 23889.167687654495, "episode/length": 268.0, "episode/score": 0.16249999403953552, "episode/reward_rate": 0.0037174721189591076, "episode/intrinsic_return": 0.0}
{"step": 207824, "time": 23924.48459124565, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 207872, "time": 23929.891356229782, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 208280, "time": 23976.048494815826, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 208368, "time": 23986.099580049515, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 208368, "time": 23986.108460187912, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 208632, "time": 24016.00186753273, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 209648, "time": 24130.959490060806, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 209672, "time": 24133.72058081627, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 209824, "time": 24150.865894556046, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 210080, "time": 24184.649386882782, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 24184.656425237656, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 24184.662040948868, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 24184.668318986893, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 24184.674162864685, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 24184.68002319336, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 24184.684915542603, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 24184.6906914711, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210184, "time": 24196.428789377213, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 210545, "time": 24238.04738020897, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.081632988637985, "train/action_min": 0.0, "train/action_std": 1.833381294659828, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0066241250829516, "train/actor_opt_grad_steps": 51150.0, "train/actor_opt_loss": -6.6777949388304805, "train/adv_mag": 0.33966009944813436, "train/adv_max": 0.2664062360378161, "train/adv_mean": 0.0034036382824163174, "train/adv_min": -0.2543997106622888, "train/adv_std": 0.021724839214252556, "train/cont_avg": 0.996218607305936, "train/cont_loss_mean": 0.008962813282138818, "train/cont_loss_std": 0.16467755019864638, "train/cont_neg_acc": 0.5482604984687344, "train/cont_neg_loss": 1.956138273268036, "train/cont_pos_acc": 0.9999059721759466, "train/cont_pos_loss": 0.0017249757458815207, "train/cont_pred": 0.9962789851780895, "train/cont_rate": 0.996218607305936, "train/dyn_loss_mean": 1.0000020799027185, "train/dyn_loss_std": 6.652589729635181e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.24126268566913528, "train/extr_critic_critic_opt_grad_steps": 51150.0, "train/extr_critic_critic_opt_loss": 11866.847025274687, "train/extr_critic_mag": 0.506970887859118, "train/extr_critic_max": 0.506970887859118, "train/extr_critic_mean": 0.29521196121222354, "train/extr_critic_min": 0.2489392762859118, "train/extr_critic_std": 0.026339267882344114, "train/extr_return_normed_mag": 0.4114276745003652, "train/extr_return_normed_max": 0.3835040250597479, "train/extr_return_normed_mean": 0.03473259563663687, "train/extr_return_normed_min": -0.19921050224130013, "train/extr_return_normed_std": 0.035269085532607145, "train/extr_return_rate": 0.00844184066801939, "train/extr_return_raw_mag": 0.647387002837168, "train/extr_return_raw_max": 0.647387002837168, "train/extr_return_raw_mean": 0.2986155857914659, "train/extr_return_raw_min": 0.06467247403919969, "train/extr_return_raw_std": 0.035269085422039166, "train/extr_reward_mag": 0.38136260640131286, "train/extr_reward_max": 0.38136260640131286, "train/extr_reward_mean": 0.00039324259570222743, "train/extr_reward_min": 6.423148934699629e-08, "train/extr_reward_std": 0.0072004911257219865, "train/image_loss_mean": 0.068098412035671, "train/image_loss_std": 0.09417491491254606, "train/model_loss_mean": 0.6788879488701145, "train/model_loss_std": 0.23268411509250397, "train/model_opt_grad_norm": 18.647018955178456, "train/model_opt_grad_steps": 51105.6301369863, "train/model_opt_loss": 3394.4397407427227, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5022.83105022831, "train/policy_entropy_mag": 1.425877150879603, "train/policy_entropy_max": 1.425877150879603, "train/policy_entropy_mean": 0.15762454795238634, "train/policy_entropy_min": 0.064686577852186, "train/policy_entropy_std": 0.20114653111864986, "train/policy_logprob_mag": 6.551080229075532, "train/policy_logprob_max": -0.008608195828656628, "train/policy_logprob_mean": -0.1569084969761709, "train/policy_logprob_min": -6.551080229075532, "train/policy_logprob_std": 0.6916327321366088, "train/policy_randomness_mag": 0.7327559489637749, "train/policy_randomness_max": 0.7327559489637749, "train/policy_randomness_mean": 0.0810029987909206, "train/policy_randomness_min": 0.03324232765868919, "train/policy_randomness_std": 0.10336887482638772, "train/post_ent_mag": 43.74755463970306, "train/post_ent_max": 43.74755463970306, "train/post_ent_mean": 42.46033037089866, "train/post_ent_min": 41.50225472994591, "train/post_ent_std": 0.48156314666412736, "train/prior_ent_mag": 45.35364532470703, "train/prior_ent_max": 45.35364532470703, "train/prior_ent_mean": 43.311538191146504, "train/prior_ent_min": 40.57567021618151, "train/prior_ent_std": 0.8351408082600598, "train/rep_loss_mean": 1.0000020799027185, "train/rep_loss_std": 6.652589729635181e-05, "train/reward_avg": 0.00030867345740095834, "train/reward_loss_mean": 0.0018254555545196567, "train/reward_loss_std": 0.04758115094707913, "train/reward_max_data": 0.26846461140946165, "train/reward_max_pred": 0.14288637463904952, "train/reward_neg_acc": 0.9999107854551377, "train/reward_neg_loss": 0.0003024427110487946, "train/reward_pos_acc": 0.4955673759922068, "train/reward_pos_loss": 2.9898317427711283, "train/reward_pred": 0.00025727309884086727, "train/reward_rate": 0.000512806792237443, "train_stats/mean_log_entropy": 0.13310029397945147, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.0020806738175451756, "report/cont_loss_std": 0.03265303745865822, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.025932909920811653, "report/cont_pos_acc": 0.9990195631980896, "report/cont_pos_loss": 0.0019871355034410954, "report/cont_pred": 0.9946060180664062, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.0778285562992096, "report/image_loss_std": 0.09289316087961197, "report/model_loss_mean": 0.6801971793174744, "report/model_loss_std": 0.10025604814291, "report/post_ent_mag": 44.062713623046875, "report/post_ent_max": 44.062713623046875, "report/post_ent_mean": 42.76275634765625, "report/post_ent_min": 41.83477020263672, "report/post_ent_std": 0.48016616702079773, "report/prior_ent_mag": 45.60570526123047, "report/prior_ent_max": 45.60570526123047, "report/prior_ent_mean": 43.11932373046875, "report/prior_ent_min": 39.734134674072266, "report/prior_ent_std": 0.8957164883613586, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.0002879293169826269, "report/reward_loss_std": 0.005308135412633419, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.08811056613922119, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0002879293169826269, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00014410435687750578, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.026459887623786926, "eval/cont_loss_std": 0.48979467153549194, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 8.752775192260742, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0008193926769308746, "eval/cont_pred": 0.9991984963417053, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.24785813689231873, "eval/image_loss_std": 0.1728467494249344, "eval/model_loss_mean": 0.8745481967926025, "eval/model_loss_std": 0.5085794925689697, "eval/post_ent_mag": 43.82463073730469, "eval/post_ent_max": 43.82463073730469, "eval/post_ent_mean": 42.64404296875, "eval/post_ent_min": 41.68014144897461, "eval/post_ent_std": 0.4221227467060089, "eval/prior_ent_mag": 45.285831451416016, "eval/prior_ent_max": 45.285831451416016, "eval/prior_ent_mean": 42.88591766357422, "eval/prior_ent_min": 40.28148651123047, "eval/prior_ent_std": 0.8593959212303162, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00023014727048575878, "eval/reward_loss_std": 0.002685840940102935, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.024243593215942383, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00023014727048575878, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00010254525113850832, "eval/reward_rate": 0.0, "replay/size": 210041.0, "replay/inserts": 8788.0, "replay/samples": 35152.0, "replay/insert_wait_avg": 1.5527593259329572e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.314184442345642e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 51920.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0597870836620925e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.940696716308594e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3722116947174, "timer/env.step_count": 1099.0, "timer/env.step_total": 10.795441627502441, "timer/env.step_frac": 0.010791424932939737, "timer/env.step_avg": 0.009822967813923968, "timer/env.step_min": 0.008664369583129883, "timer/env.step_max": 0.03571796417236328, "timer/replay._sample_count": 35152.0, "timer/replay._sample_total": 18.661479949951172, "timer/replay._sample_frac": 0.018654536513301387, "timer/replay._sample_avg": 0.0005308796071333401, "timer/replay._sample_min": 0.0003490447998046875, "timer/replay._sample_max": 0.024991273880004883, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1388.0, "timer/agent.policy_total": 13.900871276855469, "timer/agent.policy_frac": 0.013895699135131098, "timer/agent.policy_avg": 0.010015036942979444, "timer/agent.policy_min": 0.008540153503417969, "timer/agent.policy_max": 0.0348663330078125, "timer/dataset_train_count": 2197.0, "timer/dataset_train_total": 0.38878798484802246, "timer/dataset_train_frac": 0.0003886433272565437, "timer/dataset_train_avg": 0.00017696312464634615, "timer/dataset_train_min": 9.584426879882812e-05, "timer/dataset_train_max": 0.0009226799011230469, "timer/agent.train_count": 2197.0, "timer/agent.train_total": 970.5463352203369, "timer/agent.train_frac": 0.9701852209350629, "timer/agent.train_avg": 0.4417598248613277, "timer/agent.train_min": 0.428037166595459, "timer/agent.train_max": 0.5870380401611328, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4748845100402832, "timer/agent.report_frac": 0.000474707818238761, "timer/agent.report_avg": 0.2374422550201416, "timer/agent.report_min": 0.2293710708618164, "timer/agent.report_max": 0.2455134391784668, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 5.1975250244140625e-05, "timer/dataset_eval_frac": 5.19559116462162e-08, "timer/dataset_eval_avg": 5.1975250244140625e-05, "timer/dataset_eval_min": 5.1975250244140625e-05, "timer/dataset_eval_max": 5.1975250244140625e-05, "fps": 8.784601072842104}
{"step": 210592, "time": 24243.259596586227, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 210680, "time": 24253.418409347534, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 210680, "time": 24253.425886631012, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 210736, "time": 24259.812930107117, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 210800, "time": 24267.164056777954, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 210944, "time": 24283.735109090805, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 210992, "time": 24289.220488786697, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 211016, "time": 24291.97123026848, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 211816, "time": 24383.314722537994, "episode/length": 270.0, "episode/score": 0.15625, "episode/reward_rate": 0.0036900369003690036, "episode/intrinsic_return": 0.0}
{"step": 212136, "time": 24419.935682296753, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 212432, "time": 24453.79713010788, "episode/length": 203.0, "episode/score": 0.3656249940395355, "episode/reward_rate": 0.004901960784313725, "episode/intrinsic_return": 0.0}
{"step": 212536, "time": 24465.75865674019, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 212632, "time": 24476.721064329147, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 212992, "time": 24517.996694803238, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 212992, "time": 24518.014449834824, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 213048, "time": 24524.540585517883, "episode/length": 262.0, "episode/score": 0.18125000596046448, "episode/reward_rate": 0.0038022813688212928, "episode/intrinsic_return": 0.0}
{"step": 213112, "time": 24531.789271593094, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 213304, "time": 24553.583976507187, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 213328, "time": 24556.318177461624, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 213688, "time": 24597.490936517715, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 214040, "time": 24637.75381374359, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 214312, "time": 24668.85495519638, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 214536, "time": 24694.522912979126, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 214736, "time": 24717.317539453506, "episode/length": 217.0, "episode/score": 0.3218750059604645, "episode/reward_rate": 0.0045871559633027525, "episode/intrinsic_return": 0.0}
{"step": 214848, "time": 24730.1190469265, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 214944, "time": 24741.13773059845, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 215360, "time": 24788.614593744278, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 215392, "time": 24792.315686941147, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 215520, "time": 24807.010939359665, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 215664, "time": 24823.59176182747, "episode/length": 246.0, "episode/score": 0.23125000298023224, "episode/reward_rate": 0.004048582995951417, "episode/intrinsic_return": 0.0}
{"step": 216352, "time": 24902.489006757736, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 216360, "time": 24903.421479940414, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 216624, "time": 24933.520673036575, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 216704, "time": 24942.702369451523, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 216848, "time": 24959.109550476074, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 217672, "time": 25053.19425201416, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 217704, "time": 25056.86185336113, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 217832, "time": 25071.496475219727, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 218072, "time": 25098.911051034927, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 218264, "time": 25120.762779712677, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 218296, "time": 25124.4703040123, "episode/length": 198.0, "episode/score": 0.3812499940395355, "episode/reward_rate": 0.005025125628140704, "episode/intrinsic_return": 0.0}
{"step": 218664, "time": 25166.34265446663, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 218672, "time": 25167.252500772476, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 218784, "time": 25180.028559923172, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 219160, "time": 25223.042790174484, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 219285, "time": 25238.086009263992, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.608074031464041, "train/action_min": 0.0, "train/action_std": 1.7482510282568735, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0073266035332833525, "train/actor_opt_grad_steps": 53340.0, "train/actor_opt_loss": -5.1203431712897265, "train/adv_mag": 0.3849369584153232, "train/adv_max": 0.2622268141404679, "train/adv_mean": 0.004957006704911417, "train/adv_min": -0.3358095802672922, "train/adv_std": 0.02464476582428364, "train/cont_avg": 0.9961695562214612, "train/cont_loss_mean": 0.009101090099307449, "train/cont_loss_std": 0.16548057505860925, "train/cont_neg_acc": 0.5567478668030506, "train/cont_neg_loss": 1.9400402313693264, "train/cont_pos_acc": 0.9998567833748038, "train/cont_pos_loss": 0.0019009254987619512, "train/cont_pred": 0.9961127889210775, "train/cont_rate": 0.9961695562214612, "train/dyn_loss_mean": 1.0000007479158166, "train/dyn_loss_std": 2.3918490156267673e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.24226674394996744, "train/extr_critic_critic_opt_grad_steps": 53340.0, "train/extr_critic_critic_opt_loss": 9830.024041720177, "train/extr_critic_mag": 0.5295222181163423, "train/extr_critic_max": 0.5295222181163423, "train/extr_critic_mean": 0.3889038790034377, "train/extr_critic_min": 0.33946048451340904, "train/extr_critic_std": 0.02215015510581944, "train/extr_return_normed_mag": 0.43137887582931345, "train/extr_return_normed_max": 0.36294003014695153, "train/extr_return_normed_mean": 0.0372901412011996, "train/extr_return_normed_min": -0.29955612293117123, "train/extr_return_normed_std": 0.034814115917760895, "train/extr_return_rate": 0.032631756000797006, "train/extr_return_raw_mag": 0.7195107921889928, "train/extr_return_raw_max": 0.7195107921889928, "train/extr_return_raw_mean": 0.3938609240534099, "train/extr_return_raw_min": 0.05701463911087001, "train/extr_return_raw_std": 0.034814116013444724, "train/extr_reward_mag": 0.4076035877341005, "train/extr_reward_max": 0.4076035877341005, "train/extr_reward_mean": 0.0012951867517698053, "train/extr_reward_min": 3.9736429850260414e-08, "train/extr_reward_std": 0.013156754332307521, "train/image_loss_mean": 0.06898691352099588, "train/image_loss_std": 0.09574634168450147, "train/model_loss_mean": 0.6803873067032801, "train/model_loss_std": 0.2461867165756008, "train/model_opt_grad_norm": 18.66436497152668, "train/model_opt_grad_steps": 53293.520547945205, "train/model_opt_loss": 3587.383543807078, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5273.972602739726, "train/policy_entropy_mag": 1.417956046862145, "train/policy_entropy_max": 1.417956046862145, "train/policy_entropy_mean": 0.13899607939398997, "train/policy_entropy_min": 0.06468658421409729, "train/policy_entropy_std": 0.17905611983717304, "train/policy_logprob_mag": 6.55108024867158, "train/policy_logprob_max": -0.008608187727426013, "train/policy_logprob_mean": -0.1389895052942511, "train/policy_logprob_min": -6.55108024867158, "train/policy_logprob_std": 0.6744490946264572, "train/policy_randomness_mag": 0.7286853058153091, "train/policy_randomness_max": 0.7286853058153091, "train/policy_randomness_mean": 0.07142985855403557, "train/policy_randomness_min": 0.03324233090768666, "train/policy_randomness_std": 0.09201664868827279, "train/post_ent_mag": 43.906280012435566, "train/post_ent_max": 43.906280012435566, "train/post_ent_mean": 42.584754525798644, "train/post_ent_min": 41.60576647057381, "train/post_ent_std": 0.49298075943777003, "train/prior_ent_mag": 45.09973951017476, "train/prior_ent_max": 45.09973951017476, "train/prior_ent_mean": 42.791311655959035, "train/prior_ent_min": 40.17337727655559, "train/prior_ent_std": 0.8464414934589438, "train/rep_loss_mean": 1.0000007479158166, "train/rep_loss_std": 2.3918490156267673e-05, "train/reward_avg": 0.00035361372931519116, "train/reward_loss_mean": 0.0022988304363980414, "train/reward_loss_std": 0.05829405835877517, "train/reward_max_data": 0.28007990934941324, "train/reward_max_pred": 0.14457375001689615, "train/reward_neg_acc": 0.9998616644236595, "train/reward_neg_loss": 0.000334077536386409, "train/reward_pos_acc": 0.4255775582082201, "train/reward_pos_loss": 3.2226140268958443, "train/reward_pred": 0.000271375821031562, "train/reward_rate": 0.0006109089611872146, "train_stats/mean_log_entropy": 0.12091407262616688, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.016806209459900856, "report/cont_loss_std": 0.27074792981147766, "report/cont_neg_acc": 0.25, "report/cont_neg_loss": 3.7348883152008057, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0022254958748817444, "report/cont_pred": 0.9968577027320862, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.08346523344516754, "report/image_loss_std": 0.10375358909368515, "report/model_loss_mean": 0.7007260322570801, "report/model_loss_std": 0.29037582874298096, "report/post_ent_mag": 44.90239715576172, "report/post_ent_max": 44.90239715576172, "report/post_ent_mean": 43.52289581298828, "report/post_ent_min": 42.32478332519531, "report/post_ent_std": 0.5215288400650024, "report/prior_ent_mag": 44.910362243652344, "report/prior_ent_max": 44.910362243652344, "report/prior_ent_mean": 42.465511322021484, "report/prior_ent_min": 39.93665313720703, "report/prior_ent_std": 0.8053838014602661, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.00045459019020199776, "report/reward_loss_std": 0.004194206092506647, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.030480146408081055, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00045459019020199776, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00020610308274626732, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.03507138788700104, "eval/cont_loss_std": 0.6012912392616272, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 11.007865905761719, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0028300744015723467, "eval/cont_pred": 0.9972778558731079, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.16766759753227234, "eval/image_loss_std": 0.1643504649400711, "eval/model_loss_mean": 0.8032965660095215, "eval/model_loss_std": 0.628311276435852, "eval/post_ent_mag": 44.94550323486328, "eval/post_ent_max": 44.94550323486328, "eval/post_ent_mean": 43.553165435791016, "eval/post_ent_min": 42.473472595214844, "eval/post_ent_std": 0.5697357058525085, "eval/prior_ent_mag": 44.910362243652344, "eval/prior_ent_max": 44.910362243652344, "eval/prior_ent_mean": 42.44045639038086, "eval/prior_ent_min": 40.20319366455078, "eval/prior_ent_std": 0.8376553654670715, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0005575085524469614, "eval/reward_loss_std": 0.006577123422175646, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.049257636070251465, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0005575085524469614, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00022823538165539503, "eval/reward_rate": 0.0, "replay/size": 218781.0, "replay/inserts": 8740.0, "replay/samples": 34960.0, "replay/insert_wait_avg": 1.6466158205639033e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.535486526838429e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 51920.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 8.791685104370117e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0245246887207, "timer/env.step_count": 1092.0, "timer/env.step_total": 10.82023572921753, "timer/env.step_frac": 0.010819970372812168, "timer/env.step_avg": 0.00990864077767173, "timer/env.step_min": 0.008644819259643555, "timer/env.step_max": 0.03493666648864746, "timer/replay._sample_count": 34960.0, "timer/replay._sample_total": 19.156283378601074, "timer/replay._sample_frac": 0.01915581358823563, "timer/replay._sample_avg": 0.0005479486092277195, "timer/replay._sample_min": 0.0003733634948730469, "timer/replay._sample_max": 0.029112577438354492, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1092.0, "timer/agent.policy_total": 11.429210662841797, "timer/agent.policy_frac": 0.011428930371882015, "timer/agent.policy_avg": 0.010466310130807507, "timer/agent.policy_min": 0.00963139533996582, "timer/agent.policy_max": 0.03789663314819336, "timer/dataset_train_count": 2185.0, "timer/dataset_train_total": 0.39191627502441406, "timer/dataset_train_frac": 0.00039190666363548085, "timer/dataset_train_avg": 0.00017936671625831308, "timer/dataset_train_min": 9.72747802734375e-05, "timer/dataset_train_max": 0.0007009506225585938, "timer/agent.train_count": 2185.0, "timer/agent.train_total": 974.7983317375183, "timer/agent.train_frac": 0.9747744256981552, "timer/agent.train_avg": 0.4461319596052715, "timer/agent.train_min": 0.43496203422546387, "timer/agent.train_max": 0.572380781173706, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4806537628173828, "timer/agent.report_frac": 0.00048064197522255437, "timer/agent.report_avg": 0.2403268814086914, "timer/agent.report_min": 0.23194599151611328, "timer/agent.report_max": 0.24870777130126953, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 7.510185241699219e-05, "timer/dataset_eval_frac": 7.5100010612609e-08, "timer/dataset_eval_avg": 7.510185241699219e-05, "timer/dataset_eval_min": 7.510185241699219e-05, "timer/dataset_eval_max": 7.510185241699219e-05, "fps": 8.739646884680042}
{"step": 219720, "time": 25287.746824979782, "episode/length": 205.0, "episode/score": 0.359375, "episode/reward_rate": 0.0048543689320388345, "episode/intrinsic_return": 0.0}
{"step": 220016, "time": 25321.488701581955, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 220064, "time": 25330.473348855972, "eval_episode/length": 198.0, "eval_episode/score": 0.3812499940395355, "eval_episode/reward_rate": 0.005025125628140704}
{"step": 220064, "time": 25332.205401420593, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 25332.2143034935, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 25332.219847917557, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 25332.225458860397, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 25332.23090314865, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 25332.23627448082, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 25332.24162173271, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220576, "time": 25391.113660097122, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 220608, "time": 25394.800927639008, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 220856, "time": 25423.192093372345, "episode/length": 258.0, "episode/score": 0.19374999403953552, "episode/reward_rate": 0.003861003861003861, "episode/intrinsic_return": 0.0}
{"step": 220976, "time": 25436.912739753723, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 220984, "time": 25437.836393356323, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 221392, "time": 25485.086320638657, "episode/length": 278.0, "episode/score": 0.13124999403953552, "episode/reward_rate": 0.0035842293906810036, "episode/intrinsic_return": 0.0}
{"step": 221424, "time": 25488.755476236343, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 221544, "time": 25502.465310573578, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 222032, "time": 25558.355833530426, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 222328, "time": 25592.20747423172, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 222888, "time": 25656.1563873291, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 223288, "time": 25701.870171785355, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 223296, "time": 25702.79139137268, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 223704, "time": 25749.348098278046, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 223736, "time": 25753.099685668945, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 223760, "time": 25755.84829735756, "episode/length": 215.0, "episode/score": 0.328125, "episode/reward_rate": 0.004629629629629629, "episode/intrinsic_return": 0.0}
{"step": 223856, "time": 25766.78626346588, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 224640, "time": 25856.548792123795, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 225200, "time": 25920.560123205185, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 225600, "time": 25966.35901093483, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 225608, "time": 25967.271296024323, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 226016, "time": 26013.79772043228, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 226048, "time": 26017.462554693222, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 226072, "time": 26020.1958796978, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 226168, "time": 26031.250888824463, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 226952, "time": 26120.696307182312, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 227512, "time": 26184.733731508255, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 227912, "time": 26230.374608516693, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 227920, "time": 26231.38069844246, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 227973, "time": 26238.282061576843, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.0946942166798674, "train/action_min": 0.0, "train/action_std": 1.948020105537731, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00804699163332427, "train/actor_opt_grad_steps": 55520.0, "train/actor_opt_loss": -9.031726119155708, "train/adv_mag": 0.5055597392919426, "train/adv_max": 0.2600081473726281, "train/adv_mean": 0.004082655585465512, "train/adv_min": -0.45095205540481254, "train/adv_std": 0.030161202303670382, "train/cont_avg": 0.9963907690092166, "train/cont_loss_mean": 0.00915182146918638, "train/cont_loss_std": 0.16676120556921006, "train/cont_neg_acc": 0.5177565454877039, "train/cont_neg_loss": 2.017744343736777, "train/cont_pos_acc": 0.9998780140129652, "train/cont_pos_loss": 0.0018730675342947692, "train/cont_pred": 0.9963493069745428, "train/cont_rate": 0.9963907690092166, "train/dyn_loss_mean": 1.0000010910122077, "train/dyn_loss_std": 3.490903230238071e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.34201966096488284, "train/extr_critic_critic_opt_grad_steps": 55520.0, "train/extr_critic_critic_opt_loss": 9119.949590023762, "train/extr_critic_mag": 0.7071225143248036, "train/extr_critic_max": 0.7071225143248036, "train/extr_critic_mean": 0.5645323061997989, "train/extr_critic_min": 0.5083067763236261, "train/extr_critic_std": 0.02285445554928708, "train/extr_return_normed_mag": 0.5522809049226172, "train/extr_return_normed_max": 0.3610901463141639, "train/extr_return_normed_mean": 0.040386055032604624, "train/extr_return_normed_min": -0.4161754768290278, "train/extr_return_normed_std": 0.040326223137878606, "train/extr_return_rate": 0.7736247460430805, "train/extr_return_raw_mag": 0.8893190369627992, "train/extr_return_raw_max": 0.8893190369627992, "train/extr_return_raw_mean": 0.5686149689184355, "train/extr_return_raw_min": 0.11205341327025593, "train/extr_return_raw_std": 0.040326223125003176, "train/extr_reward_mag": 0.39539653969250516, "train/extr_reward_max": 0.39539653969250516, "train/extr_reward_mean": 0.000991196400265064, "train/extr_reward_min": -2.5660211589479226e-06, "train/extr_reward_std": 0.012654891513231155, "train/image_loss_mean": 0.06653112672647024, "train/image_loss_std": 0.09247743973534228, "train/model_loss_mean": 0.6780212252370773, "train/model_loss_std": 0.24233415431003966, "train/model_opt_grad_norm": 18.191317779046518, "train/model_opt_grad_steps": 55471.857142857145, "train/model_opt_loss": 2733.570536951865, "train/model_opt_model_opt_grad_overflow": 0.004608294930875576, "train/model_opt_model_opt_grad_scale": 4009.2165898617513, "train/policy_entropy_mag": 1.302652527110368, "train/policy_entropy_max": 1.302652527110368, "train/policy_entropy_mean": 0.10839606014676907, "train/policy_entropy_min": 0.06468650530422887, "train/policy_entropy_std": 0.13949044642772543, "train/policy_logprob_mag": 6.551080248872256, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.10851152927919466, "train/policy_logprob_min": -6.551080248872256, "train/policy_logprob_std": 0.646647067663307, "train/policy_randomness_mag": 0.6694310139950519, "train/policy_randomness_max": 0.6694310139950519, "train/policy_randomness_mean": 0.05570455901496421, "train/policy_randomness_min": 0.033242289045576676, "train/policy_randomness_std": 0.07168391310880261, "train/post_ent_mag": 43.1131961488504, "train/post_ent_max": 43.1131961488504, "train/post_ent_mean": 41.73869272750643, "train/post_ent_min": 40.70957261186591, "train/post_ent_std": 0.5123691317123202, "train/prior_ent_mag": 44.676437026344686, "train/prior_ent_max": 44.676437026344686, "train/prior_ent_mean": 42.102666933965025, "train/prior_ent_min": 39.76607390372984, "train/prior_ent_std": 0.8290614469260115, "train/rep_loss_mean": 1.0000010910122077, "train/rep_loss_std": 3.490903230238071e-05, "train/reward_avg": 0.0003674063262031285, "train/reward_loss_mean": 0.002337600942888868, "train/reward_loss_std": 0.055317999522817594, "train/reward_max_data": 0.2782546087824804, "train/reward_max_pred": 0.15364007301594254, "train/reward_neg_acc": 0.9998198343861487, "train/reward_neg_loss": 0.0003926909459366684, "train/reward_pos_acc": 0.4880952388048172, "train/reward_pos_loss": 2.850192022870998, "train/reward_pred": 0.0003035705191113295, "train/reward_rate": 0.0006570420506912442, "train_stats/mean_log_entropy": 0.10003427079608364, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.014426203444600105, "report/cont_loss_std": 0.26593446731567383, "report/cont_neg_acc": 0.5, "report/cont_neg_loss": 2.348385810852051, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0006700567901134491, "report/cont_pred": 0.9963347911834717, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.06613889336585999, "report/image_loss_std": 0.10042503476142883, "report/model_loss_mean": 0.6934981346130371, "report/model_loss_std": 0.5402551889419556, "report/post_ent_mag": 43.829566955566406, "report/post_ent_max": 43.829566955566406, "report/post_ent_mean": 42.36064910888672, "report/post_ent_min": 41.46090316772461, "report/post_ent_std": 0.5098966360092163, "report/prior_ent_mag": 44.421974182128906, "report/prior_ent_max": 44.421974182128906, "report/prior_ent_mean": 41.80731964111328, "report/prior_ent_min": 39.612525939941406, "report/prior_ent_std": 0.8662569522857666, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.001434326171875, "report/reward_loss_mean": 0.012933051213622093, "report/reward_loss_std": 0.29090967774391174, "report/reward_max_data": 0.671875, "report/reward_max_pred": 0.5889523029327393, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 4.460739000933245e-05, "report/reward_pos_acc": 0.3333333432674408, "report/reward_pos_loss": 4.399300575256348, "report/reward_pred": 0.0006109045352786779, "report/reward_rate": 0.0029296875, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.04141053557395935, "eval/cont_loss_std": 0.6039022207260132, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 8.154098510742188, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.001603429322130978, "eval/cont_pred": 0.9984683990478516, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.22129324078559875, "eval/image_loss_std": 0.19597215950489044, "eval/model_loss_mean": 0.8897973299026489, "eval/model_loss_std": 1.0589139461517334, "eval/post_ent_mag": 43.793907165527344, "eval/post_ent_max": 43.793907165527344, "eval/post_ent_mean": 42.477455139160156, "eval/post_ent_min": 41.4932746887207, "eval/post_ent_std": 0.5512538552284241, "eval/prior_ent_mag": 44.421974182128906, "eval/prior_ent_max": 44.421974182128906, "eval/prior_ent_mean": 41.920494079589844, "eval/prior_ent_min": 39.16489028930664, "eval/prior_ent_std": 0.9176961183547974, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0021087646018713713, "eval/reward_loss_mean": 0.02709352783858776, "eval/reward_loss_std": 0.5238261818885803, "eval/reward_max_data": 0.840624988079071, "eval/reward_max_pred": 0.024223804473876953, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00016199970559682697, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 9.192790031433105, "eval/reward_pred": 7.988081779330969e-05, "eval/reward_rate": 0.0029296875, "replay/size": 227469.0, "replay/inserts": 8688.0, "replay/samples": 34752.0, "replay/insert_wait_avg": 1.6252144924184893e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.428489556848234e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 54232.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1385724618773147e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.791685104370117e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1824586391449, "timer/env.step_count": 1086.0, "timer/env.step_total": 10.557214736938477, "timer/env.step_frac": 0.010555288833302172, "timer/env.step_avg": 0.009721192207125669, "timer/env.step_min": 0.008649826049804688, "timer/env.step_max": 0.03552436828613281, "timer/replay._sample_count": 34752.0, "timer/replay._sample_total": 18.636286973953247, "timer/replay._sample_frac": 0.018632887242703604, "timer/replay._sample_avg": 0.0005362651638453397, "timer/replay._sample_min": 0.0003478527069091797, "timer/replay._sample_max": 0.0323030948638916, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1375.0, "timer/agent.policy_total": 13.945486545562744, "timer/agent.policy_frac": 0.013942942535242088, "timer/agent.policy_avg": 0.010142172033136542, "timer/agent.policy_min": 0.008964300155639648, "timer/agent.policy_max": 0.047307729721069336, "timer/dataset_train_count": 2172.0, "timer/dataset_train_total": 0.3831179141998291, "timer/dataset_train_frac": 0.0003830480237786833, "timer/dataset_train_avg": 0.00017638946325958984, "timer/dataset_train_min": 9.512901306152344e-05, "timer/dataset_train_max": 0.0007925033569335938, "timer/agent.train_count": 2172.0, "timer/agent.train_total": 970.381245136261, "timer/agent.train_frac": 0.9702042229940409, "timer/agent.train_avg": 0.44676852906826015, "timer/agent.train_min": 0.4363596439361572, "timer/agent.train_max": 0.5877726078033447, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47831082344055176, "timer/agent.report_frac": 0.0004782235674192334, "timer/agent.report_avg": 0.23915541172027588, "timer/agent.report_min": 0.23278546333312988, "timer/agent.report_max": 0.24552536010742188, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 4.291534423828125e-05, "timer/dataset_eval_frac": 4.290751539141384e-08, "timer/dataset_eval_avg": 4.291534423828125e-05, "timer/dataset_eval_min": 4.291534423828125e-05, "timer/dataset_eval_max": 4.291534423828125e-05, "fps": 8.68629174314776}
{"step": 228328, "time": 26278.646946668625, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 228360, "time": 26282.29497385025, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 228384, "time": 26285.010623455048, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 228480, "time": 26296.04065322876, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 229264, "time": 26385.531749486923, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 229824, "time": 26449.943608760834, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 230008, "time": 26470.973098516464, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 230048, "time": 26478.60196375847, "eval_episode/length": 177.0, "eval_episode/score": 0.4468750059604645, "eval_episode/reward_rate": 0.0056179775280898875}
{"step": 230048, "time": 26480.506500720978, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 26480.514029741287, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 26480.5193939209, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 26480.524867534637, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 26480.530309915543, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 26480.53561925888, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 26480.54096221924, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230224, "time": 26500.55162715912, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 230232, "time": 26501.53471159935, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 230640, "time": 26548.23929953575, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 230672, "time": 26551.901562690735, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 230696, "time": 26554.670558929443, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 230792, "time": 26565.705505609512, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 231360, "time": 26630.59313440323, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 232136, "time": 26719.44520831108, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 232320, "time": 26740.441839694977, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 232536, "time": 26765.08216881752, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 232544, "time": 26766.001695632935, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 232952, "time": 26812.672170639038, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 232984, "time": 26816.33537554741, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 233072, "time": 26826.372792243958, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 233104, "time": 26830.037997961044, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 233648, "time": 26892.319342136383, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 233672, "time": 26895.062713623047, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 233736, "time": 26902.40400147438, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 233776, "time": 26906.9858212471, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 234448, "time": 26983.9623568058, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 234632, "time": 27004.923521757126, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 234856, "time": 27030.51407980919, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 235264, "time": 27077.178240060806, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 235960, "time": 27156.61981678009, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 235968, "time": 27157.53641963005, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 235984, "time": 27159.37072968483, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 236048, "time": 27166.757848501205, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 236088, "time": 27171.317598104477, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 236669, "time": 27238.418630838394, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.1830469650057602, "train/action_min": 0.0, "train/action_std": 2.1079256424706103, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.005185306164509003, "train/actor_opt_grad_steps": 57690.0, "train/actor_opt_loss": -8.720258349921846, "train/adv_mag": 0.43755697599753807, "train/adv_max": 0.16647277559552873, "train/adv_mean": 0.0003676853094865302, "train/adv_min": -0.40464710928328024, "train/adv_std": 0.014559457615052226, "train/cont_avg": 0.9961522537442397, "train/cont_loss_mean": 0.009191410627306228, "train/cont_loss_std": 0.16814851979210046, "train/cont_neg_acc": 0.5476574582575653, "train/cont_neg_loss": 1.9062861919322336, "train/cont_pos_acc": 0.99986900876744, "train/cont_pos_loss": 0.0018481435994553263, "train/cont_pred": 0.9961832750777495, "train/cont_rate": 0.9961522537442397, "train/dyn_loss_mean": 1.0000006394452214, "train/dyn_loss_std": 2.0460502463414372e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.10824504423423022, "train/extr_critic_critic_opt_grad_steps": 57690.0, "train/extr_critic_critic_opt_loss": 9603.184682819701, "train/extr_critic_mag": 0.7276367822550409, "train/extr_critic_max": 0.7276367822550409, "train/extr_critic_mean": 0.6339056478118017, "train/extr_critic_min": 0.5517995917852023, "train/extr_critic_std": 0.01966287713274703, "train/extr_return_normed_mag": 0.44376456023361277, "train/extr_return_normed_max": 0.2043699682582908, "train/extr_return_normed_mean": 0.029933567423762943, "train/extr_return_normed_min": -0.3837394376504256, "train/extr_return_normed_std": 0.023488359658845832, "train/extr_return_rate": 0.9989844725428638, "train/extr_return_raw_mag": 0.8087096456009122, "train/extr_return_raw_max": 0.8087096456009122, "train/extr_return_raw_mean": 0.6342732744282841, "train/extr_return_raw_min": 0.22060023969219578, "train/extr_return_raw_std": 0.02348835971893116, "train/extr_reward_mag": 0.23016734112242948, "train/extr_reward_max": 0.23016734112242948, "train/extr_reward_mean": 0.00019317013124873903, "train/extr_reward_min": 5.49351564750144e-09, "train/extr_reward_std": 0.003914524784981175, "train/image_loss_mean": 0.06640599772746113, "train/image_loss_std": 0.0932422094218742, "train/model_loss_mean": 0.6778094018659284, "train/model_loss_std": 0.24119483834038133, "train/model_opt_grad_norm": 18.533670662734917, "train/model_opt_grad_steps": 57640.12903225807, "train/model_opt_loss": 3467.0275282618086, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5115.207373271889, "train/policy_entropy_mag": 1.285217217036656, "train/policy_entropy_max": 1.285217217036656, "train/policy_entropy_mean": 0.10132137624212124, "train/policy_entropy_min": 0.06468649211979133, "train/policy_entropy_std": 0.12775304329834775, "train/policy_logprob_mag": 6.551080295017788, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.10120653985969481, "train/policy_logprob_min": -6.551080295017788, "train/policy_logprob_std": 0.6395274851179342, "train/policy_randomness_mag": 0.6604710358628479, "train/policy_randomness_max": 0.6604710358628479, "train/policy_randomness_mean": 0.052068890033779056, "train/policy_randomness_min": 0.03324228154349437, "train/policy_randomness_std": 0.06565208099610795, "train/post_ent_mag": 41.97667548184021, "train/post_ent_max": 41.97667548184021, "train/post_ent_mean": 40.67202851959088, "train/post_ent_min": 39.714111257808, "train/post_ent_std": 0.48642833565237337, "train/prior_ent_mag": 43.02729240101054, "train/prior_ent_max": 43.02729240101054, "train/prior_ent_mean": 40.56348760226904, "train/prior_ent_min": 38.276212437361615, "train/prior_ent_std": 0.8322299389245873, "train/rep_loss_mean": 1.0000006394452214, "train/rep_loss_std": 2.0460502463414372e-05, "train/reward_avg": 0.00034963018858396504, "train/reward_loss_mean": 0.002211587874793924, "train/reward_loss_std": 0.05665285274703463, "train/reward_max_data": 0.29546370906626573, "train/reward_max_pred": 0.15921299688277707, "train/reward_neg_acc": 0.9998603768063031, "train/reward_neg_loss": 0.0004291767436538368, "train/reward_pos_acc": 0.45192307749619853, "train/reward_pos_loss": 3.103408085182309, "train/reward_pred": 0.0003077074057049191, "train/reward_rate": 0.0005895377304147466, "train_stats/mean_log_entropy": 0.0864702114037105, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.010388229042291641, "report/cont_loss_std": 0.21599118411540985, "report/cont_neg_acc": 0.3333333432674408, "report/cont_neg_loss": 2.8424174785614014, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.002066890010610223, "report/cont_pred": 0.9968925714492798, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.06176335737109184, "report/image_loss_std": 0.08372114598751068, "report/model_loss_mean": 0.6842706203460693, "report/model_loss_std": 0.591131329536438, "report/post_ent_mag": 41.198707580566406, "report/post_ent_max": 41.198707580566406, "report/post_ent_mean": 39.915992736816406, "report/post_ent_min": 39.138179779052734, "report/post_ent_std": 0.4391292333602905, "report/prior_ent_mag": 40.06752014160156, "report/prior_ent_max": 40.06752014160156, "report/prior_ent_mean": 38.36038589477539, "report/prior_ent_min": 36.331295013427734, "report/prior_ent_std": 0.6964506506919861, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0004821777401957661, "report/reward_loss_mean": 0.012119016610085964, "report/reward_loss_std": 0.3628455102443695, "report/reward_max_data": 0.4937500059604645, "report/reward_max_pred": 0.07788527011871338, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0007780450978316367, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 11.613932609558105, "report/reward_pred": 0.00030289555434137583, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.9931640625, "eval/cont_loss_mean": 0.07063595950603485, "eval/cont_loss_std": 0.8742035627365112, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 10.11048698425293, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.0015317774377763271, "eval/cont_pred": 0.998509407043457, "eval/cont_rate": 0.9931640625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.21396934986114502, "eval/image_loss_std": 0.18216298520565033, "eval/model_loss_mean": 0.8897452354431152, "eval/model_loss_std": 0.9325141906738281, "eval/post_ent_mag": 41.09818649291992, "eval/post_ent_max": 41.09818649291992, "eval/post_ent_mean": 39.871986389160156, "eval/post_ent_min": 39.12668991088867, "eval/post_ent_std": 0.4531431198120117, "eval/prior_ent_mag": 40.1160888671875, "eval/prior_ent_max": 40.1160888671875, "eval/prior_ent_mean": 38.177398681640625, "eval/prior_ent_min": 36.044456481933594, "eval/prior_ent_std": 0.6913769245147705, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0006622314685955644, "eval/reward_loss_mean": 0.005139904096722603, "eval/reward_loss_std": 0.16021886467933655, "eval/reward_max_data": 0.6781250238418579, "eval/reward_max_pred": 0.015904903411865234, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00013091253640595824, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.129338264465332, "eval/reward_pred": 5.724094808101654e-05, "eval/reward_rate": 0.0009765625, "replay/size": 236165.0, "replay/inserts": 8696.0, "replay/samples": 34784.0, "replay/insert_wait_avg": 1.5359025760429543e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.374087055560746e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 56544.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0658712948069853e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.791685104370117e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1230854988098, "timer/env.step_count": 1087.0, "timer/env.step_total": 10.5226411819458, "timer/env.step_frac": 0.010521346156805939, "timer/env.step_avg": 0.00968044266968335, "timer/env.step_min": 0.00859689712524414, "timer/env.step_max": 0.03298044204711914, "timer/replay._sample_count": 34784.0, "timer/replay._sample_total": 18.53505802154541, "timer/replay._sample_frac": 0.01853277690545567, "timer/replay._sample_avg": 0.0005328616036552843, "timer/replay._sample_min": 0.0003883838653564453, "timer/replay._sample_max": 0.011656045913696289, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1376.0, "timer/agent.policy_total": 13.767300844192505, "timer/agent.policy_frac": 0.013765606497650322, "timer/agent.policy_avg": 0.010005305846070135, "timer/agent.policy_min": 0.008631467819213867, "timer/agent.policy_max": 0.03433513641357422, "timer/dataset_train_count": 2174.0, "timer/dataset_train_total": 0.3762369155883789, "timer/dataset_train_frac": 0.0003761906119792559, "timer/dataset_train_avg": 0.00017306205868830677, "timer/dataset_train_min": 8.988380432128906e-05, "timer/dataset_train_max": 0.0007305145263671875, "timer/agent.train_count": 2174.0, "timer/agent.train_total": 970.7282910346985, "timer/agent.train_frac": 0.9706088231635502, "timer/agent.train_avg": 0.4465171531898337, "timer/agent.train_min": 0.43462324142456055, "timer/agent.train_max": 0.5831501483917236, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4714527130126953, "timer/agent.report_frac": 0.00047139469116199735, "timer/agent.report_avg": 0.23572635650634766, "timer/agent.report_min": 0.22878098487854004, "timer/agent.report_max": 0.24267172813415527, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.24249267578125e-05, "timer/dataset_eval_frac": 3.2420936210707124e-08, "timer/dataset_eval_avg": 3.24249267578125e-05, "timer/dataset_eval_min": 3.24249267578125e-05, "timer/dataset_eval_max": 3.24249267578125e-05, "fps": 8.694808665372872}
{"step": 236760, "time": 27248.63538956642, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 236952, "time": 27270.623480319977, "episode/length": 261.0, "episode/score": 0.18437500298023224, "episode/reward_rate": 0.003816793893129771, "episode/intrinsic_return": 0.0}
{"step": 237576, "time": 27342.37646794319, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 237576, "time": 27342.384019374847, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 237632, "time": 27348.77606701851, "episode/length": 197.0, "episode/score": 0.3843750059604645, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.0}
{"step": 238264, "time": 27421.000777482986, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 238272, "time": 27421.921609163284, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 238280, "time": 27422.85328269005, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 238296, "time": 27424.674151420593, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 239072, "time": 27513.601951360703, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 239424, "time": 27553.978993415833, "episode/length": 230.0, "episode/score": 0.28125, "episode/reward_rate": 0.004329004329004329, "episode/intrinsic_return": 0.0}
{"step": 239888, "time": 27607.091834545135, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 239944, "time": 27613.55870962143, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 240032, "time": 27625.22906756401, "eval_episode/length": 58.0, "eval_episode/score": 0.8187500238418579, "eval_episode/reward_rate": 0.01694915254237288}
{"step": 240032, "time": 27625.88187098503, "eval_episode/length": 96.0, "eval_episode/score": 0.699999988079071, "eval_episode/reward_rate": 0.010309278350515464}
{"step": 240032, "time": 27627.428941965103, "eval_episode/length": 130.0, "eval_episode/score": 0.59375, "eval_episode/reward_rate": 0.007633587786259542}
{"step": 240032, "time": 27629.099994421005, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 27629.10627603531, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 27629.11238193512, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 27629.11773300171, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 27629.12305521965, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 27629.128393888474, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240576, "time": 27691.41624188423, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 240584, "time": 27692.33659863472, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 240592, "time": 27693.25395512581, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 240608, "time": 27695.105173826218, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 240792, "time": 27716.224841594696, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 241384, "time": 27784.067503213882, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 241736, "time": 27824.2638194561, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 242200, "time": 27877.211094856262, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 242256, "time": 27883.652007102966, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 242888, "time": 27955.9453458786, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 242896, "time": 27956.863810777664, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 242904, "time": 27957.78172636032, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 243104, "time": 27980.661283493042, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 243392, "time": 28013.66749238968, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 243696, "time": 28048.45046567917, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 243848, "time": 28065.841831207275, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 244040, "time": 28087.7246530056, "episode/length": 222.0, "episode/score": 0.3062500059604645, "episode/reward_rate": 0.004484304932735426, "episode/intrinsic_return": 0.0}
{"step": 244048, "time": 28088.636487722397, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 244128, "time": 28097.818690538406, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 244512, "time": 28141.664757490158, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 244544, "time": 28145.33014178276, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 245208, "time": 28222.17315888405, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 245345, "time": 28238.63754248619, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 1.9864347255724366, "train/action_min": 0.0, "train/action_std": 2.085483034085568, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.004210822693016466, "train/actor_opt_grad_steps": 59860.0, "train/actor_opt_loss": -8.94531361628238, "train/adv_mag": 0.3944247717956244, "train/adv_max": 0.17762706741209952, "train/adv_mean": -0.000880160075258292, "train/adv_min": -0.3669608937155816, "train/adv_std": 0.013818215902826066, "train/cont_avg": 0.9961612543202765, "train/cont_loss_mean": 0.009355683722490368, "train/cont_loss_std": 0.17018570341513178, "train/cont_neg_acc": 0.5376488163515374, "train/cont_neg_loss": 1.989462544953666, "train/cont_pos_acc": 0.9998734401118371, "train/cont_pos_loss": 0.001871803850804623, "train/cont_pred": 0.9962173313039788, "train/cont_rate": 0.9961612543202765, "train/dyn_loss_mean": 1.0000005608879476, "train/dyn_loss_std": 1.7949018932123614e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.08613696137726444, "train/extr_critic_critic_opt_grad_steps": 59860.0, "train/extr_critic_critic_opt_loss": 8935.822681901642, "train/extr_critic_mag": 0.6901980336360668, "train/extr_critic_max": 0.6901980336360668, "train/extr_critic_mean": 0.5600799984096931, "train/extr_critic_min": 0.49506802657782206, "train/extr_critic_std": 0.018045488071160107, "train/extr_return_normed_mag": 0.41164549786923665, "train/extr_return_normed_max": 0.2359262674634907, "train/extr_return_normed_mean": 0.020758248144580473, "train/extr_return_normed_min": -0.34684485924958086, "train/extr_return_normed_std": 0.023503591800065633, "train/extr_return_rate": 0.9991968870162964, "train/extr_return_raw_mag": 0.7743678120424121, "train/extr_return_raw_max": 0.7743678120424121, "train/extr_return_raw_mean": 0.5591998185430255, "train/extr_return_raw_min": 0.19159668532934057, "train/extr_return_raw_std": 0.023503591748563923, "train/extr_reward_mag": 0.2853251426450668, "train/extr_reward_max": 0.2853251426450668, "train/extr_reward_mean": 0.00039598222061898344, "train/extr_reward_min": 3.1313039190758205e-08, "train/extr_reward_std": 0.00579181204422287, "train/image_loss_mean": 0.06474356730962129, "train/image_loss_std": 0.0916668820422366, "train/model_loss_mean": 0.6763449893569067, "train/model_loss_std": 0.24205970283477538, "train/model_opt_grad_norm": 17.33259418717137, "train/model_opt_grad_steps": 59807.74193548387, "train/model_opt_loss": 2958.674473353795, "train/model_opt_model_opt_grad_overflow": 0.004608294930875576, "train/model_opt_model_opt_grad_scale": 4354.8387096774195, "train/policy_entropy_mag": 1.2751687721173335, "train/policy_entropy_max": 1.2751687721173335, "train/policy_entropy_mean": 0.10611580566327143, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.13427282986553035, "train/policy_logprob_mag": 6.551080301610006, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.10582981680944768, "train/policy_logprob_min": -6.551080301610006, "train/policy_logprob_std": 0.6427938039951061, "train/policy_randomness_mag": 0.6553071566990444, "train/policy_randomness_max": 0.6553071566990444, "train/policy_randomness_mean": 0.05453274000762245, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06900258882460507, "train/post_ent_mag": 41.238051541939306, "train/post_ent_max": 41.238051541939306, "train/post_ent_mean": 40.038473296275335, "train/post_ent_min": 39.16139957761984, "train/post_ent_std": 0.4465311315202493, "train/prior_ent_mag": 41.006297291698544, "train/prior_ent_max": 41.006297291698544, "train/prior_ent_mean": 39.351859132265716, "train/prior_ent_min": 37.64650917932185, "train/prior_ent_std": 0.5580838039723409, "train/rep_loss_mean": 1.0000005608879476, "train/rep_loss_std": 1.7949018932123614e-05, "train/reward_avg": 0.0003612324954085653, "train/reward_loss_mean": 0.002245380552963049, "train/reward_loss_std": 0.05473571398814771, "train/reward_max_data": 0.27992511523484087, "train/reward_max_pred": 0.16118498606615903, "train/reward_neg_acc": 0.9998063368182029, "train/reward_neg_loss": 0.000423876094798963, "train/reward_pos_acc": 0.5237179498832959, "train/reward_pos_loss": 2.7522582242695184, "train/reward_pred": 0.00032872963516462233, "train/reward_rate": 0.0006705429147465438, "train_stats/mean_log_entropy": 0.08768745298896517, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.004726152867078781, "report/cont_loss_std": 0.07448034733533859, "report/cont_neg_acc": 0.5, "report/cont_neg_loss": 0.8405009508132935, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0014486049767583609, "report/cont_pred": 0.9962611198425293, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.06058044731616974, "report/image_loss_std": 0.08782581239938736, "report/model_loss_mean": 0.6679896116256714, "report/model_loss_std": 0.17993368208408356, "report/post_ent_mag": 41.074928283691406, "report/post_ent_max": 41.074928283691406, "report/post_ent_mean": 39.724037170410156, "report/post_ent_min": 38.7692985534668, "report/post_ent_std": 0.48008373379707336, "report/prior_ent_mag": 41.116554260253906, "report/prior_ent_max": 41.116554260253906, "report/prior_ent_mean": 39.54142761230469, "report/prior_ent_min": 37.971771240234375, "report/prior_ent_std": 0.5183702707290649, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0005828857538290322, "report/reward_loss_mean": 0.0026829964481294155, "report/reward_loss_std": 0.07809000462293625, "report/reward_max_data": 0.596875011920929, "report/reward_max_pred": 0.05554342269897461, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00024290168948937207, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 2.4988999366760254, "report/reward_pred": 0.00015090592205524445, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.0417141318321228, "eval/cont_loss_std": 0.608012855052948, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 8.285659790039062, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0012629764387384057, "eval/cont_pred": 0.9987331032752991, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.23409608006477356, "eval/image_loss_std": 0.1757519245147705, "eval/model_loss_mean": 0.9016947746276855, "eval/model_loss_std": 1.0029016733169556, "eval/post_ent_mag": 41.00413131713867, "eval/post_ent_max": 41.00413131713867, "eval/post_ent_mean": 39.710906982421875, "eval/post_ent_min": 38.79875564575195, "eval/post_ent_std": 0.4740630090236664, "eval/prior_ent_mag": 41.10854721069336, "eval/prior_ent_max": 41.10854721069336, "eval/prior_ent_mean": 39.386497497558594, "eval/prior_ent_min": 37.96534729003906, "eval/prior_ent_std": 0.5205670595169067, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0023529052268713713, "eval/reward_loss_mean": 0.02588452771306038, "eval/reward_loss_std": 0.49131810665130615, "eval/reward_max_data": 0.840624988079071, "eval/reward_max_pred": 0.03262436389923096, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0002991627552546561, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 8.733438491821289, "eval/reward_pred": 0.00014563254080712795, "eval/reward_rate": 0.0029296875, "replay/size": 244841.0, "replay/inserts": 8676.0, "replay/samples": 34704.0, "replay/insert_wait_avg": 1.5917655343336684e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.298340056556993e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 58856.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0917549727284784e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.897615432739258e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2041969299316, "timer/env.step_count": 1085.0, "timer/env.step_total": 10.570114850997925, "timer/env.step_frac": 0.010567956906641938, "timer/env.step_avg": 0.009742041337325277, "timer/env.step_min": 0.008534908294677734, "timer/env.step_max": 0.039463043212890625, "timer/replay._sample_count": 34704.0, "timer/replay._sample_total": 18.563201665878296, "timer/replay._sample_frac": 0.018559411890948826, "timer/replay._sample_avg": 0.0005349009239822008, "timer/replay._sample_min": 0.0003962516784667969, "timer/replay._sample_max": 0.011420249938964844, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1374.0, "timer/agent.policy_total": 14.212130546569824, "timer/agent.policy_frac": 0.01420922906561793, "timer/agent.policy_avg": 0.010343617573922725, "timer/agent.policy_min": 0.008726835250854492, "timer/agent.policy_max": 0.08723020553588867, "timer/dataset_train_count": 2169.0, "timer/dataset_train_total": 0.36751604080200195, "timer/dataset_train_frac": 0.0003674410104757318, "timer/dataset_train_avg": 0.00016944031387828583, "timer/dataset_train_min": 8.96453857421875e-05, "timer/dataset_train_max": 0.0007977485656738281, "timer/agent.train_count": 2169.0, "timer/agent.train_total": 970.1631870269775, "timer/agent.train_frac": 0.9699651231266943, "timer/agent.train_avg": 0.44728593223927043, "timer/agent.train_min": 0.4373948574066162, "timer/agent.train_max": 1.3056929111480713, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4759829044342041, "timer/agent.report_frac": 0.0004758857300291339, "timer/agent.report_avg": 0.23799145221710205, "timer/agent.report_min": 0.23230290412902832, "timer/agent.report_max": 0.24368000030517578, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0040740966796875e-05, "timer/dataset_eval_frac": 3.0034607992053195e-08, "timer/dataset_eval_avg": 3.0040740966796875e-05, "timer/dataset_eval_min": 3.0040740966796875e-05, "timer/dataset_eval_max": 3.0040740966796875e-05, "fps": 8.67411382099099}
{"step": 245416, "time": 28246.591514348984, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 245704, "time": 28279.33075237274, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 245912, "time": 28303.451110124588, "episode/length": 232.0, "episode/score": 0.2750000059604645, "episode/reward_rate": 0.004291845493562232, "episode/intrinsic_return": 0.0}
{"step": 246352, "time": 28353.43575334549, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 246440, "time": 28363.546846151352, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 246824, "time": 28407.381690740585, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 246856, "time": 28411.046851873398, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 247520, "time": 28486.825445890427, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 247728, "time": 28510.502326726913, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 248016, "time": 28543.510931015015, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 248224, "time": 28567.19220852852, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 248664, "time": 28617.379037618637, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 248752, "time": 28627.3500957489, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 249136, "time": 28670.989547252655, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 249168, "time": 28674.622322797775, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 249544, "time": 28717.2926633358, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 249832, "time": 28749.96660232544, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 250016, "time": 28775.98501586914, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 28775.992779493332, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 28775.998653173447, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 28776.004108428955, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 28776.0095140934, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 28776.014820814133, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 28776.020204782486, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 28776.025607585907, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250040, "time": 28778.772179841995, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 250152, "time": 28791.61345100403, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 250480, "time": 28828.860561847687, "episode/length": 281.0, "episode/score": 0.12187500298023224, "episode/reward_rate": 0.0035460992907801418, "episode/intrinsic_return": 0.0}
{"step": 250976, "time": 28885.310037612915, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 251064, "time": 28895.332728624344, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 251448, "time": 28939.27278828621, "episode/length": 288.0, "episode/score": 0.10000000149011612, "episode/reward_rate": 0.0034602076124567475, "episode/intrinsic_return": 0.0}
{"step": 251480, "time": 28942.92643046379, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 251720, "time": 28970.299904108047, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 252136, "time": 29017.742612361908, "episode/length": 206.0, "episode/score": 0.35624998807907104, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.0}
{"step": 252144, "time": 29018.674738168716, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 252352, "time": 29042.341545581818, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 252464, "time": 29055.09983277321, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 252760, "time": 29088.727870225906, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 253096, "time": 29127.03910303116, "episode/length": 264.0, "episode/score": 0.17499999701976776, "episode/reward_rate": 0.0037735849056603774, "episode/intrinsic_return": 0.0}
{"step": 253760, "time": 29203.114335536957, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 253792, "time": 29206.74832391739, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 254032, "time": 29234.637268781662, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 254061, "time": 29238.83811402321, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.4727981987349485, "train/action_min": 0.0, "train/action_std": 2.220161926855735, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.004951227582892864, "train/actor_opt_grad_steps": 62035.0, "train/actor_opt_loss": -8.869985795895987, "train/adv_mag": 0.41674111551101056, "train/adv_max": 0.17687992054388063, "train/adv_mean": 0.00029108977652717716, "train/adv_min": -0.38115269301134513, "train/adv_std": 0.01626818466914493, "train/cont_avg": 0.9962326189793578, "train/cont_loss_mean": 0.009695360871323453, "train/cont_loss_std": 0.1684973202058362, "train/cont_neg_acc": 0.510541030428779, "train/cont_neg_loss": 2.0240562658645884, "train/cont_pos_acc": 0.9998965637946348, "train/cont_pos_loss": 0.0020029523464372605, "train/cont_pred": 0.9962258185815374, "train/cont_rate": 0.9962326189793578, "train/dyn_loss_mean": 1.0000200616110355, "train/dyn_loss_std": 0.0005463304635192857, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.11824222209803555, "train/extr_critic_critic_opt_grad_steps": 62035.0, "train/extr_critic_critic_opt_loss": 7499.539512704272, "train/extr_critic_mag": 0.6899856520355294, "train/extr_critic_max": 0.6899856520355294, "train/extr_critic_mean": 0.5751402911243089, "train/extr_critic_min": 0.5221895367727367, "train/extr_critic_std": 0.01924589313481242, "train/extr_return_normed_mag": 0.4377714146714692, "train/extr_return_normed_max": 0.2505145589692877, "train/extr_return_normed_mean": 0.027598870649011037, "train/extr_return_normed_min": -0.3478560667792591, "train/extr_return_normed_std": 0.026138862671860313, "train/extr_return_rate": 0.9992095281224732, "train/extr_return_raw_mag": 0.7983470802460242, "train/extr_return_raw_max": 0.7983470802460242, "train/extr_return_raw_mean": 0.5754314275509721, "train/extr_return_raw_min": 0.19997645449747734, "train/extr_return_raw_std": 0.026138862778663362, "train/extr_reward_mag": 0.3178804691778411, "train/extr_reward_max": 0.3178804691778411, "train/extr_reward_mean": 0.0003754357346783471, "train/extr_reward_min": -2.826572558201781e-06, "train/extr_reward_std": 0.006533394939877059, "train/image_loss_mean": 0.06834513803414248, "train/image_loss_std": 0.09522073105866209, "train/model_loss_mean": 0.6808220372287506, "train/model_loss_std": 0.25414674267719645, "train/model_opt_grad_norm": 16.98656105557713, "train/model_opt_grad_steps": 61980.66513761468, "train/model_opt_loss": 3077.2453753270142, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 4518.348623853211, "train/policy_entropy_mag": 1.3085258663247485, "train/policy_entropy_max": 1.3085258663247485, "train/policy_entropy_mean": 0.09906969544127447, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.12543351982438236, "train/policy_logprob_mag": 6.551080279394028, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09862652786691255, "train/policy_logprob_min": -6.551080279394028, "train/policy_logprob_std": 0.6353573178479431, "train/policy_randomness_mag": 0.6724493123522592, "train/policy_randomness_max": 0.6724493123522592, "train/policy_randomness_mean": 0.05091175486530186, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06446008124482741, "train/post_ent_mag": 41.37786076047005, "train/post_ent_max": 41.37786076047005, "train/post_ent_mean": 40.17046413946589, "train/post_ent_min": 39.277096564616635, "train/post_ent_std": 0.4525459701314979, "train/prior_ent_mag": 41.80044681654064, "train/prior_ent_max": 41.80044681654064, "train/prior_ent_mean": 39.98365941178908, "train/prior_ent_min": 38.18235411337756, "train/prior_ent_std": 0.5903715812558428, "train/rep_loss_mean": 1.0000200616110355, "train/rep_loss_std": 0.0005463304635192857, "train/reward_avg": 0.0003961265626015812, "train/reward_loss_mean": 0.0027694786637658337, "train/reward_loss_std": 0.0675488390739251, "train/reward_max_data": 0.298079128146445, "train/reward_max_pred": 0.1495158716079292, "train/reward_neg_acc": 0.9998117359953189, "train/reward_neg_loss": 0.0004412139039457276, "train/reward_pos_acc": 0.40972222332601194, "train/reward_pos_loss": 3.3466659604951188, "train/reward_pred": 0.0003059450750572419, "train/reward_rate": 0.0006988245412844037, "train_stats/mean_log_entropy": 0.09040161200305995, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.01646227389574051, "report/cont_loss_std": 0.2725510895252228, "report/cont_neg_acc": 0.25, "report/cont_neg_loss": 3.751974105834961, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0018132044933736324, "report/cont_pred": 0.9972209930419922, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07425658404827118, "report/image_loss_std": 0.1029658392071724, "report/model_loss_mean": 0.696052074432373, "report/model_loss_std": 0.39923417568206787, "report/post_ent_mag": 41.60923767089844, "report/post_ent_max": 41.60923767089844, "report/post_ent_mean": 40.52278518676758, "report/post_ent_min": 39.70375061035156, "report/post_ent_std": 0.43732935190200806, "report/prior_ent_mag": 41.2392578125, "report/prior_ent_max": 41.2392578125, "report/prior_ent_mean": 40.05879211425781, "report/prior_ent_min": 38.52340316772461, "report/prior_ent_std": 0.48699164390563965, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0007476806640625, "report/reward_loss_mean": 0.0053331623785197735, "report/reward_loss_std": 0.16027507185935974, "report/reward_max_data": 0.765625, "report/reward_max_pred": 0.018889904022216797, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00032276095589622855, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 5.130973815917969, "report/reward_pred": 0.00014734058640897274, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.03029237501323223, "eval/cont_loss_std": 0.5052391886711121, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 7.40443754196167, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.001374158775433898, "eval/cont_pred": 0.9985897541046143, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.16857072710990906, "eval/image_loss_std": 0.1446961909532547, "eval/model_loss_mean": 0.8052613735198975, "eval/model_loss_std": 0.5931698679924011, "eval/post_ent_mag": 41.60152816772461, "eval/post_ent_max": 41.60152816772461, "eval/post_ent_mean": 40.545433044433594, "eval/post_ent_min": 39.65168762207031, "eval/post_ent_std": 0.4519120454788208, "eval/prior_ent_mag": 41.636993408203125, "eval/prior_ent_max": 41.636993408203125, "eval/prior_ent_mean": 40.08433532714844, "eval/prior_ent_min": 38.520957946777344, "eval/prior_ent_std": 0.5890399217605591, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0004241943242959678, "eval/reward_loss_mean": 0.0063982498832046986, "eval/reward_loss_std": 0.19903069734573364, "eval/reward_max_data": 0.43437498807907104, "eval/reward_max_pred": 0.03257632255554199, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0001759417209541425, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 6.371819496154785, "eval/reward_pred": 0.00011819088831543922, "eval/reward_rate": 0.0009765625, "replay/size": 253557.0, "replay/inserts": 8716.0, "replay/samples": 34864.0, "replay/insert_wait_avg": 1.5414871716510271e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.446817936400527e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 61168.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0777303504283865e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.791685104370117e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.185355424881, "timer/env.step_count": 1089.0, "timer/env.step_total": 10.802368879318237, "timer/env.step_frac": 0.010800366972709141, "timer/env.step_avg": 0.009919530651348244, "timer/env.step_min": 0.008654356002807617, "timer/env.step_max": 0.035095930099487305, "timer/replay._sample_count": 34864.0, "timer/replay._sample_total": 18.789263010025024, "timer/replay._sample_frac": 0.018785780963612792, "timer/replay._sample_avg": 0.0005389302148355044, "timer/replay._sample_min": 0.00037360191345214844, "timer/replay._sample_max": 0.011383771896362305, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1378.0, "timer/agent.policy_total": 13.960382461547852, "timer/agent.policy_frac": 0.013957795308468048, "timer/agent.policy_avg": 0.010130901641181314, "timer/agent.policy_min": 0.008718252182006836, "timer/agent.policy_max": 0.0503692626953125, "timer/dataset_train_count": 2179.0, "timer/dataset_train_total": 0.36922264099121094, "timer/dataset_train_frac": 0.0003691542162546105, "timer/dataset_train_avg": 0.0001694459114232267, "timer/dataset_train_min": 8.893013000488281e-05, "timer/dataset_train_max": 0.001191854476928711, "timer/agent.train_count": 2179.0, "timer/agent.train_total": 970.1246151924133, "timer/agent.train_frac": 0.969944830656216, "timer/agent.train_avg": 0.4452155186748111, "timer/agent.train_min": 0.432938814163208, "timer/agent.train_max": 0.5898256301879883, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4796006679534912, "timer/agent.report_frac": 0.00047951178784232026, "timer/agent.report_avg": 0.2398003339767456, "timer/agent.report_min": 0.23167109489440918, "timer/agent.report_max": 0.24792957305908203, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0517578125e-05, "timer/dataset_eval_frac": 3.051192257462724e-08, "timer/dataset_eval_avg": 3.0517578125e-05, "timer/dataset_eval_min": 3.0517578125e-05, "timer/dataset_eval_max": 3.0517578125e-05, "fps": 8.714252588647557}
{"step": 254128, "time": 29246.341586351395, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 254448, "time": 29282.932644605637, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 254456, "time": 29283.84693646431, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 254464, "time": 29284.762480974197, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 254560, "time": 29295.86665534973, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 254664, "time": 29307.70272397995, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 254856, "time": 29329.71622300148, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 255072, "time": 29354.50642490387, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 255408, "time": 29393.17475295067, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 255768, "time": 29434.420475959778, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 256248, "time": 29489.178347826004, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 256440, "time": 29511.05931687355, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 256680, "time": 29538.34263420105, "episode/length": 276.0, "episode/score": 0.13750000298023224, "episode/reward_rate": 0.0036101083032490976, "episode/intrinsic_return": 0.0}
{"step": 256760, "time": 29547.468515872955, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 256976, "time": 29571.97748351097, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 257080, "time": 29583.84072613716, "episode/length": 277.0, "episode/score": 0.13437500596046448, "episode/reward_rate": 0.0035971223021582736, "episode/intrinsic_return": 0.0}
{"step": 257384, "time": 29618.528218269348, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 258080, "time": 29697.723529815674, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 258560, "time": 29752.271863937378, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 258752, "time": 29773.945009469986, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 258992, "time": 29800.99820780754, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 259072, "time": 29810.05246758461, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 259160, "time": 29819.983672380447, "episode/length": 259.0, "episode/score": 0.19062499701976776, "episode/reward_rate": 0.0038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 259288, "time": 29834.478629112244, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 259440, "time": 29851.6069085598, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 259552, "time": 29864.300679683685, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 259696, "time": 29880.56046628952, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 260000, "time": 29916.561911821365, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 260000, "time": 29917.2859518528, "eval_episode/length": 141.0, "eval_episode/score": 0.559374988079071, "eval_episode/reward_rate": 0.007042253521126761}
{"step": 260000, "time": 29918.25807237625, "eval_episode/length": 199.0, "eval_episode/score": 0.37812501192092896, "eval_episode/reward_rate": 0.005}
{"step": 260000, "time": 29918.551045417786, "eval_episode/length": 216.0, "eval_episode/score": 0.32499998807907104, "eval_episode/reward_rate": 0.004608294930875576}
{"step": 260000, "time": 29919.77834200859, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 29919.785489082336, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 29919.791138887405, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 29919.79661822319, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260392, "time": 29964.07479763031, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 261064, "time": 30040.10683298111, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 261304, "time": 30067.19467139244, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 261472, "time": 30086.20755958557, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 261480, "time": 30087.131781101227, "episode/length": 240.0, "episode/score": 0.25, "episode/reward_rate": 0.004149377593360996, "episode/intrinsic_return": 0.0}
{"step": 261600, "time": 30100.66865181923, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 261752, "time": 30117.920135736465, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 262008, "time": 30146.796839237213, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 262672, "time": 30222.22585630417, "episode/length": 284.0, "episode/score": 0.11249999701976776, "episode/reward_rate": 0.0035087719298245615, "episode/intrinsic_return": 0.0}
{"step": 262813, "time": 30238.94272685051, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.3656173078981166, "train/action_min": 0.0, "train/action_std": 2.0720130635178795, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.004395168287930457, "train/actor_opt_grad_steps": 64220.0, "train/actor_opt_loss": -8.551112300184764, "train/adv_mag": 0.36148224464834555, "train/adv_max": 0.1328094351237223, "train/adv_mean": -0.000549721019428923, "train/adv_min": -0.33772293073401605, "train/adv_std": 0.012534180511486585, "train/cont_avg": 0.9963345462328768, "train/cont_loss_mean": 0.009227222449105812, "train/cont_loss_std": 0.16221285117875156, "train/cont_neg_acc": 0.5147840600374133, "train/cont_neg_loss": 1.9637672397461186, "train/cont_pos_acc": 0.9998746756549295, "train/cont_pos_loss": 0.001986239324738463, "train/cont_pred": 0.9962222649626535, "train/cont_rate": 0.9963345462328768, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.08476711151543069, "train/extr_critic_critic_opt_grad_steps": 64220.0, "train/extr_critic_critic_opt_loss": 9438.461521653824, "train/extr_critic_mag": 0.6647834609088288, "train/extr_critic_max": 0.6647834609088288, "train/extr_critic_mean": 0.5561863461585894, "train/extr_critic_min": 0.5019318654656955, "train/extr_critic_std": 0.017566929805224344, "train/extr_return_normed_mag": 0.3824127123236112, "train/extr_return_normed_max": 0.1954788924896554, "train/extr_return_normed_mean": 0.02243909096881135, "train/extr_return_normed_min": -0.3096819604368515, "train/extr_return_normed_std": 0.02194190069982042, "train/extr_return_rate": 0.9992410823634771, "train/extr_return_raw_mag": 0.728676452484305, "train/extr_return_raw_max": 0.728676452484305, "train/extr_return_raw_mean": 0.5556366743018094, "train/extr_return_raw_min": 0.2235155995577982, "train/extr_return_raw_std": 0.021941900572241987, "train/extr_reward_mag": 0.26007440699834256, "train/extr_reward_max": 0.26007440699834256, "train/extr_reward_mean": 0.00025927665824196556, "train/extr_reward_min": 1.0886693109660388e-09, "train/extr_reward_std": 0.0047830670878512265, "train/image_loss_mean": 0.06802081418772267, "train/image_loss_std": 0.09449192116113558, "train/model_loss_mean": 0.6798115383544469, "train/model_loss_std": 0.2412898459527046, "train/model_opt_grad_norm": 16.75715152495498, "train/model_opt_grad_steps": 64163.748858447485, "train/model_opt_loss": 3537.9315915739157, "train/model_opt_model_opt_grad_overflow": 0.0045662100456621, "train/model_opt_model_opt_grad_scale": 5182.648401826484, "train/policy_entropy_mag": 1.307004533946242, "train/policy_entropy_max": 1.307004533946242, "train/policy_entropy_mean": 0.10664321291664419, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.13542433004809296, "train/policy_logprob_mag": 6.551080250848918, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.10748462617125142, "train/policy_logprob_min": -6.551080250848918, "train/policy_logprob_std": 0.6472987570719088, "train/policy_randomness_mag": 0.6716675042561745, "train/policy_randomness_max": 0.6716675042561745, "train/policy_randomness_mean": 0.05480377309738773, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06959434304403388, "train/post_ent_mag": 41.56465023511077, "train/post_ent_max": 41.56465023511077, "train/post_ent_mean": 40.41052409829614, "train/post_ent_min": 39.534164167430305, "train/post_ent_std": 0.4375493165837031, "train/prior_ent_mag": 41.70161971000776, "train/prior_ent_max": 41.70161971000776, "train/prior_ent_mean": 40.28969553072159, "train/prior_ent_min": 38.79318991534786, "train/prior_ent_std": 0.4603339403731638, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.00039118239839484734, "train/reward_loss_mean": 0.0025634820523595257, "train/reward_loss_std": 0.06176497028225216, "train/reward_max_data": 0.3012414385466815, "train/reward_max_pred": 0.16024326298334826, "train/reward_neg_acc": 0.9998348831586098, "train/reward_neg_loss": 0.0004609529149333721, "train/reward_pos_acc": 0.38473520323494886, "train/reward_pos_loss": 3.183218854610051, "train/reward_pred": 0.0003294092890079299, "train/reward_rate": 0.000682255993150685, "train_stats/mean_log_entropy": 0.09557775552901956, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.009756739251315594, "report/cont_loss_std": 0.18973824381828308, "report/cont_neg_acc": 0.6000000238418579, "report/cont_neg_loss": 1.6888173818588257, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0015179722104221582, "report/cont_pred": 0.9956706762313843, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.05658053234219551, "report/image_loss_std": 0.08032739907503128, "report/model_loss_mean": 0.6704972982406616, "report/model_loss_std": 0.29945939779281616, "report/post_ent_mag": 41.6875, "report/post_ent_max": 41.6875, "report/post_ent_mean": 40.57246017456055, "report/post_ent_min": 39.69011688232422, "report/post_ent_std": 0.4851783215999603, "report/prior_ent_mag": 41.28101348876953, "report/prior_ent_max": 41.28101348876953, "report/prior_ent_mean": 39.97809600830078, "report/prior_ent_min": 38.405609130859375, "report/prior_ent_std": 0.5000014305114746, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0007141113164834678, "report/reward_loss_mean": 0.004159992560744286, "report/reward_loss_std": 0.12285105139017105, "report/reward_max_data": 0.731249988079071, "report/reward_max_pred": 0.027733445167541504, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0003197279293090105, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 3.932750701904297, "report/reward_pred": 0.00017177476547658443, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.04128529876470566, "eval/cont_loss_std": 0.6238260865211487, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 7.505659580230713, "eval/cont_pos_acc": 0.999018669128418, "eval/cont_pos_loss": 0.004659323953092098, "eval/cont_pred": 0.9971510171890259, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.13664759695529938, "eval/image_loss_std": 0.1291305273771286, "eval/model_loss_mean": 0.7807040214538574, "eval/model_loss_std": 0.6519599556922913, "eval/post_ent_mag": 41.71372985839844, "eval/post_ent_max": 41.71372985839844, "eval/post_ent_mean": 40.588375091552734, "eval/post_ent_min": 39.6343879699707, "eval/post_ent_std": 0.4874158799648285, "eval/prior_ent_mag": 41.384063720703125, "eval/prior_ent_max": 41.384063720703125, "eval/prior_ent_mean": 40.10374450683594, "eval/prior_ent_min": 38.75861358642578, "eval/prior_ent_std": 0.47890952229499817, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0007659912225790322, "eval/reward_loss_mean": 0.0027710862923413515, "eval/reward_loss_std": 0.07394479960203171, "eval/reward_max_data": 0.784375011920929, "eval/reward_max_pred": 0.11009001731872559, "eval/reward_neg_acc": 0.9990224838256836, "eval/reward_neg_loss": 0.0004668704350478947, "eval/reward_pos_acc": 1.0, "eval/reward_pos_loss": 2.3599839210510254, "eval/reward_pred": 0.00034375337418168783, "eval/reward_rate": 0.0009765625, "replay/size": 262309.0, "replay/inserts": 8752.0, "replay/samples": 35008.0, "replay/insert_wait_avg": 1.546996603064389e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.078947891918789e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 63480.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0212193723368396e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.897615432739258e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0887176990509, "timer/env.step_count": 1094.0, "timer/env.step_total": 10.793950080871582, "timer/env.step_frac": 0.010792992551406548, "timer/env.step_avg": 0.009866499159846054, "timer/env.step_min": 0.00869607925415039, "timer/env.step_max": 0.03467226028442383, "timer/replay._sample_count": 35008.0, "timer/replay._sample_total": 18.936326026916504, "timer/replay._sample_frac": 0.0189346461886743, "timer/replay._sample_avg": 0.0005409142489407136, "timer/replay._sample_min": 0.0003733634948730469, "timer/replay._sample_max": 0.023517131805419922, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1383.0, "timer/agent.policy_total": 13.855566501617432, "timer/agent.policy_frac": 0.013854337376683498, "timer/agent.policy_avg": 0.010018486262919329, "timer/agent.policy_min": 0.008663654327392578, "timer/agent.policy_max": 0.0344235897064209, "timer/dataset_train_count": 2188.0, "timer/dataset_train_total": 0.38062238693237305, "timer/dataset_train_frac": 0.00038058862198554554, "timer/dataset_train_avg": 0.00017395904338773905, "timer/dataset_train_min": 9.298324584960938e-05, "timer/dataset_train_max": 0.0008425712585449219, "timer/agent.train_count": 2188.0, "timer/agent.train_total": 970.2926142215729, "timer/agent.train_frac": 0.9702065397297639, "timer/agent.train_avg": 0.44346097542119417, "timer/agent.train_min": 0.4321630001068115, "timer/agent.train_max": 0.6146664619445801, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47425413131713867, "timer/agent.report_frac": 0.0004742120603142854, "timer/agent.report_avg": 0.23712706565856934, "timer/agent.report_min": 0.23100638389587402, "timer/agent.report_max": 0.24324774742126465, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0040740966796875e-05, "timer/dataset_eval_frac": 3.0038076057805113e-08, "timer/dataset_eval_avg": 3.0040740966796875e-05, "timer/dataset_eval_min": 3.0040740966796875e-05, "timer/dataset_eval_max": 3.0040740966796875e-05, "fps": 8.751091342022333}
{"step": 262912, "time": 30249.89763021469, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 263376, "time": 30302.454127788544, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 263536, "time": 30320.63178372383, "episode/length": 256.0, "episode/score": 0.20000000298023224, "episode/reward_rate": 0.0038910505836575876, "episode/intrinsic_return": 0.0}
{"step": 263608, "time": 30328.76069188118, "episode/length": 266.0, "episode/score": 0.16875000298023224, "episode/reward_rate": 0.003745318352059925, "episode/intrinsic_return": 0.0}
{"step": 263616, "time": 30329.666724205017, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 264064, "time": 30380.33447623253, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 264320, "time": 30409.33549284935, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 264984, "time": 30484.337982177734, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 265224, "time": 30511.555603981018, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 265688, "time": 30564.04762816429, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 265848, "time": 30582.192795991898, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 265920, "time": 30590.338170528412, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 265928, "time": 30591.249568462372, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 266376, "time": 30642.000944375992, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 266632, "time": 30670.87980723381, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 267296, "time": 30746.009707450867, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 267424, "time": 30760.446202516556, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.0}
{"step": 267536, "time": 30773.135353565216, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 268000, "time": 30825.57870411873, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 268232, "time": 30851.795374393463, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 268240, "time": 30852.719031572342, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 268688, "time": 30903.318820238113, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 268944, "time": 30932.24229335785, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 269392, "time": 30982.94475221634, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 269608, "time": 31007.34157562256, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 269736, "time": 31021.786087989807, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 269848, "time": 31034.501984119415, "episode/length": 230.0, "episode/score": 0.28125, "episode/reward_rate": 0.004329004329004329, "episode/intrinsic_return": 0.0}
{"step": 269848, "time": 31034.509137630463, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 270088, "time": 31062.50845503807, "eval_episode/length": 47.0, "eval_episode/score": 0.8531249761581421, "eval_episode/reward_rate": 0.020833333333333332}
{"step": 270088, "time": 31062.811826467514, "eval_episode/length": 65.0, "eval_episode/score": 0.796875, "eval_episode/reward_rate": 0.015151515151515152}
{"step": 270088, "time": 31066.23744535446, "eval_episode/length": 165.0, "eval_episode/score": 0.484375, "eval_episode/reward_rate": 0.006024096385542169}
{"step": 270088, "time": 31067.204872131348, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 31067.211139440536, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 31067.21691441536, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 31067.222729444504, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 31067.22839999199, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 31067.234265327454, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270528, "time": 31117.29793357849, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 270552, "time": 31119.99802851677, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 270648, "time": 31130.935433149338, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 270752, "time": 31142.635959863663, "episode/length": 225.0, "episode/score": 0.296875, "episode/reward_rate": 0.004424778761061947, "episode/intrinsic_return": 0.0}
{"step": 271000, "time": 31170.70863056183, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 271597, "time": 31239.085028648376, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.594751808860085, "train/action_min": 0.0, "train/action_std": 2.1935675897381524, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0056501968583854085, "train/actor_opt_grad_steps": 66415.0, "train/actor_opt_loss": -9.839011073112488, "train/adv_mag": 0.44222284880551427, "train/adv_max": 0.1726951309225776, "train/adv_mean": 0.00035020026626749644, "train/adv_min": -0.4161283108321103, "train/adv_std": 0.015913302699019284, "train/cont_avg": 0.9961825284090909, "train/cont_loss_mean": 0.009816679253179411, "train/cont_loss_std": 0.1688845950432799, "train/cont_neg_acc": 0.5063418987709256, "train/cont_neg_loss": 2.0781012738987696, "train/cont_pos_acc": 0.9999197753992948, "train/cont_pos_loss": 0.0020274912200296635, "train/cont_pred": 0.9961003170772033, "train/cont_rate": 0.9961825284090909, "train/dyn_loss_mean": 1.0000002844767137, "train/dyn_loss_std": 9.08440587491813e-06, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.08974579803814942, "train/extr_critic_critic_opt_grad_steps": 66415.0, "train/extr_critic_critic_opt_loss": 9548.534301757812, "train/extr_critic_mag": 0.6573531595143405, "train/extr_critic_max": 0.6573531595143405, "train/extr_critic_mean": 0.5542347520589829, "train/extr_critic_min": 0.47501916668631816, "train/extr_critic_std": 0.018721675656905228, "train/extr_return_normed_mag": 0.45206899344921114, "train/extr_return_normed_max": 0.23359853381460363, "train/extr_return_normed_mean": 0.02890910659916699, "train/extr_return_normed_min": -0.3989626891233704, "train/extr_return_normed_std": 0.025062225018204612, "train/extr_return_rate": 0.9986979641697623, "train/extr_return_raw_mag": 0.7592743935910138, "train/extr_return_raw_max": 0.7592743935910138, "train/extr_return_raw_mean": 0.5545849927447059, "train/extr_return_raw_min": 0.12671317065303975, "train/extr_return_raw_std": 0.025062224997038193, "train/extr_reward_mag": 0.31003558744083753, "train/extr_reward_max": 0.31003558744083753, "train/extr_reward_mean": 0.0003557173612286781, "train/extr_reward_min": -2.3516741665926846e-07, "train/extr_reward_std": 0.00587595956034916, "train/image_loss_mean": 0.07233227935026992, "train/image_loss_std": 0.0980010279708288, "train/model_loss_mean": 0.6847432708198374, "train/model_loss_std": 0.25122191018678924, "train/model_opt_grad_norm": 16.89062779570279, "train/model_opt_grad_steps": 66356.65909090909, "train/model_opt_loss": 3515.8113547585226, "train/model_opt_model_opt_grad_overflow": 0.004545454545454545, "train/model_opt_model_opt_grad_scale": 5113.636363636364, "train/policy_entropy_mag": 1.499051375280727, "train/policy_entropy_max": 1.499051375280727, "train/policy_entropy_mean": 0.10998217185789888, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.1493865362961184, "train/policy_logprob_mag": 6.551080239902843, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.11016456654125995, "train/policy_logprob_min": -6.551080239902843, "train/policy_logprob_std": 0.6499742207202044, "train/policy_randomness_mag": 0.7703600628809495, "train/policy_randomness_max": 0.7703600628809495, "train/policy_randomness_mean": 0.05651965881274505, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.07676949722861702, "train/post_ent_mag": 41.69969289953058, "train/post_ent_max": 41.69969289953058, "train/post_ent_mean": 40.55640059384433, "train/post_ent_min": 39.66674128445712, "train/post_ent_std": 0.43649196231907067, "train/prior_ent_mag": 41.9513033433394, "train/prior_ent_max": 41.9513033433394, "train/prior_ent_mean": 40.548702881552956, "train/prior_ent_min": 39.16513047651811, "train/prior_ent_std": 0.4268605282360857, "train/rep_loss_mean": 1.0000002844767137, "train/rep_loss_std": 9.08440587491813e-06, "train/reward_avg": 0.00036138361382737376, "train/reward_loss_mean": 0.002594120824571953, "train/reward_loss_std": 0.06292085522224873, "train/reward_max_data": 0.2849573859098283, "train/reward_max_pred": 0.16493289362300526, "train/reward_neg_acc": 0.9997868529774926, "train/reward_neg_loss": 0.0004959919074529104, "train/reward_pos_acc": 0.36556603801700305, "train/reward_pos_loss": 3.2075201492264585, "train/reward_pred": 0.00033421477895568717, "train/reward_rate": 0.0006569602272727273, "train_stats/mean_log_entropy": 0.09461897250377771, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.003901103511452675, "report/cont_loss_std": 0.0919804647564888, "report/cont_neg_acc": 0.75, "report/cont_neg_loss": 0.7398840188980103, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0010148966684937477, "report/cont_pred": 0.9960329532623291, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.0780915692448616, "report/image_loss_std": 0.10860016196966171, "report/model_loss_mean": 0.6858664751052856, "report/model_loss_std": 0.24617546796798706, "report/post_ent_mag": 42.34343338012695, "report/post_ent_max": 42.34343338012695, "report/post_ent_mean": 41.19373321533203, "report/post_ent_min": 40.34621810913086, "report/post_ent_std": 0.448265016078949, "report/prior_ent_mag": 42.371063232421875, "report/prior_ent_max": 42.371063232421875, "report/prior_ent_mean": 40.96710968017578, "report/prior_ent_min": 39.86289596557617, "report/prior_ent_std": 0.44168007373809814, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0007202148553915322, "report/reward_loss_mean": 0.003873735200613737, "report/reward_loss_std": 0.12057437747716904, "report/reward_max_data": 0.737500011920929, "report/reward_max_pred": 0.026509404182434082, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00010409313108539209, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 3.860217571258545, "report/reward_pred": 6.81558158248663e-05, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.05057479441165924, "eval/cont_loss_std": 0.7234753966331482, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 10.165351867675781, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0009438981651328504, "eval/cont_pred": 0.999065637588501, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2014668583869934, "eval/image_loss_std": 0.1686847060918808, "eval/model_loss_mean": 0.852220892906189, "eval/model_loss_std": 0.7441964745521545, "eval/post_ent_mag": 42.325035095214844, "eval/post_ent_max": 42.325035095214844, "eval/post_ent_mean": 41.18867492675781, "eval/post_ent_min": 40.32463836669922, "eval/post_ent_std": 0.4488508403301239, "eval/prior_ent_mag": 42.132659912109375, "eval/prior_ent_max": 42.132659912109375, "eval/prior_ent_mean": 40.91934585571289, "eval/prior_ent_min": 39.69001007080078, "eval/prior_ent_std": 0.4292931854724884, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00017921347171068192, "eval/reward_loss_std": 0.0018373954808339477, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.01580977439880371, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00017921347171068192, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 7.35113862901926e-05, "eval/reward_rate": 0.0, "replay/size": 271093.0, "replay/inserts": 8784.0, "replay/samples": 35136.0, "replay/insert_wait_avg": 1.5391895245550327e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.365549893544237e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 65792.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0633963614599102e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.897615432739258e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1271529197693, "timer/env.step_count": 1098.0, "timer/env.step_total": 10.676158905029297, "timer/env.step_frac": 0.010674801572841352, "timer/env.step_avg": 0.009723277691283512, "timer/env.step_min": 0.008657217025756836, "timer/env.step_max": 0.028076648712158203, "timer/replay._sample_count": 35136.0, "timer/replay._sample_total": 19.029174327850342, "timer/replay._sample_frac": 0.019026755020395764, "timer/replay._sample_avg": 0.0005415862456696933, "timer/replay._sample_min": 0.0003840923309326172, "timer/replay._sample_max": 0.024533987045288086, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1387.0, "timer/agent.policy_total": 14.336498975753784, "timer/agent.policy_frac": 0.014334676279810858, "timer/agent.policy_avg": 0.010336336680428106, "timer/agent.policy_min": 0.008699655532836914, "timer/agent.policy_max": 0.07613515853881836, "timer/dataset_train_count": 2196.0, "timer/dataset_train_total": 0.3852696418762207, "timer/dataset_train_frac": 0.0003852206599445533, "timer/dataset_train_avg": 0.00017544154912396207, "timer/dataset_train_min": 9.250640869140625e-05, "timer/dataset_train_max": 0.00081634521484375, "timer/agent.train_count": 2196.0, "timer/agent.train_total": 969.8118765354156, "timer/agent.train_frac": 0.9696885778014812, "timer/agent.train_avg": 0.4416265375844334, "timer/agent.train_min": 0.4308497905731201, "timer/agent.train_max": 0.5713543891906738, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4687352180480957, "timer/agent.report_frac": 0.00046867562457400644, "timer/agent.report_avg": 0.23436760902404785, "timer/agent.report_min": 0.2229630947113037, "timer/agent.report_max": 0.245772123336792, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 0.00010275840759277344, "timer/dataset_eval_frac": 1.0274534322239001e-07, "timer/dataset_eval_avg": 0.00010275840759277344, "timer/dataset_eval_min": 0.00010275840759277344, "timer/dataset_eval_max": 0.00010275840759277344, "fps": 8.782746784077332}
{"step": 271704, "time": 31251.149594783783, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 271920, "time": 31275.78795337677, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 272160, "time": 31303.102078437805, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 272840, "time": 31380.59205365181, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 272864, "time": 31383.31461954117, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 272960, "time": 31394.30846810341, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 273064, "time": 31406.052550792694, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 273312, "time": 31434.185155391693, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 273720, "time": 31480.384969711304, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 274016, "time": 31514.155683517456, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 274104, "time": 31524.15908932686, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 274232, "time": 31538.74152159691, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 274472, "time": 31566.04633164406, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 274576, "time": 31577.909049272537, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 275152, "time": 31643.580862283707, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 275176, "time": 31646.31576681137, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 275272, "time": 31657.2383787632, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 275624, "time": 31697.339717149734, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 276328, "time": 31777.038383483887, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 276544, "time": 31801.721680402756, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 276784, "time": 31829.116541862488, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 276888, "time": 31840.94940638542, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 277464, "time": 31906.463570594788, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 277488, "time": 31909.195032596588, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 277584, "time": 31920.03378343582, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 277912, "time": 31957.25508093834, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 277936, "time": 31959.997908353806, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 278064, "time": 31974.606516599655, "episode/length": 216.0, "episode/score": 0.32499998807907104, "episode/reward_rate": 0.004608294930875576, "episode/intrinsic_return": 0.0}
{"step": 278576, "time": 32033.016032218933, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 278864, "time": 32065.80996656418, "episode/length": 246.0, "episode/score": 0.23125000298023224, "episode/reward_rate": 0.004048582995951417, "episode/intrinsic_return": 0.0}
{"step": 279096, "time": 32092.29891061783, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 279136, "time": 32096.87892627716, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 279776, "time": 32169.77928185463, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 279800, "time": 32172.622718334198, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 279896, "time": 32183.54578614235, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 280072, "time": 32204.03686761856, "eval_episode/length": 22.0, "eval_episode/score": 0.9312499761581421, "eval_episode/reward_rate": 0.043478260869565216}
{"step": 280072, "time": 32204.461408376694, "eval_episode/length": 47.0, "eval_episode/score": 0.8531249761581421, "eval_episode/reward_rate": 0.020833333333333332}
{"step": 280072, "time": 32205.23724412918, "eval_episode/length": 93.0, "eval_episode/score": 0.7093750238418579, "eval_episode/reward_rate": 0.010638297872340425}
{"step": 280072, "time": 32206.9814991951, "eval_episode/length": 195.0, "eval_episode/score": 0.390625, "eval_episode/reward_rate": 0.00510204081632653}
{"step": 280072, "time": 32207.75248003006, "eval_episode/length": 146.0, "eval_episode/score": 0.543749988079071, "eval_episode/reward_rate": 0.006802721088435374}
{"step": 280072, "time": 32207.958831071854, "eval_episode/length": 11.0, "eval_episode/score": 0.965624988079071, "eval_episode/reward_rate": 0.08333333333333333}
{"step": 280072, "time": 32208.099724769592, "eval_episode/length": 237.0, "eval_episode/score": 0.2593750059604645, "eval_episode/reward_rate": 0.004201680672268907}
{"step": 280072, "time": 32208.54307794571, "eval_episode/length": 286.0, "eval_episode/score": 0.10625000298023224, "eval_episode/reward_rate": 0.003484320557491289}
{"step": 280160, "time": 32218.577494859695, "episode/length": 280.0, "episode/score": 0.125, "episode/reward_rate": 0.0035587188612099642, "episode/intrinsic_return": 0.0}
{"step": 280333, "time": 32239.180420398712, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.710945339377867, "train/action_min": 0.0, "train/action_std": 2.1079255189370674, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.004716363846572167, "train/actor_opt_grad_steps": 68605.0, "train/actor_opt_loss": -10.496964373719802, "train/adv_mag": 0.35819332998826964, "train/adv_max": 0.16891612057838964, "train/adv_mean": -0.0017739577605333655, "train/adv_min": -0.3340091736765083, "train/adv_std": 0.01360822844301957, "train/cont_avg": 0.9961743836009175, "train/cont_loss_mean": 0.010349475960204498, "train/cont_loss_std": 0.17698111318675544, "train/cont_neg_acc": 0.4758511417519266, "train/cont_neg_loss": 2.1646765254946017, "train/cont_pos_acc": 0.9998605390754315, "train/cont_pos_loss": 0.002043722276981715, "train/cont_pred": 0.9962845879410385, "train/cont_rate": 0.9961743836009175, "train/dyn_loss_mean": 1.0000010723367743, "train/dyn_loss_std": 3.429274117454476e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.09372736399121788, "train/extr_critic_critic_opt_grad_steps": 68605.0, "train/extr_critic_critic_opt_loss": 12476.440286338877, "train/extr_critic_mag": 0.6444573790655224, "train/extr_critic_max": 0.6444573790655224, "train/extr_critic_mean": 0.5048432515575252, "train/extr_critic_min": 0.4315905915487797, "train/extr_critic_std": 0.017695783205979733, "train/extr_return_normed_mag": 0.37723392111445786, "train/extr_return_normed_max": 0.2335142821346948, "train/extr_return_normed_mean": 0.017396428472781125, "train/extr_return_normed_min": -0.30286499775877784, "train/extr_return_normed_std": 0.02306522325176848, "train/extr_return_rate": 0.516014157444102, "train/extr_return_raw_mag": 0.7191871946011115, "train/extr_return_raw_max": 0.7191871946011115, "train/extr_return_raw_mean": 0.5030693659268388, "train/extr_return_raw_min": 0.1828079148443467, "train/extr_return_raw_std": 0.023065223345755163, "train/extr_reward_mag": 0.32836437280024955, "train/extr_reward_max": 0.32836437280024955, "train/extr_reward_mean": 0.00044982900039064314, "train/extr_reward_min": 1.3123958482654817e-08, "train/extr_reward_std": 0.006677242899484454, "train/image_loss_mean": 0.0708582826949861, "train/image_loss_std": 0.09644968535990343, "train/model_loss_mean": 0.6841951130180184, "train/model_loss_std": 0.26377891082692584, "train/model_opt_grad_norm": 16.684678357675534, "train/model_opt_grad_steps": 68544.4862385321, "train/model_opt_loss": 3530.863498512758, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5160.5504587155965, "train/policy_entropy_mag": 1.4680633714439673, "train/policy_entropy_max": 1.4680633714439673, "train/policy_entropy_mean": 0.11827626581722443, "train/policy_entropy_min": 0.06468649232469567, "train/policy_entropy_std": 0.1574225246291095, "train/policy_logprob_mag": 6.5510802487714574, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.11832633679476354, "train/policy_logprob_min": -6.5510802487714574, "train/policy_logprob_std": 0.6572102896117289, "train/policy_randomness_mag": 0.7544353779302825, "train/policy_randomness_max": 0.7544353779302825, "train/policy_randomness_mean": 0.06078198025806235, "train/policy_randomness_min": 0.033242281645946545, "train/policy_randomness_std": 0.08089917961405504, "train/post_ent_mag": 41.539160317237226, "train/post_ent_max": 41.539160317237226, "train/post_ent_mean": 40.387399813450806, "train/post_ent_min": 39.466803856945916, "train/post_ent_std": 0.43945487827882856, "train/prior_ent_mag": 41.975145794929716, "train/prior_ent_max": 41.975145794929716, "train/prior_ent_mean": 40.4601775353108, "train/prior_ent_min": 39.18058587870467, "train/prior_ent_std": 0.3902058338900225, "train/rep_loss_mean": 1.0000010723367743, "train/rep_loss_std": 3.429274117454476e-05, "train/reward_avg": 0.00041852478577954043, "train/reward_loss_mean": 0.002986688757744626, "train/reward_loss_std": 0.07037925420658996, "train/reward_max_data": 0.309776376146789, "train/reward_max_pred": 0.16486789381832156, "train/reward_neg_acc": 0.9998251082153495, "train/reward_neg_loss": 0.00048659548231233936, "train/reward_pos_acc": 0.4109195411719125, "train/reward_pos_loss": 3.278781499970576, "train/reward_pred": 0.00033731425369004593, "train/reward_rate": 0.0007615395642201835, "train_stats/mean_log_entropy": 0.09132327056593365, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.006532732397317886, "report/cont_loss_std": 0.11773736029863358, "report/cont_neg_acc": 0.6666666865348816, "report/cont_neg_loss": 1.2433701753616333, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0028985387180000544, "report/cont_pred": 0.9952784180641174, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07846954464912415, "report/image_loss_std": 0.10749799013137817, "report/model_loss_mean": 0.6854742765426636, "report/model_loss_std": 0.1655275970697403, "report/post_ent_mag": 42.31129837036133, "report/post_ent_max": 42.31129837036133, "report/post_ent_mean": 41.30693817138672, "report/post_ent_min": 40.470062255859375, "report/post_ent_std": 0.38589876890182495, "report/prior_ent_mag": 42.09053039550781, "report/prior_ent_max": 42.09053039550781, "report/prior_ent_mean": 40.53206253051758, "report/prior_ent_min": 39.247474670410156, "report/prior_ent_std": 0.38561761379241943, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.00047196075320243835, "report/reward_loss_std": 0.0038964070845395327, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.038080453872680664, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00047196075320243835, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00020907504949718714, "report/reward_rate": 0.0, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.06699766963720322, "eval/cont_loss_std": 0.8613272309303284, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 12.046881675720215, "eval/cont_pos_acc": 0.999018669128418, "eval/cont_pos_loss": 0.008215119130909443, "eval/cont_pred": 0.9970462322235107, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.19699923694133759, "eval/image_loss_std": 0.13681383430957794, "eval/model_loss_mean": 0.8641514778137207, "eval/model_loss_std": 0.8749842643737793, "eval/post_ent_mag": 42.395084381103516, "eval/post_ent_max": 42.395084381103516, "eval/post_ent_mean": 41.22319030761719, "eval/post_ent_min": 40.29340362548828, "eval/post_ent_std": 0.42875081300735474, "eval/prior_ent_mag": 42.551910400390625, "eval/prior_ent_max": 42.551910400390625, "eval/prior_ent_mean": 40.4917106628418, "eval/prior_ent_min": 39.367431640625, "eval/prior_ent_std": 0.40284374356269836, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0001545366831123829, "eval/reward_loss_std": 0.0015220044879242778, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.02005910873413086, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0001545366831123829, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 6.814044900238514e-05, "eval/reward_rate": 0.0, "replay/size": 279829.0, "replay/inserts": 8736.0, "replay/samples": 34944.0, "replay/insert_wait_avg": 1.5376306278801663e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.336297423848302e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 68088.0, "eval_replay/inserts": 2296.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0456773046832467e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.791685104370117e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0814340114594, "timer/env.step_count": 1092.0, "timer/env.step_total": 10.737452507019043, "timer/env.step_frac": 0.010736578184388142, "timer/env.step_avg": 0.009832831966134655, "timer/env.step_min": 0.008543729782104492, "timer/env.step_max": 0.035002708435058594, "timer/replay._sample_count": 34944.0, "timer/replay._sample_total": 18.816826343536377, "timer/replay._sample_frac": 0.01881529413865788, "timer/replay._sample_avg": 0.000538485186113106, "timer/replay._sample_min": 0.00037860870361328125, "timer/replay._sample_max": 0.03551483154296875, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1379.0, "timer/agent.policy_total": 13.886488199234009, "timer/agent.policy_frac": 0.013885357458875586, "timer/agent.policy_avg": 0.010069969687624372, "timer/agent.policy_min": 0.008687734603881836, "timer/agent.policy_max": 0.03670072555541992, "timer/dataset_train_count": 2184.0, "timer/dataset_train_total": 0.431779146194458, "timer/dataset_train_frac": 0.0004317439875496284, "timer/dataset_train_avg": 0.00019770107426486173, "timer/dataset_train_min": 9.489059448242188e-05, "timer/dataset_train_max": 0.046404361724853516, "timer/agent.train_count": 2184.0, "timer/agent.train_total": 970.2843809127808, "timer/agent.train_frac": 0.9702053731973019, "timer/agent.train_avg": 0.44426940517984465, "timer/agent.train_min": 0.4267115592956543, "timer/agent.train_max": 0.5789332389831543, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47666192054748535, "timer/agent.report_frac": 0.00047662310721591054, "timer/agent.report_avg": 0.23833096027374268, "timer/agent.report_min": 0.23169422149658203, "timer/agent.report_max": 0.24496769905090332, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7894973754882812e-05, "timer/dataset_eval_frac": 2.7892702340240805e-08, "timer/dataset_eval_avg": 2.7894973754882812e-05, "timer/dataset_eval_min": 2.7894973754882812e-05, "timer/dataset_eval_max": 2.7894973754882812e-05, "fps": 8.73515348252521}
{"step": 280376, "time": 32243.894207954407, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 280424, "time": 32249.29749894142, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 280888, "time": 32302.146410226822, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 281128, "time": 32329.45459675789, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 281408, "time": 32361.317589759827, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 281448, "time": 32365.82854270935, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 281864, "time": 32413.237053394318, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 282088, "time": 32438.732477664948, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 282112, "time": 32441.48652768135, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 282384, "time": 32472.378938674927, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 282472, "time": 32482.417870283127, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 282736, "time": 32512.538521528244, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 283024, "time": 32545.359957695007, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 283040, "time": 32547.19171690941, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 283200, "time": 32565.48530101776, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 283400, "time": 32588.128420829773, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 283440, "time": 32592.755491495132, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 283480, "time": 32597.306082248688, "episode/length": 258.0, "episode/score": 0.19374999403953552, "episode/reward_rate": 0.003861003861003861, "episode/intrinsic_return": 0.0}
{"step": 283784, "time": 32631.90661263466, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 283824, "time": 32636.464334011078, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 284536, "time": 32717.650948047638, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 284696, "time": 32735.76074743271, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 284912, "time": 32760.35723590851, "episode/length": 233.0, "episode/score": 0.2718749940395355, "episode/reward_rate": 0.004273504273504274, "episode/intrinsic_return": 0.0}
{"step": 285048, "time": 32775.919557094574, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 285232, "time": 32796.8054959774, "episode/length": 228.0, "episode/score": 0.2874999940395355, "episode/reward_rate": 0.004366812227074236, "episode/intrinsic_return": 0.0}
{"step": 285792, "time": 32860.407733917236, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 285896, "time": 32872.29359102249, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 286096, "time": 32895.035620212555, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 286136, "time": 32899.58542728424, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 286160, "time": 32902.33165717125, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 286248, "time": 32912.2832775116, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 286272, "time": 32915.00685286522, "episode/length": 216.0, "episode/score": 0.32499998807907104, "episode/reward_rate": 0.004608294930875576, "episode/intrinsic_return": 0.0}
{"step": 286312, "time": 32919.55567288399, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 286552, "time": 32946.79288935661, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 286696, "time": 32963.109865903854, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 286848, "time": 32980.70964741707, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 287224, "time": 33023.72235369682, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 287360, "time": 33039.153141498566, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 288448, "time": 33163.13839030266, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 288560, "time": 33175.825095653534, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 288584, "time": 33178.54229736328, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 288864, "time": 33210.42458367348, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 288968, "time": 33222.34083366394, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 289008, "time": 33226.87577486038, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 289109, "time": 33239.20422911644, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.61164723574843, "train/action_min": 0.0, "train/action_std": 1.9244637113727936, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00943085922408832, "train/actor_opt_grad_steps": 70790.0, "train/actor_opt_loss": -18.235785509897692, "train/adv_mag": 0.47721399890777727, "train/adv_max": 0.29679549556888946, "train/adv_mean": 0.005932412792429549, "train/adv_min": -0.42521958427342105, "train/adv_std": 0.03183255046946273, "train/cont_avg": 0.9962275256849316, "train/cont_loss_mean": 0.009915874424160854, "train/cont_loss_std": 0.1733206242671636, "train/cont_neg_acc": 0.5004650102159299, "train/cont_neg_loss": 2.022243953947701, "train/cont_pos_acc": 0.9999239637971469, "train/cont_pos_loss": 0.0019542850101085967, "train/cont_pred": 0.9962751233958762, "train/cont_rate": 0.9962275256849316, "train/dyn_loss_mean": 1.0000450420597373, "train/dyn_loss_std": 0.0004127465434889118, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.2800126231305267, "train/extr_critic_critic_opt_grad_steps": 70790.0, "train/extr_critic_critic_opt_loss": 11421.731416327768, "train/extr_critic_mag": 0.7872783228686956, "train/extr_critic_max": 0.7872783228686956, "train/extr_critic_mean": 0.5539726612230415, "train/extr_critic_min": 0.4395199654853507, "train/extr_critic_std": 0.060463987750141585, "train/extr_return_normed_mag": 0.5634265431802566, "train/extr_return_normed_max": 0.47881609623290633, "train/extr_return_normed_mean": 0.07258511445225646, "train/extr_return_normed_min": -0.34288571046911964, "train/extr_return_normed_std": 0.07153063918969947, "train/extr_return_rate": 0.7070966866462742, "train/extr_return_raw_mag": 0.9661360875656616, "train/extr_return_raw_max": 0.9661360875656616, "train/extr_return_raw_mean": 0.5599051322022529, "train/extr_return_raw_min": 0.14443427950279897, "train/extr_return_raw_std": 0.07153063920670993, "train/extr_reward_mag": 0.42557641088146053, "train/extr_reward_max": 0.42557641088146053, "train/extr_reward_mean": 0.0007843469568851434, "train/extr_reward_min": 0.0, "train/extr_reward_std": 0.011281792603892414, "train/image_loss_mean": 0.07206640387438748, "train/image_loss_std": 0.09758246183123219, "train/model_loss_mean": 0.6850707490150243, "train/model_loss_std": 0.2632988916888629, "train/model_opt_grad_norm": 16.214927100699786, "train/model_opt_grad_steps": 70727.45205479451, "train/model_opt_loss": 3767.668200627854, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5502.2831050228315, "train/policy_entropy_mag": 1.4344122257406853, "train/policy_entropy_max": 1.4344122257406853, "train/policy_entropy_mean": 0.11824320733002876, "train/policy_entropy_min": 0.06468649225556143, "train/policy_entropy_std": 0.1575033063553784, "train/policy_logprob_mag": 6.5510802443169025, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.11843980532394696, "train/policy_logprob_min": -6.5510802443169025, "train/policy_logprob_std": 0.6586252630573429, "train/policy_randomness_mag": 0.7371421086189409, "train/policy_randomness_max": 0.7371421086189409, "train/policy_randomness_mean": 0.060764991580487385, "train/policy_randomness_min": 0.033242281611379425, "train/policy_randomness_std": 0.08094069324263699, "train/post_ent_mag": 37.75244736344847, "train/post_ent_max": 37.75244736344847, "train/post_ent_mean": 36.60922788158399, "train/post_ent_min": 35.708731699207604, "train/post_ent_std": 0.4245601497828688, "train/prior_ent_mag": 38.01066685158368, "train/prior_ent_max": 38.01066685158368, "train/prior_ent_mean": 36.4054186050206, "train/prior_ent_min": 34.98717991728761, "train/prior_ent_std": 0.432129474263213, "train/rep_loss_mean": 1.0000450420597373, "train/rep_loss_std": 0.0004127465434889118, "train/reward_avg": 0.00040628790548953683, "train/reward_loss_mean": 0.003061419390896803, "train/reward_loss_std": 0.07468238458904909, "train/reward_max_data": 0.33344748867973345, "train/reward_max_pred": 0.1270795554330904, "train/reward_neg_acc": 0.999852750127174, "train/reward_neg_loss": 0.00048716320984089985, "train/reward_pos_acc": 0.33984375, "train/reward_pos_loss": 3.3917350927367806, "train/reward_pred": 0.00031180769581449765, "train/reward_rate": 0.0007669805936073059, "train_stats/mean_log_entropy": 0.10086366000839254, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.015674354508519173, "report/cont_loss_std": 0.2474941462278366, "report/cont_neg_acc": 0.5714285969734192, "report/cont_neg_loss": 1.930061936378479, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0024976450949907303, "report/cont_pred": 0.993605375289917, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.060833871364593506, "report/image_loss_std": 0.10019443929195404, "report/model_loss_mean": 0.6812735795974731, "report/model_loss_std": 0.35904672741889954, "report/post_ent_mag": 38.308815002441406, "report/post_ent_max": 38.308815002441406, "report/post_ent_mean": 37.14716720581055, "report/post_ent_min": 36.2223014831543, "report/post_ent_std": 0.4876936972141266, "report/prior_ent_mag": 37.84197235107422, "report/prior_ent_max": 37.84197235107422, "report/prior_ent_mean": 36.387176513671875, "report/prior_ent_min": 35.17820358276367, "report/prior_ent_std": 0.42395660281181335, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0001312255917582661, "report/reward_loss_mean": 0.004765287972986698, "report/reward_loss_std": 0.13429541885852814, "report/reward_max_data": 0.13437500596046448, "report/reward_max_pred": 0.03360724449157715, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0005692100385203958, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.297353267669678, "report/reward_pred": 0.00022299448028206825, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.028963517397642136, "eval/cont_loss_std": 0.3918887972831726, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.467430114746094, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0022782068699598312, "eval/cont_pred": 0.9977205991744995, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.12943483889102936, "eval/image_loss_std": 0.13075384497642517, "eval/model_loss_mean": 0.7817951440811157, "eval/model_loss_std": 0.7797532081604004, "eval/post_ent_mag": 38.26191329956055, "eval/post_ent_max": 38.26191329956055, "eval/post_ent_mean": 37.19736862182617, "eval/post_ent_min": 36.20444869995117, "eval/post_ent_std": 0.4645104706287384, "eval/prior_ent_mag": 38.8331184387207, "eval/prior_ent_max": 38.8331184387207, "eval/prior_ent_mean": 36.445335388183594, "eval/prior_ent_min": 35.185935974121094, "eval/prior_ent_std": 0.44657135009765625, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0023712157271802425, "eval/reward_loss_mean": 0.023396743461489677, "eval/reward_loss_std": 0.4328080713748932, "eval/reward_max_data": 0.9125000238418579, "eval/reward_max_pred": 0.022833943367004395, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0004325181362219155, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 7.838889122009277, "eval/reward_pred": 0.00018827919848263264, "eval/reward_rate": 0.0029296875, "replay/size": 288605.0, "replay/inserts": 8776.0, "replay/samples": 35104.0, "replay/insert_wait_avg": 1.5761815317131328e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.40561902577375e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 68088.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0058360099792, "timer/env.step_count": 1097.0, "timer/env.step_total": 10.876841306686401, "timer/env.step_frac": 0.010876777829702445, "timer/env.step_avg": 0.009915078675192708, "timer/env.step_min": 0.008635997772216797, "timer/env.step_max": 0.035396575927734375, "timer/replay._sample_count": 35104.0, "timer/replay._sample_total": 18.920044422149658, "timer/replay._sample_frac": 0.018919934005225996, "timer/replay._sample_avg": 0.0005389711834021667, "timer/replay._sample_min": 0.00038051605224609375, "timer/replay._sample_max": 0.0253598690032959, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1097.0, "timer/agent.policy_total": 11.21688985824585, "timer/agent.policy_frac": 0.011216824396746735, "timer/agent.policy_avg": 0.010225059123287009, "timer/agent.policy_min": 0.009326457977294922, "timer/agent.policy_max": 0.02630472183227539, "timer/dataset_train_count": 2194.0, "timer/dataset_train_total": 0.39048171043395996, "timer/dataset_train_frac": 0.0003904794315921005, "timer/dataset_train_avg": 0.0001779770785934184, "timer/dataset_train_min": 9.512901306152344e-05, "timer/dataset_train_max": 0.001074075698852539, "timer/agent.train_count": 2194.0, "timer/agent.train_total": 975.0248048305511, "timer/agent.train_frac": 0.9750191146092684, "timer/agent.train_avg": 0.44440510703306796, "timer/agent.train_min": 0.4327583312988281, "timer/agent.train_max": 0.5885694026947021, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4715762138366699, "timer/agent.report_frac": 0.0004715734617292413, "timer/agent.report_avg": 0.23578810691833496, "timer/agent.report_min": 0.22948002815246582, "timer/agent.report_max": 0.2420961856842041, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9087066650390625e-05, "timer/dataset_eval_frac": 2.9086896898970057e-08, "timer/dataset_eval_avg": 2.9087066650390625e-05, "timer/dataset_eval_min": 2.9087066650390625e-05, "timer/dataset_eval_max": 2.9087066650390625e-05, "fps": 8.775827400313876}
{"step": 289160, "time": 33244.84500312805, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 289536, "time": 33287.73350977898, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 290056, "time": 33347.610756874084, "eval_episode/length": 38.0, "eval_episode/score": 0.8812500238418579, "eval_episode/reward_rate": 0.02564102564102564}
{"step": 290056, "time": 33351.8485057354, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "time": 33351.85663938522, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "time": 33351.862498521805, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "time": 33351.867906332016, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "time": 33351.8732213974, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "time": 33351.878578186035, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "time": 33351.88407611847, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290760, "time": 33432.32670903206, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 290872, "time": 33445.06923246384, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 290896, "time": 33447.8087990284, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 291176, "time": 33479.81199979782, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 291280, "time": 33491.755299568176, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 291320, "time": 33496.29438996315, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 291472, "time": 33513.502068042755, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 291560, "time": 33523.62394452095, "episode/length": 252.0, "episode/score": 0.21250000596046448, "episode/reward_rate": 0.003952569169960474, "episode/intrinsic_return": 0.0}
{"step": 292640, "time": 33646.86841106415, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 292944, "time": 33681.496621608734, "episode/length": 255.0, "episode/score": 0.203125, "episode/reward_rate": 0.00390625, "episode/intrinsic_return": 0.0}
{"step": 293072, "time": 33696.0630800724, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 293184, "time": 33708.87207198143, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 293488, "time": 33743.50962495804, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 293592, "time": 33755.26475358009, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 293632, "time": 33759.80104351044, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 293784, "time": 33777.192118644714, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 294424, "time": 33849.950659036636, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 294952, "time": 33910.447367191315, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 295256, "time": 33945.115888118744, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 295384, "time": 33959.71266388893, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 295448, "time": 33966.99574923515, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 295496, "time": 33972.62089180946, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 295800, "time": 34007.30484390259, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 295904, "time": 34019.11505937576, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 296096, "time": 34041.013748407364, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 296736, "time": 34113.86727690697, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 296984, "time": 34142.109635829926, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 297320, "time": 34180.39367437363, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 297568, "time": 34208.63508558273, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 297696, "time": 34223.211462020874, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 297760, "time": 34230.50671982765, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 297808, "time": 34235.98318147659, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 297829, "time": 34239.24175405502, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.7089628167108657, "train/action_min": 0.0, "train/action_std": 2.085889966116039, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.007624991059756128, "train/actor_opt_grad_steps": 72975.0, "train/actor_opt_loss": -16.82000737890191, "train/adv_mag": 0.4901763296455418, "train/adv_max": 0.1892028385346089, "train/adv_mean": -0.0024090963589606797, "train/adv_min": -0.464549660956094, "train/adv_std": 0.01982444165906775, "train/cont_avg": 0.9962147004013762, "train/cont_loss_mean": 0.010026963369989204, "train/cont_loss_std": 0.17284733890085865, "train/cont_neg_acc": 0.47252448439319555, "train/cont_neg_loss": 2.140741683387893, "train/cont_pos_acc": 0.9998830977929841, "train/cont_pos_loss": 0.0020838503569894293, "train/cont_pred": 0.9961894988466841, "train/cont_rate": 0.9962147004013762, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.11999140940008497, "train/extr_critic_critic_opt_grad_steps": 72975.0, "train/extr_critic_critic_opt_loss": 8435.984261888976, "train/extr_critic_mag": 0.8428564044313693, "train/extr_critic_max": 0.8428564044313693, "train/extr_critic_mean": 0.6598755632518628, "train/extr_critic_min": 0.5206833066196617, "train/extr_critic_std": 0.037074337606617346, "train/extr_return_normed_mag": 0.5085116564680677, "train/extr_return_normed_max": 0.2813386933519206, "train/extr_return_normed_mean": 0.041638482021563845, "train/extr_return_normed_min": -0.4423587199197997, "train/extr_return_normed_std": 0.040728807872280885, "train/extr_return_rate": 0.9994499429103432, "train/extr_return_raw_mag": 0.8971666556979538, "train/extr_return_raw_max": 0.8971666556979538, "train/extr_return_raw_mean": 0.6574664763901212, "train/extr_return_raw_min": 0.17346924269964936, "train/extr_return_raw_std": 0.040728807859464526, "train/extr_reward_mag": 0.271262365196823, "train/extr_reward_max": 0.271262365196823, "train/extr_reward_mean": 0.000335661634213933, "train/extr_reward_min": -1.4038807755216545e-05, "train/extr_reward_std": 0.0050756948134421855, "train/image_loss_mean": 0.06947103381977168, "train/image_loss_std": 0.09597016566800415, "train/model_loss_mean": 0.6825128771843166, "train/model_loss_std": 0.2600152528067248, "train/model_opt_grad_norm": 15.873646132442929, "train/model_opt_grad_steps": 72910.41284403669, "train/model_opt_loss": 3552.108056864607, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5206.422018348624, "train/policy_entropy_mag": 1.403178154875379, "train/policy_entropy_max": 1.403178154875379, "train/policy_entropy_mean": 0.12355178587753839, "train/policy_entropy_min": 0.06468649211963383, "train/policy_entropy_std": 0.16419699542019345, "train/policy_logprob_mag": 6.551080285956006, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.12376606402867431, "train/policy_logprob_min": -6.551080285956006, "train/policy_logprob_std": 0.662274610558781, "train/policy_randomness_mag": 0.7210909718767219, "train/policy_randomness_max": 0.7210909718767219, "train/policy_randomness_mean": 0.06349306157149306, "train/policy_randomness_min": 0.033242281543415624, "train/policy_randomness_std": 0.08438056881684776, "train/post_ent_mag": 39.08754049528629, "train/post_ent_max": 39.08754049528629, "train/post_ent_mean": 37.8430451209392, "train/post_ent_min": 36.86574722430028, "train/post_ent_std": 0.46339254928838225, "train/prior_ent_mag": 38.215057373046875, "train/prior_ent_max": 38.215057373046875, "train/prior_ent_mean": 36.38359976252285, "train/prior_ent_min": 35.186435052014275, "train/prior_ent_std": 0.4310844763429887, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0004382492183590705, "train/reward_loss_mean": 0.003014856806332502, "train/reward_loss_std": 0.07212937604518471, "train/reward_max_data": 0.3342889908598651, "train/reward_max_pred": 0.15186204877468423, "train/reward_neg_acc": 0.999865461106694, "train/reward_neg_loss": 0.0005375884865558014, "train/reward_pos_acc": 0.32971014613690586, "train/reward_pos_loss": 3.3798765573812566, "train/reward_pred": 0.00034520621977558513, "train/reward_rate": 0.0007570599197247707, "train_stats/mean_log_entropy": 0.10879732712226756, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.012988729402422905, "report/cont_loss_std": 0.22890815138816833, "report/cont_neg_acc": 0.5, "report/cont_neg_loss": 1.8206267356872559, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.002334674121811986, "report/cont_pred": 0.9942741990089417, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.09300298988819122, "report/image_loss_std": 0.10790485143661499, "report/model_loss_mean": 0.7065092325210571, "report/model_loss_std": 0.26202720403671265, "report/post_ent_mag": 39.19729995727539, "report/post_ent_max": 39.19729995727539, "report/post_ent_mean": 38.039039611816406, "report/post_ent_min": 36.56906509399414, "report/post_ent_std": 0.4826210141181946, "report/prior_ent_mag": 38.504676818847656, "report/prior_ent_max": 38.504676818847656, "report/prior_ent_mean": 36.80657196044922, "report/prior_ent_min": 35.79499816894531, "report/prior_ent_std": 0.3714618384838104, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.0005174693651497364, "report/reward_loss_std": 0.0036988432984799147, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.026758313179016113, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0005174693651497364, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00025725457817316055, "report/reward_rate": 0.0, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.04152589291334152, "eval/cont_loss_std": 0.6458534002304077, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 10.042848587036133, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.002305018249899149, "eval/cont_pred": 0.9977253079414368, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.15718528628349304, "eval/image_loss_std": 0.146121546626091, "eval/model_loss_mean": 0.7991197109222412, "eval/model_loss_std": 0.66571044921875, "eval/post_ent_mag": 39.21075439453125, "eval/post_ent_max": 39.21075439453125, "eval/post_ent_mean": 37.980926513671875, "eval/post_ent_min": 36.727783203125, "eval/post_ent_std": 0.5109724998474121, "eval/prior_ent_mag": 39.242671966552734, "eval/prior_ent_max": 39.242671966552734, "eval/prior_ent_mean": 36.78286361694336, "eval/prior_ent_min": 35.50720977783203, "eval/prior_ent_std": 0.3903046250343323, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0004084566608071327, "eval/reward_loss_std": 0.0032629831694066525, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.023099422454833984, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0004084566608071327, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0001961569068953395, "eval/reward_rate": 0.0, "replay/size": 297325.0, "replay/inserts": 8720.0, "replay/samples": 34880.0, "replay/insert_wait_avg": 1.5923462876486122e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.506904252078555e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 70400.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1162980617536394e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.791685104370117e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0250329971313, "timer/env.step_count": 1090.0, "timer/env.step_total": 10.810375690460205, "timer/env.step_frac": 0.010810105081130719, "timer/env.step_avg": 0.009917775862807527, "timer/env.step_min": 0.008795976638793945, "timer/env.step_max": 0.035376787185668945, "timer/replay._sample_count": 34880.0, "timer/replay._sample_total": 18.970500707626343, "timer/replay._sample_frac": 0.018970025831024133, "timer/replay._sample_avg": 0.0005438790340489204, "timer/replay._sample_min": 0.00038313865661621094, "timer/replay._sample_max": 0.021411418914794922, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1379.0, "timer/agent.policy_total": 13.935176372528076, "timer/agent.policy_frac": 0.01393482754203019, "timer/agent.policy_avg": 0.01010527655730825, "timer/agent.policy_min": 0.008729696273803711, "timer/agent.policy_max": 0.040879011154174805, "timer/dataset_train_count": 2180.0, "timer/dataset_train_total": 0.3875393867492676, "timer/dataset_train_frac": 0.00038752968571975665, "timer/dataset_train_avg": 0.00017777036089415945, "timer/dataset_train_min": 9.679794311523438e-05, "timer/dataset_train_max": 0.0007030963897705078, "timer/agent.train_count": 2180.0, "timer/agent.train_total": 970.1139152050018, "timer/agent.train_frac": 0.970089630954053, "timer/agent.train_avg": 0.4450063831215605, "timer/agent.train_min": 0.4340054988861084, "timer/agent.train_max": 0.5790431499481201, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4751729965209961, "timer/agent.report_frac": 0.00047516110181449747, "timer/agent.report_avg": 0.23758649826049805, "timer/agent.report_min": 0.22923660278320312, "timer/agent.report_max": 0.24593639373779297, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.218650817871094e-05, "timer/dataset_eval_frac": 3.218570247411323e-08, "timer/dataset_eval_avg": 3.218650817871094e-05, "timer/dataset_eval_min": 3.218650817871094e-05, "timer/dataset_eval_max": 3.218650817871094e-05, "fps": 8.71965662135987}
{"step": 298112, "time": 34271.36985325813, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 298216, "time": 34283.22751832008, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 298408, "time": 34305.13348484039, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 298992, "time": 34371.75145125389, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 299264, "time": 34402.7652964592, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 299280, "time": 34404.59467411041, "episode/length": 244.0, "episode/score": 0.23749999701976776, "episode/reward_rate": 0.004081632653061225, "episode/intrinsic_return": 0.0}
{"step": 299440, "time": 34422.87071657181, "episode/length": 233.0, "episode/score": 0.2718749940395355, "episode/reward_rate": 0.004273504273504274, "episode/intrinsic_return": 0.0}
{"step": 299960, "time": 34482.21023225784, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 299968, "time": 34483.126339912415, "episode/length": 231.0, "episode/score": 0.27812498807907104, "episode/reward_rate": 0.004310344827586207, "episode/intrinsic_return": 0.0}
{"step": 299992, "time": 34485.856523513794, "episode/length": 221.0, "episode/score": 0.30937498807907104, "episode/reward_rate": 0.0045045045045045045, "episode/intrinsic_return": 0.0}
{"step": 300040, "time": 34492.626933813095, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 300040, "time": 34492.63247060776, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 300040, "time": 34496.28191614151, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300040, "time": 34496.29028701782, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300040, "time": 34496.29593157768, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300040, "time": 34496.30148077011, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300040, "time": 34496.30666780472, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300040, "time": 34496.31263923645, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300072, "time": 34499.921385765076, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 300696, "time": 34570.98290300369, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 300720, "time": 34573.75438308716, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 300960, "time": 34601.01317834854, "episode/length": 211.0, "episode/score": 0.34062498807907104, "episode/reward_rate": 0.0047169811320754715, "episode/intrinsic_return": 0.0}
{"step": 301160, "time": 34623.72939133644, "episode/length": 270.0, "episode/score": 0.15625, "episode/reward_rate": 0.0036900369003690036, "episode/intrinsic_return": 0.0}
{"step": 301408, "time": 34651.94818329811, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 301568, "time": 34670.09993672371, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 301592, "time": 34672.82130908966, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 301880, "time": 34705.56123161316, "episode/length": 225.0, "episode/score": 0.296875, "episode/reward_rate": 0.004424778761061947, "episode/intrinsic_return": 0.0}
{"step": 302272, "time": 34750.03185868263, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 302304, "time": 34753.73745441437, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 302416, "time": 34766.467322826385, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 302608, "time": 34788.30163478851, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 302920, "time": 34823.759004592896, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 303032, "time": 34836.45447063446, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 303464, "time": 34885.86354589462, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 303472, "time": 34886.771314144135, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 303880, "time": 34933.20723223686, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 303904, "time": 34935.93099522591, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 303912, "time": 34936.8467798233, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 304016, "time": 34948.67540240288, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 304480, "time": 35001.4043507576, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 304728, "time": 35029.63529753685, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 304744, "time": 35031.45675110817, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 304920, "time": 35051.48614406586, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 305232, "time": 35087.02266287804, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 305272, "time": 35091.56752347946, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 305432, "time": 35109.72277402878, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 305752, "time": 35146.14389681816, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 305752, "time": 35146.1519715786, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 305776, "time": 35148.89484143257, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 306328, "time": 35211.48870873451, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 306565, "time": 35239.28914785385, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.6819017662849602, "train/action_min": 0.0, "train/action_std": 2.1537046258308026, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.007744401507823809, "train/actor_opt_grad_steps": 75160.0, "train/actor_opt_loss": -10.414427955400997, "train/adv_mag": 0.4466422645196523, "train/adv_max": 0.2642306331630167, "train/adv_mean": 0.005543604426403366, "train/adv_min": -0.4126921360079012, "train/adv_std": 0.02865267593251992, "train/cont_avg": 0.9959555151255708, "train/cont_loss_mean": 0.01101363130917424, "train/cont_loss_std": 0.18269201185443698, "train/cont_neg_acc": 0.45572090624935097, "train/cont_neg_loss": 2.1943514279909895, "train/cont_pos_acc": 0.9998298507847198, "train/cont_pos_loss": 0.0022867716541598855, "train/cont_pred": 0.9959718370002154, "train/cont_rate": 0.9959555151255708, "train/dyn_loss_mean": 1.0000029693455457, "train/dyn_loss_std": 6.259879794771268e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.15232981234516726, "train/extr_critic_critic_opt_grad_steps": 75160.0, "train/extr_critic_critic_opt_loss": 8685.552908283391, "train/extr_critic_mag": 0.7641445850128452, "train/extr_critic_max": 0.7641445850128452, "train/extr_critic_mean": 0.592962303662409, "train/extr_critic_min": 0.49479559240820203, "train/extr_critic_std": 0.033708539357638526, "train/extr_return_normed_mag": 0.4818186207449055, "train/extr_return_normed_max": 0.35254963674501744, "train/extr_return_normed_mean": 0.04789309605071534, "train/extr_return_normed_min": -0.36212031808617995, "train/extr_return_normed_std": 0.047491210551090436, "train/extr_return_rate": 0.9969344958322778, "train/extr_return_raw_mag": 0.9031625014461883, "train/extr_return_raw_max": 0.9031625014461883, "train/extr_return_raw_mean": 0.5985059896016229, "train/extr_return_raw_min": 0.18849254661499093, "train/extr_return_raw_std": 0.047491210784984236, "train/extr_reward_mag": 0.39846656420459486, "train/extr_reward_max": 0.39846656420459486, "train/extr_reward_mean": 0.0017821345133834507, "train/extr_reward_min": 0.0, "train/extr_reward_std": 0.014110229181159782, "train/image_loss_mean": 0.07226728404697762, "train/image_loss_std": 0.09744133181087503, "train/model_loss_mean": 0.6867349830936623, "train/model_loss_std": 0.27357123588045984, "train/model_opt_grad_norm": 16.06375120981643, "train/model_opt_grad_steps": 75093.33333333333, "train/model_opt_loss": 3604.994583199558, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5251.141552511415, "train/policy_entropy_mag": 1.3501679450953932, "train/policy_entropy_max": 1.3501679450953932, "train/policy_entropy_mean": 0.11294531172405095, "train/policy_entropy_min": 0.06468649211947776, "train/policy_entropy_std": 0.14574687465276892, "train/policy_logprob_mag": 6.551080292218352, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.11218211463052932, "train/policy_logprob_min": -6.551080292218352, "train/policy_logprob_std": 0.6479809651636097, "train/policy_randomness_mag": 0.6938491093513628, "train/policy_randomness_max": 0.6938491093513628, "train/policy_randomness_mean": 0.05804241196886045, "train/policy_randomness_min": 0.03324228154333759, "train/policy_randomness_std": 0.07489908132787164, "train/post_ent_mag": 40.08951467575004, "train/post_ent_max": 40.08951467575004, "train/post_ent_mean": 38.8435456437063, "train/post_ent_min": 37.83609911078187, "train/post_ent_std": 0.4652950061510687, "train/prior_ent_mag": 39.63394403675375, "train/prior_ent_max": 39.63394403675375, "train/prior_ent_mean": 37.952370926669744, "train/prior_ent_min": 36.64209540031816, "train/prior_ent_std": 0.4224985797111302, "train/rep_loss_mean": 1.0000029693455457, "train/rep_loss_std": 6.259879794771268e-05, "train/reward_avg": 0.0004887829110311816, "train/reward_loss_mean": 0.0034522610720774355, "train/reward_loss_std": 0.07713264490894498, "train/reward_max_data": 0.34711758013321387, "train/reward_max_pred": 0.1438141750962767, "train/reward_neg_acc": 0.9998080929120382, "train/reward_neg_loss": 0.0005782682903921104, "train/reward_pos_acc": 0.33683473497879607, "train/reward_pos_loss": 3.3416246088112103, "train/reward_pred": 0.0003648215913337115, "train/reward_rate": 0.0008427868150684932, "train_stats/mean_log_entropy": 0.09611614580665316, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9990234375, "report/cont_loss_mean": 0.0068324534222483635, "report/cont_loss_std": 0.19503706693649292, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 6.244131088256836, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0007353870314545929, "report/cont_pred": 0.9992687702178955, "report/cont_rate": 0.9990234375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.042914919555187225, "report/image_loss_std": 0.08127783983945847, "report/model_loss_mean": 0.649935245513916, "report/model_loss_std": 0.21148858964443207, "report/post_ent_mag": 40.62141418457031, "report/post_ent_max": 40.62141418457031, "report/post_ent_mean": 39.21171951293945, "report/post_ent_min": 38.25973892211914, "report/post_ent_std": 0.47831887006759644, "report/prior_ent_mag": 39.84719467163086, "report/prior_ent_max": 39.84719467163086, "report/prior_ent_mean": 38.655460357666016, "report/prior_ent_min": 37.243560791015625, "report/prior_ent_std": 0.3555716574192047, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.00018789316527545452, "report/reward_loss_std": 0.0021495791152119637, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.01914846897125244, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00018789316527545452, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 7.693376392126083e-05, "report/reward_rate": 0.0, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.04814328998327255, "eval/cont_loss_std": 0.746002197265625, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 11.957038879394531, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.0014417446218430996, "eval/cont_pred": 0.998609721660614, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.17332029342651367, "eval/image_loss_std": 0.1749880313873291, "eval/model_loss_mean": 0.8216971158981323, "eval/model_loss_std": 0.7719713449478149, "eval/post_ent_mag": 40.57883834838867, "eval/post_ent_max": 40.57883834838867, "eval/post_ent_mean": 39.20108413696289, "eval/post_ent_min": 38.26719284057617, "eval/post_ent_std": 0.47841405868530273, "eval/prior_ent_mag": 39.90026092529297, "eval/prior_ent_max": 39.90026092529297, "eval/prior_ent_mean": 38.663604736328125, "eval/prior_ent_min": 37.37568664550781, "eval/prior_ent_std": 0.38140690326690674, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0002335328608751297, "eval/reward_loss_std": 0.0022523256484419107, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.015187621116638184, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0002335328608751297, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 9.440584108233452e-05, "eval/reward_rate": 0.0, "replay/size": 306061.0, "replay/inserts": 8736.0, "replay/samples": 34944.0, "replay/insert_wait_avg": 1.5612650703597854e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.583450928712502e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 72712.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0942299060755535e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.450580596923828e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0338418483734, "timer/env.step_count": 1092.0, "timer/env.step_total": 10.897402048110962, "timer/env.step_frac": 0.010897033272363238, "timer/env.step_avg": 0.009979305904863518, "timer/env.step_min": 0.008620977401733398, "timer/env.step_max": 0.03558969497680664, "timer/replay._sample_count": 34944.0, "timer/replay._sample_total": 18.869579792022705, "timer/replay._sample_frac": 0.018868941232174558, "timer/replay._sample_avg": 0.0005399948429493677, "timer/replay._sample_min": 0.00037217140197753906, "timer/replay._sample_max": 0.0263822078704834, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1381.0, "timer/agent.policy_total": 14.006067276000977, "timer/agent.policy_frac": 0.01400559330083611, "timer/agent.policy_avg": 0.010141974855902227, "timer/agent.policy_min": 0.008679628372192383, "timer/agent.policy_max": 0.03487896919250488, "timer/dataset_train_count": 2184.0, "timer/dataset_train_total": 0.38825464248657227, "timer/dataset_train_frac": 0.0003882415036764726, "timer/dataset_train_avg": 0.00017777227220081148, "timer/dataset_train_min": 9.72747802734375e-05, "timer/dataset_train_max": 0.0009500980377197266, "timer/agent.train_count": 2184.0, "timer/agent.train_total": 969.9670841693878, "timer/agent.train_frac": 0.9699342598012355, "timer/agent.train_avg": 0.44412412278818125, "timer/agent.train_min": 0.43032193183898926, "timer/agent.train_max": 0.5757796764373779, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47503042221069336, "timer/agent.report_frac": 0.00047501434684719214, "timer/agent.report_avg": 0.23751521110534668, "timer/agent.report_min": 0.232802152633667, "timer/agent.report_max": 0.24222826957702637, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.2901763916015625e-05, "timer/dataset_eval_frac": 3.2900650497190114e-08, "timer/dataset_eval_avg": 3.2901763916015625e-05, "timer/dataset_eval_min": 3.2901763916015625e-05, "timer/dataset_eval_max": 3.2901763916015625e-05, "fps": 8.73558005191131}
{"step": 307040, "time": 35293.21473431587, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 307232, "time": 35314.982365846634, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 307544, "time": 35350.3990585804, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 307584, "time": 35354.99977636337, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 308064, "time": 35409.51932024956, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 308064, "time": 35409.52680826187, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 308088, "time": 35412.33457517624, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 308256, "time": 35431.37095093727, "episode/length": 20.0, "episode/score": 0.9375, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.0}
{"step": 308640, "time": 35475.08076405525, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 309352, "time": 35555.950583934784, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 309512, "time": 35574.17190980911, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 309544, "time": 35577.80763220787, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 309856, "time": 35613.29225230217, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 309856, "time": 35613.29911327362, "episode/length": 199.0, "episode/score": 0.37812501192092896, "episode/reward_rate": 0.005, "episode/intrinsic_return": 0.0}
{"step": 309896, "time": 35617.827839136124, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 310024, "time": 35633.246404886246, "eval_episode/length": 44.0, "eval_episode/score": 0.862500011920929, "eval_episode/reward_rate": 0.022222222222222223}
{"step": 310024, "time": 35634.41999959946, "eval_episode/length": 75.0, "eval_episode/score": 0.765625, "eval_episode/reward_rate": 0.013157894736842105}
{"step": 310024, "time": 35634.72351002693, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 310024, "time": 35635.38960313797, "eval_episode/length": 85.0, "eval_episode/score": 0.734375, "eval_episode/reward_rate": 0.011627906976744186}
{"step": 310024, "time": 35636.1211540699, "eval_episode/length": 171.0, "eval_episode/score": 0.46562498807907104, "eval_episode/reward_rate": 0.005813953488372093}
{"step": 310024, "time": 35638.15910720825, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "time": 35638.16543054581, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "time": 35638.17080903053, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "time": 35638.17609620094, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310304, "time": 35670.0294239521, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 310376, "time": 35678.21027803421, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 310376, "time": 35678.21783185005, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 310776, "time": 35723.81356883049, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 310792, "time": 35725.638949632645, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 310824, "time": 35729.28259754181, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 310888, "time": 35736.56255674362, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 311208, "time": 35773.1097240448, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 311472, "time": 35803.523654937744, "episode/length": 244.0, "episode/score": 0.23749999701976776, "episode/reward_rate": 0.004081632653061225, "episode/intrinsic_return": 0.0}
{"step": 311592, "time": 35817.13127374649, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 311856, "time": 35847.17158651352, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 312080, "time": 35872.7091987133, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 312160, "time": 35881.79246068001, "episode/length": 287.0, "episode/score": 0.10312499850988388, "episode/reward_rate": 0.003472222222222222, "episode/intrinsic_return": 0.0}
{"step": 312440, "time": 35913.586495399475, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 312552, "time": 35926.35466194153, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 312616, "time": 35933.60273551941, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 312792, "time": 35953.63766288757, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 313088, "time": 35987.32598924637, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 313104, "time": 35989.135102272034, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 313520, "time": 36036.30065393448, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 313784, "time": 36066.25068616867, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 314392, "time": 36135.30870342255, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 314848, "time": 36187.961881399155, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 314864, "time": 36189.77099943161, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 314880, "time": 36191.717965364456, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 314928, "time": 36197.148440122604, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 315104, "time": 36217.11238670349, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 315293, "time": 36239.52061057091, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.607190053397362, "train/action_min": 0.0, "train/action_std": 1.8222264674825406, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.006132344937447561, "train/actor_opt_grad_steps": 77345.0, "train/actor_opt_loss": -14.3390552822603, "train/adv_mag": 0.5150727449207131, "train/adv_max": 0.1740358414453104, "train/adv_mean": 0.0005762700664035947, "train/adv_min": -0.49577676812443167, "train/adv_std": 0.019332406820233808, "train/cont_avg": 0.99609375, "train/cont_loss_mean": 0.010451209088979682, "train/cont_loss_std": 0.17865766018389836, "train/cont_neg_acc": 0.49006796153478843, "train/cont_neg_loss": 2.0767603494523383, "train/cont_pos_acc": 0.9998200404534646, "train/cont_pos_loss": 0.002207924481566756, "train/cont_pred": 0.9960688997846131, "train/cont_rate": 0.99609375, "train/dyn_loss_mean": 1.0000000678071188, "train/dyn_loss_std": 2.170612671361262e-06, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.10592920593746485, "train/extr_critic_critic_opt_grad_steps": 77345.0, "train/extr_critic_critic_opt_loss": 12820.845250680906, "train/extr_critic_mag": 0.8489752329817606, "train/extr_critic_max": 0.8489752329817606, "train/extr_critic_mean": 0.7305879581958876, "train/extr_critic_min": 0.6350960818999404, "train/extr_critic_std": 0.030211893974060038, "train/extr_return_normed_mag": 0.5236111824665595, "train/extr_return_normed_max": 0.25194666391118953, "train/extr_return_normed_mean": 0.0466234125624146, "train/extr_return_normed_min": -0.45682535669125546, "train/extr_return_normed_std": 0.036075471601354964, "train/extr_return_rate": 0.9993292867043696, "train/extr_return_raw_mag": 0.93648739172778, "train/extr_return_raw_max": 0.93648739172778, "train/extr_return_raw_mean": 0.7311641778967796, "train/extr_return_raw_min": 0.22771537139875078, "train/extr_return_raw_std": 0.0360754717252465, "train/extr_reward_mag": 0.29671224596303536, "train/extr_reward_max": 0.29671224596303536, "train/extr_reward_mean": 0.00047011318441311914, "train/extr_reward_min": 0.0, "train/extr_reward_std": 0.005932251294116797, "train/image_loss_mean": 0.07314354405148861, "train/image_loss_std": 0.09800212679926408, "train/model_loss_mean": 0.6869644440642191, "train/model_loss_std": 0.27079200983867735, "train/model_opt_grad_norm": 15.618817353467328, "train/model_opt_grad_steps": 77276.22935779816, "train/model_opt_loss": 3578.1787187768778, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5229.357798165138, "train/policy_entropy_mag": 1.2960884718719972, "train/policy_entropy_max": 1.2960884718719972, "train/policy_entropy_mean": 0.10383703634826415, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.13273358580852868, "train/policy_logprob_mag": 6.551080310016597, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.10376590005028138, "train/policy_logprob_min": -6.551080310016597, "train/policy_logprob_std": 0.6412129754867029, "train/policy_randomness_mag": 0.6660577575547979, "train/policy_randomness_max": 0.6660577575547979, "train/policy_randomness_mean": 0.053361684169381036, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06821157369728482, "train/post_ent_mag": 40.872010922213214, "train/post_ent_max": 40.872010922213214, "train/post_ent_mean": 39.666389745309814, "train/post_ent_min": 38.67094605122138, "train/post_ent_std": 0.4506299510734891, "train/prior_ent_mag": 40.25760939361852, "train/prior_ent_max": 40.25760939361852, "train/prior_ent_mean": 38.98068657271359, "train/prior_ent_min": 37.669125005739545, "train/prior_ent_std": 0.3965068567510045, "train/rep_loss_mean": 1.0000000678071188, "train/rep_loss_std": 2.170612671361262e-06, "train/reward_avg": 0.0004628032697962785, "train/reward_loss_mean": 0.0033696272427540855, "train/reward_loss_std": 0.07782684454433791, "train/reward_max_data": 0.3504730486268297, "train/reward_max_pred": 0.17365739651776235, "train/reward_neg_acc": 0.9998654788787212, "train/reward_neg_loss": 0.0005867072592882991, "train/reward_pos_acc": 0.376302084652707, "train/reward_pos_loss": 3.2261119661852717, "train/reward_pred": 0.00041003671310278116, "train/reward_rate": 0.0008690510321100917, "train_stats/mean_log_entropy": 0.09681955618517739, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.012184275314211845, "report/cont_loss_std": 0.23388457298278809, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 4.803452491760254, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0028080164920538664, "report/cont_pred": 0.9972778558731079, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.06515300273895264, "report/image_loss_std": 0.08601436018943787, "report/model_loss_mean": 0.678192138671875, "report/model_loss_std": 0.24808979034423828, "report/post_ent_mag": 40.85078811645508, "report/post_ent_max": 40.85078811645508, "report/post_ent_mean": 39.71489715576172, "report/post_ent_min": 38.82493591308594, "report/post_ent_std": 0.4364929795265198, "report/prior_ent_mag": 40.90821838378906, "report/prior_ent_max": 40.90821838378906, "report/prior_ent_mean": 39.65398406982422, "report/prior_ent_min": 38.066619873046875, "report/prior_ent_std": 0.4711684286594391, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.0008548235055059195, "report/reward_loss_std": 0.006056159269064665, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.03306913375854492, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0008548235055059195, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0003627609694376588, "report/reward_rate": 0.0, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.04048515856266022, "eval/cont_loss_std": 0.6241440773010254, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 9.607279777526855, "eval/cont_pos_acc": 0.9990195631980896, "eval/cont_pos_loss": 0.0029683203902095556, "eval/cont_pred": 0.997931957244873, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.17548730969429016, "eval/image_loss_std": 0.17193438112735748, "eval/model_loss_mean": 0.8161994218826294, "eval/model_loss_std": 0.6515401601791382, "eval/post_ent_mag": 40.856834411621094, "eval/post_ent_max": 40.856834411621094, "eval/post_ent_mean": 39.582763671875, "eval/post_ent_min": 38.80189514160156, "eval/post_ent_std": 0.43202078342437744, "eval/prior_ent_mag": 40.76060485839844, "eval/prior_ent_max": 40.76060485839844, "eval/prior_ent_mean": 39.585365295410156, "eval/prior_ent_min": 38.1341552734375, "eval/prior_ent_std": 0.47725290060043335, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00022694887593388557, "eval/reward_loss_std": 0.0019643804989755154, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.01194620132446289, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00022694887593388557, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00010554713662713766, "eval/reward_rate": 0.0, "replay/size": 314789.0, "replay/inserts": 8728.0, "replay/samples": 34912.0, "replay/insert_wait_avg": 1.5560581966019027e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.306281084537943e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 75024.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1154730839712809e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.450580596923828e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2153761386871, "timer/env.step_count": 1091.0, "timer/env.step_total": 10.85990023612976, "timer/env.step_frac": 0.010857561776398803, "timer/env.step_avg": 0.00995407904319868, "timer/env.step_min": 0.008676767349243164, "timer/env.step_max": 0.035352468490600586, "timer/replay._sample_count": 34912.0, "timer/replay._sample_total": 19.0317862033844, "timer/replay._sample_frac": 0.019027688093394703, "timer/replay._sample_avg": 0.0005451359476221471, "timer/replay._sample_min": 0.0003561973571777344, "timer/replay._sample_max": 0.032968997955322266, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1380.0, "timer/agent.policy_total": 14.363660097122192, "timer/agent.policy_frac": 0.014360567173614981, "timer/agent.policy_avg": 0.01040844934574072, "timer/agent.policy_min": 0.008768558502197266, "timer/agent.policy_max": 0.0937962532043457, "timer/dataset_train_count": 2182.0, "timer/dataset_train_total": 0.38999104499816895, "timer/dataset_train_frac": 0.0003899070683193475, "timer/dataset_train_avg": 0.00017873100137404626, "timer/dataset_train_min": 9.751319885253906e-05, "timer/dataset_train_max": 0.0005755424499511719, "timer/agent.train_count": 2182.0, "timer/agent.train_total": 969.5717303752899, "timer/agent.train_frac": 0.9693629527255455, "timer/agent.train_avg": 0.44435001392084783, "timer/agent.train_min": 0.43428897857666016, "timer/agent.train_max": 1.4152467250823975, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47206783294677734, "timer/agent.report_frac": 0.00047196618269275804, "timer/agent.report_avg": 0.23603391647338867, "timer/agent.report_min": 0.22986555099487305, "timer/agent.report_max": 0.2422022819519043, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8133392333984375e-05, "timer/dataset_eval_frac": 2.8127334377314626e-08, "timer/dataset_eval_avg": 2.8133392333984375e-05, "timer/dataset_eval_min": 2.8133392333984375e-05, "timer/dataset_eval_max": 2.8133392333984375e-05, "fps": 8.725999436041429}
{"step": 315400, "time": 36251.542241573334, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 315416, "time": 36253.35146546364, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 315752, "time": 36291.4846162796, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 316096, "time": 36330.475845098495, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 316384, "time": 36363.10888123512, "episode/length": 191.0, "episode/score": 0.40312498807907104, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.0}
{"step": 316952, "time": 36427.56414818764, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 317176, "time": 36453.03242993355, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 317192, "time": 36454.849476099014, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 317240, "time": 36460.31328821182, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 317536, "time": 36493.97169446945, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 317712, "time": 36513.91596674919, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 317728, "time": 36515.739558935165, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 318048, "time": 36552.17488050461, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 318064, "time": 36553.98013353348, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 318552, "time": 36609.22451710701, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 318696, "time": 36625.60345053673, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 319000, "time": 36660.07212662697, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 319264, "time": 36689.986221551895, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 319504, "time": 36717.57806634903, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 319552, "time": 36723.029396772385, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 320008, "time": 36776.15062093735, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 320008, "time": 36776.513979911804, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 320008, "time": 36777.21678900719, "eval_episode/length": 138.0, "eval_episode/score": 0.5687500238418579, "eval_episode/reward_rate": 0.007194244604316547}
{"step": 320008, "time": 36778.19135951996, "eval_episode/length": 56.0, "eval_episode/score": 0.824999988079071, "eval_episode/reward_rate": 0.017543859649122806}
{"step": 320008, "time": 36778.352229356766, "eval_episode/length": 126.0, "eval_episode/score": 0.606249988079071, "eval_episode/reward_rate": 0.007874015748031496}
{"step": 320008, "time": 36778.500371456146, "eval_episode/length": 212.0, "eval_episode/score": 0.3375000059604645, "eval_episode/reward_rate": 0.004694835680751174}
{"step": 320008, "time": 36778.693063020706, "eval_episode/length": 18.0, "eval_episode/score": 0.9437500238418579, "eval_episode/reward_rate": 0.05263157894736842}
{"step": 320008, "time": 36779.74480819702, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 320040, "time": 36783.375866651535, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 320176, "time": 36798.93155622482, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 320360, "time": 36819.75842118263, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 320456, "time": 36830.77397966385, "episode/length": 219.0, "episode/score": 0.31562501192092896, "episode/reward_rate": 0.004545454545454545, "episode/intrinsic_return": 0.0}
{"step": 320864, "time": 36876.9915368557, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 321136, "time": 36907.890763521194, "episode/length": 203.0, "episode/score": 0.3656249940395355, "episode/reward_rate": 0.004901960784313725, "episode/intrinsic_return": 0.0}
{"step": 321224, "time": 36917.95844364166, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 321312, "time": 36927.91539692879, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 321432, "time": 36941.51007437706, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 321456, "time": 36944.22948670387, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 321576, "time": 36957.822177410126, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 321624, "time": 36963.253814935684, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 321680, "time": 36969.59864926338, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 321688, "time": 36970.501569509506, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 321832, "time": 36986.814646959305, "episode/length": 206.0, "episode/score": 0.35624998807907104, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.0}
{"step": 321920, "time": 36996.79745864868, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 322192, "time": 37027.60353589058, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 322288, "time": 37038.5809636116, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 322336, "time": 37044.004356622696, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 322360, "time": 37046.737730026245, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 322448, "time": 37056.669741630554, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 322504, "time": 37063.063412189484, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 322544, "time": 37067.579374074936, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 322904, "time": 37108.35126209259, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 322936, "time": 37111.983870744705, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 323056, "time": 37125.58755946159, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 323232, "time": 37145.43584537506, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 323328, "time": 37156.419377565384, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 323424, "time": 37167.31356596947, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 323520, "time": 37178.223360300064, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 323816, "time": 37211.87349963188, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 324000, "time": 37232.680102586746, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 324053, "time": 37239.55177807808, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.749754465878282, "train/action_min": 0.0, "train/action_std": 1.5274307782247187, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.006744539791496989, "train/actor_opt_grad_steps": 79530.0, "train/actor_opt_loss": -13.900330634966288, "train/adv_mag": 0.5699399298728873, "train/adv_max": 0.23802810036428443, "train/adv_mean": 0.001393361610700686, "train/adv_min": -0.5127127215470353, "train/adv_std": 0.019020818620409868, "train/cont_avg": 0.9961428010844748, "train/cont_loss_mean": 0.010551567613062147, "train/cont_loss_std": 0.1760962376600667, "train/cont_neg_acc": 0.45845894071213694, "train/cont_neg_loss": 2.0850967437297494, "train/cont_pos_acc": 0.9998343306589345, "train/cont_pos_loss": 0.002323480817323474, "train/cont_pred": 0.9960513525901864, "train/cont_rate": 0.9961428010844748, "train/dyn_loss_mean": 1.0000005791720734, "train/dyn_loss_std": 1.852048687093581e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.09165468964232429, "train/extr_critic_critic_opt_grad_steps": 79530.0, "train/extr_critic_critic_opt_loss": 10686.464067851028, "train/extr_critic_mag": 0.896668208788519, "train/extr_critic_max": 0.896668208788519, "train/extr_critic_mean": 0.8033813711715071, "train/extr_critic_min": 0.657600986358782, "train/extr_critic_std": 0.024338797831984414, "train/extr_return_normed_mag": 0.5930726530889397, "train/extr_return_normed_max": 0.2771463497588624, "train/extr_return_normed_mean": 0.04174991511658991, "train/extr_return_normed_min": -0.5067631430821876, "train/extr_return_normed_std": 0.03146124917792675, "train/extr_return_rate": 0.9994485860001551, "train/extr_return_raw_mag": 1.0401711755147263, "train/extr_return_raw_max": 1.0401711755147263, "train/extr_return_raw_mean": 0.8047747807959987, "train/extr_return_raw_min": 0.2562616829458437, "train/extr_return_raw_std": 0.03146124912689538, "train/extr_reward_mag": 0.28437945015354243, "train/extr_reward_max": 0.28437945015354243, "train/extr_reward_mean": 0.00053319432016528, "train/extr_reward_min": 1.6330039664490581e-09, "train/extr_reward_std": 0.0057966368130438, "train/image_loss_mean": 0.0715540342168993, "train/image_loss_std": 0.09708333882975252, "train/model_loss_mean": 0.6857831064424559, "train/model_loss_std": 0.27181115334845024, "train/model_opt_grad_norm": 15.693558318429886, "train/model_opt_grad_steps": 79459.1506849315, "train/model_opt_loss": 3585.91073371504, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5228.310502283105, "train/policy_entropy_mag": 1.3650764139819906, "train/policy_entropy_max": 1.3650764139819906, "train/policy_entropy_mean": 0.09622505293589205, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.12124201277755711, "train/policy_logprob_mag": 6.551080250848918, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09631185168953246, "train/policy_logprob_min": -6.551080250848918, "train/policy_logprob_std": 0.6345517297857972, "train/policy_randomness_mag": 0.7015105475029445, "train/policy_randomness_max": 0.7015105475029445, "train/policy_randomness_mean": 0.04944989848967012, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06230607297118396, "train/post_ent_mag": 41.28387435495037, "train/post_ent_max": 41.28387435495037, "train/post_ent_mean": 40.110332210314326, "train/post_ent_min": 39.12939519316094, "train/post_ent_std": 0.4412848881390541, "train/prior_ent_mag": 41.10149245937121, "train/prior_ent_max": 41.10149245937121, "train/prior_ent_mean": 39.86777161898678, "train/prior_ent_min": 38.337715096669655, "train/prior_ent_std": 0.43610904124229466, "train/rep_loss_mean": 1.0000005791720734, "train/rep_loss_std": 1.852048687093581e-05, "train/reward_avg": 0.0005402447452867556, "train/reward_loss_mean": 0.003677130625508811, "train/reward_loss_std": 0.0841611229668937, "train/reward_max_data": 0.38642979518735787, "train/reward_max_pred": 0.17592706527884147, "train/reward_neg_acc": 0.9998214699361967, "train/reward_neg_loss": 0.0006762148325887539, "train/reward_pos_acc": 0.35385572265333204, "train/reward_pos_loss": 3.3444104716181755, "train/reward_pred": 0.0004359128136510991, "train/reward_rate": 0.0009185930365296803, "train_stats/mean_log_entropy": 0.0778584354198896, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.021776648238301277, "report/cont_loss_std": 0.32004472613334656, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.0489630699157715, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.002062189159914851, "report/cont_pred": 0.9979683756828308, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07174801081418991, "report/image_loss_std": 0.10038108378648758, "report/model_loss_mean": 0.69875568151474, "report/model_loss_std": 0.41333693265914917, "report/post_ent_mag": 41.958251953125, "report/post_ent_max": 41.958251953125, "report/post_ent_mean": 40.90077209472656, "report/post_ent_min": 39.9312629699707, "report/post_ent_std": 0.4347223937511444, "report/prior_ent_mag": 41.47820281982422, "report/prior_ent_max": 41.47820281982422, "report/prior_ent_mean": 40.457763671875, "report/prior_ent_min": 38.71952438354492, "report/prior_ent_std": 0.45312798023223877, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0005737304454669356, "report/reward_loss_mean": 0.005230976268649101, "report/reward_loss_std": 0.1403658241033554, "report/reward_max_data": 0.5874999761581421, "report/reward_max_pred": 0.035218000411987305, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0008478721720166504, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.4891462326049805, "report/reward_pred": 0.0003588033141568303, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.06057671457529068, "eval/cont_loss_std": 0.7969682812690735, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 9.993643760681152, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0020321120973676443, "eval/cont_pred": 0.998007595539093, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.1826881766319275, "eval/image_loss_std": 0.15394388139247894, "eval/model_loss_mean": 0.8438461422920227, "eval/model_loss_std": 0.8078146576881409, "eval/post_ent_mag": 42.011497497558594, "eval/post_ent_max": 42.011497497558594, "eval/post_ent_mean": 40.87587356567383, "eval/post_ent_min": 39.96052551269531, "eval/post_ent_std": 0.4477473199367523, "eval/prior_ent_mag": 41.7113151550293, "eval/prior_ent_max": 41.7113151550293, "eval/prior_ent_mean": 40.40961456298828, "eval/prior_ent_min": 38.934017181396484, "eval/prior_ent_std": 0.42273572087287903, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0005812337622046471, "eval/reward_loss_std": 0.005035053007304668, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0703742504119873, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0005812337622046471, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0002746253740042448, "eval/reward_rate": 0.0, "replay/size": 323549.0, "replay/inserts": 8760.0, "replay/samples": 35040.0, "replay/insert_wait_avg": 1.5307779181493471e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.467659096739608e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 77312.0, "eval_replay/inserts": 2288.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0438107110403635e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.046627044677734e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0165066719055, "timer/env.step_count": 1095.0, "timer/env.step_total": 10.803996801376343, "timer/env.step_frac": 0.010803818466289593, "timer/env.step_avg": 0.009866663745549172, "timer/env.step_min": 0.00856637954711914, "timer/env.step_max": 0.03554034233093262, "timer/replay._sample_count": 35040.0, "timer/replay._sample_total": 18.77482509613037, "timer/replay._sample_frac": 0.018774515191367924, "timer/replay._sample_avg": 0.0005358112184968713, "timer/replay._sample_min": 0.0003905296325683594, "timer/replay._sample_max": 0.011840105056762695, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1381.0, "timer/agent.policy_total": 13.929785966873169, "timer/agent.policy_frac": 0.013929556036261889, "timer/agent.policy_avg": 0.010086738571233286, "timer/agent.policy_min": 0.008752822875976562, "timer/agent.policy_max": 0.03780865669250488, "timer/dataset_train_count": 2190.0, "timer/dataset_train_total": 0.3892083168029785, "timer/dataset_train_frac": 0.00038920189237503605, "timer/dataset_train_avg": 0.00017772069260409978, "timer/dataset_train_min": 9.512901306152344e-05, "timer/dataset_train_max": 0.0006647109985351562, "timer/agent.train_count": 2190.0, "timer/agent.train_total": 970.104022026062, "timer/agent.train_frac": 0.9700880091015763, "timer/agent.train_avg": 0.4429698730712612, "timer/agent.train_min": 0.4302098751068115, "timer/agent.train_max": 0.5820183753967285, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4791278839111328, "timer/agent.report_frac": 0.0004791199752348982, "timer/agent.report_avg": 0.2395639419555664, "timer/agent.report_min": 0.23275518417358398, "timer/agent.report_max": 0.24637269973754883, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.2172927856445312e-05, "timer/dataset_eval_frac": 2.2172561861241364e-08, "timer/dataset_eval_avg": 2.2172927856445312e-05, "timer/dataset_eval_min": 2.2172927856445312e-05, "timer/dataset_eval_max": 2.2172927856445312e-05, "fps": 8.759724805016969}
{"step": 324472, "time": 37287.22891998291, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 324552, "time": 37296.27930569649, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 324728, "time": 37316.33290743828, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 324816, "time": 37326.32112455368, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 325208, "time": 37370.890107393265, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 325232, "time": 37373.62090587616, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 325248, "time": 37375.450632572174, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 325504, "time": 37404.70416545868, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 325512, "time": 37405.62314414978, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 325544, "time": 37409.29711604118, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 325640, "time": 37420.355768203735, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 325736, "time": 37431.39297938347, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 326128, "time": 37476.31802535057, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 326296, "time": 37495.608879089355, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 326312, "time": 37497.42422294617, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 326464, "time": 37514.908030986786, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 326576, "time": 37527.60615468025, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 326696, "time": 37541.37050294876, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 326816, "time": 37555.09737730026, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 327304, "time": 37610.98037290573, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 327648, "time": 37650.365512132645, "episode/length": 267.0, "episode/score": 0.16562500596046448, "episode/reward_rate": 0.0037313432835820895, "episode/intrinsic_return": 0.0}
{"step": 327800, "time": 37668.106162548065, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 327896, "time": 37679.018157720566, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 327952, "time": 37685.38364815712, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 328016, "time": 37692.77170372009, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 328048, "time": 37696.426936626434, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 328056, "time": 37697.335146188736, "episode/length": 19.0, "episode/score": 0.940625011920929, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.0}
{"step": 328760, "time": 37777.34217238426, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 328776, "time": 37779.17103409767, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 328992, "time": 37803.74260735512, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 329256, "time": 37833.817984342575, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 329512, "time": 37863.00798821449, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 329608, "time": 37874.00388288498, "episode/length": 206.0, "episode/score": 0.35624998807907104, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.0}
{"step": 329616, "time": 37874.91143321991, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 329960, "time": 37914.11669921875, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 330032, "time": 37922.29950213432, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 330080, "time": 37927.79529953003, "episode/length": 257.0, "episode/score": 0.19687500596046448, "episode/reward_rate": 0.003875968992248062, "episode/intrinsic_return": 0.0}
{"step": 330096, "time": 37930.174374103546, "eval_episode/length": 31.0, "eval_episode/score": 0.903124988079071, "eval_episode/reward_rate": 0.03125}
{"step": 330096, "time": 37930.77520656586, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 330096, "time": 37931.64276051521, "eval_episode/length": 108.0, "eval_episode/score": 0.6625000238418579, "eval_episode/reward_rate": 0.009174311926605505}
{"step": 330096, "time": 37931.75105857849, "eval_episode/length": 114.0, "eval_episode/score": 0.643750011920929, "eval_episode/reward_rate": 0.008695652173913044}
{"step": 330096, "time": 37931.84565806389, "eval_episode/length": 119.0, "eval_episode/score": 0.628125011920929, "eval_episode/reward_rate": 0.008333333333333333}
{"step": 330096, "time": 37932.152314186096, "eval_episode/length": 136.0, "eval_episode/score": 0.574999988079071, "eval_episode/reward_rate": 0.0072992700729927005}
{"step": 330096, "time": 37932.442240953445, "eval_episode/length": 43.0, "eval_episode/score": 0.8656250238418579, "eval_episode/reward_rate": 0.022727272727272728}
{"step": 330096, "time": 37932.97761130333, "eval_episode/length": 151.0, "eval_episode/score": 0.528124988079071, "eval_episode/reward_rate": 0.006578947368421052}
{"step": 330352, "time": 37961.98553323746, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 330360, "time": 37962.915293216705, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 330632, "time": 37993.79526400566, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 331200, "time": 38058.35769057274, "episode/length": 197.0, "episode/score": 0.3843750059604645, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.0}
{"step": 331232, "time": 38061.98299884796, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 331304, "time": 38070.184092998505, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 331576, "time": 38101.14252305031, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 331792, "time": 38125.792140483856, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 331824, "time": 38129.445714235306, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 331872, "time": 38134.884605169296, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 332136, "time": 38164.874247312546, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 332272, "time": 38180.3824698925, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 332584, "time": 38215.954781770706, "episode/length": 243.0, "episode/score": 0.24062499403953552, "episode/reward_rate": 0.004098360655737705, "episode/intrinsic_return": 0.0}
{"step": 332664, "time": 38225.04176282883, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 332785, "time": 38239.71991252899, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.8999065434167144, "train/action_min": 0.0, "train/action_std": 1.5533000881518793, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0077394151423604935, "train/actor_opt_grad_steps": 81715.0, "train/actor_opt_loss": -13.319270451134498, "train/adv_mag": 0.6180249582463448, "train/adv_max": 0.22510188407854204, "train/adv_mean": 0.001473187988851534, "train/adv_min": -0.5811910515804903, "train/adv_std": 0.020640552347235448, "train/cont_avg": 0.9959772792431193, "train/cont_loss_mean": 0.01165045358223516, "train/cont_loss_std": 0.18796156623417837, "train/cont_neg_acc": 0.42958738065014285, "train/cont_neg_loss": 2.2483117599936966, "train/cont_pos_acc": 0.9998380219170807, "train/cont_pos_loss": 0.0023776584640230742, "train/cont_pred": 0.9960338418636847, "train/cont_rate": 0.9959772792431193, "train/dyn_loss_mean": 1.0000010236687618, "train/dyn_loss_std": 3.273950018193744e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.14155001738407744, "train/extr_critic_critic_opt_grad_steps": 81715.0, "train/extr_critic_critic_opt_loss": 5215.370158624211, "train/extr_critic_mag": 0.9699689056895194, "train/extr_critic_max": 0.9699689056895194, "train/extr_critic_mean": 0.8709865242516229, "train/extr_critic_min": 0.7218653083941259, "train/extr_critic_std": 0.022071763386078382, "train/extr_return_normed_mag": 0.6263901648718283, "train/extr_return_normed_max": 0.2616642702610121, "train/extr_return_normed_mean": 0.03908996247267778, "train/extr_return_normed_min": -0.5668433579283023, "train/extr_return_normed_std": 0.03156817893266951, "train/extr_return_rate": 0.999223269727252, "train/extr_return_raw_mag": 1.0950340081792358, "train/extr_return_raw_max": 1.0950340081792358, "train/extr_return_raw_mean": 0.8724597440947086, "train/extr_return_raw_min": 0.2665263799899215, "train/extr_return_raw_std": 0.031568178877131925, "train/extr_reward_mag": 0.3186345734727492, "train/extr_reward_max": 0.3186345734727492, "train/extr_reward_mean": 0.0007761935154755746, "train/extr_reward_min": 2.7341580172197536e-09, "train/extr_reward_std": 0.006744224090052239, "train/image_loss_mean": 0.07175688382340681, "train/image_loss_std": 0.09594258635279236, "train/model_loss_mean": 0.6880556118050847, "train/model_loss_std": 0.2975894010395085, "train/model_opt_grad_norm": 14.523386067206706, "train/model_opt_grad_steps": 81642.09633027524, "train/model_opt_loss": 3629.6982735450115, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5298.165137614679, "train/policy_entropy_mag": 1.30554421232381, "train/policy_entropy_max": 1.30554421232381, "train/policy_entropy_mean": 0.09027462746572057, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.1081627556421888, "train/policy_logprob_mag": 6.55108025314611, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09005032090145514, "train/policy_logprob_min": -6.55108025314611, "train/policy_logprob_std": 0.6271025087308446, "train/policy_randomness_mag": 0.6709170461794652, "train/policy_randomness_max": 0.6709170461794652, "train/policy_randomness_mean": 0.04639198456745629, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.055584664413825084, "train/post_ent_mag": 40.950544392297026, "train/post_ent_max": 40.950544392297026, "train/post_ent_mean": 39.778385424832685, "train/post_ent_min": 38.785248170205215, "train/post_ent_std": 0.4460547443376769, "train/prior_ent_mag": 41.13007470227163, "train/prior_ent_max": 41.13007470227163, "train/prior_ent_mean": 39.99405712162683, "train/prior_ent_min": 38.65051804988756, "train/prior_ent_std": 0.37792377351620876, "train/rep_loss_mean": 1.0000010236687618, "train/rep_loss_std": 3.273950018193744e-05, "train/reward_avg": 0.0006753344089727327, "train/reward_loss_mean": 0.004647635684429813, "train/reward_loss_std": 0.10321462717240489, "train/reward_max_data": 0.46556766105627795, "train/reward_max_pred": 0.1865648479636656, "train/reward_neg_acc": 0.9997264064780069, "train/reward_neg_loss": 0.0008073112571723075, "train/reward_pos_acc": 0.3205128210859421, "train/reward_pos_loss": 3.464822283348976, "train/reward_pred": 0.0005281196117888144, "train/reward_rate": 0.0011467889908256881, "train_stats/mean_log_entropy": 0.07296008806602627, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.0061247749254107475, "report/cont_loss_std": 0.06900927424430847, "report/cont_neg_acc": 0.6666666865348816, "report/cont_neg_loss": 0.720253586769104, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.004026453010737896, "report/cont_pred": 0.9940339922904968, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.08097267150878906, "report/image_loss_std": 0.09997053444385529, "report/model_loss_mean": 0.6894457936286926, "report/model_loss_std": 0.16278091073036194, "report/post_ent_mag": 40.617469787597656, "report/post_ent_max": 40.617469787597656, "report/post_ent_mean": 39.561344146728516, "report/post_ent_min": 38.53169250488281, "report/post_ent_std": 0.47057607769966125, "report/prior_ent_mag": 40.38409423828125, "report/prior_ent_max": 40.38409423828125, "report/prior_ent_mean": 39.356510162353516, "report/prior_ent_min": 38.0466423034668, "report/prior_ent_std": 0.3513394892215729, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0005676269647665322, "report/reward_loss_mean": 0.0023483484983444214, "report/reward_loss_std": 0.04811180382966995, "report/reward_max_data": 0.581250011920929, "report/reward_max_pred": 0.1600644588470459, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0008549669291824102, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 1.5300778150558472, "report/reward_pred": 0.0005412311293184757, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.04099848493933678, "eval/cont_loss_std": 0.6084403991699219, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 7.8522233963012695, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.002670592861250043, "eval/cont_pred": 0.9973341226577759, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.14756283164024353, "eval/image_loss_std": 0.14376400411128998, "eval/model_loss_mean": 0.79454505443573, "eval/model_loss_std": 0.6959030628204346, "eval/post_ent_mag": 40.604209899902344, "eval/post_ent_max": 40.604209899902344, "eval/post_ent_mean": 39.54207992553711, "eval/post_ent_min": 38.46928024291992, "eval/post_ent_std": 0.4554002583026886, "eval/prior_ent_mag": 40.28207778930664, "eval/prior_ent_max": 40.28207778930664, "eval/prior_ent_mean": 39.26061248779297, "eval/prior_ent_min": 37.99903869628906, "eval/prior_ent_std": 0.41088223457336426, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0002532959042582661, "eval/reward_loss_mean": 0.005983717739582062, "eval/reward_loss_std": 0.1692839413881302, "eval/reward_max_data": 0.2593750059604645, "eval/reward_max_pred": 0.024914860725402832, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0006929059163667262, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.418484687805176, "eval/reward_pred": 0.00031469459645450115, "eval/reward_rate": 0.0009765625, "replay/size": 332281.0, "replay/inserts": 8732.0, "replay/samples": 34928.0, "replay/insert_wait_avg": 1.540027842082619e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.525530092988165e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 78784.0, "eval_replay/inserts": 1472.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0562007841856584e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1545705795288, "timer/env.step_count": 1092.0, "timer/env.step_total": 10.846184968948364, "timer/env.step_frac": 0.010844508726949734, "timer/env.step_avg": 0.009932403817718283, "timer/env.step_min": 0.008546113967895508, "timer/env.step_max": 0.03479480743408203, "timer/replay._sample_count": 34928.0, "timer/replay._sample_total": 19.038116455078125, "timer/replay._sample_frac": 0.019035174177174128, "timer/replay._sample_avg": 0.0005450674660753013, "timer/replay._sample_min": 0.0003705024719238281, "timer/replay._sample_max": 0.03342485427856445, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1276.0, "timer/agent.policy_total": 13.131235599517822, "timer/agent.policy_frac": 0.01312920621050511, "timer/agent.policy_avg": 0.01029093699021773, "timer/agent.policy_min": 0.008818626403808594, "timer/agent.policy_max": 0.03600764274597168, "timer/dataset_train_count": 2183.0, "timer/dataset_train_total": 0.3884859085083008, "timer/dataset_train_frac": 0.0003884258692965796, "timer/dataset_train_avg": 0.00017795964659106768, "timer/dataset_train_min": 9.679794311523438e-05, "timer/dataset_train_max": 0.0009152889251708984, "timer/agent.train_count": 2183.0, "timer/agent.train_total": 971.6729476451874, "timer/agent.train_frac": 0.9715227788062418, "timer/agent.train_avg": 0.4451090002955508, "timer/agent.train_min": 0.43305182456970215, "timer/agent.train_max": 0.589275598526001, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4771275520324707, "timer/agent.report_frac": 0.00047705381354804416, "timer/agent.report_avg": 0.23856377601623535, "timer/agent.report_min": 0.23183584213256836, "timer/agent.report_max": 0.24529170989990234, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0517578125e-05, "timer/dataset_eval_frac": 3.051286173427865e-08, "timer/dataset_eval_avg": 3.0517578125e-05, "timer/dataset_eval_min": 3.0517578125e-05, "timer/dataset_eval_max": 3.0517578125e-05, "fps": 8.730521536930139}
{"step": 332832, "time": 38244.89278936386, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 333192, "time": 38285.97519636154, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 333512, "time": 38322.43529820442, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 333680, "time": 38341.559851169586, "episode/length": 225.0, "episode/score": 0.296875, "episode/reward_rate": 0.004424778761061947, "episode/intrinsic_return": 0.0}
{"step": 333832, "time": 38358.99986743927, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 334072, "time": 38386.53541088104, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 334104, "time": 38390.236255168915, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 334136, "time": 38393.91425347328, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 334152, "time": 38395.74868798256, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 334376, "time": 38421.406829833984, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 334448, "time": 38429.62792754173, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 334640, "time": 38451.634076833725, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 334848, "time": 38475.453090667725, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 334888, "time": 38480.04098558426, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 335552, "time": 38555.66889643669, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 335632, "time": 38564.877714157104, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 335832, "time": 38587.59426856041, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 336128, "time": 38621.818120718, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 336144, "time": 38623.64122343063, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 336384, "time": 38650.946105480194, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 336416, "time": 38654.635370731354, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 336464, "time": 38660.07900261879, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 336504, "time": 38664.65398836136, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 336616, "time": 38677.40677142143, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 336680, "time": 38684.81720972061, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 336760, "time": 38693.91916465759, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 337200, "time": 38744.15874505043, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 337240, "time": 38748.75392770767, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 337584, "time": 38788.05704283714, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 337792, "time": 38811.79137444496, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 337896, "time": 38823.63565778732, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 337960, "time": 38830.95910906792, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 338072, "time": 38843.7215616703, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 338304, "time": 38870.127992391586, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 338344, "time": 38874.66139626503, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 338440, "time": 38885.54413318634, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 338632, "time": 38907.39415359497, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 338784, "time": 38924.78458786011, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 338816, "time": 38928.46256709099, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 338848, "time": 38932.12338232994, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 338928, "time": 38941.22380065918, "episode/length": 17.0, "episode/score": 0.9468749761581421, "episode/reward_rate": 0.05555555555555555, "episode/intrinsic_return": 0.0}
{"step": 339152, "time": 38966.79342675209, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 339208, "time": 38973.171046972275, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 339304, "time": 38984.15880036354, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 339512, "time": 39007.81423521042, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 339864, "time": 39048.00061774254, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 339864, "time": 39048.006670713425, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 340016, "time": 39065.31724882126, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 340080, "time": 39074.078615665436, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 340080, "time": 39074.24985766411, "eval_episode/length": 93.0, "eval_episode/score": 0.7093750238418579, "eval_episode/reward_rate": 0.010638297872340425}
{"step": 340080, "time": 39074.65586400032, "eval_episode/length": 117.0, "eval_episode/score": 0.6343749761581421, "eval_episode/reward_rate": 0.00847457627118644}
{"step": 340080, "time": 39075.06306266785, "eval_episode/length": 140.0, "eval_episode/score": 0.5625, "eval_episode/reward_rate": 0.0070921985815602835}
{"step": 340080, "time": 39075.13878560066, "eval_episode/length": 60.0, "eval_episode/score": 0.8125, "eval_episode/reward_rate": 0.01639344262295082}
{"step": 340080, "time": 39075.71957230568, "eval_episode/length": 178.0, "eval_episode/score": 0.4437499940395355, "eval_episode/reward_rate": 0.00558659217877095}
{"step": 340080, "time": 39076.36634397507, "eval_episode/length": 216.0, "eval_episode/score": 0.32499998807907104, "eval_episode/reward_rate": 0.004608294930875576}
{"step": 340080, "time": 39076.59586024284, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 340424, "time": 39115.57072067261, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 340464, "time": 39120.12446451187, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 340600, "time": 39135.69294118881, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 340656, "time": 39142.050651073456, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 341464, "time": 39234.037521362305, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 341472, "time": 39234.94788122177, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 341472, "time": 39234.95501089096, "episode/length": 282.0, "episode/score": 0.11874999850988388, "episode/reward_rate": 0.0035335689045936395, "episode/intrinsic_return": 0.0}
{"step": 341509, "time": 39240.03293323517, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.113702336582569, "train/action_min": 0.0, "train/action_std": 1.645697279260793, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.008240787710763788, "train/actor_opt_grad_steps": 83895.0, "train/actor_opt_loss": -14.414233008655932, "train/adv_mag": 0.5482655598209538, "train/adv_max": 0.211387829769642, "train/adv_mean": -0.0006587209543152838, "train/adv_min": -0.5161369631596662, "train/adv_std": 0.01884658917049886, "train/cont_avg": 0.9960220756880734, "train/cont_loss_mean": 0.011440957922044151, "train/cont_loss_std": 0.18691872557787514, "train/cont_neg_acc": 0.40799373124921046, "train/cont_neg_loss": 2.3355844331602023, "train/cont_pos_acc": 0.9999279954017849, "train/cont_pos_loss": 0.002295588215795952, "train/cont_pred": 0.9961317703811401, "train/cont_rate": 0.9960220756880734, "train/dyn_loss_mean": 1.0000000995233518, "train/dyn_loss_std": 3.1798783745274906e-06, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.08667157561338823, "train/extr_critic_critic_opt_grad_steps": 83895.0, "train/extr_critic_critic_opt_loss": 5557.439868612027, "train/extr_critic_mag": 0.9876792343384629, "train/extr_critic_max": 0.9876792343384629, "train/extr_critic_mean": 0.8665561285040794, "train/extr_critic_min": 0.709126448412554, "train/extr_critic_std": 0.023836770556320292, "train/extr_return_normed_mag": 0.5683893698071121, "train/extr_return_normed_max": 0.24798970293561254, "train/extr_return_normed_mean": 0.0378970975278441, "train/extr_return_normed_min": -0.5041230162349316, "train/extr_return_normed_std": 0.030888147566706763, "train/extr_return_rate": 0.9994281330786714, "train/extr_return_raw_mag": 1.0759899772088461, "train/extr_return_raw_max": 1.0759899772088461, "train/extr_return_raw_mean": 0.8658974157014024, "train/extr_return_raw_min": 0.3238772580383021, "train/extr_return_raw_std": 0.030888147566706763, "train/extr_reward_mag": 0.2901244398650773, "train/extr_reward_max": 0.2901244398650773, "train/extr_reward_mean": 0.0006568692730704468, "train/extr_reward_min": 0.0, "train/extr_reward_std": 0.006274605845955602, "train/image_loss_mean": 0.07225634063670941, "train/image_loss_std": 0.09758538523808531, "train/model_loss_mean": 0.6884022847228094, "train/model_loss_std": 0.29480218784798173, "train/model_opt_grad_norm": 14.689264745887266, "train/model_opt_grad_steps": 83820.05963302753, "train/model_opt_loss": 3679.435764137758, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5344.036697247707, "train/policy_entropy_mag": 1.4309811788961428, "train/policy_entropy_max": 1.4309811788961428, "train/policy_entropy_mean": 0.10907533265855335, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.14415539073151187, "train/policy_logprob_mag": 6.551080246584131, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.10848743988013049, "train/policy_logprob_min": -6.551080246584131, "train/policy_logprob_std": 0.6442675872133412, "train/policy_randomness_mag": 0.7353788994321035, "train/policy_randomness_max": 0.7353788994321035, "train/policy_randomness_mean": 0.05605363586080184, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.07408122057009728, "train/post_ent_mag": 42.13597246922484, "train/post_ent_max": 42.13597246922484, "train/post_ent_mean": 41.05809600200128, "train/post_ent_min": 40.10480005806739, "train/post_ent_std": 0.4189584164991291, "train/prior_ent_mag": 41.42701547955154, "train/prior_ent_max": 41.42701547955154, "train/prior_ent_mean": 40.42907214383467, "train/prior_ent_min": 39.29527426203457, "train/prior_ent_std": 0.3391324712322393, "train/rep_loss_mean": 1.0000000995233518, "train/rep_loss_std": 3.1798783745274906e-06, "train/reward_avg": 0.0007104296174483511, "train/reward_loss_mean": 0.004704905730467119, "train/reward_loss_std": 0.09957799789711508, "train/reward_max_data": 0.4605504595631853, "train/reward_max_pred": 0.1955934916067561, "train/reward_neg_acc": 0.9998071398756919, "train/reward_neg_loss": 0.0007803558757520119, "train/reward_pos_acc": 0.31388888974984486, "train/reward_pos_loss": 3.3377615183591844, "train/reward_pred": 0.0005326767637898479, "train/reward_rate": 0.0011647075688073394, "train_stats/mean_log_entropy": 0.06910629827867855, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.0017396773910149932, "report/cont_loss_std": 0.02347537688910961, "report/cont_neg_acc": 0.800000011920929, "report/cont_neg_loss": 0.15070541203022003, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0010087365517392755, "report/cont_pred": 0.9946411848068237, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.06676718592643738, "report/image_loss_std": 0.09504005312919617, "report/model_loss_mean": 0.6705430746078491, "report/model_loss_std": 0.115980364382267, "report/post_ent_mag": 42.04044723510742, "report/post_ent_max": 42.04044723510742, "report/post_ent_mean": 40.935516357421875, "report/post_ent_min": 40.05230712890625, "report/post_ent_std": 0.40349629521369934, "report/prior_ent_mag": 41.537200927734375, "report/prior_ent_max": 41.537200927734375, "report/prior_ent_mean": 40.728755950927734, "report/prior_ent_min": 39.78696823120117, "report/prior_ent_std": 0.31287577748298645, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0010223388671875, "report/reward_loss_mean": 0.0020361701026558876, "report/reward_loss_std": 0.041813090443611145, "report/reward_max_data": 0.637499988079071, "report/reward_max_pred": 0.38458001613616943, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00032643094891682267, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.8757128119468689, "report/reward_pred": 0.000769173027947545, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.026035359129309654, "eval/cont_loss_std": 0.4766251742839813, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 10.129009246826172, "eval/cont_pos_acc": 0.9990215301513672, "eval/cont_pos_loss": 0.006264376919716597, "eval/cont_pred": 0.9975095987319946, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.13278082013130188, "eval/image_loss_std": 0.14158451557159424, "eval/model_loss_mean": 0.7693859934806824, "eval/model_loss_std": 0.7316569089889526, "eval/post_ent_mag": 42.035186767578125, "eval/post_ent_max": 42.035186767578125, "eval/post_ent_mean": 40.922576904296875, "eval/post_ent_min": 39.965850830078125, "eval/post_ent_std": 0.4153525233268738, "eval/prior_ent_mag": 41.58830642700195, "eval/prior_ent_max": 41.58830642700195, "eval/prior_ent_mean": 40.71924591064453, "eval/prior_ent_min": 39.73430633544922, "eval/prior_ent_std": 0.29557719826698303, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0002532959042582661, "eval/reward_loss_mean": 0.010569790378212929, "eval/reward_loss_std": 0.3233337700366974, "eval/reward_max_data": 0.2593750059604645, "eval/reward_max_pred": 0.09119522571563721, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0004622661217581481, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 10.350566864013672, "eval/reward_pred": 0.0002052108757197857, "eval/reward_rate": 0.0009765625, "replay/size": 341005.0, "replay/inserts": 8724.0, "replay/samples": 34896.0, "replay/insert_wait_avg": 1.5592312714420617e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.405009416198031e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 80616.0, "eval_replay/inserts": 1832.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.060390055960443e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.152557373046875e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3003072738647, "timer/env.step_count": 1090.0, "timer/env.step_total": 10.764644145965576, "timer/env.step_frac": 0.010761412415540132, "timer/env.step_avg": 0.00987582031739961, "timer/env.step_min": 0.008616924285888672, "timer/env.step_max": 0.03535580635070801, "timer/replay._sample_count": 34896.0, "timer/replay._sample_total": 18.866722106933594, "timer/replay._sample_frac": 0.018861057994025203, "timer/replay._sample_avg": 0.0005406557229176293, "timer/replay._sample_min": 0.0003936290740966797, "timer/replay._sample_max": 0.02637624740600586, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1319.0, "timer/agent.policy_total": 13.40493106842041, "timer/agent.policy_frac": 0.013400906678668424, "timer/agent.policy_avg": 0.010162950013965437, "timer/agent.policy_min": 0.008608579635620117, "timer/agent.policy_max": 0.03699088096618652, "timer/dataset_train_count": 2181.0, "timer/dataset_train_total": 0.40894651412963867, "timer/dataset_train_frac": 0.0004088237413863717, "timer/dataset_train_avg": 0.00018750413302596913, "timer/dataset_train_min": 9.512901306152344e-05, "timer/dataset_train_max": 0.023331165313720703, "timer/agent.train_count": 2181.0, "timer/agent.train_total": 971.3621060848236, "timer/agent.train_frac": 0.971070486554276, "timer/agent.train_avg": 0.44537464744833727, "timer/agent.train_min": 0.43378186225891113, "timer/agent.train_max": 0.5848643779754639, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4729771614074707, "timer/agent.report_frac": 0.0004728351655679116, "timer/agent.report_avg": 0.23648858070373535, "timer/agent.report_min": 0.23063898086547852, "timer/agent.report_max": 0.2423381805419922, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0994415283203125e-05, "timer/dataset_eval_frac": 3.098511022921979e-08, "timer/dataset_eval_avg": 3.0994415283203125e-05, "timer/dataset_eval_min": 3.0994415283203125e-05, "timer/dataset_eval_max": 3.0994415283203125e-05, "fps": 8.721258808024102}
{"step": 341824, "time": 39275.94861769676, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 342104, "time": 39307.92758893967, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 342176, "time": 39316.26672697067, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 342328, "time": 39333.60967540741, "episode/length": 208.0, "episode/score": 0.3499999940395355, "episode/reward_rate": 0.004784688995215311, "episode/intrinsic_return": 0.0}
{"step": 342656, "time": 39371.138456344604, "episode/length": 278.0, "episode/score": 0.13124999403953552, "episode/reward_rate": 0.0035842293906810036, "episode/intrinsic_return": 0.0}
{"step": 342776, "time": 39384.795677900314, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 343080, "time": 39419.53427147865, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 343632, "time": 39482.68614935875, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 343776, "time": 39499.2098300457, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 343784, "time": 39500.122795820236, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 343816, "time": 39503.77702498436, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.0}
{"step": 344136, "time": 39540.74125480652, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 344256, "time": 39554.469408512115, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 344360, "time": 39566.32881617546, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 344632, "time": 39597.4248816967, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 344640, "time": 39598.356035232544, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 344968, "time": 39635.72681927681, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 345000, "time": 39639.39235019684, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 345120, "time": 39653.13196396828, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 345480, "time": 39694.181557416916, "episode/length": 207.0, "episode/score": 0.3531250059604645, "episode/reward_rate": 0.004807692307692308, "episode/intrinsic_return": 0.0}
{"step": 345608, "time": 39708.800592660904, "episode/length": 227.0, "episode/score": 0.2906250059604645, "episode/reward_rate": 0.0043859649122807015, "episode/intrinsic_return": 0.0}
{"step": 346192, "time": 39775.508699178696, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 346448, "time": 39804.65428686142, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 346504, "time": 39811.011322021484, "episode/length": 233.0, "episode/score": 0.2718749940395355, "episode/reward_rate": 0.004273504273504274, "episode/intrinsic_return": 0.0}
{"step": 346568, "time": 39818.29107379913, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 346632, "time": 39825.61547613144, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 346760, "time": 39840.16251254082, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 347280, "time": 39899.483615875244, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 347432, "time": 39916.83237242699, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 347720, "time": 39949.715937137604, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 347920, "time": 39972.552334070206, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 348760, "time": 40068.314344882965, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 348816, "time": 40074.679458618164, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 348816, "time": 40074.68800616264, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 348880, "time": 40081.983172655106, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 348944, "time": 40089.27492451668, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 349072, "time": 40103.93806266785, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 349368, "time": 40137.67055916786, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 349592, "time": 40163.209600925446, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 350032, "time": 40213.36817789078, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 350064, "time": 40217.8912653923, "eval_episode/length": 50.0, "eval_episode/score": 0.84375, "eval_episode/reward_rate": 0.0196078431372549}
{"step": 350064, "time": 40218.40570187569, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 350064, "time": 40219.5046851635, "eval_episode/length": 108.0, "eval_episode/score": 0.6625000238418579, "eval_episode/reward_rate": 0.009174311926605505}
{"step": 350064, "time": 40220.154592990875, "eval_episode/length": 146.0, "eval_episode/score": 0.543749988079071, "eval_episode/reward_rate": 0.006802721088435374}
{"step": 350064, "time": 40221.077773571014, "eval_episode/length": 200.0, "eval_episode/score": 0.375, "eval_episode/reward_rate": 0.004975124378109453}
{"step": 350064, "time": 40221.34327316284, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 350064, "time": 40221.48702502251, "eval_episode/length": 114.0, "eval_episode/score": 0.643750011920929, "eval_episode/reward_rate": 0.008695652173913044}
{"step": 350064, "time": 40221.61316728592, "eval_episode/length": 29.0, "eval_episode/score": 0.909375011920929, "eval_episode/reward_rate": 0.03333333333333333}
{"step": 350152, "time": 40231.615262031555, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 350152, "time": 40231.621329545975, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 350200, "time": 40237.096600055695, "episode/length": 284.0, "episode/score": 0.11249999701976776, "episode/reward_rate": 0.0035087719298245615, "episode/intrinsic_return": 0.0}
{"step": 350221, "time": 40240.334087371826, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.8950396896502295, "train/action_min": 0.0, "train/action_std": 1.614226673174342, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.007899906186156248, "train/actor_opt_grad_steps": 86075.0, "train/actor_opt_loss": -13.563067670262187, "train/adv_mag": 0.5681999463827239, "train/adv_max": 0.23693588458069967, "train/adv_mean": 4.814557663798909e-05, "train/adv_min": -0.5233807428440916, "train/adv_std": 0.019841237170963522, "train/cont_avg": 0.9957532970183486, "train/cont_loss_mean": 0.011651105835922746, "train/cont_loss_std": 0.18632471567306053, "train/cont_neg_acc": 0.450010980191868, "train/cont_neg_loss": 2.115898898940572, "train/cont_pos_acc": 0.9998604906808346, "train/cont_pos_loss": 0.0025025508681594164, "train/cont_pred": 0.9957513371738819, "train/cont_rate": 0.9957532970183486, "train/dyn_loss_mean": 1.0000076239262152, "train/dyn_loss_std": 0.00010921252656988628, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.10323105491014249, "train/extr_critic_critic_opt_grad_steps": 86075.0, "train/extr_critic_critic_opt_loss": 7851.406928666141, "train/extr_critic_mag": 0.9570123465783006, "train/extr_critic_max": 0.9570123465783006, "train/extr_critic_mean": 0.8361391214602584, "train/extr_critic_min": 0.6965618833489374, "train/extr_critic_std": 0.022582034939267765, "train/extr_return_normed_mag": 0.5892801979266176, "train/extr_return_normed_max": 0.2860347822718664, "train/extr_return_normed_mean": 0.03433959255285493, "train/extr_return_normed_min": -0.510272392439186, "train/extr_return_normed_std": 0.031082750080204613, "train/extr_return_rate": 0.999312260282149, "train/extr_return_raw_mag": 1.0878825163075683, "train/extr_return_raw_max": 1.0878825163075683, "train/extr_return_raw_mean": 0.8361873711467883, "train/extr_return_raw_min": 0.2915753413231001, "train/extr_return_raw_std": 0.031082750011850662, "train/extr_reward_mag": 0.3305606880319228, "train/extr_reward_max": 0.3305606880319228, "train/extr_reward_mean": 0.001012713993753204, "train/extr_reward_min": 1.6404948103318522e-09, "train/extr_reward_std": 0.007647524670048386, "train/image_loss_mean": 0.07150764920569341, "train/image_loss_std": 0.0969900524055739, "train/model_loss_mean": 0.6879386040595693, "train/model_loss_std": 0.2925174234930528, "train/model_opt_grad_norm": 14.56703427734725, "train/model_opt_grad_steps": 85998.08256880734, "train/model_opt_loss": 3832.418474949828, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5573.394495412844, "train/policy_entropy_mag": 1.4032458608303595, "train/policy_entropy_max": 1.4032458608303595, "train/policy_entropy_mean": 0.09988438324370516, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.12931302179573873, "train/policy_logprob_mag": 6.551080255333437, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.0992221926945612, "train/policy_logprob_min": -6.551080255333437, "train/policy_logprob_std": 0.6348914774732852, "train/policy_randomness_mag": 0.721125762670412, "train/policy_randomness_max": 0.721125762670412, "train/policy_randomness_mean": 0.0513304225724498, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06645375103988779, "train/post_ent_mag": 41.65599961237076, "train/post_ent_max": 41.65599961237076, "train/post_ent_mean": 40.492602969528335, "train/post_ent_min": 39.451836489756175, "train/post_ent_std": 0.4527250027984654, "train/prior_ent_mag": 41.563583933979, "train/prior_ent_max": 41.563583933979, "train/prior_ent_mean": 40.413317076656796, "train/prior_ent_min": 39.16543775086009, "train/prior_ent_std": 0.37872859425500993, "train/rep_loss_mean": 1.0000076239262152, "train/rep_loss_std": 0.00010921252656988628, "train/reward_avg": 0.0006703647991552641, "train/reward_loss_mean": 0.004775254841661081, "train/reward_loss_std": 0.10152600753578195, "train/reward_max_data": 0.4698824532193328, "train/reward_max_pred": 0.1906427068447848, "train/reward_neg_acc": 0.9998026438262484, "train/reward_neg_loss": 0.0008970322961189545, "train/reward_pos_acc": 0.315734990450166, "train/reward_pos_loss": 3.292193960514128, "train/reward_pred": 0.0005637026170841119, "train/reward_rate": 0.0011691872133027523, "train_stats/mean_log_entropy": 0.08006428511336793, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.006071631330996752, "report/cont_loss_std": 0.09004560858011246, "report/cont_neg_acc": 0.800000011920929, "report/cont_neg_loss": 0.6529288291931152, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.002897651167586446, "report/cont_pred": 0.9937100410461426, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07416558265686035, "report/image_loss_std": 0.10270648449659348, "report/model_loss_mean": 0.6826735734939575, "report/model_loss_std": 0.14089737832546234, "report/post_ent_mag": 41.28715133666992, "report/post_ent_max": 41.28715133666992, "report/post_ent_mean": 40.244972229003906, "report/post_ent_min": 39.44376754760742, "report/post_ent_std": 0.3866683542728424, "report/prior_ent_mag": 40.4638671875, "report/prior_ent_max": 40.4638671875, "report/prior_ent_mean": 38.79031753540039, "report/prior_ent_min": 37.0800895690918, "report/prior_ent_std": 0.5884883403778076, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0006805419689044356, "report/reward_loss_mean": 0.002436358015984297, "report/reward_loss_std": 0.030056027695536613, "report/reward_max_data": 0.4937500059604645, "report/reward_max_pred": 0.4581340551376343, "report/reward_neg_acc": 0.9990215301513672, "report/reward_neg_loss": 0.00125601957552135, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6055892109870911, "report/reward_pred": 0.001177163445390761, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.04438336566090584, "eval/cont_loss_std": 0.665719211101532, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 9.65510368347168, "eval/cont_pos_acc": 0.9990195631980896, "eval/cont_pos_loss": 0.006694268435239792, "eval/cont_pred": 0.997597873210907, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.16187728941440582, "eval/image_loss_std": 0.15215937793254852, "eval/model_loss_mean": 0.8118746280670166, "eval/model_loss_std": 0.7267035245895386, "eval/post_ent_mag": 41.302032470703125, "eval/post_ent_max": 41.302032470703125, "eval/post_ent_mean": 40.29204177856445, "eval/post_ent_min": 39.3909797668457, "eval/post_ent_std": 0.44311678409576416, "eval/prior_ent_mag": 40.65558624267578, "eval/prior_ent_max": 40.65558624267578, "eval/prior_ent_mean": 38.823795318603516, "eval/prior_ent_min": 37.12384796142578, "eval/prior_ent_std": 0.658597469329834, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0003173828008584678, "eval/reward_loss_mean": 0.0056139519438147545, "eval/reward_loss_std": 0.16789554059505463, "eval/reward_max_data": 0.32499998807907104, "eval/reward_max_pred": 0.018899917602539062, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00036550196819007397, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.374778747558594, "eval/reward_pred": 0.00018754310440272093, "eval/reward_rate": 0.0009765625, "replay/size": 349717.0, "replay/inserts": 8712.0, "replay/samples": 34848.0, "replay/insert_wait_avg": 1.579577819922301e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.479110368355575e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 82464.0, "eval_replay/inserts": 1848.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1639677600943164e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.238719940185547e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2861812114716, "timer/env.step_count": 1089.0, "timer/env.step_total": 10.774614572525024, "timer/env.step_frac": 0.010771531962458603, "timer/env.step_avg": 0.009894044602869627, "timer/env.step_min": 0.008641958236694336, "timer/env.step_max": 0.034780263900756836, "timer/replay._sample_count": 34848.0, "timer/replay._sample_total": 18.952117204666138, "timer/replay._sample_frac": 0.018946695016532924, "timer/replay._sample_avg": 0.0005438509298859659, "timer/replay._sample_min": 0.0003809928894042969, "timer/replay._sample_max": 0.023879289627075195, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1320.0, "timer/agent.policy_total": 13.849266052246094, "timer/agent.policy_frac": 0.0138453037864353, "timer/agent.policy_avg": 0.010491868221398555, "timer/agent.policy_min": 0.008751153945922852, "timer/agent.policy_max": 0.08121609687805176, "timer/dataset_train_count": 2178.0, "timer/dataset_train_total": 0.3741316795349121, "timer/dataset_train_frac": 0.00037402464071011347, "timer/dataset_train_avg": 0.0001717776306404555, "timer/dataset_train_min": 9.202957153320312e-05, "timer/dataset_train_max": 0.0006892681121826172, "timer/agent.train_count": 2178.0, "timer/agent.train_total": 970.7630753517151, "timer/agent.train_frac": 0.9704853406812035, "timer/agent.train_avg": 0.4457130740825138, "timer/agent.train_min": 0.43585968017578125, "timer/agent.train_max": 0.5905625820159912, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.46329784393310547, "timer/agent.report_frac": 0.0004631652947279486, "timer/agent.report_avg": 0.23164892196655273, "timer/agent.report_min": 0.2221536636352539, "timer/agent.report_max": 0.24114418029785156, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.24249267578125e-05, "timer/dataset_eval_frac": 3.2415650007822625e-08, "timer/dataset_eval_avg": 3.24249267578125e-05, "timer/dataset_eval_min": 3.24249267578125e-05, "timer/dataset_eval_max": 3.24249267578125e-05, "fps": 8.709386347689744}
{"step": 350312, "time": 40250.62896132469, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 350392, "time": 40259.7273004055, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 350600, "time": 40283.52248215675, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 350944, "time": 40322.69558405876, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.0}
{"step": 351024, "time": 40331.8528342247, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 351072, "time": 40337.305072784424, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 351144, "time": 40345.491032123566, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 351632, "time": 40401.277433633804, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 352064, "time": 40450.67451548576, "episode/length": 238.0, "episode/score": 0.2562499940395355, "episode/reward_rate": 0.0041841004184100415, "episode/intrinsic_return": 0.0}
{"step": 352344, "time": 40483.15051364899, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 352360, "time": 40484.98542404175, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 352392, "time": 40488.61188340187, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 352912, "time": 40548.10651469231, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 353256, "time": 40587.404868364334, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 353336, "time": 40596.50890016556, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 353384, "time": 40602.0697684288, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 353408, "time": 40604.81997847557, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 353456, "time": 40610.28439474106, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 354656, "time": 40747.349179029465, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 354672, "time": 40749.174563884735, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 355224, "time": 40812.26050925255, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 355344, "time": 40825.94496130943, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 355568, "time": 40851.54489946365, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 355648, "time": 40860.64464569092, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 355696, "time": 40866.10004711151, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 355720, "time": 40868.835836172104, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 355768, "time": 40874.42829632759, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 356984, "time": 41012.90586519241, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 357536, "time": 41076.000348329544, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 357656, "time": 41089.782200574875, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 357880, "time": 41115.51348400116, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 357960, "time": 41124.63181948662, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 358008, "time": 41130.087998867035, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 358032, "time": 41132.80535578728, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 358080, "time": 41138.28989601135, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 358448, "time": 41180.388976335526, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 358888, "time": 41230.82115936279, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 358965, "time": 41240.53747630119, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.9032113410566494, "train/action_min": 0.0, "train/action_std": 1.7801918635085292, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.009666878030503586, "train/actor_opt_grad_steps": 88260.0, "train/actor_opt_loss": -15.044420391729433, "train/adv_mag": 0.6120200619849985, "train/adv_max": 0.2913277715308481, "train/adv_mean": 0.0005984143987571774, "train/adv_min": -0.5709783355939334, "train/adv_std": 0.030741288832741784, "train/cont_avg": 0.9958975456621004, "train/cont_loss_mean": 0.01169730767822446, "train/cont_loss_std": 0.1850409594930062, "train/cont_neg_acc": 0.45306357194524294, "train/cont_neg_loss": 2.158903816440666, "train/cont_pos_acc": 0.999905983334807, "train/cont_pos_loss": 0.0024255481192450887, "train/cont_pred": 0.9959304819912671, "train/cont_rate": 0.9958975456621004, "train/dyn_loss_mean": 1.0000004077066569, "train/dyn_loss_std": 1.0742590343792281e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.16788499580364522, "train/extr_critic_critic_opt_grad_steps": 88260.0, "train/extr_critic_critic_opt_loss": 6618.256931810074, "train/extr_critic_mag": 1.0205403871187881, "train/extr_critic_max": 1.0205403871187881, "train/extr_critic_mean": 0.8702423874646017, "train/extr_critic_min": 0.774453456543352, "train/extr_critic_std": 0.02974143246673558, "train/extr_return_normed_mag": 0.6231093335913741, "train/extr_return_normed_max": 0.37783749952708207, "train/extr_return_normed_mean": 0.04285745885325213, "train/extr_return_normed_min": -0.5109933407883666, "train/extr_return_normed_std": 0.04512475121375088, "train/extr_return_rate": 0.9988305408116345, "train/extr_return_raw_mag": 1.205820804317248, "train/extr_return_raw_max": 1.205820804317248, "train/extr_return_raw_mean": 0.8708408036732782, "train/extr_return_raw_min": 0.3169899640017993, "train/extr_return_raw_std": 0.04512475132431886, "train/extr_reward_mag": 0.40714339741833133, "train/extr_reward_max": 0.40714339741833133, "train/extr_reward_mean": 0.001276698591334843, "train/extr_reward_min": 6.5320158657962325e-09, "train/extr_reward_std": 0.012696854947198641, "train/image_loss_mean": 0.07065890904635055, "train/image_loss_std": 0.09648787434378715, "train/model_loss_mean": 0.6874753119738679, "train/model_loss_std": 0.3002562039110759, "train/model_opt_grad_norm": 14.376654399644345, "train/model_opt_grad_steps": 88181.12785388128, "train/model_opt_loss": 3691.6925656392696, "train/model_opt_model_opt_grad_overflow": 0.0045662100456621, "train/model_opt_model_opt_grad_scale": 5342.465753424657, "train/policy_entropy_mag": 1.3500960711474832, "train/policy_entropy_max": 1.3500960711474832, "train/policy_entropy_mean": 0.09814959876749614, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.12466694421419815, "train/policy_logprob_mag": 6.551080261735612, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09806725433836244, "train/policy_logprob_min": -6.551080261735612, "train/policy_logprob_std": 0.6359939036304003, "train/policy_randomness_mag": 0.6938121729789803, "train/policy_randomness_max": 0.6938121729789803, "train/policy_randomness_mean": 0.050438918530532756, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06406613927521662, "train/post_ent_mag": 41.33167247685123, "train/post_ent_max": 41.33167247685123, "train/post_ent_mean": 40.28807947515897, "train/post_ent_min": 39.39890057637811, "train/post_ent_std": 0.41415620013459087, "train/prior_ent_mag": 40.73868689689462, "train/prior_ent_max": 40.73868689689462, "train/prior_ent_mean": 38.97065370812264, "train/prior_ent_min": 37.299569116879816, "train/prior_ent_std": 0.5886784293880202, "train/rep_loss_mean": 1.0000004077066569, "train/rep_loss_std": 1.0742590343792281e-05, "train/reward_avg": 0.0007289102676494119, "train/reward_loss_mean": 0.005118829845907975, "train/reward_loss_std": 0.10841225625066826, "train/reward_max_data": 0.47480022958288454, "train/reward_max_pred": 0.20717323969488274, "train/reward_neg_acc": 0.9998571429078438, "train/reward_neg_loss": 0.0008411803580480351, "train/reward_pos_acc": 0.29681528791500505, "train/reward_pos_loss": 3.392131134393109, "train/reward_pred": 0.00058373647420901, "train/reward_rate": 0.0012619506278538813, "train_stats/mean_log_entropy": 0.08064874624078339, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 0.011914905160665512, "report/cont_loss_std": 0.20951659977436066, "report/cont_neg_acc": 0.625, "report/cont_neg_loss": 1.2726247310638428, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0019880568142980337, "report/cont_pred": 0.993080735206604, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.054790645837783813, "report/image_loss_std": 0.08098872750997543, "report/model_loss_mean": 0.6804581880569458, "report/model_loss_std": 0.546287477016449, "report/post_ent_mag": 41.49808883666992, "report/post_ent_max": 41.49808883666992, "report/post_ent_mean": 40.426116943359375, "report/post_ent_min": 39.599586486816406, "report/post_ent_std": 0.4379013180732727, "report/prior_ent_mag": 40.82182312011719, "report/prior_ent_max": 40.82182312011719, "report/prior_ent_mean": 39.0504150390625, "report/prior_ent_min": 37.41480255126953, "report/prior_ent_std": 0.6184049248695374, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0009643554221838713, "report/reward_loss_mean": 0.013752593658864498, "report/reward_loss_std": 0.3148781657218933, "report/reward_max_data": 0.5874999761581421, "report/reward_max_pred": 0.05632472038269043, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0005197951686568558, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 6.775712490081787, "report/reward_pred": 0.0002672531409189105, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.017311828210949898, "eval/cont_loss_std": 0.37713614106178284, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 8.233717918395996, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0012327572330832481, "eval/cont_pred": 0.9988088011741638, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.22174349427223206, "eval/image_loss_std": 0.16891805827617645, "eval/model_loss_mean": 0.8392463326454163, "eval/model_loss_std": 0.41428521275520325, "eval/post_ent_mag": 41.51624298095703, "eval/post_ent_max": 41.51624298095703, "eval/post_ent_mean": 40.42169189453125, "eval/post_ent_min": 39.615386962890625, "eval/post_ent_std": 0.4116062819957733, "eval/prior_ent_mag": 40.82182312011719, "eval/prior_ent_max": 40.82182312011719, "eval/prior_ent_mean": 38.94041442871094, "eval/prior_ent_min": 37.38108825683594, "eval/prior_ent_std": 0.6130161285400391, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00019096443429589272, "eval/reward_loss_std": 0.0021786487195640802, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.021992802619934082, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00019096443429589272, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 8.83565517142415e-05, "eval/reward_rate": 0.0, "replay/size": 358461.0, "replay/inserts": 8744.0, "replay/samples": 34976.0, "replay/insert_wait_avg": 1.538187019997306e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.242605262574862e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 82464.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 9.5367431640625e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1910700798035, "timer/env.step_count": 1093.0, "timer/env.step_total": 10.706594228744507, "timer/env.step_frac": 0.010704548909730065, "timer/env.step_avg": 0.009795603137003209, "timer/env.step_min": 0.008533954620361328, "timer/env.step_max": 0.03635549545288086, "timer/replay._sample_count": 34976.0, "timer/replay._sample_total": 19.055683851242065, "timer/replay._sample_frac": 0.01905204357575563, "timer/replay._sample_avg": 0.0005448217020597571, "timer/replay._sample_min": 0.0003476142883300781, "timer/replay._sample_max": 0.04109311103820801, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1093.0, "timer/agent.policy_total": 11.347989320755005, "timer/agent.policy_frac": 0.011345821473740582, "timer/agent.policy_avg": 0.010382423898220498, "timer/agent.policy_min": 0.009420394897460938, "timer/agent.policy_max": 0.04379105567932129, "timer/dataset_train_count": 2186.0, "timer/dataset_train_total": 0.37084484100341797, "timer/dataset_train_frac": 0.00037077399718618657, "timer/dataset_train_avg": 0.00016964539844621133, "timer/dataset_train_min": 9.083747863769531e-05, "timer/dataset_train_max": 0.0004918575286865234, "timer/agent.train_count": 2186.0, "timer/agent.train_total": 975.2957899570465, "timer/agent.train_frac": 0.9751094757117051, "timer/agent.train_avg": 0.4461554391386306, "timer/agent.train_min": 0.436173677444458, "timer/agent.train_max": 0.6151540279388428, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4726393222808838, "timer/agent.report_frac": 0.0004725490322995713, "timer/agent.report_avg": 0.2363196611404419, "timer/agent.report_min": 0.22947216033935547, "timer/agent.report_max": 0.24316716194152832, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8848648071289062e-05, "timer/dataset_eval_frac": 2.8843137010798627e-08, "timer/dataset_eval_avg": 2.8848648071289062e-05, "timer/dataset_eval_min": 2.8848648071289062e-05, "timer/dataset_eval_max": 2.8848648071289062e-05, "fps": 8.742198420606126}
{"step": 359152, "time": 41261.70177435875, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 359264, "time": 41274.44190144539, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 359296, "time": 41278.096090078354, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 359296, "time": 41278.10360574722, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 359360, "time": 41285.391585826874, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 360048, "time": 41364.57293796539, "eval_episode/length": 49.0, "eval_episode/score": 0.846875011920929, "eval_episode/reward_rate": 0.02}
{"step": 360048, "time": 41365.16200590134, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 360048, "time": 41365.4685356617, "eval_episode/length": 49.0, "eval_episode/score": 0.846875011920929, "eval_episode/reward_rate": 0.02}
{"step": 360048, "time": 41366.04095339775, "eval_episode/length": 49.0, "eval_episode/score": 0.846875011920929, "eval_episode/reward_rate": 0.02}
{"step": 360048, "time": 41367.5446434021, "eval_episode/length": 217.0, "eval_episode/score": 0.3218750059604645, "eval_episode/reward_rate": 0.0045871559633027525}
{"step": 360048, "time": 41367.832823991776, "eval_episode/length": 133.0, "eval_episode/score": 0.5843750238418579, "eval_episode/reward_rate": 0.007462686567164179}
{"step": 360048, "time": 41368.2576584816, "eval_episode/length": 124.0, "eval_episode/score": 0.612500011920929, "eval_episode/reward_rate": 0.008}
{"step": 360048, "time": 41368.531869888306, "eval_episode/length": 54.0, "eval_episode/score": 0.831250011920929, "eval_episode/reward_rate": 0.01818181818181818}
{"step": 360056, "time": 41369.44328212738, "episode/length": 261.0, "episode/score": 0.18437500298023224, "episode/reward_rate": 0.003816793893129771, "episode/intrinsic_return": 0.0}
{"step": 360136, "time": 41378.53361582756, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 360392, "time": 41407.70691156387, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 360496, "time": 41419.96742248535, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 360616, "time": 41433.55966877937, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 360664, "time": 41439.00336408615, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 360808, "time": 41455.495148420334, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 361080, "time": 41486.47947096825, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 361096, "time": 41488.29724216461, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 361168, "time": 41496.495033979416, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 361200, "time": 41500.1168115139, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 361200, "time": 41500.12552571297, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 361272, "time": 41508.344789266586, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 361464, "time": 41530.19347882271, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 361608, "time": 41546.71531534195, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 361880, "time": 41577.80386400223, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 362120, "time": 41605.133848428726, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 362320, "time": 41627.99823093414, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 362384, "time": 41635.278336286545, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 362432, "time": 41640.74344420433, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 362800, "time": 41682.67065501213, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 362904, "time": 41694.457426548004, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 362976, "time": 41702.61431646347, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 363024, "time": 41708.05302190781, "episode/length": 242.0, "episode/score": 0.24375000596046448, "episode/reward_rate": 0.00411522633744856, "episode/intrinsic_return": 0.0}
{"step": 363160, "time": 41723.538113832474, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 363432, "time": 41754.51266384125, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 363528, "time": 41765.43365287781, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 363648, "time": 41779.112164497375, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 363656, "time": 41780.01953911781, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 363880, "time": 41805.51831769943, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 363904, "time": 41808.23980641365, "episode/length": 197.0, "episode/score": 0.3843750059604645, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.0}
{"step": 364304, "time": 41853.69857215881, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 364432, "time": 41868.28555774689, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 364464, "time": 41871.93753743172, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 364744, "time": 41903.724069833755, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 364840, "time": 41914.653925418854, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 364960, "time": 41928.31667757034, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 365192, "time": 41954.70302581787, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 365288, "time": 41965.64941692352, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 365544, "time": 41994.93130350113, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 365560, "time": 41996.77514410019, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 365568, "time": 41997.68685722351, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 365608, "time": 42002.240859508514, "episode/length": 7.0, "episode/score": 0.9781249761581421, "episode/reward_rate": 0.125, "episode/intrinsic_return": 0.0}
{"step": 365688, "time": 42011.40489935875, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 365720, "time": 42015.058198690414, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 365744, "time": 42017.800277233124, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 365840, "time": 42028.73368859291, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 366176, "time": 42066.89782190323, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 366288, "time": 42079.65512108803, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 366536, "time": 42107.87085103989, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 366576, "time": 42112.4228682518, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 366928, "time": 42152.59005999565, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 367152, "time": 42178.11306452751, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 367296, "time": 42194.56657099724, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 367544, "time": 42222.83281517029, "episode/length": 224.0, "episode/score": 0.30000001192092896, "episode/reward_rate": 0.0044444444444444444, "episode/intrinsic_return": 0.0}
{"step": 367693, "time": 42240.60735940933, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.6252164228246846, "train/action_min": 0.0, "train/action_std": 1.5371785207625923, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.009340492261941075, "train/actor_opt_grad_steps": 90445.0, "train/actor_opt_loss": -18.20125172553806, "train/adv_mag": 0.6132380385464484, "train/adv_max": 0.28826490509400676, "train/adv_mean": 0.0020635070209407687, "train/adv_min": -0.565589374221793, "train/adv_std": 0.02711198148702126, "train/cont_avg": 0.9957308987958715, "train/cont_loss_mean": 0.012244259355453039, "train/cont_loss_std": 0.19388083942499387, "train/cont_neg_acc": 0.40886731665529963, "train/cont_neg_loss": 2.304908642525359, "train/cont_pos_acc": 0.9999010054343337, "train/cont_pos_loss": 0.0023622447395176037, "train/cont_pred": 0.9959329648302235, "train/cont_rate": 0.9957308987958715, "train/dyn_loss_mean": 1.0000025296429975, "train/dyn_loss_std": 8.091965979691424e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.15233885780523676, "train/extr_critic_critic_opt_grad_steps": 90445.0, "train/extr_critic_critic_opt_loss": 7484.709430099627, "train/extr_critic_mag": 1.0135127278642917, "train/extr_critic_max": 1.0135127278642917, "train/extr_critic_mean": 0.8883732778763552, "train/extr_critic_min": 0.7457010636635877, "train/extr_critic_std": 0.033215131849870766, "train/extr_return_normed_mag": 0.6254321574617964, "train/extr_return_normed_max": 0.35540972362964524, "train/extr_return_normed_mean": 0.053055341876701474, "train/extr_return_normed_min": -0.5269635650542898, "train/extr_return_normed_std": 0.04392315977073591, "train/extr_return_rate": 0.9990697642531964, "train/extr_return_raw_mag": 1.1927910649448359, "train/extr_return_raw_max": 1.1927910649448359, "train/extr_return_raw_mean": 0.89043672615235, "train/extr_return_raw_min": 0.31041777626090095, "train/extr_return_raw_std": 0.04392315954858557, "train/extr_reward_mag": 0.37653849321767824, "train/extr_reward_max": 0.37653849321767824, "train/extr_reward_mean": 0.0011613724383188052, "train/extr_reward_min": 0.0, "train/extr_reward_std": 0.009858711540417045, "train/image_loss_mean": 0.07022688373786594, "train/image_loss_std": 0.09640490314965948, "train/model_loss_mean": 0.6876836233182785, "train/model_loss_std": 0.30721338035179935, "train/model_opt_grad_norm": 14.470797897478857, "train/model_opt_grad_steps": 90364.08256880734, "train/model_opt_loss": 3688.321939730863, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5366.972477064221, "train/policy_entropy_mag": 1.3038485400173643, "train/policy_entropy_max": 1.3038485400173643, "train/policy_entropy_mean": 0.09187156782237761, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.11248375461735857, "train/policy_logprob_mag": 6.5510802706447215, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09245305484451286, "train/policy_logprob_min": -6.5510802706447215, "train/policy_logprob_std": 0.6325402817594896, "train/policy_randomness_mag": 0.6700456421309655, "train/policy_randomness_max": 0.6700456421309655, "train/policy_randomness_mean": 0.04721264987158666, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.057805218468975586, "train/post_ent_mag": 41.55932981158615, "train/post_ent_max": 41.55932981158615, "train/post_ent_mean": 40.47358187404247, "train/post_ent_min": 39.57149013904257, "train/post_ent_std": 0.4201091563482897, "train/prior_ent_mag": 40.99726976167172, "train/prior_ent_max": 40.99726976167172, "train/prior_ent_mean": 39.136182032593894, "train/prior_ent_min": 37.45631195208348, "train/prior_ent_std": 0.606436674747992, "train/rep_loss_mean": 1.0000025296429975, "train/rep_loss_std": 8.091965979691424e-05, "train/reward_avg": 0.0007794581455394301, "train/reward_loss_mean": 0.0052109440556864055, "train/reward_loss_std": 0.10795203399088302, "train/reward_max_data": 0.4882310798408788, "train/reward_max_pred": 0.21893256027764135, "train/reward_neg_acc": 0.9998519806140059, "train/reward_neg_loss": 0.0008961462969528597, "train/reward_pos_acc": 0.34202454115715497, "train/reward_pos_loss": 3.280061904455255, "train/reward_pred": 0.0006040000813850843, "train/reward_rate": 0.0012901376146788992, "train_stats/mean_log_entropy": 0.07451181045422951, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.013638070784509182, "report/cont_loss_std": 0.252188503742218, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.710356712341309, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0024898943956941366, "report/cont_pred": 0.9975513219833374, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.0488479882478714, "report/image_loss_std": 0.062153104692697525, "report/model_loss_mean": 0.6641161441802979, "report/model_loss_std": 0.25987356901168823, "report/post_ent_mag": 41.82832336425781, "report/post_ent_max": 41.82832336425781, "report/post_ent_mean": 40.73189163208008, "report/post_ent_min": 39.785919189453125, "report/post_ent_std": 0.39080357551574707, "report/prior_ent_mag": 40.95830535888672, "report/prior_ent_max": 40.95830535888672, "report/prior_ent_mean": 39.25243377685547, "report/prior_ent_min": 37.36970138549805, "report/prior_ent_std": 0.6111299395561218, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.0016300964634865522, "report/reward_loss_std": 0.011130829341709614, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.1468815803527832, "report/reward_neg_acc": 0.9990234375, "report/reward_neg_loss": 0.0016300964634865522, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0008163312450051308, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.023938007652759552, "eval/cont_loss_std": 0.42928895354270935, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 7.712093353271484, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0013479324989020824, "eval/cont_pred": 0.9986706972122192, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.1364750862121582, "eval/image_loss_std": 0.1307191699743271, "eval/model_loss_mean": 0.7716377973556519, "eval/model_loss_std": 0.7497340440750122, "eval/post_ent_mag": 41.820953369140625, "eval/post_ent_max": 41.820953369140625, "eval/post_ent_mean": 40.64203643798828, "eval/post_ent_min": 39.87200927734375, "eval/post_ent_std": 0.4084043502807617, "eval/prior_ent_mag": 40.95830535888672, "eval/prior_ent_max": 40.95830535888672, "eval/prior_ent_mean": 39.096031188964844, "eval/prior_ent_min": 37.514564514160156, "eval/prior_ent_std": 0.6321829557418823, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0003723144473042339, "eval/reward_loss_mean": 0.011224709451198578, "eval/reward_loss_std": 0.34286361932754517, "eval/reward_max_data": 0.3812499940395355, "eval/reward_max_pred": 0.031255125999450684, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0005056730005890131, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 10.976799011230469, "eval/reward_pred": 0.00023343681823462248, "eval/reward_rate": 0.0009765625, "replay/size": 367189.0, "replay/inserts": 8728.0, "replay/samples": 34912.0, "replay/insert_wait_avg": 1.5481637225688652e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.446209953860555e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 84648.0, "eval_replay/inserts": 2184.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.083363543499957e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.748603820800781e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0556879043579, "timer/env.step_count": 1091.0, "timer/env.step_total": 10.88878870010376, "timer/env.step_frac": 0.010888182360045863, "timer/env.step_avg": 0.009980557928601063, "timer/env.step_min": 0.008594274520874023, "timer/env.step_max": 0.03521394729614258, "timer/replay._sample_count": 34912.0, "timer/replay._sample_total": 19.218015670776367, "timer/replay._sample_frac": 0.019216945519352234, "timer/replay._sample_avg": 0.0005504702013856659, "timer/replay._sample_min": 0.00040841102600097656, "timer/replay._sample_max": 0.0325465202331543, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1364.0, "timer/agent.policy_total": 14.027246952056885, "timer/agent.policy_frac": 0.014026465847568287, "timer/agent.policy_avg": 0.01028390539007103, "timer/agent.policy_min": 0.008867979049682617, "timer/agent.policy_max": 0.03919672966003418, "timer/dataset_train_count": 2182.0, "timer/dataset_train_total": 0.3744347095489502, "timer/dataset_train_frac": 0.00037441385922576734, "timer/dataset_train_avg": 0.00017160160840923473, "timer/dataset_train_min": 8.893013000488281e-05, "timer/dataset_train_max": 0.004632711410522461, "timer/agent.train_count": 2182.0, "timer/agent.train_total": 969.9637894630432, "timer/agent.train_frac": 0.9699097772201336, "timer/agent.train_avg": 0.4445296926961701, "timer/agent.train_min": 0.4331057071685791, "timer/agent.train_max": 0.5807950496673584, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47149229049682617, "timer/agent.report_frac": 0.0004714660355413309, "timer/agent.report_avg": 0.23574614524841309, "timer/agent.report_min": 0.22867870330810547, "timer/agent.report_max": 0.2428135871887207, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.1948089599609375e-05, "timer/dataset_eval_frac": 3.19463105765214e-08, "timer/dataset_eval_avg": 3.1948089599609375e-05, "timer/dataset_eval_min": 3.1948089599609375e-05, "timer/dataset_eval_max": 3.1948089599609375e-05, "fps": 8.727400582982172}
{"step": 367920, "time": 42266.31886410713, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 368024, "time": 42278.13430213928, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 368032, "time": 42279.05954122543, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 368152, "time": 42292.84536194801, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 368408, "time": 42322.059151887894, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 368456, "time": 42327.5186457634, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 368848, "time": 42372.65781664848, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 368888, "time": 42377.21035718918, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 369520, "time": 42449.17695426941, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 369624, "time": 42461.01779937744, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 369856, "time": 42487.36870265007, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 369936, "time": 42496.519229888916, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 370032, "time": 42509.23589801788, "eval_episode/length": 104.0, "eval_episode/score": 0.675000011920929, "eval_episode/reward_rate": 0.009523809523809525}
{"step": 370032, "time": 42509.63330388069, "eval_episode/length": 126.0, "eval_episode/score": 0.606249988079071, "eval_episode/reward_rate": 0.007874015748031496}
{"step": 370032, "time": 42510.16327667236, "eval_episode/length": 156.0, "eval_episode/score": 0.512499988079071, "eval_episode/reward_rate": 0.006369426751592357}
{"step": 370032, "time": 42512.098678827286, "eval_episode/length": 269.0, "eval_episode/score": 0.15937499701976776, "eval_episode/reward_rate": 0.003703703703703704}
{"step": 370032, "time": 42512.409720659256, "eval_episode/length": 160.0, "eval_episode/score": 0.5, "eval_episode/reward_rate": 0.006211180124223602}
{"step": 370032, "time": 42512.434475660324, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370032, "time": 42512.44040679932, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370032, "time": 42512.446001291275, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370032, "time": 42512.45170426369, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370208, "time": 42532.576068639755, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 370320, "time": 42545.23921728134, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 370336, "time": 42547.05222439766, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 370344, "time": 42547.95887732506, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 370464, "time": 42561.67182159424, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 370520, "time": 42568.04450368881, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 370720, "time": 42590.85005068779, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 370960, "time": 42618.13260746002, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 371480, "time": 42677.23057317734, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 371528, "time": 42682.67204785347, "episode/length": 208.0, "episode/score": 0.3499999940395355, "episode/reward_rate": 0.004784688995215311, "episode/intrinsic_return": 0.0}
{"step": 371640, "time": 42695.37246608734, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 371688, "time": 42700.78574633598, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 371736, "time": 42706.275289058685, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 372392, "time": 42781.02408361435, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 372456, "time": 42788.346502542496, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 372632, "time": 42808.39633989334, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 372648, "time": 42810.23641228676, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 372656, "time": 42811.14795565605, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 373032, "time": 42854.012724876404, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 373056, "time": 42856.74741315842, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 373272, "time": 42881.372524261475, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 373952, "time": 42959.04348611832, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 373968, "time": 42960.87934231758, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 373976, "time": 42961.7869348526, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 374216, "time": 42989.048676252365, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 374232, "time": 42990.86664581299, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 374488, "time": 43020.013637542725, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 374536, "time": 43025.47133755684, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 374704, "time": 43044.56308937073, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 374752, "time": 43050.004392147064, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 374768, "time": 43051.83082294464, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 374960, "time": 43073.65971159935, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 375344, "time": 43117.276452064514, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 375648, "time": 43151.93310379982, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 375872, "time": 43177.31847333908, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 375880, "time": 43178.25323152542, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 375976, "time": 43189.19075512886, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 376040, "time": 43196.45364713669, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 376048, "time": 43197.3670732975, "episode/length": 259.0, "episode/score": 0.19062499701976776, "episode/reward_rate": 0.0038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 376421, "time": 43240.70289516449, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.615967356830562, "train/action_min": 0.0, "train/action_std": 1.5942367282482461, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.008993152707362326, "train/actor_opt_grad_steps": 92625.0, "train/actor_opt_loss": -16.6588653074492, "train/adv_mag": 0.655852424852345, "train/adv_max": 0.31801184191616305, "train/adv_mean": 0.0005246844493260576, "train/adv_min": -0.6201135091005116, "train/adv_std": 0.02832129891585866, "train/cont_avg": 0.9960041571100917, "train/cont_loss_mean": 0.011817104836238053, "train/cont_loss_std": 0.18540276257415225, "train/cont_neg_acc": 0.42357362882332866, "train/cont_neg_loss": 2.270601834511987, "train/cont_pos_acc": 0.9998920185303469, "train/cont_pos_loss": 0.002573214385363726, "train/cont_pred": 0.995867426789135, "train/cont_rate": 0.9960041571100917, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.1383905802349295, "train/extr_critic_critic_opt_grad_steps": 92625.0, "train/extr_critic_critic_opt_loss": 7636.944636073681, "train/extr_critic_mag": 1.140560782283818, "train/extr_critic_max": 1.140560782283818, "train/extr_critic_mean": 0.9217162249831978, "train/extr_critic_min": 0.753108003817567, "train/extr_critic_std": 0.031218084344349868, "train/extr_return_normed_mag": 0.6779513725446998, "train/extr_return_normed_max": 0.43142352191680067, "train/extr_return_normed_mean": 0.044726677674697624, "train/extr_return_normed_min": -0.5647682643264805, "train/extr_return_normed_std": 0.0434972343094852, "train/extr_return_rate": 0.9992677632274978, "train/extr_return_raw_mag": 1.3089377338733148, "train/extr_return_raw_max": 1.3089377338733148, "train/extr_return_raw_mean": 0.9222409298660559, "train/extr_return_raw_min": 0.3127459476300336, "train/extr_return_raw_std": 0.043497234300940955, "train/extr_reward_mag": 0.4396260495579571, "train/extr_reward_max": 0.4396260495579571, "train/extr_reward_mean": 0.001430379001048838, "train/extr_reward_min": -1.3380969336273474e-05, "train/extr_reward_std": 0.011951336332750634, "train/image_loss_mean": 0.07088709132181942, "train/image_loss_std": 0.09619946148964244, "train/model_loss_mean": 0.6876448338184882, "train/model_loss_std": 0.2947686553650766, "train/model_opt_grad_norm": 14.123829215352986, "train/model_opt_grad_steps": 92542.07798165138, "train/model_opt_loss": 3641.3628971204844, "train/model_opt_model_opt_grad_overflow": 0.0045871559633027525, "train/model_opt_model_opt_grad_scale": 5275.229357798165, "train/policy_entropy_mag": 1.2955425928492066, "train/policy_entropy_max": 1.2955425928492066, "train/policy_entropy_mean": 0.09054602966259379, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.10946561843840354, "train/policy_logprob_mag": 6.551080255333437, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09066464676769502, "train/policy_logprob_min": -6.551080255333437, "train/policy_logprob_std": 0.6292484927614894, "train/policy_randomness_mag": 0.6657772302080732, "train/policy_randomness_max": 0.6657772302080732, "train/policy_randomness_mean": 0.046531457727381945, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.05625420299555184, "train/post_ent_mag": 41.73294433103789, "train/post_ent_max": 41.73294433103789, "train/post_ent_mean": 40.66341142916898, "train/post_ent_min": 39.76662441568637, "train/post_ent_std": 0.41048326760257053, "train/prior_ent_mag": 41.08518575965812, "train/prior_ent_max": 41.08518575965812, "train/prior_ent_mean": 39.30293126937446, "train/prior_ent_min": 37.57499670326163, "train/prior_ent_std": 0.6049622961687385, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0007042841098822414, "train/reward_loss_mean": 0.00494061227927386, "train/reward_loss_std": 0.1027238921266596, "train/reward_max_data": 0.4820097490051471, "train/reward_max_pred": 0.1866103377910929, "train/reward_neg_acc": 0.999829601530635, "train/reward_neg_loss": 0.0009931235299435008, "train/reward_pos_acc": 0.2870726504195959, "train/reward_pos_loss": 3.3780754322233872, "train/reward_pred": 0.0006059471847822701, "train/reward_rate": 0.0011647075688073394, "train_stats/mean_log_entropy": 0.07246430364309572, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.018418164923787117, "report/cont_loss_std": 0.28981178998947144, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.294561386108398, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0029152955394238234, "report/cont_pred": 0.9972970485687256, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07170206308364868, "report/image_loss_std": 0.10085005313158035, "report/model_loss_mean": 0.6922014951705933, "report/model_loss_std": 0.3157670497894287, "report/post_ent_mag": 41.8768310546875, "report/post_ent_max": 41.8768310546875, "report/post_ent_mean": 40.76555633544922, "report/post_ent_min": 39.84449005126953, "report/post_ent_std": 0.3843429386615753, "report/prior_ent_mag": 41.18379211425781, "report/prior_ent_max": 41.18379211425781, "report/prior_ent_mean": 39.335540771484375, "report/prior_ent_min": 37.56794738769531, "report/prior_ent_std": 0.590232789516449, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.002081295009702444, "report/reward_loss_std": 0.025905616581439972, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.36113858222961426, "report/reward_neg_acc": 0.998046875, "report/reward_neg_loss": 0.002081295009702444, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0010450613917782903, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.03008974902331829, "eval/cont_loss_std": 0.5666236281394958, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 9.667998313903809, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0017707243096083403, "eval/cont_pred": 0.9982575178146362, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.16150277853012085, "eval/image_loss_std": 0.16971909999847412, "eval/model_loss_mean": 0.7970846891403198, "eval/model_loss_std": 0.645104706287384, "eval/post_ent_mag": 41.868953704833984, "eval/post_ent_max": 41.868953704833984, "eval/post_ent_mean": 40.74290466308594, "eval/post_ent_min": 39.79277038574219, "eval/post_ent_std": 0.39393213391304016, "eval/prior_ent_mag": 41.13141632080078, "eval/prior_ent_max": 41.13141632080078, "eval/prior_ent_mean": 39.31343078613281, "eval/prior_ent_min": 37.696388244628906, "eval/prior_ent_std": 0.6251099109649658, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0007995605701580644, "eval/reward_loss_mean": 0.005492120049893856, "eval/reward_loss_std": 0.1536833792924881, "eval/reward_max_data": 0.8187500238418579, "eval/reward_max_pred": 0.06573641300201416, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0006899423315189779, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 4.918120384216309, "eval/reward_pred": 0.0003639423521235585, "eval/reward_rate": 0.0009765625, "replay/size": 375917.0, "replay/inserts": 8728.0, "replay/samples": 34912.0, "replay/insert_wait_avg": 1.5405970467655731e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.429137129394644e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 86960.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.048031150263486e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.791685104370117e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0796113014221, "timer/env.step_count": 1091.0, "timer/env.step_total": 10.864023685455322, "timer/env.step_frac": 0.010863158855241301, "timer/env.step_avg": 0.009957858556787647, "timer/env.step_min": 0.00860738754272461, "timer/env.step_max": 0.03494763374328613, "timer/replay._sample_count": 34912.0, "timer/replay._sample_total": 18.978164196014404, "timer/replay._sample_frac": 0.018976653439937416, "timer/replay._sample_avg": 0.0005436000285292851, "timer/replay._sample_min": 0.00039315223693847656, "timer/replay._sample_max": 0.025556325912475586, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1380.0, "timer/agent.policy_total": 13.983709573745728, "timer/agent.policy_frac": 0.01398259640104898, "timer/agent.policy_avg": 0.01013312287952589, "timer/agent.policy_min": 0.008918523788452148, "timer/agent.policy_max": 0.034960269927978516, "timer/dataset_train_count": 2182.0, "timer/dataset_train_total": 0.3787863254547119, "timer/dataset_train_frac": 0.00037875617218292276, "timer/dataset_train_avg": 0.00017359593283900636, "timer/dataset_train_min": 9.393692016601562e-05, "timer/dataset_train_max": 0.0004839897155761719, "timer/agent.train_count": 2182.0, "timer/agent.train_total": 970.0173337459564, "timer/agent.train_frac": 0.9699401155510559, "timer/agent.train_avg": 0.44455423178091497, "timer/agent.train_min": 0.43335509300231934, "timer/agent.train_max": 0.5943748950958252, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4774048328399658, "timer/agent.report_frac": 0.00047736682904544976, "timer/agent.report_avg": 0.2387024164199829, "timer/agent.report_min": 0.23437285423278809, "timer/agent.report_max": 0.24303197860717773, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.2649765014648438e-05, "timer/dataset_eval_frac": 2.2647961980920576e-08, "timer/dataset_eval_avg": 2.2649765014648438e-05, "timer/dataset_eval_min": 2.2649765014648438e-05, "timer/dataset_eval_max": 2.2649765014648438e-05, "fps": 8.727179423695445}
{"step": 376528, "time": 43252.838416576385, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 376848, "time": 43289.784663915634, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 376904, "time": 43296.1926009655, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 376920, "time": 43298.04143738747, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 377080, "time": 43316.341381073, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 377312, "time": 43342.84982705116, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 377736, "time": 43391.2755010128, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 377768, "time": 43394.94261980057, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 378184, "time": 43442.37426161766, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 378192, "time": 43443.28723812103, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 378280, "time": 43453.46722650528, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 378288, "time": 43454.380346775055, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 378552, "time": 43484.45391535759, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 378984, "time": 43533.7230989933, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 378984, "time": 43533.732028484344, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 379216, "time": 43560.123876810074, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 379232, "time": 43561.942046165466, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 379256, "time": 43564.67600488663, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 379824, "time": 43629.520568847656, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 379952, "time": 43644.11520791054, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 380008, "time": 43650.48737549782, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 380016, "time": 43652.79475212097, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 380016, "time": 43654.02273130417, "eval_episode/length": 154.0, "eval_episode/score": 0.518750011920929, "eval_episode/reward_rate": 0.0064516129032258064}
{"step": 380016, "time": 43654.367178440094, "eval_episode/length": 174.0, "eval_episode/score": 0.45625001192092896, "eval_episode/reward_rate": 0.005714285714285714}
{"step": 380016, "time": 43655.56103157997, "eval_episode/length": 245.0, "eval_episode/score": 0.234375, "eval_episode/reward_rate": 0.0040650406504065045}
{"step": 380016, "time": 43655.984045267105, "eval_episode/length": 270.0, "eval_episode/score": 0.15625, "eval_episode/reward_rate": 0.0036900369003690036}
{"step": 380016, "time": 43656.126473903656, "eval_episode/length": 196.0, "eval_episode/score": 0.38749998807907104, "eval_episode/reward_rate": 0.005076142131979695}
{"step": 380016, "time": 43656.30682349205, "eval_episode/length": 288.0, "eval_episode/score": 0.10000000149011612, "eval_episode/reward_rate": 0.0034602076124567475}
{"step": 380016, "time": 43656.31374645233, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380016, "time": 43656.319789648056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380256, "time": 43683.744632959366, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 380496, "time": 43711.07433104515, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 380504, "time": 43711.993418216705, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 380800, "time": 43745.76155900955, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 380928, "time": 43760.3888566494, "episode/length": 242.0, "episode/score": 0.24375000596046448, "episode/reward_rate": 0.00411522633744856, "episode/intrinsic_return": 0.0}
{"step": 381248, "time": 43796.99746751785, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 381272, "time": 43799.717341184616, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 381528, "time": 43828.870123147964, "episode/length": 286.0, "episode/score": 0.10625000298023224, "episode/reward_rate": 0.003484320557491289, "episode/intrinsic_return": 0.0}
{"step": 381824, "time": 43862.64359283447, "episode/length": 226.0, "episode/score": 0.29374998807907104, "episode/reward_rate": 0.004405286343612335, "episode/intrinsic_return": 0.0}
{"step": 381840, "time": 43864.48266649246, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 382264, "time": 43912.8293800354, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 382400, "time": 43928.30978989601, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 382808, "time": 43974.96587562561, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 383112, "time": 44009.72245883942, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 383240, "time": 44024.38407659531, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 383312, "time": 44032.563489198685, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 383416, "time": 44044.45977807045, "episode/length": 235.0, "episode/score": 0.265625, "episode/reward_rate": 0.00423728813559322, "episode/intrinsic_return": 0.0}
{"step": 383712, "time": 44078.309911727905, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 383776, "time": 44085.68663573265, "episode/length": 243.0, "episode/score": 0.24062499403953552, "episode/reward_rate": 0.004098360655737705, "episode/intrinsic_return": 0.0}
{"step": 383904, "time": 44100.25503945351, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 384008, "time": 44112.21211528778, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 384112, "time": 44124.03888940811, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 384120, "time": 44124.970537662506, "episode/length": 284.0, "episode/score": 0.11249999701976776, "episode/reward_rate": 0.0035087719298245615, "episode/intrinsic_return": 0.0}
{"step": 384208, "time": 44134.992007255554, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 384312, "time": 44146.86202645302, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 384616, "time": 44181.54857587814, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 384872, "time": 44210.83316731453, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 384984, "time": 44223.58201766014, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 385125, "time": 44240.9996073246, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.003846334754874, "train/action_min": 0.0, "train/action_std": 1.725081723764402, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.006313987194833884, "train/actor_opt_grad_steps": 94805.0, "train/actor_opt_loss": -14.426721563033007, "train/adv_mag": 0.46787781357218367, "train/adv_max": 0.23011569637771045, "train/adv_mean": -0.0008775079079587658, "train/adv_min": -0.4085675435602118, "train/adv_std": 0.01692059378079865, "train/cont_avg": 0.9959862385321101, "train/cont_loss_mean": 0.012132993139916125, "train/cont_loss_std": 0.1939153748696858, "train/cont_neg_acc": 0.40639906099766765, "train/cont_neg_loss": 2.3859532320473575, "train/cont_pos_acc": 0.9999010521884358, "train/cont_pos_loss": 0.0025780801137977646, "train/cont_pred": 0.9959244205864197, "train/cont_rate": 0.9959862385321101, "train/dyn_loss_mean": 1.000000226388284, "train/dyn_loss_std": 7.250928854005873e-06, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.09759014570624183, "train/extr_critic_critic_opt_grad_steps": 94805.0, "train/extr_critic_critic_opt_loss": 6778.19684677824, "train/extr_critic_mag": 1.0691200194008854, "train/extr_critic_max": 1.0691200194008854, "train/extr_critic_mean": 0.9112548633999781, "train/extr_critic_min": 0.773756110886915, "train/extr_critic_std": 0.02234670624068571, "train/extr_return_normed_mag": 0.5146411681940796, "train/extr_return_normed_max": 0.2970539872799445, "train/extr_return_normed_mean": 0.03377975648217792, "train/extr_return_normed_min": -0.37498370086381194, "train/extr_return_normed_std": 0.028744395489061096, "train/extr_return_rate": 0.9997503585224852, "train/extr_return_raw_mag": 1.1736515429588632, "train/extr_return_raw_max": 1.1736515429588632, "train/extr_return_raw_mean": 0.9103773561639523, "train/extr_return_raw_min": 0.5016138548151069, "train/extr_return_raw_std": 0.028744395574503534, "train/extr_reward_mag": 0.30457519938092714, "train/extr_reward_max": 0.30457519938092714, "train/extr_reward_mean": 0.0010395190687081137, "train/extr_reward_min": 3.2809896206637043e-09, "train/extr_reward_std": 0.007614073221819526, "train/image_loss_mean": 0.07060621511362014, "train/image_loss_std": 0.09643392712561362, "train/model_loss_mean": 0.6881210251685677, "train/model_loss_std": 0.3073504911308442, "train/model_opt_grad_norm": 14.070848992111486, "train/model_opt_grad_steps": 94719.95871559632, "train/model_opt_loss": 3550.702634478928, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5160.5504587155965, "train/policy_entropy_mag": 1.42626775787511, "train/policy_entropy_max": 1.42626775787511, "train/policy_entropy_mean": 0.09237923609827636, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.11795265107936816, "train/policy_logprob_mag": 6.551080244396805, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09233237416782511, "train/policy_logprob_min": -6.551080244396805, "train/policy_logprob_std": 0.6314032550798644, "train/policy_randomness_mag": 0.7329566812296526, "train/policy_randomness_max": 0.7329566812296526, "train/policy_randomness_mean": 0.047473539316326106, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06061567538716924, "train/post_ent_mag": 41.597758056920604, "train/post_ent_max": 41.597758056920604, "train/post_ent_mean": 40.51468619950321, "train/post_ent_min": 39.60815669418475, "train/post_ent_std": 0.41422701661193045, "train/prior_ent_mag": 41.30315294178254, "train/prior_ent_max": 41.30315294178254, "train/prior_ent_mean": 39.40265571524244, "train/prior_ent_min": 37.62898698859259, "train/prior_ent_std": 0.6310546406365316, "train/rep_loss_mean": 1.000000226388284, "train/rep_loss_std": 7.250928854005873e-06, "train/reward_avg": 0.0007627294715248271, "train/reward_loss_mean": 0.005381662296045811, "train/reward_loss_std": 0.10939319332935549, "train/reward_max_data": 0.48440367147463176, "train/reward_max_pred": 0.19276770211141045, "train/reward_neg_acc": 0.9997936848106734, "train/reward_neg_loss": 0.0010639449700055252, "train/reward_pos_acc": 0.3112179501316486, "train/reward_pos_loss": 3.430161457699843, "train/reward_pred": 0.0006276983420637974, "train/reward_rate": 0.0012587801032110091, "train_stats/mean_log_entropy": 0.0734579003587061, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9990234375, "report/cont_loss_mean": 0.00604932801797986, "report/cont_loss_std": 0.12111326307058334, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 3.866849422454834, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0022753302473574877, "report/cont_pred": 0.9977563619613647, "report/cont_rate": 0.9990234375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.06056452915072441, "report/image_loss_std": 0.07855569571256638, "report/model_loss_mean": 0.6673546433448792, "report/model_loss_std": 0.1442430019378662, "report/post_ent_mag": 40.9963264465332, "report/post_ent_max": 40.9963264465332, "report/post_ent_mean": 39.984352111816406, "report/post_ent_min": 38.92045593261719, "report/post_ent_std": 0.4142155647277832, "report/prior_ent_mag": 41.023948669433594, "report/prior_ent_max": 41.023948669433594, "report/prior_ent_mean": 39.24132537841797, "report/prior_ent_min": 37.848304748535156, "report/prior_ent_std": 0.5544618964195251, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.000740742078050971, "report/reward_loss_std": 0.005977196153253317, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.048805952072143555, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.000740742078050971, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00033219309989362955, "report/reward_rate": 0.0, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.034102920442819595, "eval/cont_loss_std": 0.524799644947052, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 7.978780269622803, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.0029473251197487116, "eval/cont_pred": 0.9971168041229248, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.12694653868675232, "eval/image_loss_std": 0.137012779712677, "eval/model_loss_mean": 0.7619683742523193, "eval/model_loss_std": 0.5444676876068115, "eval/post_ent_mag": 41.13458251953125, "eval/post_ent_max": 41.13458251953125, "eval/post_ent_mean": 39.987422943115234, "eval/post_ent_min": 39.06184768676758, "eval/post_ent_std": 0.41548216342926025, "eval/prior_ent_mag": 40.99420928955078, "eval/prior_ent_max": 40.99420928955078, "eval/prior_ent_mean": 39.31196594238281, "eval/prior_ent_min": 37.79041290283203, "eval/prior_ent_std": 0.5787357091903687, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0009189324919134378, "eval/reward_loss_std": 0.005772696807980537, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.06950438022613525, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0009189324919134378, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0004927553236484528, "eval/reward_rate": 0.0, "replay/size": 384621.0, "replay/inserts": 8704.0, "replay/samples": 34816.0, "replay/insert_wait_avg": 1.5561030629803152e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.447635974077617e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 89272.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0661806614753696e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.940696716308594e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.280923128128, "timer/env.step_count": 1088.0, "timer/env.step_total": 10.722827196121216, "timer/env.step_frac": 0.010719815751947222, "timer/env.step_avg": 0.009855539702317295, "timer/env.step_min": 0.00869131088256836, "timer/env.step_max": 0.03442835807800293, "timer/replay._sample_count": 34816.0, "timer/replay._sample_total": 19.01750874519348, "timer/replay._sample_frac": 0.019012167787546108, "timer/replay._sample_avg": 0.0005462289965875886, "timer/replay._sample_min": 0.0003764629364013672, "timer/replay._sample_max": 0.02085256576538086, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1377.0, "timer/agent.policy_total": 13.970057249069214, "timer/agent.policy_frac": 0.01396613383906329, "timer/agent.policy_avg": 0.010145284857711847, "timer/agent.policy_min": 0.008764028549194336, "timer/agent.policy_max": 0.044443607330322266, "timer/dataset_train_count": 2176.0, "timer/dataset_train_total": 0.38336658477783203, "timer/dataset_train_frac": 0.00038325891848356864, "timer/dataset_train_avg": 0.00017617949668098898, "timer/dataset_train_min": 9.512901306152344e-05, "timer/dataset_train_max": 0.00067901611328125, "timer/agent.train_count": 2176.0, "timer/agent.train_total": 970.3132469654083, "timer/agent.train_frac": 0.9700407400862916, "timer/agent.train_avg": 0.4459160142304266, "timer/agent.train_min": 0.43549680709838867, "timer/agent.train_max": 0.6444413661956787, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4733576774597168, "timer/agent.report_frac": 0.00047322473768609847, "timer/agent.report_avg": 0.2366788387298584, "timer/agent.report_min": 0.22898054122924805, "timer/agent.report_max": 0.24437713623046875, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.314018249511719e-05, "timer/dataset_eval_frac": 3.313087526599984e-08, "timer/dataset_eval_avg": 3.314018249511719e-05, "timer/dataset_eval_min": 3.314018249511719e-05, "timer/dataset_eval_max": 3.314018249511719e-05, "fps": 8.70142596493612}
{"step": 385424, "time": 44274.91928625107, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 385496, "time": 44283.13440442085, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 385512, "time": 44284.95828580856, "episode/length": 224.0, "episode/score": 0.30000001192092896, "episode/reward_rate": 0.0044444444444444444, "episode/intrinsic_return": 0.0}
{"step": 385768, "time": 44314.102130651474, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 386072, "time": 44348.79231762886, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 386088, "time": 44350.64125132561, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 386096, "time": 44351.687537670135, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 386112, "time": 44353.50917887688, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 387184, "time": 44475.945510149, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 387304, "time": 44489.62597346306, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 387328, "time": 44492.39763855934, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 387808, "time": 44547.32625865936, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 387824, "time": 44549.15466594696, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 388288, "time": 44602.296449422836, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 388384, "time": 44613.23088431358, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 388400, "time": 44615.078795433044, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 388424, "time": 44617.81608200073, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 388768, "time": 44657.09861278534, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 389480, "time": 44738.48266816139, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 389496, "time": 44740.30979967117, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 389640, "time": 44756.78776502609, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 389744, "time": 44768.60524702072, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 389856, "time": 44781.39235329628, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 389880, "time": 44784.13659238815, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 389896, "time": 44785.95825839043, "episode/length": 4.0, "episode/score": 0.987500011920929, "episode/reward_rate": 0.2, "episode/intrinsic_return": 0.0}
{"step": 390000, "time": 44799.6351044178, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 390000, "time": 44800.752690553665, "eval_episode/length": 130.0, "eval_episode/score": 0.59375, "eval_episode/reward_rate": 0.007633587786259542}
{"step": 390000, "time": 44801.31564974785, "eval_episode/length": 153.0, "eval_episode/score": 0.5218750238418579, "eval_episode/reward_rate": 0.006493506493506494}
{"step": 390000, "time": 44801.93499541283, "eval_episode/length": 188.0, "eval_episode/score": 0.4124999940395355, "eval_episode/reward_rate": 0.005291005291005291}
{"step": 390000, "time": 44802.04506063461, "eval_episode/length": 194.0, "eval_episode/score": 0.39375001192092896, "eval_episode/reward_rate": 0.005128205128205128}
{"step": 390000, "time": 44802.18655490875, "eval_episode/length": 202.0, "eval_episode/score": 0.3687500059604645, "eval_episode/reward_rate": 0.0049261083743842365}
{"step": 390000, "time": 44802.86411476135, "eval_episode/length": 52.0, "eval_episode/score": 0.8374999761581421, "eval_episode/reward_rate": 0.018867924528301886}
{"step": 390000, "time": 44802.92377448082, "eval_episode/length": 176.0, "eval_episode/score": 0.44999998807907104, "eval_episode/reward_rate": 0.005649717514124294}
{"step": 390120, "time": 44816.580891132355, "episode/length": 216.0, "episode/score": 0.32499998807907104, "episode/reward_rate": 0.004608294930875576, "episode/intrinsic_return": 0.0}
{"step": 390136, "time": 44818.398433208466, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 390520, "time": 44862.33732128143, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 390696, "time": 44882.382471084595, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 390736, "time": 44886.97839307785, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 390832, "time": 44898.04445528984, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 390848, "time": 44899.879157304764, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 391040, "time": 44921.83545732498, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 391424, "time": 44965.54262471199, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 391432, "time": 44966.465093135834, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 391952, "time": 45025.840935468674, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 391976, "time": 45028.58168268204, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 392160, "time": 45049.605892658234, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 392248, "time": 45059.64195251465, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 392336, "time": 45069.69756817818, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 392480, "time": 45086.22734618187, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 392832, "time": 45127.39657878876, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 393160, "time": 45164.925166368484, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 393256, "time": 45176.2042222023, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 393736, "time": 45230.89598417282, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 393816, "time": 45240.00410461426, "episode/length": 206.0, "episode/score": 0.35624998807907104, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.0}
{"step": 393821, "time": 45241.44088625908, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.9955871863299253, "train/action_min": 0.0, "train/action_std": 1.7847354670274094, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.006170331306802753, "train/actor_opt_grad_steps": 96980.0, "train/actor_opt_loss": -17.814755154095486, "train/adv_mag": 0.5151593469529657, "train/adv_max": 0.24171127207268217, "train/adv_mean": -0.0005611142481821814, "train/adv_min": -0.473191375968643, "train/adv_std": 0.019801119591371256, "train/cont_avg": 0.9957517281105991, "train/cont_loss_mean": 0.012053847573118172, "train/cont_loss_std": 0.18802518916449376, "train/cont_neg_acc": 0.4188010008117863, "train/cont_neg_loss": 2.2685214262140185, "train/cont_pos_acc": 0.9999231682395056, "train/cont_pos_loss": 0.0025593121573629397, "train/cont_pred": 0.9956820469847473, "train/cont_rate": 0.9957517281105991, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.09621014144735128, "train/extr_critic_critic_opt_grad_steps": 96980.0, "train/extr_critic_critic_opt_loss": 7364.4907429075465, "train/extr_critic_mag": 1.047436044512806, "train/extr_critic_max": 1.047436044512806, "train/extr_critic_mean": 0.8458162829073893, "train/extr_critic_min": 0.7073962336861044, "train/extr_critic_std": 0.03026659475115862, "train/extr_return_normed_mag": 0.5662826766616188, "train/extr_return_normed_max": 0.3608031124563261, "train/extr_return_normed_mean": 0.03723305809710707, "train/extr_return_normed_min": -0.42100398304275655, "train/extr_return_normed_std": 0.03785062546966263, "train/extr_return_rate": 0.999667908738835, "train/extr_return_raw_mag": 1.1688251998018009, "train/extr_return_raw_max": 1.1688251998018009, "train/extr_return_raw_mean": 0.8452551949958098, "train/extr_return_raw_min": 0.3870181043027183, "train/extr_return_raw_std": 0.037850625323741116, "train/extr_reward_mag": 0.3546138584339124, "train/extr_reward_max": 0.3546138584339124, "train/extr_reward_mean": 0.0009721179745183649, "train/extr_reward_min": -1.010806879140265e-07, "train/extr_reward_std": 0.00872488430817075, "train/image_loss_mean": 0.07000600613550656, "train/image_loss_std": 0.09547586042073465, "train/model_loss_mean": 0.6879642336599289, "train/model_loss_std": 0.3104556199798386, "train/model_opt_grad_norm": 14.115308048548522, "train/model_opt_grad_steps": 96892.96774193548, "train/model_opt_loss": 3851.7274670578918, "train/model_opt_model_opt_grad_overflow": 0.004608294930875576, "train/model_opt_model_opt_grad_scale": 5576.036866359447, "train/policy_entropy_mag": 1.3309800591886318, "train/policy_entropy_max": 1.3309800591886318, "train/policy_entropy_mean": 0.09005799879264172, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.10874561958598651, "train/policy_logprob_mag": 6.551080284030756, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09057931509298113, "train/policy_logprob_min": -6.551080284030756, "train/policy_logprob_std": 0.6314324143295464, "train/policy_randomness_mag": 0.6839884873908786, "train/policy_randomness_max": 0.6839884873908786, "train/policy_randomness_mean": 0.046280659666533844, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.05588419695947027, "train/post_ent_mag": 41.42195083688481, "train/post_ent_max": 41.42195083688481, "train/post_ent_mean": 40.340284866122055, "train/post_ent_min": 39.4007435284452, "train/post_ent_std": 0.42767559836537056, "train/prior_ent_mag": 41.178406447309506, "train/prior_ent_max": 41.178406447309506, "train/prior_ent_mean": 39.414437148977534, "train/prior_ent_min": 37.78819426083894, "train/prior_ent_std": 0.5900080600916515, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0008758966796784683, "train/reward_loss_mean": 0.005904358444190348, "train/reward_loss_std": 0.1178769392469975, "train/reward_max_data": 0.5382200457533384, "train/reward_max_pred": 0.238686144626635, "train/reward_neg_acc": 0.9997791911599823, "train/reward_neg_loss": 0.0011119136202131926, "train/reward_pos_acc": 0.3322154483417185, "train/reward_pos_loss": 3.319328915055205, "train/reward_pred": 0.0007408666386899929, "train/reward_rate": 0.0014310915898617512, "train_stats/mean_log_entropy": 0.07686961944336476, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.010611109435558319, "report/cont_loss_std": 0.24548442661762238, "report/cont_neg_acc": 0.5, "report/cont_neg_loss": 3.932145357131958, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0029368726536631584, "report/cont_pred": 0.9962441921234131, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.05399784818291664, "report/image_loss_std": 0.08068022131919861, "report/model_loss_mean": 0.6656285524368286, "report/model_loss_std": 0.2616427540779114, "report/post_ent_mag": 41.13672637939453, "report/post_ent_max": 41.13672637939453, "report/post_ent_mean": 39.888404846191406, "report/post_ent_min": 38.96979522705078, "report/post_ent_std": 0.4383748769760132, "report/prior_ent_mag": 41.58159255981445, "report/prior_ent_max": 41.58159255981445, "report/prior_ent_mean": 39.86589431762695, "report/prior_ent_min": 38.40495681762695, "report/prior_ent_std": 0.5560827255249023, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.0010196231305599213, "report/reward_loss_std": 0.008690175600349903, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.12818169593811035, "report/reward_neg_acc": 0.9990234375, "report/reward_neg_loss": 0.0010196231305599213, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0005117639666423202, "report/reward_rate": 0.0, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.041804272681474686, "eval/cont_loss_std": 0.5917055606842041, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 8.102423667907715, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.002252658363431692, "eval/cont_pred": 0.9978640079498291, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.22242368757724762, "eval/image_loss_std": 0.1822420358657837, "eval/model_loss_mean": 0.8719323873519897, "eval/model_loss_std": 0.7042203545570374, "eval/post_ent_mag": 41.12385559082031, "eval/post_ent_max": 41.12385559082031, "eval/post_ent_mean": 39.97524642944336, "eval/post_ent_min": 39.040489196777344, "eval/post_ent_std": 0.4414072632789612, "eval/prior_ent_mag": 41.998741149902344, "eval/prior_ent_max": 41.998741149902344, "eval/prior_ent_mean": 39.94523620605469, "eval/prior_ent_min": 38.334144592285156, "eval/prior_ent_std": 0.6018033027648926, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0008331298595294356, "eval/reward_loss_mean": 0.007704377174377441, "eval/reward_loss_std": 0.21202927827835083, "eval/reward_max_data": 0.8531249761581421, "eval/reward_max_pred": 0.2502472400665283, "eval/reward_neg_acc": 0.9990224838256836, "eval/reward_neg_loss": 0.0010909743141382933, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 6.7732157707214355, "eval/reward_pred": 0.0005398574285209179, "eval/reward_rate": 0.0009765625, "replay/size": 393317.0, "replay/inserts": 8696.0, "replay/samples": 34784.0, "replay/insert_wait_avg": 1.592573597547431e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.441601516351638e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 91232.0, "eval_replay/inserts": 1960.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1385703573421557e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.08970832824707e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4273858070374, "timer/env.step_count": 1087.0, "timer/env.step_total": 10.6691312789917, "timer/env.step_frac": 0.010664573391685984, "timer/env.step_avg": 0.00981520816834563, "timer/env.step_min": 0.008526325225830078, "timer/env.step_max": 0.03775525093078613, "timer/replay._sample_count": 34784.0, "timer/replay._sample_total": 19.023534297943115, "timer/replay._sample_frac": 0.01901540738271271, "timer/replay._sample_avg": 0.0005469047348764695, "timer/replay._sample_min": 0.0003600120544433594, "timer/replay._sample_max": 0.012076139450073242, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1332.0, "timer/agent.policy_total": 13.996930837631226, "timer/agent.policy_frac": 0.013990951303617109, "timer/agent.policy_avg": 0.010508206334557978, "timer/agent.policy_min": 0.008754253387451172, "timer/agent.policy_max": 0.08934831619262695, "timer/dataset_train_count": 2174.0, "timer/dataset_train_total": 0.3825080394744873, "timer/dataset_train_frac": 0.00038234463080588394, "timer/dataset_train_avg": 0.00017594666029185248, "timer/dataset_train_min": 9.655952453613281e-05, "timer/dataset_train_max": 0.0006754398345947266, "timer/agent.train_count": 2174.0, "timer/agent.train_total": 970.6375775337219, "timer/agent.train_frac": 0.970222918028894, "timer/agent.train_avg": 0.44647542664844614, "timer/agent.train_min": 0.43451571464538574, "timer/agent.train_max": 1.635190486907959, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47649717330932617, "timer/agent.report_frac": 0.0004762936121794981, "timer/agent.report_avg": 0.23824858665466309, "timer/agent.report_min": 0.23108386993408203, "timer/agent.report_max": 0.24541330337524414, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.266334533691406e-05, "timer/dataset_eval_frac": 3.2649391450399756e-08, "timer/dataset_eval_avg": 3.266334533691406e-05, "timer/dataset_eval_min": 3.266334533691406e-05, "timer/dataset_eval_max": 3.266334533691406e-05, "fps": 8.692166315444245}
{"step": 394160, "time": 45279.859266757965, "episode/length": 209.0, "episode/score": 0.34687501192092896, "episode/reward_rate": 0.004761904761904762, "episode/intrinsic_return": 0.0}
{"step": 394216, "time": 45286.29582428932, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 394240, "time": 45289.046387672424, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 394560, "time": 45325.665182352066, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 394568, "time": 45326.58143949509, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 394592, "time": 45329.30888938904, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 394648, "time": 45335.70465564728, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 394784, "time": 45351.31142616272, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 394928, "time": 45367.75155091286, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 395472, "time": 45430.005386829376, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 395568, "time": 45441.06674194336, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 395568, "time": 45441.07233095169, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 396376, "time": 45533.36358356476, "episode/length": 215.0, "episode/score": 0.328125, "episode/reward_rate": 0.004629629629629629, "episode/intrinsic_return": 0.0}
{"step": 396400, "time": 45536.12329649925, "episode/length": 229.0, "episode/score": 0.28437501192092896, "episode/reward_rate": 0.004347826086956522, "episode/intrinsic_return": 0.0}
{"step": 396528, "time": 45550.7043941021, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 396784, "time": 45580.11611413956, "episode/length": 273.0, "episode/score": 0.14687499403953552, "episode/reward_rate": 0.0036496350364963502, "episode/intrinsic_return": 0.0}
{"step": 396808, "time": 45582.95762181282, "episode/length": 252.0, "episode/score": 0.21250000596046448, "episode/reward_rate": 0.003952569169960474, "episode/intrinsic_return": 0.0}
{"step": 397096, "time": 45615.98900222778, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 397152, "time": 45622.39545702934, "episode/length": 209.0, "episode/score": 0.34687501192092896, "episode/reward_rate": 0.004761904761904762, "episode/intrinsic_return": 0.0}
{"step": 397536, "time": 45666.181211948395, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 397880, "time": 45705.35757565498, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 397880, "time": 45705.365882873535, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 397976, "time": 45716.2557053566, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 398168, "time": 45738.26453065872, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 398688, "time": 45797.69303703308, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 399096, "time": 45843.903057575226, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 399416, "time": 45880.24731898308, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 399464, "time": 45885.80120706558, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 399848, "time": 45929.47128558159, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 399872, "time": 45932.186136722565, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 400072, "time": 45954.87921857834, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 400088, "time": 45958.03269147873, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 400088, "time": 45958.16094684601, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 400088, "time": 45958.65651726723, "eval_episode/length": 110.0, "eval_episode/score": 0.65625, "eval_episode/reward_rate": 0.009009009009009009}
{"step": 400088, "time": 45960.40296983719, "eval_episode/length": 215.0, "eval_episode/score": 0.328125, "eval_episode/reward_rate": 0.004629629629629629}
{"step": 400088, "time": 45961.6441423893, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 400088, "time": 45961.65131473541, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 400088, "time": 45961.6720097065, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 400088, "time": 45961.680352926254, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 400192, "time": 45973.51245594025, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 400192, "time": 45973.521372795105, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 400288, "time": 45984.43697500229, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 400384, "time": 45995.3409717083, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 400480, "time": 46006.39800810814, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 400600, "time": 46020.10784006119, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 400784, "time": 46041.133581638336, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 400936, "time": 46058.32355117798, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 401000, "time": 46065.643375873566, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 401776, "time": 46154.630672454834, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 401800, "time": 46157.365329027176, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 402032, "time": 46183.99440383911, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 402256, "time": 46209.57375955582, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 402504, "time": 46237.882697582245, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 402529, "time": 46241.7926838398, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.812579233712013, "train/action_min": 0.0, "train/action_std": 1.7361752904883219, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.006438651611310763, "train/actor_opt_grad_steps": 99155.0, "train/actor_opt_loss": -17.130829863592027, "train/adv_mag": 0.574632681017622, "train/adv_max": 0.3383371283154969, "train/adv_mean": 0.0003530973905580716, "train/adv_min": -0.5206189446766442, "train/adv_std": 0.02436890521240549, "train/cont_avg": 0.9956637041284404, "train/cont_loss_mean": 0.013800220110628822, "train/cont_loss_std": 0.20993378575156452, "train/cont_neg_acc": 0.3577491242645515, "train/cont_neg_loss": 2.546936992302276, "train/cont_pos_acc": 0.9999325004739499, "train/cont_pos_loss": 0.002618563970243302, "train/cont_pred": 0.9958799596226543, "train/cont_rate": 0.9956637041284404, "train/dyn_loss_mean": 1.0000010335117304, "train/dyn_loss_std": 3.304842158878615e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.11478096434692724, "train/extr_critic_critic_opt_grad_steps": 99155.0, "train/extr_critic_critic_opt_loss": 6249.573825661196, "train/extr_critic_mag": 1.0984439658462455, "train/extr_critic_max": 1.0984439658462455, "train/extr_critic_mean": 0.8681954746946282, "train/extr_critic_min": 0.7174129245478079, "train/extr_critic_std": 0.03333324949692832, "train/extr_return_normed_mag": 0.6211827424688077, "train/extr_return_normed_max": 0.467014761692887, "train/extr_return_normed_mean": 0.043810015031640684, "train/extr_return_normed_min": -0.4535582746387622, "train/extr_return_normed_std": 0.042350662944821316, "train/extr_return_rate": 0.9994260400807092, "train/extr_return_raw_mag": 1.291753297825472, "train/extr_return_raw_max": 1.291753297825472, "train/extr_return_raw_mean": 0.868548595577205, "train/extr_return_raw_min": 0.3711802614938228, "train/extr_return_raw_std": 0.04235066277393644, "train/extr_reward_mag": 0.4877746258306941, "train/extr_reward_max": 0.4877746258306941, "train/extr_reward_mean": 0.0012241212309096778, "train/extr_reward_min": -5.468316034439507e-10, "train/extr_reward_std": 0.01109249247483687, "train/image_loss_mean": 0.07011847408197888, "train/image_loss_std": 0.09595183474481653, "train/model_loss_mean": 0.6902786892488462, "train/model_loss_std": 0.3340185278804477, "train/model_opt_grad_norm": 13.651702732121178, "train/model_opt_grad_steps": 99065.94036697247, "train/model_opt_loss": 3562.9424936837013, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5183.48623853211, "train/policy_entropy_mag": 1.295903216808214, "train/policy_entropy_max": 1.295903216808214, "train/policy_entropy_mean": 0.0856202077974967, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.09863095819403273, "train/policy_logprob_mag": 6.551080275019374, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.08501592842400621, "train/policy_logprob_min": -6.551080275019374, "train/policy_logprob_std": 0.6208009777265951, "train/policy_randomness_mag": 0.6659625552663015, "train/policy_randomness_max": 0.6659625552663015, "train/policy_randomness_mean": 0.044000086092620815, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.05068628941107234, "train/post_ent_mag": 41.35419315373132, "train/post_ent_max": 41.35419315373132, "train/post_ent_mean": 40.189932394465174, "train/post_ent_min": 39.1912181224298, "train/post_ent_std": 0.4547738184075837, "train/prior_ent_mag": 41.49805658672928, "train/prior_ent_max": 41.49805658672928, "train/prior_ent_mean": 39.93697322180512, "train/prior_ent_min": 38.359914114715856, "train/prior_ent_std": 0.5551860377602621, "train/rep_loss_mean": 1.0000010335117304, "train/rep_loss_std": 3.304842158878615e-05, "train/reward_avg": 0.0008620235928050733, "train/reward_loss_mean": 0.006359353046618624, "train/reward_loss_std": 0.12716709503929619, "train/reward_max_data": 0.5405246573372171, "train/reward_max_pred": 0.20121351841392868, "train/reward_neg_acc": 0.9997802056850643, "train/reward_neg_loss": 0.0011308724120731354, "train/reward_pos_acc": 0.2616387345937377, "train/reward_pos_loss": 3.5298134436487487, "train/reward_pred": 0.0006915285068333423, "train/reward_rate": 0.001460364105504587, "train_stats/mean_log_entropy": 0.07089057970378133, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.016298169270157814, "report/cont_loss_std": 0.2218489795923233, "report/cont_neg_acc": 0.1666666716337204, "report/cont_neg_loss": 2.4596168994903564, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.001897470443509519, "report/cont_pred": 0.9966745376586914, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.06391531229019165, "report/image_loss_std": 0.0880095511674881, "report/model_loss_mean": 0.6924449801445007, "report/model_loss_std": 0.4329150915145874, "report/post_ent_mag": 40.827430725097656, "report/post_ent_max": 40.827430725097656, "report/post_ent_mean": 39.65789794921875, "report/post_ent_min": 38.611087799072266, "report/post_ent_std": 0.4929904639720917, "report/prior_ent_mag": 41.71762466430664, "report/prior_ent_max": 41.71762466430664, "report/prior_ent_mean": 39.942901611328125, "report/prior_ent_min": 38.34544372558594, "report/prior_ent_std": 0.5218513011932373, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0019104003440588713, "report/reward_loss_mean": 0.012231462635099888, "report/reward_loss_std": 0.2118341028690338, "report/reward_max_data": 0.824999988079071, "report/reward_max_pred": 0.04293835163116455, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0009024764294736087, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 3.867863178253174, "report/reward_pred": 0.0005243384512141347, "report/reward_rate": 0.0029296875, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.013158605434000492, "eval/cont_loss_std": 0.3474760055541992, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 11.117202758789062, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.002304211724549532, "eval/cont_pred": 0.9977980256080627, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.15741044282913208, "eval/image_loss_std": 0.16186143457889557, "eval/model_loss_mean": 0.7717267274856567, "eval/model_loss_std": 0.3802816867828369, "eval/post_ent_mag": 40.8100471496582, "eval/post_ent_max": 40.8100471496582, "eval/post_ent_mean": 39.583274841308594, "eval/post_ent_min": 38.47856140136719, "eval/post_ent_std": 0.49062421917915344, "eval/prior_ent_mag": 41.51094055175781, "eval/prior_ent_max": 41.51094055175781, "eval/prior_ent_mean": 39.828895568847656, "eval/prior_ent_min": 38.33828353881836, "eval/prior_ent_std": 0.5269355773925781, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0011576756369322538, "eval/reward_loss_std": 0.010860731825232506, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.12153053283691406, "eval/reward_neg_acc": 0.9990234375, "eval/reward_neg_loss": 0.0011576756369322538, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0005502053536474705, "eval/reward_rate": 0.0, "replay/size": 402025.0, "replay/inserts": 8708.0, "replay/samples": 34832.0, "replay/insert_wait_avg": 1.5755667837595907e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.474195206992167e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 93544.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0620557725635779e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.685754776000977e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3382041454315, "timer/env.step_count": 1089.0, "timer/env.step_total": 10.68130111694336, "timer/env.step_frac": 0.010677689877963, "timer/env.step_avg": 0.009808357315834123, "timer/env.step_min": 0.008569478988647461, "timer/env.step_max": 0.03447675704956055, "timer/replay._sample_count": 34832.0, "timer/replay._sample_total": 19.099962949752808, "timer/replay._sample_frac": 0.019093505447059792, "timer/replay._sample_avg": 0.0005483452845014013, "timer/replay._sample_min": 0.0003561973571777344, "timer/replay._sample_max": 0.03595256805419922, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1378.0, "timer/agent.policy_total": 13.901618003845215, "timer/agent.policy_frac": 0.013896918008565996, "timer/agent.policy_avg": 0.010088256896839778, "timer/agent.policy_min": 0.008728981018066406, "timer/agent.policy_max": 0.03630423545837402, "timer/dataset_train_count": 2177.0, "timer/dataset_train_total": 0.38410019874572754, "timer/dataset_train_frac": 0.0003839703383855628, "timer/dataset_train_avg": 0.0001764355529378629, "timer/dataset_train_min": 9.679794311523438e-05, "timer/dataset_train_max": 0.0005040168762207031, "timer/agent.train_count": 2177.0, "timer/agent.train_total": 970.5363700389862, "timer/agent.train_frac": 0.9702082415897487, "timer/agent.train_avg": 0.44581367479971806, "timer/agent.train_min": 0.4333317279815674, "timer/agent.train_max": 0.5927658081054688, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4755892753601074, "timer/agent.report_frac": 0.00047542848347613956, "timer/agent.report_avg": 0.2377946376800537, "timer/agent.report_min": 0.22986149787902832, "timer/agent.report_max": 0.2457277774810791, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.314018249511719e-05, "timer/dataset_eval_frac": 3.3128978137377214e-08, "timer/dataset_eval_avg": 3.314018249511719e-05, "timer/dataset_eval_min": 3.314018249511719e-05, "timer/dataset_eval_max": 3.314018249511719e-05, "fps": 8.704915787956732}
{"step": 402696, "time": 46260.670954465866, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 402792, "time": 46271.69835972786, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 402912, "time": 46285.35535168648, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 403096, "time": 46306.37837743759, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 403328, "time": 46332.765019893646, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 403376, "time": 46338.201555490494, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 403856, "time": 46393.16376543045, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 404088, "time": 46419.66913485527, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 404344, "time": 46448.98979473114, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 404376, "time": 46452.71252846718, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 404568, "time": 46474.62644958496, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 404816, "time": 46502.99364852905, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 405016, "time": 46525.9287109375, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 405104, "time": 46536.03471946716, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 405208, "time": 46548.057888031006, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 405408, "time": 46571.06773304939, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 405456, "time": 46576.590550899506, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 405632, "time": 46596.69919300079, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 405656, "time": 46599.44712305069, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 406296, "time": 46672.630392313, "episode/length": 243.0, "episode/score": 0.24062499403953552, "episode/reward_rate": 0.004098360655737705, "episode/intrinsic_return": 0.0}
{"step": 407032, "time": 46756.79941225052, "episode/length": 276.0, "episode/score": 0.13750000298023224, "episode/reward_rate": 0.0036101083032490976, "episode/intrinsic_return": 0.0}
{"step": 407328, "time": 46790.60949587822, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 407520, "time": 46812.669080019, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 407720, "time": 46835.49809336662, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 407768, "time": 46840.98525094986, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 407944, "time": 46861.10348749161, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 407968, "time": 46863.8579788208, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 408608, "time": 46937.13724708557, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 409344, "time": 47021.09343409538, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 409640, "time": 47055.37081336975, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 409832, "time": 47077.21814751625, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 410032, "time": 47100.06236243248, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 410072, "time": 47105.25575184822, "eval_episode/length": 36.0, "eval_episode/score": 0.887499988079071, "eval_episode/reward_rate": 0.02702702702702703}
{"step": 410072, "time": 47105.66533732414, "eval_episode/length": 60.0, "eval_episode/score": 0.8125, "eval_episode/reward_rate": 0.01639344262295082}
{"step": 410072, "time": 47106.8957464695, "eval_episode/length": 132.0, "eval_episode/score": 0.5874999761581421, "eval_episode/reward_rate": 0.007518796992481203}
{"step": 410072, "time": 47107.8248064518, "eval_episode/length": 54.0, "eval_episode/score": 0.831250011920929, "eval_episode/reward_rate": 0.01818181818181818}
{"step": 410072, "time": 47108.38224005699, "eval_episode/length": 220.0, "eval_episode/score": 0.3125, "eval_episode/reward_rate": 0.004524886877828055}
{"step": 410072, "time": 47109.38429260254, "eval_episode/length": 278.0, "eval_episode/score": 0.13124999403953552, "eval_episode/reward_rate": 0.0035842293906810036}
{"step": 410072, "time": 47109.557701826096, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 410072, "time": 47109.5647354126, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 410072, "time": 47109.57038593292, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 410080, "time": 47110.50551247597, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 410256, "time": 47130.58164811134, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 410264, "time": 47131.509903907776, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 410280, "time": 47133.36133313179, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 410416, "time": 47149.00413489342, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 410528, "time": 47161.81084394455, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 410720, "time": 47183.78016114235, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 410920, "time": 47206.675763607025, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 411000, "time": 47215.787465810776, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 411008, "time": 47216.70198178291, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 411221, "time": 47241.906220436096, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.9354129914314515, "train/action_min": 0.0, "train/action_std": 1.6750349125005133, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.010779285945066934, "train/actor_opt_grad_steps": 101330.0, "train/actor_opt_loss": -17.567426755131663, "train/adv_mag": 0.5753414805309014, "train/adv_max": 0.3437140402705988, "train/adv_mean": -0.0015058794937355788, "train/adv_min": -0.4809989333152771, "train/adv_std": 0.032859106827098104, "train/cont_avg": 0.9957427275345622, "train/cont_loss_mean": 0.012850276782490691, "train/cont_loss_std": 0.1978664861644365, "train/cont_neg_acc": 0.3894393296766391, "train/cont_neg_loss": 2.4328162986638984, "train/cont_pos_acc": 0.9999186459774246, "train/cont_pos_loss": 0.00257664514047819, "train/cont_pred": 0.9958414064574351, "train/cont_rate": 0.9957427275345622, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.16648798388287356, "train/extr_critic_critic_opt_grad_steps": 101330.0, "train/extr_critic_critic_opt_loss": 10589.258350284419, "train/extr_critic_mag": 0.9630872637445477, "train/extr_critic_max": 0.9630872637445477, "train/extr_critic_mean": 0.8039670891476117, "train/extr_critic_min": 0.6857370802883729, "train/extr_critic_std": 0.02936019469910915, "train/extr_return_normed_mag": 0.6050194941358082, "train/extr_return_normed_max": 0.4185274583952768, "train/extr_return_normed_mean": 0.036500928803317005, "train/extr_return_normed_min": -0.42726096195009994, "train/extr_return_normed_std": 0.04685133212773893, "train/extr_return_rate": 0.9989016602665598, "train/extr_return_raw_mag": 1.184487749903982, "train/extr_return_raw_max": 1.184487749903982, "train/extr_return_raw_mean": 0.8024612571786626, "train/extr_return_raw_min": 0.33869932928392965, "train/extr_return_raw_std": 0.04685133223503416, "train/extr_reward_mag": 0.4170605477100144, "train/extr_reward_max": 0.4170605477100144, "train/extr_reward_mean": 0.0020818983572216013, "train/extr_reward_min": 1.6480546942504321e-09, "train/extr_reward_std": 0.015338300846941976, "train/image_loss_mean": 0.06942440969397395, "train/image_loss_std": 0.09538792530375143, "train/model_loss_mean": 0.6886559400690316, "train/model_loss_std": 0.32249086851485864, "train/model_opt_grad_norm": 13.277677340441585, "train/model_opt_grad_steps": 101238.9262672811, "train/model_opt_loss": 3761.6330195132487, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5460.829493087557, "train/policy_entropy_mag": 1.3085310937072825, "train/policy_entropy_max": 1.3085310937072825, "train/policy_entropy_mean": 0.10112248979131197, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.1279917265962346, "train/policy_logprob_mag": 6.55108028183335, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.1009428890482072, "train/policy_logprob_min": -6.55108028183335, "train/policy_logprob_std": 0.6375454848263121, "train/policy_randomness_mag": 0.6724520015277071, "train/policy_randomness_max": 0.6724520015277071, "train/policy_randomness_mean": 0.051966684119355296, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06577474005898024, "train/post_ent_mag": 41.83757711665422, "train/post_ent_max": 41.83757711665422, "train/post_ent_mean": 40.54040631061326, "train/post_ent_min": 39.41186015397173, "train/post_ent_std": 0.5120829384997144, "train/prior_ent_mag": 41.803143426569925, "train/prior_ent_max": 41.803143426569925, "train/prior_ent_mean": 40.53172762822446, "train/prior_ent_min": 39.082620313090665, "train/prior_ent_std": 0.4824142649701114, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0009206323575618471, "train/reward_loss_mean": 0.006381229342987186, "train/reward_loss_std": 0.12340587166498505, "train/reward_max_data": 0.5431307610210185, "train/reward_max_pred": 0.20901758824625322, "train/reward_neg_acc": 0.9998467405270871, "train/reward_neg_loss": 0.0011180359583180656, "train/reward_pos_acc": 0.26201550523902095, "train/reward_pos_loss": 3.4487715943954713, "train/reward_pred": 0.0007290048422806892, "train/reward_rate": 0.0015165970622119816, "train_stats/mean_log_entropy": 0.08820986490519274, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.008517896756529808, "report/cont_loss_std": 0.14457140862941742, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 3.210127353668213, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0022525154054164886, "report/cont_pred": 0.997702956199646, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.046978164464235306, "report/image_loss_std": 0.073184072971344, "report/model_loss_mean": 0.660136342048645, "report/model_loss_std": 0.25618302822113037, "report/post_ent_mag": 41.44390869140625, "report/post_ent_max": 41.44390869140625, "report/post_ent_mean": 40.1859016418457, "report/post_ent_min": 38.92789840698242, "report/post_ent_std": 0.5103802680969238, "report/prior_ent_mag": 41.72771072387695, "report/prior_ent_max": 41.72771072387695, "report/prior_ent_mean": 40.599674224853516, "report/prior_ent_min": 39.48094940185547, "report/prior_ent_std": 0.407263845205307, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0004150390741415322, "report/reward_loss_mean": 0.004640236496925354, "report/reward_loss_std": 0.12283908575773239, "report/reward_max_data": 0.42500001192092896, "report/reward_max_pred": 0.05862581729888916, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0008044072892516851, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 3.9286937713623047, "report/reward_pred": 0.0003924401244148612, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.05862624570727348, "eval/cont_loss_std": 0.7660897970199585, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 9.62030029296875, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.002270602621138096, "eval/cont_pred": 0.9978048205375671, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.13983643054962158, "eval/image_loss_std": 0.13858726620674133, "eval/model_loss_mean": 0.798998236656189, "eval/model_loss_std": 0.7749395370483398, "eval/post_ent_mag": 41.536617279052734, "eval/post_ent_max": 41.536617279052734, "eval/post_ent_mean": 40.15226364135742, "eval/post_ent_min": 39.048912048339844, "eval/post_ent_std": 0.5584953427314758, "eval/prior_ent_mag": 41.72771072387695, "eval/prior_ent_max": 41.72771072387695, "eval/prior_ent_mean": 40.548805236816406, "eval/prior_ent_min": 39.272193908691406, "eval/prior_ent_std": 0.4400728642940521, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.000535555649548769, "eval/reward_loss_std": 0.004105222411453724, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.03565549850463867, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.000535555649548769, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0002383252140134573, "eval/reward_rate": 0.0, "replay/size": 410717.0, "replay/inserts": 8692.0, "replay/samples": 34768.0, "replay/insert_wait_avg": 1.5717742084304803e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.512297325292272e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 95856.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0519497947296882e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0132789611816406e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0938324928284, "timer/env.step_count": 1086.0, "timer/env.step_total": 10.724127531051636, "timer/env.step_frac": 0.010723121353844104, "timer/env.step_avg": 0.009874887229329315, "timer/env.step_min": 0.008639812469482422, "timer/env.step_max": 0.035030364990234375, "timer/replay._sample_count": 34768.0, "timer/replay._sample_total": 19.08463454246521, "timer/replay._sample_frac": 0.01908284395164697, "timer/replay._sample_avg": 0.0005489137868863671, "timer/replay._sample_min": 0.000392913818359375, "timer/replay._sample_max": 0.011263132095336914, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1375.0, "timer/agent.policy_total": 13.95745325088501, "timer/agent.policy_frac": 0.013956143711130324, "timer/agent.policy_avg": 0.010150875091552734, "timer/agent.policy_min": 0.00870370864868164, "timer/agent.policy_max": 0.03606057167053223, "timer/dataset_train_count": 2173.0, "timer/dataset_train_total": 0.40722179412841797, "timer/dataset_train_frac": 0.0004071835870774037, "timer/dataset_train_avg": 0.0001874007336071873, "timer/dataset_train_min": 9.679794311523438e-05, "timer/dataset_train_max": 0.0211794376373291, "timer/agent.train_count": 2173.0, "timer/agent.train_total": 970.157995223999, "timer/agent.train_frac": 0.97006697142186, "timer/agent.train_avg": 0.44646019108329454, "timer/agent.train_min": 0.4358804225921631, "timer/agent.train_max": 0.6212661266326904, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4795815944671631, "timer/agent.report_frac": 0.00047953659835273723, "timer/agent.report_avg": 0.23979079723358154, "timer/agent.report_min": 0.23118233680725098, "timer/agent.report_max": 0.2483992576599121, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.409385681152344e-05, "timer/dataset_eval_frac": 3.409065800010113e-08, "timer/dataset_eval_avg": 3.409385681152344e-05, "timer/dataset_eval_min": 3.409385681152344e-05, "timer/dataset_eval_max": 3.409385681152344e-05, "fps": 8.69100656603766}
{"step": 411296, "time": 47250.278316020966, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 411576, "time": 47282.36825442314, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 411856, "time": 47314.53034543991, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 411968, "time": 47327.44002199173, "episode/length": 213.0, "episode/score": 0.3343749940395355, "episode/reward_rate": 0.004672897196261682, "episode/intrinsic_return": 0.0}
{"step": 412008, "time": 47332.020021915436, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 412368, "time": 47373.21872019768, "episode/length": 262.0, "episode/score": 0.18125000596046448, "episode/reward_rate": 0.0038022813688212928, "episode/intrinsic_return": 0.0}
{"step": 412392, "time": 47375.96684765816, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 412592, "time": 47398.93220949173, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 412640, "time": 47404.44692516327, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 413232, "time": 47472.275344371796, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 413352, "time": 47486.04404473305, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 413432, "time": 47495.18239951134, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.0}
{"step": 413512, "time": 47504.4307038784, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 413512, "time": 47504.43688464165, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 413888, "time": 47547.56658220291, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 414040, "time": 47565.01779675484, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 414152, "time": 47577.820989608765, "episode/length": 272.0, "episode/score": 0.15000000596046448, "episode/reward_rate": 0.003663003663003663, "episode/intrinsic_return": 0.0}
{"step": 414680, "time": 47638.574806928635, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 414680, "time": 47638.58242869377, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 414720, "time": 47643.168632268906, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 414952, "time": 47669.84563374519, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 415072, "time": 47683.736814022064, "episode/length": 214.0, "episode/score": 0.33125001192092896, "episode/reward_rate": 0.004651162790697674, "episode/intrinsic_return": 0.0}
{"step": 415256, "time": 47704.83568406105, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 415304, "time": 47710.32738804817, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 415600, "time": 47744.24639415741, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 415744, "time": 47760.62190365791, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 415824, "time": 47769.75407934189, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 416000, "time": 47789.98394584656, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 416016, "time": 47791.808529138565, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 416248, "time": 47818.38900303841, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 416352, "time": 47830.273512363434, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 416608, "time": 47859.56515908241, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 416616, "time": 47860.480397462845, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 416880, "time": 47890.666273355484, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 417616, "time": 47974.71004343033, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 418056, "time": 48025.47395133972, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 418064, "time": 48026.38739705086, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 418104, "time": 48030.94770860672, "episode/length": 231.0, "episode/score": 0.27812498807907104, "episode/reward_rate": 0.004310344827586207, "episode/intrinsic_return": 0.0}
{"step": 418328, "time": 48056.59596824646, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 418432, "time": 48068.47267508507, "episode/length": 227.0, "episode/score": 0.2906250059604645, "episode/reward_rate": 0.0043859649122807015, "episode/intrinsic_return": 0.0}
{"step": 418656, "time": 48094.11735653877, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 418664, "time": 48095.039254426956, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 418864, "time": 48117.917568683624, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 418976, "time": 48130.7305893898, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 419080, "time": 48142.75231742859, "episode/length": 274.0, "episode/score": 0.14374999701976776, "episode/reward_rate": 0.0036363636363636364, "episode/intrinsic_return": 0.0}
{"step": 419344, "time": 48173.030514001846, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 419400, "time": 48179.43197751045, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 419504, "time": 48191.30919837952, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 419928, "time": 48239.74063825607, "episode/length": 233.0, "episode/score": 0.2718749940395355, "episode/reward_rate": 0.004273504273504274, "episode/intrinsic_return": 0.0}
{"step": 419928, "time": 48239.75136232376, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 419941, "time": 48242.095687389374, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.8137534605253727, "train/action_min": 0.0, "train/action_std": 1.7919313934964871, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.006609500164204542, "train/actor_opt_grad_steps": 103505.0, "train/actor_opt_loss": -19.899605996018156, "train/adv_mag": 0.48853994386458616, "train/adv_max": 0.24461066531478812, "train/adv_mean": 0.001779960875255961, "train/adv_min": -0.4402477421344967, "train/adv_std": 0.02141999818786227, "train/cont_avg": 0.9956009891055045, "train/cont_loss_mean": 0.013185215049098597, "train/cont_loss_std": 0.20109607945110888, "train/cont_neg_acc": 0.3853229528747945, "train/cont_neg_loss": 2.3451632022614106, "train/cont_pos_acc": 0.9999054779700183, "train/cont_pos_loss": 0.002630355391691977, "train/cont_pred": 0.9957576724914236, "train/cont_rate": 0.9956009891055045, "train/dyn_loss_mean": 1.0000001405357222, "train/dyn_loss_std": 4.491735000906666e-06, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.10648603804853804, "train/extr_critic_critic_opt_grad_steps": 103505.0, "train/extr_critic_critic_opt_loss": 10195.918154655246, "train/extr_critic_mag": 0.9655209714119587, "train/extr_critic_max": 0.9655209714119587, "train/extr_critic_mean": 0.8050254061134583, "train/extr_critic_min": 0.6820067139940524, "train/extr_critic_std": 0.03743877760860898, "train/extr_return_normed_mag": 0.5200571108848677, "train/extr_return_normed_max": 0.33514248477209596, "train/extr_return_normed_mean": 0.05366214379292289, "train/extr_return_normed_min": -0.3777394860709479, "train/extr_return_normed_std": 0.04349351921246959, "train/extr_return_rate": 0.9994346972452391, "train/extr_return_raw_mag": 1.0882857048183405, "train/extr_return_raw_max": 1.0882857048183405, "train/extr_return_raw_mean": 0.8068054058683027, "train/extr_return_raw_min": 0.3754037339752967, "train/extr_return_raw_std": 0.04349351924664657, "train/extr_reward_mag": 0.35127374775912784, "train/extr_reward_max": 0.35127374775912784, "train/extr_reward_mean": 0.0010108077612122385, "train/extr_reward_min": 5.3042665534063216e-08, "train/extr_reward_std": 0.007841524423458913, "train/image_loss_mean": 0.06998093598821295, "train/image_loss_std": 0.09551505754710338, "train/model_loss_mean": 0.6897268382781142, "train/model_loss_std": 0.32837942741606213, "train/model_opt_grad_norm": 13.400478992987116, "train/model_opt_grad_steps": 103412.1376146789, "train/model_opt_loss": 3985.108905757239, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5779.816513761468, "train/policy_entropy_mag": 1.3171801632697429, "train/policy_entropy_max": 1.3171801632697429, "train/policy_entropy_mean": 0.09256331232983038, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.11565838391901156, "train/policy_logprob_mag": 6.551080285956006, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09234832114446054, "train/policy_logprob_min": -6.551080285956006, "train/policy_logprob_std": 0.6303526124822985, "train/policy_randomness_mag": 0.676896743271329, "train/policy_randomness_max": 0.676896743271329, "train/policy_randomness_mean": 0.04756813730463522, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.05943665515050429, "train/post_ent_mag": 41.66559277105769, "train/post_ent_max": 41.66559277105769, "train/post_ent_mean": 40.472843432645185, "train/post_ent_min": 39.44665714578891, "train/post_ent_std": 0.46769293841965703, "train/prior_ent_mag": 41.44902689522559, "train/prior_ent_max": 41.44902689522559, "train/prior_ent_mean": 40.13124073973489, "train/prior_ent_min": 38.83534956415859, "train/prior_ent_std": 0.4432285541514738, "train/rep_loss_mean": 1.0000001405357222, "train/rep_loss_std": 4.491735000906666e-06, "train/reward_avg": 0.0009385275184160841, "train/reward_loss_mean": 0.006560577824604997, "train/reward_loss_std": 0.12803909403310423, "train/reward_max_data": 0.5402236238395403, "train/reward_max_pred": 0.2034477066556248, "train/reward_neg_acc": 0.9998339280622814, "train/reward_neg_loss": 0.0011513119137850207, "train/reward_pos_acc": 0.2442495137975927, "train/reward_pos_loss": 3.568184237382565, "train/reward_pred": 0.0007029177029318082, "train/reward_rate": 0.0015141198394495413, "train_stats/mean_log_entropy": 0.07241318434476852, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.012757194228470325, "report/cont_loss_std": 0.18745680153369904, "report/cont_neg_acc": 0.25, "report/cont_neg_loss": 2.5514450073242188, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.002801555208861828, "report/cont_pred": 0.9961671829223633, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.051515255123376846, "report/image_loss_std": 0.07104531675577164, "report/model_loss_mean": 0.6658791303634644, "report/model_loss_std": 0.20132751762866974, "report/post_ent_mag": 42.044654846191406, "report/post_ent_max": 42.044654846191406, "report/post_ent_mean": 40.92210006713867, "report/post_ent_min": 39.92021179199219, "report/post_ent_std": 0.44016799330711365, "report/prior_ent_mag": 41.12348175048828, "report/prior_ent_max": 41.12348175048828, "report/prior_ent_mean": 40.164527893066406, "report/prior_ent_min": 38.91858673095703, "report/prior_ent_std": 0.3760978579521179, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.0016066988464444876, "report/reward_loss_std": 0.00868475716561079, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.041374921798706055, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0016066988464444876, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0007086014375090599, "report/reward_rate": 0.0, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.015033535659313202, "eval/cont_loss_std": 0.3776837885379791, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 12.078130722045898, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.003241651225835085, "eval/cont_pred": 0.996941089630127, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.15423475205898285, "eval/image_loss_std": 0.14273536205291748, "eval/model_loss_mean": 0.7699910402297974, "eval/model_loss_std": 0.40344852209091187, "eval/post_ent_mag": 42.057926177978516, "eval/post_ent_max": 42.057926177978516, "eval/post_ent_mean": 40.93879318237305, "eval/post_ent_min": 39.9263916015625, "eval/post_ent_std": 0.4820755124092102, "eval/prior_ent_mag": 41.31132507324219, "eval/prior_ent_max": 41.31132507324219, "eval/prior_ent_mean": 40.2080078125, "eval/prior_ent_min": 39.22511672973633, "eval/prior_ent_std": 0.41894906759262085, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0007227554451674223, "eval/reward_loss_std": 0.005198235157877207, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.02961409091949463, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0007227554451674223, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0003080805763602257, "eval/reward_rate": 0.0, "replay/size": 419437.0, "replay/inserts": 8720.0, "replay/samples": 34880.0, "replay/insert_wait_avg": 1.6469200816723184e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.605607356500188e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 95856.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 8.940696716308594e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1758122444153, "timer/env.step_count": 1090.0, "timer/env.step_total": 10.731482028961182, "timer/env.step_frac": 0.010729595634670982, "timer/env.step_avg": 0.00984539635684512, "timer/env.step_min": 0.00867152214050293, "timer/env.step_max": 0.03581833839416504, "timer/replay._sample_count": 34880.0, "timer/replay._sample_total": 19.27675724029541, "timer/replay._sample_frac": 0.01927336874607872, "timer/replay._sample_avg": 0.0005526593245497538, "timer/replay._sample_min": 0.0003762245178222656, "timer/replay._sample_max": 0.0344998836517334, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1090.0, "timer/agent.policy_total": 11.264959573745728, "timer/agent.policy_frac": 0.011262979404057898, "timer/agent.policy_avg": 0.01033482529701443, "timer/agent.policy_min": 0.00934290885925293, "timer/agent.policy_max": 0.036074161529541016, "timer/dataset_train_count": 2180.0, "timer/dataset_train_total": 0.37816357612609863, "timer/dataset_train_frac": 0.00037809710202598454, "timer/dataset_train_avg": 0.00017346953033307277, "timer/dataset_train_min": 9.202957153320312e-05, "timer/dataset_train_max": 0.0009679794311523438, "timer/agent.train_count": 2180.0, "timer/agent.train_total": 975.2582590579987, "timer/agent.train_frac": 0.9750868268544696, "timer/agent.train_avg": 0.4473661738798159, "timer/agent.train_min": 0.43615198135375977, "timer/agent.train_max": 0.5879249572753906, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4752645492553711, "timer/agent.report_frac": 0.0004751810066160944, "timer/agent.report_avg": 0.23763227462768555, "timer/agent.report_min": 0.23081183433532715, "timer/agent.report_max": 0.24445271492004395, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.86102294921875e-05, "timer/dataset_eval_frac": 2.860520034771242e-08, "timer/dataset_eval_avg": 2.86102294921875e-05, "timer/dataset_eval_min": 2.86102294921875e-05, "timer/dataset_eval_max": 2.86102294921875e-05, "fps": 8.718342200798453}
{"step": 419984, "time": 48246.81127119064, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 420008, "time": 48249.55171751976, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 420056, "time": 48256.3568854332, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 420056, "time": 48256.83928608894, "eval_episode/length": 99.0, "eval_episode/score": 0.690625011920929, "eval_episode/reward_rate": 0.01}
{"step": 420056, "time": 48257.212223529816, "eval_episode/length": 121.0, "eval_episode/score": 0.621874988079071, "eval_episode/reward_rate": 0.00819672131147541}
{"step": 420056, "time": 48257.43702173233, "eval_episode/length": 134.0, "eval_episode/score": 0.581250011920929, "eval_episode/reward_rate": 0.007407407407407408}
{"step": 420056, "time": 48257.44341850281, "eval_episode/length": 134.0, "eval_episode/score": 0.581250011920929, "eval_episode/reward_rate": 0.007407407407407408}
{"step": 420056, "time": 48258.014285326004, "eval_episode/length": 33.0, "eval_episode/score": 0.8968750238418579, "eval_episode/reward_rate": 0.029411764705882353}
{"step": 420056, "time": 48258.77186203003, "eval_episode/length": 113.0, "eval_episode/score": 0.6468750238418579, "eval_episode/reward_rate": 0.008771929824561403}
{"step": 420056, "time": 48258.848257780075, "eval_episode/length": 217.0, "eval_episode/score": 0.3218750059604645, "eval_episode/reward_rate": 0.0045871559633027525}
{"step": 420112, "time": 48265.21801185608, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 420528, "time": 48312.666079998016, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 420552, "time": 48315.39439868927, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 420576, "time": 48318.13323998451, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 420720, "time": 48334.52607154846, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 421016, "time": 48368.17826318741, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 421944, "time": 48474.32136678696, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 422240, "time": 48508.224962711334, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 422320, "time": 48517.37989258766, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 422416, "time": 48528.40654492378, "episode/length": 211.0, "episode/score": 0.34062498807907104, "episode/reward_rate": 0.0047169811320754715, "episode/intrinsic_return": 0.0}
{"step": 422424, "time": 48529.319788217545, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 422840, "time": 48576.96933341026, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 422888, "time": 48582.572237968445, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 423080, "time": 48604.534287929535, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 423264, "time": 48625.66126227379, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 423328, "time": 48632.99457812309, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 423336, "time": 48633.907552957535, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 423336, "time": 48633.91297364235, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 423656, "time": 48670.56840515137, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 423976, "time": 48707.2557387352, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 424256, "time": 48739.35675525665, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 424416, "time": 48757.6980714798, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 424472, "time": 48764.12468123436, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 424736, "time": 48794.43037438393, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 425392, "time": 48869.6510014534, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 425648, "time": 48899.05175089836, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 425656, "time": 48899.97198152542, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 425968, "time": 48935.75123524666, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 426248, "time": 48968.17762541771, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 426288, "time": 48972.8195309639, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 426544, "time": 49002.15633225441, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 426680, "time": 49017.73800444603, "episode/length": 282.0, "episode/score": 0.11874999850988388, "episode/reward_rate": 0.0035335689045936395, "episode/intrinsic_return": 0.0}
{"step": 426736, "time": 49024.12484550476, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 426784, "time": 49029.60312652588, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 426840, "time": 49036.03866648674, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 427200, "time": 49077.25441789627, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 427472, "time": 49108.32255315781, "episode/length": 226.0, "episode/score": 0.29374998807907104, "episode/reward_rate": 0.004405286343612335, "episode/intrinsic_return": 0.0}
{"step": 427704, "time": 49134.84375810623, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 427832, "time": 49149.48456454277, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 428328, "time": 49206.25905919075, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 428560, "time": 49232.74668312073, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 428637, "time": 49242.4947309494, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.7132226786482225, "train/action_min": 0.0, "train/action_std": 1.7631025986933926, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00884273837089812, "train/actor_opt_grad_steps": 105685.0, "train/actor_opt_loss": -18.724555041811882, "train/adv_mag": 0.572638711387958, "train/adv_max": 0.2616368348992199, "train/adv_mean": 0.0014847720353744313, "train/adv_min": -0.529424414175366, "train/adv_std": 0.026957735342375184, "train/cont_avg": 0.9957936138188074, "train/cont_loss_mean": 0.012697440667137709, "train/cont_loss_std": 0.1933398068532211, "train/cont_neg_acc": 0.383752210755591, "train/cont_neg_loss": 2.356305723940413, "train/cont_pos_acc": 0.9999189961940871, "train/cont_pos_loss": 0.0026904003301618296, "train/cont_pred": 0.9957447792958776, "train/cont_rate": 0.9957936138188074, "train/dyn_loss_mean": 1.000002576123684, "train/dyn_loss_std": 5.778348673596431e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.13706072466020738, "train/extr_critic_critic_opt_grad_steps": 105685.0, "train/extr_critic_critic_opt_loss": 8882.481801444237, "train/extr_critic_mag": 0.9937791895428929, "train/extr_critic_max": 0.9937791895428929, "train/extr_critic_mean": 0.8323833387379252, "train/extr_critic_min": 0.6847231278725721, "train/extr_critic_std": 0.035002324849777264, "train/extr_return_normed_mag": 0.5936902351335648, "train/extr_return_normed_max": 0.3385734793243058, "train/extr_return_normed_mean": 0.04997195928024316, "train/extr_return_normed_min": -0.4839975114809264, "train/extr_return_normed_std": 0.04613972654344019, "train/extr_return_rate": 0.9991689102912168, "train/extr_return_raw_mag": 1.1224696529567788, "train/extr_return_raw_max": 1.1224696529567788, "train/extr_return_raw_mean": 0.8338681798462474, "train/extr_return_raw_min": 0.2998986620831927, "train/extr_return_raw_std": 0.046139726739957795, "train/extr_reward_mag": 0.3506519253100824, "train/extr_reward_max": 0.3506519253100824, "train/extr_reward_mean": 0.0011629383552311109, "train/extr_reward_min": 8.749305655103211e-09, "train/extr_reward_std": 0.00956161775724501, "train/image_loss_mean": 0.06954050383641633, "train/image_loss_std": 0.09528240677687007, "train/model_loss_mean": 0.6887293411504238, "train/model_loss_std": 0.32402899553742975, "train/model_opt_grad_norm": 13.418507665669152, "train/model_opt_grad_steps": 105590.1513761468, "train/model_opt_loss": 3743.402950741829, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5435.779816513761, "train/policy_entropy_mag": 1.3211899897374144, "train/policy_entropy_max": 1.3211899897374144, "train/policy_entropy_mean": 0.09714987709981586, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.12305319794547667, "train/policy_logprob_mag": 6.55108028376868, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.0974823340021689, "train/policy_logprob_min": -6.55108028376868, "train/policy_logprob_std": 0.6365562302803774, "train/policy_randomness_mag": 0.6789573849341192, "train/policy_randomness_max": 0.6789573849341192, "train/policy_randomness_mean": 0.04992516485786219, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06323683825791429, "train/post_ent_mag": 41.990571293262164, "train/post_ent_max": 41.990571293262164, "train/post_ent_mean": 40.97336889844422, "train/post_ent_min": 40.09206262640997, "train/post_ent_std": 0.39947745914852945, "train/prior_ent_mag": 41.381523989756175, "train/prior_ent_max": 41.381523989756175, "train/prior_ent_mean": 40.40625874930566, "train/prior_ent_min": 39.31191446146834, "train/prior_ent_std": 0.3340210343172791, "train/rep_loss_mean": 1.000002576123684, "train/rep_loss_std": 5.778348673596431e-05, "train/reward_avg": 0.0008517484072290912, "train/reward_loss_mean": 0.006489832232195731, "train/reward_loss_std": 0.12732351812375967, "train/reward_max_data": 0.5373566528320859, "train/reward_max_pred": 0.19184914750790377, "train/reward_neg_acc": 0.9997757172912632, "train/reward_neg_loss": 0.0012491456706369502, "train/reward_pos_acc": 0.23976608326560572, "train/reward_pos_loss": 3.626320076093339, "train/reward_pred": 0.0007293980820702577, "train/reward_rate": 0.0014200473050458716, "train_stats/mean_log_entropy": 0.0764661344677903, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.018167516216635704, "report/cont_loss_std": 0.2818473279476166, "report/cont_neg_acc": 0.5, "report/cont_neg_loss": 2.5744738578796387, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.003100878791883588, "report/cont_pred": 0.9941040277481079, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.056596338748931885, "report/image_loss_std": 0.07482204586267471, "report/model_loss_mean": 0.6769450306892395, "report/model_loss_std": 0.2908782660961151, "report/post_ent_mag": 41.81089401245117, "report/post_ent_max": 41.81089401245117, "report/post_ent_mean": 40.84339141845703, "report/post_ent_min": 39.908077239990234, "report/post_ent_std": 0.40396353602409363, "report/prior_ent_mag": 41.315155029296875, "report/prior_ent_max": 41.315155029296875, "report/prior_ent_mean": 40.18500518798828, "report/prior_ent_min": 38.94329071044922, "report/prior_ent_std": 0.3634885847568512, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0002807617129292339, "report/reward_loss_mean": 0.0021811597980558872, "report/reward_loss_std": 0.022862020879983902, "report/reward_max_data": 0.2874999940395355, "report/reward_max_pred": 0.27553069591522217, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0015042839804664254, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6946251392364502, "report/reward_pred": 0.0010068488772958517, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.031242866069078445, "eval/cont_loss_std": 0.5155138969421387, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 8.874966621398926, "eval/cont_pos_acc": 0.999020516872406, "eval/cont_pos_loss": 0.00525739137083292, "eval/cont_pred": 0.9965171813964844, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.17018455266952515, "eval/image_loss_std": 0.14368246495723724, "eval/model_loss_mean": 0.8198061585426331, "eval/model_loss_std": 0.8297209739685059, "eval/post_ent_mag": 41.84925079345703, "eval/post_ent_max": 41.84925079345703, "eval/post_ent_mean": 40.89970779418945, "eval/post_ent_min": 40.013240814208984, "eval/post_ent_std": 0.38268500566482544, "eval/prior_ent_mag": 41.223663330078125, "eval/prior_ent_max": 41.223663330078125, "eval/prior_ent_mean": 40.22571563720703, "eval/prior_ent_min": 39.14741897583008, "eval/prior_ent_std": 0.36657434701919556, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0015655518509447575, "eval/reward_loss_mean": 0.01837868243455887, "eval/reward_loss_std": 0.3626366853713989, "eval/reward_max_data": 0.815625011920929, "eval/reward_max_pred": 0.2912856340408325, "eval/reward_neg_acc": 0.9990215301513672, "eval/reward_neg_loss": 0.003326058853417635, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 7.710270404815674, "eval/reward_pred": 0.0009099990129470825, "eval/reward_rate": 0.001953125, "replay/size": 428133.0, "replay/inserts": 8696.0, "replay/samples": 34784.0, "replay/insert_wait_avg": 1.546704889769497e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.561413980780551e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 97600.0, "eval_replay/inserts": 1744.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0935264989870405e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.493661880493164e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3831796646118, "timer/env.step_count": 1087.0, "timer/env.step_total": 10.661157846450806, "timer/env.step_frac": 0.010657074272305401, "timer/env.step_avg": 0.009807872903818588, "timer/env.step_min": 0.008551597595214844, "timer/env.step_max": 0.0357511043548584, "timer/replay._sample_count": 34784.0, "timer/replay._sample_total": 19.00749444961548, "timer/replay._sample_frac": 0.01900021395400503, "timer/replay._sample_avg": 0.0005464436076821378, "timer/replay._sample_min": 0.0003898143768310547, "timer/replay._sample_max": 0.027402162551879883, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1305.0, "timer/agent.policy_total": 13.26814317703247, "timer/agent.policy_frac": 0.013263061041750767, "timer/agent.policy_avg": 0.010167159522630245, "timer/agent.policy_min": 0.008778095245361328, "timer/agent.policy_max": 0.04274439811706543, "timer/dataset_train_count": 2174.0, "timer/dataset_train_total": 0.37296056747436523, "timer/dataset_train_frac": 0.0003728177113087846, "timer/dataset_train_avg": 0.0001715549988382545, "timer/dataset_train_min": 9.059906005859375e-05, "timer/dataset_train_max": 0.0012280941009521484, "timer/agent.train_count": 2174.0, "timer/agent.train_total": 971.8203251361847, "timer/agent.train_frac": 0.9714480859844093, "timer/agent.train_avg": 0.4470194687838936, "timer/agent.train_min": 0.43561625480651855, "timer/agent.train_max": 0.5802087783813477, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4816548824310303, "timer/agent.report_frac": 0.00048147039276740916, "timer/agent.report_avg": 0.24082744121551514, "timer/agent.report_min": 0.23493671417236328, "timer/agent.report_max": 0.246718168258667, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.5033950805664062e-05, "timer/dataset_eval_frac": 2.5024361979033813e-08, "timer/dataset_eval_avg": 2.5033950805664062e-05, "timer/dataset_eval_min": 2.5033950805664062e-05, "timer/dataset_eval_max": 2.5033950805664062e-05, "fps": 8.692555058930811}
{"step": 428640, "time": 49242.519840717316, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 428760, "time": 49256.46066951752, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 428992, "time": 49282.80810499191, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 429048, "time": 49289.197328567505, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 429096, "time": 49294.65614438057, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 429192, "time": 49305.63237571716, "episode/length": 17.0, "episode/score": 0.9468749761581421, "episode/reward_rate": 0.05555555555555555, "episode/intrinsic_return": 0.0}
{"step": 429200, "time": 49306.56656098366, "episode/length": 12.0, "episode/score": 0.9624999761581421, "episode/reward_rate": 0.07692307692307693, "episode/intrinsic_return": 0.0}
{"step": 429248, "time": 49312.02834105492, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 429944, "time": 49391.78137254715, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 430016, "time": 49400.01738882065, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 430040, "time": 49404.928929805756, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 430040, "time": 49405.05714607239, "eval_episode/length": 93.0, "eval_episode/score": 0.7093750238418579, "eval_episode/reward_rate": 0.010638297872340425}
{"step": 430040, "time": 49405.51367354393, "eval_episode/length": 119.0, "eval_episode/score": 0.628125011920929, "eval_episode/reward_rate": 0.008333333333333333}
{"step": 430040, "time": 49405.80129313469, "eval_episode/length": 41.0, "eval_episode/score": 0.871874988079071, "eval_episode/reward_rate": 0.023809523809523808}
{"step": 430040, "time": 49406.14096450806, "eval_episode/length": 154.0, "eval_episode/score": 0.518750011920929, "eval_episode/reward_rate": 0.0064516129032258064}
{"step": 430040, "time": 49406.300656080246, "eval_episode/length": 163.0, "eval_episode/score": 0.4906249940395355, "eval_episode/reward_rate": 0.006097560975609756}
{"step": 430040, "time": 49406.83098697662, "eval_episode/length": 194.0, "eval_episode/score": 0.39375001192092896, "eval_episode/reward_rate": 0.005128205128205128}
{"step": 430040, "time": 49407.32454633713, "eval_episode/length": 58.0, "eval_episode/score": 0.8187500238418579, "eval_episode/reward_rate": 0.01694915254237288}
{"step": 430096, "time": 49413.70362877846, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 430112, "time": 49415.51616191864, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 430112, "time": 49415.52245545387, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 430520, "time": 49461.95360279083, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 430592, "time": 49470.13877868652, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 430640, "time": 49475.6503162384, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 430688, "time": 49481.263051748276, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 430952, "time": 49511.412157058716, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 431152, "time": 49534.22688746452, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 431168, "time": 49536.0692615509, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 431416, "time": 49564.48546028137, "episode/length": 270.0, "episode/score": 0.15625, "episode/reward_rate": 0.0036900369003690036, "episode/intrinsic_return": 0.0}
{"step": 431648, "time": 49590.97568678856, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 431840, "time": 49612.8864774704, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 432136, "time": 49646.57952642441, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 432320, "time": 49667.65875458717, "episode/length": 275.0, "episode/score": 0.140625, "episode/reward_rate": 0.0036231884057971015, "episode/intrinsic_return": 0.0}
{"step": 432384, "time": 49674.95742177963, "episode/length": 211.0, "episode/score": 0.34062498807907104, "episode/reward_rate": 0.0047169811320754715, "episode/intrinsic_return": 0.0}
{"step": 432592, "time": 49698.71807050705, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 432656, "time": 49706.04246401787, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 433120, "time": 49759.12613654137, "episode/length": 243.0, "episode/score": 0.24062499403953552, "episode/reward_rate": 0.004098360655737705, "episode/intrinsic_return": 0.0}
{"step": 433192, "time": 49767.257850170135, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 433376, "time": 49788.25409221649, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 433384, "time": 49789.16624498367, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 433464, "time": 49798.33124375343, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 433944, "time": 49853.12468314171, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 433944, "time": 49853.13280534744, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 434152, "time": 49876.673756837845, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 434288, "time": 49892.51558446884, "episode/length": 237.0, "episode/score": 0.2593750059604645, "episode/reward_rate": 0.004201680672268907, "episode/intrinsic_return": 0.0}
{"step": 434704, "time": 49940.06643438339, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 434816, "time": 49952.7993786335, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 434904, "time": 49962.85728430748, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 435096, "time": 49984.731402635574, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 435504, "time": 50031.27654671669, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 435536, "time": 50034.951513528824, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 435696, "time": 50053.2701048851, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 435776, "time": 50062.38906097412, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 436040, "time": 50092.53109526634, "episode/length": 218.0, "episode/score": 0.3187499940395355, "episode/reward_rate": 0.0045662100456621, "episode/intrinsic_return": 0.0}
{"step": 436256, "time": 50117.10546755791, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 437128, "time": 50216.19780039787, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 437168, "time": 50220.7664308548, "episode/length": 203.0, "episode/score": 0.3656249940395355, "episode/reward_rate": 0.004901960784313725, "episode/intrinsic_return": 0.0}
{"step": 437224, "time": 50227.142593860626, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 437304, "time": 50236.31792330742, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 437353, "time": 50242.77536153793, "train_stats/mean_log_entropy": 0.07062317825415555, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.7368307509180587, "train/action_min": 0.0, "train/action_std": 1.863001174641095, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.004873821927633669, "train/actor_opt_grad_steps": 107860.0, "train/actor_opt_loss": -17.689804969295377, "train/adv_mag": 0.4642539548983772, "train/adv_max": 0.2260834681822957, "train/adv_mean": 0.0002572825905492025, "train/adv_min": -0.41490120574625955, "train/adv_std": 0.017361274066333948, "train/cont_avg": 0.9958147321428571, "train/cont_loss_mean": 0.013039939306152788, "train/cont_loss_std": 0.2025349089459512, "train/cont_neg_acc": 0.38122185846400813, "train/cont_neg_loss": 2.499197065937441, "train/cont_pos_acc": 0.9999457853181022, "train/cont_pos_loss": 0.002647574179299382, "train/cont_pred": 0.9958542052501907, "train/cont_rate": 0.9958147321428571, "train/dyn_loss_mean": 1.0000000142831407, "train/dyn_loss_std": 4.59754383266573e-07, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.09845016064972098, "train/extr_critic_critic_opt_grad_steps": 107860.0, "train/extr_critic_critic_opt_loss": 6224.669516849079, "train/extr_critic_mag": 0.996613465146535, "train/extr_critic_max": 0.996613465146535, "train/extr_critic_mean": 0.8589182062083126, "train/extr_critic_min": 0.6930906849522744, "train/extr_critic_std": 0.028047794424649757, "train/extr_return_normed_mag": 0.48814541211326, "train/extr_return_normed_max": 0.2785993385974163, "train/extr_return_normed_mean": 0.04114179313182831, "train/extr_return_normed_min": -0.37811388315693023, "train/extr_return_normed_std": 0.03351991380723665, "train/extr_return_rate": 0.9996775053613197, "train/extr_return_raw_mag": 1.09663299041959, "train/extr_return_raw_max": 1.09663299041959, "train/extr_return_raw_mean": 0.8591754843013077, "train/extr_return_raw_min": 0.4399197686652434, "train/extr_return_raw_std": 0.0335199137814858, "train/extr_reward_mag": 0.30665232618832916, "train/extr_reward_max": 0.30665232618832916, "train/extr_reward_mean": 0.0009811729401154744, "train/extr_reward_min": 1.5931195377754177e-08, "train/extr_reward_std": 0.007442533973098007, "train/image_loss_mean": 0.06693735581389221, "train/image_loss_std": 0.09304434012982153, "train/model_loss_mean": 0.6863528687833091, "train/model_loss_std": 0.32805005505612367, "train/model_opt_grad_norm": 13.300630657354258, "train/model_opt_grad_steps": 107763.13824884793, "train/model_opt_loss": 3699.6970901137674, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5391.705069124424, "train/policy_entropy_mag": 1.2751109286936746, "train/policy_entropy_max": 1.2751109286936746, "train/policy_entropy_mean": 0.08915016086008143, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.10677125995060266, "train/policy_logprob_mag": 6.5510802796359435, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.08956417637074598, "train/policy_logprob_min": -6.5510802796359435, "train/policy_logprob_std": 0.6293320356426151, "train/policy_randomness_mag": 0.655277433483282, "train/policy_randomness_max": 0.655277433483282, "train/policy_randomness_mean": 0.04581412398320739, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.054869576807945006, "train/post_ent_mag": 41.60821253693049, "train/post_ent_max": 41.60821253693049, "train/post_ent_mean": 40.66248507873254, "train/post_ent_min": 39.80862374020062, "train/post_ent_std": 0.3833624044871001, "train/prior_ent_mag": 41.2353398722987, "train/prior_ent_max": 41.2353398722987, "train/prior_ent_mean": 40.19603873397897, "train/prior_ent_min": 39.00350136471234, "train/prior_ent_std": 0.36137281886992917, "train/rep_loss_mean": 1.0000000142831407, "train/rep_loss_std": 4.59754383266573e-07, "train/reward_avg": 0.0009094519579696173, "train/reward_loss_mean": 0.006375542589707926, "train/reward_loss_std": 0.12544973935472697, "train/reward_max_data": 0.5393865212180098, "train/reward_max_pred": 0.23037815148929297, "train/reward_neg_acc": 0.9998602238118923, "train/reward_neg_loss": 0.0011618308787886482, "train/reward_pos_acc": 0.29060077649909394, "train/reward_pos_loss": 3.470346301794052, "train/reward_pred": 0.0007519055268413941, "train/reward_rate": 0.0014985959101382488, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.011394808068871498, "report/cont_loss_std": 0.14206932485103607, "report/cont_neg_acc": 0.4000000059604645, "report/cont_neg_loss": 1.6087709665298462, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.003556848270818591, "report/cont_pred": 0.9946596026420593, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.09093689173460007, "report/image_loss_std": 0.10353976488113403, "report/model_loss_mean": 0.7083529233932495, "report/model_loss_std": 0.283306360244751, "report/post_ent_mag": 41.51126480102539, "report/post_ent_max": 41.51126480102539, "report/post_ent_mean": 40.657814025878906, "report/post_ent_min": 39.71821594238281, "report/post_ent_std": 0.37222492694854736, "report/prior_ent_mag": 41.47171401977539, "report/prior_ent_max": 41.47171401977539, "report/prior_ent_mean": 40.567901611328125, "report/prior_ent_min": 39.45049285888672, "report/prior_ent_std": 0.3197479844093323, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0007781982421875, "report/reward_loss_mean": 0.006021186243742704, "report/reward_loss_std": 0.1285352259874344, "report/reward_max_data": 0.565625011920929, "report/reward_max_pred": 0.19058775901794434, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0012731129536405206, "report/reward_pos_acc": 0.5, "report/reward_pos_loss": 2.432286500930786, "report/reward_pred": 0.0007923052180558443, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.9921875, "eval/cont_loss_mean": 0.07003019005060196, "eval/cont_loss_std": 0.7954270243644714, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 8.629873275756836, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0026298516895622015, "eval/cont_pred": 0.9973761439323425, "eval/cont_rate": 0.9921875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.16283529996871948, "eval/image_loss_std": 0.1600884050130844, "eval/model_loss_mean": 0.8653676509857178, "eval/model_loss_std": 1.205764651298523, "eval/post_ent_mag": 41.55006790161133, "eval/post_ent_max": 41.55006790161133, "eval/post_ent_mean": 40.614479064941406, "eval/post_ent_min": 39.72308349609375, "eval/post_ent_std": 0.37294885516166687, "eval/prior_ent_mag": 41.45146179199219, "eval/prior_ent_max": 41.45146179199219, "eval/prior_ent_mean": 40.48215866088867, "eval/prior_ent_min": 39.544960021972656, "eval/prior_ent_std": 0.355913907289505, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0028717040549963713, "eval/reward_loss_mean": 0.03250213339924812, "eval/reward_loss_std": 0.5263750553131104, "eval/reward_max_data": 0.846875011920929, "eval/reward_max_pred": 0.03797459602355957, "eval/reward_neg_acc": 0.9999999403953552, "eval/reward_neg_loss": 0.0011905919527634978, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 8.016944885253906, "eval/reward_pred": 0.0006009895587339997, "eval/reward_rate": 0.00390625, "replay/size": 436849.0, "replay/inserts": 8716.0, "replay/samples": 34864.0, "replay/insert_wait_avg": 1.5364266579826254e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.577572135872774e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 99384.0, "eval_replay/inserts": 1784.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1650970698472095e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.08970832824707e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2695620059967, "timer/env.step_count": 1090.0, "timer/env.step_total": 10.787675380706787, "timer/env.step_frac": 0.010784768216952016, "timer/env.step_avg": 0.009896949890556686, "timer/env.step_min": 0.00807046890258789, "timer/env.step_max": 0.03517794609069824, "timer/replay._sample_count": 34864.0, "timer/replay._sample_total": 18.982640981674194, "timer/replay._sample_frac": 0.018977525361868797, "timer/replay._sample_avg": 0.0005444768523885439, "timer/replay._sample_min": 0.0004048347473144531, "timer/replay._sample_max": 0.028972387313842773, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1313.0, "timer/agent.policy_total": 13.825693845748901, "timer/agent.policy_frac": 0.013821967968336535, "timer/agent.policy_avg": 0.010529850606053999, "timer/agent.policy_min": 0.00809478759765625, "timer/agent.policy_max": 0.09108591079711914, "timer/dataset_train_count": 2179.0, "timer/dataset_train_total": 0.3715221881866455, "timer/dataset_train_frac": 0.000371422066909218, "timer/dataset_train_avg": 0.00017050123367904797, "timer/dataset_train_min": 9.107589721679688e-05, "timer/dataset_train_max": 0.0012083053588867188, "timer/agent.train_count": 2179.0, "timer/agent.train_total": 970.5004239082336, "timer/agent.train_frac": 0.9702388843682673, "timer/agent.train_avg": 0.44538798710795485, "timer/agent.train_min": 0.43387413024902344, "timer/agent.train_max": 0.5720264911651611, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47545552253723145, "timer/agent.report_frac": 0.0004753273923318493, "timer/agent.report_avg": 0.23772776126861572, "timer/agent.report_min": 0.23611998558044434, "timer/agent.report_max": 0.2393355369567871, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.574920654296875e-05, "timer/dataset_eval_frac": 2.5742267405727957e-08, "timer/dataset_eval_avg": 2.574920654296875e-05, "timer/dataset_eval_min": 2.574920654296875e-05, "timer/dataset_eval_max": 2.574920654296875e-05, "fps": 8.7135363669553}
{"step": 437408, "time": 50248.86891293526, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 437464, "time": 50255.23741149902, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 437712, "time": 50283.541768074036, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 437784, "time": 50291.82262277603, "episode/length": 250.0, "episode/score": 0.21875, "episode/reward_rate": 0.00398406374501992, "episode/intrinsic_return": 0.0}
{"step": 437816, "time": 50295.48094153404, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 438176, "time": 50336.683455228806, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 438288, "time": 50349.44422674179, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 438400, "time": 50362.32187795639, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 438448, "time": 50367.82061171532, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 438592, "time": 50384.42622256279, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 438936, "time": 50423.752948760986, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 439536, "time": 50492.18075442314, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 440024, "time": 50547.88786029816, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 440024, "time": 50548.616549015045, "eval_episode/length": 42.0, "eval_episode/score": 0.8687499761581421, "eval_episode/reward_rate": 0.023255813953488372}
{"step": 440024, "time": 50549.25509476662, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 440024, "time": 50549.551028966904, "eval_episode/length": 97.0, "eval_episode/score": 0.6968749761581421, "eval_episode/reward_rate": 0.01020408163265306}
{"step": 440024, "time": 50550.30666208267, "eval_episode/length": 142.0, "eval_episode/score": 0.5562499761581421, "eval_episode/reward_rate": 0.006993006993006993}
{"step": 440024, "time": 50550.42883634567, "eval_episode/length": 149.0, "eval_episode/score": 0.534375011920929, "eval_episode/reward_rate": 0.006666666666666667}
{"step": 440024, "time": 50551.149691820145, "eval_episode/length": 149.0, "eval_episode/score": 0.534375011920929, "eval_episode/reward_rate": 0.006666666666666667}
{"step": 440024, "time": 50552.348641872406, "eval_episode/length": 264.0, "eval_episode/score": 0.17499999701976776, "eval_episode/reward_rate": 0.0037735849056603774}
{"step": 440024, "time": 50552.405088186264, "eval_episode/length": 169.0, "eval_episode/score": 0.47187501192092896, "eval_episode/reward_rate": 0.0058823529411764705}
{"step": 440328, "time": 50587.03609275818, "episode/length": 216.0, "episode/score": 0.32499998807907104, "episode/reward_rate": 0.004608294930875576, "episode/intrinsic_return": 0.0}
{"step": 440360, "time": 50590.6762740612, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 440432, "time": 50598.92275094986, "episode/length": 281.0, "episode/score": 0.12187500298023224, "episode/reward_rate": 0.0035460992907801418, "episode/intrinsic_return": 0.0}
{"step": 440600, "time": 50618.04984712601, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 440712, "time": 50630.89550423622, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 440760, "time": 50636.36991047859, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 440824, "time": 50643.63992714882, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 440960, "time": 50659.26066613197, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 441384, "time": 50707.70780587196, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 441640, "time": 50736.910566568375, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 441712, "time": 50745.1570751667, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 441848, "time": 50760.634471178055, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 442392, "time": 50823.11516070366, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 442744, "time": 50863.30628037453, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 443072, "time": 50900.65744256973, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 443136, "time": 50907.92843079567, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 443272, "time": 50923.39071440697, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 443336, "time": 50930.651337862015, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 443600, "time": 50960.69468474388, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 443656, "time": 50967.061059474945, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 443696, "time": 50971.62733697891, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 443952, "time": 51000.82370901108, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 444128, "time": 51020.9207572937, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 444160, "time": 51024.5542473793, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 444336, "time": 51044.56164073944, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 444512, "time": 51064.45975136757, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 444648, "time": 51079.899517059326, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 444808, "time": 51098.035923719406, "episode/length": 191.0, "episode/score": 0.40312498807907104, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.0}
{"step": 445280, "time": 51151.71944475174, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 445384, "time": 51163.60726809502, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 445520, "time": 51179.06137800217, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 446008, "time": 51234.66068458557, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 446064, "time": 51241.02669453621, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 446073, "time": 51242.92948627472, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.8270781630769783, "train/action_min": 0.0, "train/action_std": 1.8311294311777166, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.005676702924666568, "train/actor_opt_grad_steps": 110035.0, "train/actor_opt_loss": -16.5366156779298, "train/adv_mag": 0.47114115543321733, "train/adv_max": 0.22768435839119308, "train/adv_mean": 0.0002874245497678036, "train/adv_min": -0.4269039700610922, "train/adv_std": 0.01717591165658941, "train/cont_avg": 0.9955741112385321, "train/cont_loss_mean": 0.013384139045662836, "train/cont_loss_std": 0.19898674866492186, "train/cont_neg_acc": 0.3730926841909435, "train/cont_neg_loss": 2.417615888174489, "train/cont_pos_acc": 0.9999280011435168, "train/cont_pos_loss": 0.002747804726689729, "train/cont_pred": 0.9956471211866501, "train/cont_rate": 0.9955741112385321, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.08487402710106669, "train/extr_critic_critic_opt_grad_steps": 110035.0, "train/extr_critic_critic_opt_loss": 5074.888907056336, "train/extr_critic_mag": 1.00891598922397, "train/extr_critic_max": 1.00891598922397, "train/extr_critic_mean": 0.8694567663953938, "train/extr_critic_min": 0.7298210547604692, "train/extr_critic_std": 0.024779448448039525, "train/extr_return_normed_mag": 0.5094527099110665, "train/extr_return_normed_max": 0.28550790974853235, "train/extr_return_normed_mean": 0.03815147034618833, "train/extr_return_normed_min": -0.38912690369361036, "train/extr_return_normed_std": 0.030956057276269166, "train/extr_return_rate": 0.9994759089356169, "train/extr_return_raw_mag": 1.1171006103721233, "train/extr_return_raw_max": 1.1171006103721233, "train/extr_return_raw_mean": 0.869744216903634, "train/extr_return_raw_min": 0.4424657969299806, "train/extr_return_raw_std": 0.03095605719937097, "train/extr_reward_mag": 0.3178450689403289, "train/extr_reward_max": 0.3178450689403289, "train/extr_reward_mean": 0.0010821030582269277, "train/extr_reward_min": 3.2809896206637043e-09, "train/extr_reward_std": 0.007939209272965379, "train/image_loss_mean": 0.06961806820825152, "train/image_loss_std": 0.09616343584766082, "train/model_loss_mean": 0.690134891129415, "train/model_loss_std": 0.3331068994118533, "train/model_opt_grad_norm": 13.13504250038604, "train/model_opt_grad_steps": 109936.19724770643, "train/model_opt_loss": 4082.1319479286126, "train/model_opt_model_opt_grad_overflow": 0.0045871559633027525, "train/model_opt_model_opt_grad_scale": 5894.495412844037, "train/policy_entropy_mag": 1.3090186261255807, "train/policy_entropy_max": 1.3090186261255807, "train/policy_entropy_mean": 0.08645241779335049, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.1025909197713257, "train/policy_logprob_mag": 6.551080264082742, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.08662583050104457, "train/policy_logprob_min": -6.551080264082742, "train/policy_logprob_std": 0.6256073549253132, "train/policy_randomness_mag": 0.6727025383109346, "train/policy_randomness_max": 0.6727025383109346, "train/policy_randomness_mean": 0.04442775837325175, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.052721306322774754, "train/post_ent_mag": 42.22565377961605, "train/post_ent_max": 42.22565377961605, "train/post_ent_mean": 41.27084609565385, "train/post_ent_min": 40.390775820530884, "train/post_ent_std": 0.3947281570882972, "train/prior_ent_mag": 41.75535468005259, "train/prior_ent_max": 41.75535468005259, "train/prior_ent_mean": 40.95108133718508, "train/prior_ent_min": 39.888745176682775, "train/prior_ent_std": 0.30808522675288924, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0009918352835325721, "train/reward_loss_mean": 0.007132663179259457, "train/reward_loss_std": 0.13219535791468934, "train/reward_max_data": 0.5594896814281788, "train/reward_max_pred": 0.22023855655565175, "train/reward_neg_acc": 0.9998249739681909, "train/reward_neg_loss": 0.001327227743143865, "train/reward_pos_acc": 0.2692775990475308, "train/reward_pos_loss": 3.4141882830722765, "train/reward_pred": 0.00081699552151178, "train/reward_rate": 0.0016529888188073394, "train_stats/mean_log_entropy": 0.07097541832405588, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.018543995916843414, "report/cont_loss_std": 0.2727697491645813, "report/cont_neg_acc": 0.3333333432674408, "report/cont_neg_loss": 2.598151683807373, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.003340020077303052, "report/cont_pred": 0.9946877360343933, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.06746748089790344, "report/image_loss_std": 0.082375667989254, "report/model_loss_mean": 0.693372905254364, "report/model_loss_std": 0.3571678400039673, "report/post_ent_mag": 42.205169677734375, "report/post_ent_max": 42.205169677734375, "report/post_ent_mean": 41.261070251464844, "report/post_ent_min": 40.33185958862305, "report/post_ent_std": 0.40819838643074036, "report/prior_ent_mag": 41.291419982910156, "report/prior_ent_max": 41.291419982910156, "report/prior_ent_mean": 40.5446662902832, "report/prior_ent_min": 39.85026550292969, "report/prior_ent_std": 0.23895522952079773, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0007965087424963713, "report/reward_loss_mean": 0.007361408323049545, "report/reward_loss_std": 0.1364315003156662, "report/reward_max_data": 0.684374988079071, "report/reward_max_pred": 0.10494387149810791, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0014504233840852976, "report/reward_pos_acc": 0.5, "report/reward_pos_loss": 3.0278749465942383, "report/reward_pred": 0.0008541466668248177, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.9931640625, "eval/cont_loss_mean": 0.044644273817539215, "eval/cont_loss_std": 0.5440076589584351, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.112448215484619, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.0028796480037271976, "eval/cont_pred": 0.9971673488616943, "eval/cont_rate": 0.9931640625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.13172920048236847, "eval/image_loss_std": 0.1347547173500061, "eval/model_loss_mean": 0.7865328192710876, "eval/model_loss_std": 0.6573026180267334, "eval/post_ent_mag": 42.21092224121094, "eval/post_ent_max": 42.21092224121094, "eval/post_ent_mean": 41.22692108154297, "eval/post_ent_min": 40.211029052734375, "eval/post_ent_std": 0.41417914628982544, "eval/prior_ent_mag": 41.30979919433594, "eval/prior_ent_max": 41.30979919433594, "eval/prior_ent_mean": 40.51804733276367, "eval/prior_ent_min": 39.839500427246094, "eval/prior_ent_std": 0.25120070576667786, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0013061524368822575, "eval/reward_loss_mean": 0.010159289464354515, "eval/reward_loss_std": 0.1974174976348877, "eval/reward_max_data": 0.675000011920929, "eval/reward_max_pred": 0.11780142784118652, "eval/reward_neg_acc": 0.9990215301513672, "eval/reward_neg_loss": 0.0015971765387803316, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 4.385398864746094, "eval/reward_pred": 0.0008084827568382025, "eval/reward_rate": 0.001953125, "replay/size": 445569.0, "replay/inserts": 8720.0, "replay/samples": 34880.0, "replay/insert_wait_avg": 1.6029548207554248e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.582230305452959e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 2144.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.000268245810893e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.195638656616211e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1388833522797, "timer/env.step_count": 1090.0, "timer/env.step_total": 10.826748371124268, "timer/env.step_frac": 0.01082524492481986, "timer/env.step_avg": 0.009932796670756208, "timer/env.step_min": 0.00865030288696289, "timer/env.step_max": 0.035045623779296875, "timer/replay._sample_count": 34880.0, "timer/replay._sample_total": 18.813351154327393, "timer/replay._sample_frac": 0.018810738655884007, "timer/replay._sample_avg": 0.00053937359960801, "timer/replay._sample_min": 0.00037741661071777344, "timer/replay._sample_max": 0.0283660888671875, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1358.0, "timer/agent.policy_total": 13.676444292068481, "timer/agent.policy_frac": 0.013674545125400566, "timer/agent.policy_avg": 0.01007101936087517, "timer/agent.policy_min": 0.00874781608581543, "timer/agent.policy_max": 0.03625798225402832, "timer/dataset_train_count": 2180.0, "timer/dataset_train_total": 0.37850499153137207, "timer/dataset_train_frac": 0.0003784524307891057, "timer/dataset_train_avg": 0.00017362614290429912, "timer/dataset_train_min": 9.34600830078125e-05, "timer/dataset_train_max": 0.000978231430053711, "timer/agent.train_count": 2180.0, "timer/agent.train_total": 970.7361252307892, "timer/agent.train_frac": 0.9706013248650649, "timer/agent.train_avg": 0.4452918005645822, "timer/agent.train_min": 0.4330270290374756, "timer/agent.train_max": 0.5965862274169922, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47974538803100586, "timer/agent.report_frac": 0.00047967876863560036, "timer/agent.report_avg": 0.23987269401550293, "timer/agent.report_min": 0.2354588508605957, "timer/agent.report_max": 0.24428653717041016, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.5033950805664062e-05, "timer/dataset_eval_frac": 2.5030474489457815e-08, "timer/dataset_eval_avg": 2.5033950805664062e-05, "timer/dataset_eval_min": 2.5033950805664062e-05, "timer/dataset_eval_max": 2.5033950805664062e-05, "fps": 8.718680325690382}
{"step": 446264, "time": 51264.52926135063, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 446440, "time": 51284.67899465561, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 446456, "time": 51286.49503207207, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 446776, "time": 51322.81289124489, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 446960, "time": 51343.79050922394, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 447120, "time": 51361.95694947243, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 447256, "time": 51377.442194223404, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 447280, "time": 51380.1802880764, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 447376, "time": 51391.06619334221, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 447664, "time": 51423.87670660019, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 447832, "time": 51443.02124786377, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 447832, "time": 51443.03028798103, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 448184, "time": 51483.07644033432, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 448432, "time": 51511.31359028816, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 448504, "time": 51519.49925470352, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 448576, "time": 51527.742941617966, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 448696, "time": 51541.37168717384, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 448736, "time": 51545.917798280716, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 448976, "time": 51573.10308980942, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 449272, "time": 51606.82525897026, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 449432, "time": 51625.13637781143, "episode/length": 199.0, "episode/score": 0.37812501192092896, "episode/reward_rate": 0.005, "episode/intrinsic_return": 0.0}
{"step": 449680, "time": 51653.374696969986, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 449920, "time": 51680.622163534164, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 449992, "time": 51688.771723270416, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 450008, "time": 51691.08389496803, "eval_episode/length": 26.0, "eval_episode/score": 0.918749988079071, "eval_episode/reward_rate": 0.037037037037037035}
{"step": 450008, "time": 51691.3088862896, "eval_episode/length": 39.0, "eval_episode/score": 0.878125011920929, "eval_episode/reward_rate": 0.025}
{"step": 450008, "time": 51692.14568376541, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 450008, "time": 51692.15127134323, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 450008, "time": 51692.68668460846, "eval_episode/length": 119.0, "eval_episode/score": 0.628125011920929, "eval_episode/reward_rate": 0.008333333333333333}
{"step": 450008, "time": 51692.98860216141, "eval_episode/length": 136.0, "eval_episode/score": 0.574999988079071, "eval_episode/reward_rate": 0.0072992700729927005}
{"step": 450008, "time": 51693.01187825203, "eval_episode/length": 137.0, "eval_episode/score": 0.5718749761581421, "eval_episode/reward_rate": 0.007246376811594203}
{"step": 450008, "time": 51693.42328977585, "eval_episode/length": 161.0, "eval_episode/score": 0.49687498807907104, "eval_episode/reward_rate": 0.006172839506172839}
{"step": 450048, "time": 51697.95249128342, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 450168, "time": 51711.670317173004, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 450216, "time": 51717.11073899269, "episode/length": 213.0, "episode/score": 0.3343749940395355, "episode/reward_rate": 0.004672897196261682, "episode/intrinsic_return": 0.0}
{"step": 450664, "time": 51768.474657297134, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 450744, "time": 51777.575268507004, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 450960, "time": 51802.164615154266, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 451336, "time": 51845.00607419014, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 451584, "time": 51873.19137477875, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 451680, "time": 51884.16867375374, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 451760, "time": 51893.258867025375, "episode/length": 21.0, "episode/score": 0.934374988079071, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.0}
{"step": 451992, "time": 51919.63599705696, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 452360, "time": 51961.41357254982, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 452480, "time": 51975.103058815, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 452528, "time": 51980.54731297493, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 452736, "time": 52004.16320538521, "episode/length": 221.0, "episode/score": 0.30937498807907104, "episode/reward_rate": 0.0045045045045045045, "episode/intrinsic_return": 0.0}
{"step": 452736, "time": 52004.169632434845, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 453056, "time": 52040.44344210625, "episode/length": 214.0, "episode/score": 0.33125001192092896, "episode/reward_rate": 0.004651162790697674, "episode/intrinsic_return": 0.0}
{"step": 453344, "time": 52073.09154033661, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 453416, "time": 52081.2927274704, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 453600, "time": 52102.2432076931, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 453712, "time": 52114.91330933571, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 453952, "time": 52142.095705509186, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 453992, "time": 52146.62960767746, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 454024, "time": 52150.27180767059, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 454072, "time": 52155.79500222206, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 454072, "time": 52155.80207324028, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 454336, "time": 52185.79759669304, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 454336, "time": 52185.805847883224, "episode/length": 199.0, "episode/score": 0.37812501192092896, "episode/reward_rate": 0.005, "episode/intrinsic_return": 0.0}
{"step": 454672, "time": 52223.96337866783, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 454833, "time": 52243.17578315735, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.6668932492330195, "train/action_min": 0.0, "train/action_std": 1.8299440074729048, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.005058186895800882, "train/actor_opt_grad_steps": 112220.0, "train/actor_opt_loss": -18.736188635978525, "train/adv_mag": 0.4398943478386152, "train/adv_max": 0.22052549444921485, "train/adv_mean": -0.0006606016792734387, "train/adv_min": -0.3945558992422879, "train/adv_std": 0.016933454944832955, "train/cont_avg": 0.9954204123858448, "train/cont_loss_mean": 0.014689719410226192, "train/cont_loss_std": 0.2147679525453036, "train/cont_neg_acc": 0.3430016142649388, "train/cont_neg_loss": 2.5480234805922293, "train/cont_pos_acc": 0.9999238162824552, "train/cont_pos_loss": 0.0028978733815780105, "train/cont_pred": 0.9956084201325021, "train/cont_rate": 0.9954204123858448, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.08650132043278652, "train/extr_critic_critic_opt_grad_steps": 112220.0, "train/extr_critic_critic_opt_loss": 7419.8094833583045, "train/extr_critic_mag": 0.9812607727094328, "train/extr_critic_max": 0.9812607727094328, "train/extr_critic_mean": 0.8397714623577519, "train/extr_critic_min": 0.7124053511989715, "train/extr_critic_std": 0.02789748724141758, "train/extr_return_normed_mag": 0.47448357000742875, "train/extr_return_normed_max": 0.28842745251851537, "train/extr_return_normed_mean": 0.03842364949892917, "train/extr_return_normed_min": -0.34417658826531883, "train/extr_return_normed_std": 0.033429636547690655, "train/extr_return_rate": 0.9996970995376099, "train/extr_return_raw_mag": 1.0891146706119519, "train/extr_return_raw_max": 1.0891146706119519, "train/extr_return_raw_mean": 0.8391109144306619, "train/extr_return_raw_min": 0.45651062982811774, "train/extr_return_raw_std": 0.03342963645413314, "train/extr_reward_mag": 0.32511295466662543, "train/extr_reward_max": 0.32511295466662543, "train/extr_reward_mean": 0.0010191555310106628, "train/extr_reward_min": 2.9938406051566066e-08, "train/extr_reward_std": 0.0075070570907704364, "train/image_loss_mean": 0.06919754473449977, "train/image_loss_std": 0.09522941358149324, "train/model_loss_mean": 0.6915051292066705, "train/model_loss_std": 0.34853173942054244, "train/model_opt_grad_norm": 12.945967598048519, "train/model_opt_grad_steps": 112119.43378995433, "train/model_opt_loss": 3915.1065567922374, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5662.100456621005, "train/policy_entropy_mag": 1.2842436304919795, "train/policy_entropy_max": 1.2842436304919795, "train/policy_entropy_mean": 0.09301268244715041, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.11500163658704932, "train/policy_logprob_mag": 6.551080272622304, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09276549126867835, "train/policy_logprob_min": -6.551080272622304, "train/policy_logprob_std": 0.629856775884759, "train/policy_randomness_mag": 0.6599707124440093, "train/policy_randomness_max": 0.6599707124440093, "train/policy_randomness_mean": 0.0477990678864527, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.059099154147111116, "train/post_ent_mag": 42.05690936084207, "train/post_ent_max": 42.05690936084207, "train/post_ent_mean": 41.02151956079213, "train/post_ent_min": 40.06910560991122, "train/post_ent_std": 0.4274156292279561, "train/prior_ent_mag": 41.28666234125286, "train/prior_ent_max": 41.28666234125286, "train/prior_ent_mean": 40.49963474709149, "train/prior_ent_min": 39.73493279931752, "train/prior_ent_std": 0.24671980602556168, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.001083401892747258, "train/reward_loss_mean": 0.007617841098887089, "train/reward_loss_std": 0.137618133371917, "train/reward_max_data": 0.564469178721785, "train/reward_max_pred": 0.2570377620932174, "train/reward_neg_acc": 0.9997766883405921, "train/reward_neg_loss": 0.0013857545268926004, "train/reward_pos_acc": 0.28641775106503203, "train/reward_pos_loss": 3.3997879860584033, "train/reward_pred": 0.0009245243440190815, "train/reward_rate": 0.0018461044520547945, "train_stats/mean_log_entropy": 0.07251393106186164, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.012294922955334187, "report/cont_loss_std": 0.2158958911895752, "report/cont_neg_acc": 0.5, "report/cont_neg_loss": 2.5040764808654785, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.002523228991776705, "report/cont_pred": 0.9960449934005737, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.08181874454021454, "report/image_loss_std": 0.12093988806009293, "report/model_loss_mean": 0.6997039318084717, "report/model_loss_std": 0.32948461174964905, "report/post_ent_mag": 42.40907287597656, "report/post_ent_max": 42.40907287597656, "report/post_ent_mean": 41.25110626220703, "report/post_ent_min": 40.26136779785156, "report/post_ent_std": 0.4359876811504364, "report/prior_ent_mag": 41.2896728515625, "report/prior_ent_max": 41.2896728515625, "report/prior_ent_mean": 40.4251708984375, "report/prior_ent_min": 39.74617004394531, "report/prior_ent_std": 0.23774836957454681, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0012115478748455644, "report/reward_loss_mean": 0.00559026375412941, "report/reward_loss_std": 0.12582965195178986, "report/reward_max_data": 0.643750011920929, "report/reward_max_pred": 0.5873829126358032, "report/reward_neg_acc": 0.9980430603027344, "report/reward_neg_loss": 0.0015127017395570874, "report/reward_pos_acc": 0.5, "report/reward_pos_loss": 2.089224338531494, "report/reward_pred": 0.0013546994887292385, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.056260913610458374, "eval/cont_loss_std": 0.7585519552230835, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 10.825037002563477, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.003420991124585271, "eval/cont_pred": 0.9967777729034424, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.14988848567008972, "eval/image_loss_std": 0.1450050175189972, "eval/model_loss_mean": 0.8075131177902222, "eval/model_loss_std": 0.7734227180480957, "eval/post_ent_mag": 42.333133697509766, "eval/post_ent_max": 42.333133697509766, "eval/post_ent_mean": 41.23444366455078, "eval/post_ent_min": 40.256248474121094, "eval/post_ent_std": 0.4370814263820648, "eval/prior_ent_mag": 41.09119415283203, "eval/prior_ent_max": 41.09119415283203, "eval/prior_ent_mean": 40.4412841796875, "eval/prior_ent_min": 39.738128662109375, "eval/prior_ent_std": 0.24967655539512634, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.001363646937534213, "eval/reward_loss_std": 0.011474157683551311, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.16080141067504883, "eval/reward_neg_acc": 0.9990234375, "eval/reward_neg_loss": 0.001363646937534213, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0006865722825750709, "eval/reward_rate": 0.0, "replay/size": 454329.0, "replay/inserts": 8760.0, "replay/samples": 35040.0, "replay/insert_wait_avg": 1.5497207641601562e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.015112872537413e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 1296.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.043449213475357e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.834766387939453e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.232274055481, "timer/env.step_count": 1095.0, "timer/env.step_total": 10.830627202987671, "timer/env.step_frac": 0.010828112113473872, "timer/env.step_avg": 0.009890983747020705, "timer/env.step_min": 0.008706331253051758, "timer/env.step_max": 0.036153554916381836, "timer/replay._sample_count": 35040.0, "timer/replay._sample_total": 17.643916845321655, "timer/replay._sample_frac": 0.017639819572891506, "timer/replay._sample_avg": 0.0005035364396495907, "timer/replay._sample_min": 0.00035953521728515625, "timer/replay._sample_max": 0.02826523780822754, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1257.0, "timer/agent.policy_total": 12.780788898468018, "timer/agent.policy_frac": 0.012777820942177569, "timer/agent.policy_avg": 0.010167692043331756, "timer/agent.policy_min": 0.008829593658447266, "timer/agent.policy_max": 0.03249096870422363, "timer/dataset_train_count": 2190.0, "timer/dataset_train_total": 0.3836793899536133, "timer/dataset_train_frac": 0.000383590291880875, "timer/dataset_train_avg": 0.00017519606847196954, "timer/dataset_train_min": 9.298324584960938e-05, "timer/dataset_train_max": 0.003693103790283203, "timer/agent.train_count": 2190.0, "timer/agent.train_total": 972.3943316936493, "timer/agent.train_frac": 0.9721685221683943, "timer/agent.train_avg": 0.4440156765724426, "timer/agent.train_min": 0.43366003036499023, "timer/agent.train_max": 0.5953280925750732, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47905707359313965, "timer/agent.report_frac": 0.0004789458269035691, "timer/agent.report_avg": 0.23952853679656982, "timer/agent.report_min": 0.23251700401306152, "timer/agent.report_max": 0.24654006958007812, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.24249267578125e-05, "timer/dataset_eval_frac": 3.2417397037534454e-08, "timer/dataset_eval_avg": 3.24249267578125e-05, "timer/dataset_eval_min": 3.24249267578125e-05, "timer/dataset_eval_max": 3.24249267578125e-05, "fps": 8.75784723955485}
{"step": 454888, "time": 52249.22306227684, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 455064, "time": 52269.17060470581, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 455232, "time": 52288.257754802704, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 455304, "time": 52296.43989229202, "episode/length": 235.0, "episode/score": 0.265625, "episode/reward_rate": 0.00423728813559322, "episode/intrinsic_return": 0.0}
{"step": 455440, "time": 52311.95521593094, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 455640, "time": 52334.73142695427, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 455736, "time": 52345.623698711395, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 455824, "time": 52355.58628535271, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 456024, "time": 52378.308250665665, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 456312, "time": 52411.01477313042, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 456384, "time": 52419.180032491684, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 456648, "time": 52449.182315826416, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 456784, "time": 52464.6275370121, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 456904, "time": 52478.176404953, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 457120, "time": 52502.69272708893, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 457200, "time": 52511.87247943878, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 457280, "time": 52520.96994662285, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 457392, "time": 52533.76072883606, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 457616, "time": 52559.355870723724, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 457728, "time": 52572.177723646164, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 457752, "time": 52574.90128040314, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 458128, "time": 52617.72372031212, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 458136, "time": 52618.638489723206, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 458440, "time": 52653.24046635628, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 458816, "time": 52696.48077201843, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 459192, "time": 52739.21707725525, "episode/length": 238.0, "episode/score": 0.2562499940395355, "episode/reward_rate": 0.0041841004184100415, "episode/intrinsic_return": 0.0}
{"step": 459216, "time": 52741.95567560196, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 459304, "time": 52752.0332801342, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 459512, "time": 52775.649117946625, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 460064, "time": 52838.68430662155, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 460096, "time": 52843.80954194069, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 460096, "time": 52844.28188538551, "eval_episode/length": 107.0, "eval_episode/score": 0.6656249761581421, "eval_episode/reward_rate": 0.009259259259259259}
{"step": 460096, "time": 52844.824939250946, "eval_episode/length": 55.0, "eval_episode/score": 0.828125, "eval_episode/reward_rate": 0.017857142857142856}
{"step": 460096, "time": 52845.09269785881, "eval_episode/length": 152.0, "eval_episode/score": 0.5249999761581421, "eval_episode/reward_rate": 0.006535947712418301}
{"step": 460096, "time": 52845.13391947746, "eval_episode/length": 154.0, "eval_episode/score": 0.518750011920929, "eval_episode/reward_rate": 0.0064516129032258064}
{"step": 460096, "time": 52845.2940325737, "eval_episode/length": 55.0, "eval_episode/score": 0.828125, "eval_episode/reward_rate": 0.017857142857142856}
{"step": 460096, "time": 52845.31720876694, "eval_episode/length": 164.0, "eval_episode/score": 0.48750001192092896, "eval_episode/reward_rate": 0.006060606060606061}
{"step": 460096, "time": 52845.6232585907, "eval_episode/length": 182.0, "eval_episode/score": 0.4312500059604645, "eval_episode/reward_rate": 0.00546448087431694}
{"step": 460440, "time": 52884.79587650299, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 460448, "time": 52885.70494532585, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 460752, "time": 52920.35516452789, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 461344, "time": 52987.77360725403, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 461504, "time": 53006.01027035713, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 461528, "time": 53008.74659013748, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 461616, "time": 53018.75980043411, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 461632, "time": 53020.57451581955, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 461744, "time": 53033.378524303436, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 461824, "time": 53042.48287320137, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 462376, "time": 53105.41973686218, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 462744, "time": 53147.4237370491, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 462760, "time": 53149.25862669945, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 462824, "time": 53156.53491663933, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 462872, "time": 53161.98799228668, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 462896, "time": 53164.726065158844, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 463112, "time": 53189.349617004395, "episode/length": 197.0, "episode/score": 0.3843750059604645, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.0}
{"step": 463577, "time": 53243.3103928566, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.5088944108518834, "train/action_min": 0.0, "train/action_std": 1.8298117608240205, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0058047896576407425, "train/actor_opt_grad_steps": 114410.0, "train/actor_opt_loss": -20.07715107643441, "train/adv_mag": 0.4583710832138584, "train/adv_max": 0.2251696891436294, "train/adv_mean": 0.000164910218604725, "train/adv_min": -0.4140951675639305, "train/adv_std": 0.018554588350293028, "train/cont_avg": 0.9953891980593608, "train/cont_loss_mean": 0.01423852403380283, "train/cont_loss_std": 0.20733768941375286, "train/cont_neg_acc": 0.3466297341381899, "train/cont_neg_loss": 2.453874455199444, "train/cont_pos_acc": 0.9999059196476523, "train/cont_pos_loss": 0.0029325537743965444, "train/cont_pred": 0.9955085322737149, "train/cont_rate": 0.9953891980593608, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.0870277848622026, "train/extr_critic_critic_opt_grad_steps": 114410.0, "train/extr_critic_critic_opt_loss": 7650.324187535673, "train/extr_critic_mag": 0.9713834720115139, "train/extr_critic_max": 0.9713834720115139, "train/extr_critic_mean": 0.840399396746126, "train/extr_critic_min": 0.7008806477942967, "train/extr_critic_std": 0.030483443723761872, "train/extr_return_normed_mag": 0.48474356491271764, "train/extr_return_normed_max": 0.28204141251028403, "train/extr_return_normed_mean": 0.04405612087719245, "train/extr_return_normed_min": -0.3676202109415237, "train/extr_return_normed_std": 0.03637482504015916, "train/extr_return_rate": 0.9996260483515317, "train/extr_return_raw_mag": 1.0785496381864155, "train/extr_return_raw_max": 1.0785496381864155, "train/extr_return_raw_mean": 0.840564389751382, "train/extr_return_raw_min": 0.42888801473460786, "train/extr_return_raw_std": 0.036374824895570264, "train/extr_reward_mag": 0.3191469167465489, "train/extr_reward_max": 0.3191469167465489, "train/extr_reward_mean": 0.0009612741330734211, "train/extr_reward_min": 2.667239811866795e-08, "train/extr_reward_std": 0.007553136500330072, "train/image_loss_mean": 0.06988898338112112, "train/image_loss_std": 0.09602858655188726, "train/model_loss_mean": 0.692270963975828, "train/model_loss_std": 0.3533836965487428, "train/model_opt_grad_norm": 12.897350513771789, "train/model_opt_grad_steps": 114307.44748858447, "train/model_opt_loss": 3796.5003021100883, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5479.45205479452, "train/policy_entropy_mag": 1.284606187855272, "train/policy_entropy_max": 1.284606187855272, "train/policy_entropy_mean": 0.09900569252363622, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.12518538674127022, "train/policy_logprob_mag": 6.5510803009277065, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09854035130510591, "train/policy_logprob_min": -6.5510803009277065, "train/policy_logprob_std": 0.6338834348878905, "train/policy_randomness_mag": 0.6601570283985574, "train/policy_randomness_max": 0.6601570283985574, "train/policy_randomness_mean": 0.05087886568686189, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06433256659401607, "train/post_ent_mag": 42.34652781377644, "train/post_ent_max": 42.34652781377644, "train/post_ent_mean": 41.252975516123314, "train/post_ent_min": 40.22769079687389, "train/post_ent_std": 0.45292890861154145, "train/prior_ent_mag": 41.29856346513583, "train/prior_ent_max": 41.29856346513583, "train/prior_ent_mean": 40.42994935545203, "train/prior_ent_min": 39.56483407216529, "train/prior_ent_std": 0.27587465213858375, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0011222525871864874, "train/reward_loss_mean": 0.008143436277421302, "train/reward_loss_std": 0.1472033572140826, "train/reward_max_data": 0.6099315089722203, "train/reward_max_pred": 0.2239600077067336, "train/reward_neg_acc": 0.999790010114783, "train/reward_neg_loss": 0.0013984591312351377, "train/reward_pos_acc": 0.24835069570690393, "train/reward_pos_loss": 3.4409898781838515, "train/reward_pred": 0.000866323918929179, "train/reward_rate": 0.001912992294520548, "train_stats/mean_log_entropy": 0.07291872038486157, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.004408065229654312, "report/cont_loss_std": 0.07243922352790833, "report/cont_neg_acc": 0.5, "report/cont_neg_loss": 1.1621395349502563, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0021424461156129837, "report/cont_pred": 0.9968910813331604, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.06751836091279984, "report/image_loss_std": 0.09355086088180542, "report/model_loss_mean": 0.6753685474395752, "report/model_loss_std": 0.19376549124717712, "report/post_ent_mag": 42.172508239746094, "report/post_ent_max": 42.172508239746094, "report/post_ent_mean": 41.02690124511719, "report/post_ent_min": 39.88699722290039, "report/post_ent_std": 0.4604828953742981, "report/prior_ent_mag": 41.21108627319336, "report/prior_ent_max": 41.21108627319336, "report/prior_ent_mean": 40.11953353881836, "report/prior_ent_min": 38.698448181152344, "report/prior_ent_std": 0.4132218658924103, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0007202148553915322, "report/reward_loss_mean": 0.0034421065356582403, "report/reward_loss_std": 0.08576475083827972, "report/reward_max_data": 0.737500011920929, "report/reward_max_pred": 0.0819786787033081, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0007651716587133706, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 2.7419464588165283, "report/reward_pred": 0.00043285335414111614, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.02882986143231392, "eval/cont_loss_std": 0.46648693084716797, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.791266441345215, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.0023105049040168524, "eval/cont_pred": 0.9976916909217834, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.14833292365074158, "eval/image_loss_std": 0.13123393058776855, "eval/model_loss_mean": 0.7861823439598083, "eval/model_loss_std": 0.6506676077842712, "eval/post_ent_mag": 42.2540397644043, "eval/post_ent_max": 42.2540397644043, "eval/post_ent_mean": 41.12250518798828, "eval/post_ent_min": 40.01909255981445, "eval/post_ent_std": 0.4647320508956909, "eval/prior_ent_mag": 41.219783782958984, "eval/prior_ent_max": 41.219783782958984, "eval/prior_ent_mean": 40.161170959472656, "eval/prior_ent_min": 38.756622314453125, "eval/prior_ent_std": 0.4183472990989685, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0008148193592205644, "eval/reward_loss_mean": 0.009019552730023861, "eval/reward_loss_std": 0.2569827735424042, "eval/reward_max_data": 0.8343750238418579, "eval/reward_max_pred": 0.04411280155181885, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0009872345253825188, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 8.226079940795898, "eval/reward_pred": 0.0004496531328186393, "eval/reward_rate": 0.0009765625, "replay/size": 463073.0, "replay/inserts": 8744.0, "replay/samples": 34976.0, "replay/insert_wait_avg": 1.5791958881318843e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 6.940628232371338e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 1464.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.073860731281218e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.121723651886, "timer/env.step_count": 1093.0, "timer/env.step_total": 10.832813739776611, "timer/env.step_frac": 0.010831495290614453, "timer/env.step_avg": 0.009911083019008794, "timer/env.step_min": 0.008616924285888672, "timer/env.step_max": 0.034911155700683594, "timer/replay._sample_count": 34976.0, "timer/replay._sample_total": 17.53050947189331, "timer/replay._sample_frac": 0.017528375853972735, "timer/replay._sample_avg": 0.0005012153897499231, "timer/replay._sample_min": 0.0003840923309326172, "timer/replay._sample_max": 0.010977029800415039, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1276.0, "timer/agent.policy_total": 12.969013452529907, "timer/agent.policy_frac": 0.012967435008985019, "timer/agent.policy_avg": 0.010163803646183312, "timer/agent.policy_min": 0.00878286361694336, "timer/agent.policy_max": 0.031198740005493164, "timer/dataset_train_count": 2186.0, "timer/dataset_train_total": 0.40363645553588867, "timer/dataset_train_frac": 0.0004035873294122977, "timer/dataset_train_avg": 0.00018464613702465172, "timer/dataset_train_min": 9.465217590332031e-05, "timer/dataset_train_max": 0.021992921829223633, "timer/agent.train_count": 2186.0, "timer/agent.train_total": 971.8932373523712, "timer/agent.train_frac": 0.9717749493567241, "timer/agent.train_avg": 0.44459891919138667, "timer/agent.train_min": 0.4339568614959717, "timer/agent.train_max": 0.6088886260986328, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4769575595855713, "timer/agent.report_frac": 0.0004768995096356758, "timer/agent.report_avg": 0.23847877979278564, "timer/agent.report_min": 0.23154091835021973, "timer/agent.report_max": 0.24541664123535156, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.147125244140625e-05, "timer/dataset_eval_frac": 3.1467422111871356e-08, "timer/dataset_eval_avg": 3.147125244140625e-05, "timer/dataset_eval_min": 3.147125244140625e-05, "timer/dataset_eval_max": 3.147125244140625e-05, "fps": 8.742819838218907}
{"step": 463656, "time": 53252.15565657616, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 463816, "time": 53270.415400743484, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 463968, "time": 53287.706330776215, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 463976, "time": 53288.61415219307, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 464080, "time": 53300.518280267715, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 464376, "time": 53334.23976063728, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 464384, "time": 53335.15815639496, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 465000, "time": 53405.68809866905, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 465080, "time": 53414.98324370384, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 465136, "time": 53421.396966695786, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 465208, "time": 53429.623473882675, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 465424, "time": 53454.382158994675, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 465512, "time": 53464.461165905, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 465864, "time": 53504.92739224434, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 465944, "time": 53514.13439202309, "episode/length": 246.0, "episode/score": 0.23125000298023224, "episode/reward_rate": 0.004048582995951417, "episode/intrinsic_return": 0.0}
{"step": 466296, "time": 53554.568236112595, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 466384, "time": 53564.70928502083, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 466440, "time": 53571.130021333694, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 466592, "time": 53588.508501291275, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 466688, "time": 53599.59361076355, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 466888, "time": 53622.62008190155, "episode/length": 209.0, "episode/score": 0.34687501192092896, "episode/reward_rate": 0.004761904761904762, "episode/intrinsic_return": 0.0}
{"step": 466920, "time": 53626.29284095764, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 467224, "time": 53661.4627494812, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 467312, "time": 53671.523668289185, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 467336, "time": 53674.28572702408, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 467648, "time": 53709.85137796402, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 468080, "time": 53759.13959360123, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 468096, "time": 53760.952652692795, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 468200, "time": 53772.857088804245, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 468256, "time": 53779.21380066872, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 468608, "time": 53819.207181453705, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 468800, "time": 53841.11027431488, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 468824, "time": 53843.83836436272, "episode/length": 241.0, "episode/score": 0.24687500298023224, "episode/reward_rate": 0.004132231404958678, "episode/intrinsic_return": 0.0}
{"step": 468960, "time": 53859.27404713631, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 468992, "time": 53862.990671396255, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 469200, "time": 53886.72891807556, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 469392, "time": 53908.58878445625, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 469624, "time": 53934.98924779892, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 469648, "time": 53937.71820139885, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 469696, "time": 53943.1509616375, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 469824, "time": 53957.727972745895, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 470080, "time": 53987.462844371796, "eval_episode/length": 32.0, "eval_episode/score": 0.8999999761581421, "eval_episode/reward_rate": 0.030303030303030304}
{"step": 470080, "time": 53987.467529296875, "eval_episode/length": 32.0, "eval_episode/score": 0.8999999761581421, "eval_episode/reward_rate": 0.030303030303030304}
{"step": 470080, "time": 53987.59258246422, "eval_episode/length": 39.0, "eval_episode/score": 0.878125011920929, "eval_episode/reward_rate": 0.025}
{"step": 470080, "time": 53988.07579946518, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 470080, "time": 53988.559532403946, "eval_episode/length": 94.0, "eval_episode/score": 0.706250011920929, "eval_episode/reward_rate": 0.010526315789473684}
{"step": 470080, "time": 53988.91215157509, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 470080, "time": 53989.278824567795, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 470080, "time": 53989.69505786896, "eval_episode/length": 126.0, "eval_episode/score": 0.606249988079071, "eval_episode/reward_rate": 0.007874015748031496}
{"step": 470408, "time": 54027.007942676544, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 470448, "time": 54031.567244291306, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 470800, "time": 54071.732560157776, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 471112, "time": 54107.279766082764, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 471152, "time": 54111.8466424942, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 471416, "time": 54141.91176366806, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 471512, "time": 54152.79493379593, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 471560, "time": 54158.272783756256, "episode/length": 270.0, "episode/score": 0.15625, "episode/reward_rate": 0.0036900369003690036, "episode/intrinsic_return": 0.0}
{"step": 471848, "time": 54191.02278113365, "episode/length": 252.0, "episode/score": 0.21250000596046448, "episode/reward_rate": 0.003952569169960474, "episode/intrinsic_return": 0.0}
{"step": 471936, "time": 54201.01010966301, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 472301, "time": 54243.33162546158, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.4104703850702407, "train/action_min": 0.0, "train/action_std": 1.8432324151380346, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00707192726672516, "train/actor_opt_grad_steps": 116595.0, "train/actor_opt_loss": -20.167137110998873, "train/adv_mag": 0.5155881212665401, "train/adv_max": 0.26225011884619337, "train/adv_mean": 5.730266088575046e-05, "train/adv_min": -0.4612496657929289, "train/adv_std": 0.020590322732993768, "train/cont_avg": 0.9958204916857798, "train/cont_loss_mean": 0.013366026469557589, "train/cont_loss_std": 0.19580569671928336, "train/cont_neg_acc": 0.3726210570031846, "train/cont_neg_loss": 2.430059041265782, "train/cont_pos_acc": 0.9999145419772612, "train/cont_pos_loss": 0.0029649239099144493, "train/cont_pred": 0.9956809301441962, "train/cont_rate": 0.9958204916857798, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.10030426623282629, "train/extr_critic_critic_opt_grad_steps": 116595.0, "train/extr_critic_critic_opt_loss": 8510.718792556623, "train/extr_critic_mag": 0.9915618836332899, "train/extr_critic_max": 0.9915618836332899, "train/extr_critic_mean": 0.8290808826958368, "train/extr_critic_min": 0.6755272713276225, "train/extr_critic_std": 0.031799423542523055, "train/extr_return_normed_mag": 0.5444302173382646, "train/extr_return_normed_max": 0.34138756334234815, "train/extr_return_normed_mean": 0.046172332898670926, "train/extr_return_normed_min": -0.40899249801941967, "train/extr_return_normed_std": 0.03866366813933357, "train/extr_return_rate": 0.9994048336777118, "train/extr_return_raw_mag": 1.1243533735428382, "train/extr_return_raw_max": 1.1243533735428382, "train/extr_return_raw_mean": 0.8291381857263933, "train/extr_return_raw_min": 0.3739733121810703, "train/extr_return_raw_std": 0.03866366794281596, "train/extr_reward_mag": 0.36271103478352956, "train/extr_reward_max": 0.36271103478352956, "train/extr_reward_mean": 0.0010133785094986797, "train/extr_reward_min": 8.038424570626075e-08, "train/extr_reward_std": 0.00822208518452874, "train/image_loss_mean": 0.06863320808550087, "train/image_loss_std": 0.09518185850882202, "train/model_loss_mean": 0.6894111575883463, "train/model_loss_std": 0.33694172777030446, "train/model_opt_grad_norm": 12.658827182349809, "train/model_opt_grad_steps": 116490.43577981651, "train/model_opt_loss": 3810.5825788865395, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5527.522935779816, "train/policy_entropy_mag": 1.2612889578583044, "train/policy_entropy_max": 1.2612889578583044, "train/policy_entropy_mean": 0.09616006165742874, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.12010377091825555, "train/policy_logprob_mag": 6.551080338451841, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09614616885371165, "train/policy_logprob_min": -6.551080338451841, "train/policy_logprob_std": 0.6338671481390612, "train/policy_randomness_mag": 0.6481743411186638, "train/policy_randomness_max": 0.6481743411186638, "train/policy_randomness_mean": 0.049416500340224406, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06172113267516871, "train/post_ent_mag": 41.938302888782744, "train/post_ent_max": 41.938302888782744, "train/post_ent_mean": 40.801127390030324, "train/post_ent_min": 39.758611101622975, "train/post_ent_std": 0.46482155847986906, "train/prior_ent_mag": 41.41368257015123, "train/prior_ent_max": 41.41368257015123, "train/prior_ent_mean": 40.442004370033196, "train/prior_ent_min": 39.316214937682545, "train/prior_ent_std": 0.3564665115207707, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0009890355118974902, "train/reward_loss_mean": 0.007411898663555861, "train/reward_loss_std": 0.13710841357092793, "train/reward_max_data": 0.549856651984497, "train/reward_max_pred": 0.21648734425186017, "train/reward_neg_acc": 0.9997352317932549, "train/reward_neg_loss": 0.0014555761805541147, "train/reward_pos_acc": 0.2608007459833635, "train/reward_pos_loss": 3.503389800560541, "train/reward_pred": 0.0008536122345211787, "train/reward_rate": 0.0016753870412844036, "train_stats/mean_log_entropy": 0.07490274653423067, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9990234375, "report/cont_loss_mean": 0.0044508930295705795, "report/cont_loss_std": 0.0930665135383606, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 2.974308729171753, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0015478059649467468, "report/cont_pred": 0.9984244108200073, "report/cont_rate": 0.9990234375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.05007532238960266, "report/image_loss_std": 0.07628897577524185, "report/model_loss_mean": 0.658390998840332, "report/model_loss_std": 0.21852700412273407, "report/post_ent_mag": 42.79196548461914, "report/post_ent_max": 42.79196548461914, "report/post_ent_mean": 41.76256561279297, "report/post_ent_min": 40.97621154785156, "report/post_ent_std": 0.3949960768222809, "report/prior_ent_mag": 41.57004165649414, "report/prior_ent_max": 41.57004165649414, "report/prior_ent_mean": 40.62353515625, "report/prior_ent_min": 39.521305084228516, "report/prior_ent_std": 0.3408488929271698, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0006256103515625, "report/reward_loss_mean": 0.003864755854010582, "report/reward_loss_std": 0.10200094431638718, "report/reward_max_data": 0.640625, "report/reward_max_pred": 0.05710029602050781, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.000679749995470047, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 3.2621257305145264, "report/reward_pred": 0.00036918139085173607, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.028601985424757004, "eval/cont_loss_std": 0.5124002695083618, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 9.285551071166992, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0014023311669006944, "eval/cont_pred": 0.9986088871955872, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.11544734984636307, "eval/image_loss_std": 0.11488322913646698, "eval/model_loss_mean": 0.7555551528930664, "eval/model_loss_std": 0.7938801050186157, "eval/post_ent_mag": 42.77655792236328, "eval/post_ent_max": 42.77655792236328, "eval/post_ent_mean": 41.788944244384766, "eval/post_ent_min": 40.828060150146484, "eval/post_ent_std": 0.4188586175441742, "eval/prior_ent_mag": 41.5521125793457, "eval/prior_ent_max": 41.5521125793457, "eval/prior_ent_mean": 40.686500549316406, "eval/prior_ent_min": 39.606773376464844, "eval/prior_ent_std": 0.30962473154067993, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0006927490467205644, "eval/reward_loss_mean": 0.01150583941489458, "eval/reward_loss_std": 0.35487809777259827, "eval/reward_max_data": 0.7093750238418579, "eval/reward_max_pred": 0.0227200984954834, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00041085557313635945, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 11.361675262451172, "eval/reward_pred": 0.0001994305057451129, "eval/reward_rate": 0.0009765625, "replay/size": 471797.0, "replay/inserts": 8724.0, "replay/samples": 34896.0, "replay/insert_wait_avg": 1.5649703706639014e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.062166560302902e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 1280.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0095536708831787e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0072629451752, "timer/env.step_count": 1090.0, "timer/env.step_total": 10.938814163208008, "timer/env.step_frac": 0.010938734715777481, "timer/env.step_avg": 0.010035609324044044, "timer/env.step_min": 0.008723020553588867, "timer/env.step_max": 0.03505730628967285, "timer/replay._sample_count": 34896.0, "timer/replay._sample_total": 17.737898111343384, "timer/replay._sample_frac": 0.017737769282897553, "timer/replay._sample_avg": 0.0005083074882892991, "timer/replay._sample_min": 0.0003643035888671875, "timer/replay._sample_max": 0.02565312385559082, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1250.0, "timer/agent.policy_total": 12.92226505279541, "timer/agent.policy_frac": 0.012922171199774441, "timer/agent.policy_avg": 0.010337812042236327, "timer/agent.policy_min": 0.008849143981933594, "timer/agent.policy_max": 0.04248452186584473, "timer/dataset_train_count": 2181.0, "timer/dataset_train_total": 0.3908851146697998, "timer/dataset_train_frac": 0.00039088227571326136, "timer/dataset_train_avg": 0.00017922288613929382, "timer/dataset_train_min": 9.107589721679688e-05, "timer/dataset_train_max": 0.0012676715850830078, "timer/agent.train_count": 2181.0, "timer/agent.train_total": 971.8494920730591, "timer/agent.train_frac": 0.9718424336347447, "timer/agent.train_avg": 0.4455981164938373, "timer/agent.train_min": 0.433835506439209, "timer/agent.train_max": 0.5876297950744629, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47354650497436523, "timer/agent.report_frac": 0.00047354306565704126, "timer/agent.report_avg": 0.23677325248718262, "timer/agent.report_min": 0.23056316375732422, "timer/agent.report_max": 0.24298334121704102, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8848648071289062e-05, "timer/dataset_eval_frac": 2.884843854666151e-08, "timer/dataset_eval_avg": 2.8848648071289062e-05, "timer/dataset_eval_min": 2.8848648071289062e-05, "timer/dataset_eval_max": 2.8848648071289062e-05, "fps": 8.723817451647216}
{"step": 472576, "time": 54274.58777117729, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 472688, "time": 54287.35619354248, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 472720, "time": 54290.995141744614, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 473248, "time": 54351.20746612549, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 473424, "time": 54371.30197811127, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 473464, "time": 54375.87383008003, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 473824, "time": 54416.87949299812, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 473872, "time": 54422.35913872719, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 474888, "time": 54538.49213886261, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 474976, "time": 54548.48854970932, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 474992, "time": 54550.31749200821, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 475000, "time": 54551.31458854675, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 475032, "time": 54554.94623851776, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 475496, "time": 54608.22444629669, "episode/length": 253.0, "episode/score": 0.20937499403953552, "episode/reward_rate": 0.003937007874015748, "episode/intrinsic_return": 0.0}
{"step": 475496, "time": 54608.231724739075, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 475560, "time": 54615.61938881874, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 475736, "time": 54635.67679023743, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 476000, "time": 54665.88156104088, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 476400, "time": 54711.45244717598, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 476424, "time": 54714.17895388603, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 476464, "time": 54718.73672771454, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.0}
{"step": 476904, "time": 54768.932119607925, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 477288, "time": 54812.70446395874, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 477312, "time": 54815.42324447632, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 477456, "time": 54831.89394235611, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 477504, "time": 54837.36036467552, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 477744, "time": 54864.693940639496, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 477808, "time": 54872.01487493515, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 477808, "time": 54872.02313518524, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 478072, "time": 54902.15944766998, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 478208, "time": 54917.72101831436, "episode/length": 222.0, "episode/score": 0.3062500059604645, "episode/reward_rate": 0.004484304932735426, "episode/intrinsic_return": 0.0}
{"step": 478416, "time": 54941.46622347832, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 479192, "time": 55029.923139333725, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 479216, "time": 55032.749740600586, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 479288, "time": 55040.947474718094, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 479312, "time": 55043.66952395439, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 479600, "time": 55076.51058077812, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 479768, "time": 55095.7846095562, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 479816, "time": 55101.242646217346, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 480064, "time": 55129.673849105835, "eval_episode/length": 9.0, "eval_episode/score": 0.971875011920929, "eval_episode/reward_rate": 0.1}
{"step": 480064, "time": 55131.763431310654, "eval_episode/length": 94.0, "eval_episode/score": 0.706250011920929, "eval_episode/reward_rate": 0.010526315789473684}
{"step": 480064, "time": 55131.7685508728, "eval_episode/length": 84.0, "eval_episode/score": 0.737500011920929, "eval_episode/reward_rate": 0.011764705882352941}
{"step": 480064, "time": 55133.02489542961, "eval_episode/length": 169.0, "eval_episode/score": 0.47187501192092896, "eval_episode/reward_rate": 0.0058823529411764705}
{"step": 480064, "time": 55134.10736298561, "eval_episode/length": 233.0, "eval_episode/score": 0.2718749940395355, "eval_episode/reward_rate": 0.004273504273504274}
{"step": 480064, "time": 55134.23101186752, "eval_episode/length": 240.0, "eval_episode/score": 0.25, "eval_episode/reward_rate": 0.004149377593360996}
{"step": 480064, "time": 55135.07833480835, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 480064, "time": 55135.08441066742, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 480064, "time": 55135.08948087692, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 480384, "time": 55171.511092185974, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 480392, "time": 55172.42740702629, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 480424, "time": 55176.06066226959, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 480440, "time": 55177.90416049957, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 480880, "time": 55228.129365205765, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 481009, "time": 55243.746759176254, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.435378888331422, "train/action_min": 0.0, "train/action_std": 1.8490689560907696, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.010330561296416258, "train/actor_opt_grad_steps": 118775.0, "train/actor_opt_loss": -25.604659839507637, "train/adv_mag": 0.6067696733212252, "train/adv_max": 0.3924937300178983, "train/adv_mean": 0.0018776432594226741, "train/adv_min": -0.5554972729825098, "train/adv_std": 0.035302119940485155, "train/cont_avg": 0.9954665997706422, "train/cont_loss_mean": 0.014286651804727083, "train/cont_loss_std": 0.20670071960888256, "train/cont_neg_acc": 0.3444590802703585, "train/cont_neg_loss": 2.4345896830135842, "train/cont_pos_acc": 0.9998874986937286, "train/cont_pos_loss": 0.002978461870385351, "train/cont_pred": 0.9955191609509494, "train/cont_rate": 0.9954665997706422, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.16844995673574986, "train/extr_critic_critic_opt_grad_steps": 118775.0, "train/extr_critic_critic_opt_loss": 8100.990866004874, "train/extr_critic_mag": 1.1093041732770588, "train/extr_critic_max": 1.1093041732770588, "train/extr_critic_mean": 0.8798132549732103, "train/extr_critic_min": 0.7020340025971789, "train/extr_critic_std": 0.052455264818641024, "train/extr_return_normed_mag": 0.6374244555967663, "train/extr_return_normed_max": 0.48933463577830466, "train/extr_return_normed_mean": 0.06435981379189623, "train/extr_return_normed_min": -0.48193772424251663, "train/extr_return_normed_std": 0.06522602377749911, "train/extr_return_rate": 0.9987648457562158, "train/extr_return_raw_mag": 1.3066656707076851, "train/extr_return_raw_max": 1.3066656707076851, "train/extr_return_raw_mean": 0.8816908934247603, "train/extr_return_raw_min": 0.3353933106868639, "train/extr_return_raw_std": 0.0652260237945876, "train/extr_reward_mag": 0.5365392658688607, "train/extr_reward_max": 0.5365392658688607, "train/extr_reward_mean": 0.0016584900336515226, "train/extr_reward_min": 4.046553865485235e-08, "train/extr_reward_std": 0.016054022039389323, "train/image_loss_mean": 0.07003944987482434, "train/image_loss_std": 0.09609315173546655, "train/model_loss_mean": 0.6925806498855626, "train/model_loss_std": 0.3568416509879838, "train/model_opt_grad_norm": 12.70481233203083, "train/model_opt_grad_steps": 118668.38532110091, "train/model_opt_loss": 3527.3780192803897, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5091.743119266055, "train/policy_entropy_mag": 1.2640515401822712, "train/policy_entropy_max": 1.2640515401822712, "train/policy_entropy_mean": 0.09524188597404629, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.11857391114628643, "train/policy_logprob_mag": 6.551080349388473, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09470380148893102, "train/policy_logprob_min": -6.551080349388473, "train/policy_logprob_std": 0.6299973023593972, "train/policy_randomness_mag": 0.6495940283350988, "train/policy_randomness_max": 0.6495940283350988, "train/policy_randomness_mean": 0.04894465155079277, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.060934939772027345, "train/post_ent_mag": 42.23348230834401, "train/post_ent_max": 42.23348230834401, "train/post_ent_mean": 41.15619092468822, "train/post_ent_min": 40.12358805455199, "train/post_ent_std": 0.4580154332819335, "train/prior_ent_mag": 41.71117135144155, "train/prior_ent_max": 41.71117135144155, "train/prior_ent_mean": 40.77984368910483, "train/prior_ent_min": 39.77332631382374, "train/prior_ent_std": 0.3167592477087581, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0011219269653246632, "train/reward_loss_mean": 0.008254524177247915, "train/reward_loss_std": 0.15167442040193244, "train/reward_max_data": 0.6110808476463917, "train/reward_max_pred": 0.20124098467170645, "train/reward_neg_acc": 0.9997801706878418, "train/reward_neg_loss": 0.0014682100724520742, "train/reward_pos_acc": 0.21046099399632595, "train/reward_pos_loss": 3.598587322425335, "train/reward_pred": 0.0008724508155564512, "train/reward_rate": 0.0018814506880733945, "train_stats/mean_log_entropy": 0.07439749941907146, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.01271920558065176, "report/cont_loss_std": 0.17917008697986603, "report/cont_neg_acc": 0.5714285969734192, "report/cont_neg_loss": 1.4218907356262207, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.003019892843440175, "report/cont_pred": 0.9930586814880371, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.06486792862415314, "report/image_loss_std": 0.09082262963056564, "report/model_loss_mean": 0.6921569108963013, "report/model_loss_std": 0.4327060282230377, "report/post_ent_mag": 42.11079025268555, "report/post_ent_max": 42.11079025268555, "report/post_ent_mean": 41.044559478759766, "report/post_ent_min": 39.89142608642578, "report/post_ent_std": 0.4494299590587616, "report/prior_ent_mag": 41.349143981933594, "report/prior_ent_max": 41.349143981933594, "report/prior_ent_mean": 40.583030700683594, "report/prior_ent_min": 39.62060546875, "report/prior_ent_std": 0.3090028464794159, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0024841309059411287, "report/reward_loss_mean": 0.014569705352187157, "report/reward_loss_std": 0.22646120190620422, "report/reward_max_data": 0.7093750238418579, "report/reward_max_pred": 0.6411694288253784, "report/reward_neg_acc": 0.9999999403953552, "report/reward_neg_loss": 0.001949763623997569, "report/reward_pos_acc": 0.25, "report/reward_pos_loss": 3.232654571533203, "report/reward_pred": 0.0016177642391994596, "report/reward_rate": 0.00390625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.029241539537906647, "eval/cont_loss_std": 0.49898409843444824, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 8.856292724609375, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0033050538040697575, "eval/cont_pred": 0.9968767762184143, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.14351384341716766, "eval/image_loss_std": 0.15265285968780518, "eval/model_loss_mean": 0.7823936939239502, "eval/model_loss_std": 0.6794207096099854, "eval/post_ent_mag": 42.09642791748047, "eval/post_ent_max": 42.09642791748047, "eval/post_ent_mean": 40.9189567565918, "eval/post_ent_min": 39.9437370300293, "eval/post_ent_std": 0.4546092450618744, "eval/prior_ent_mag": 41.36124801635742, "eval/prior_ent_max": 41.36124801635742, "eval/prior_ent_mean": 40.5880012512207, "eval/prior_ent_min": 39.452789306640625, "eval/prior_ent_std": 0.29039478302001953, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0008056640508584678, "eval/reward_loss_mean": 0.009638315066695213, "eval/reward_loss_std": 0.24173839390277863, "eval/reward_max_data": 0.824999988079071, "eval/reward_max_pred": 0.11157286167144775, "eval/reward_neg_acc": 0.9990224838256836, "eval/reward_neg_loss": 0.0020932198967784643, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 7.728270530700684, "eval/reward_pred": 0.0009498231811448932, "eval/reward_rate": 0.0009765625, "replay/size": 480505.0, "replay/inserts": 8708.0, "replay/samples": 34832.0, "replay/insert_wait_avg": 1.5611379147671097e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.786619941630822e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.009669683383823e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4055109024048, "timer/env.step_count": 1089.0, "timer/env.step_total": 10.762530088424683, "timer/env.step_frac": 0.010758167534199668, "timer/env.step_avg": 0.009882947739600259, "timer/env.step_min": 0.008705854415893555, "timer/env.step_max": 0.035341501235961914, "timer/replay._sample_count": 34832.0, "timer/replay._sample_total": 17.641549348831177, "timer/replay._sample_frac": 0.017634398408019374, "timer/replay._sample_avg": 0.0005064753487836236, "timer/replay._sample_min": 0.00037932395935058594, "timer/replay._sample_max": 0.011032819747924805, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1378.0, "timer/agent.policy_total": 14.455781698226929, "timer/agent.policy_frac": 0.014449922097277582, "timer/agent.policy_avg": 0.010490407618452052, "timer/agent.policy_min": 0.00875234603881836, "timer/agent.policy_max": 0.08794736862182617, "timer/dataset_train_count": 2177.0, "timer/dataset_train_total": 0.38117122650146484, "timer/dataset_train_frac": 0.000381016720067479, "timer/dataset_train_avg": 0.0001750901361972737, "timer/dataset_train_min": 9.489059448242188e-05, "timer/dataset_train_max": 0.0008955001831054688, "timer/agent.train_count": 2177.0, "timer/agent.train_total": 969.7861769199371, "timer/agent.train_frac": 0.969393077458312, "timer/agent.train_avg": 0.4454690752962504, "timer/agent.train_min": 0.4342050552368164, "timer/agent.train_max": 0.5726144313812256, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47225379943847656, "timer/agent.report_frac": 0.00047206237299961013, "timer/agent.report_avg": 0.23612689971923828, "timer/agent.report_min": 0.2240433692932129, "timer/agent.report_max": 0.24821043014526367, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.956390380859375e-05, "timer/dataset_eval_frac": 2.955192018277264e-08, "timer/dataset_eval_avg": 2.956390380859375e-05, "timer/dataset_eval_min": 2.956390380859375e-05, "timer/dataset_eval_max": 2.956390380859375e-05, "fps": 8.704353335369566}
{"step": 481264, "time": 55273.960043907166, "episode/length": 246.0, "episode/score": 0.23125000298023224, "episode/reward_rate": 0.004048582995951417, "episode/intrinsic_return": 0.0}
{"step": 481336, "time": 55282.17505502701, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 481528, "time": 55304.12270903587, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 481616, "time": 55314.158386945724, "episode/length": 230.0, "episode/score": 0.28125, "episode/reward_rate": 0.004329004329004329, "episode/intrinsic_return": 0.0}
{"step": 481800, "time": 55335.174679517746, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 481912, "time": 55347.95415139198, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 482264, "time": 55388.21214222908, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 482672, "time": 55434.720980644226, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 482696, "time": 55437.48834776878, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 482720, "time": 55440.24373984337, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 482736, "time": 55442.073476314545, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 482776, "time": 55446.66330599785, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 483072, "time": 55480.48974132538, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 483192, "time": 55494.22288775444, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 483232, "time": 55498.78086543083, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 483416, "time": 55520.19422316551, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 483928, "time": 55578.67962384224, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 484344, "time": 55626.15494942665, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 484456, "time": 55639.022688150406, "episode/length": 222.0, "episode/score": 0.3062500059604645, "episode/reward_rate": 0.004484304932735426, "episode/intrinsic_return": 0.0}
{"step": 485072, "time": 55709.34121084213, "episode/length": 206.0, "episode/score": 0.35624998807907104, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.0}
{"step": 485088, "time": 55711.17856645584, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 485128, "time": 55715.72351694107, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 485384, "time": 55744.97937846184, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 485504, "time": 55758.7193441391, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 485544, "time": 55763.27390551567, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 485768, "time": 55788.87536716461, "episode/length": 229.0, "episode/score": 0.28437501192092896, "episode/reward_rate": 0.004347826086956522, "episode/intrinsic_return": 0.0}
{"step": 485832, "time": 55796.15428709984, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 486360, "time": 55856.46646642685, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 486656, "time": 55890.27633881569, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 486792, "time": 55905.85222816467, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 486864, "time": 55914.06286025047, "episode/length": 223.0, "episode/score": 0.3031249940395355, "episode/reward_rate": 0.004464285714285714, "episode/intrinsic_return": 0.0}
{"step": 487296, "time": 55963.292860746384, "episode/length": 218.0, "episode/score": 0.3187499940395355, "episode/reward_rate": 0.0045662100456621, "episode/intrinsic_return": 0.0}
{"step": 487312, "time": 55965.12168264389, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 487344, "time": 55968.78276324272, "episode/length": 276.0, "episode/score": 0.13750000298023224, "episode/reward_rate": 0.0036101083032490976, "episode/intrinsic_return": 0.0}
{"step": 487512, "time": 55987.88048887253, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 487632, "time": 56001.63945889473, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 488016, "time": 56045.3919711113, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 488144, "time": 56060.0531373024, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 488400, "time": 56089.165332078934, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 488584, "time": 56110.08825087547, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 488824, "time": 56137.360192775726, "episode/length": 244.0, "episode/score": 0.23749999701976776, "episode/reward_rate": 0.004081632653061225, "episode/intrinsic_return": 0.0}
{"step": 489088, "time": 56167.43405199051, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 489104, "time": 56169.24946284294, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 489128, "time": 56172.07272362709, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 489608, "time": 56226.70625662804, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 489664, "time": 56233.11324763298, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 489753, "time": 56244.10851216316, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.409187246900086, "train/action_min": 0.0, "train/action_std": 1.809143504965196, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.010596844084654857, "train/actor_opt_grad_steps": 120955.0, "train/actor_opt_loss": -22.352226217952342, "train/adv_mag": 0.5531058684674972, "train/adv_max": 0.3254008230266221, "train/adv_mean": -0.0005503826895152305, "train/adv_min": -0.509949099990206, "train/adv_std": 0.030359135876589137, "train/cont_avg": 0.9956099483944955, "train/cont_loss_mean": 0.0139860453462194, "train/cont_loss_std": 0.20450281316773333, "train/cont_neg_acc": 0.3566107146338933, "train/cont_neg_loss": 2.4655224785993566, "train/cont_pos_acc": 0.9999055739389647, "train/cont_pos_loss": 0.0030896090811605506, "train/cont_pred": 0.9954371487875597, "train/cont_rate": 0.9956099483944955, "train/dyn_loss_mean": 1.0000041788871135, "train/dyn_loss_std": 8.813725248269668e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.149917736640969, "train/extr_critic_critic_opt_grad_steps": 120955.0, "train/extr_critic_critic_opt_loss": 7380.784419348481, "train/extr_critic_mag": 1.0792338820772434, "train/extr_critic_max": 1.0792338820772434, "train/extr_critic_mean": 0.8578082413301555, "train/extr_critic_min": 0.6814077223112823, "train/extr_critic_std": 0.037629750916102066, "train/extr_return_normed_mag": 0.584983106873451, "train/extr_return_normed_max": 0.4133381430709034, "train/extr_return_normed_mean": 0.04663676337911448, "train/extr_return_normed_min": -0.44634286662854183, "train/extr_return_normed_std": 0.04992527119097633, "train/extr_return_rate": 0.999354664338838, "train/extr_return_raw_mag": 1.2239592346029544, "train/extr_return_raw_max": 1.2239592346029544, "train/extr_return_raw_mean": 0.857257894146333, "train/extr_return_raw_min": 0.36427822490350914, "train/extr_return_raw_std": 0.04992527081502961, "train/extr_reward_mag": 0.4406293368120806, "train/extr_reward_max": 0.4406293368120806, "train/extr_reward_mean": 0.0016188249421848514, "train/extr_reward_min": 9.842968861991113e-09, "train/extr_reward_std": 0.014388348929660925, "train/image_loss_mean": 0.06906136284249091, "train/image_loss_std": 0.09464475413391349, "train/model_loss_mean": 0.6909041831252771, "train/model_loss_std": 0.34621769121480644, "train/model_opt_grad_norm": 12.57334148336988, "train/model_opt_grad_steps": 120846.39449541284, "train/model_opt_loss": 3755.8299728533543, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5458.715596330275, "train/policy_entropy_mag": 1.2677677569039372, "train/policy_entropy_max": 1.2677677569039372, "train/policy_entropy_mean": 0.0960945070405072, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.11795668437256726, "train/policy_logprob_mag": 6.551080388760348, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09640552394023728, "train/policy_logprob_min": -6.551080388760348, "train/policy_logprob_std": 0.6347872817188228, "train/policy_randomness_mag": 0.6515037879484509, "train/policy_randomness_max": 0.6515037879484509, "train/policy_randomness_mean": 0.04938281221537415, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.060617748408689415, "train/post_ent_mag": 41.834609600382116, "train/post_ent_max": 41.834609600382116, "train/post_ent_mean": 40.715444564819336, "train/post_ent_min": 39.662759868376845, "train/post_ent_std": 0.4658234373691979, "train/prior_ent_mag": 41.50312976662172, "train/prior_ent_max": 41.50312976662172, "train/prior_ent_mean": 40.371002197265625, "train/prior_ent_min": 39.16312854661854, "train/prior_ent_std": 0.3991397189984628, "train/rep_loss_mean": 1.0000041788871135, "train/rep_loss_std": 8.813725248269668e-05, "train/reward_avg": 0.0011195191540987629, "train/reward_loss_mean": 0.007854239849070377, "train/reward_loss_std": 0.14495565672725474, "train/reward_max_data": 0.6098480514088355, "train/reward_max_pred": 0.2273587836038082, "train/reward_neg_acc": 0.9997620585314725, "train/reward_neg_loss": 0.0015345623291101855, "train/reward_pos_acc": 0.2428571446232064, "train/reward_pos_loss": 3.503237352721275, "train/reward_pred": 0.0009447383094117592, "train/reward_rate": 0.0018232153096330275, "train_stats/mean_log_entropy": 0.07565789135253947, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.019419103860855103, "report/cont_loss_std": 0.2714332044124603, "report/cont_neg_acc": 0.4285714626312256, "report/cont_neg_loss": 2.367943525314331, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.003254237584769726, "report/cont_pred": 0.9938812255859375, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.05685900151729584, "report/image_loss_std": 0.08886193484067917, "report/model_loss_mean": 0.6954799890518188, "report/model_loss_std": 0.5953603982925415, "report/post_ent_mag": 41.444000244140625, "report/post_ent_max": 41.444000244140625, "report/post_ent_mean": 40.416446685791016, "report/post_ent_min": 39.4176025390625, "report/post_ent_std": 0.4462338984012604, "report/prior_ent_mag": 40.9443473815918, "report/prior_ent_max": 40.9443473815918, "report/prior_ent_mean": 39.72323989868164, "report/prior_ent_min": 38.319393157958984, "report/prior_ent_std": 0.4757361114025116, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0015075684059411287, "report/reward_loss_mean": 0.01920187473297119, "report/reward_loss_std": 0.3290160298347473, "report/reward_max_data": 0.762499988079071, "report/reward_max_pred": 0.2062169313430786, "report/reward_neg_acc": 0.999020516872406, "report/reward_neg_loss": 0.0021885328460484743, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 5.8094096183776855, "report/reward_pred": 0.0009629414416849613, "report/reward_rate": 0.0029296875, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.058955565094947815, "eval/cont_loss_std": 0.7513629198074341, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 9.274164199829102, "eval/cont_pos_acc": 0.9990177154541016, "eval/cont_pos_loss": 0.004641953855752945, "eval/cont_pred": 0.9970493912696838, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.13001683354377747, "eval/image_loss_std": 0.14433497190475464, "eval/model_loss_mean": 0.8121579885482788, "eval/model_loss_std": 1.0815902948379517, "eval/post_ent_mag": 41.484066009521484, "eval/post_ent_max": 41.484066009521484, "eval/post_ent_mean": 40.37136459350586, "eval/post_ent_min": 39.304283142089844, "eval/post_ent_std": 0.45622798800468445, "eval/prior_ent_mag": 40.96769714355469, "eval/prior_ent_max": 40.96769714355469, "eval/prior_ent_mean": 39.72661209106445, "eval/prior_ent_min": 38.45228958129883, "eval/prior_ent_std": 0.4564199149608612, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0023223876487463713, "eval/reward_loss_mean": 0.023185530677437782, "eval/reward_loss_std": 0.4360801875591278, "eval/reward_max_data": 0.8500000238418579, "eval/reward_max_pred": 0.059436917304992676, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0007920099305920303, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 7.644447326660156, "eval/reward_pred": 0.0004039723426103592, "eval/reward_rate": 0.0029296875, "replay/size": 489249.0, "replay/inserts": 8744.0, "replay/samples": 34976.0, "replay/insert_wait_avg": 1.5364692283134774e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.105249935404925e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 8.791685104370117e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3479444980621, "timer/env.step_count": 1093.0, "timer/env.step_total": 10.761419296264648, "timer/env.step_frac": 0.010757676222011266, "timer/env.step_avg": 0.00984576330856784, "timer/env.step_min": 0.008644580841064453, "timer/env.step_max": 0.03470134735107422, "timer/replay._sample_count": 34976.0, "timer/replay._sample_total": 17.82502818107605, "timer/replay._sample_frac": 0.01781882821783574, "timer/replay._sample_avg": 0.0005096359841341505, "timer/replay._sample_min": 0.0003826618194580078, "timer/replay._sample_max": 0.025691986083984375, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1093.0, "timer/agent.policy_total": 11.271141767501831, "timer/agent.policy_frac": 0.01126722139980732, "timer/agent.policy_avg": 0.010312115066332873, "timer/agent.policy_min": 0.009393692016601562, "timer/agent.policy_max": 0.027977466583251953, "timer/dataset_train_count": 2186.0, "timer/dataset_train_total": 0.38621020317077637, "timer/dataset_train_frac": 0.00038607587019590713, "timer/dataset_train_avg": 0.0001766743838841612, "timer/dataset_train_min": 9.5367431640625e-05, "timer/dataset_train_max": 0.0010294914245605469, "timer/agent.train_count": 2186.0, "timer/agent.train_total": 975.4078617095947, "timer/agent.train_frac": 0.9750685919577898, "timer/agent.train_avg": 0.44620670709496557, "timer/agent.train_min": 0.4351074695587158, "timer/agent.train_max": 1.7267637252807617, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47561073303222656, "timer/agent.report_frac": 0.00047544530445441216, "timer/agent.report_avg": 0.23780536651611328, "timer/agent.report_min": 0.23259210586547852, "timer/agent.report_max": 0.24301862716674805, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.075599670410156e-05, "timer/dataset_eval_frac": 3.074529904645707e-08, "timer/dataset_eval_avg": 3.075599670410156e-05, "timer/dataset_eval_min": 3.075599670410156e-05, "timer/dataset_eval_max": 3.075599670410156e-05, "fps": 8.740842127622708}
{"step": 489824, "time": 56251.980417728424, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 489896, "time": 56260.12940335274, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 490048, "time": 56278.45597600937, "eval_episode/length": 64.0, "eval_episode/score": 0.800000011920929, "eval_episode/reward_rate": 0.015384615384615385}
{"step": 490048, "time": 56278.54664063454, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 490048, "time": 56278.671135663986, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 490048, "time": 56278.93385243416, "eval_episode/length": 91.0, "eval_episode/score": 0.715624988079071, "eval_episode/reward_rate": 0.010869565217391304}
{"step": 490048, "time": 56279.40855693817, "eval_episode/length": 118.0, "eval_episode/score": 0.6312500238418579, "eval_episode/reward_rate": 0.008403361344537815}
{"step": 490048, "time": 56279.41465115547, "eval_episode/length": 118.0, "eval_episode/score": 0.6312500238418579, "eval_episode/reward_rate": 0.008403361344537815}
{"step": 490048, "time": 56279.831805706024, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 490048, "time": 56280.05963754654, "eval_episode/length": 90.0, "eval_episode/score": 0.71875, "eval_episode/reward_rate": 0.01098901098901099}
{"step": 490184, "time": 56295.48172831535, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 490328, "time": 56311.760070323944, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 490880, "time": 56374.2691950798, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 490888, "time": 56375.17557358742, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 491136, "time": 56403.39580273628, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 491440, "time": 56437.95026302338, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 491456, "time": 56439.76557016373, "episode/length": 230.0, "episode/score": 0.28125, "episode/reward_rate": 0.004329004329004329, "episode/intrinsic_return": 0.0}
{"step": 491648, "time": 56462.031396865845, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 491904, "time": 56491.053750276566, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 491928, "time": 56493.77817416191, "episode/length": 253.0, "episode/score": 0.20937499403953552, "episode/reward_rate": 0.003937007874015748, "episode/intrinsic_return": 0.0}
{"step": 492456, "time": 56553.64416766167, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 492496, "time": 56558.16322994232, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 492576, "time": 56567.30615282059, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 492616, "time": 56571.83596038818, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 492736, "time": 56585.42229127884, "episode/length": 231.0, "episode/score": 0.27812498807907104, "episode/reward_rate": 0.004310344827586207, "episode/intrinsic_return": 0.0}
{"step": 492816, "time": 56594.56713485718, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 493184, "time": 56636.24862408638, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 493288, "time": 56648.0186958313, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 493408, "time": 56661.638675928116, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 493576, "time": 56680.62983560562, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 493712, "time": 56696.080744981766, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 493752, "time": 56700.6139755249, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 493904, "time": 56717.877853393555, "episode/length": 246.0, "episode/score": 0.23125000298023224, "episode/reward_rate": 0.004048582995951417, "episode/intrinsic_return": 0.0}
{"step": 494224, "time": 56754.05597162247, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 494240, "time": 56755.873386621475, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 494240, "time": 56755.88027238846, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 494320, "time": 56764.90479969978, "episode/length": 232.0, "episode/score": 0.2750000059604645, "episode/reward_rate": 0.004291845493562232, "episode/intrinsic_return": 0.0}
{"step": 494568, "time": 56792.907007694244, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 494640, "time": 56801.09075713158, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 494808, "time": 56820.03986740112, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 494952, "time": 56836.347256183624, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 495600, "time": 56909.65029287338, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 495816, "time": 56934.109387636185, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 496064, "time": 56962.18448090553, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 496192, "time": 56976.62823390961, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 496216, "time": 56979.340812921524, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 496416, "time": 57002.02189087868, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 496464, "time": 57007.4335269928, "episode/length": 277.0, "episode/score": 0.13437500596046448, "episode/reward_rate": 0.0035971223021582736, "episode/intrinsic_return": 0.0}
{"step": 496504, "time": 57012.06090593338, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 496880, "time": 57054.61748480797, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 497024, "time": 57070.90568733215, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 497136, "time": 57083.593663692474, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 497264, "time": 57098.04444742203, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 497304, "time": 57102.64304327965, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 497656, "time": 57142.512900829315, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 497864, "time": 57166.17673254013, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 497912, "time": 57171.60046315193, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 498120, "time": 57195.267152071, "episode/length": 287.0, "episode/score": 0.10312499850988388, "episode/reward_rate": 0.003472222222222222, "episode/intrinsic_return": 0.0}
{"step": 498272, "time": 57212.45683217049, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 498528, "time": 57241.515840530396, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 498545, "time": 57244.314459085464, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.4081884210759945, "train/action_min": 0.0, "train/action_std": 1.8037549983371388, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0060049262882040984, "train/actor_opt_grad_steps": 123145.0, "train/actor_opt_loss": -21.44389501918446, "train/adv_mag": 0.44061208936301144, "train/adv_max": 0.19702024270187724, "train/adv_mean": -0.000541765697033208, "train/adv_min": -0.4041528577154333, "train/adv_std": 0.018983089479363776, "train/cont_avg": 0.9952681107954545, "train/cont_loss_mean": 0.014539687683678824, "train/cont_loss_std": 0.20619838260622186, "train/cont_neg_acc": 0.34786429703919164, "train/cont_neg_loss": 2.401401877849162, "train/cont_pos_acc": 0.9999152782288465, "train/cont_pos_loss": 0.003048090327700431, "train/cont_pred": 0.9953871098431674, "train/cont_rate": 0.9952681107954545, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.0949811595746062, "train/extr_critic_critic_opt_grad_steps": 123145.0, "train/extr_critic_critic_opt_loss": 10060.889397638495, "train/extr_critic_mag": 0.9712330178780989, "train/extr_critic_max": 0.9712330178780989, "train/extr_critic_mean": 0.8102817567912015, "train/extr_critic_min": 0.6801215881651098, "train/extr_critic_std": 0.03130333574319428, "train/extr_return_normed_mag": 0.475343255834146, "train/extr_return_normed_max": 0.28443500589240683, "train/extr_return_normed_mean": 0.042948042169551955, "train/extr_return_normed_min": -0.34411525834690443, "train/extr_return_normed_std": 0.03727919713340022, "train/extr_return_rate": 0.9995076003399762, "train/extr_return_raw_mag": 1.051226951588284, "train/extr_return_raw_max": 1.051226951588284, "train/extr_return_raw_mean": 0.8097400356422771, "train/extr_return_raw_min": 0.4226766873489727, "train/extr_return_raw_std": 0.037279197057201105, "train/extr_reward_mag": 0.2777002665129575, "train/extr_reward_max": 0.2777002665129575, "train/extr_reward_mean": 0.0010515540929521773, "train/extr_reward_min": 2.1674416281960228e-08, "train/extr_reward_std": 0.007327531576579944, "train/image_loss_mean": 0.07153900472277945, "train/image_loss_std": 0.09744787883352149, "train/model_loss_mean": 0.6951647132635117, "train/model_loss_std": 0.36376355564729734, "train/model_opt_grad_norm": 12.417184472084045, "train/model_opt_grad_steps": 123034.26363636364, "train/model_opt_loss": 3570.658270818537, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5136.363636363636, "train/policy_entropy_mag": 1.2186719257723202, "train/policy_entropy_max": 1.2186719257723202, "train/policy_entropy_mean": 0.09109679196368564, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.10831542089581489, "train/policy_logprob_mag": 6.551080365614458, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09139915040948174, "train/policy_logprob_min": -6.551080365614458, "train/policy_logprob_std": 0.6301944201642816, "train/policy_randomness_mag": 0.6262735177170147, "train/policy_randomness_max": 0.6262735177170147, "train/policy_randomness_mean": 0.046814494647762994, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.055663118392906406, "train/post_ent_mag": 42.09073257446289, "train/post_ent_max": 42.09073257446289, "train/post_ent_mean": 41.01520756808194, "train/post_ent_min": 40.01933699521152, "train/post_ent_std": 0.4340434270826253, "train/prior_ent_mag": 40.9929232857444, "train/prior_ent_max": 40.9929232857444, "train/prior_ent_mean": 39.849346646395595, "train/prior_ent_min": 38.46236175190319, "train/prior_ent_std": 0.45004698552868583, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0012161116257960781, "train/reward_loss_mean": 0.009085998068224977, "train/reward_loss_std": 0.15683181361422283, "train/reward_max_data": 0.584900568628853, "train/reward_max_pred": 0.20326640714298594, "train/reward_neg_acc": 0.9997775289145383, "train/reward_neg_loss": 0.0015731809348587624, "train/reward_pos_acc": 0.2160440248679061, "train/reward_pos_loss": 3.697443256556, "train/reward_pred": 0.0009249378090978347, "train/reward_rate": 0.0020285866477272726, "train_stats/mean_log_entropy": 0.070618240449291, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.00920186284929514, "report/cont_loss_std": 0.14629317820072174, "report/cont_neg_acc": 0.5, "report/cont_neg_loss": 1.6519109010696411, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.002759866416454315, "report/cont_pred": 0.9952990412712097, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.0856262668967247, "report/image_loss_std": 0.10603757947683334, "report/model_loss_mean": 0.7051733732223511, "report/model_loss_std": 0.38000044226646423, "report/post_ent_mag": 42.57666015625, "report/post_ent_max": 42.57666015625, "report/post_ent_mean": 41.54600524902344, "report/post_ent_min": 40.549774169921875, "report/post_ent_std": 0.43169254064559937, "report/prior_ent_mag": 41.17386245727539, "report/prior_ent_max": 41.17386245727539, "report/prior_ent_mean": 40.15082931518555, "report/prior_ent_min": 38.73912811279297, "report/prior_ent_std": 0.46041619777679443, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0015502930618822575, "report/reward_loss_mean": 0.010345200076699257, "report/reward_loss_std": 0.20805342495441437, "report/reward_max_data": 0.8031250238418579, "report/reward_max_pred": 0.04265296459197998, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0011816213373094797, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.692934036254883, "report/reward_pred": 0.000549652031622827, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.045492980629205704, "eval/cont_loss_std": 0.6279526352882385, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 7.1125640869140625, "eval/cont_pos_acc": 0.999018669128418, "eval/cont_pos_loss": 0.010816479101777077, "eval/cont_pred": 0.9963822364807129, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.16476695239543915, "eval/image_loss_std": 0.1309497356414795, "eval/model_loss_mean": 0.8262747526168823, "eval/model_loss_std": 0.7891637682914734, "eval/post_ent_mag": 42.49283981323242, "eval/post_ent_max": 42.49283981323242, "eval/post_ent_mean": 41.51698303222656, "eval/post_ent_min": 40.4353141784668, "eval/post_ent_std": 0.41086965799331665, "eval/prior_ent_mag": 41.17527770996094, "eval/prior_ent_max": 41.17527770996094, "eval/prior_ent_mean": 40.112396240234375, "eval/prior_ent_min": 38.77997970581055, "eval/prior_ent_std": 0.4429844319820404, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0016998291248455644, "eval/reward_loss_mean": 0.01601479947566986, "eval/reward_loss_std": 0.276667058467865, "eval/reward_max_data": 0.8187500238418579, "eval/reward_max_pred": 0.027576446533203125, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0010258331894874573, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.117259979248047, "eval/reward_pred": 0.0004783641779795289, "eval/reward_rate": 0.0029296875, "replay/size": 498041.0, "replay/inserts": 8792.0, "replay/samples": 35168.0, "replay/insert_wait_avg": 1.505952840289601e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.139405301747483e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 1248.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 9.943659488971416e-07, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.493661880493164e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1887838840485, "timer/env.step_count": 1099.0, "timer/env.step_total": 10.880553245544434, "timer/env.step_frac": 0.01087849956014485, "timer/env.step_avg": 0.009900412416327964, "timer/env.step_min": 0.008635759353637695, "timer/env.step_max": 0.03539276123046875, "timer/replay._sample_count": 35168.0, "timer/replay._sample_total": 17.983969688415527, "timer/replay._sample_frac": 0.01798057524558324, "timer/replay._sample_avg": 0.0005113731144340175, "timer/replay._sample_min": 0.00040435791015625, "timer/replay._sample_max": 0.019379377365112305, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1255.0, "timer/agent.policy_total": 12.79701280593872, "timer/agent.policy_frac": 0.012794597392148195, "timer/agent.policy_avg": 0.01019682295293922, "timer/agent.policy_min": 0.008862972259521484, "timer/agent.policy_max": 0.03721880912780762, "timer/dataset_train_count": 2198.0, "timer/dataset_train_total": 0.39078426361083984, "timer/dataset_train_frac": 0.00039071050376440064, "timer/dataset_train_avg": 0.00017779083876744305, "timer/dataset_train_min": 9.512901306152344e-05, "timer/dataset_train_max": 0.0007522106170654297, "timer/agent.train_count": 2198.0, "timer/agent.train_total": 972.2855689525604, "timer/agent.train_frac": 0.9721020517515393, "timer/agent.train_avg": 0.4423501223624024, "timer/agent.train_min": 0.4320979118347168, "timer/agent.train_max": 0.5926291942596436, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4752686023712158, "timer/agent.report_frac": 0.0004751788962535632, "timer/agent.report_avg": 0.2376343011856079, "timer/agent.report_min": 0.23181700706481934, "timer/agent.report_max": 0.24345159530639648, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0279159545898438e-05, "timer/dataset_eval_frac": 3.027344440747967e-08, "timer/dataset_eval_avg": 3.0279159545898438e-05, "timer/dataset_eval_min": 3.0279159545898438e-05, "timer/dataset_eval_max": 3.0279159545898438e-05, "fps": 8.79021463854558}
{"step": 498568, "time": 57246.770874261856, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 498752, "time": 57267.71027421951, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 498984, "time": 57294.16561436653, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 499152, "time": 57313.35489106178, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 499192, "time": 57317.91034436226, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 499440, "time": 57346.26981854439, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 499488, "time": 57351.730988264084, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 499616, "time": 57366.33382773399, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 499952, "time": 57405.03208112717, "episode/length": 254.0, "episode/score": 0.20624999701976776, "episode/reward_rate": 0.00392156862745098, "episode/intrinsic_return": 0.0}
{"step": 500032, "time": 57414.628346681595, "eval_episode/length": 28.0, "eval_episode/score": 0.9125000238418579, "eval_episode/reward_rate": 0.034482758620689655}
{"step": 500032, "time": 57415.05752468109, "eval_episode/length": 52.0, "eval_episode/score": 0.8374999761581421, "eval_episode/reward_rate": 0.018867924528301886}
{"step": 500032, "time": 57415.30371308327, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 500032, "time": 57415.428527355194, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 500032, "time": 57415.64968276024, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 500032, "time": 57416.014499902725, "eval_episode/length": 107.0, "eval_episode/score": 0.6656249761581421, "eval_episode/reward_rate": 0.009259259259259259}
{"step": 500032, "time": 57416.562026023865, "eval_episode/length": 52.0, "eval_episode/score": 0.8374999761581421, "eval_episode/reward_rate": 0.018867924528301886}
{"step": 500032, "time": 57416.9530172348, "eval_episode/length": 131.0, "eval_episode/score": 0.590624988079071, "eval_episode/reward_rate": 0.007575757575757576}
{"step": 500176, "time": 57433.42287349701, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 500712, "time": 57494.56215119362, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 500928, "time": 57519.13000488281, "episode/length": 221.0, "episode/score": 0.30937498807907104, "episode/reward_rate": 0.0045045045045045045, "episode/intrinsic_return": 0.0}
{"step": 501120, "time": 57541.057076931, "episode/length": 266.0, "episode/score": 0.16875000298023224, "episode/reward_rate": 0.003745318352059925, "episode/intrinsic_return": 0.0}
{"step": 501376, "time": 57570.28595304489, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 501432, "time": 57576.64174056053, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 501504, "time": 57584.914903879166, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 501800, "time": 57618.591161727905, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 501896, "time": 57629.469829797745, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 501928, "time": 57633.11200594902, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 502120, "time": 57654.98209762573, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 502264, "time": 57671.38535284996, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 502488, "time": 57696.82897210121, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 502504, "time": 57698.65027689934, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 503432, "time": 57804.160547971725, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 503448, "time": 57805.993354558945, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 503768, "time": 57842.342237234116, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 503816, "time": 57847.77247071266, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 503824, "time": 57848.67982316017, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 503968, "time": 57865.05894112587, "episode/length": 230.0, "episode/score": 0.28125, "episode/reward_rate": 0.004329004329004329, "episode/intrinsic_return": 0.0}
{"step": 504112, "time": 57881.44800424576, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 504112, "time": 57881.45751142502, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 504240, "time": 57896.0031144619, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 504776, "time": 57957.009860515594, "episode/length": 285.0, "episode/score": 0.109375, "episode/reward_rate": 0.0034965034965034965, "episode/intrinsic_return": 0.0}
{"step": 504960, "time": 57978.0595972538, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 505120, "time": 57996.253489494324, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 505688, "time": 58060.920259952545, "episode/length": 239.0, "episode/score": 0.25312501192092896, "episode/reward_rate": 0.004166666666666667, "episode/intrinsic_return": 0.0}
{"step": 505720, "time": 58064.62488031387, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 506128, "time": 58110.9940366745, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 506128, "time": 58111.0034096241, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 506424, "time": 58144.620128154755, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 506552, "time": 58159.20058465004, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 506552, "time": 58159.23635101318, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 507008, "time": 58211.2948307991, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 507088, "time": 58220.377168655396, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 507272, "time": 58241.32844734192, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 507293, "time": 58244.58845829964, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.441492089397831, "train/action_min": 0.0, "train/action_std": 1.8111234222917252, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.007289687185399405, "train/actor_opt_grad_steps": 125340.0, "train/actor_opt_loss": -26.03557149024859, "train/adv_mag": 0.4561897244083283, "train/adv_max": 0.1999937026468042, "train/adv_mean": -0.0002611915427153121, "train/adv_min": -0.4295393721153747, "train/adv_std": 0.022138777848111985, "train/cont_avg": 0.9955140553652968, "train/cont_loss_mean": 0.01453505861030713, "train/cont_loss_std": 0.2108690640506373, "train/cont_neg_acc": 0.32409582433363077, "train/cont_neg_loss": 2.610302931374496, "train/cont_pos_acc": 0.9999238878624624, "train/cont_pos_loss": 0.0029498578403272654, "train/cont_pred": 0.9955997175821975, "train/cont_rate": 0.9955140553652968, "train/dyn_loss_mean": 1.000001046211208, "train/dyn_loss_std": 3.346355063691905e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.11293338978297363, "train/extr_critic_critic_opt_grad_steps": 125340.0, "train/extr_critic_critic_opt_loss": 11230.833859517694, "train/extr_critic_mag": 1.0050500092441088, "train/extr_critic_max": 1.0050500092441088, "train/extr_critic_mean": 0.7874742161193394, "train/extr_critic_min": 0.6577234709099548, "train/extr_critic_std": 0.0428341196841437, "train/extr_return_normed_mag": 0.4891145123194342, "train/extr_return_normed_max": 0.3230376183714497, "train/extr_return_normed_mean": 0.056364823983276274, "train/extr_return_normed_min": -0.3437787525730046, "train/extr_return_normed_std": 0.04886347979103049, "train/extr_return_rate": 0.9992247221132392, "train/extr_return_raw_mag": 1.0538857473086005, "train/extr_return_raw_max": 1.0538857473086005, "train/extr_return_raw_mean": 0.7872129891016711, "train/extr_return_raw_min": 0.3870693763641462, "train/extr_return_raw_std": 0.04886347986757755, "train/extr_reward_mag": 0.28835985268632025, "train/extr_reward_max": 0.28835985268632025, "train/extr_reward_mean": 0.000880920678774771, "train/extr_reward_min": 3.2660079328981163e-09, "train/extr_reward_std": 0.007001068040124698, "train/image_loss_mean": 0.0690234558631296, "train/image_loss_std": 0.0951175049083418, "train/model_loss_mean": 0.692071910046007, "train/model_loss_std": 0.3639809135772866, "train/model_opt_grad_norm": 12.184279126119396, "train/model_opt_grad_steps": 125227.55707762558, "train/model_opt_loss": 4252.706532935574, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 6164.3835616438355, "train/policy_entropy_mag": 1.2243413424383016, "train/policy_entropy_max": 1.2243413424383016, "train/policy_entropy_mean": 0.09381373325303265, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.11480139083650014, "train/policy_logprob_mag": 6.551080370602542, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09361094835142023, "train/policy_logprob_min": -6.551080370602542, "train/policy_logprob_std": 0.6302333305415497, "train/policy_randomness_mag": 0.629187023530812, "train/policy_randomness_max": 0.629187023530812, "train/policy_randomness_mean": 0.048210726583112866, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.05899624820781625, "train/post_ent_mag": 42.70789821398313, "train/post_ent_max": 42.70789821398313, "train/post_ent_mean": 41.61473235038862, "train/post_ent_min": 40.60121428258887, "train/post_ent_std": 0.44229264877158214, "train/prior_ent_mag": 42.0485164346216, "train/prior_ent_max": 42.0485164346216, "train/prior_ent_mean": 41.04116626199522, "train/prior_ent_min": 39.61879862606798, "train/prior_ent_std": 0.42738586745850027, "train/rep_loss_mean": 1.000001046211208, "train/rep_loss_std": 3.346355063691905e-05, "train/reward_avg": 0.0011116202059055713, "train/reward_loss_mean": 0.008512742683444529, "train/reward_loss_std": 0.15785238286692937, "train/reward_max_data": 0.5976312797703699, "train/reward_max_pred": 0.20890383143403216, "train/reward_neg_acc": 0.9998391480206354, "train/reward_neg_loss": 0.0015015267419095095, "train/reward_pos_acc": 0.1927241976491086, "train/reward_pos_loss": 3.760598060140755, "train/reward_pred": 0.0008873734187300755, "train/reward_rate": 0.0018862371575342465, "train_stats/mean_log_entropy": 0.07659967905945247, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.008427362889051437, "report/cont_loss_std": 0.14011812210083008, "report/cont_neg_acc": 0.3333333432674408, "report/cont_neg_loss": 2.1126549243927, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.00224451906979084, "report/cont_pred": 0.9967536926269531, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.06121578440070152, "report/image_loss_std": 0.09885548055171967, "report/model_loss_mean": 0.6783369183540344, "report/model_loss_std": 0.34507855772972107, "report/post_ent_mag": 41.92780685424805, "report/post_ent_max": 41.92780685424805, "report/post_ent_mean": 40.82606506347656, "report/post_ent_min": 39.804603576660156, "report/post_ent_std": 0.49239081144332886, "report/prior_ent_mag": 42.260826110839844, "report/prior_ent_max": 42.260826110839844, "report/prior_ent_mean": 41.203880310058594, "report/prior_ent_min": 39.626075744628906, "report/prior_ent_std": 0.5342686176300049, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0013824462657794356, "report/reward_loss_mean": 0.008693735115230083, "report/reward_loss_std": 0.17235469818115234, "report/reward_max_data": 0.7906249761581421, "report/reward_max_pred": 0.029973864555358887, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0011090307962149382, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 3.8844780921936035, "report/reward_pred": 0.0005496068624779582, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.039254654198884964, "eval/cont_loss_std": 0.545110821723938, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.438605308532715, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0015374614158645272, "eval/cont_pred": 0.9983991980552673, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.21476298570632935, "eval/image_loss_std": 0.16723378002643585, "eval/model_loss_mean": 0.8816148042678833, "eval/model_loss_std": 0.9828052520751953, "eval/post_ent_mag": 41.99436950683594, "eval/post_ent_max": 41.99436950683594, "eval/post_ent_mean": 40.745452880859375, "eval/post_ent_min": 39.743568420410156, "eval/post_ent_std": 0.44817623496055603, "eval/prior_ent_mag": 42.24510955810547, "eval/prior_ent_max": 42.24510955810547, "eval/prior_ent_mean": 41.085105895996094, "eval/prior_ent_min": 39.58262252807617, "eval/prior_ent_std": 0.4921708405017853, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0026763915084302425, "eval/reward_loss_mean": 0.027597075328230858, "eval/reward_loss_std": 0.4723406434059143, "eval/reward_max_data": 0.8812500238418579, "eval/reward_max_pred": 0.02979433536529541, "eval/reward_neg_acc": 0.9999999403953552, "eval/reward_neg_loss": 0.0005992059013806283, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 6.91205358505249, "eval/reward_pred": 0.00028388784267008305, "eval/reward_rate": 0.00390625, "replay/size": 506789.0, "replay/inserts": 8748.0, "replay/samples": 34992.0, "replay/insert_wait_avg": 1.5086216309542628e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.20549839841322e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 1288.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0477089733810898e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.195638656616211e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2598166465759, "timer/env.step_count": 1093.0, "timer/env.step_total": 10.831995487213135, "timer/env.step_frac": 0.010829181885490485, "timer/env.step_avg": 0.00991033438903306, "timer/env.step_min": 0.008715391159057617, "timer/env.step_max": 0.03550457954406738, "timer/replay._sample_count": 34992.0, "timer/replay._sample_total": 17.93889546394348, "timer/replay._sample_frac": 0.01793423585092579, "timer/replay._sample_avg": 0.0005126570491524771, "timer/replay._sample_min": 0.0003657341003417969, "timer/replay._sample_max": 0.03343963623046875, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1254.0, "timer/agent.policy_total": 12.831363201141357, "timer/agent.policy_frac": 0.012828030265335643, "timer/agent.policy_avg": 0.01023234705035196, "timer/agent.policy_min": 0.008719205856323242, "timer/agent.policy_max": 0.03757190704345703, "timer/dataset_train_count": 2187.0, "timer/dataset_train_total": 0.4256880283355713, "timer/dataset_train_frac": 0.0004255774562280358, "timer/dataset_train_avg": 0.00019464473174923242, "timer/dataset_train_min": 9.34600830078125e-05, "timer/dataset_train_max": 0.04123258590698242, "timer/agent.train_count": 2187.0, "timer/agent.train_total": 972.0919160842896, "timer/agent.train_frac": 0.9718394160262073, "timer/agent.train_avg": 0.4444864728323226, "timer/agent.train_min": 0.4337432384490967, "timer/agent.train_max": 0.5736410617828369, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47388792037963867, "timer/agent.report_frac": 0.0004737648283906606, "timer/agent.report_avg": 0.23694396018981934, "timer/agent.report_min": 0.23149728775024414, "timer/agent.report_max": 0.24239063262939453, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.170967102050781e-05, "timer/dataset_eval_frac": 3.170143446011474e-08, "timer/dataset_eval_avg": 3.170967102050781e-05, "timer/dataset_eval_min": 3.170967102050781e-05, "timer/dataset_eval_max": 3.170967102050781e-05, "fps": 8.745605158128852}
{"step": 507432, "time": 58260.194400548935, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 507800, "time": 58302.14946079254, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 507856, "time": 58308.48310613632, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 508176, "time": 58345.098262786865, "episode/length": 255.0, "episode/score": 0.203125, "episode/reward_rate": 0.00390625, "episode/intrinsic_return": 0.0}
{"step": 508448, "time": 58376.08813261986, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 508456, "time": 58377.003717422485, "episode/length": 237.0, "episode/score": 0.2593750059604645, "episode/reward_rate": 0.004201680672268907, "episode/intrinsic_return": 0.0}
{"step": 508704, "time": 58405.286922216415, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 508864, "time": 58423.50767946243, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 508952, "time": 58433.50805354118, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 508992, "time": 58438.06928348541, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 509112, "time": 58451.868106126785, "episode/length": 252.0, "episode/score": 0.21250000596046448, "episode/reward_rate": 0.003952569169960474, "episode/intrinsic_return": 0.0}
{"step": 509352, "time": 58479.239161491394, "episode/length": 259.0, "episode/score": 0.19062499701976776, "episode/reward_rate": 0.0038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 509632, "time": 58511.27402997017, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 509640, "time": 58512.20277810097, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 509672, "time": 58515.821848869324, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 510016, "time": 58555.10774517059, "eval_episode/length": 9.0, "eval_episode/score": 0.971875011920929, "eval_episode/reward_rate": 0.1}
{"step": 510016, "time": 58555.62955522537, "eval_episode/length": 39.0, "eval_episode/score": 0.878125011920929, "eval_episode/reward_rate": 0.025}
{"step": 510016, "time": 58556.10917139053, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 510016, "time": 58556.183957099915, "eval_episode/length": 70.0, "eval_episode/score": 0.78125, "eval_episode/reward_rate": 0.014084507042253521}
{"step": 510016, "time": 58557.40106678009, "eval_episode/length": 130.0, "eval_episode/score": 0.59375, "eval_episode/reward_rate": 0.007633587786259542}
{"step": 510016, "time": 58557.564835071564, "eval_episode/length": 149.0, "eval_episode/score": 0.534375011920929, "eval_episode/reward_rate": 0.006666666666666667}
{"step": 510016, "time": 58557.64321684837, "eval_episode/length": 153.0, "eval_episode/score": 0.5218750238418579, "eval_episode/reward_rate": 0.006493506493506494}
{"step": 510016, "time": 58557.77092218399, "eval_episode/length": 120.0, "eval_episode/score": 0.625, "eval_episode/reward_rate": 0.008264462809917356}
{"step": 510112, "time": 58568.66988801956, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 510208, "time": 58579.63458824158, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 510280, "time": 58587.809003829956, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 510728, "time": 58638.79110836983, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 510768, "time": 58643.34048104286, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 511056, "time": 58676.16495347023, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 511064, "time": 58677.07646751404, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 511160, "time": 58688.01543068886, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.0}
{"step": 511560, "time": 58733.54729580879, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 511848, "time": 58766.27356004715, "episode/length": 216.0, "episode/score": 0.32499998807907104, "episode/reward_rate": 0.004608294930875576, "episode/intrinsic_return": 0.0}
{"step": 511920, "time": 58774.44496202469, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 511944, "time": 58777.16831064224, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 511984, "time": 58781.78378486633, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 512336, "time": 58821.78116297722, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 512344, "time": 58822.69741606712, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 512416, "time": 58830.87205243111, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 512944, "time": 58890.961285829544, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 512976, "time": 58894.60391712189, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 513040, "time": 58901.927277326584, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 513448, "time": 58948.248861312866, "episode/length": 199.0, "episode/score": 0.37812501192092896, "episode/reward_rate": 0.005, "episode/intrinsic_return": 0.0}
{"step": 513472, "time": 58950.96377778053, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 513824, "time": 58991.20383930206, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 513832, "time": 58992.11304092407, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 513872, "time": 58996.65258359909, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 513896, "time": 58999.397968530655, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 513912, "time": 59001.21175312996, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 513952, "time": 59005.765795230865, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.0}
{"step": 514456, "time": 59063.08996844292, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 514536, "time": 59072.17466855049, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 514640, "time": 59084.03252506256, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 514920, "time": 59115.84460783005, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 514952, "time": 59119.46470284462, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 515056, "time": 59131.294504880905, "episode/length": 16.0, "episode/score": 0.949999988079071, "episode/reward_rate": 0.058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 515072, "time": 59133.112433195114, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 515080, "time": 59134.04490971565, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 515488, "time": 59180.45768237114, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 515936, "time": 59231.41559576988, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 515960, "time": 59234.14114069939, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.0}
{"step": 516000, "time": 59238.67084693909, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 516045, "time": 59244.66185426712, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.3922682113299087, "train/action_min": 0.0, "train/action_std": 1.7040001676507193, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.006247266761312202, "train/actor_opt_grad_steps": 127530.0, "train/actor_opt_loss": -24.117862226756195, "train/adv_mag": 0.4409397048492954, "train/adv_max": 0.20542861201447438, "train/adv_mean": -0.00044174734616987557, "train/adv_min": -0.4147242880575189, "train/adv_std": 0.01914225356253587, "train/cont_avg": 0.995447167522831, "train/cont_loss_mean": 0.01424456943681285, "train/cont_loss_std": 0.2071916369219485, "train/cont_neg_acc": 0.3470481800923654, "train/cont_neg_loss": 2.47896549420039, "train/cont_pos_acc": 0.9999283579386533, "train/cont_pos_loss": 0.0030649751350368677, "train/cont_pred": 0.9953848311345871, "train/cont_rate": 0.995447167522831, "train/dyn_loss_mean": 1.0000000239507247, "train/dyn_loss_std": 7.679530729850134e-07, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.10299155996372439, "train/extr_critic_critic_opt_grad_steps": 127530.0, "train/extr_critic_critic_opt_loss": 12288.03160673516, "train/extr_critic_mag": 0.963280199325248, "train/extr_critic_max": 0.963280199325248, "train/extr_critic_mean": 0.7649602293968201, "train/extr_critic_min": 0.6475303271045424, "train/extr_critic_std": 0.03860850789537441, "train/extr_return_normed_mag": 0.48899582967366256, "train/extr_return_normed_max": 0.3410939394611202, "train/extr_return_normed_mean": 0.05376886951494707, "train/extr_return_normed_min": -0.34557633312869834, "train/extr_return_normed_std": 0.04332022305969234, "train/extr_return_rate": 0.9996334823299217, "train/extr_return_raw_mag": 1.0518435019336334, "train/extr_return_raw_max": 1.0518435019336334, "train/extr_return_raw_mean": 0.7645184740628281, "train/extr_return_raw_min": 0.36517322934381496, "train/extr_return_raw_std": 0.043320223000155735, "train/extr_reward_mag": 0.3256644304484537, "train/extr_reward_max": 0.3256644304484537, "train/extr_reward_mean": 0.0009435173413784298, "train/extr_reward_min": 0.0, "train/extr_reward_std": 0.007080883132166242, "train/image_loss_mean": 0.07039246714958862, "train/image_loss_std": 0.09639462838842444, "train/model_loss_mean": 0.6933428128016049, "train/model_loss_std": 0.3600603988793887, "train/model_opt_grad_norm": 11.930085970386523, "train/model_opt_grad_steps": 127415.81278538813, "train/model_opt_loss": 4052.817400649258, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5844.748858447489, "train/policy_entropy_mag": 1.2668107040396563, "train/policy_entropy_max": 1.2668107040396563, "train/policy_entropy_mean": 0.09317205040013954, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.114282302592443, "train/policy_logprob_mag": 6.551080318346416, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09312038402579147, "train/policy_logprob_min": -6.551080318346416, "train/policy_logprob_std": 0.6305352661707629, "train/policy_randomness_mag": 0.6510119587863417, "train/policy_randomness_max": 0.6510119587863417, "train/policy_randomness_mean": 0.04788096710086957, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.058729489338180244, "train/post_ent_mag": 42.93684143345106, "train/post_ent_max": 42.93684143345106, "train/post_ent_mean": 41.84476216634115, "train/post_ent_min": 40.781046044336605, "train/post_ent_std": 0.4514908813722602, "train/prior_ent_mag": 42.41541060356245, "train/prior_ent_max": 42.41541060356245, "train/prior_ent_mean": 41.41877257116309, "train/prior_ent_min": 40.00341791649387, "train/prior_ent_std": 0.43914661410192374, "train/rep_loss_mean": 1.0000000239507247, "train/rep_loss_std": 7.679530729850134e-07, "train/reward_avg": 0.0011885830247854456, "train/reward_loss_mean": 0.008705738034061068, "train/reward_loss_std": 0.15395764087658528, "train/reward_max_data": 0.5915525118101678, "train/reward_max_pred": 0.21250513046299485, "train/reward_neg_acc": 0.9997989946304391, "train/reward_neg_loss": 0.0015817114184440441, "train/reward_pos_acc": 0.19211866758405205, "train/reward_pos_loss": 3.676056305673671, "train/reward_pred": 0.0009550750494794283, "train/reward_rate": 0.001993257705479452, "train_stats/mean_log_entropy": 0.07484741729718668, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.01575607992708683, "report/cont_loss_std": 0.23029066622257233, "report/cont_neg_acc": 0.3333333432674408, "report/cont_neg_loss": 2.1291799545288086, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0032997499220073223, "report/cont_pred": 0.9947863817214966, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07250921428203583, "report/image_loss_std": 0.10372170060873032, "report/model_loss_mean": 0.693816065788269, "report/model_loss_std": 0.3251182734966278, "report/post_ent_mag": 42.47039794921875, "report/post_ent_max": 42.47039794921875, "report/post_ent_mean": 41.21171188354492, "report/post_ent_min": 39.98361587524414, "report/post_ent_std": 0.5154786705970764, "report/prior_ent_mag": 42.39152526855469, "report/prior_ent_max": 42.39152526855469, "report/prior_ent_mean": 41.4464111328125, "report/prior_ent_min": 40.6066780090332, "report/prior_ent_std": 0.3157691955566406, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0004913330194540322, "report/reward_loss_mean": 0.00555071234703064, "report/reward_loss_std": 0.11996272951364517, "report/reward_max_data": 0.503125011920929, "report/reward_max_pred": 0.03997790813446045, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0018128493102267385, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 3.8293845653533936, "report/reward_pred": 0.000775183318182826, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.01170847937464714, "eval/cont_loss_std": 0.23485322296619415, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 4.967625617980957, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.002010011812672019, "eval/cont_pred": 0.9979809522628784, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.17129741609096527, "eval/image_loss_std": 0.14868542551994324, "eval/model_loss_mean": 0.7875832319259644, "eval/model_loss_std": 0.3466027081012726, "eval/post_ent_mag": 42.39655685424805, "eval/post_ent_max": 42.39655685424805, "eval/post_ent_mean": 41.1236457824707, "eval/post_ent_min": 39.97468185424805, "eval/post_ent_std": 0.5118088126182556, "eval/prior_ent_mag": 42.21220779418945, "eval/prior_ent_max": 42.21220779418945, "eval/prior_ent_mean": 41.42015838623047, "eval/prior_ent_min": 40.5614013671875, "eval/prior_ent_std": 0.30814507603645325, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0006195068126544356, "eval/reward_loss_mean": 0.004577253013849258, "eval/reward_loss_std": 0.1242593377828598, "eval/reward_max_data": 0.6343749761581421, "eval/reward_max_pred": 0.026554226875305176, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0006950242095626891, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 3.976097345352173, "eval/reward_pred": 0.00034409912768751383, "eval/reward_rate": 0.0009765625, "replay/size": 515541.0, "replay/inserts": 8752.0, "replay/samples": 35008.0, "replay/insert_wait_avg": 1.5336482136951287e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.190423212278042e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 1288.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0214236952503276e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.834766387939453e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0616717338562, "timer/env.step_count": 1094.0, "timer/env.step_total": 10.845041275024414, "timer/env.step_frac": 0.010844372483770758, "timer/env.step_avg": 0.009913200434208787, "timer/env.step_min": 0.008644580841064453, "timer/env.step_max": 0.03492617607116699, "timer/replay._sample_count": 35008.0, "timer/replay._sample_total": 18.203402757644653, "timer/replay._sample_frac": 0.01820228019146511, "timer/replay._sample_avg": 0.000519978369448259, "timer/replay._sample_min": 0.00037384033203125, "timer/replay._sample_max": 0.02622389793395996, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1255.0, "timer/agent.policy_total": 12.85062575340271, "timer/agent.policy_frac": 0.012849833281904453, "timer/agent.policy_avg": 0.010239542432990207, "timer/agent.policy_min": 0.009062051773071289, "timer/agent.policy_max": 0.04452776908874512, "timer/dataset_train_count": 2188.0, "timer/dataset_train_total": 0.3752255439758301, "timer/dataset_train_frac": 0.0003752024045929918, "timer/dataset_train_avg": 0.00017149247896518742, "timer/dataset_train_min": 8.96453857421875e-05, "timer/dataset_train_max": 0.0010318756103515625, "timer/agent.train_count": 2188.0, "timer/agent.train_total": 972.0563991069794, "timer/agent.train_frac": 0.9719964544003344, "timer/agent.train_avg": 0.4442670928276871, "timer/agent.train_min": 0.43300747871398926, "timer/agent.train_max": 0.5730769634246826, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.476393461227417, "timer/agent.report_frac": 0.0004763640830284698, "timer/agent.report_avg": 0.2381967306137085, "timer/agent.report_min": 0.23174715042114258, "timer/agent.report_max": 0.24464631080627441, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 9.894371032714844e-05, "timer/dataset_eval_frac": 9.893760867327797e-08, "timer/dataset_eval_avg": 9.894371032714844e-05, "timer/dataset_eval_min": 9.894371032714844e-05, "timer/dataset_eval_max": 9.894371032714844e-05, "fps": 8.751324965795629}
{"step": 516184, "time": 59260.618587732315, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 516600, "time": 59308.09135365486, "episode/length": 205.0, "episode/score": 0.359375, "episode/reward_rate": 0.0048543689320388345, "episode/intrinsic_return": 0.0}
{"step": 517368, "time": 59395.59002304077, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 517392, "time": 59398.32290530205, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 517600, "time": 59422.04754471779, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.0}
{"step": 517800, "time": 59444.91656947136, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 517888, "time": 59454.926332473755, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 518024, "time": 59470.383868694305, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 518032, "time": 59471.35814380646, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 518248, "time": 59495.93628549576, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 518312, "time": 59503.2815053463, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 518496, "time": 59524.217363357544, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 518632, "time": 59539.70799064636, "episode/length": 16.0, "episode/score": 0.949999988079071, "episode/reward_rate": 0.058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 518728, "time": 59550.622631549835, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 519424, "time": 59629.99532222748, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 519496, "time": 59638.22051334381, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 519536, "time": 59642.79995560646, "episode/length": 216.0, "episode/score": 0.32499998807907104, "episode/reward_rate": 0.004608294930875576, "episode/intrinsic_return": 0.0}
{"step": 519632, "time": 59653.84080410004, "episode/length": 279.0, "episode/score": 0.12812499701976776, "episode/reward_rate": 0.0035714285714285713, "episode/intrinsic_return": 0.0}
{"step": 519880, "time": 59682.18998169899, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 520000, "time": 59697.30279350281, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 520000, "time": 59697.32947802544, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 520000, "time": 59697.767397642136, "eval_episode/length": 107.0, "eval_episode/score": 0.6656249761581421, "eval_episode/reward_rate": 0.009259259259259259}
{"step": 520000, "time": 59698.15681862831, "eval_episode/length": 129.0, "eval_episode/score": 0.596875011920929, "eval_episode/reward_rate": 0.007692307692307693}
{"step": 520000, "time": 59698.72929120064, "eval_episode/length": 161.0, "eval_episode/score": 0.49687498807907104, "eval_episode/reward_rate": 0.006172839506172839}
{"step": 520000, "time": 59699.586842775345, "eval_episode/length": 210.0, "eval_episode/score": 0.34375, "eval_episode/reward_rate": 0.004739336492890996}
{"step": 520000, "time": 59700.17092251778, "eval_episode/length": 113.0, "eval_episode/score": 0.6468750238418579, "eval_episode/reward_rate": 0.008771929824561403}
{"step": 520000, "time": 59700.20549464226, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 520008, "time": 59701.12224984169, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 520200, "time": 59723.05462265015, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 520328, "time": 59737.624524116516, "episode/length": 199.0, "episode/score": 0.37812501192092896, "episode/reward_rate": 0.005, "episode/intrinsic_return": 0.0}
{"step": 520416, "time": 59747.73677897453, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 520624, "time": 59771.42979502678, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 520752, "time": 59785.97367286682, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 520944, "time": 59807.756987571716, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 521048, "time": 59819.636974573135, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 521304, "time": 59848.68737530708, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 521624, "time": 59885.029702186584, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 521784, "time": 59903.295498371124, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 521848, "time": 59910.62306404114, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 521944, "time": 59921.600903749466, "episode/length": 257.0, "episode/score": 0.19687500596046448, "episode/reward_rate": 0.003875968992248062, "episode/intrinsic_return": 0.0}
{"step": 522208, "time": 59951.73922133446, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 522360, "time": 59969.01265048981, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 522400, "time": 59973.5843000412, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 522728, "time": 60010.906948804855, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 522832, "time": 60022.751052856445, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 522936, "time": 60034.55373668671, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 523312, "time": 60077.28717541695, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 523344, "time": 60080.93113923073, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 523360, "time": 60082.7702229023, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 523568, "time": 60106.47892832756, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 523888, "time": 60142.84499454498, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 523936, "time": 60148.31495332718, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 524264, "time": 60185.65665102005, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 524488, "time": 60211.56202793121, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 524520, "time": 60215.23770570755, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 524773, "time": 60244.976224422455, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.4626420047305047, "train/action_min": 0.0, "train/action_std": 1.816447393609843, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.007146857671414015, "train/actor_opt_grad_steps": 129715.0, "train/actor_opt_loss": -22.807118035237725, "train/adv_mag": 0.4573935184183471, "train/adv_max": 0.25972802978043164, "train/adv_mean": 8.116336600298817e-05, "train/adv_min": -0.41895880283565695, "train/adv_std": 0.02243314152412595, "train/cont_avg": 0.9954442015481652, "train/cont_loss_mean": 0.014342128850814434, "train/cont_loss_std": 0.20959116097266248, "train/cont_neg_acc": 0.34445093448535635, "train/cont_neg_loss": 2.4874809551005, "train/cont_pos_acc": 0.9999325330104303, "train/cont_pos_loss": 0.003026985642372058, "train/cont_pred": 0.9954391315989538, "train/cont_rate": 0.9954442015481652, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.10381737705149235, "train/extr_critic_critic_opt_grad_steps": 129715.0, "train/extr_critic_critic_opt_loss": 12462.2667225129, "train/extr_critic_mag": 0.9330069931275254, "train/extr_critic_max": 0.9330069931275254, "train/extr_critic_mean": 0.761061803736818, "train/extr_critic_min": 0.6150466914570659, "train/extr_critic_std": 0.0381899815343252, "train/extr_return_normed_mag": 0.49722493952567426, "train/extr_return_normed_max": 0.3523177643981549, "train/extr_return_normed_mean": 0.052501595493645296, "train/extr_return_normed_min": -0.36186414191482263, "train/extr_return_normed_std": 0.045246503999405496, "train/extr_return_rate": 0.9989371600501035, "train/extr_return_raw_mag": 1.0609591750923646, "train/extr_return_raw_max": 1.0609591750923646, "train/extr_return_raw_mean": 0.761143040492994, "train/extr_return_raw_min": 0.346777269052803, "train/extr_return_raw_std": 0.045246503896874575, "train/extr_reward_mag": 0.37828086330256333, "train/extr_reward_max": 0.37828086330256333, "train/extr_reward_mean": 0.0011360622260777212, "train/extr_reward_min": 5.468316034439507e-10, "train/extr_reward_std": 0.009629753163007489, "train/image_loss_mean": 0.06871228902643427, "train/image_loss_std": 0.09497178978192697, "train/model_loss_mean": 0.6917895756730246, "train/model_loss_std": 0.36599119759480886, "train/model_opt_grad_norm": 11.821063245108368, "train/model_opt_grad_steps": 129598.91284403669, "train/model_opt_loss": 4029.753076395857, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5825.688073394495, "train/policy_entropy_mag": 1.3058385050624883, "train/policy_entropy_max": 1.3058385050624883, "train/policy_entropy_mean": 0.09376831010940971, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.11682288806646242, "train/policy_logprob_mag": 6.5510803275152085, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09350897973283716, "train/policy_logprob_min": -6.5510803275152085, "train/policy_logprob_std": 0.630701228566126, "train/policy_randomness_mag": 0.6710682836694455, "train/policy_randomness_max": 0.6710682836694455, "train/policy_randomness_mean": 0.04818738415973996, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06003509193590475, "train/post_ent_mag": 42.614979892695715, "train/post_ent_max": 42.614979892695715, "train/post_ent_mean": 41.447053174360086, "train/post_ent_min": 40.298771167020185, "train/post_ent_std": 0.49037076314108086, "train/prior_ent_mag": 42.18910728244607, "train/prior_ent_max": 42.18910728244607, "train/prior_ent_mean": 41.29782515709553, "train/prior_ent_min": 40.33400208359465, "train/prior_ent_std": 0.3242943548007843, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0011259166508394512, "train/reward_loss_mean": 0.008735133308293555, "train/reward_loss_std": 0.15733714859479817, "train/reward_max_data": 0.5945384176020775, "train/reward_max_pred": 0.21118894028007437, "train/reward_neg_acc": 0.999789038382539, "train/reward_neg_loss": 0.0015884258592375256, "train/reward_pos_acc": 0.18761904916247807, "train/reward_pos_loss": 3.7193790728175964, "train/reward_pred": 0.0009200315160992974, "train/reward_rate": 0.0019307267775229358, "train_stats/mean_log_entropy": 0.07565982219703654, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 0.036268800497055054, "report/cont_loss_std": 0.4156559407711029, "report/cont_neg_acc": 0.125, "report/cont_neg_loss": 4.051321029663086, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.004654215183109045, "report/cont_pred": 0.9942083358764648, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.0839272141456604, "report/image_loss_std": 0.09941094368696213, "report/model_loss_mean": 0.7310701608657837, "report/model_loss_std": 0.5181013941764832, "report/post_ent_mag": 42.81037139892578, "report/post_ent_max": 42.81037139892578, "report/post_ent_mean": 41.81425094604492, "report/post_ent_min": 40.70156478881836, "report/post_ent_std": 0.44946685433387756, "report/prior_ent_mag": 42.31749725341797, "report/prior_ent_max": 42.31749725341797, "report/prior_ent_mean": 41.32121276855469, "report/prior_ent_min": 40.27238464355469, "report/prior_ent_std": 0.3383671045303345, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0010559081565588713, "report/reward_loss_mean": 0.010874143801629543, "report/reward_loss_std": 0.17878001928329468, "report/reward_max_data": 0.6812499761581421, "report/reward_max_pred": 0.05914497375488281, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0029877470806241035, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.040822982788086, "report/reward_pred": 0.0013877153396606445, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.023419775068759918, "eval/cont_loss_std": 0.4321620464324951, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 9.691534042358398, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.004499785136431456, "eval/cont_pred": 0.9956389665603638, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.1217438280582428, "eval/image_loss_std": 0.13238012790679932, "eval/model_loss_mean": 0.7475239038467407, "eval/model_loss_std": 0.45490771532058716, "eval/post_ent_mag": 42.81097412109375, "eval/post_ent_max": 42.81097412109375, "eval/post_ent_mean": 41.81474685668945, "eval/post_ent_min": 40.6841926574707, "eval/post_ent_std": 0.4506685733795166, "eval/prior_ent_mag": 42.13703155517578, "eval/prior_ent_max": 42.13703155517578, "eval/prior_ent_mean": 41.329097747802734, "eval/prior_ent_min": 40.38017272949219, "eval/prior_ent_std": 0.3070165514945984, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.002360273152589798, "eval/reward_loss_std": 0.01324874721467495, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.12370729446411133, "eval/reward_neg_acc": 0.9990234375, "eval/reward_neg_loss": 0.002360273152589798, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0010110157309100032, "eval/reward_rate": 0.0, "replay/size": 524269.0, "replay/inserts": 8728.0, "replay/samples": 34912.0, "replay/insert_wait_avg": 1.5666023729920497e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.0721102241635e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 1952.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0058283805847168e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.301568984985352e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2945685386658, "timer/env.step_count": 1091.0, "timer/env.step_total": 10.787386655807495, "timer/env.step_frac": 0.0107842099668369, "timer/env.step_avg": 0.00988761380000687, "timer/env.step_min": 0.008668899536132812, "timer/env.step_max": 0.03525996208190918, "timer/replay._sample_count": 34912.0, "timer/replay._sample_total": 18.015804052352905, "timer/replay._sample_frac": 0.018010498726062526, "timer/replay._sample_avg": 0.0005160347173565796, "timer/replay._sample_min": 0.0003681182861328125, "timer/replay._sample_max": 0.02173590660095215, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1335.0, "timer/agent.policy_total": 13.686259984970093, "timer/agent.policy_frac": 0.013682229630582122, "timer/agent.policy_avg": 0.010251880138554376, "timer/agent.policy_min": 0.008712530136108398, "timer/agent.policy_max": 0.04318594932556152, "timer/dataset_train_count": 2182.0, "timer/dataset_train_total": 0.37447524070739746, "timer/dataset_train_frac": 0.00037436496456685734, "timer/dataset_train_avg": 0.00017162018364225365, "timer/dataset_train_min": 9.107589721679688e-05, "timer/dataset_train_max": 0.0012140274047851562, "timer/agent.train_count": 2182.0, "timer/agent.train_total": 970.6409587860107, "timer/agent.train_frac": 0.9703551226955315, "timer/agent.train_avg": 0.444840036107246, "timer/agent.train_min": 0.4326908588409424, "timer/agent.train_max": 0.5802018642425537, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4778103828430176, "timer/agent.report_frac": 0.00047766967638448007, "timer/agent.report_avg": 0.2389051914215088, "timer/agent.report_min": 0.23354673385620117, "timer/agent.report_max": 0.2442636489868164, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.5987625122070312e-05, "timer/dataset_eval_frac": 2.5979972239613113e-08, "timer/dataset_eval_avg": 2.5987625122070312e-05, "timer/dataset_eval_min": 2.5987625122070312e-05, "timer/dataset_eval_max": 2.5987625122070312e-05, "fps": 8.725290696121021}
{"step": 525024, "time": 60273.37889409065, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 525040, "time": 60275.22106337547, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 525568, "time": 60335.427035570145, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 525656, "time": 60345.47640299797, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 525672, "time": 60347.296707868576, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 525888, "time": 60371.793308496475, "episode/length": 243.0, "episode/score": 0.24062499403953552, "episode/reward_rate": 0.004098360655737705, "episode/intrinsic_return": 0.0}
{"step": 525960, "time": 60379.97114086151, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 526200, "time": 60407.32130360603, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 526376, "time": 60427.29024720192, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 526488, "time": 60440.080490112305, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 526504, "time": 60441.8987326622, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 526536, "time": 60445.546078920364, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 526728, "time": 60467.400955200195, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 526800, "time": 60475.582889556885, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 527000, "time": 60498.28035187721, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 527112, "time": 60510.95319676399, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 527256, "time": 60527.41567969322, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 527504, "time": 60555.629212379456, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 527592, "time": 60565.63368010521, "episode/length": 239.0, "episode/score": 0.25312501192092896, "episode/reward_rate": 0.004166666666666667, "episode/intrinsic_return": 0.0}
{"step": 528192, "time": 60634.09807944298, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 528208, "time": 60635.94749236107, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 528240, "time": 60639.60468149185, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 528288, "time": 60645.16919755936, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 528424, "time": 60660.708169698715, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 528688, "time": 60690.992195129395, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 529152, "time": 60744.09857463837, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 529816, "time": 60819.84039402008, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 529848, "time": 60823.56096124649, "episode/length": 206.0, "episode/score": 0.35624998807907104, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.0}
{"step": 529904, "time": 60829.9456050396, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 529952, "time": 60835.398062467575, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 530088, "time": 60853.0896384716, "eval_episode/length": 87.0, "eval_episode/score": 0.7281249761581421, "eval_episode/reward_rate": 0.011363636363636364}
{"step": 530088, "time": 60853.16310977936, "eval_episode/length": 91.0, "eval_episode/score": 0.715624988079071, "eval_episode/reward_rate": 0.010869565217391304}
{"step": 530088, "time": 60853.28717851639, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 530088, "time": 60853.630694150925, "eval_episode/length": 118.0, "eval_episode/score": 0.6312500238418579, "eval_episode/reward_rate": 0.008403361344537815}
{"step": 530088, "time": 60853.75257015228, "eval_episode/length": 125.0, "eval_episode/score": 0.609375, "eval_episode/reward_rate": 0.007936507936507936}
{"step": 530088, "time": 60854.39800977707, "eval_episode/length": 163.0, "eval_episode/score": 0.4906249940395355, "eval_episode/reward_rate": 0.006097560975609756}
{"step": 530088, "time": 60854.50660324097, "eval_episode/length": 169.0, "eval_episode/score": 0.47187501192092896, "eval_episode/reward_rate": 0.0058823529411764705}
{"step": 530088, "time": 60855.10317468643, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 530200, "time": 60867.835839509964, "episode/length": 238.0, "episode/score": 0.2562499940395355, "episode/reward_rate": 0.0041841004184100415, "episode/intrinsic_return": 0.0}
{"step": 530520, "time": 60904.14183998108, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 530552, "time": 60907.76694536209, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 530640, "time": 60917.84359240532, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 530736, "time": 60928.74372601509, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 531024, "time": 60961.40940260887, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 531392, "time": 61003.26796126366, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 531640, "time": 61031.65768146515, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 531704, "time": 61038.9267270565, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 532128, "time": 61087.07446527481, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 532160, "time": 61090.715774059296, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 532688, "time": 61151.32862782478, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 532856, "time": 61170.4394364357, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 532864, "time": 61171.35523176193, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 532952, "time": 61181.46006965637, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 533000, "time": 61186.92143559456, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 533336, "time": 61225.102974653244, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 533505, "time": 61245.16011953354, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.4883025283113533, "train/action_min": 0.0, "train/action_std": 1.803512459501214, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.006486417426633725, "train/actor_opt_grad_steps": 131895.0, "train/actor_opt_loss": -23.694609729521865, "train/adv_mag": 0.4856517570554663, "train/adv_max": 0.2305529656213358, "train/adv_mean": 0.000868017600719672, "train/adv_min": -0.43618328021753816, "train/adv_std": 0.02090136944786261, "train/cont_avg": 0.9953008529243119, "train/cont_loss_mean": 0.015370059175280119, "train/cont_loss_std": 0.21819684482734958, "train/cont_neg_acc": 0.30489115188017896, "train/cont_neg_loss": 2.623002115076615, "train/cont_pos_acc": 0.9998829815912684, "train/cont_pos_loss": 0.0031267847965146763, "train/cont_pred": 0.9954822941110768, "train/cont_rate": 0.9953008529243119, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.09545761777019691, "train/extr_critic_critic_opt_grad_steps": 131895.0, "train/extr_critic_critic_opt_loss": 11773.107596581136, "train/extr_critic_mag": 0.9364396519617203, "train/extr_critic_max": 0.9364396519617203, "train/extr_critic_mean": 0.7773714204993817, "train/extr_critic_min": 0.6540211854724709, "train/extr_critic_std": 0.03707291011553292, "train/extr_return_normed_mag": 0.5173837228105702, "train/extr_return_normed_max": 0.3290871756339292, "train/extr_return_normed_mean": 0.05516257993193394, "train/extr_return_normed_min": -0.3761619504438628, "train/extr_return_normed_std": 0.0433199451894525, "train/extr_return_rate": 0.9994723277354459, "train/extr_return_raw_mag": 1.0521641130294275, "train/extr_return_raw_max": 1.0521641130294275, "train/extr_return_raw_mean": 0.7782395580492982, "train/extr_return_raw_min": 0.3469149864048039, "train/extr_return_raw_std": 0.043319945232173716, "train/extr_reward_mag": 0.3505773320110566, "train/extr_reward_max": 0.3505773320110566, "train/extr_reward_mean": 0.0011049528278350624, "train/extr_reward_min": 8.20247405165926e-09, "train/extr_reward_std": 0.007891702604556987, "train/image_loss_mean": 0.07176181024641072, "train/image_loss_std": 0.09766938790268855, "train/model_loss_mean": 0.6964981173156598, "train/model_loss_std": 0.3793943937902057, "train/model_opt_grad_norm": 11.772585562609752, "train/model_opt_grad_steps": 131777.0504587156, "train/model_opt_loss": 4297.329710794152, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 6169.724770642202, "train/policy_entropy_mag": 1.3255140781402588, "train/policy_entropy_max": 1.3255140781402588, "train/policy_entropy_mean": 0.09060236924421897, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.1103463623365131, "train/policy_logprob_mag": 6.551080288143333, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09037178963286067, "train/policy_logprob_min": -6.551080288143333, "train/policy_logprob_std": 0.6268453190632917, "train/policy_randomness_mag": 0.6811795286629179, "train/policy_randomness_max": 0.6811795286629179, "train/policy_randomness_mean": 0.046560412358253374, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.05670681590675761, "train/post_ent_mag": 42.733054554790534, "train/post_ent_max": 42.733054554790534, "train/post_ent_mean": 41.66195193999404, "train/post_ent_min": 40.60329132780023, "train/post_ent_std": 0.4542906698557215, "train/prior_ent_mag": 42.15432048062666, "train/prior_ent_max": 42.15432048062666, "train/prior_ent_mean": 41.26434929873965, "train/prior_ent_min": 40.269837300711814, "train/prior_ent_std": 0.32613493611506367, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0012173433913614327, "train/reward_loss_mean": 0.009366224037158654, "train/reward_loss_std": 0.1659373418126819, "train/reward_max_data": 0.6385894501154575, "train/reward_max_pred": 0.2135437978517025, "train/reward_neg_acc": 0.9998294076788317, "train/reward_neg_loss": 0.0016171946743003375, "train/reward_pos_acc": 0.2037037050332686, "train/reward_pos_loss": 3.6608083636471718, "train/reward_pred": 0.0009521693551972713, "train/reward_rate": 0.0020919939793577983, "train_stats/mean_log_entropy": 0.07232955050595263, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.018107902258634567, "report/cont_loss_std": 0.29904595017433167, "report/cont_neg_acc": 0.4000000059604645, "report/cont_neg_loss": 3.1594948768615723, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.002693836111575365, "report/cont_pred": 0.9953441023826599, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.056051015853881836, "report/image_loss_std": 0.09098204225301743, "report/model_loss_mean": 0.6756451725959778, "report/model_loss_std": 0.31603294610977173, "report/post_ent_mag": 42.658470153808594, "report/post_ent_max": 42.658470153808594, "report/post_ent_mean": 41.562156677246094, "report/post_ent_min": 40.689308166503906, "report/post_ent_std": 0.4262889325618744, "report/prior_ent_mag": 42.287689208984375, "report/prior_ent_max": 42.287689208984375, "report/prior_ent_mean": 41.29391098022461, "report/prior_ent_min": 40.17444610595703, "report/prior_ent_std": 0.34518226981163025, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.0014862497337162495, "report/reward_loss_std": 0.007978815585374832, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.039557814598083496, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0014862497337162495, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0006639123894274235, "report/reward_rate": 0.0, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.04982035234570503, "eval/cont_loss_std": 0.7427041530609131, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 11.898445129394531, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.0033551629167050123, "eval/cont_pred": 0.9967440366744995, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.13969199359416962, "eval/image_loss_std": 0.11748474091291428, "eval/model_loss_mean": 0.7907532453536987, "eval/model_loss_std": 0.7489846348762512, "eval/post_ent_mag": 42.65416717529297, "eval/post_ent_max": 42.65416717529297, "eval/post_ent_mean": 41.64778137207031, "eval/post_ent_min": 40.66471862792969, "eval/post_ent_std": 0.42235422134399414, "eval/prior_ent_mag": 42.179046630859375, "eval/prior_ent_max": 42.179046630859375, "eval/prior_ent_mean": 41.300865173339844, "eval/prior_ent_min": 40.41135025024414, "eval/prior_ent_std": 0.3183978199958801, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0012408343609422445, "eval/reward_loss_std": 0.007961219176650047, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.07935976982116699, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0012408343609422445, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0005664260825142264, "eval/reward_rate": 0.0, "replay/size": 533001.0, "replay/inserts": 8732.0, "replay/samples": 34928.0, "replay/insert_wait_avg": 1.545925507346698e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.069484935241503e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 1632.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.046733528959985e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.152557373046875e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1702065467834, "timer/env.step_count": 1092.0, "timer/env.step_total": 10.85022497177124, "timer/env.step_frac": 0.01084837850672741, "timer/env.step_avg": 0.009936103454002967, "timer/env.step_min": 0.008675813674926758, "timer/env.step_max": 0.03508782386779785, "timer/replay._sample_count": 34928.0, "timer/replay._sample_total": 18.030933141708374, "timer/replay._sample_frac": 0.018027864681115124, "timer/replay._sample_avg": 0.0005162314802367263, "timer/replay._sample_min": 0.0004076957702636719, "timer/replay._sample_max": 0.029592275619506836, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1296.0, "timer/agent.policy_total": 13.69731593132019, "timer/agent.policy_frac": 0.01369498495522271, "timer/agent.policy_avg": 0.010568916613672987, "timer/agent.policy_min": 0.008842945098876953, "timer/agent.policy_max": 0.08142924308776855, "timer/dataset_train_count": 2183.0, "timer/dataset_train_total": 0.37773942947387695, "timer/dataset_train_frac": 0.0003776751466913527, "timer/dataset_train_avg": 0.0001730368435519363, "timer/dataset_train_min": 8.96453857421875e-05, "timer/dataset_train_max": 0.0012483596801757812, "timer/agent.train_count": 2183.0, "timer/agent.train_total": 970.8248722553253, "timer/agent.train_frac": 0.9706596596265583, "timer/agent.train_avg": 0.4447205095077074, "timer/agent.train_min": 0.4336228370666504, "timer/agent.train_max": 0.5972552299499512, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4780409336090088, "timer/agent.report_frac": 0.0004779595817590955, "timer/agent.report_avg": 0.2390204668045044, "timer/agent.report_min": 0.23277688026428223, "timer/agent.report_max": 0.24526405334472656, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.147125244140625e-05, "timer/dataset_eval_frac": 3.146589673978073e-08, "timer/dataset_eval_avg": 3.147125244140625e-05, "timer/dataset_eval_min": 3.147125244140625e-05, "timer/dataset_eval_max": 3.147125244140625e-05, "fps": 8.730388161194325}
{"step": 533672, "time": 61263.91989517212, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 533744, "time": 61272.18196892738, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 533776, "time": 61275.81331896782, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 533952, "time": 61295.7877805233, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 534016, "time": 61303.120948791504, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 534400, "time": 61346.68247938156, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 534568, "time": 61365.7661113739, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 534840, "time": 61396.51212668419, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 534936, "time": 61407.339260578156, "episode/length": 241.0, "episode/score": 0.24687500298023224, "episode/reward_rate": 0.004132231404958678, "episode/intrinsic_return": 0.0}
{"step": 535080, "time": 61423.689856767654, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 535168, "time": 61433.620309114456, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 535272, "time": 61445.335201501846, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 535288, "time": 61447.155849933624, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 535520, "time": 61473.38814306259, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 535560, "time": 61477.907514333725, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 535648, "time": 61487.91436505318, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 535784, "time": 61503.236167669296, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 535800, "time": 61505.05737781525, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 535888, "time": 61515.016063690186, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 536328, "time": 61564.70054960251, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 536352, "time": 61567.40085482597, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 536616, "time": 61597.29528141022, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 537136, "time": 61656.17553448677, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.0}
{"step": 537392, "time": 61685.122431993484, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 537512, "time": 61698.70348453522, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 537584, "time": 61706.819289684296, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 537608, "time": 61709.53764677048, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 537640, "time": 61713.157274484634, "episode/length": 231.0, "episode/score": 0.27812498807907104, "episode/reward_rate": 0.004310344827586207, "episode/intrinsic_return": 0.0}
{"step": 537784, "time": 61729.419295310974, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 537896, "time": 61742.03797698021, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 537976, "time": 61751.1047308445, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 537992, "time": 61752.897463560104, "episode/length": 207.0, "episode/score": 0.3531250059604645, "episode/reward_rate": 0.004807692307692308, "episode/intrinsic_return": 0.0}
{"step": 538112, "time": 61766.40912079811, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 538112, "time": 61766.42421936989, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 538272, "time": 61784.59289574623, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 538336, "time": 61791.82268190384, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 538616, "time": 61823.445345163345, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 538792, "time": 61843.3044424057, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 538896, "time": 61855.01866769791, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 539160, "time": 61884.808458566666, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 539360, "time": 61907.3900282383, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 539384, "time": 61910.09702038765, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 539528, "time": 61926.351236343384, "episode/length": 203.0, "episode/score": 0.3656249940395355, "episode/reward_rate": 0.004901960784313725, "episode/intrinsic_return": 0.0}
{"step": 539624, "time": 61937.20565319061, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 539976, "time": 61976.974246025085, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 540064, "time": 61986.91831469536, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 540072, "time": 61989.027975320816, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 540072, "time": 61989.65304350853, "eval_episode/length": 104.0, "eval_episode/score": 0.675000011920929, "eval_episode/reward_rate": 0.009523809523809525}
{"step": 540072, "time": 61990.032517910004, "eval_episode/length": 126.0, "eval_episode/score": 0.606249988079071, "eval_episode/reward_rate": 0.007874015748031496}
{"step": 540072, "time": 61990.51349210739, "eval_episode/length": 154.0, "eval_episode/score": 0.518750011920929, "eval_episode/reward_rate": 0.0064516129032258064}
{"step": 540072, "time": 61990.610365629196, "eval_episode/length": 159.0, "eval_episode/score": 0.503125011920929, "eval_episode/reward_rate": 0.00625}
{"step": 540072, "time": 61990.783965587616, "eval_episode/length": 42.0, "eval_episode/score": 0.8687499761581421, "eval_episode/reward_rate": 0.023255813953488372}
{"step": 540072, "time": 61991.494822740555, "eval_episode/length": 97.0, "eval_episode/score": 0.6968749761581421, "eval_episode/reward_rate": 0.01020408163265306}
{"step": 540072, "time": 61992.00379347801, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 540128, "time": 61998.33256101608, "episode/length": 251.0, "episode/score": 0.21562500298023224, "episode/reward_rate": 0.003968253968253968, "episode/intrinsic_return": 0.0}
{"step": 540184, "time": 62004.6353559494, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 540216, "time": 62008.24308800697, "episode/length": 234.0, "episode/score": 0.26875001192092896, "episode/reward_rate": 0.00425531914893617, "episode/intrinsic_return": 0.0}
{"step": 540224, "time": 62009.14612722397, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 540272, "time": 62014.54031300545, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 540312, "time": 62019.041241407394, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 540416, "time": 62030.850972890854, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 540784, "time": 62072.782413721085, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 541024, "time": 62099.917360305786, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 541216, "time": 62121.64054584503, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 541544, "time": 62158.75075054169, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 541600, "time": 62165.089379787445, "episode/length": 191.0, "episode/score": 0.40312498807907104, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.0}
{"step": 542032, "time": 62213.89360046387, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 542224, "time": 62235.550347328186, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 542248, "time": 62238.27888560295, "episode/length": 264.0, "episode/score": 0.17499999701976776, "episode/reward_rate": 0.0037735849056603774, "episode/intrinsic_return": 0.0}
{"step": 542305, "time": 62245.59843540192, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.5452728271484375, "train/action_min": 0.0, "train/action_std": 1.8088511196049777, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.007491509581450373, "train/actor_opt_grad_steps": 134085.0, "train/actor_opt_loss": -24.596456198258835, "train/adv_mag": 0.5354579119519753, "train/adv_max": 0.26602805283936587, "train/adv_mean": 0.00034992253682730734, "train/adv_min": -0.4974985972046852, "train/adv_std": 0.02276336156593805, "train/cont_avg": 0.9955033735795454, "train/cont_loss_mean": 0.015109553394458172, "train/cont_loss_std": 0.21752668901515956, "train/cont_neg_acc": 0.30775794197212564, "train/cont_neg_loss": 2.691192477034532, "train/cont_pos_acc": 0.9999331170862371, "train/cont_pos_loss": 0.003115894036388702, "train/cont_pred": 0.9955159336328506, "train/cont_rate": 0.9955033735795454, "train/dyn_loss_mean": 1.0000010745091872, "train/dyn_loss_std": 3.4365563293580305e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.10067433427849953, "train/extr_critic_critic_opt_grad_steps": 134085.0, "train/extr_critic_critic_opt_loss": 10443.715309836647, "train/extr_critic_mag": 0.9700977433811534, "train/extr_critic_max": 0.9700977433811534, "train/extr_critic_mean": 0.8025611961429769, "train/extr_critic_min": 0.6574152431704782, "train/extr_critic_std": 0.03752897706052119, "train/extr_return_normed_mag": 0.5577842395414006, "train/extr_return_normed_max": 0.3622699043967507, "train/extr_return_normed_mean": 0.055032764764671976, "train/extr_return_normed_min": -0.44711350717327814, "train/extr_return_normed_std": 0.04454180056398565, "train/extr_return_rate": 0.9993344927375967, "train/extr_return_raw_mag": 1.110148245367137, "train/extr_return_raw_max": 1.110148245367137, "train/extr_return_raw_mean": 0.8029111442240802, "train/extr_return_raw_min": 0.30076483379710806, "train/extr_return_raw_std": 0.04454180056398565, "train/extr_reward_mag": 0.39622570113702255, "train/extr_reward_max": 0.39622570113702255, "train/extr_reward_mean": 0.0011832070116228847, "train/extr_reward_min": 4.876743663441051e-09, "train/extr_reward_std": 0.008555047852198848, "train/image_loss_mean": 0.06878159940242767, "train/image_loss_std": 0.09492329514839433, "train/model_loss_mean": 0.6930661656639793, "train/model_loss_std": 0.37442880936644296, "train/model_opt_grad_norm": 11.758154715191234, "train/model_opt_grad_steps": 133965.25, "train/model_opt_loss": 3842.3516057794745, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5545.454545454545, "train/policy_entropy_mag": 1.3136659784750504, "train/policy_entropy_max": 1.3136659784750504, "train/policy_entropy_mean": 0.08700169304555112, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.10260624678974802, "train/policy_logprob_mag": 6.551080309260975, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.08703211342746561, "train/policy_logprob_min": -6.551080309260975, "train/policy_logprob_std": 0.6252016866748983, "train/policy_randomness_mag": 0.675090808489106, "train/policy_randomness_max": 0.675090808489106, "train/policy_randomness_mean": 0.04471003076230938, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.0527291833169081, "train/post_ent_mag": 42.46167944127863, "train/post_ent_max": 42.46167944127863, "train/post_ent_mean": 41.44394354386763, "train/post_ent_min": 40.46247754530473, "train/post_ent_std": 0.4277131787755273, "train/prior_ent_mag": 42.13599466844038, "train/prior_ent_max": 42.13599466844038, "train/prior_ent_mean": 41.184543956409804, "train/prior_ent_min": 40.22220507535067, "train/prior_ent_std": 0.3222684142264453, "train/rep_loss_mean": 1.0000010745091872, "train/rep_loss_std": 3.4365563293580305e-05, "train/reward_avg": 0.001237224240520101, "train/reward_loss_mean": 0.00917434306730601, "train/reward_loss_std": 0.1604850258381868, "train/reward_max_data": 0.6248863657089797, "train/reward_max_pred": 0.24012304544448854, "train/reward_neg_acc": 0.9997997945005244, "train/reward_neg_loss": 0.0016853213270554659, "train/reward_pos_acc": 0.23874570682798466, "train/reward_pos_loss": 3.6058158464345738, "train/reward_pred": 0.0010221279485532167, "train/reward_rate": 0.002077414772727273, "train_stats/mean_log_entropy": 0.0709733421929547, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.014300158247351646, "report/cont_loss_std": 0.22554847598075867, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 3.9824225902557373, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0026406419929116964, "report/cont_pred": 0.9973168969154358, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.05790475010871887, "report/image_loss_std": 0.0805005431175232, "report/model_loss_mean": 0.6825940608978271, "report/model_loss_std": 0.4131721556186676, "report/post_ent_mag": 42.948368072509766, "report/post_ent_max": 42.948368072509766, "report/post_ent_mean": 41.93244934082031, "report/post_ent_min": 41.00577926635742, "report/post_ent_std": 0.4019504487514496, "report/prior_ent_mag": 41.982749938964844, "report/prior_ent_max": 41.982749938964844, "report/prior_ent_mean": 41.039634704589844, "report/prior_ent_min": 40.07058334350586, "report/prior_ent_std": 0.3049401640892029, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0010894774459302425, "report/reward_loss_mean": 0.010389131493866444, "report/reward_loss_std": 0.20424991846084595, "report/reward_max_data": 0.7906249761581421, "report/reward_max_pred": 0.03947269916534424, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0013729201164096594, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.617672920227051, "report/reward_pred": 0.0006802469724789262, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.044627878814935684, "eval/cont_loss_std": 0.6851316094398499, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 10.826297760009766, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.002346820430830121, "eval/cont_pred": 0.9976931214332581, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.1095564067363739, "eval/image_loss_std": 0.13105516135692596, "eval/model_loss_mean": 0.7647935152053833, "eval/model_loss_std": 0.8508183360099792, "eval/post_ent_mag": 42.96756362915039, "eval/post_ent_max": 42.96756362915039, "eval/post_ent_mean": 41.887142181396484, "eval/post_ent_min": 41.00127029418945, "eval/post_ent_std": 0.3964485824108124, "eval/prior_ent_mag": 41.98733901977539, "eval/prior_ent_max": 41.98733901977539, "eval/prior_ent_mean": 40.99540710449219, "eval/prior_ent_min": 40.18358612060547, "eval/prior_ent_std": 0.2927914559841156, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0004364013730082661, "eval/reward_loss_mean": 0.010609207674860954, "eval/reward_loss_std": 0.30254417657852173, "eval/reward_max_data": 0.4468750059604645, "eval/reward_max_pred": 0.03366649150848389, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00115247443318367, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 9.684847831726074, "eval/reward_pred": 0.0005211620591580868, "eval/reward_rate": 0.0009765625, "replay/size": 541801.0, "replay/inserts": 8800.0, "replay/samples": 35200.0, "replay/insert_wait_avg": 1.4820423993197354e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.167052138935435e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 1856.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 9.970932171262543e-07, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.599592208862305e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4270169734955, "timer/env.step_count": 1100.0, "timer/env.step_total": 10.825235843658447, "timer/env.step_frac": 0.010820615257279925, "timer/env.step_avg": 0.009841123494234952, "timer/env.step_min": 0.008661985397338867, "timer/env.step_max": 0.03446221351623535, "timer/replay._sample_count": 35200.0, "timer/replay._sample_total": 18.12568235397339, "timer/replay._sample_frac": 0.018117945683641605, "timer/replay._sample_avg": 0.0005149341577833349, "timer/replay._sample_min": 0.0003795623779296875, "timer/replay._sample_max": 0.013033390045166016, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1332.0, "timer/agent.policy_total": 13.59207534790039, "timer/agent.policy_frac": 0.013586273778390461, "timer/agent.policy_avg": 0.01020426077169699, "timer/agent.policy_min": 0.00879049301147461, "timer/agent.policy_max": 0.03967881202697754, "timer/dataset_train_count": 2200.0, "timer/dataset_train_total": 0.3931396007537842, "timer/dataset_train_frac": 0.0003929717951271599, "timer/dataset_train_avg": 0.00017869981852444735, "timer/dataset_train_min": 9.632110595703125e-05, "timer/dataset_train_max": 0.0010521411895751953, "timer/agent.train_count": 2200.0, "timer/agent.train_total": 971.0832722187042, "timer/agent.train_frac": 0.9706687801739278, "timer/agent.train_avg": 0.4414014873721383, "timer/agent.train_min": 0.4318220615386963, "timer/agent.train_max": 0.5689342021942139, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47551798820495605, "timer/agent.report_frac": 0.0004753150206233925, "timer/agent.report_avg": 0.23775899410247803, "timer/agent.report_min": 0.23188209533691406, "timer/agent.report_max": 0.243635892868042, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0517578125e-05, "timer/dataset_eval_frac": 3.0504552163457325e-08, "timer/dataset_eval_avg": 3.0517578125e-05, "timer/dataset_eval_min": 3.0517578125e-05, "timer/dataset_eval_max": 3.0517578125e-05, "fps": 8.796120992565685}
{"step": 542456, "time": 62262.580768823624, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 542496, "time": 62267.10650062561, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 542528, "time": 62270.72478437424, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 542536, "time": 62271.63580203056, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 542600, "time": 62278.869366168976, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 542728, "time": 62293.354028463364, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 542776, "time": 62298.76249527931, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 543128, "time": 62338.50953292847, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 543224, "time": 62349.36412501335, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 543240, "time": 62351.28356528282, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 543752, "time": 62409.161556482315, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 544040, "time": 62441.85389280319, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 544400, "time": 62482.61716628075, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 544560, "time": 62500.76238942146, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 544848, "time": 62533.54689002037, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 544912, "time": 62540.776267290115, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 545040, "time": 62555.238822221756, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 545040, "time": 62555.24760437012, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 545552, "time": 62613.52022266388, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 545984, "time": 62662.574709653854, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 546064, "time": 62671.62940740585, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 546120, "time": 62677.975711107254, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 546168, "time": 62683.513335466385, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 546232, "time": 62690.73887658119, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 546712, "time": 62745.24276304245, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 546728, "time": 62747.069088220596, "episode/length": 210.0, "episode/score": 0.34375, "episode/reward_rate": 0.004739336492890996, "episode/intrinsic_return": 0.0}
{"step": 546800, "time": 62755.19896411896, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 546808, "time": 62756.10767030716, "episode/length": 9.0, "episode/score": 0.971875011920929, "episode/reward_rate": 0.1, "episode/intrinsic_return": 0.0}
{"step": 546880, "time": 62764.25701212883, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 547736, "time": 62861.252359867096, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 547864, "time": 62875.682529211044, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 548432, "time": 62939.95492529869, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 548432, "time": 62939.96830058098, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 548480, "time": 62945.41324901581, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 548504, "time": 62948.10974407196, "episode/length": 283.0, "episode/score": 0.11562500149011612, "episode/reward_rate": 0.0035211267605633804, "episode/intrinsic_return": 0.0}
{"step": 548928, "time": 62996.5669336319, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 549024, "time": 63007.39971160889, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 549024, "time": 63007.41271734238, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 549112, "time": 63017.41406464577, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 549120, "time": 63018.338540792465, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 549856, "time": 63101.668860435486, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 549856, "time": 63101.68487095833, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 550056, "time": 63125.49070620537, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 550056, "time": 63126.01337766647, "eval_episode/length": 97.0, "eval_episode/score": 0.6968749761581421, "eval_episode/reward_rate": 0.01020408163265306}
{"step": 550056, "time": 63126.36416506767, "eval_episode/length": 116.0, "eval_episode/score": 0.637499988079071, "eval_episode/reward_rate": 0.008547008547008548}
{"step": 550056, "time": 63126.51041054726, "eval_episode/length": 124.0, "eval_episode/score": 0.612500011920929, "eval_episode/reward_rate": 0.008}
{"step": 550056, "time": 63127.41539478302, "eval_episode/length": 176.0, "eval_episode/score": 0.44999998807907104, "eval_episode/reward_rate": 0.005649717514124294}
{"step": 550056, "time": 63127.68981552124, "eval_episode/length": 75.0, "eval_episode/score": 0.765625, "eval_episode/reward_rate": 0.013157894736842105}
{"step": 550056, "time": 63127.98693609238, "eval_episode/length": 84.0, "eval_episode/score": 0.737500011920929, "eval_episode/reward_rate": 0.011764705882352941}
{"step": 550056, "time": 63128.045251369476, "eval_episode/length": 114.0, "eval_episode/score": 0.643750011920929, "eval_episode/reward_rate": 0.008695652173913044}
{"step": 550112, "time": 63134.431596040726, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 550744, "time": 63205.84512042999, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 551016, "time": 63236.6411781311, "episode/length": 248.0, "episode/score": 0.22499999403953552, "episode/reward_rate": 0.004016064257028112, "episode/intrinsic_return": 0.0}
{"step": 551089, "time": 63245.743438243866, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.477469149502841, "train/action_min": 0.0, "train/action_std": 1.8493387547406284, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.007505940788806501, "train/actor_opt_grad_steps": 136285.0, "train/actor_opt_loss": -26.35890448743647, "train/adv_mag": 0.5542111854661594, "train/adv_max": 0.300564952601086, "train/adv_mean": 0.0022685768407034795, "train/adv_min": -0.5143913878635926, "train/adv_std": 0.028619810210710223, "train/cont_avg": 0.9954412286931819, "train/cont_loss_mean": 0.015035252411193637, "train/cont_loss_std": 0.21191074314357883, "train/cont_neg_acc": 0.32380251514001024, "train/cont_neg_loss": 2.599997705509951, "train/cont_pos_acc": 0.999924207275564, "train/cont_pos_loss": 0.0031784708093089815, "train/cont_pred": 0.9954159354621713, "train/cont_rate": 0.9954412286931819, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.1250032480552115, "train/extr_critic_critic_opt_grad_steps": 136285.0, "train/extr_critic_critic_opt_loss": 8767.391051136363, "train/extr_critic_mag": 1.0770907217806036, "train/extr_critic_max": 1.0770907217806036, "train/extr_critic_mean": 0.8513419777154922, "train/extr_critic_min": 0.7039984025738456, "train/extr_critic_std": 0.04731714877892624, "train/extr_return_normed_mag": 0.600486514785073, "train/extr_return_normed_max": 0.46210222379727794, "train/extr_return_normed_mean": 0.06372066522863779, "train/extr_return_normed_min": -0.41226192956620994, "train/extr_return_normed_std": 0.056363307345997204, "train/extr_return_rate": 0.9994395437565717, "train/extr_return_raw_mag": 1.2519920454783873, "train/extr_return_raw_max": 1.2519920454783873, "train/extr_return_raw_mean": 0.8536105348305268, "train/extr_return_raw_min": 0.3776278921148994, "train/extr_return_raw_std": 0.05636330744759603, "train/extr_reward_mag": 0.45022571953860197, "train/extr_reward_max": 0.45022571953860197, "train/extr_reward_mean": 0.0014647892512254079, "train/extr_reward_min": 5.960464477539063e-09, "train/extr_reward_std": 0.012998096172867174, "train/image_loss_mean": 0.07016574361107566, "train/image_loss_std": 0.09537440646778453, "train/model_loss_mean": 0.6945137739181518, "train/model_loss_std": 0.37119296013631603, "train/model_opt_grad_norm": 12.026088038357821, "train/model_opt_grad_steps": 136163.4818181818, "train/model_opt_loss": 4070.279053844105, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5886.363636363636, "train/policy_entropy_mag": 1.2501080052419142, "train/policy_entropy_max": 1.2501080052419142, "train/policy_entropy_mean": 0.08693629669194872, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.10173026357184757, "train/policy_logprob_mag": 6.551080330935392, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.08718769682401961, "train/policy_logprob_min": -6.551080330935392, "train/policy_logprob_std": 0.6262160824103788, "train/policy_randomness_mag": 0.6424284699288282, "train/policy_randomness_max": 0.6424284699288282, "train/policy_randomness_mean": 0.044676423038948664, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.05227901696820151, "train/post_ent_mag": 42.8583817395297, "train/post_ent_max": 42.8583817395297, "train/post_ent_mean": 41.857521785389295, "train/post_ent_min": 40.865185616233134, "train/post_ent_std": 0.4217534218322147, "train/prior_ent_mag": 42.100448192249644, "train/prior_ent_max": 42.100448192249644, "train/prior_ent_mean": 41.04345399683172, "train/prior_ent_min": 40.14545327966864, "train/prior_ent_std": 0.3395611874081872, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0012393604561194396, "train/reward_loss_mean": 0.009312754624459723, "train/reward_loss_std": 0.16272895251908762, "train/reward_max_data": 0.6313068186694926, "train/reward_max_pred": 0.21310679479078812, "train/reward_neg_acc": 0.9997552679343658, "train/reward_neg_loss": 0.001698315412134186, "train/reward_pos_acc": 0.18864839004747797, "train/reward_pos_loss": 3.6621295141451284, "train/reward_pred": 0.0010033728512512012, "train/reward_rate": 0.0020862926136363635, "train_stats/mean_log_entropy": 0.07395537967483203, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.009213359095156193, "report/cont_loss_std": 0.12855897843837738, "report/cont_neg_acc": 0.6666666865348816, "report/cont_neg_loss": 0.978512167930603, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0035004005767405033, "report/cont_pred": 0.9926230311393738, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.0894806832075119, "report/image_loss_std": 0.11348205804824829, "report/model_loss_mean": 0.70979905128479, "report/model_loss_std": 0.3663635849952698, "report/post_ent_mag": 42.61900329589844, "report/post_ent_max": 42.61900329589844, "report/post_ent_mean": 41.62612533569336, "report/post_ent_min": 40.433990478515625, "report/post_ent_std": 0.4540944993495941, "report/prior_ent_mag": 42.639862060546875, "report/prior_ent_max": 42.639862060546875, "report/prior_ent_mean": 41.76995086669922, "report/prior_ent_min": 40.66569137573242, "report/prior_ent_std": 0.3109346032142639, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0007659911643713713, "report/reward_loss_mean": 0.011105031706392765, "report/reward_loss_std": 0.20783105492591858, "report/reward_max_data": 0.5874999761581421, "report/reward_max_pred": 0.040787339210510254, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.002086919266730547, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.619359970092773, "report/reward_pred": 0.0010392641415819526, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.018913738429546356, "eval/cont_loss_std": 0.2433091104030609, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 3.6812543869018555, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.004551616031676531, "eval/cont_pred": 0.9954934120178223, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.14650267362594604, "eval/image_loss_std": 0.13584476709365845, "eval/model_loss_mean": 0.776037335395813, "eval/model_loss_std": 0.40764957666397095, "eval/post_ent_mag": 42.63733673095703, "eval/post_ent_max": 42.63733673095703, "eval/post_ent_mean": 41.68234634399414, "eval/post_ent_min": 40.49245834350586, "eval/post_ent_std": 0.43991172313690186, "eval/prior_ent_mag": 42.63213348388672, "eval/prior_ent_max": 42.63213348388672, "eval/prior_ent_mean": 41.78437805175781, "eval/prior_ent_min": 40.99197769165039, "eval/prior_ent_std": 0.30532190203666687, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.001617431640625, "eval/reward_loss_mean": 0.010620884597301483, "eval/reward_loss_std": 0.17560620605945587, "eval/reward_max_data": 0.828125, "eval/reward_max_pred": 0.06517243385314941, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.002880722051486373, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 3.965843677520752, "eval/reward_pred": 0.001367839751765132, "eval/reward_rate": 0.001953125, "replay/size": 550585.0, "replay/inserts": 8784.0, "replay/samples": 35136.0, "replay/insert_wait_avg": 1.5166884997286215e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.16124293148409e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 1704.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0208344795334506e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.046627044677734e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.127801656723, "timer/env.step_count": 1098.0, "timer/env.step_total": 10.840818881988525, "timer/env.step_frac": 0.010839433584418497, "timer/env.step_avg": 0.009873241240426708, "timer/env.step_min": 0.008619070053100586, "timer/env.step_max": 0.0343775749206543, "timer/replay._sample_count": 35136.0, "timer/replay._sample_total": 18.121164083480835, "timer/replay._sample_frac": 0.01811884846462914, "timer/replay._sample_avg": 0.0005157435133048962, "timer/replay._sample_min": 0.00038313865661621094, "timer/replay._sample_max": 0.016543149948120117, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1311.0, "timer/agent.policy_total": 13.427988767623901, "timer/agent.policy_frac": 0.013426272867707792, "timer/agent.policy_avg": 0.010242554361269186, "timer/agent.policy_min": 0.008795499801635742, "timer/agent.policy_max": 0.039678096771240234, "timer/dataset_train_count": 2196.0, "timer/dataset_train_total": 0.4144284725189209, "timer/dataset_train_frac": 0.0004143755146416442, "timer/dataset_train_avg": 0.00018871970515433556, "timer/dataset_train_min": 9.799003601074219e-05, "timer/dataset_train_max": 0.02324199676513672, "timer/agent.train_count": 2196.0, "timer/agent.train_total": 971.0634961128235, "timer/agent.train_frac": 0.9709394084478462, "timer/agent.train_avg": 0.4421964918546555, "timer/agent.train_min": 0.4318850040435791, "timer/agent.train_max": 0.5709238052368164, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4756286144256592, "timer/agent.report_frac": 0.00047556783606832545, "timer/agent.report_avg": 0.2378143072128296, "timer/agent.report_min": 0.2328031063079834, "timer/agent.report_max": 0.24282550811767578, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7418136596679688e-05, "timer/dataset_eval_frac": 2.7414632961168797e-08, "timer/dataset_eval_avg": 2.7418136596679688e-05, "timer/dataset_eval_min": 2.7418136596679688e-05, "timer/dataset_eval_max": 2.7418136596679688e-05, "fps": 8.782754302457269}
{"step": 551240, "time": 63262.63992333412, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 551336, "time": 63273.44139671326, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 551424, "time": 63283.48198843002, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 551432, "time": 63284.38429021835, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 551512, "time": 63293.397548913956, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 551560, "time": 63298.818813085556, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 551816, "time": 63327.68573451042, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 551944, "time": 63342.18486428261, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 552112, "time": 63361.1064286232, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 552160, "time": 63366.52104973793, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 552168, "time": 63367.42653799057, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 552168, "time": 63367.501445531845, "episode/length": 288.0, "episode/score": 0.10000000149011612, "episode/reward_rate": 0.0034602076124567475, "episode/intrinsic_return": 0.0}
{"step": 552856, "time": 63445.27395629883, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 552888, "time": 63448.88304877281, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 552904, "time": 63450.686385154724, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 553872, "time": 63560.054856061935, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 554128, "time": 63589.04179739952, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 554216, "time": 63598.97278428078, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 554424, "time": 63622.54822087288, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 554480, "time": 63628.87809967995, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 554480, "time": 63628.88540840149, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 554568, "time": 63638.79962468147, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 554712, "time": 63655.120329380035, "episode/length": 225.0, "episode/score": 0.296875, "episode/reward_rate": 0.004424778761061947, "episode/intrinsic_return": 0.0}
{"step": 554880, "time": 63674.09806060791, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 555168, "time": 63706.5598359108, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 555248, "time": 63715.57136964798, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 555552, "time": 63749.855520009995, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 555864, "time": 63785.10069537163, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 555984, "time": 63798.6636865139, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 556368, "time": 63842.06842112541, "episode/length": 235.0, "episode/score": 0.265625, "episode/reward_rate": 0.00423728813559322, "episode/intrinsic_return": 0.0}
{"step": 556552, "time": 63862.934844493866, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 556568, "time": 63864.75440168381, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 556736, "time": 63883.77243232727, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 556792, "time": 63890.08448433876, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 556800, "time": 63891.00496125221, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 556880, "time": 63900.01877331734, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 557120, "time": 63927.464696884155, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 557264, "time": 63943.73438692093, "episode/length": 251.0, "episode/score": 0.21562500298023224, "episode/reward_rate": 0.003968253968253968, "episode/intrinsic_return": 0.0}
{"step": 557720, "time": 63995.12468910217, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 557968, "time": 64023.07737207413, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 558296, "time": 64060.1292052269, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 558464, "time": 64079.0526509285, "episode/length": 238.0, "episode/score": 0.2562499940395355, "episode/reward_rate": 0.0041841004184100415, "episode/intrinsic_return": 0.0}
{"step": 558496, "time": 64082.663511276245, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 558880, "time": 64126.01188611984, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 559104, "time": 64151.28851342201, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 559112, "time": 64152.19953250885, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 559352, "time": 64179.28380703926, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 559576, "time": 64204.66553616524, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 559832, "time": 64233.51867413521, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 559933, "time": 64245.853732824326, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.5607440655048075, "train/action_min": 0.0, "train/action_std": 1.8345251574235804, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00586539496271555, "train/actor_opt_grad_steps": 138490.0, "train/actor_opt_loss": -21.590452315041382, "train/adv_mag": 0.4430828702665562, "train/adv_max": 0.20658407087239744, "train/adv_mean": -0.0001657857815004154, "train/adv_min": -0.39076988823813014, "train/adv_std": 0.017838833170913462, "train/cont_avg": 0.9955325579751131, "train/cont_loss_mean": 0.014625663604646314, "train/cont_loss_std": 0.21012588672980465, "train/cont_neg_acc": 0.3228860082951459, "train/cont_neg_loss": 2.5469580639164304, "train/cont_pos_acc": 0.9999245130098783, "train/cont_pos_loss": 0.0031418294358231567, "train/cont_pred": 0.9954393883636095, "train/cont_rate": 0.9955325579751131, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.10099911182377133, "train/extr_critic_critic_opt_grad_steps": 138490.0, "train/extr_critic_critic_opt_loss": 5797.956777166996, "train/extr_critic_mag": 1.0508351676604326, "train/extr_critic_max": 1.0508351676604326, "train/extr_critic_mean": 0.8951158960480495, "train/extr_critic_min": 0.7683423622700963, "train/extr_critic_std": 0.02924936797419285, "train/extr_return_normed_mag": 0.4858843970083004, "train/extr_return_normed_max": 0.28603621251982264, "train/extr_return_normed_mean": 0.04524434646970816, "train/extr_return_normed_min": -0.3329389507953937, "train/extr_return_normed_std": 0.03463303136778363, "train/extr_return_rate": 0.999795282048877, "train/extr_return_raw_mag": 1.1357419264262618, "train/extr_return_raw_max": 1.1357419264262618, "train/extr_return_raw_mean": 0.8949501101787274, "train/extr_return_raw_min": 0.5167667633807498, "train/extr_return_raw_std": 0.03463303132564234, "train/extr_reward_mag": 0.2886114568192495, "train/extr_reward_max": 0.2886114568192495, "train/extr_reward_mean": 0.0010485994301386583, "train/extr_reward_min": 0.0, "train/extr_reward_std": 0.007207237376844114, "train/image_loss_mean": 0.06937569821447269, "train/image_loss_std": 0.09509271690074135, "train/model_loss_mean": 0.6931363786507516, "train/model_loss_std": 0.3648355425213257, "train/model_opt_grad_norm": 11.298859242400432, "train/model_opt_grad_steps": 138366.62443438914, "train/model_opt_loss": 4139.849718741162, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5972.850678733032, "train/policy_entropy_mag": 1.252669780502492, "train/policy_entropy_max": 1.252669780502492, "train/policy_entropy_mean": 0.08762558802490321, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.10325141969174821, "train/policy_logprob_mag": 6.5510803498833425, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.088127122745255, "train/policy_logprob_min": -6.5510803498833425, "train/policy_logprob_std": 0.6277616989558639, "train/policy_randomness_mag": 0.6437449606295624, "train/policy_randomness_max": 0.6437449606295624, "train/policy_randomness_mean": 0.04503064875689027, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.05306073649032084, "train/post_ent_mag": 42.902421649225154, "train/post_ent_max": 42.902421649225154, "train/post_ent_mean": 41.897758932674634, "train/post_ent_min": 40.87000576726991, "train/post_ent_std": 0.434054764822058, "train/prior_ent_mag": 42.64680570714614, "train/prior_ent_max": 42.64680570714614, "train/prior_ent_mean": 41.73531301852265, "train/prior_ent_min": 40.87086535147412, "train/prior_ent_std": 0.30328250470744, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0012475475397951822, "train/reward_loss_mean": 0.009134995522993149, "train/reward_loss_std": 0.15912351164359986, "train/reward_max_data": 0.6338376680313192, "train/reward_max_pred": 0.24121487464300648, "train/reward_neg_acc": 0.999849417630364, "train/reward_neg_loss": 0.001713832644893202, "train/reward_pos_acc": 0.22089678722287193, "train/reward_pos_loss": 3.534565017610637, "train/reward_pred": 0.001046925972793167, "train/reward_rate": 0.0021033653846153845, "train_stats/mean_log_entropy": 0.07183361844140657, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.020657263696193695, "report/cont_loss_std": 0.3020998239517212, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 4.480268478393555, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0031685943249613047, "report/cont_pred": 0.9967563152313232, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07020121812820435, "report/image_loss_std": 0.1011686623096466, "report/model_loss_mean": 0.7004650831222534, "report/model_loss_std": 0.43753671646118164, "report/post_ent_mag": 42.61796569824219, "report/post_ent_max": 42.61796569824219, "report/post_ent_mean": 41.601348876953125, "report/post_ent_min": 40.53562927246094, "report/post_ent_std": 0.44763991236686707, "report/prior_ent_mag": 42.57530975341797, "report/prior_ent_max": 42.57530975341797, "report/prior_ent_mean": 41.72267150878906, "report/prior_ent_min": 40.87861633300781, "report/prior_ent_std": 0.3099207878112793, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0015228271950036287, "report/reward_loss_mean": 0.009606542997062206, "report/reward_loss_std": 0.17527008056640625, "report/reward_max_data": 0.8687499761581421, "report/reward_max_pred": 0.03310573101043701, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00187881535384804, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 3.9584755897521973, "report/reward_pred": 0.0009247725829482079, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.032367341220378876, "eval/cont_loss_std": 0.559422492980957, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 10.034388542175293, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.002978445729240775, "eval/cont_pred": 0.9970862865447998, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.13068640232086182, "eval/image_loss_std": 0.15474571287631989, "eval/model_loss_mean": 0.7644683122634888, "eval/model_loss_std": 0.5761197805404663, "eval/post_ent_mag": 42.64069747924805, "eval/post_ent_max": 42.64069747924805, "eval/post_ent_mean": 41.57472229003906, "eval/post_ent_min": 40.57404327392578, "eval/post_ent_std": 0.42923590540885925, "eval/prior_ent_mag": 42.64918518066406, "eval/prior_ent_max": 42.64918518066406, "eval/prior_ent_mean": 41.727996826171875, "eval/prior_ent_min": 40.78577423095703, "eval/prior_ent_std": 0.3052603602409363, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.001414535567164421, "eval/reward_loss_std": 0.007450392935425043, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.04047989845275879, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.001414535567164421, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0006565452786162496, "eval/reward_rate": 0.0, "replay/size": 559429.0, "replay/inserts": 8844.0, "replay/samples": 35376.0, "replay/insert_wait_avg": 1.5077468012857631e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.966224126069593e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 8.940696716308594e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0981049537659, "timer/env.step_count": 1105.0, "timer/env.step_total": 10.85367727279663, "timer/env.step_frac": 0.010852612577741453, "timer/env.step_avg": 0.009822332373571612, "timer/env.step_min": 0.008644580841064453, "timer/env.step_max": 0.03683185577392578, "timer/replay._sample_count": 35376.0, "timer/replay._sample_total": 18.35759449005127, "timer/replay._sample_frac": 0.01835579369575941, "timer/replay._sample_avg": 0.0005189279310846695, "timer/replay._sample_min": 0.00037384033203125, "timer/replay._sample_max": 0.0357205867767334, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1105.0, "timer/agent.policy_total": 11.353480100631714, "timer/agent.policy_frac": 0.011352366377253141, "timer/agent.policy_avg": 0.010274642625006075, "timer/agent.policy_min": 0.009438514709472656, "timer/agent.policy_max": 0.03555035591125488, "timer/dataset_train_count": 2211.0, "timer/dataset_train_total": 0.3822956085205078, "timer/dataset_train_frac": 0.0003822581071065835, "timer/dataset_train_avg": 0.00017290620014496057, "timer/dataset_train_min": 9.107589721679688e-05, "timer/dataset_train_max": 0.0012011528015136719, "timer/agent.train_count": 2211.0, "timer/agent.train_total": 974.8656754493713, "timer/agent.train_frac": 0.9747700456791076, "timer/agent.train_avg": 0.4409161806645732, "timer/agent.train_min": 0.4310314655303955, "timer/agent.train_max": 0.5806026458740234, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4779362678527832, "timer/agent.report_frac": 0.000477889384536808, "timer/agent.report_avg": 0.2389681339263916, "timer/agent.report_min": 0.2317674160003662, "timer/agent.report_max": 0.246168851852417, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0279159545898438e-05, "timer/dataset_eval_frac": 3.027618930174678e-08, "timer/dataset_eval_avg": 3.0279159545898438e-05, "timer/dataset_eval_min": 3.0279159545898438e-05, "timer/dataset_eval_max": 3.0279159545898438e-05, "fps": 8.843001877923003}
{"step": 559968, "time": 64249.633690834045, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.0}
{"step": 560040, "time": 64259.330687999725, "eval_episode/length": 87.0, "eval_episode/score": 0.7281249761581421, "eval_episode/reward_rate": 0.011363636363636364}
{"step": 560040, "time": 64260.2477209568, "eval_episode/length": 138.0, "eval_episode/score": 0.5687500238418579, "eval_episode/reward_rate": 0.007194244604316547}
{"step": 560040, "time": 64260.966925144196, "eval_episode/length": 178.0, "eval_episode/score": 0.4437499940395355, "eval_episode/reward_rate": 0.00558659217877095}
{"step": 560040, "time": 64261.443725824356, "eval_episode/length": 205.0, "eval_episode/score": 0.359375, "eval_episode/reward_rate": 0.0048543689320388345}
{"step": 560040, "time": 64261.82658791542, "eval_episode/length": 138.0, "eval_episode/score": 0.5687500238418579, "eval_episode/reward_rate": 0.007194244604316547}
{"step": 560040, "time": 64262.52513337135, "eval_episode/length": 39.0, "eval_episode/score": 0.878125011920929, "eval_episode/reward_rate": 0.025}
{"step": 560040, "time": 64262.637707710266, "eval_episode/length": 272.0, "eval_episode/score": 0.15000000596046448, "eval_episode/reward_rate": 0.003663003663003663}
{"step": 560040, "time": 64262.67872619629, "eval_episode/length": 135.0, "eval_episode/score": 0.578125, "eval_episode/reward_rate": 0.007352941176470588}
{"step": 560280, "time": 64289.840979099274, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 560376, "time": 64300.63032078743, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 560496, "time": 64314.2512922287, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 560640, "time": 64330.48368167877, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 560808, "time": 64349.52241373062, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 560960, "time": 64366.7825717926, "episode/length": 231.0, "episode/score": 0.27812498807907104, "episode/reward_rate": 0.004310344827586207, "episode/intrinsic_return": 0.0}
{"step": 561408, "time": 64417.501902103424, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 561432, "time": 64420.2012925148, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 561512, "time": 64429.395036935806, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 561568, "time": 64435.79248023033, "episode/length": 199.0, "episode/score": 0.37812501192092896, "episode/reward_rate": 0.005, "episode/intrinsic_return": 0.0}
{"step": 561584, "time": 64437.6139729023, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 561592, "time": 64438.52573013306, "episode/length": 251.0, "episode/score": 0.21562500298023224, "episode/reward_rate": 0.003968253968253968, "episode/intrinsic_return": 0.0}
{"step": 562504, "time": 64542.08971142769, "episode/length": 211.0, "episode/score": 0.34062498807907104, "episode/reward_rate": 0.0047169811320754715, "episode/intrinsic_return": 0.0}
{"step": 562512, "time": 64542.99711060524, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 562512, "time": 64543.00363492966, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 562952, "time": 64592.761798620224, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 563344, "time": 64637.20865917206, "episode/length": 228.0, "episode/score": 0.2874999940395355, "episode/reward_rate": 0.004366812227074236, "episode/intrinsic_return": 0.0}
{"step": 563720, "time": 64679.82981491089, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 563832, "time": 64692.61051392555, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 563880, "time": 64698.05275249481, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 563896, "time": 64699.87875676155, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 564048, "time": 64717.14346694946, "episode/length": 191.0, "episode/score": 0.40312498807907104, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.0}
{"step": 564096, "time": 64722.70592570305, "episode/length": 198.0, "episode/score": 0.3812499940395355, "episode/reward_rate": 0.005025125628140704, "episode/intrinsic_return": 0.0}
{"step": 564472, "time": 64765.40214800835, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 564592, "time": 64779.03082561493, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 564592, "time": 64779.037494659424, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 564664, "time": 64787.31232738495, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 564736, "time": 64795.52044391632, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 565000, "time": 64825.593876600266, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 565120, "time": 64839.14236307144, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 565264, "time": 64855.77030873299, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 565352, "time": 64865.74980378151, "episode/length": 250.0, "episode/score": 0.21875, "episode/reward_rate": 0.00398406374501992, "episode/intrinsic_return": 0.0}
{"step": 565504, "time": 64883.06219935417, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 565792, "time": 64915.751459121704, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 565912, "time": 64929.27405524254, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 566184, "time": 64960.29247403145, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.0}
{"step": 566256, "time": 64968.54891848564, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 566296, "time": 64973.04700422287, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 566368, "time": 64981.17547559738, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 566520, "time": 64998.48929524422, "episode/length": 240.0, "episode/score": 0.25, "episode/reward_rate": 0.004149377593360996, "episode/intrinsic_return": 0.0}
{"step": 566784, "time": 65028.43098974228, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 567312, "time": 65088.255472421646, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.0}
{"step": 567784, "time": 65141.70844769478, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 567816, "time": 65145.35505247116, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 568008, "time": 65167.08806729317, "episode/length": 227.0, "episode/score": 0.2906250059604645, "episode/reward_rate": 0.0043859649122807015, "episode/intrinsic_return": 0.0}
{"step": 568088, "time": 65176.194981098175, "episode/length": 223.0, "episode/score": 0.3031249940395355, "episode/reward_rate": 0.004464285714285714, "episode/intrinsic_return": 0.0}
{"step": 568176, "time": 65186.09794592857, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 568448, "time": 65216.7836933136, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 568568, "time": 65230.294337034225, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 568656, "time": 65240.28508448601, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 568680, "time": 65243.00459718704, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 568701, "time": 65246.225237846375, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.566369461686644, "train/action_min": 0.0, "train/action_std": 1.8634093199690727, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.009044338675794196, "train/actor_opt_grad_steps": 140690.0, "train/actor_opt_loss": -26.895863476409215, "train/adv_mag": 0.5650843780606849, "train/adv_max": 0.27430588469657724, "train/adv_mean": 6.036196455544049e-05, "train/adv_min": -0.5246193973713269, "train/adv_std": 0.026813633714432586, "train/cont_avg": 0.9952465039954338, "train/cont_loss_mean": 0.016103490533256163, "train/cont_loss_std": 0.22382304955435467, "train/cont_neg_acc": 0.3047474142010898, "train/cont_neg_loss": 2.661835391133557, "train/cont_pos_acc": 0.9999193151791891, "train/cont_pos_loss": 0.003183298441262482, "train/cont_pred": 0.9954455260816775, "train/cont_rate": 0.9952465039954338, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.10986076143132226, "train/extr_critic_critic_opt_grad_steps": 140690.0, "train/extr_critic_critic_opt_loss": 6700.596844677511, "train/extr_critic_mag": 1.1046817607531265, "train/extr_critic_max": 1.1046817607531265, "train/extr_critic_mean": 0.8920334133927681, "train/extr_critic_min": 0.748843460322515, "train/extr_critic_std": 0.04464772801216879, "train/extr_return_normed_mag": 0.5847604500648638, "train/extr_return_normed_max": 0.4024817440063442, "train/extr_return_normed_mean": 0.05839740376085995, "train/extr_return_normed_min": -0.43214658161276553, "train/extr_return_normed_std": 0.05291702360186947, "train/extr_return_rate": 0.9994022002503208, "train/extr_return_raw_mag": 1.2361781335856816, "train/extr_return_raw_max": 1.2361781335856816, "train/extr_return_raw_mean": 0.892093835628196, "train/extr_return_raw_min": 0.40154980796657197, "train/extr_return_raw_std": 0.052917023312691686, "train/extr_reward_mag": 0.42011795686260206, "train/extr_reward_max": 0.42011795686260206, "train/extr_reward_mean": 0.0011758878431070306, "train/extr_reward_min": 0.0, "train/extr_reward_std": 0.010568548740232235, "train/image_loss_mean": 0.07144971404513811, "train/image_loss_std": 0.09677761456329528, "train/model_loss_mean": 0.6976866820087172, "train/model_loss_std": 0.3907700849858593, "train/model_opt_grad_norm": 11.551528654142057, "train/model_opt_grad_steps": 140564.85388127854, "train/model_opt_loss": 4286.970664107092, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 6141.552511415525, "train/policy_entropy_mag": 1.2816222247467737, "train/policy_entropy_max": 1.2816222247467737, "train/policy_entropy_mean": 0.08818505956157702, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.10490522424788236, "train/policy_logprob_mag": 6.551080329233109, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.0882217908218571, "train/policy_logprob_min": -6.551080329233109, "train/policy_logprob_std": 0.6259758899745331, "train/policy_randomness_mag": 0.6586235767085803, "train/policy_randomness_max": 0.6586235767085803, "train/policy_randomness_mean": 0.045318160631340934, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.05391062384462792, "train/post_ent_mag": 42.75162549650288, "train/post_ent_max": 42.75162549650288, "train/post_ent_mean": 41.75195911703589, "train/post_ent_min": 40.69769409040338, "train/post_ent_std": 0.4468350558792619, "train/prior_ent_mag": 42.622595364644646, "train/prior_ent_max": 42.622595364644646, "train/prior_ent_mean": 41.659712264526924, "train/prior_ent_min": 40.71041445100688, "train/prior_ent_std": 0.32749459691787963, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0013552731097453662, "train/reward_loss_mean": 0.01013345488498081, "train/reward_loss_std": 0.17433935158235364, "train/reward_max_data": 0.6655964617995911, "train/reward_max_pred": 0.22127484132165778, "train/reward_neg_acc": 0.9998346020097602, "train/reward_neg_loss": 0.0017601654451015112, "train/reward_pos_acc": 0.1966503285163758, "train/reward_pos_loss": 3.7063955482022437, "train/reward_pred": 0.001051993025828272, "train/reward_rate": 0.002256349885844749, "train_stats/mean_log_entropy": 0.07547157902557117, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.014787016436457634, "report/cont_loss_std": 0.2383320927619934, "report/cont_neg_acc": 0.25, "report/cont_neg_loss": 3.206531524658203, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0022703714203089476, "report/cont_pred": 0.9967271685600281, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.05294984579086304, "report/image_loss_std": 0.08641599863767624, "report/model_loss_mean": 0.679343044757843, "report/model_loss_std": 0.46694421768188477, "report/post_ent_mag": 42.74501419067383, "report/post_ent_max": 42.74501419067383, "report/post_ent_mean": 41.65171813964844, "report/post_ent_min": 40.68754577636719, "report/post_ent_std": 0.45464229583740234, "report/prior_ent_mag": 42.590362548828125, "report/prior_ent_max": 42.590362548828125, "report/prior_ent_mean": 41.504878997802734, "report/prior_ent_min": 40.350181579589844, "report/prior_ent_std": 0.3972158133983612, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.000701904296875, "report/reward_loss_mean": 0.011606124229729176, "report/reward_loss_std": 0.24169021844863892, "report/reward_max_data": 0.45625001192092896, "report/reward_max_pred": 0.033716440200805664, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.001060417969711125, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 5.4004621505737305, "report/reward_pred": 0.0005265487125143409, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.044292718172073364, "eval/cont_loss_std": 0.6880723237991333, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 10.532071113586426, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.003164175897836685, "eval/cont_pred": 0.9970189332962036, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.14055433869361877, "eval/image_loss_std": 0.16021375358104706, "eval/model_loss_mean": 0.7928605079650879, "eval/model_loss_std": 0.7929280996322632, "eval/post_ent_mag": 42.74545669555664, "eval/post_ent_max": 42.74545669555664, "eval/post_ent_mean": 41.670921325683594, "eval/post_ent_min": 40.6121826171875, "eval/post_ent_std": 0.44763273000717163, "eval/prior_ent_mag": 42.719696044921875, "eval/prior_ent_max": 42.719696044921875, "eval/prior_ent_mean": 41.480064392089844, "eval/prior_ent_min": 40.491817474365234, "eval/prior_ent_std": 0.4090847074985504, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0008178710704669356, "eval/reward_loss_mean": 0.008013417012989521, "eval/reward_loss_std": 0.22815421223640442, "eval/reward_max_data": 0.8374999761581421, "eval/reward_max_pred": 0.030634522438049316, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0008826670818962157, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 7.302770614624023, "eval/reward_pred": 0.00039653899148106575, "eval/reward_rate": 0.0009765625, "replay/size": 568197.0, "replay/inserts": 8768.0, "replay/samples": 35072.0, "replay/insert_wait_avg": 1.52326304547108e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.196200372528856e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 2200.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0543519800359552e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3576107025146, "timer/env.step_count": 1096.0, "timer/env.step_total": 10.835390090942383, "timer/env.step_frac": 0.010831516624672934, "timer/env.step_avg": 0.009886304827502175, "timer/env.step_min": 0.008666038513183594, "timer/env.step_max": 0.03559303283691406, "timer/replay._sample_count": 35072.0, "timer/replay._sample_total": 18.24258327484131, "timer/replay._sample_frac": 0.01823606186394704, "timer/replay._sample_avg": 0.0005201466490317435, "timer/replay._sample_min": 0.0003845691680908203, "timer/replay._sample_max": 0.025527238845825195, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1371.0, "timer/agent.policy_total": 13.956571102142334, "timer/agent.policy_frac": 0.013951581867149633, "timer/agent.policy_avg": 0.010179847631030149, "timer/agent.policy_min": 0.008813619613647461, "timer/agent.policy_max": 0.03601264953613281, "timer/dataset_train_count": 2192.0, "timer/dataset_train_total": 0.3753199577331543, "timer/dataset_train_frac": 0.0003751857872801915, "timer/dataset_train_avg": 0.00017122260845490615, "timer/dataset_train_min": 9.083747863769531e-05, "timer/dataset_train_max": 0.0011985301971435547, "timer/agent.train_count": 2192.0, "timer/agent.train_total": 970.3054015636444, "timer/agent.train_frac": 0.9699585340108867, "timer/agent.train_avg": 0.44265757370604214, "timer/agent.train_min": 0.4318277835845947, "timer/agent.train_max": 0.5859830379486084, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47656750679016113, "timer/agent.report_frac": 0.00047639714207350827, "timer/agent.report_avg": 0.23828375339508057, "timer/agent.report_min": 0.2324380874633789, "timer/agent.report_max": 0.24412941932678223, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.075599670410156e-05, "timer/dataset_eval_frac": 3.074500196235099e-08, "timer/dataset_eval_avg": 3.075599670410156e-05, "timer/dataset_eval_min": 3.075599670410156e-05, "timer/dataset_eval_max": 3.075599670410156e-05, "fps": 8.764742926169125}
{"step": 568832, "time": 65260.82853627205, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 568976, "time": 65277.18961453438, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 569008, "time": 65280.82287836075, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 569280, "time": 65311.653606176376, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 570024, "time": 65397.22331118584, "eval_episode/length": 56.0, "eval_episode/score": 0.824999988079071, "eval_episode/reward_rate": 0.017543859649122806}
{"step": 570024, "time": 65397.79127764702, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 570024, "time": 65398.105352163315, "eval_episode/length": 107.0, "eval_episode/score": 0.6656249761581421, "eval_episode/reward_rate": 0.009259259259259259}
{"step": 570024, "time": 65399.86018490791, "eval_episode/length": 174.0, "eval_episode/score": 0.45625001192092896, "eval_episode/reward_rate": 0.005714285714285714}
{"step": 570024, "time": 65399.941266298294, "eval_episode/length": 178.0, "eval_episode/score": 0.4437499940395355, "eval_episode/reward_rate": 0.00558659217877095}
{"step": 570024, "time": 65400.285809993744, "eval_episode/length": 198.0, "eval_episode/score": 0.3812499940395355, "eval_episode/reward_rate": 0.005025125628140704}
{"step": 570024, "time": 65401.68227124214, "eval_episode/length": 190.0, "eval_episode/score": 0.40625, "eval_episode/reward_rate": 0.005235602094240838}
{"step": 570024, "time": 65401.82315945625, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 570024, "time": 65401.829448223114, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 570096, "time": 65409.986678123474, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 570144, "time": 65415.475957393646, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 570352, "time": 65438.95615029335, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 570376, "time": 65441.740045785904, "episode/length": 240.0, "episode/score": 0.25, "episode/reward_rate": 0.004149377593360996, "episode/intrinsic_return": 0.0}
{"step": 570856, "time": 65496.26211810112, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 570872, "time": 65498.08109641075, "episode/length": 254.0, "episode/score": 0.20624999701976776, "episode/reward_rate": 0.00392156862745098, "episode/intrinsic_return": 0.0}
{"step": 570888, "time": 65499.91611933708, "episode/length": 234.0, "episode/score": 0.26875001192092896, "episode/reward_rate": 0.00425531914893617, "episode/intrinsic_return": 0.0}
{"step": 570968, "time": 65509.06626367569, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 571288, "time": 65545.4835691452, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 571432, "time": 65561.85439968109, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 571648, "time": 65586.27638602257, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 571904, "time": 65615.24747419357, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 572008, "time": 65627.15332603455, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 572456, "time": 65678.04605460167, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 572576, "time": 65691.74695563316, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 572664, "time": 65701.7803914547, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 573184, "time": 65761.01604962349, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 573224, "time": 65765.54681110382, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 573464, "time": 65793.05004096031, "episode/length": 226.0, "episode/score": 0.29374998807907104, "episode/reward_rate": 0.004405286343612335, "episode/intrinsic_return": 0.0}
{"step": 573504, "time": 65797.5636548996, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 573600, "time": 65808.53740906715, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 573920, "time": 65844.8927769661, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 573928, "time": 65845.79992580414, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 574216, "time": 65878.48175525665, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 574768, "time": 65941.13670277596, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 574776, "time": 65942.04169774055, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 574848, "time": 65950.18307638168, "episode/length": 283.0, "episode/score": 0.11562500149011612, "episode/reward_rate": 0.0035211267605633804, "episode/intrinsic_return": 0.0}
{"step": 575328, "time": 66004.57855820656, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 575392, "time": 66011.89422273636, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 575536, "time": 66028.16842722893, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 575816, "time": 66060.02607798576, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 576184, "time": 66101.85682344437, "episode/length": 245.0, "episode/score": 0.234375, "episode/reward_rate": 0.0040650406504065045, "episode/intrinsic_return": 0.0}
{"step": 576456, "time": 66132.75752949715, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 576504, "time": 66138.19689702988, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 576696, "time": 66159.93747115135, "episode/length": 239.0, "episode/score": 0.25312501192092896, "episode/reward_rate": 0.004166666666666667, "episode/intrinsic_return": 0.0}
{"step": 576720, "time": 66162.76277899742, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 576936, "time": 66187.18824958801, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 577080, "time": 66203.57267904282, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 577312, "time": 66229.90883803368, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 577432, "time": 66243.49798464775, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 577449, "time": 66246.32535600662, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.3944816415168377, "train/action_min": 0.0, "train/action_std": 1.807410582559838, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.008071936093925682, "train/actor_opt_grad_steps": 142880.0, "train/actor_opt_loss": -23.48417549481675, "train/adv_mag": 0.517983566816539, "train/adv_max": 0.23658642812406636, "train/adv_mean": -0.0005708370973151677, "train/adv_min": -0.4799550261399517, "train/adv_std": 0.023410565700364983, "train/cont_avg": 0.995353524543379, "train/cont_loss_mean": 0.015710324813403426, "train/cont_loss_std": 0.22095261773808975, "train/cont_neg_acc": 0.30222252653353776, "train/cont_neg_loss": 2.6580612957984537, "train/cont_pos_acc": 0.9999103567915965, "train/cont_pos_loss": 0.0033169038802147183, "train/cont_pred": 0.9953353445823878, "train/cont_rate": 0.995353524543379, "train/dyn_loss_mean": 1.0000024974073993, "train/dyn_loss_std": 7.988388339678447e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.10149031779707567, "train/extr_critic_critic_opt_grad_steps": 142880.0, "train/extr_critic_critic_opt_loss": 6515.351687357306, "train/extr_critic_mag": 1.0430919884546708, "train/extr_critic_max": 1.0430919884546708, "train/extr_critic_mean": 0.8672276852337737, "train/extr_critic_min": 0.757677061372696, "train/extr_critic_std": 0.03466256388960636, "train/extr_return_normed_mag": 0.5566145807640738, "train/extr_return_normed_max": 0.34854807211383837, "train/extr_return_normed_mean": 0.050089098487610687, "train/extr_return_normed_min": -0.400726107429696, "train/extr_return_normed_std": 0.042919591945260085, "train/extr_return_rate": 0.9993790113218298, "train/extr_return_raw_mag": 1.165115862676542, "train/extr_return_raw_max": 1.165115862676542, "train/extr_return_raw_mean": 0.8666569383721373, "train/extr_return_raw_min": 0.4158416834051751, "train/extr_return_raw_std": 0.04291959203031237, "train/extr_reward_mag": 0.3478022890003849, "train/extr_reward_max": 0.3478022890003849, "train/extr_reward_mean": 0.0012461622830344254, "train/extr_reward_min": 0.0, "train/extr_reward_std": 0.008987804884346176, "train/image_loss_mean": 0.0708331583263395, "train/image_loss_std": 0.09623755101267606, "train/model_loss_mean": 0.6962872370737329, "train/model_loss_std": 0.3833598756490777, "train/model_opt_grad_norm": 11.93368600601475, "train/model_opt_grad_steps": 142753.200913242, "train/model_opt_loss": 4121.507335366724, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5913.24200913242, "train/policy_entropy_mag": 1.2618341315282535, "train/policy_entropy_max": 1.2618341315282535, "train/policy_entropy_mean": 0.08832928364815777, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.10439699367709356, "train/policy_logprob_mag": 6.551080318346416, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.08843127872845898, "train/policy_logprob_min": -6.551080318346416, "train/policy_logprob_std": 0.6265608744534183, "train/policy_randomness_mag": 0.6484545058311393, "train/policy_randomness_max": 0.6484545058311393, "train/policy_randomness_mean": 0.04539227645555043, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.05364944493253482, "train/post_ent_mag": 42.95398494424341, "train/post_ent_max": 42.95398494424341, "train/post_ent_mean": 41.940315420769124, "train/post_ent_min": 40.85451887296215, "train/post_ent_std": 0.44999295990216676, "train/prior_ent_mag": 42.577859312432, "train/prior_ent_max": 42.577859312432, "train/prior_ent_mean": 41.477281370119414, "train/prior_ent_min": 40.39604044178305, "train/prior_ent_std": 0.3777865057122217, "train/rep_loss_mean": 1.0000024974073993, "train/rep_loss_std": 7.988388339678447e-05, "train/reward_avg": 0.0012911722454992994, "train/reward_loss_mean": 0.00974223100724864, "train/reward_loss_std": 0.16872139035226547, "train/reward_max_data": 0.6465896110828608, "train/reward_max_pred": 0.20773124477090357, "train/reward_neg_acc": 0.9997944184089904, "train/reward_neg_loss": 0.0018346627900955271, "train/reward_pos_acc": 0.17621440638848884, "train/reward_pos_loss": 3.7801016056956955, "train/reward_pred": 0.0010391930734832266, "train/reward_rate": 0.0021136558219178084, "train_stats/mean_log_entropy": 0.07451222599907355, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.02229953557252884, "report/cont_loss_std": 0.2826719582080841, "report/cont_neg_acc": 0.1428571492433548, "report/cont_neg_loss": 2.8377740383148193, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0029206553008407354, "report/cont_pred": 0.9956039190292358, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.08975578844547272, "report/image_loss_std": 0.1209108829498291, "report/model_loss_mean": 0.7268952131271362, "report/model_loss_std": 0.4701516628265381, "report/post_ent_mag": 43.02101516723633, "report/post_ent_max": 43.02101516723633, "report/post_ent_mean": 42.0958251953125, "report/post_ent_min": 40.949607849121094, "report/post_ent_std": 0.4498607814311981, "report/prior_ent_mag": 42.400917053222656, "report/prior_ent_max": 42.400917053222656, "report/prior_ent_mean": 41.5008544921875, "report/prior_ent_min": 40.46977615356445, "report/prior_ent_std": 0.3760715126991272, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0026153563521802425, "report/reward_loss_mean": 0.014839883893728256, "report/reward_loss_std": 0.2166214883327484, "report/reward_max_data": 0.8343750238418579, "report/reward_max_pred": 0.15037381649017334, "report/reward_neg_acc": 0.9999999403953552, "report/reward_neg_loss": 0.001779853948391974, "report/reward_pos_acc": 0.25, "report/reward_pos_loss": 3.345147132873535, "report/reward_pred": 0.0010545396944507957, "report/reward_rate": 0.00390625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.036681048572063446, "eval/cont_loss_std": 0.5897210836410522, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 8.593216896057129, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.0031260026153177023, "eval/cont_pred": 0.9969953298568726, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.13006441295146942, "eval/image_loss_std": 0.1337810754776001, "eval/model_loss_mean": 0.772553563117981, "eval/model_loss_std": 0.6382061243057251, "eval/post_ent_mag": 43.103614807128906, "eval/post_ent_max": 43.103614807128906, "eval/post_ent_mean": 42.07588577270508, "eval/post_ent_min": 40.991859436035156, "eval/post_ent_std": 0.4059739112854004, "eval/prior_ent_mag": 42.58369445800781, "eval/prior_ent_max": 42.58369445800781, "eval/prior_ent_mean": 41.47649383544922, "eval/prior_ent_min": 40.31735610961914, "eval/prior_ent_std": 0.3713705539703369, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0008331298595294356, "eval/reward_loss_mean": 0.005808076821267605, "eval/reward_loss_std": 0.13099385797977448, "eval/reward_max_data": 0.8531249761581421, "eval/reward_max_pred": 0.1637578010559082, "eval/reward_neg_acc": 0.9980449676513672, "eval/reward_neg_loss": 0.0017444425029680133, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 4.162905216217041, "eval/reward_pred": 0.0008159932913258672, "eval/reward_rate": 0.0009765625, "replay/size": 576945.0, "replay/inserts": 8748.0, "replay/samples": 34992.0, "replay/insert_wait_avg": 1.5069046247261651e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.141792016537374e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0296753946060129e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.450580596923828e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.083582162857, "timer/env.step_count": 1094.0, "timer/env.step_total": 10.80301308631897, "timer/env.step_frac": 0.010802110222583147, "timer/env.step_avg": 0.009874783442704725, "timer/env.step_min": 0.008506536483764648, "timer/env.step_max": 0.03477215766906738, "timer/replay._sample_count": 34992.0, "timer/replay._sample_total": 18.10544204711914, "timer/replay._sample_frac": 0.018103928881587007, "timer/replay._sample_avg": 0.0005174166108573143, "timer/replay._sample_min": 0.00037860870361328125, "timer/replay._sample_max": 0.012130260467529297, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1383.0, "timer/agent.policy_total": 14.485821723937988, "timer/agent.policy_frac": 0.014484611068816714, "timer/agent.policy_avg": 0.010474202258812718, "timer/agent.policy_min": 0.008769750595092773, "timer/agent.policy_max": 0.08219242095947266, "timer/dataset_train_count": 2187.0, "timer/dataset_train_total": 0.3731527328491211, "timer/dataset_train_frac": 0.00037312154654325246, "timer/dataset_train_avg": 0.00017062310601240104, "timer/dataset_train_min": 8.726119995117188e-05, "timer/dataset_train_max": 0.0027611255645751953, "timer/agent.train_count": 2187.0, "timer/agent.train_total": 969.4670467376709, "timer/agent.train_frac": 0.9693860233571953, "timer/agent.train_avg": 0.4432862582248152, "timer/agent.train_min": 0.4327549934387207, "timer/agent.train_max": 0.5894083976745605, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4754636287689209, "timer/agent.report_frac": 0.00047542389181176933, "timer/agent.report_avg": 0.23773181438446045, "timer/agent.report_min": 0.2322216033935547, "timer/agent.report_max": 0.2432420253753662, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.956390380859375e-05, "timer/dataset_eval_frac": 2.956143300008645e-08, "timer/dataset_eval_avg": 2.956390380859375e-05, "timer/dataset_eval_min": 2.956390380859375e-05, "timer/dataset_eval_max": 2.956390380859375e-05, "fps": 8.747147873908489}
{"step": 577504, "time": 66252.41637468338, "episode/length": 271.0, "episode/score": 0.15312500298023224, "episode/reward_rate": 0.003676470588235294, "episode/intrinsic_return": 0.0}
{"step": 577704, "time": 66275.05137300491, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 577848, "time": 66291.38828372955, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 578048, "time": 66314.11611437798, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 578368, "time": 66350.35942173004, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 578392, "time": 66353.0805516243, "episode/length": 208.0, "episode/score": 0.3499999940395355, "episode/reward_rate": 0.004784688995215311, "episode/intrinsic_return": 0.0}
{"step": 578408, "time": 66354.90744066238, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 578816, "time": 66401.53071427345, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 578880, "time": 66408.82878923416, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 579072, "time": 66430.5881447792, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 579080, "time": 66431.60626626015, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 579176, "time": 66442.48836874962, "episode/length": 261.0, "episode/score": 0.18437500298023224, "episode/reward_rate": 0.003816793893129771, "episode/intrinsic_return": 0.0}
{"step": 579624, "time": 66493.37224936485, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 579752, "time": 66507.86203050613, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 579920, "time": 66526.93062710762, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 580008, "time": 66537.58956742287, "eval_episode/length": 38.0, "eval_episode/score": 0.8812500238418579, "eval_episode/reward_rate": 0.02564102564102564}
{"step": 580008, "time": 66538.01733899117, "eval_episode/length": 24.0, "eval_episode/score": 0.925000011920929, "eval_episode/reward_rate": 0.04}
{"step": 580008, "time": 66538.15905332565, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 580008, "time": 66538.59922456741, "eval_episode/length": 33.0, "eval_episode/score": 0.8968750238418579, "eval_episode/reward_rate": 0.029411764705882353}
{"step": 580008, "time": 66538.72336268425, "eval_episode/length": 104.0, "eval_episode/score": 0.675000011920929, "eval_episode/reward_rate": 0.009523809523809525}
{"step": 580008, "time": 66538.72921657562, "eval_episode/length": 104.0, "eval_episode/score": 0.675000011920929, "eval_episode/reward_rate": 0.009523809523809525}
{"step": 580008, "time": 66539.0632109642, "eval_episode/length": 123.0, "eval_episode/score": 0.6156250238418579, "eval_episode/reward_rate": 0.008064516129032258}
{"step": 580008, "time": 66540.44175577164, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 580088, "time": 66549.52643609047, "episode/length": 214.0, "episode/score": 0.33125001192092896, "episode/reward_rate": 0.004651162790697674, "episode/intrinsic_return": 0.0}
{"step": 580704, "time": 66619.78078460693, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 580952, "time": 66648.0717959404, "episode/length": 233.0, "episode/score": 0.2718749940395355, "episode/reward_rate": 0.004273504273504274, "episode/intrinsic_return": 0.0}
{"step": 581192, "time": 66675.38408041, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 581208, "time": 66677.21552872658, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 581384, "time": 66697.26098060608, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 581584, "time": 66720.06014442444, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 581632, "time": 66725.7872042656, "episode/length": 250.0, "episode/score": 0.21875, "episode/reward_rate": 0.00398406374501992, "episode/intrinsic_return": 0.0}
{"step": 581672, "time": 66730.43777322769, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 581712, "time": 66735.02746796608, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 581904, "time": 66756.83321332932, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 581920, "time": 66758.66552639008, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 582232, "time": 66794.27576208115, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 582400, "time": 66813.37265396118, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 582512, "time": 66826.12799024582, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 582848, "time": 66864.0390393734, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 582944, "time": 66874.94997882843, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 583016, "time": 66883.17066049576, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 583280, "time": 66913.11405229568, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 583800, "time": 66972.30555415154, "episode/length": 260.0, "episode/score": 0.1875, "episode/reward_rate": 0.0038314176245210726, "episode/intrinsic_return": 0.0}
{"step": 583808, "time": 66973.21845722198, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 584048, "time": 67000.4793817997, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 584216, "time": 67019.65597891808, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 584384, "time": 67038.7099583149, "episode/length": 247.0, "episode/score": 0.22812500596046448, "episode/reward_rate": 0.004032258064516129, "episode/intrinsic_return": 0.0}
{"step": 584640, "time": 67067.80390405655, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 584744, "time": 67079.6074655056, "episode/length": 236.0, "episode/score": 0.26249998807907104, "episode/reward_rate": 0.004219409282700422, "episode/intrinsic_return": 0.0}
{"step": 585168, "time": 67129.25128245354, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 585256, "time": 67139.18815231323, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 585440, "time": 67160.13503980637, "episode/length": 203.0, "episode/score": 0.3656249940395355, "episode/reward_rate": 0.004901960784313725, "episode/intrinsic_return": 0.0}
{"step": 585752, "time": 67195.58554029465, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 585992, "time": 67222.97591543198, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 586120, "time": 67237.47568798065, "episode/length": 237.0, "episode/score": 0.2593750059604645, "episode/reward_rate": 0.004201680672268907, "episode/intrinsic_return": 0.0}
{"step": 586193, "time": 67246.6842110157, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.3592621689542717, "train/action_min": 0.0, "train/action_std": 1.8160650680918213, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0101903161384302, "train/actor_opt_grad_steps": 145065.0, "train/actor_opt_loss": -25.34869084664441, "train/adv_mag": 0.53778965593478, "train/adv_max": 0.2614916374377154, "train/adv_mean": 0.0008546350964383426, "train/adv_min": -0.4918995822241547, "train/adv_std": 0.02442797325517333, "train/cont_avg": 0.9953187715022935, "train/cont_loss_mean": 0.015335208270698786, "train/cont_loss_std": 0.21587187606721706, "train/cont_neg_acc": 0.30894677956169897, "train/cont_neg_loss": 2.5994202374904405, "train/cont_pos_acc": 0.9999414797222942, "train/cont_pos_loss": 0.003243718879968099, "train/cont_pred": 0.9953061473478965, "train/cont_rate": 0.9953187715022935, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.11325940136891713, "train/extr_critic_critic_opt_grad_steps": 145065.0, "train/extr_critic_critic_opt_loss": 7361.193545280246, "train/extr_critic_mag": 1.0723800473256941, "train/extr_critic_max": 1.0723800473256941, "train/extr_critic_mean": 0.8698711020684023, "train/extr_critic_min": 0.7290127758586079, "train/extr_critic_std": 0.04174495534544144, "train/extr_return_normed_mag": 0.582194156602982, "train/extr_return_normed_max": 0.38654311999268487, "train/extr_return_normed_mean": 0.06069866677216434, "train/extr_return_normed_min": -0.41737835232270964, "train/extr_return_normed_std": 0.04918357164282865, "train/extr_return_rate": 0.9995822272169481, "train/extr_return_raw_mag": 1.1965701951893097, "train/extr_return_raw_max": 1.1965701951893097, "train/extr_return_raw_mean": 0.870725782365974, "train/extr_return_raw_min": 0.3926487234207468, "train/extr_return_raw_std": 0.04918357143776679, "train/extr_reward_mag": 0.3472609837120826, "train/extr_reward_max": 0.3472609837120826, "train/extr_reward_mean": 0.0010664632312692873, "train/extr_reward_min": 0.0, "train/extr_reward_std": 0.008078368251434091, "train/image_loss_mean": 0.07066983374160364, "train/image_loss_std": 0.09618666911617331, "train/model_loss_mean": 0.695734308947117, "train/model_loss_std": 0.37781467476705893, "train/model_opt_grad_norm": 11.711879734619423, "train/model_opt_grad_steps": 144936.3623853211, "train/model_opt_loss": 4040.149560770857, "train/model_opt_model_opt_grad_overflow": 0.0045871559633027525, "train/model_opt_model_opt_grad_scale": 5779.816513761468, "train/policy_entropy_mag": 1.2649785340379138, "train/policy_entropy_max": 1.2649785340379138, "train/policy_entropy_mean": 0.09232741170520083, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.11251167481372115, "train/policy_logprob_mag": 6.551080336264514, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09283675981360838, "train/policy_logprob_min": -6.551080336264514, "train/policy_logprob_std": 0.6324227867870156, "train/policy_randomness_mag": 0.6500704099825763, "train/policy_randomness_max": 0.6500704099825763, "train/policy_randomness_mean": 0.04744690829255712, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.057819566322029184, "train/post_ent_mag": 43.094187325293866, "train/post_ent_max": 43.094187325293866, "train/post_ent_mean": 42.04382131734025, "train/post_ent_min": 40.95960225096536, "train/post_ent_std": 0.45264391956526207, "train/prior_ent_mag": 42.55477474807599, "train/prior_ent_max": 42.55477474807599, "train/prior_ent_mean": 41.44265593082533, "train/prior_ent_min": 40.34082536959867, "train/prior_ent_std": 0.38050758701945664, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0012672494405305437, "train/reward_loss_mean": 0.009729242682298902, "train/reward_loss_std": 0.16618009338394626, "train/reward_max_data": 0.6296731655682446, "train/reward_max_pred": 0.21325906482311563, "train/reward_neg_acc": 0.9997665554011633, "train/reward_neg_loss": 0.0018652522401914103, "train/reward_pos_acc": 0.18575054573528657, "train/reward_pos_loss": 3.6953283245793456, "train/reward_pred": 0.0010675676460719641, "train/reward_rate": 0.0021591886467889907, "train_stats/mean_log_entropy": 0.07649123391255419, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.01232114713639021, "report/cont_loss_std": 0.21531495451927185, "report/cont_neg_acc": 0.6000000238418579, "report/cont_neg_loss": 1.910646677017212, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0030064976308494806, "report/cont_pred": 0.9941235780715942, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.05643369257450104, "report/image_loss_std": 0.07962983846664429, "report/model_loss_mean": 0.6760582327842712, "report/model_loss_std": 0.34663790464401245, "report/post_ent_mag": 42.93581008911133, "report/post_ent_max": 42.93581008911133, "report/post_ent_mean": 41.80051040649414, "report/post_ent_min": 40.557804107666016, "report/post_ent_std": 0.507300615310669, "report/prior_ent_mag": 42.52796173095703, "report/prior_ent_max": 42.52796173095703, "report/prior_ent_mean": 41.394004821777344, "report/prior_ent_min": 40.343013763427734, "report/prior_ent_std": 0.38996532559394836, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0015686035621911287, "report/reward_loss_mean": 0.007303380407392979, "report/reward_loss_std": 0.15300175547599792, "report/reward_max_data": 0.8374999761581421, "report/reward_max_pred": 0.8017308712005615, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0018933656392619014, "report/reward_pos_acc": 0.5, "report/reward_pos_loss": 2.7718212604522705, "report/reward_pred": 0.0016825220081955194, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.024888673797249794, "eval/cont_loss_std": 0.4175489842891693, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.9287238121032715, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.004603165201842785, "eval/cont_pred": 0.9955321550369263, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.11457342654466629, "eval/image_loss_std": 0.131539985537529, "eval/model_loss_mean": 0.7551146745681763, "eval/model_loss_std": 0.8164151310920715, "eval/post_ent_mag": 42.95844268798828, "eval/post_ent_max": 42.95844268798828, "eval/post_ent_mean": 41.80345916748047, "eval/post_ent_min": 40.77606201171875, "eval/post_ent_std": 0.4813052713871002, "eval/prior_ent_mag": 42.61939239501953, "eval/prior_ent_max": 42.61939239501953, "eval/prior_ent_mean": 41.39440155029297, "eval/prior_ent_min": 40.33257293701172, "eval/prior_ent_std": 0.3968086540699005, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0008209228399209678, "eval/reward_loss_mean": 0.015652596950531006, "eval/reward_loss_std": 0.41140854358673096, "eval/reward_max_data": 0.840624988079071, "eval/reward_max_pred": 0.0771784782409668, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.002797104185447097, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 13.16682243347168, "eval/reward_pred": 0.001243442646227777, "eval/reward_rate": 0.0009765625, "replay/size": 585689.0, "replay/inserts": 8744.0, "replay/samples": 34976.0, "replay/insert_wait_avg": 1.500395602953074e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.176688256224469e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 1640.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 9.875471999005573e-07, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.791685104370117e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3440110683441, "timer/env.step_count": 1093.0, "timer/env.step_total": 10.644669771194458, "timer/env.step_frac": 0.01064100914626979, "timer/env.step_avg": 0.009738947640617071, "timer/env.step_min": 0.008517742156982422, "timer/env.step_max": 0.03483152389526367, "timer/replay._sample_count": 34976.0, "timer/replay._sample_total": 18.067609310150146, "timer/replay._sample_frac": 0.018061395990019834, "timer/replay._sample_avg": 0.000516571629407312, "timer/replay._sample_min": 0.0004038810729980469, "timer/replay._sample_max": 0.025702953338623047, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1298.0, "timer/agent.policy_total": 13.089875221252441, "timer/agent.policy_frac": 0.013085373707863517, "timer/agent.policy_avg": 0.01008464963116521, "timer/agent.policy_min": 0.008846521377563477, "timer/agent.policy_max": 0.03332638740539551, "timer/dataset_train_count": 2186.0, "timer/dataset_train_total": 0.37547945976257324, "timer/dataset_train_frac": 0.00037535033509279465, "timer/dataset_train_avg": 0.00017176553511554128, "timer/dataset_train_min": 8.916854858398438e-05, "timer/dataset_train_max": 0.0008471012115478516, "timer/agent.train_count": 2186.0, "timer/agent.train_total": 972.0704743862152, "timer/agent.train_frac": 0.9717361863825891, "timer/agent.train_avg": 0.4446799974319374, "timer/agent.train_min": 0.43340015411376953, "timer/agent.train_max": 1.9288694858551025, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47724294662475586, "timer/agent.report_frac": 0.00047707882622806077, "timer/agent.report_avg": 0.23862147331237793, "timer/agent.report_min": 0.23250985145568848, "timer/agent.report_max": 0.24473309516906738, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.765655517578125e-05, "timer/dataset_eval_frac": 2.764704428653968e-08, "timer/dataset_eval_avg": 2.765655517578125e-05, "timer/dataset_eval_min": 2.765655517578125e-05, "timer/dataset_eval_max": 2.765655517578125e-05, "fps": 8.740870132526766}
{"step": 586280, "time": 67256.32242822647, "episode/length": 236.0, "episode/score": 0.26249998807907104, "episode/reward_rate": 0.004219409282700422, "episode/intrinsic_return": 0.0}
{"step": 586360, "time": 67265.32150387764, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 586928, "time": 67329.7496817112, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 586984, "time": 67336.25407004356, "episode/length": 215.0, "episode/score": 0.328125, "episode/reward_rate": 0.004629629629629629, "episode/intrinsic_return": 0.0}
{"step": 587056, "time": 67344.46751213074, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 587320, "time": 67374.55832505226, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 587480, "time": 67392.64782547951, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 587912, "time": 67441.4110531807, "episode/length": 223.0, "episode/score": 0.3031249940395355, "episode/reward_rate": 0.004464285714285714, "episode/intrinsic_return": 0.0}
{"step": 588592, "time": 67518.52982711792, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 588672, "time": 67527.5357336998, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 588912, "time": 67554.79311347008, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 588952, "time": 67559.31073451042, "episode/length": 245.0, "episode/score": 0.234375, "episode/reward_rate": 0.0040650406504065045, "episode/intrinsic_return": 0.0}
{"step": 588968, "time": 67561.13660740852, "episode/length": 205.0, "episode/score": 0.359375, "episode/reward_rate": 0.0048543689320388345, "episode/intrinsic_return": 0.0}
{"step": 589240, "time": 67592.02237582207, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 589368, "time": 67606.57927680016, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 589488, "time": 67620.16855621338, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 589568, "time": 67629.24343204498, "episode/length": 206.0, "episode/score": 0.35624998807907104, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.0}
{"step": 589576, "time": 67630.16015434265, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 589640, "time": 67637.54156088829, "episode/length": 269.0, "episode/score": 0.15937499701976776, "episode/reward_rate": 0.003703703703703704, "episode/intrinsic_return": 0.0}
{"step": 590040, "time": 67683.22612404823, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 590096, "time": 67691.07870435715, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 590096, "time": 67691.17299509048, "eval_episode/length": 85.0, "eval_episode/score": 0.734375, "eval_episode/reward_rate": 0.011627906976744186}
{"step": 590096, "time": 67691.54836368561, "eval_episode/length": 107.0, "eval_episode/score": 0.6656249761581421, "eval_episode/reward_rate": 0.009259259259259259}
{"step": 590096, "time": 67691.63779449463, "eval_episode/length": 112.0, "eval_episode/score": 0.6499999761581421, "eval_episode/reward_rate": 0.008849557522123894}
{"step": 590096, "time": 67691.70952391624, "eval_episode/length": 30.0, "eval_episode/score": 0.90625, "eval_episode/reward_rate": 0.03225806451612903}
{"step": 590096, "time": 67692.02403616905, "eval_episode/length": 134.0, "eval_episode/score": 0.581250011920929, "eval_episode/reward_rate": 0.007407407407407408}
{"step": 590096, "time": 67692.2678308487, "eval_episode/length": 148.0, "eval_episode/score": 0.5375000238418579, "eval_episode/reward_rate": 0.006711409395973154}
{"step": 590096, "time": 67692.45674920082, "eval_episode/length": 46.0, "eval_episode/score": 0.856249988079071, "eval_episode/reward_rate": 0.02127659574468085}
{"step": 590368, "time": 67723.26172590256, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 590488, "time": 67736.82241940498, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.0}
{"step": 590984, "time": 67793.01204562187, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 591104, "time": 67806.59400486946, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 591120, "time": 67808.42383813858, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 591264, "time": 67824.83037614822, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 591472, "time": 67848.47557330132, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 591880, "time": 67894.72439670563, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 591952, "time": 67902.94539642334, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 592352, "time": 67948.22146892548, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 592672, "time": 67984.56178116798, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 592688, "time": 67986.38684439659, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 592784, "time": 67997.3390071392, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 592800, "time": 67999.17697739601, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 593048, "time": 68027.32867360115, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 593176, "time": 68041.78337979317, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 593256, "time": 68050.88196754456, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 593296, "time": 68055.4729001522, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 593432, "time": 68070.81213831902, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 593528, "time": 68081.71531581879, "episode/length": 282.0, "episode/score": 0.11874999850988388, "episode/reward_rate": 0.0035335689045936395, "episode/intrinsic_return": 0.0}
{"step": 594264, "time": 68165.21440076828, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 594464, "time": 68187.91126227379, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 594488, "time": 68190.63764762878, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 594512, "time": 68193.35085344315, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 594824, "time": 68228.68635320663, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 594848, "time": 68231.46521258354, "episode/length": 208.0, "episode/score": 0.3499999940395355, "episode/reward_rate": 0.004784688995215311, "episode/intrinsic_return": 0.0}
{"step": 594977, "time": 68246.93790864944, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.1512304132634945, "train/action_min": 0.0, "train/action_std": 1.7681637460535222, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.009258179950781844, "train/actor_opt_grad_steps": 147255.0, "train/actor_opt_loss": -20.985559942505578, "train/adv_mag": 0.5500726290724495, "train/adv_max": 0.28615340915593235, "train/adv_mean": -0.00019131194193588188, "train/adv_min": -0.5067897699095986, "train/adv_std": 0.022922901267355137, "train/cont_avg": 0.9952325994318182, "train/cont_loss_mean": 0.015917533802249553, "train/cont_loss_std": 0.22220158008435234, "train/cont_neg_acc": 0.29263789788500905, "train/cont_neg_loss": 2.665530010970675, "train/cont_pos_acc": 0.9999419740655205, "train/cont_pos_loss": 0.003242091563614932, "train/cont_pred": 0.9953553096814589, "train/cont_rate": 0.9952325994318182, "train/dyn_loss_mean": 1.0000011010603471, "train/dyn_loss_std": 2.4429037743671374e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.12147583659230309, "train/extr_critic_critic_opt_grad_steps": 147255.0, "train/extr_critic_critic_opt_loss": 5793.867990944602, "train/extr_critic_mag": 1.0948132135651327, "train/extr_critic_max": 1.0948132135651327, "train/extr_critic_mean": 0.8943320377306505, "train/extr_critic_min": 0.7386362785642797, "train/extr_critic_std": 0.03163895875384862, "train/extr_return_normed_mag": 0.5912440690127286, "train/extr_return_normed_max": 0.38103220435706053, "train/extr_return_normed_mean": 0.04675218763507225, "train/extr_return_normed_min": -0.4577899388291619, "train/extr_return_normed_std": 0.0399021538736468, "train/extr_return_rate": 0.9994845244017514, "train/extr_return_raw_mag": 1.2284207192334262, "train/extr_return_raw_max": 1.2284207192334262, "train/extr_return_raw_mean": 0.8941407485441728, "train/extr_return_raw_min": 0.38959857577627355, "train/extr_return_raw_std": 0.03990215388211337, "train/extr_reward_mag": 0.3672007051381198, "train/extr_reward_max": 0.3672007051381198, "train/extr_reward_mean": 0.0011894136398702606, "train/extr_reward_min": 4.334883256392045e-09, "train/extr_reward_std": 0.00906019945078614, "train/image_loss_mean": 0.0721224071457982, "train/image_loss_std": 0.09734976913102648, "train/model_loss_mean": 0.6988722215999257, "train/model_loss_std": 0.40068488256497814, "train/model_opt_grad_norm": 10.99406333619898, "train/model_opt_grad_steps": 147124.44090909092, "train/model_opt_loss": 4004.657092285156, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5772.727272727273, "train/policy_entropy_mag": 1.3139405033805154, "train/policy_entropy_max": 1.3139405033805154, "train/policy_entropy_mean": 0.09550657922571355, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.1193715825676918, "train/policy_logprob_mag": 6.551080367781899, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09616492387246002, "train/policy_logprob_min": -6.551080367781899, "train/policy_logprob_std": 0.6362233015623959, "train/policy_randomness_mag": 0.6752318859100341, "train/policy_randomness_max": 0.6752318859100341, "train/policy_randomness_mean": 0.049080676907165485, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06134486217051745, "train/post_ent_mag": 43.15606332258745, "train/post_ent_max": 43.15606332258745, "train/post_ent_mean": 42.03807461478493, "train/post_ent_min": 40.88258245641535, "train/post_ent_std": 0.490456708046523, "train/prior_ent_mag": 42.72300515608354, "train/prior_ent_max": 42.72300515608354, "train/prior_ent_mean": 41.594345248829235, "train/prior_ent_min": 40.498912932656026, "train/prior_ent_std": 0.38483472872864116, "train/rep_loss_mean": 1.0000011010603471, "train/rep_loss_std": 2.4429037743671374e-05, "train/reward_avg": 0.0013822104717043906, "train/reward_loss_mean": 0.010831596170001748, "train/reward_loss_std": 0.1840349313654852, "train/reward_max_data": 0.6735085238109936, "train/reward_max_pred": 0.2047264359214089, "train/reward_neg_acc": 0.9998309067704461, "train/reward_neg_loss": 0.0018320321692788803, "train/reward_pos_acc": 0.1612311281082107, "train/reward_pos_loss": 3.8127334492962537, "train/reward_pred": 0.0010593418164221062, "train/reward_rate": 0.0023615056818181816, "train_stats/mean_log_entropy": 0.08056451137299123, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.015615971758961678, "report/cont_loss_std": 0.243251234292984, "report/cont_neg_acc": 0.4000000059604645, "report/cont_neg_loss": 2.5801713466644287, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.003032286185771227, "report/cont_pred": 0.9950166940689087, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07041806727647781, "report/image_loss_std": 0.09664379805326462, "report/model_loss_mean": 0.6969789266586304, "report/model_loss_std": 0.4408654272556305, "report/post_ent_mag": 43.77537536621094, "report/post_ent_max": 43.77537536621094, "report/post_ent_mean": 43.00654602050781, "report/post_ent_min": 42.269630432128906, "report/post_ent_std": 0.3308199644088745, "report/prior_ent_mag": 43.29570770263672, "report/prior_ent_max": 43.29570770263672, "report/prior_ent_mean": 42.43317794799805, "report/prior_ent_min": 41.054359436035156, "report/prior_ent_std": 0.42741599678993225, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0009033203241415322, "report/reward_loss_mean": 0.01094488613307476, "report/reward_loss_std": 0.21298325061798096, "report/reward_max_data": 0.53125, "report/reward_max_pred": 0.07476353645324707, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0017797196051105857, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.694344997406006, "report/reward_pred": 0.0008719224715605378, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.9931640625, "eval/cont_loss_mean": 0.03920014202594757, "eval/cont_loss_std": 0.4797860085964203, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.263189315795898, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.00324348546564579, "eval/cont_pred": 0.9966769814491272, "eval/cont_rate": 0.9931640625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.12829339504241943, "eval/image_loss_std": 0.12616266310214996, "eval/model_loss_mean": 0.7890286445617676, "eval/model_loss_std": 0.7324790358543396, "eval/post_ent_mag": 43.79145050048828, "eval/post_ent_max": 43.79145050048828, "eval/post_ent_mean": 43.040557861328125, "eval/post_ent_min": 42.107486724853516, "eval/post_ent_std": 0.3525379002094269, "eval/prior_ent_mag": 43.413795471191406, "eval/prior_ent_max": 43.413795471191406, "eval/prior_ent_mean": 42.482975006103516, "eval/prior_ent_min": 40.67340087890625, "eval/prior_ent_std": 0.41788437962532043, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0022247314918786287, "eval/reward_loss_mean": 0.021535083651542664, "eval/reward_loss_std": 0.3239208161830902, "eval/reward_max_data": 0.628125011920929, "eval/reward_max_pred": 0.029573917388916016, "eval/reward_neg_acc": 0.9999999403953552, "eval/reward_neg_loss": 0.0018852523062378168, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.032242298126221, "eval/reward_pred": 0.0009306557476520538, "eval/reward_rate": 0.00390625, "replay/size": 594473.0, "replay/inserts": 8784.0, "replay/samples": 35136.0, "replay/insert_wait_avg": 1.477684913871501e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.045209299236916e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 1280.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0097399353981018e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.599592208862305e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2430329322815, "timer/env.step_count": 1098.0, "timer/env.step_total": 10.742751121520996, "timer/env.step_frac": 0.010740140913581652, "timer/env.step_avg": 0.009783926340183057, "timer/env.step_min": 0.008654594421386719, "timer/env.step_max": 0.0353240966796875, "timer/replay._sample_count": 35136.0, "timer/replay._sample_total": 18.176236152648926, "timer/replay._sample_frac": 0.018171819801997554, "timer/replay._sample_avg": 0.0005173109105375946, "timer/replay._sample_min": 0.0004019737243652344, "timer/replay._sample_max": 0.02680802345275879, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1258.0, "timer/agent.policy_total": 12.803174495697021, "timer/agent.policy_frac": 0.01280006365869266, "timer/agent.policy_avg": 0.010177404209616074, "timer/agent.policy_min": 0.008800983428955078, "timer/agent.policy_max": 0.035094499588012695, "timer/dataset_train_count": 2196.0, "timer/dataset_train_total": 0.387622594833374, "timer/dataset_train_frac": 0.0003875284126669012, "timer/dataset_train_avg": 0.00017651302132667306, "timer/dataset_train_min": 9.512901306152344e-05, "timer/dataset_train_max": 0.0013995170593261719, "timer/agent.train_count": 2196.0, "timer/agent.train_total": 972.4400370121002, "timer/agent.train_frac": 0.9722037594816583, "timer/agent.train_avg": 0.4428233319727232, "timer/agent.train_min": 0.4326322078704834, "timer/agent.train_max": 0.5802650451660156, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48563480377197266, "timer/agent.report_frac": 0.00048551680719864724, "timer/agent.report_avg": 0.24281740188598633, "timer/agent.report_min": 0.23730039596557617, "timer/agent.report_max": 0.24833440780639648, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.2649765014648438e-05, "timer/dataset_eval_frac": 2.26442617133249e-08, "timer/dataset_eval_avg": 2.2649765014648438e-05, "timer/dataset_eval_min": 2.2649765014648438e-05, "timer/dataset_eval_max": 2.2649765014648438e-05, "fps": 8.781746060441614}
{"step": 594984, "time": 68247.51788139343, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 595112, "time": 68262.16559171677, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 595424, "time": 68297.57838129997, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 595448, "time": 68300.3015935421, "episode/length": 273.0, "episode/score": 0.14687499403953552, "episode/reward_rate": 0.0036496350364963502, "episode/intrinsic_return": 0.0}
{"step": 595672, "time": 68325.72638773918, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 595952, "time": 68357.44881081581, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 596544, "time": 68424.55516123772, "episode/length": 256.0, "episode/score": 0.20000000298023224, "episode/reward_rate": 0.0038910505836575876, "episode/intrinsic_return": 0.0}
{"step": 596592, "time": 68429.97408890724, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 596824, "time": 68456.27379989624, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 597160, "time": 68494.34151434898, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 597376, "time": 68518.99351859093, "episode/length": 212.0, "episode/score": 0.3375000059604645, "episode/reward_rate": 0.004694835680751174, "episode/intrinsic_return": 0.0}
{"step": 597424, "time": 68524.42282485962, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 597760, "time": 68562.61863708496, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 598264, "time": 68620.16308927536, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 598328, "time": 68627.48612833023, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 598504, "time": 68647.41354131699, "episode/length": 244.0, "episode/score": 0.23749999701976776, "episode/reward_rate": 0.004081632653061225, "episode/intrinsic_return": 0.0}
{"step": 598784, "time": 68679.13001537323, "episode/length": 244.0, "episode/score": 0.23749999701976776, "episode/reward_rate": 0.004081632653061225, "episode/intrinsic_return": 0.0}
{"step": 598792, "time": 68680.03823304176, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 598904, "time": 68692.80296492577, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 599048, "time": 68709.06615686417, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 599736, "time": 68786.94324493408, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 599896, "time": 68805.05266880989, "episode/length": 203.0, "episode/score": 0.3656249940395355, "episode/reward_rate": 0.004901960784313725, "episode/intrinsic_return": 0.0}
{"step": 600072, "time": 68824.92266774178, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 600080, "time": 68829.05846309662, "eval_episode/length": 189.0, "eval_episode/score": 0.40937501192092896, "eval_episode/reward_rate": 0.005263157894736842}
{"step": 600080, "time": 68830.70053434372, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 600080, "time": 68830.70794939995, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 600080, "time": 68830.71424746513, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 600080, "time": 68830.71958184242, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 600080, "time": 68830.72479557991, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 600080, "time": 68830.72989201546, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 600080, "time": 68830.73492789268, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 600208, "time": 68845.2753367424, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 600352, "time": 68861.6339161396, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 600640, "time": 68894.21596050262, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 601096, "time": 68945.77422595024, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 601104, "time": 68946.68424844742, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 602048, "time": 69053.60693526268, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 602208, "time": 69071.7665822506, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 602312, "time": 69083.5737016201, "episode/length": 279.0, "episode/score": 0.12812499701976776, "episode/reward_rate": 0.0035714285714285713, "episode/intrinsic_return": 0.0}
{"step": 602456, "time": 69099.86295866966, "episode/length": 17.0, "episode/score": 0.9468749761581421, "episode/reward_rate": 0.05555555555555555, "episode/intrinsic_return": 0.0}
{"step": 602504, "time": 69105.34853553772, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 602520, "time": 69107.17644691467, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 602664, "time": 69123.50028920174, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 602952, "time": 69156.12674117088, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 602992, "time": 69160.64568448067, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 603144, "time": 69177.93515014648, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 603264, "time": 69191.53398013115, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 603384, "time": 69205.08312416077, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 603408, "time": 69207.81782054901, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 603749, "time": 69247.27194666862, "train_stats/mean_log_entropy": 0.07745638998543344, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.263270826644549, "train/action_min": 0.0, "train/action_std": 1.7786513752044608, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.009264801188742053, "train/actor_opt_grad_steps": 149450.0, "train/actor_opt_loss": -26.10980746299709, "train/adv_mag": 0.5467392415760859, "train/adv_max": 0.282023064077717, "train/adv_mean": -0.0008036056243663427, "train/adv_min": -0.5159897447721055, "train/adv_std": 0.02513287903222183, "train/cont_avg": 0.9955497288812786, "train/cont_loss_mean": 0.015108425543350104, "train/cont_loss_std": 0.21536757312842633, "train/cont_neg_acc": 0.2896734434051798, "train/cont_neg_loss": 2.6785861728000007, "train/cont_pos_acc": 0.9998880042333037, "train/cont_pos_loss": 0.003266602207068779, "train/cont_pred": 0.995468375889678, "train/cont_rate": 0.9955497288812786, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.1025851796972289, "train/extr_critic_critic_opt_grad_steps": 149450.0, "train/extr_critic_critic_opt_loss": 7215.798186001713, "train/extr_critic_mag": 1.1156801556887692, "train/extr_critic_max": 1.1156801556887692, "train/extr_critic_mean": 0.8737532844826511, "train/extr_critic_min": 0.7233593153626952, "train/extr_critic_std": 0.04155518254903082, "train/extr_return_normed_mag": 0.5753975605855793, "train/extr_return_normed_max": 0.40450721462023315, "train/extr_return_normed_mean": 0.05336399439331059, "train/extr_return_normed_min": -0.44567559053908745, "train/extr_return_normed_std": 0.049273326346591186, "train/extr_return_rate": 0.9994069601847156, "train/extr_return_raw_mag": 1.224092891499332, "train/extr_return_raw_max": 1.224092891499332, "train/extr_return_raw_mean": 0.8729497112639962, "train/extr_return_raw_min": 0.3739100860678442, "train/extr_return_raw_std": 0.04927332631257027, "train/extr_reward_mag": 0.4226638982285103, "train/extr_reward_max": 0.4226638982285103, "train/extr_reward_mean": 0.0012704603791026373, "train/extr_reward_min": 5.443346554830194e-10, "train/extr_reward_std": 0.01091394221546239, "train/image_loss_mean": 0.06988590510060254, "train/image_loss_std": 0.09576426000763837, "train/model_loss_mean": 0.6946479041282445, "train/model_loss_std": 0.3785754518081608, "train/model_opt_grad_norm": 11.149291778808315, "train/model_opt_grad_steps": 149317.76255707763, "train/model_opt_loss": 4106.01053817958, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5913.24200913242, "train/policy_entropy_mag": 1.3680399797822786, "train/policy_entropy_max": 1.3680399797822786, "train/policy_entropy_mean": 0.09724893264438464, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.12485116499063631, "train/policy_logprob_mag": 6.551080337942463, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09757661850076832, "train/policy_logprob_min": -6.551080337942463, "train/policy_logprob_std": 0.6368442594188534, "train/policy_randomness_mag": 0.7030335177569629, "train/policy_randomness_max": 0.7030335177569629, "train/policy_randomness_mean": 0.04997606956523303, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06416080983942501, "train/post_ent_mag": 43.05475821995844, "train/post_ent_max": 43.05475821995844, "train/post_ent_mean": 42.178421508231665, "train/post_ent_min": 41.28648379948586, "train/post_ent_std": 0.3820676623958431, "train/prior_ent_mag": 42.84636810163385, "train/prior_ent_max": 42.84636810163385, "train/prior_ent_mean": 41.69659928970685, "train/prior_ent_min": 40.25922115099485, "train/prior_ent_std": 0.4476065860219198, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0012696984628817176, "train/reward_loss_mean": 0.00965355560459945, "train/reward_loss_std": 0.16690177409633244, "train/reward_max_data": 0.6440353872569184, "train/reward_max_pred": 0.2006491536963476, "train/reward_neg_acc": 0.999843615375153, "train/reward_neg_loss": 0.0017844129377151052, "train/reward_pos_acc": 0.15900673536640225, "train/reward_pos_loss": 3.729727459074271, "train/reward_pred": 0.0010202323579863054, "train/reward_rate": 0.0021270333904109587, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.01237520482391119, "report/cont_loss_std": 0.20233389735221863, "report/cont_neg_acc": 0.5, "report/cont_neg_loss": 2.3216817378997803, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0033191004768013954, "report/cont_pred": 0.9951746463775635, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.06782501935958862, "report/image_loss_std": 0.09787954390048981, "report/model_loss_mean": 0.6868742108345032, "report/model_loss_std": 0.31703051924705505, "report/post_ent_mag": 42.695289611816406, "report/post_ent_max": 42.695289611816406, "report/post_ent_mean": 41.800514221191406, "report/post_ent_min": 40.92448043823242, "report/post_ent_std": 0.39272406697273254, "report/prior_ent_mag": 42.72659683227539, "report/prior_ent_max": 42.72659683227539, "report/prior_ent_mean": 41.48976516723633, "report/prior_ent_min": 40.0230827331543, "report/prior_ent_std": 0.47487443685531616, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0011688233353197575, "report/reward_loss_mean": 0.006673974916338921, "report/reward_loss_std": 0.13381682336330414, "report/reward_max_data": 0.6937500238418579, "report/reward_max_pred": 0.5022627115249634, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0018476350232958794, "report/reward_pos_acc": 0.5, "report/reward_pos_loss": 2.472933769226074, "report/reward_pred": 0.0013268559705466032, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.035719238221645355, "eval/cont_loss_std": 0.5075017213821411, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.7373881340026855, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0028356858529150486, "eval/cont_pred": 0.9971591830253601, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.08541553467512131, "eval/image_loss_std": 0.09667813032865524, "eval/model_loss_mean": 0.7528380155563354, "eval/model_loss_std": 1.001797080039978, "eval/post_ent_mag": 42.67671203613281, "eval/post_ent_max": 42.67671203613281, "eval/post_ent_mean": 41.76123809814453, "eval/post_ent_min": 40.909908294677734, "eval/post_ent_std": 0.4110299050807953, "eval/prior_ent_mag": 42.73749542236328, "eval/prior_ent_max": 42.73749542236328, "eval/prior_ent_mean": 41.46354293823242, "eval/prior_ent_min": 40.124820709228516, "eval/prior_ent_std": 0.48724672198295593, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0023101805709302425, "eval/reward_loss_mean": 0.0317031666636467, "eval/reward_loss_std": 0.5215592384338379, "eval/reward_max_data": 0.715624988079071, "eval/reward_max_pred": 0.07516372203826904, "eval/reward_neg_acc": 0.9999999403953552, "eval/reward_neg_loss": 0.0015812352066859603, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 7.712794780731201, "eval/reward_pred": 0.0007715498795732856, "eval/reward_rate": 0.00390625, "replay/size": 603245.0, "replay/inserts": 8772.0, "replay/samples": 35088.0, "replay/insert_wait_avg": 1.4811197046922648e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 6.952176505009225e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 9.658427386960357e-07, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3209843635559, "timer/env.step_count": 1096.0, "timer/env.step_total": 10.688332319259644, "timer/env.step_frac": 0.010684902632588466, "timer/env.step_avg": 0.009752128028521573, "timer/env.step_min": 0.007889986038208008, "timer/env.step_max": 0.034360647201538086, "timer/replay._sample_count": 35088.0, "timer/replay._sample_total": 17.87131929397583, "timer/replay._sample_frac": 0.017865584720634722, "timer/replay._sample_avg": 0.0005093285252501091, "timer/replay._sample_min": 0.0003368854522705078, "timer/replay._sample_max": 0.011522769927978516, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1385.0, "timer/agent.policy_total": 13.900734663009644, "timer/agent.policy_frac": 0.01389627417628737, "timer/agent.policy_avg": 0.010036631525638731, "timer/agent.policy_min": 0.008463621139526367, "timer/agent.policy_max": 0.03561687469482422, "timer/dataset_train_count": 2193.0, "timer/dataset_train_total": 0.3912360668182373, "timer/dataset_train_frac": 0.00039111052645482316, "timer/dataset_train_avg": 0.0001784022192513622, "timer/dataset_train_min": 9.632110595703125e-05, "timer/dataset_train_max": 0.0007669925689697266, "timer/agent.train_count": 2193.0, "timer/agent.train_total": 970.5067868232727, "timer/agent.train_frac": 0.9701953692801394, "timer/agent.train_avg": 0.44254755441097704, "timer/agent.train_min": 0.43299388885498047, "timer/agent.train_max": 0.5703952312469482, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.473616361618042, "timer/agent.report_frac": 0.00047346438695312947, "timer/agent.report_avg": 0.236808180809021, "timer/agent.report_min": 0.23421287536621094, "timer/agent.report_max": 0.23940348625183105, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.3603439331054688e-05, "timer/dataset_eval_frac": 2.3595865427207984e-08, "timer/dataset_eval_avg": 2.3603439331054688e-05, "timer/dataset_eval_min": 2.3603439331054688e-05, "timer/dataset_eval_max": 2.3603439331054688e-05, "fps": 8.769068627529784}
{"step": 604360, "time": 69316.52688217163, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 604400, "time": 69321.04775762558, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 604768, "time": 69362.84092497826, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 604824, "time": 69369.19268083572, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 605264, "time": 69419.1090786457, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 605296, "time": 69422.74345469475, "episode/length": 253.0, "episode/score": 0.20937499403953552, "episode/reward_rate": 0.003937007874015748, "episode/intrinsic_return": 0.0}
{"step": 605304, "time": 69423.65462636948, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 605456, "time": 69440.95298862457, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 605616, "time": 69459.05454611778, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 605920, "time": 69493.69835448265, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 605984, "time": 69500.95893526077, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 606000, "time": 69502.7891163826, "episode/length": 199.0, "episode/score": 0.37812501192092896, "episode/reward_rate": 0.005, "episode/intrinsic_return": 0.0}
{"step": 606168, "time": 69521.96294283867, "episode/length": 225.0, "episode/score": 0.296875, "episode/reward_rate": 0.004424778761061947, "episode/intrinsic_return": 0.0}
{"step": 606696, "time": 69582.53620314598, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 606776, "time": 69591.59097766876, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 607488, "time": 69672.67088246346, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 607608, "time": 69686.28884339333, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 607616, "time": 69687.1965432167, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 607792, "time": 69707.26982021332, "episode/length": 225.0, "episode/score": 0.296875, "episode/reward_rate": 0.004424778761061947, "episode/intrinsic_return": 0.0}
{"step": 607928, "time": 69722.7281665802, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 607984, "time": 69729.12354969978, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 608032, "time": 69734.67302322388, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 608312, "time": 69766.47934913635, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 608480, "time": 69785.55408978462, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 608888, "time": 69831.79428267479, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 608952, "time": 69838.99595952034, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 609008, "time": 69845.3563683033, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 609120, "time": 69858.16396069527, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 609496, "time": 69900.98686766624, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 609632, "time": 69916.52164363861, "episode/length": 251.0, "episode/score": 0.21562500298023224, "episode/reward_rate": 0.003968253968253968, "episode/intrinsic_return": 0.0}
{"step": 610064, "time": 69966.58107876778, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 610064, "time": 69966.89617753029, "eval_episode/length": 84.0, "eval_episode/score": 0.737500011920929, "eval_episode/reward_rate": 0.011764705882352941}
{"step": 610064, "time": 69966.99021339417, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 610064, "time": 69967.23759007454, "eval_episode/length": 103.0, "eval_episode/score": 0.6781250238418579, "eval_episode/reward_rate": 0.009615384615384616}
{"step": 610064, "time": 69968.3520629406, "eval_episode/length": 167.0, "eval_episode/score": 0.4781250059604645, "eval_episode/reward_rate": 0.005952380952380952}
{"step": 610064, "time": 69968.736972332, "eval_episode/length": 122.0, "eval_episode/score": 0.6187499761581421, "eval_episode/reward_rate": 0.008130081300813009}
{"step": 610064, "time": 69969.21072101593, "eval_episode/length": 112.0, "eval_episode/score": 0.6499999761581421, "eval_episode/reward_rate": 0.008849557522123894}
{"step": 610064, "time": 69970.35451364517, "eval_episode/length": 84.0, "eval_episode/score": 0.737500011920929, "eval_episode/reward_rate": 0.011764705882352941}
{"step": 610192, "time": 69984.97624206543, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 610240, "time": 69990.41608715057, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 610464, "time": 70015.85274195671, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 610624, "time": 70034.04311418533, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 610760, "time": 70049.48648643494, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 610808, "time": 70054.95789170265, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 611200, "time": 70099.52453780174, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 611264, "time": 70106.77613377571, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 611320, "time": 70113.13868069649, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 611968, "time": 70186.84704375267, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 612008, "time": 70191.39434289932, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 612080, "time": 70199.56349778175, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 612328, "time": 70227.63986110687, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 612360, "time": 70231.26474261284, "episode/length": 236.0, "episode/score": 0.26249998807907104, "episode/reward_rate": 0.004219409282700422, "episode/intrinsic_return": 0.0}
{"step": 612497, "time": 70247.6636557579, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.5669067940211185, "train/action_min": 0.0, "train/action_std": 1.5927394318254027, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.007916515079628863, "train/actor_opt_grad_steps": 151640.0, "train/actor_opt_loss": -25.795038157946443, "train/adv_mag": 0.46533543606327005, "train/adv_max": 0.256160333004172, "train/adv_mean": 0.0001953752996344615, "train/adv_min": -0.43017848359939714, "train/adv_std": 0.02350808167617479, "train/cont_avg": 0.9952375856164384, "train/cont_loss_mean": 0.015891937839853914, "train/cont_loss_std": 0.22004630530176505, "train/cont_neg_acc": 0.29938211771723344, "train/cont_neg_loss": 2.600627379123011, "train/cont_pos_acc": 0.9999192699994126, "train/cont_pos_loss": 0.0033726660517729035, "train/cont_pred": 0.995258836985723, "train/cont_rate": 0.9952375856164384, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.11709746254871697, "train/extr_critic_critic_opt_grad_steps": 151640.0, "train/extr_critic_critic_opt_loss": 8029.5179794520545, "train/extr_critic_mag": 1.0382346018264283, "train/extr_critic_max": 1.0382346018264283, "train/extr_critic_mean": 0.8430030955571562, "train/extr_critic_min": 0.7203348276277656, "train/extr_critic_std": 0.03982679419151452, "train/extr_return_normed_mag": 0.4968604551602716, "train/extr_return_normed_max": 0.3406379331736804, "train/extr_return_normed_mean": 0.054774276316846345, "train/extr_return_normed_min": -0.34887967534261205, "train/extr_return_normed_std": 0.04702352892318273, "train/extr_return_rate": 0.9993700926706671, "train/extr_return_raw_mag": 1.1290621017212192, "train/extr_return_raw_max": 1.1290621017212192, "train/extr_return_raw_mean": 0.8431984891085864, "train/extr_return_raw_min": 0.4395444932049268, "train/extr_return_raw_std": 0.04702352899972979, "train/extr_reward_mag": 0.342062075388486, "train/extr_reward_max": 0.342062075388486, "train/extr_reward_mean": 0.0013072336819256788, "train/extr_reward_min": 2.721673277415097e-09, "train/extr_reward_std": 0.00957853243937163, "train/image_loss_mean": 0.07055096540889239, "train/image_loss_std": 0.09637418749942082, "train/model_loss_mean": 0.6969262552043619, "train/model_loss_std": 0.39248712694263893, "train/model_opt_grad_norm": 10.905152177157467, "train/model_opt_grad_steps": 151506.19178082192, "train/model_opt_loss": 4537.386094463471, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 6529.680365296804, "train/policy_entropy_mag": 1.3502368823578368, "train/policy_entropy_max": 1.3502368823578368, "train/policy_entropy_mean": 0.09493221206479965, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.12029683321170066, "train/policy_logprob_mag": 6.5510803161690765, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09520424293464722, "train/policy_logprob_min": -6.5510803161690765, "train/policy_logprob_std": 0.6344348126894808, "train/policy_randomness_mag": 0.6938845354672436, "train/policy_randomness_max": 0.6938845354672436, "train/policy_randomness_mean": 0.04878551162541185, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.0618203465048581, "train/post_ent_mag": 42.78048024983167, "train/post_ent_max": 42.78048024983167, "train/post_ent_mean": 41.95627125430869, "train/post_ent_min": 41.084034836999905, "train/post_ent_std": 0.37039234934876497, "train/prior_ent_mag": 42.62622700869765, "train/prior_ent_max": 42.62622700869765, "train/prior_ent_mean": 41.45229797711655, "train/prior_ent_min": 40.105130861883296, "train/prior_ent_std": 0.43591421094114924, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0013526951420130464, "train/reward_loss_mean": 0.01048332926302672, "train/reward_loss_std": 0.17884972644331928, "train/reward_max_data": 0.6578339056609428, "train/reward_max_pred": 0.2321472679643326, "train/reward_neg_acc": 0.9997585660790744, "train/reward_neg_loss": 0.0019177577815010088, "train/reward_pos_acc": 0.17213827980538973, "train/reward_pos_loss": 3.720017435745551, "train/reward_pred": 0.0010988470113763933, "train/reward_rate": 0.0023276969178082194, "train_stats/mean_log_entropy": 0.07443076287480918, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.013663917779922485, "report/cont_loss_std": 0.17929156124591827, "report/cont_neg_acc": 0.20000000298023224, "report/cont_neg_loss": 2.1652166843414307, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.003106742398813367, "report/cont_pred": 0.9955637454986572, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.08560790866613388, "report/image_loss_std": 0.10393451154232025, "report/model_loss_mean": 0.7099131941795349, "report/model_loss_std": 0.3898058533668518, "report/post_ent_mag": 42.876068115234375, "report/post_ent_max": 42.876068115234375, "report/post_ent_mean": 42.01935958862305, "report/post_ent_min": 41.283851623535156, "report/post_ent_std": 0.35802850127220154, "report/prior_ent_mag": 42.50647735595703, "report/prior_ent_max": 42.50647735595703, "report/prior_ent_mean": 41.42804718017578, "report/prior_ent_min": 40.20066833496094, "report/prior_ent_std": 0.4084397554397583, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0008728026878088713, "report/reward_loss_mean": 0.010641318745911121, "report/reward_loss_std": 0.20226481556892395, "report/reward_max_data": 0.4749999940395355, "report/reward_max_pred": 0.08644187450408936, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0017135784728452563, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.572716236114502, "report/reward_pred": 0.0007404794450849295, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.01557196956127882, "eval/cont_loss_std": 0.29632896184921265, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.916701793670654, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.004023770336061716, "eval/cont_pred": 0.9959990978240967, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.10983554273843765, "eval/image_loss_std": 0.12442597001791, "eval/model_loss_mean": 0.7409545183181763, "eval/model_loss_std": 0.6261047720909119, "eval/post_ent_mag": 42.834712982177734, "eval/post_ent_max": 42.834712982177734, "eval/post_ent_mean": 42.10767364501953, "eval/post_ent_min": 41.255653381347656, "eval/post_ent_std": 0.3587440848350525, "eval/prior_ent_mag": 42.41967010498047, "eval/prior_ent_max": 42.41967010498047, "eval/prior_ent_mean": 41.453369140625, "eval/prior_ent_min": 40.01177978515625, "eval/prior_ent_std": 0.3980400264263153, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0009399413829669356, "eval/reward_loss_mean": 0.015546957030892372, "eval/reward_loss_std": 0.3059232831001282, "eval/reward_max_data": 0.690625011920929, "eval/reward_max_pred": 0.03407001495361328, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.002384747611358762, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 6.7414350509643555, "eval/reward_pred": 0.0011203635949641466, "eval/reward_rate": 0.001953125, "replay/size": 611993.0, "replay/inserts": 8748.0, "replay/samples": 34992.0, "replay/insert_wait_avg": 1.5455781459590318e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.108473919492146e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 2024.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0237627821006323e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.195638656616211e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3788831233978, "timer/env.step_count": 1094.0, "timer/env.step_total": 10.950082302093506, "timer/env.step_frac": 0.010945935072024907, "timer/env.step_avg": 0.010009215998257317, "timer/env.step_min": 0.00876307487487793, "timer/env.step_max": 0.035315513610839844, "timer/replay._sample_count": 34992.0, "timer/replay._sample_total": 17.89893674850464, "timer/replay._sample_frac": 0.017892157711906425, "timer/replay._sample_avg": 0.0005115151105539735, "timer/replay._sample_min": 0.00038504600524902344, "timer/replay._sample_max": 0.010888814926147461, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1347.0, "timer/agent.policy_total": 14.253767967224121, "timer/agent.policy_frac": 0.014248369500484451, "timer/agent.policy_avg": 0.010581861891034982, "timer/agent.policy_min": 0.008652448654174805, "timer/agent.policy_max": 0.08075165748596191, "timer/dataset_train_count": 2187.0, "timer/dataset_train_total": 0.3923068046569824, "timer/dataset_train_frac": 0.0003921582225247661, "timer/dataset_train_avg": 0.00017938125498718905, "timer/dataset_train_min": 9.72747802734375e-05, "timer/dataset_train_max": 0.0005502700805664062, "timer/agent.train_count": 2187.0, "timer/agent.train_total": 970.0394849777222, "timer/agent.train_frac": 0.9696720925866112, "timer/agent.train_avg": 0.44354800410503986, "timer/agent.train_min": 0.4302949905395508, "timer/agent.train_max": 0.5785958766937256, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4725492000579834, "timer/agent.report_frac": 0.0004723702269509961, "timer/agent.report_avg": 0.2362746000289917, "timer/agent.report_min": 0.23042917251586914, "timer/agent.report_max": 0.24212002754211426, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.123283386230469e-05, "timer/dataset_eval_frac": 3.1221004750509195e-08, "timer/dataset_eval_avg": 3.123283386230469e-05, "timer/dataset_eval_min": 3.123283386230469e-05, "timer/dataset_eval_max": 3.123283386230469e-05, "fps": 8.744572417759223}
{"step": 612552, "time": 70253.6978931427, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 612552, "time": 70253.7057466507, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 612816, "time": 70283.69950318336, "episode/length": 256.0, "episode/score": 0.20000000298023224, "episode/reward_rate": 0.0038910505836575876, "episode/intrinsic_return": 0.0}
{"step": 612936, "time": 70297.28426241875, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 613096, "time": 70315.52553224564, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 613248, "time": 70332.82072043419, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 613352, "time": 70344.51338744164, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 613464, "time": 70357.1857073307, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 613576, "time": 70369.97646188736, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 613616, "time": 70374.52979755402, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 613752, "time": 70389.9628918171, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 613960, "time": 70413.63003778458, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 614112, "time": 70430.78828525543, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 614120, "time": 70431.70901417732, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 614424, "time": 70466.66346549988, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 614544, "time": 70480.29863643646, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 614568, "time": 70483.11013579369, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 614864, "time": 70516.79378008842, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 614864, "time": 70516.81204628944, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 615256, "time": 70561.40087771416, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 615416, "time": 70579.61914253235, "episode/length": 224.0, "episode/score": 0.30000001192092896, "episode/reward_rate": 0.0044444444444444444, "episode/intrinsic_return": 0.0}
{"step": 615728, "time": 70615.02077627182, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 615752, "time": 70617.737251997, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 615776, "time": 70620.47599220276, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 615944, "time": 70639.49894714355, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 616000, "time": 70645.85779094696, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 616064, "time": 70653.10645723343, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 616432, "time": 70694.91484189034, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 616504, "time": 70703.08059310913, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 616512, "time": 70703.99212622643, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 616568, "time": 70710.3359978199, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 617000, "time": 70759.15811634064, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 617040, "time": 70763.69112634659, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 617104, "time": 70770.93007683754, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 617456, "time": 70810.74387431145, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 617768, "time": 70846.05694937706, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 617928, "time": 70864.09121465683, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 618008, "time": 70873.19065928459, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 618040, "time": 70876.812885046, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 618080, "time": 70881.33451986313, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 618256, "time": 70901.30073022842, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 618312, "time": 70907.63527870178, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 618504, "time": 70929.40409946442, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 618576, "time": 70937.63914132118, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 618824, "time": 70965.82711410522, "episode/length": 227.0, "episode/score": 0.2906250059604645, "episode/reward_rate": 0.0043859649122807015, "episode/intrinsic_return": 0.0}
{"step": 618880, "time": 70972.18968653679, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 619184, "time": 71006.68515467644, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 619416, "time": 71033.03379249573, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 619616, "time": 71055.78342843056, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 619672, "time": 71062.11685585976, "episode/length": 207.0, "episode/score": 0.3531250059604645, "episode/reward_rate": 0.004807692307692308, "episode/intrinsic_return": 0.0}
{"step": 619736, "time": 71069.38000011444, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 619840, "time": 71081.27664494514, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 620000, "time": 71099.39271759987, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 620048, "time": 71105.16903352737, "eval_episode/length": 18.0, "eval_episode/score": 0.9437500238418579, "eval_episode/reward_rate": 0.05263157894736842}
{"step": 620048, "time": 71106.34804582596, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 620048, "time": 71107.2057504654, "eval_episode/length": 136.0, "eval_episode/score": 0.574999988079071, "eval_episode/reward_rate": 0.0072992700729927005}
{"step": 620048, "time": 71107.39509558678, "eval_episode/length": 147.0, "eval_episode/score": 0.5406249761581421, "eval_episode/reward_rate": 0.006756756756756757}
{"step": 620048, "time": 71107.72037029266, "eval_episode/length": 166.0, "eval_episode/score": 0.48124998807907104, "eval_episode/reward_rate": 0.005988023952095809}
{"step": 620048, "time": 71107.94927692413, "eval_episode/length": 91.0, "eval_episode/score": 0.715624988079071, "eval_episode/reward_rate": 0.010869565217391304}
{"step": 620048, "time": 71108.42170596123, "eval_episode/length": 39.0, "eval_episode/score": 0.878125011920929, "eval_episode/reward_rate": 0.025}
{"step": 620048, "time": 71108.89660286903, "eval_episode/length": 97.0, "eval_episode/score": 0.6968749761581421, "eval_episode/reward_rate": 0.01020408163265306}
{"step": 620352, "time": 71143.56120300293, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 620592, "time": 71170.77379727364, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 621096, "time": 71228.07599925995, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 621192, "time": 71239.05437922478, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 621261, "time": 71247.7631380558, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.9534892600420948, "train/action_min": 0.0, "train/action_std": 1.494262049187264, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.006451264969987548, "train/actor_opt_grad_steps": 153830.0, "train/actor_opt_loss": -22.626377310382722, "train/adv_mag": 0.43301311951794036, "train/adv_max": 0.2005136034804392, "train/adv_mean": -0.00038072867037501314, "train/adv_min": -0.3985545190229808, "train/adv_std": 0.018562195001841954, "train/cont_avg": 0.9953802796803652, "train/cont_loss_mean": 0.01519289189847569, "train/cont_loss_std": 0.21234351823948425, "train/cont_neg_acc": 0.3098077816085531, "train/cont_neg_loss": 2.5804785604139044, "train/cont_pos_acc": 0.9998924881900282, "train/cont_pos_loss": 0.0034043440200839208, "train/cont_pred": 0.9952407743288502, "train/cont_rate": 0.9953802796803652, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.08571619121995691, "train/extr_critic_critic_opt_grad_steps": 153830.0, "train/extr_critic_critic_opt_loss": 7540.373573059361, "train/extr_critic_mag": 0.9843163903989748, "train/extr_critic_max": 0.9843163903989748, "train/extr_critic_mean": 0.8405364234697873, "train/extr_critic_min": 0.7236927252381904, "train/extr_critic_std": 0.030788225389710846, "train/extr_return_normed_mag": 0.46773196790860666, "train/extr_return_normed_max": 0.2755393211700056, "train/extr_return_normed_mean": 0.04610995601301324, "train/extr_return_normed_min": -0.33890954109087384, "train/extr_return_normed_std": 0.03636046202181409, "train/extr_return_rate": 0.9996278302310264, "train/extr_return_raw_mag": 1.0695850212280065, "train/extr_return_raw_max": 1.0695850212280065, "train/extr_return_raw_mean": 0.8401557005703721, "train/extr_return_raw_min": 0.45513615923929435, "train/extr_return_raw_std": 0.0363604619367618, "train/extr_reward_mag": 0.27983046884406104, "train/extr_reward_max": 0.27983046884406104, "train/extr_reward_mean": 0.0011640517873004862, "train/extr_reward_min": 2.721673277415097e-08, "train/extr_reward_std": 0.007579937361427434, "train/image_loss_mean": 0.0713664037622001, "train/image_loss_std": 0.09743747895915214, "train/model_loss_mean": 0.6972019620682006, "train/model_loss_std": 0.38711790495539367, "train/model_opt_grad_norm": 10.9506467466485, "train/model_opt_grad_steps": 153694.45662100456, "train/model_opt_loss": 4261.903765116653, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 6141.552511415525, "train/policy_entropy_mag": 1.3496081812741005, "train/policy_entropy_max": 1.3496081812741005, "train/policy_entropy_mean": 0.09113335367887532, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.11428935094375044, "train/policy_logprob_mag": 6.551080257380934, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09108488499846089, "train/policy_logprob_min": -6.551080257380934, "train/policy_logprob_std": 0.6297358546627166, "train/policy_randomness_mag": 0.6935614486263223, "train/policy_randomness_max": 0.6935614486263223, "train/policy_randomness_mean": 0.04683328499872935, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.05873311163015561, "train/post_ent_mag": 43.19227500811015, "train/post_ent_max": 43.19227500811015, "train/post_ent_mean": 42.39896081027375, "train/post_ent_min": 41.55710378847166, "train/post_ent_std": 0.3558786152160331, "train/prior_ent_mag": 42.66812957693997, "train/prior_ent_max": 42.66812957693997, "train/prior_ent_mean": 41.66464661898678, "train/prior_ent_min": 40.43651744546411, "train/prior_ent_std": 0.4112848202659659, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0013532385926230675, "train/reward_loss_mean": 0.010642643846235488, "train/reward_loss_std": 0.1762359150734275, "train/reward_max_data": 0.6420947491918525, "train/reward_max_pred": 0.22196836232050368, "train/reward_neg_acc": 0.9997496242936887, "train/reward_neg_loss": 0.001995206124799913, "train/reward_pos_acc": 0.1961880728903443, "train/reward_pos_loss": 3.6966080408204687, "train/reward_pred": 0.0011193475177826266, "train/reward_rate": 0.0023187785388127853, "train_stats/mean_log_entropy": 0.07289008632825132, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.014876912347972393, "report/cont_loss_std": 0.2476223260164261, "report/cont_neg_acc": 0.25, "report/cont_neg_loss": 3.2098731994628906, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.002347514731809497, "report/cont_pred": 0.9966468811035156, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07537193596363068, "report/image_loss_std": 0.106392040848732, "report/model_loss_mean": 0.7003030776977539, "report/model_loss_std": 0.4139707684516907, "report/post_ent_mag": 42.80859375, "report/post_ent_max": 42.80859375, "report/post_ent_mean": 41.926727294921875, "report/post_ent_min": 41.041160583496094, "report/post_ent_std": 0.369911253452301, "report/prior_ent_mag": 42.71241760253906, "report/prior_ent_max": 42.71241760253906, "report/prior_ent_mean": 41.73687744140625, "report/prior_ent_min": 40.681121826171875, "report/prior_ent_std": 0.3907324969768524, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0015167236560955644, "report/reward_loss_mean": 0.010054209269583225, "report/reward_loss_std": 0.19252750277519226, "report/reward_max_data": 0.7875000238418579, "report/reward_max_pred": 0.04252481460571289, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00156207790132612, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.349534034729004, "report/reward_pred": 0.0007250477792695165, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.9921875, "eval/cont_loss_mean": 0.06626663357019424, "eval/cont_loss_std": 0.7818101644515991, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 8.087067604064941, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0031107207760214806, "eval/cont_pred": 0.9969518184661865, "eval/cont_rate": 0.9921875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.1786053478717804, "eval/image_loss_std": 0.17245016992092133, "eval/model_loss_mean": 0.8684581518173218, "eval/model_loss_std": 1.0727863311767578, "eval/post_ent_mag": 42.827735900878906, "eval/post_ent_max": 42.827735900878906, "eval/post_ent_mean": 41.98273849487305, "eval/post_ent_min": 41.13470458984375, "eval/post_ent_std": 0.37045878171920776, "eval/prior_ent_mag": 42.725074768066406, "eval/prior_ent_max": 42.725074768066406, "eval/prior_ent_mean": 41.771244049072266, "eval/prior_ent_min": 40.603614807128906, "eval/prior_ent_std": 0.40116971731185913, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.001922607421875, "eval/reward_loss_mean": 0.023586157709360123, "eval/reward_loss_std": 0.4339934289455414, "eval/reward_max_data": 0.7437499761581421, "eval/reward_max_pred": 0.23290419578552246, "eval/reward_neg_acc": 0.999020516872406, "eval/reward_neg_loss": 0.0020544640719890594, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 7.351539611816406, "eval/reward_pred": 0.0009611392160877585, "eval/reward_rate": 0.0029296875, "replay/size": 620757.0, "replay/inserts": 8764.0, "replay/samples": 35056.0, "replay/insert_wait_avg": 1.501161069534838e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.845791220828204e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 1880.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 9.838570939733627e-07, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.046627044677734e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.082756280899, "timer/env.step_count": 1095.0, "timer/env.step_total": 10.82218885421753, "timer/env.step_frac": 0.010821293324227498, "timer/env.step_avg": 0.0098832774924361, "timer/env.step_min": 0.00864267349243164, "timer/env.step_max": 0.03544044494628906, "timer/replay._sample_count": 35056.0, "timer/replay._sample_total": 17.998153924942017, "timer/replay._sample_frac": 0.017996664587912135, "timer/replay._sample_avg": 0.000513411510866671, "timer/replay._sample_min": 0.0003457069396972656, "timer/replay._sample_max": 0.029999732971191406, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1330.0, "timer/agent.policy_total": 13.502311706542969, "timer/agent.policy_frac": 0.013501194397906903, "timer/agent.policy_avg": 0.010152114065069901, "timer/agent.policy_min": 0.008785486221313477, "timer/agent.policy_max": 0.03699922561645508, "timer/dataset_train_count": 2191.0, "timer/dataset_train_total": 0.3895998001098633, "timer/dataset_train_frac": 0.00038956756094736034, "timer/dataset_train_avg": 0.0001778182565540225, "timer/dataset_train_min": 9.512901306152344e-05, "timer/dataset_train_max": 0.001207590103149414, "timer/agent.train_count": 2191.0, "timer/agent.train_total": 970.9169034957886, "timer/agent.train_frac": 0.9708365606726664, "timer/agent.train_avg": 0.4431387053837465, "timer/agent.train_min": 0.4318981170654297, "timer/agent.train_max": 0.5912320613861084, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4800839424133301, "timer/agent.report_frac": 0.0004800442157393684, "timer/agent.report_avg": 0.24004197120666504, "timer/agent.report_min": 0.23361778259277344, "timer/agent.report_max": 0.24646615982055664, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9325485229492188e-05, "timer/dataset_eval_frac": 2.9323058562220993e-08, "timer/dataset_eval_avg": 2.9325485229492188e-05, "timer/dataset_eval_min": 2.9325485229492188e-05, "timer/dataset_eval_max": 2.9325485229492188e-05, "fps": 8.763149058359293}
{"step": 621296, "time": 71251.5691576004, "episode/length": 234.0, "episode/score": 0.26875001192092896, "episode/reward_rate": 0.00425531914893617, "episode/intrinsic_return": 0.0}
{"step": 621312, "time": 71253.39413547516, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 621424, "time": 71266.22613120079, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 621552, "time": 71280.77709937096, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 621648, "time": 71291.72861647606, "episode/length": 225.0, "episode/score": 0.296875, "episode/reward_rate": 0.004424778761061947, "episode/intrinsic_return": 0.0}
{"step": 621880, "time": 71317.9398598671, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 621928, "time": 71323.4952890873, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 622048, "time": 71337.07860589027, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 622392, "time": 71376.17261433601, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 622696, "time": 71411.24678683281, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 622720, "time": 71413.98576974869, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 622992, "time": 71444.91746664047, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 623408, "time": 71492.23733663559, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 623416, "time": 71493.15047121048, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 623608, "time": 71515.01525044441, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 623752, "time": 71531.43664264679, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 623864, "time": 71544.21487116814, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 623904, "time": 71548.78428673744, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 623912, "time": 71549.70228004456, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 623960, "time": 71555.19102215767, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 624136, "time": 71575.3510966301, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 624192, "time": 71581.72677278519, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 624488, "time": 71615.47752785683, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 624552, "time": 71622.80925345421, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 624712, "time": 71640.93733096123, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 624992, "time": 71672.87135100365, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 625032, "time": 71677.43912792206, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 625288, "time": 71706.84592270851, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 625304, "time": 71708.67443490028, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 625488, "time": 71729.81241321564, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 625736, "time": 71758.1162416935, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 625896, "time": 71776.2785832882, "episode/length": 248.0, "episode/score": 0.22499999403953552, "episode/reward_rate": 0.004016064257028112, "episode/intrinsic_return": 0.0}
{"step": 625952, "time": 71782.60876202583, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 626184, "time": 71809.02338981628, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 626248, "time": 71816.32075333595, "episode/length": 263.0, "episode/score": 0.17812499403953552, "episode/reward_rate": 0.003787878787878788, "episode/intrinsic_return": 0.0}
{"step": 626400, "time": 71833.65722680092, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 626656, "time": 71862.74766159058, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 626832, "time": 71882.74542951584, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 627008, "time": 71902.77400660515, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 627360, "time": 71942.70529222488, "episode/length": 233.0, "episode/score": 0.2718749940395355, "episode/reward_rate": 0.004273504273504274, "episode/intrinsic_return": 0.0}
{"step": 627592, "time": 71969.08768987656, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 627616, "time": 71971.8258318901, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 627776, "time": 71990.01238918304, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 628048, "time": 72020.89422416687, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 628384, "time": 72059.00755095482, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 628496, "time": 72071.73332262039, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 628968, "time": 72125.26737332344, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 629416, "time": 72176.23539590836, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 629632, "time": 72200.78720998764, "episode/length": 283.0, "episode/score": 0.11562500149011612, "episode/reward_rate": 0.0035211267605633804, "episode/intrinsic_return": 0.0}
{"step": 629904, "time": 72231.70185446739, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 629928, "time": 72234.42672348022, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 630032, "time": 72247.81123757362, "eval_episode/length": 95.0, "eval_episode/score": 0.703125, "eval_episode/reward_rate": 0.010416666666666666}
{"step": 630032, "time": 72248.48469471931, "eval_episode/length": 135.0, "eval_episode/score": 0.578125, "eval_episode/reward_rate": 0.007352941176470588}
{"step": 630032, "time": 72248.54066848755, "eval_episode/length": 138.0, "eval_episode/score": 0.5687500238418579, "eval_episode/reward_rate": 0.007194244604316547}
{"step": 630032, "time": 72248.99732089043, "eval_episode/length": 165.0, "eval_episode/score": 0.484375, "eval_episode/reward_rate": 0.006024096385542169}
{"step": 630032, "time": 72249.10623407364, "eval_episode/length": 171.0, "eval_episode/score": 0.46562498807907104, "eval_episode/reward_rate": 0.005813953488372093}
{"step": 630032, "time": 72249.34762811661, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 630032, "time": 72249.97265410423, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 630032, "time": 72250.94968318939, "eval_episode/length": 276.0, "eval_episode/score": 0.13750000298023224, "eval_episode/reward_rate": 0.0036101083032490976}
{"step": 630033, "time": 72251.99136400223, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.925325576573202, "train/action_min": 0.0, "train/action_std": 1.473735654190795, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.006837108728505637, "train/actor_opt_grad_steps": 156020.0, "train/actor_opt_loss": -20.260755865541224, "train/adv_mag": 0.508345921017808, "train/adv_max": 0.25521968624907543, "train/adv_mean": 0.0013998894658441747, "train/adv_min": -0.445965409551037, "train/adv_std": 0.02088146912333764, "train/cont_avg": 0.995291095890411, "train/cont_loss_mean": 0.015410357967155165, "train/cont_loss_std": 0.2124245707328393, "train/cont_neg_acc": 0.31181779245263364, "train/cont_neg_loss": 2.5289657885069454, "train/cont_pos_acc": 0.9999193570929575, "train/cont_pos_loss": 0.003399882064792051, "train/cont_pred": 0.9951732444436583, "train/cont_rate": 0.995291095890411, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.12747834942656566, "train/extr_critic_critic_opt_grad_steps": 156020.0, "train/extr_critic_critic_opt_loss": 6589.376083583048, "train/extr_critic_mag": 1.035230151050167, "train/extr_critic_max": 1.035230151050167, "train/extr_critic_mean": 0.8590134801385609, "train/extr_critic_min": 0.7479435330656565, "train/extr_critic_std": 0.031057008210416525, "train/extr_return_normed_mag": 0.55055307117227, "train/extr_return_normed_max": 0.36144702782913973, "train/extr_return_normed_mean": 0.050362117682077566, "train/extr_return_normed_min": -0.3821234523433529, "train/extr_return_normed_std": 0.0384558845634602, "train/extr_return_rate": 0.9996007795203222, "train/extr_return_raw_mag": 1.1714983119812186, "train/extr_return_raw_max": 1.1714983119812186, "train/extr_return_raw_mean": 0.8604134473626472, "train/extr_return_raw_min": 0.4279278320808933, "train/extr_return_raw_std": 0.038455884512428824, "train/extr_reward_mag": 0.3450992755149597, "train/extr_reward_max": 0.3450992755149597, "train/extr_reward_mean": 0.0012800456294481597, "train/extr_reward_min": 3.810342588381136e-09, "train/extr_reward_std": 0.008724724173282175, "train/image_loss_mean": 0.07247113567441021, "train/image_loss_std": 0.09768365881486571, "train/model_loss_mean": 0.6982568399002563, "train/model_loss_std": 0.38560608420606074, "train/model_opt_grad_norm": 11.028134256737417, "train/model_opt_grad_steps": 155882.69406392693, "train/model_opt_loss": 4322.631794689997, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 6187.214611872146, "train/policy_entropy_mag": 1.2930005914000071, "train/policy_entropy_max": 1.2930005914000071, "train/policy_entropy_mean": 0.08703307698578595, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.10278163054218031, "train/policy_logprob_mag": 6.55108026391295, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.0868230319866851, "train/policy_logprob_min": -6.55108026391295, "train/policy_logprob_std": 0.6241763005517933, "train/policy_randomness_mag": 0.6644708987784712, "train/policy_randomness_max": 0.6644708987784712, "train/policy_randomness_mean": 0.04472615925348512, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.052819312843557904, "train/post_ent_mag": 43.52258959208449, "train/post_ent_max": 43.52258959208449, "train/post_ent_mean": 42.68669687558527, "train/post_ent_min": 41.778247937764206, "train/post_ent_std": 0.375446453622487, "train/prior_ent_mag": 43.91234403984732, "train/prior_ent_max": 43.91234403984732, "train/prior_ent_mean": 42.73074980086932, "train/prior_ent_min": 41.44230244257679, "train/prior_ent_std": 0.4251169573226476, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0013748795988402843, "train/reward_loss_mean": 0.010375325104485364, "train/reward_loss_std": 0.1739855383726934, "train/reward_max_data": 0.6614297940714718, "train/reward_max_pred": 0.23166546103072494, "train/reward_neg_acc": 0.9997452064736249, "train/reward_neg_loss": 0.0019991024028930865, "train/reward_pos_acc": 0.17620232308385383, "train/reward_pos_loss": 3.7252654600795823, "train/reward_pred": 0.0011420095744478988, "train/reward_rate": 0.002287564212328767, "train_stats/mean_log_entropy": 0.07181866897964011, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.023328017443418503, "report/cont_loss_std": 0.3195188343524933, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.021919250488281, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0037256977520883083, "report/cont_pred": 0.9963284730911255, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.05266030877828598, "report/image_loss_std": 0.07432389259338379, "report/model_loss_mean": 0.6845073699951172, "report/model_loss_std": 0.43774911761283875, "report/post_ent_mag": 43.28874969482422, "report/post_ent_max": 43.28874969482422, "report/post_ent_mean": 42.43719482421875, "report/post_ent_min": 41.463191986083984, "report/post_ent_std": 0.42220285534858704, "report/prior_ent_mag": 43.29804992675781, "report/prior_ent_max": 43.29804992675781, "report/prior_ent_mean": 42.022239685058594, "report/prior_ent_min": 40.898155212402344, "report/prior_ent_std": 0.461121529340744, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0002044677676167339, "report/reward_loss_mean": 0.008519007824361324, "report/reward_loss_std": 0.1893170177936554, "report/reward_max_data": 0.20937499403953552, "report/reward_max_pred": 0.10291182994842529, "report/reward_neg_acc": 0.9990224838256836, "report/reward_neg_loss": 0.002612743992358446, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 6.050626754760742, "report/reward_pred": 0.001325986348092556, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.02472071349620819, "eval/cont_loss_std": 0.4533543586730957, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 7.249082565307617, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0034934019204229116, "eval/cont_pred": 0.9965183138847351, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.11339660733938217, "eval/image_loss_std": 0.11004926264286041, "eval/model_loss_mean": 0.7435643076896667, "eval/model_loss_std": 0.510900616645813, "eval/post_ent_mag": 43.28301239013672, "eval/post_ent_max": 43.28301239013672, "eval/post_ent_mean": 42.5185546875, "eval/post_ent_min": 41.3566780090332, "eval/post_ent_std": 0.4181610643863678, "eval/prior_ent_mag": 43.31428527832031, "eval/prior_ent_max": 43.31428527832031, "eval/prior_ent_mean": 42.173828125, "eval/prior_ent_min": 40.65932846069336, "eval/prior_ent_std": 0.5456047058105469, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0008331298595294356, "eval/reward_loss_mean": 0.005446977447718382, "eval/reward_loss_std": 0.12234745919704437, "eval/reward_max_data": 0.8531249761581421, "eval/reward_max_pred": 0.03849923610687256, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0016311687650159001, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 3.9090185165405273, "eval/reward_pred": 0.0008215587586164474, "eval/reward_rate": 0.0009765625, "replay/size": 629529.0, "replay/inserts": 8772.0, "replay/samples": 35088.0, "replay/insert_wait_avg": 1.5380607584106612e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.17735866732756e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 2216.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0118802962320376e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.301568984985352e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1004.2147738933563, "timer/env.step_count": 1097.0, "timer/env.step_total": 10.952231645584106, "timer/env.step_frac": 0.01090626420792649, "timer/env.step_avg": 0.009983802776284509, "timer/env.step_min": 0.008674383163452148, "timer/env.step_max": 0.0346980094909668, "timer/replay._sample_count": 35088.0, "timer/replay._sample_total": 18.136969327926636, "timer/replay._sample_frac": 0.018060846941744667, "timer/replay._sample_avg": 0.0005168994906499839, "timer/replay._sample_min": 0.00035691261291503906, "timer/replay._sample_max": 0.03607463836669922, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1374.0, "timer/agent.policy_total": 14.06104826927185, "timer/agent.policy_frac": 0.014002032866691402, "timer/agent.policy_avg": 0.01023365958462289, "timer/agent.policy_min": 0.008795976638793945, "timer/agent.policy_max": 0.052963972091674805, "timer/dataset_train_count": 2193.0, "timer/dataset_train_total": 0.39495086669921875, "timer/dataset_train_frac": 0.00039329322468338926, "timer/dataset_train_avg": 0.0001800961544456082, "timer/dataset_train_min": 9.72747802734375e-05, "timer/dataset_train_max": 0.0012805461883544922, "timer/agent.train_count": 2193.0, "timer/agent.train_total": 974.0160510540009, "timer/agent.train_frac": 0.9699280237411022, "timer/agent.train_avg": 0.4441477660984956, "timer/agent.train_min": 0.43427443504333496, "timer/agent.train_max": 0.5742130279541016, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4780406951904297, "timer/agent.report_frac": 0.0004760343181738489, "timer/agent.report_avg": 0.23902034759521484, "timer/agent.report_min": 0.23029184341430664, "timer/agent.report_max": 0.24774885177612305, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8133392333984375e-05, "timer/dataset_eval_frac": 2.801531411941967e-08, "timer/dataset_eval_avg": 2.8133392333984375e-05, "timer/dataset_eval_min": 2.8133392333984375e-05, "timer/dataset_eval_max": 2.8133392333984375e-05, "fps": 8.735059640241749}
{"step": 630088, "time": 72258.02271962166, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 630120, "time": 72261.64187026024, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 630360, "time": 72289.00670528412, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 630360, "time": 72289.01557517052, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 630696, "time": 72327.18538951874, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 631000, "time": 72361.88551831245, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 631056, "time": 72368.20313191414, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 631152, "time": 72379.18906354904, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 631488, "time": 72417.40111851692, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 631728, "time": 72444.67565965652, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 631976, "time": 72472.88655781746, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 631992, "time": 72474.6993625164, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 632008, "time": 72476.53893065453, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 632056, "time": 72482.00203466415, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 632232, "time": 72502.14669895172, "episode/length": 233.0, "episode/score": 0.2718749940395355, "episode/reward_rate": 0.004273504273504274, "episode/intrinsic_return": 0.0}
{"step": 632272, "time": 72506.7074534893, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 632432, "time": 72524.95407938957, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 632672, "time": 72552.38638830185, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 632904, "time": 72578.64544439316, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 633152, "time": 72606.70175814629, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 633168, "time": 72608.52884459496, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 633192, "time": 72611.30286026001, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 633296, "time": 72623.10931992531, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 633352, "time": 72629.42953252792, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 633824, "time": 72683.03554368019, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 633928, "time": 72694.82742118835, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 634320, "time": 72739.34299898148, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 634328, "time": 72740.24821090698, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 634584, "time": 72769.32936692238, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 634984, "time": 72814.82999825478, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 635480, "time": 72871.31706500053, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 635664, "time": 72892.26911330223, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 636136, "time": 72945.90070557594, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 636240, "time": 72957.70844817162, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 636632, "time": 73002.19174671173, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 636640, "time": 73003.12780547142, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 636896, "time": 73032.05785179138, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 637296, "time": 73077.33834862709, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 637792, "time": 73133.56664133072, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 637976, "time": 73154.46991658211, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 638448, "time": 73207.94069218636, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 638552, "time": 73219.80958676338, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 638829, "time": 73252.2048945427, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.327043568004261, "train/action_min": 0.0, "train/action_std": 1.5350886111909694, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.014389737756838175, "train/actor_opt_grad_steps": 158215.0, "train/actor_opt_loss": -17.73718254999681, "train/adv_mag": 0.6212020809000188, "train/adv_max": 0.29662406878037884, "train/adv_mean": 0.0038157991009794305, "train/adv_min": -0.5738031896677884, "train/adv_std": 0.03739768335468729, "train/cont_avg": 0.9952547940340909, "train/cont_loss_mean": 0.015887861895713618, "train/cont_loss_std": 0.22070987426083197, "train/cont_neg_acc": 0.2983209519013422, "train/cont_neg_loss": 2.6681624645118487, "train/cont_pos_acc": 0.9998974117365751, "train/cont_pos_loss": 0.0033202475825832647, "train/cont_pred": 0.9953045842322437, "train/cont_rate": 0.9952547940340909, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.24579698345200582, "train/extr_critic_critic_opt_grad_steps": 158215.0, "train/extr_critic_critic_opt_loss": 9701.5771484375, "train/extr_critic_mag": 1.1469124095006422, "train/extr_critic_max": 1.1469124095006422, "train/extr_critic_mean": 0.9642516282471744, "train/extr_critic_min": 0.838884302702817, "train/extr_critic_std": 0.0375225271563977, "train/extr_return_normed_mag": 0.6349949565800753, "train/extr_return_normed_max": 0.4151522882960059, "train/extr_return_normed_mean": 0.07704628010873091, "train/extr_return_normed_min": -0.4847645770419728, "train/extr_return_normed_std": 0.05534369877793572, "train/extr_return_rate": 0.9994152746417305, "train/extr_return_raw_mag": 1.3061734576116908, "train/extr_return_raw_max": 1.3061734576116908, "train/extr_return_raw_mean": 0.968067495118488, "train/extr_return_raw_min": 0.40625659227371214, "train/extr_return_raw_std": 0.05534369856203822, "train/extr_reward_mag": 0.41064894524487583, "train/extr_reward_max": 0.41064894524487583, "train/extr_reward_mean": 0.0025269611082132377, "train/extr_reward_min": -1.4684417031028055e-07, "train/extr_reward_std": 0.017837647470349275, "train/image_loss_mean": 0.07099667035720565, "train/image_loss_std": 0.09716747306625952, "train/model_loss_mean": 0.6973406168547543, "train/model_loss_std": 0.3912406703287905, "train/model_opt_grad_norm": 10.979719985615123, "train/model_opt_grad_steps": 158076.56363636363, "train/model_opt_loss": 4934.502947443182, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 7068.181818181818, "train/policy_entropy_mag": 1.2562194049358368, "train/policy_entropy_max": 1.2562194049358368, "train/policy_entropy_mean": 0.08788499540903351, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.10039365643804724, "train/policy_logprob_mag": 6.551080294088884, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.0871606392447244, "train/policy_logprob_min": -6.551080294088884, "train/policy_logprob_std": 0.6221669877117331, "train/policy_randomness_mag": 0.645569108562036, "train/policy_randomness_max": 0.645569108562036, "train/policy_randomness_mean": 0.04516395836729895, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.051592136555435986, "train/post_ent_mag": 42.96720577586781, "train/post_ent_max": 42.96720577586781, "train/post_ent_mean": 41.99431303197687, "train/post_ent_min": 40.93628531369296, "train/post_ent_std": 0.4402358563108878, "train/prior_ent_mag": 43.18105827678334, "train/prior_ent_max": 43.18105827678334, "train/prior_ent_mean": 41.84924682270397, "train/prior_ent_min": 40.53703762401234, "train/prior_ent_std": 0.47442834905602715, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.001350499935969393, "train/reward_loss_mean": 0.010456064028072764, "train/reward_loss_std": 0.17548108167777007, "train/reward_max_data": 0.6408664773810994, "train/reward_max_pred": 0.22545354908162898, "train/reward_neg_acc": 0.999817558852109, "train/reward_neg_loss": 0.001913678488926962, "train/reward_pos_acc": 0.17317857302725315, "train/reward_pos_loss": 3.729925956726074, "train/reward_pred": 0.001101272212955254, "train/reward_rate": 0.0023037997159090907, "train_stats/mean_log_entropy": 0.07714766299440748, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 0.03400350734591484, "report/cont_loss_std": 0.4120620787143707, "report/cont_neg_acc": 0.25, "report/cont_neg_loss": 3.908644676208496, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.003494526958093047, "report/cont_pred": 0.9945621490478516, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.09590445458889008, "report/image_loss_std": 0.10522737354040146, "report/model_loss_mean": 0.7413634657859802, "report/model_loss_std": 0.544026255607605, "report/post_ent_mag": 43.05096435546875, "report/post_ent_max": 43.05096435546875, "report/post_ent_mean": 42.08819580078125, "report/post_ent_min": 40.939544677734375, "report/post_ent_std": 0.49806588888168335, "report/prior_ent_mag": 42.4134635925293, "report/prior_ent_max": 42.4134635925293, "report/prior_ent_mean": 41.22785186767578, "report/prior_ent_min": 39.99292755126953, "report/prior_ent_std": 0.4532011151313782, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0006988525856286287, "report/reward_loss_mean": 0.01145547442138195, "report/reward_loss_std": 0.21213728189468384, "report/reward_max_data": 0.4468750059604645, "report/reward_max_pred": 0.038308143615722656, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.002096091629937291, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.794099807739258, "report/reward_pred": 0.0009783158311620355, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.9931640625, "eval/cont_loss_mean": 0.04718194156885147, "eval/cont_loss_std": 0.5664315819740295, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.808819770812988, "eval/cont_pos_acc": 0.9990166425704956, "eval/cont_pos_loss": 0.007524651009589434, "eval/cont_pred": 0.9947477579116821, "eval/cont_rate": 0.9931640625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.1274532973766327, "eval/image_loss_std": 0.1641666144132614, "eval/model_loss_mean": 0.8096849918365479, "eval/model_loss_std": 1.0497170686721802, "eval/post_ent_mag": 43.10487365722656, "eval/post_ent_max": 43.10487365722656, "eval/post_ent_mean": 42.11866760253906, "eval/post_ent_min": 40.97008514404297, "eval/post_ent_std": 0.4830094277858734, "eval/prior_ent_mag": 42.706565856933594, "eval/prior_ent_max": 42.706565856933594, "eval/prior_ent_mean": 41.20902633666992, "eval/prior_ent_min": 39.92530059814453, "eval/prior_ent_std": 0.48261725902557373, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.002859497210010886, "eval/reward_loss_mean": 0.035049714148044586, "eval/reward_loss_std": 0.5120320320129395, "eval/reward_max_data": 0.7406250238418579, "eval/reward_max_pred": 0.4495898485183716, "eval/reward_neg_acc": 0.999018669128418, "eval/reward_neg_loss": 0.005290689412504435, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 6.099938869476318, "eval/reward_pred": 0.0015003615990281105, "eval/reward_rate": 0.0048828125, "replay/size": 638325.0, "replay/inserts": 8796.0, "replay/samples": 35184.0, "replay/insert_wait_avg": 1.5355717761780034e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.099159851351777e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 6.854534149169922e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2006976604462, "timer/env.step_count": 1099.0, "timer/env.step_total": 10.727907657623291, "timer/env.step_frac": 0.010725755023683519, "timer/env.step_avg": 0.009761517431868327, "timer/env.step_min": 0.008654594421386719, "timer/env.step_max": 0.03476142883300781, "timer/replay._sample_count": 35184.0, "timer/replay._sample_total": 17.99176836013794, "timer/replay._sample_frac": 0.017988158178875703, "timer/replay._sample_avg": 0.000511362220331342, "timer/replay._sample_min": 0.0003628730773925781, "timer/replay._sample_max": 0.02860879898071289, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1099.0, "timer/agent.policy_total": 11.31952714920044, "timer/agent.policy_frac": 0.01131725580243822, "timer/agent.policy_avg": 0.010299842719927607, "timer/agent.policy_min": 0.009342670440673828, "timer/agent.policy_max": 0.0352175235748291, "timer/dataset_train_count": 2199.0, "timer/dataset_train_total": 0.39073777198791504, "timer/dataset_train_frac": 0.000390659367566813, "timer/dataset_train_avg": 0.00017768884583352208, "timer/dataset_train_min": 9.655952453613281e-05, "timer/dataset_train_max": 0.0009620189666748047, "timer/agent.train_count": 2199.0, "timer/agent.train_total": 975.1980109214783, "timer/agent.train_frac": 0.9750023302348706, "timer/agent.train_avg": 0.4434734019652016, "timer/agent.train_min": 0.43263936042785645, "timer/agent.train_max": 0.593698263168335, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4776906967163086, "timer/agent.report_frac": 0.0004775948445483666, "timer/agent.report_avg": 0.2388453483581543, "timer/agent.report_min": 0.23247671127319336, "timer/agent.report_max": 0.24521398544311523, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.266334533691406e-05, "timer/dataset_eval_frac": 3.2656791195323484e-08, "timer/dataset_eval_avg": 3.266334533691406e-05, "timer/dataset_eval_min": 3.266334533691406e-05, "timer/dataset_eval_max": 3.266334533691406e-05, "fps": 8.794104898724639}
{"step": 638944, "time": 73265.06920862198, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 638952, "time": 73265.98005747795, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 639208, "time": 73295.43656754494, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 639608, "time": 73340.8155863285, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 640016, "time": 73392.08998131752, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 640016, "time": 73392.09785676003, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 640016, "time": 73392.10340309143, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 640016, "time": 73392.10883522034, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 640016, "time": 73392.11381435394, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 640016, "time": 73392.11951255798, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 640016, "time": 73392.12465429306, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 640016, "time": 73392.12956428528, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 640104, "time": 73402.08500480652, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 640288, "time": 73423.06527328491, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 640760, "time": 73476.59432506561, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 640864, "time": 73488.50121307373, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 641256, "time": 73532.96572422981, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 641264, "time": 73533.87804198265, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 641520, "time": 73563.04262185097, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 641920, "time": 73608.48717665672, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 642416, "time": 73664.71901988983, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 642600, "time": 73685.57939529419, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 643072, "time": 73739.11640620232, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 643176, "time": 73750.95379662514, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 643448, "time": 73781.87393379211, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 643568, "time": 73795.4601085186, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 643576, "time": 73796.37471699715, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 643832, "time": 73825.39793372154, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 644232, "time": 73870.64464616776, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 644464, "time": 73896.98558712006, "episode/length": 255.0, "episode/score": 0.203125, "episode/reward_rate": 0.00390625, "episode/intrinsic_return": 0.0}
{"step": 645008, "time": 73958.55913376808, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 645096, "time": 73968.55647134781, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 645120, "time": 73971.28254032135, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 645160, "time": 73975.81837391853, "episode/length": 197.0, "episode/score": 0.3843750059604645, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.0}
{"step": 645384, "time": 74001.21770954132, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 645488, "time": 74012.99022650719, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 645704, "time": 74037.52109074593, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 645760, "time": 74043.87992095947, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 645824, "time": 74051.21538686752, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 645928, "time": 74062.96160507202, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 646104, "time": 74082.94949412346, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 646384, "time": 74114.63812613487, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 646472, "time": 74124.5883204937, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 646496, "time": 74127.31259918213, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 646680, "time": 74148.17524075508, "episode/length": 276.0, "episode/score": 0.13750000298023224, "episode/reward_rate": 0.0036101083032490976, "episode/intrinsic_return": 0.0}
{"step": 647589, "time": 74252.2824742794, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.4026263511344177, "train/action_min": 0.0, "train/action_std": 1.6094666626899754, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.008273647587265837, "train/actor_opt_grad_steps": 160410.0, "train/actor_opt_loss": -20.600723007498267, "train/adv_mag": 0.5135433624868524, "train/adv_max": 0.21829518580545573, "train/adv_mean": -0.0026166788582644147, "train/adv_min": -0.4714783081725308, "train/adv_std": 0.022062434444892896, "train/cont_avg": 0.9954427083333334, "train/cont_loss_mean": 0.015736664129744313, "train/cont_loss_std": 0.21768198056001914, "train/cont_neg_acc": 0.27754114417854797, "train/cont_neg_loss": 2.7436536181720914, "train/cont_pos_acc": 0.9999014612746565, "train/cont_pos_loss": 0.0034126628304036446, "train/cont_pred": 0.9953423202309979, "train/cont_rate": 0.9954427083333334, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.1075499955369117, "train/extr_critic_critic_opt_grad_steps": 160410.0, "train/extr_critic_critic_opt_loss": 7404.408884266196, "train/extr_critic_mag": 1.0436784012676918, "train/extr_critic_max": 1.0436784012676918, "train/extr_critic_mean": 0.8813992284204317, "train/extr_critic_min": 0.7653139143773954, "train/extr_critic_std": 0.0322625493783861, "train/extr_return_normed_mag": 0.5393118245960915, "train/extr_return_normed_max": 0.3059152100728527, "train/extr_return_normed_mean": 0.03885393262775424, "train/extr_return_normed_min": -0.41824429247477285, "train/extr_return_normed_std": 0.04068008488784098, "train/extr_return_rate": 0.9995139769223182, "train/extr_return_raw_mag": 1.1458438082372762, "train/extr_return_raw_max": 1.1458438082372762, "train/extr_return_raw_mean": 0.8787825758054376, "train/extr_return_raw_min": 0.4216843056896506, "train/extr_return_raw_std": 0.040680084828304375, "train/extr_reward_mag": 0.3098401076173129, "train/extr_reward_max": 0.3098401076173129, "train/extr_reward_mean": 0.0010777383246172016, "train/extr_reward_min": -1.68743743199736e-08, "train/extr_reward_std": 0.008470128300986741, "train/image_loss_mean": 0.07236323216462244, "train/image_loss_std": 0.09686757219300422, "train/model_loss_mean": 0.6982348787185808, "train/model_loss_std": 0.3810048782049793, "train/model_opt_grad_norm": 11.142375453966393, "train/model_opt_grad_steps": 160270.21461187216, "train/model_opt_loss": 5322.33465548302, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 7625.570776255708, "train/policy_entropy_mag": 1.282414824178774, "train/policy_entropy_max": 1.282414824178774, "train/policy_entropy_mean": 0.08497620894484324, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.09554068703357488, "train/policy_logprob_mag": 6.551080276976982, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.08500684685494801, "train/policy_logprob_min": -6.551080276976982, "train/policy_logprob_std": 0.6234663417350211, "train/policy_randomness_mag": 0.6590308903559158, "train/policy_randomness_max": 0.6590308903559158, "train/policy_randomness_mean": 0.04366913861403727, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.04909820374968934, "train/post_ent_mag": 43.21207736289664, "train/post_ent_max": 43.21207736289664, "train/post_ent_mean": 42.29975972981214, "train/post_ent_min": 41.297723256289686, "train/post_ent_std": 0.41817689649590617, "train/prior_ent_mag": 42.48218548570049, "train/prior_ent_max": 42.48218548570049, "train/prior_ent_mean": 41.09693866886505, "train/prior_ent_min": 39.87945849274936, "train/prior_ent_std": 0.46880083201138395, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0013176765548106237, "train/reward_loss_mean": 0.010134958098621265, "train/reward_loss_std": 0.16849130060370654, "train/reward_max_data": 0.6325913227107971, "train/reward_max_pred": 0.22106996028934983, "train/reward_neg_acc": 0.9998032877978669, "train/reward_neg_loss": 0.0019363082882089193, "train/reward_pos_acc": 0.19634353909261373, "train/reward_pos_loss": 3.666142692067185, "train/reward_pred": 0.0010954935771315337, "train/reward_rate": 0.0022295947488584476, "train_stats/mean_log_entropy": 0.07496612720392845, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.00967259518802166, "report/cont_loss_std": 0.2056676149368286, "report/cont_neg_acc": 0.5, "report/cont_neg_loss": 3.285923719406128, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0032611466012895107, "report/cont_pred": 0.9958683252334595, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.06832337379455566, "report/image_loss_std": 0.09578289091587067, "report/model_loss_mean": 0.6797640323638916, "report/model_loss_std": 0.22574105858802795, "report/post_ent_mag": 43.10079574584961, "report/post_ent_max": 43.10079574584961, "report/post_ent_mean": 42.167510986328125, "report/post_ent_min": 40.95122528076172, "report/post_ent_std": 0.4162609577178955, "report/prior_ent_mag": 42.354591369628906, "report/prior_ent_max": 42.354591369628906, "report/prior_ent_mean": 40.96514129638672, "report/prior_ent_min": 39.90407943725586, "report/prior_ent_std": 0.440416544675827, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.0017680751625448465, "report/reward_loss_std": 0.008898737840354443, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.043808817863464355, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0017680751625448465, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.000805067946203053, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.033005353063344955, "eval/cont_loss_std": 0.5634708404541016, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 10.060548782348633, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0035414663143455982, "eval/cont_pred": 0.9967775344848633, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.1595878005027771, "eval/image_loss_std": 0.17450343072414398, "eval/model_loss_mean": 0.7939110398292542, "eval/model_loss_std": 0.5861085057258606, "eval/post_ent_mag": 43.11329650878906, "eval/post_ent_max": 43.11329650878906, "eval/post_ent_mean": 42.118446350097656, "eval/post_ent_min": 41.19097137451172, "eval/post_ent_std": 0.437069833278656, "eval/prior_ent_mag": 42.44256591796875, "eval/prior_ent_max": 42.44256591796875, "eval/prior_ent_mean": 40.856719970703125, "eval/prior_ent_min": 39.58134078979492, "eval/prior_ent_std": 0.5024345517158508, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0013178857043385506, "eval/reward_loss_std": 0.009079212322831154, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.05655527114868164, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0013178857043385506, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0005536953685805202, "eval/reward_rate": 0.0, "replay/size": 647085.0, "replay/inserts": 8760.0, "replay/samples": 35040.0, "replay/insert_wait_avg": 1.563002529753942e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.930139428404368e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 9.975012610940372e-07, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.450580596923828e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.059623003006, "timer/env.step_count": 1095.0, "timer/env.step_total": 10.808798789978027, "timer/env.step_frac": 0.010808154375357216, "timer/env.step_avg": 0.009871049123267604, "timer/env.step_min": 0.008620262145996094, "timer/env.step_max": 0.035024166107177734, "timer/replay._sample_count": 35040.0, "timer/replay._sample_total": 18.13231372833252, "timer/replay._sample_frac": 0.018131232689791353, "timer/replay._sample_avg": 0.0005174747068588048, "timer/replay._sample_min": 0.00038886070251464844, "timer/replay._sample_max": 0.029619216918945312, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1384.0, "timer/agent.policy_total": 14.072631597518921, "timer/agent.policy_frac": 0.01407179259498673, "timer/agent.policy_avg": 0.010168086414392284, "timer/agent.policy_min": 0.008777141571044922, "timer/agent.policy_max": 0.041414737701416016, "timer/dataset_train_count": 2190.0, "timer/dataset_train_total": 0.3894522190093994, "timer/dataset_train_frac": 0.00038942900008295686, "timer/dataset_train_avg": 0.0001778320634746116, "timer/dataset_train_min": 9.584426879882812e-05, "timer/dataset_train_max": 0.0012061595916748047, "timer/agent.train_count": 2190.0, "timer/agent.train_total": 969.8607676029205, "timer/agent.train_frac": 0.9698029450390132, "timer/agent.train_avg": 0.4428587979922012, "timer/agent.train_min": 0.4340686798095703, "timer/agent.train_max": 0.5851712226867676, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4739656448364258, "timer/agent.report_frac": 0.0004739373872661602, "timer/agent.report_avg": 0.2369828224182129, "timer/agent.report_min": 0.2312793731689453, "timer/agent.report_max": 0.24268627166748047, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.123283386230469e-05, "timer/dataset_eval_frac": 3.123097177798049e-08, "timer/dataset_eval_avg": 3.123283386230469e-05, "timer/dataset_eval_min": 3.123283386230469e-05, "timer/dataset_eval_max": 3.123283386230469e-05, "fps": 8.759361391935187}
{"step": 647800, "time": 74276.0837135315, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 647872, "time": 74284.20934796333, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 648016, "time": 74300.5935511589, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 648072, "time": 74306.9373216629, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 648416, "time": 74345.93672132492, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 648512, "time": 74356.85397481918, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 648664, "time": 74374.04905080795, "episode/length": 273.0, "episode/score": 0.14687499403953552, "episode/reward_rate": 0.0036496350364963502, "episode/intrinsic_return": 0.0}
{"step": 648808, "time": 74390.45046591759, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 648992, "time": 74411.32010793686, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 649104, "time": 74424.01690983772, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 649624, "time": 74483.09791350365, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 649632, "time": 74484.01011753082, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.0}
{"step": 650000, "time": 74527.09716296196, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 650000, "time": 74528.39463853836, "eval_episode/length": 148.0, "eval_episode/score": 0.5375000238418579, "eval_episode/reward_rate": 0.006711409395973154}
{"step": 650000, "time": 74528.60742735863, "eval_episode/length": 160.0, "eval_episode/score": 0.5, "eval_episode/reward_rate": 0.006211180124223602}
{"step": 650000, "time": 74529.22357225418, "eval_episode/length": 195.0, "eval_episode/score": 0.390625, "eval_episode/reward_rate": 0.00510204081632653}
{"step": 650000, "time": 74529.55501389503, "eval_episode/length": 214.0, "eval_episode/score": 0.33125001192092896, "eval_episode/reward_rate": 0.004651162790697674}
{"step": 650000, "time": 74531.39789247513, "eval_episode/length": 277.0, "eval_episode/score": 0.13437500596046448, "eval_episode/reward_rate": 0.0035971223021582736}
{"step": 650000, "time": 74531.59388899803, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 650000, "time": 74531.6001317501, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 650112, "time": 74544.2835085392, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 650384, "time": 74575.15595531464, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 650728, "time": 74614.16328144073, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 650800, "time": 74622.39528012276, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 650976, "time": 74642.3071513176, "episode/length": 21.0, "episode/score": 0.934374988079071, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.0}
{"step": 651120, "time": 74658.65082502365, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 651304, "time": 74679.44532775879, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 651416, "time": 74692.1841404438, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 651688, "time": 74723.02726745605, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.0}
{"step": 651936, "time": 74751.18262887001, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 652616, "time": 74828.24275565147, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.0}
{"step": 652696, "time": 74837.37910795212, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 653040, "time": 74876.36582374573, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 653104, "time": 74883.59257388115, "episode/length": 210.0, "episode/score": 0.34375, "episode/reward_rate": 0.004739336492890996, "episode/intrinsic_return": 0.0}
{"step": 653200, "time": 74894.54087376595, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 653296, "time": 74905.4100060463, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 653432, "time": 74920.78101801872, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 653520, "time": 74930.81890153885, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 653576, "time": 74937.14588618279, "episode/length": 283.0, "episode/score": 0.11562500149011612, "episode/reward_rate": 0.0035211267605633804, "episode/intrinsic_return": 0.0}
{"step": 654264, "time": 75015.11501836777, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 654272, "time": 75016.02742743492, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 654456, "time": 75036.84833455086, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 654504, "time": 75042.32940864563, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 654640, "time": 75057.68803477287, "episode/length": 242.0, "episode/score": 0.24375000596046448, "episode/reward_rate": 0.00411522633744856, "episode/intrinsic_return": 0.0}
{"step": 655016, "time": 75100.19409370422, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 655136, "time": 75113.87367391586, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.0}
{"step": 655360, "time": 75139.51069068909, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 655416, "time": 75145.9098880291, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 655744, "time": 75183.04109454155, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 655992, "time": 75211.1426832676, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 656349, "time": 75252.62598061562, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.766753453642266, "train/action_min": 0.0, "train/action_std": 1.504530731401487, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.006954948074443768, "train/actor_opt_grad_steps": 162600.0, "train/actor_opt_loss": -26.032006446629353, "train/adv_mag": 0.4544518592695123, "train/adv_max": 0.22460491472183297, "train/adv_mean": 0.0005596385007510805, "train/adv_min": -0.4184621904538647, "train/adv_std": 0.023443117252972028, "train/cont_avg": 0.9953669021118722, "train/cont_loss_mean": 0.015394886564378325, "train/cont_loss_std": 0.21170971897690127, "train/cont_neg_acc": 0.3096148296165357, "train/cont_neg_loss": 2.547981834565364, "train/cont_pos_acc": 0.9999015034605924, "train/cont_pos_loss": 0.003427975429923669, "train/cont_pred": 0.9952359588723204, "train/cont_rate": 0.9953669021118722, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.11749835639817802, "train/extr_critic_critic_opt_grad_steps": 162600.0, "train/extr_critic_critic_opt_loss": 7679.723483429651, "train/extr_critic_mag": 1.0781530370451, "train/extr_critic_max": 1.0781530370451, "train/extr_critic_mean": 0.9034652592928987, "train/extr_critic_min": 0.771913065213591, "train/extr_critic_std": 0.03995764089671716, "train/extr_return_normed_mag": 0.49020566923977577, "train/extr_return_normed_max": 0.330987115156705, "train/extr_return_normed_mean": 0.05947834103619127, "train/extr_return_normed_min": -0.3335164657466488, "train/extr_return_normed_std": 0.04683439550096314, "train/extr_return_rate": 0.9995695624721649, "train/extr_return_raw_mag": 1.1755336449570852, "train/extr_return_raw_max": 1.1755336449570852, "train/extr_return_raw_mean": 0.9040249147915949, "train/extr_return_raw_min": 0.5110300640537314, "train/extr_return_raw_std": 0.04683439554348928, "train/extr_reward_mag": 0.3415171196471611, "train/extr_reward_max": 0.3415171196471611, "train/extr_reward_mean": 0.00114445112216112, "train/extr_reward_min": -2.667239811866795e-08, "train/extr_reward_std": 0.008868175104779264, "train/image_loss_mean": 0.07252293015451736, "train/image_loss_std": 0.0974972996877753, "train/model_loss_mean": 0.6981563323164639, "train/model_loss_std": 0.37741894798872133, "train/model_opt_grad_norm": 10.705246744634898, "train/model_opt_grad_steps": 162458.77625570775, "train/model_opt_loss": 4113.037030224386, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5890.41095890411, "train/policy_entropy_mag": 1.2645780011399153, "train/policy_entropy_max": 1.2645780011399153, "train/policy_entropy_mean": 0.09214203032456576, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.1124876386838961, "train/policy_logprob_mag": 6.551080292218352, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.0924745900513919, "train/policy_logprob_min": -6.551080292218352, "train/policy_logprob_std": 0.6318932534897164, "train/policy_randomness_mag": 0.6498645764507659, "train/policy_randomness_max": 0.6498645764507659, "train/policy_randomness_mean": 0.04735164175907226, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.057807214796270955, "train/post_ent_mag": 43.208057856450885, "train/post_ent_max": 43.208057856450885, "train/post_ent_mean": 42.32974250131546, "train/post_ent_min": 41.39030946008691, "train/post_ent_std": 0.39557525093696977, "train/prior_ent_mag": 42.973173202444976, "train/prior_ent_max": 42.973173202444976, "train/prior_ent_mean": 41.853526424599565, "train/prior_ent_min": 40.67221546608563, "train/prior_ent_std": 0.4100871916230955, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0013351649511472608, "train/reward_loss_mean": 0.010238492936874021, "train/reward_loss_std": 0.16628338532526574, "train/reward_max_data": 0.6218179236400073, "train/reward_max_pred": 0.22260818252824757, "train/reward_neg_acc": 0.9997720478876541, "train/reward_neg_loss": 0.0019627165952463502, "train/reward_pos_acc": 0.1967078203325549, "train/reward_pos_loss": 3.5905534366451244, "train/reward_pred": 0.0010956147596342105, "train/reward_rate": 0.002300941780821918, "train_stats/mean_log_entropy": 0.0839209637294213, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.030230339616537094, "report/cont_loss_std": 0.38690924644470215, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 4.6950578689575195, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0027362678665667772, "report/cont_pred": 0.997185468673706, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.06357849389314651, "report/image_loss_std": 0.09970208257436752, "report/model_loss_mean": 0.7143315672874451, "report/model_loss_std": 0.6719918847084045, "report/post_ent_mag": 42.85139465332031, "report/post_ent_max": 42.85139465332031, "report/post_ent_mean": 41.93080520629883, "report/post_ent_min": 41.03498077392578, "report/post_ent_std": 0.40372899174690247, "report/prior_ent_mag": 43.225059509277344, "report/prior_ent_max": 43.225059509277344, "report/prior_ent_mean": 42.207122802734375, "report/prior_ent_min": 41.06604766845703, "report/prior_ent_std": 0.40861865878105164, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.002899169921875, "report/reward_loss_mean": 0.0205227080732584, "report/reward_loss_std": 0.32015129923820496, "report/reward_max_data": 0.921875, "report/reward_max_pred": 0.04030489921569824, "report/reward_neg_acc": 0.9999999403953552, "report/reward_neg_loss": 0.001647932338528335, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.833590984344482, "report/reward_pred": 0.0008499984396621585, "report/reward_rate": 0.00390625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.028009682893753052, "eval/cont_loss_std": 0.42301714420318604, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.256969451904297, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.0035823879297822714, "eval/cont_pred": 0.9963928461074829, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.1241610050201416, "eval/image_loss_std": 0.12697263062000275, "eval/model_loss_mean": 0.7808194756507874, "eval/model_loss_std": 0.8983766436576843, "eval/post_ent_mag": 42.87010192871094, "eval/post_ent_max": 42.87010192871094, "eval/post_ent_mean": 42.01941680908203, "eval/post_ent_min": 41.11435317993164, "eval/post_ent_std": 0.401328980922699, "eval/prior_ent_mag": 43.51667785644531, "eval/prior_ent_max": 43.51667785644531, "eval/prior_ent_mean": 42.242515563964844, "eval/prior_ent_min": 40.91094970703125, "eval/prior_ent_std": 0.40495461225509644, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.002230835147202015, "eval/reward_loss_mean": 0.028648782521486282, "eval/reward_loss_std": 0.48651015758514404, "eval/reward_max_data": 0.8812500238418579, "eval/reward_max_pred": 0.14844155311584473, "eval/reward_neg_acc": 0.999020516872406, "eval/reward_neg_loss": 0.002349804388359189, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 8.979066848754883, "eval/reward_pred": 0.0011186369229108095, "eval/reward_rate": 0.0029296875, "replay/size": 655845.0, "replay/inserts": 8760.0, "replay/samples": 35040.0, "replay/insert_wait_avg": 1.5332274240990208e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.109282767935975e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0641182170194737e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.450580596923828e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3336732387543, "timer/env.step_count": 1095.0, "timer/env.step_total": 10.689340114593506, "timer/env.step_frac": 0.010685774557588278, "timer/env.step_avg": 0.009761954442551147, "timer/env.step_min": 0.00854635238647461, "timer/env.step_max": 0.03493618965148926, "timer/replay._sample_count": 35040.0, "timer/replay._sample_total": 18.15170645713806, "timer/replay._sample_frac": 0.018145651738753085, "timer/replay._sample_avg": 0.000518028152315584, "timer/replay._sample_min": 0.00040721893310546875, "timer/replay._sample_max": 0.03206157684326172, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1384.0, "timer/agent.policy_total": 14.539890050888062, "timer/agent.policy_frac": 0.014535040096983478, "timer/agent.policy_avg": 0.010505700903820853, "timer/agent.policy_min": 0.008867979049682617, "timer/agent.policy_max": 0.10528564453125, "timer/dataset_train_count": 2190.0, "timer/dataset_train_total": 0.39074254035949707, "timer/dataset_train_frac": 0.00039061220352045145, "timer/dataset_train_avg": 0.00017842125130570642, "timer/dataset_train_min": 9.703636169433594e-05, "timer/dataset_train_max": 0.0006625652313232422, "timer/agent.train_count": 2190.0, "timer/agent.train_total": 969.7037620544434, "timer/agent.train_frac": 0.9693803057882264, "timer/agent.train_avg": 0.442787105960933, "timer/agent.train_min": 0.43309807777404785, "timer/agent.train_max": 0.58467698097229, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47487473487854004, "timer/agent.report_frac": 0.0004747163347416372, "timer/agent.report_avg": 0.23743736743927002, "timer/agent.report_min": 0.23186850547790527, "timer/agent.report_max": 0.24300622940063477, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8133392333984375e-05, "timer/dataset_eval_frac": 2.812400810511319e-08, "timer/dataset_eval_avg": 2.8133392333984375e-05, "timer/dataset_eval_min": 2.8133392333984375e-05, "timer/dataset_eval_max": 2.8133392333984375e-05, "fps": 8.756960619560887}
{"step": 656480, "time": 75267.23987841606, "episode/length": 229.0, "episode/score": 0.28437501192092896, "episode/reward_rate": 0.004347826086956522, "episode/intrinsic_return": 0.0}
{"step": 656576, "time": 75278.02921509743, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 656768, "time": 75299.70534133911, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 656776, "time": 75300.60605049133, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 656880, "time": 75312.37372040749, "episode/length": 217.0, "episode/score": 0.3218750059604645, "episode/reward_rate": 0.0045871559633027525, "episode/intrinsic_return": 0.0}
{"step": 657328, "time": 75362.90800952911, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 657672, "time": 75401.83384895325, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 657728, "time": 75408.15903663635, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 658000, "time": 75438.90253806114, "episode/length": 281.0, "episode/score": 0.12187500298023224, "episode/reward_rate": 0.0035460992907801418, "episode/intrinsic_return": 0.0}
{"step": 658304, "time": 75473.1613752842, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 658328, "time": 75475.87837982178, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 658472, "time": 75492.17287325859, "episode/length": 198.0, "episode/score": 0.3812499940395355, "episode/reward_rate": 0.005025125628140704, "episode/intrinsic_return": 0.0}
{"step": 658888, "time": 75539.14935731888, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 658920, "time": 75542.77723360062, "episode/length": 198.0, "episode/score": 0.3812499940395355, "episode/reward_rate": 0.005025125628140704, "episode/intrinsic_return": 0.0}
{"step": 659088, "time": 75561.77797174454, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 659400, "time": 75597.05494999886, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 659744, "time": 75635.76380515099, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 659840, "time": 75646.68742752075, "episode/length": 270.0, "episode/score": 0.15625, "episode/reward_rate": 0.0036900369003690036, "episode/intrinsic_return": 0.0}
{"step": 660032, "time": 75668.28529191017, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 660088, "time": 75675.20717334747, "eval_episode/length": 31.0, "eval_episode/score": 0.903124988079071, "eval_episode/reward_rate": 0.03125}
{"step": 660088, "time": 75676.00502681732, "eval_episode/length": 78.0, "eval_episode/score": 0.7562500238418579, "eval_episode/reward_rate": 0.012658227848101266}
{"step": 660088, "time": 75676.71569609642, "eval_episode/length": 120.0, "eval_episode/score": 0.625, "eval_episode/reward_rate": 0.008264462809917356}
{"step": 660088, "time": 75676.72154808044, "eval_episode/length": 120.0, "eval_episode/score": 0.625, "eval_episode/reward_rate": 0.008264462809917356}
{"step": 660088, "time": 75676.81262111664, "eval_episode/length": 125.0, "eval_episode/score": 0.609375, "eval_episode/reward_rate": 0.007936507936507936}
{"step": 660088, "time": 75677.23186278343, "eval_episode/length": 149.0, "eval_episode/score": 0.534375011920929, "eval_episode/reward_rate": 0.006666666666666667}
{"step": 660088, "time": 75677.52274894714, "eval_episode/length": 165.0, "eval_episode/score": 0.484375, "eval_episode/reward_rate": 0.006024096385542169}
{"step": 660088, "time": 75678.1808283329, "eval_episode/length": 78.0, "eval_episode/score": 0.7562500238418579, "eval_episode/reward_rate": 0.012658227848101266}
{"step": 660248, "time": 75696.2060687542, "episode/length": 280.0, "episode/score": 0.125, "episode/reward_rate": 0.0035587188612099642, "episode/intrinsic_return": 0.0}
{"step": 660264, "time": 75698.01347374916, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 660544, "time": 75729.66534423828, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 660616, "time": 75737.8635635376, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 660784, "time": 75756.78600287437, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 661040, "time": 75785.68711614609, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 661200, "time": 75803.82384586334, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 661296, "time": 75814.60576224327, "episode/length": 275.0, "episode/score": 0.140625, "episode/reward_rate": 0.0036231884057971015, "episode/intrinsic_return": 0.0}
{"step": 661320, "time": 75817.32081055641, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 661504, "time": 75838.05305886269, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 661664, "time": 75856.16604590416, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 661680, "time": 75857.98099136353, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 661760, "time": 75866.98269677162, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 661896, "time": 75882.33404302597, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 662184, "time": 75914.85866165161, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 662304, "time": 75928.37046098709, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 662344, "time": 75932.89044547081, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 662440, "time": 75943.74602532387, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 662496, "time": 75950.04687952995, "episode/length": 243.0, "episode/score": 0.24062499403953552, "episode/reward_rate": 0.004098360655737705, "episode/intrinsic_return": 0.0}
{"step": 662576, "time": 75959.05808281898, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 662960, "time": 76002.39985060692, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 663176, "time": 76026.6808924675, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 663256, "time": 76035.78106951714, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 663336, "time": 76044.78588271141, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 663456, "time": 76058.2994017601, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 663608, "time": 76075.82029938698, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 663752, "time": 76092.08732533455, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 663992, "time": 76119.09253382683, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 664592, "time": 76186.82160973549, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 664728, "time": 76202.10860705376, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 664888, "time": 76220.21256446838, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 665128, "time": 76247.22545790672, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.0}
{"step": 665169, "time": 76252.70979118347, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.7943490835336537, "train/action_min": 0.0, "train/action_std": 1.6505481544123515, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0084781077346971, "train/actor_opt_grad_steps": 164800.0, "train/actor_opt_loss": -21.25226908895225, "train/adv_mag": 0.4833024856191954, "train/adv_max": 0.27407828121703137, "train/adv_mean": -0.0008064857229678287, "train/adv_min": -0.4396230834641608, "train/adv_std": 0.021896876723450774, "train/cont_avg": 0.995475113122172, "train/cont_loss_mean": 0.014875095881251998, "train/cont_loss_std": 0.20440771303464114, "train/cont_neg_acc": 0.3292914663369839, "train/cont_neg_loss": 2.4541525143391993, "train/cont_pos_acc": 0.9999289245627045, "train/cont_pos_loss": 0.0033588050006008053, "train/cont_pred": 0.9952668512568754, "train/cont_rate": 0.995475113122172, "train/dyn_loss_mean": 1.0000000399162328, "train/dyn_loss_std": 1.2767123484065361e-06, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.11422987181979877, "train/extr_critic_critic_opt_grad_steps": 164800.0, "train/extr_critic_critic_opt_loss": 6098.5413558752825, "train/extr_critic_mag": 1.1174114732181324, "train/extr_critic_max": 1.1174114732181324, "train/extr_critic_mean": 0.8755065429264604, "train/extr_critic_min": 0.7491334957235, "train/extr_critic_std": 0.03348720771559763, "train/extr_return_normed_mag": 0.5349349020832804, "train/extr_return_normed_max": 0.3890164721066056, "train/extr_return_normed_mean": 0.04314139492944625, "train/extr_return_normed_min": -0.3512791039177735, "train/extr_return_normed_std": 0.04106878223765759, "train/extr_return_rate": 0.9995121856081001, "train/extr_return_raw_mag": 1.2205751109446874, "train/extr_return_raw_max": 1.2205751109446874, "train/extr_return_raw_mean": 0.8747000723942373, "train/extr_return_raw_min": 0.4802795349203084, "train/extr_return_raw_std": 0.04106878236408147, "train/extr_reward_mag": 0.34157790749321154, "train/extr_reward_max": 0.34157790749321154, "train/extr_reward_mean": 0.0013119946571058547, "train/extr_reward_min": -6.2549815458409924e-06, "train/extr_reward_std": 0.009156546631313827, "train/image_loss_mean": 0.07244242009668868, "train/image_loss_std": 0.09729352392829381, "train/model_loss_mean": 0.6974816834764783, "train/model_loss_std": 0.37504031224285855, "train/model_opt_grad_norm": 10.96300517379968, "train/model_opt_grad_steps": 164656.7511312217, "train/model_opt_loss": 3849.6982709099266, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5520.361990950226, "train/policy_entropy_mag": 1.2697818667640512, "train/policy_entropy_max": 1.2697818667640512, "train/policy_entropy_mean": 0.09371286610402672, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.11544492675573038, "train/policy_logprob_mag": 6.551080287311951, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09434937550875935, "train/policy_logprob_min": -6.551080287311951, "train/policy_logprob_std": 0.6350051760673523, "train/policy_randomness_mag": 0.6525388351932371, "train/policy_randomness_max": 0.6525388351932371, "train/policy_randomness_mean": 0.04815889240929444, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.05932695956319166, "train/post_ent_mag": 42.87575039065262, "train/post_ent_max": 42.87575039065262, "train/post_ent_mean": 41.94123072214256, "train/post_ent_min": 40.92055066138911, "train/post_ent_std": 0.41974003741104676, "train/prior_ent_mag": 43.14389371224658, "train/prior_ent_max": 43.14389371224658, "train/prior_ent_mean": 42.00996547371014, "train/prior_ent_min": 40.79436287513146, "train/prior_ent_std": 0.42458751393119676, "train/rep_loss_mean": 1.0000000399162328, "train/rep_loss_std": 1.2767123484065361e-06, "train/reward_avg": 0.001344361451793698, "train/reward_loss_mean": 0.010164119931131737, "train/reward_loss_std": 0.1699092560237046, "train/reward_max_data": 0.631249999433621, "train/reward_max_pred": 0.2305302102101874, "train/reward_neg_acc": 0.9997519349080944, "train/reward_neg_loss": 0.0019402529889447995, "train/reward_pos_acc": 0.2017767430849411, "train/reward_pos_loss": 3.6518073483328126, "train/reward_pred": 0.0011121664086685462, "train/reward_rate": 0.002288956447963801, "train_stats/mean_log_entropy": 0.0731946470252439, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.014336306601762772, "report/cont_loss_std": 0.22385349869728088, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 3.7830722332000732, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0032626467291265726, "report/cont_pred": 0.9966489672660828, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.06539135426282883, "report/image_loss_std": 0.08408336341381073, "report/model_loss_mean": 0.6848008632659912, "report/model_loss_std": 0.2969948947429657, "report/post_ent_mag": 42.547386169433594, "report/post_ent_max": 42.547386169433594, "report/post_ent_mean": 41.52180480957031, "report/post_ent_min": 40.432373046875, "report/post_ent_std": 0.46746519207954407, "report/prior_ent_mag": 42.90790557861328, "report/prior_ent_max": 42.90790557861328, "report/prior_ent_mean": 41.298194885253906, "report/prior_ent_min": 39.83871078491211, "report/prior_ent_std": 0.5009062886238098, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0007171630859375, "report/reward_loss_mean": 0.005073129199445248, "report/reward_loss_std": 0.09928256273269653, "report/reward_max_data": 0.734375, "report/reward_max_pred": 0.05133509635925293, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00198200810700655, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 3.1672897338867188, "report/reward_pred": 0.0009500838350504637, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.0313492976129055, "eval/cont_loss_std": 0.46511468291282654, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.688994407653809, "eval/cont_pos_acc": 0.999018669128418, "eval/cont_pos_loss": 0.003588527673855424, "eval/cont_pred": 0.9966318607330322, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.11696694046258926, "eval/image_loss_std": 0.12072574347257614, "eval/model_loss_mean": 0.7645222544670105, "eval/model_loss_std": 0.651629626750946, "eval/post_ent_mag": 42.534584045410156, "eval/post_ent_max": 42.534584045410156, "eval/post_ent_mean": 41.5350341796875, "eval/post_ent_min": 40.531105041503906, "eval/post_ent_std": 0.46384257078170776, "eval/prior_ent_mag": 42.87881088256836, "eval/prior_ent_max": 42.87881088256836, "eval/prior_ent_mean": 41.311668395996094, "eval/prior_ent_min": 39.9376220703125, "eval/prior_ent_std": 0.5040963888168335, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0016571044689044356, "eval/reward_loss_mean": 0.016206007450819016, "eval/reward_loss_std": 0.27032387256622314, "eval/reward_max_data": 0.846875011920929, "eval/reward_max_pred": 0.11588168144226074, "eval/reward_neg_acc": 0.999020516872406, "eval/reward_neg_loss": 0.0016953288577497005, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 4.954673767089844, "eval/reward_pred": 0.0008431700989603996, "eval/reward_rate": 0.0029296875, "replay/size": 664665.0, "replay/inserts": 8820.0, "replay/samples": 35280.0, "replay/insert_wait_avg": 1.5344208870885593e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.163843059756048e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 1640.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0244730042248237e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.195638656616211e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.070698261261, "timer/env.step_count": 1103.0, "timer/env.step_total": 10.84974980354309, "timer/env.step_frac": 0.010848982799322728, "timer/env.step_avg": 0.009836581870845957, "timer/env.step_min": 0.008600711822509766, "timer/env.step_max": 0.03514885902404785, "timer/replay._sample_count": 35280.0, "timer/replay._sample_total": 18.145678281784058, "timer/replay._sample_frac": 0.018144395504570254, "timer/replay._sample_avg": 0.0005143332846310674, "timer/replay._sample_min": 0.00038552284240722656, "timer/replay._sample_max": 0.021559476852416992, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1308.0, "timer/agent.policy_total": 13.199228525161743, "timer/agent.policy_frac": 0.01319829542862333, "timer/agent.policy_avg": 0.01009115330669858, "timer/agent.policy_min": 0.008806943893432617, "timer/agent.policy_max": 0.03639388084411621, "timer/dataset_train_count": 2205.0, "timer/dataset_train_total": 0.4443552494049072, "timer/dataset_train_frac": 0.00044432383648223113, "timer/dataset_train_avg": 0.00020152165505891485, "timer/dataset_train_min": 9.679794311523438e-05, "timer/dataset_train_max": 0.04599118232727051, "timer/agent.train_count": 2205.0, "timer/agent.train_total": 971.4298467636108, "timer/agent.train_frac": 0.971361173217608, "timer/agent.train_avg": 0.4405577536342906, "timer/agent.train_min": 0.4301748275756836, "timer/agent.train_max": 0.5669739246368408, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47989964485168457, "timer/agent.report_frac": 0.0004798657191796998, "timer/agent.report_avg": 0.23994982242584229, "timer/agent.report_min": 0.23238015174865723, "timer/agent.report_max": 0.24751949310302734, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.075599670410156e-05, "timer/dataset_eval_frac": 3.075382246232635e-08, "timer/dataset_eval_avg": 3.075599670410156e-05, "timer/dataset_eval_min": 3.075599670410156e-05, "timer/dataset_eval_max": 3.075599670410156e-05, "fps": 8.81925991082022}
{"step": 665272, "time": 76264.07828497887, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 665416, "time": 76280.3297522068, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 665768, "time": 76320.0310997963, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 666016, "time": 76348.03926444054, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 666064, "time": 76353.43992137909, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 666136, "time": 76361.64287996292, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 666304, "time": 76380.57013702393, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 667040, "time": 76463.67323684692, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 667128, "time": 76473.58189582825, "episode/length": 10.0, "episode/score": 0.96875, "episode/reward_rate": 0.09090909090909091, "episode/intrinsic_return": 0.0}
{"step": 667584, "time": 76525.07695889473, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 667728, "time": 76541.3753015995, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 668080, "time": 76581.18462967873, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 668328, "time": 76609.14615821838, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 668376, "time": 76614.55337905884, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 668448, "time": 76622.65856790543, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 668616, "time": 76641.62005996704, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 669440, "time": 76734.64749217033, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 669896, "time": 76785.94217300415, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 670040, "time": 76802.15360856056, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 670072, "time": 76810.83194851875, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 670072, "time": 76810.85694432259, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 670072, "time": 76810.88389110565, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 670072, "time": 76810.89770960808, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 670072, "time": 76810.90497279167, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 670072, "time": 76810.91050982475, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 670072, "time": 76810.93064117432, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 670072, "time": 76810.93650817871, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 670392, "time": 76847.1206753254, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 670640, "time": 76875.22248697281, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 670688, "time": 76880.65221858025, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 670760, "time": 76888.74930644035, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 670928, "time": 76907.70177602768, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 671752, "time": 77001.12769317627, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 672208, "time": 77052.6623237133, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 672352, "time": 77068.84787011147, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 672704, "time": 77108.58122396469, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 672952, "time": 77136.5468223095, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 673000, "time": 77142.05126285553, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 673072, "time": 77150.13820719719, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 673240, "time": 77169.05882906914, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 673973, "time": 77252.96332669258, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 1.7882193825461647, "train/action_min": 0.0, "train/action_std": 1.4939811191775583, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.009998489584540948, "train/actor_opt_grad_steps": 167005.0, "train/actor_opt_loss": -13.055792805002156, "train/adv_mag": 0.5747628786347129, "train/adv_max": 0.37566019703041426, "train/adv_mean": -0.0013384396294151718, "train/adv_min": -0.4991066095503894, "train/adv_std": 0.03130293651060625, "train/cont_avg": 0.9951438210227272, "train/cont_loss_mean": 0.01650186883264475, "train/cont_loss_std": 0.22592232601124454, "train/cont_neg_acc": 0.29031650598989717, "train/cont_neg_loss": 2.7018542701053785, "train/cont_pos_acc": 0.999910719557242, "train/cont_pos_loss": 0.003441233453023332, "train/cont_pred": 0.9951302200555802, "train/cont_rate": 0.9951438210227272, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.15486910091289743, "train/extr_critic_critic_opt_grad_steps": 167005.0, "train/extr_critic_critic_opt_loss": 9796.169479092685, "train/extr_critic_mag": 1.0407157068902797, "train/extr_critic_max": 1.0407157068902797, "train/extr_critic_mean": 0.8209825252944772, "train/extr_critic_min": 0.7334429903463884, "train/extr_critic_std": 0.02697974080219865, "train/extr_return_normed_mag": 0.6155611626126549, "train/extr_return_normed_max": 0.47744976336305794, "train/extr_return_normed_mean": 0.028859463348370893, "train/extr_return_normed_min": -0.42144791131669823, "train/extr_return_normed_std": 0.04357152942737395, "train/extr_return_rate": 0.9988177984952926, "train/extr_return_raw_mag": 1.2682343512773513, "train/extr_return_raw_max": 1.2682343512773513, "train/extr_return_raw_mean": 0.8196440910751169, "train/extr_return_raw_min": 0.3693366765975952, "train/extr_return_raw_std": 0.0435715293596414, "train/extr_reward_mag": 0.4902774610302665, "train/extr_reward_max": 0.4902774610302665, "train/extr_reward_mean": 0.0017748285916406364, "train/extr_reward_min": 0.0, "train/extr_reward_std": 0.016007771203294396, "train/image_loss_mean": 0.07239210243252191, "train/image_loss_std": 0.09724998631599274, "train/model_loss_mean": 0.6995791248299859, "train/model_loss_std": 0.39586631930009886, "train/model_opt_grad_norm": 10.689224954084917, "train/model_opt_grad_steps": 166860.15454545454, "train/model_opt_loss": 4386.227474698154, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 6272.727272727273, "train/policy_entropy_mag": 1.208437421646985, "train/policy_entropy_max": 1.208437421646985, "train/policy_entropy_mean": 0.09441412301226096, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.11402354169298302, "train/policy_logprob_mag": 6.551080380786549, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09446105259385976, "train/policy_logprob_min": -6.551080380786549, "train/policy_logprob_std": 0.6319606377319856, "train/policy_randomness_mag": 0.6210140255364505, "train/policy_randomness_max": 0.6210140255364505, "train/policy_randomness_mean": 0.04851926470344717, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.058596512590619654, "train/post_ent_mag": 42.97628050717441, "train/post_ent_max": 42.97628050717441, "train/post_ent_mean": 42.04763981212269, "train/post_ent_min": 40.9864275152033, "train/post_ent_std": 0.4319453261115334, "train/prior_ent_mag": 42.82407155470415, "train/prior_ent_max": 42.82407155470415, "train/prior_ent_mean": 41.524009635231714, "train/prior_ent_min": 40.215182130986996, "train/prior_ent_std": 0.4479648023843765, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0014452015285893471, "train/reward_loss_mean": 0.010685129192742435, "train/reward_loss_std": 0.1765328474639153, "train/reward_max_data": 0.6683238639750264, "train/reward_max_pred": 0.252377141605724, "train/reward_neg_acc": 0.9997729721394453, "train/reward_neg_loss": 0.002033277543060566, "train/reward_pos_acc": 0.22115563466781524, "train/reward_pos_loss": 3.5765661758620566, "train/reward_pred": 0.0011721636427947405, "train/reward_rate": 0.0023881392045454544, "train_stats/mean_log_entropy": 0.10803316696546972, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.015864616259932518, "report/cont_loss_std": 0.2593144476413727, "report/cont_neg_acc": 0.5, "report/cont_neg_loss": 2.291551351547241, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0024519250728189945, "report/cont_pred": 0.994599461555481, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.05619508773088455, "report/image_loss_std": 0.09397000819444656, "report/model_loss_mean": 0.6770106554031372, "report/model_loss_std": 0.3384302854537964, "report/post_ent_mag": 42.831077575683594, "report/post_ent_max": 42.831077575683594, "report/post_ent_mean": 41.80789566040039, "report/post_ent_min": 40.69743347167969, "report/post_ent_std": 0.46451959013938904, "report/prior_ent_mag": 42.771568298339844, "report/prior_ent_max": 42.771568298339844, "report/prior_ent_mean": 41.71361541748047, "report/prior_ent_min": 40.53748321533203, "report/prior_ent_std": 0.41367200016975403, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00054931640625, "report/reward_loss_mean": 0.004950935486704111, "report/reward_loss_std": 0.10769913345575333, "report/reward_max_data": 0.5625, "report/reward_max_pred": 0.042886972427368164, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.001594536704942584, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 3.438546657562256, "report/reward_pred": 0.0007464229129254818, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.03907240554690361, "eval/cont_loss_std": 0.5975959300994873, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 9.1629638671875, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.003292437642812729, "eval/cont_pred": 0.9967965483665466, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.14742159843444824, "eval/image_loss_std": 0.16121181845664978, "eval/model_loss_mean": 0.7988885641098022, "eval/model_loss_std": 0.8622203469276428, "eval/post_ent_mag": 42.82402801513672, "eval/post_ent_max": 42.82402801513672, "eval/post_ent_mean": 41.86070251464844, "eval/post_ent_min": 40.84175109863281, "eval/post_ent_std": 0.43682271242141724, "eval/prior_ent_mag": 42.944725036621094, "eval/prior_ent_max": 42.944725036621094, "eval/prior_ent_mean": 41.73902893066406, "eval/prior_ent_min": 40.513973236083984, "eval/prior_ent_std": 0.4020620584487915, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0006927490467205644, "eval/reward_loss_mean": 0.012394517660140991, "eval/reward_loss_std": 0.3293151259422302, "eval/reward_max_data": 0.7093750238418579, "eval/reward_max_pred": 0.14226830005645752, "eval/reward_neg_acc": 0.9990224838256836, "eval/reward_neg_loss": 0.002104764571413398, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 10.538811683654785, "eval/reward_pred": 0.000995067646726966, "eval/reward_rate": 0.0009765625, "replay/size": 673469.0, "replay/inserts": 8804.0, "replay/samples": 35216.0, "replay/insert_wait_avg": 1.545929464628782e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.068877976247258e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0544247280767631e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.301568984985352e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2387447357178, "timer/env.step_count": 1100.0, "timer/env.step_total": 10.781378507614136, "timer/env.step_frac": 0.010778805124633303, "timer/env.step_avg": 0.009801253188740124, "timer/env.step_min": 0.008521556854248047, "timer/env.step_max": 0.04084944725036621, "timer/replay._sample_count": 35216.0, "timer/replay._sample_total": 18.210932970046997, "timer/replay._sample_frac": 0.018206586243425988, "timer/replay._sample_avg": 0.0005171209952875681, "timer/replay._sample_min": 0.0003452301025390625, "timer/replay._sample_max": 0.013673782348632812, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1389.0, "timer/agent.policy_total": 14.024763822555542, "timer/agent.policy_frac": 0.014021416283230613, "timer/agent.policy_avg": 0.010097022190464752, "timer/agent.policy_min": 0.008737325668334961, "timer/agent.policy_max": 0.03436279296875, "timer/dataset_train_count": 2201.0, "timer/dataset_train_total": 0.38808250427246094, "timer/dataset_train_frac": 0.0003879898737325955, "timer/dataset_train_avg": 0.00017632099240002768, "timer/dataset_train_min": 9.5367431640625e-05, "timer/dataset_train_max": 0.000835418701171875, "timer/agent.train_count": 2201.0, "timer/agent.train_total": 970.0732190608978, "timer/agent.train_frac": 0.9698416744666392, "timer/agent.train_avg": 0.4407420350117664, "timer/agent.train_min": 0.4313371181488037, "timer/agent.train_max": 0.5711655616760254, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4812924861907959, "timer/agent.report_frac": 0.00048117760757004327, "timer/agent.report_avg": 0.24064624309539795, "timer/agent.report_min": 0.23618745803833008, "timer/agent.report_max": 0.24510502815246582, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.5272369384765625e-05, "timer/dataset_eval_frac": 2.5266337179773083e-08, "timer/dataset_eval_avg": 2.5272369384765625e-05, "timer/dataset_eval_min": 2.5272369384765625e-05, "timer/dataset_eval_max": 2.5272369384765625e-05, "fps": 8.801774458246982}
{"step": 674064, "time": 77263.1699385643, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 674120, "time": 77269.53483533859, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 674496, "time": 77312.08010554314, "episode/length": 267.0, "episode/score": 0.16562500596046448, "episode/reward_rate": 0.0037313432835820895, "episode/intrinsic_return": 0.0}
{"step": 674520, "time": 77314.80358743668, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 675264, "time": 77398.97702503204, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 675312, "time": 77404.41201710701, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 675384, "time": 77412.62444090843, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 675432, "time": 77418.0412504673, "episode/length": 273.0, "episode/score": 0.14687499403953552, "episode/reward_rate": 0.0036496350364963502, "episode/intrinsic_return": 0.0}
{"step": 675496, "time": 77425.26477479935, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 675672, "time": 77445.17949342728, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 675728, "time": 77451.54972982407, "episode/length": 207.0, "episode/score": 0.3531250059604645, "episode/reward_rate": 0.004807692307692308, "episode/intrinsic_return": 0.0}
{"step": 675744, "time": 77453.36048412323, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 675952, "time": 77476.93254685402, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 676224, "time": 77507.69029784203, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 676344, "time": 77521.25167179108, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 676536, "time": 77543.03299975395, "episode/length": 251.0, "episode/score": 0.21562500298023224, "episode/reward_rate": 0.003968253968253968, "episode/intrinsic_return": 0.0}
{"step": 676608, "time": 77551.1750459671, "episode/length": 263.0, "episode/score": 0.17812499403953552, "episode/reward_rate": 0.003787878787878788, "episode/intrinsic_return": 0.0}
{"step": 676688, "time": 77560.22253036499, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 676744, "time": 77566.67749071121, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 677248, "time": 77623.66086363792, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 677328, "time": 77632.68458509445, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 677480, "time": 77649.84955763817, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 677688, "time": 77673.38262152672, "episode/length": 244.0, "episode/score": 0.23749999701976776, "episode/reward_rate": 0.004081632653061225, "episode/intrinsic_return": 0.0}
{"step": 677712, "time": 77676.09002804756, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 677872, "time": 77694.21985149384, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 677984, "time": 77706.8453900814, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 678248, "time": 77736.7235147953, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 678536, "time": 77769.22179460526, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 678856, "time": 77805.45945310593, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 678872, "time": 77807.26075363159, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 678920, "time": 77812.69334673882, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 679000, "time": 77821.72358489037, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 679032, "time": 77825.31100392342, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 679432, "time": 77870.54826021194, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 679528, "time": 77881.36198830605, "episode/length": 11.0, "episode/score": 0.965624988079071, "episode/reward_rate": 0.08333333333333333, "episode/intrinsic_return": 0.0}
{"step": 679576, "time": 77886.76790428162, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 680024, "time": 77937.79371905327, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 680056, "time": 77942.47702431679, "eval_episode/length": 59.0, "eval_episode/score": 0.815625011920929, "eval_episode/reward_rate": 0.016666666666666666}
{"step": 680056, "time": 77944.9436826706, "eval_episode/length": 200.0, "eval_episode/score": 0.375, "eval_episode/reward_rate": 0.004975124378109453}
{"step": 680056, "time": 77945.11432433128, "eval_episode/length": 209.0, "eval_episode/score": 0.34687501192092896, "eval_episode/reward_rate": 0.004761904761904762}
{"step": 680056, "time": 77945.60041427612, "eval_episode/length": 237.0, "eval_episode/score": 0.2593750059604645, "eval_episode/reward_rate": 0.004201680672268907}
{"step": 680056, "time": 77946.2295255661, "eval_episode/length": 35.0, "eval_episode/score": 0.890625, "eval_episode/reward_rate": 0.027777777777777776}
{"step": 680056, "time": 77946.49320149422, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 680056, "time": 77946.50026774406, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 680056, "time": 77946.50559282303, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 680056, "time": 77946.5110206604, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 680208, "time": 77963.71342897415, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 680256, "time": 77969.12012863159, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 680296, "time": 77973.63022756577, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 680320, "time": 77976.35078549385, "episode/length": 258.0, "episode/score": 0.19374999403953552, "episode/reward_rate": 0.003861003861003861, "episode/intrinsic_return": 0.0}
{"step": 681184, "time": 78074.17762684822, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 681344, "time": 78092.25431323051, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 681424, "time": 78101.34839272499, "episode/length": 230.0, "episode/score": 0.28125, "episode/reward_rate": 0.004329004329004329, "episode/intrinsic_return": 0.0}
{"step": 681464, "time": 78105.87083816528, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 681728, "time": 78135.78984880447, "episode/length": 212.0, "episode/score": 0.3375000059604645, "episode/reward_rate": 0.004694835680751174, "episode/intrinsic_return": 0.0}
{"step": 682168, "time": 78185.47461032867, "episode/length": 230.0, "episode/score": 0.28125, "episode/reward_rate": 0.004329004329004329, "episode/intrinsic_return": 0.0}
{"step": 682384, "time": 78209.87529230118, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 682520, "time": 78225.29796648026, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 682568, "time": 78230.72685170174, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 682712, "time": 78246.96838188171, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 682757, "time": 78253.005453825, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.8903006813742897, "train/action_min": 0.0, "train/action_std": 1.6020025838505139, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.008551592679313299, "train/actor_opt_grad_steps": 169205.0, "train/actor_opt_loss": -21.164077910509977, "train/adv_mag": 0.4581394150853157, "train/adv_max": 0.2451912920583378, "train/adv_mean": 0.0012583863462065313, "train/adv_min": -0.4260586324063214, "train/adv_std": 0.025939212036742404, "train/cont_avg": 0.9954323508522728, "train/cont_loss_mean": 0.016549604458057067, "train/cont_loss_std": 0.23116557524454864, "train/cont_neg_acc": 0.2542406252839349, "train/cont_neg_loss": 2.932384987775533, "train/cont_pos_acc": 0.999901832504706, "train/cont_pos_loss": 0.003363224765053019, "train/cont_pred": 0.995490100979805, "train/cont_rate": 0.9954323508522728, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.14275504637678915, "train/extr_critic_critic_opt_grad_steps": 169205.0, "train/extr_critic_critic_opt_loss": 12776.896537642046, "train/extr_critic_mag": 0.9436455141414296, "train/extr_critic_max": 0.9436455141414296, "train/extr_critic_mean": 0.7414401395754381, "train/extr_critic_min": 0.6369479060173034, "train/extr_critic_std": 0.03578147322616794, "train/extr_return_normed_mag": 0.4848010881380601, "train/extr_return_normed_max": 0.3538346897472035, "train/extr_return_normed_mean": 0.05493439060889862, "train/extr_return_normed_min": -0.3554296241565184, "train/extr_return_normed_std": 0.04490512659434568, "train/extr_return_rate": 0.9992116784507578, "train/extr_return_raw_mag": 1.0415987339886752, "train/extr_return_raw_max": 1.0415987339886752, "train/extr_return_raw_mean": 0.7426984659650109, "train/extr_return_raw_min": 0.3323344200849533, "train/extr_return_raw_std": 0.04490512671287764, "train/extr_reward_mag": 0.35828821604902095, "train/extr_reward_max": 0.35828821604902095, "train/extr_reward_mean": 0.0014131228516238148, "train/extr_reward_min": -9.5367431640625e-08, "train/extr_reward_std": 0.010140618537975984, "train/image_loss_mean": 0.07299618031829595, "train/image_loss_std": 0.097400653463873, "train/model_loss_mean": 0.6993675110015002, "train/model_loss_std": 0.38859445655887775, "train/model_opt_grad_norm": 10.822009526599537, "train/model_opt_grad_steps": 169058.22272727272, "train/model_opt_loss": 4193.983111017401, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 6022.727272727273, "train/policy_entropy_mag": 1.2906381991776552, "train/policy_entropy_max": 1.2906381991776552, "train/policy_entropy_mean": 0.08886067437177354, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.10674008916724811, "train/policy_logprob_mag": 6.55108030275865, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.08940801888026974, "train/policy_logprob_min": -6.55108030275865, "train/policy_logprob_std": 0.6297020782123912, "train/policy_randomness_mag": 0.6632568711584265, "train/policy_randomness_max": 0.6632568711584265, "train/policy_randomness_mean": 0.04566535926000639, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.05485355837101286, "train/post_ent_mag": 42.96887127269398, "train/post_ent_max": 42.96887127269398, "train/post_ent_mean": 42.0203353881836, "train/post_ent_min": 40.934045392816714, "train/post_ent_std": 0.44133327928456395, "train/prior_ent_mag": 42.93507903705944, "train/prior_ent_max": 42.93507903705944, "train/prior_ent_mean": 41.72725556113503, "train/prior_ent_min": 40.59912086833607, "train/prior_ent_std": 0.41132086393508044, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0012558815697544063, "train/reward_loss_mean": 0.00982170523758131, "train/reward_loss_std": 0.16580228821205145, "train/reward_max_data": 0.621022728458047, "train/reward_max_pred": 0.22292952754280784, "train/reward_neg_acc": 0.9997197473591024, "train/reward_neg_loss": 0.001887031463742129, "train/reward_pos_acc": 0.19415140587549942, "train/reward_pos_loss": 3.668053685472562, "train/reward_pred": 0.0010557615483941679, "train/reward_rate": 0.0021218039772727274, "train_stats/mean_log_entropy": 0.08371285582874335, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.017131920903921127, "report/cont_loss_std": 0.2208939641714096, "report/cont_neg_acc": 0.2857142984867096, "report/cont_neg_loss": 2.0600666999816895, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.003070423612371087, "report/cont_pred": 0.9946032762527466, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.06703341007232666, "report/image_loss_std": 0.0845983475446701, "report/model_loss_mean": 0.6936061382293701, "report/model_loss_std": 0.35769277811050415, "report/post_ent_mag": 43.728126525878906, "report/post_ent_max": 43.728126525878906, "report/post_ent_mean": 42.849464416503906, "report/post_ent_min": 41.79399490356445, "report/post_ent_std": 0.40687185525894165, "report/prior_ent_mag": 42.86781311035156, "report/prior_ent_max": 42.86781311035156, "report/prior_ent_mean": 41.77318572998047, "report/prior_ent_min": 40.70588302612305, "report/prior_ent_std": 0.4222754240036011, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0019317626720294356, "report/reward_loss_mean": 0.009440754540264606, "report/reward_loss_std": 0.16536657512187958, "report/reward_max_data": 0.65625, "report/reward_max_pred": 0.5795807838439941, "report/reward_neg_acc": 0.9999999403953552, "report/reward_neg_loss": 0.0015790117904543877, "report/reward_pos_acc": 0.75, "report/reward_pos_loss": 2.0141851902008057, "report/reward_pred": 0.0018628818215802312, "report/reward_rate": 0.00390625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.016808558255434036, "eval/cont_loss_std": 0.2433357983827591, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 4.0887770652771, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.004843909293413162, "eval/cont_pred": 0.9952037334442139, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.11457124352455139, "eval/image_loss_std": 0.122670479118824, "eval/model_loss_mean": 0.7479910254478455, "eval/model_loss_std": 0.5362029075622559, "eval/post_ent_mag": 43.71643829345703, "eval/post_ent_max": 43.71643829345703, "eval/post_ent_mean": 42.86305618286133, "eval/post_ent_min": 41.92744827270508, "eval/post_ent_std": 0.4033331274986267, "eval/prior_ent_mag": 42.78664779663086, "eval/prior_ent_max": 42.78664779663086, "eval/prior_ent_mean": 41.76634216308594, "eval/prior_ent_min": 40.56079864501953, "eval/prior_ent_std": 0.4015715420246124, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0016601562965661287, "eval/reward_loss_mean": 0.016611184924840927, "eval/reward_loss_std": 0.267575740814209, "eval/reward_max_data": 0.643750011920929, "eval/reward_max_pred": 0.11721181869506836, "eval/reward_neg_acc": 0.999020516872406, "eval/reward_neg_loss": 0.002828143537044525, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 4.707440376281738, "eval/reward_pred": 0.0013349391520023346, "eval/reward_rate": 0.0029296875, "replay/size": 682253.0, "replay/inserts": 8784.0, "replay/samples": 35136.0, "replay/insert_wait_avg": 1.5121285815490833e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.183567530904746e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 9.938919832962194e-07, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.152557373046875e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0240857601166, "timer/env.step_count": 1098.0, "timer/env.step_total": 10.779724836349487, "timer/env.step_frac": 0.01077946520473638, "timer/env.step_avg": 0.00981760003310518, "timer/env.step_min": 0.008542060852050781, "timer/env.step_max": 0.035094499588012695, "timer/replay._sample_count": 35136.0, "timer/replay._sample_total": 18.150963306427002, "timer/replay._sample_frac": 0.01815052613720847, "timer/replay._sample_avg": 0.0005165916241583277, "timer/replay._sample_min": 0.0003726482391357422, "timer/replay._sample_max": 0.02515411376953125, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1387.0, "timer/agent.policy_total": 13.914881229400635, "timer/agent.policy_frac": 0.013914546086981453, "timer/agent.policy_avg": 0.010032358492718555, "timer/agent.policy_min": 0.008870601654052734, "timer/agent.policy_max": 0.0279843807220459, "timer/dataset_train_count": 2196.0, "timer/dataset_train_total": 0.41249608993530273, "timer/dataset_train_frac": 0.00041248615489272456, "timer/dataset_train_avg": 0.00018783974951516519, "timer/dataset_train_min": 9.5367431640625e-05, "timer/dataset_train_max": 0.023044586181640625, "timer/agent.train_count": 2196.0, "timer/agent.train_total": 970.0163426399231, "timer/agent.train_frac": 0.9699929796217012, "timer/agent.train_avg": 0.4417196460108939, "timer/agent.train_min": 0.4323160648345947, "timer/agent.train_max": 0.5663635730743408, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47442626953125, "timer/agent.report_frac": 0.00047441484288914844, "timer/agent.report_avg": 0.237213134765625, "timer/agent.report_min": 0.23077154159545898, "timer/agent.report_max": 0.24365472793579102, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.1948089599609375e-05, "timer/dataset_eval_frac": 3.19473201241205e-08, "timer/dataset_eval_avg": 3.1948089599609375e-05, "timer/dataset_eval_min": 3.1948089599609375e-05, "timer/dataset_eval_max": 3.1948089599609375e-05, "fps": 8.78364706915452}
{"step": 682800, "time": 78257.69507741928, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 683040, "time": 78284.84967064857, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 683400, "time": 78325.66547012329, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 683496, "time": 78336.53728914261, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 683736, "time": 78363.79244160652, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 683872, "time": 78379.24102687836, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 684040, "time": 78398.26335310936, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 684200, "time": 78416.42629098892, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 684408, "time": 78440.01129198074, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 684480, "time": 78448.42574954033, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 684768, "time": 78480.95615124702, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 684880, "time": 78493.73014187813, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 684888, "time": 78494.63572573662, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 685096, "time": 78518.14451146126, "episode/length": 211.0, "episode/score": 0.34062498807907104, "episode/reward_rate": 0.0047169811320754715, "episode/intrinsic_return": 0.0}
{"step": 685352, "time": 78547.2005019188, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 686352, "time": 78660.76648497581, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 686552, "time": 78683.50886106491, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 686720, "time": 78702.59754443169, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 686792, "time": 78710.74150776863, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 686928, "time": 78726.15579009056, "episode/length": 228.0, "episode/score": 0.2874999940395355, "episode/reward_rate": 0.004366812227074236, "episode/intrinsic_return": 0.0}
{"step": 687080, "time": 78743.46915078163, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 687192, "time": 78756.08720827103, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 687200, "time": 78757.02073645592, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 687664, "time": 78809.75544404984, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 687872, "time": 78833.38610935211, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 688112, "time": 78860.68251013756, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 688416, "time": 78895.54929423332, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 688568, "time": 78912.77786302567, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 688696, "time": 78927.98102474213, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.0}
{"step": 688864, "time": 78947.10930275917, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 689032, "time": 78966.20306563377, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 689104, "time": 78974.42571282387, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 689392, "time": 79007.00393104553, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 689600, "time": 79030.53921818733, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 689608, "time": 79031.51352906227, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 689672, "time": 79038.75716304779, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 689920, "time": 79066.90403819084, "episode/length": 255.0, "episode/score": 0.203125, "episode/reward_rate": 0.00390625, "episode/intrinsic_return": 0.0}
{"step": 690040, "time": 79081.41709089279, "eval_episode/length": 50.0, "eval_episode/score": 0.84375, "eval_episode/reward_rate": 0.0196078431372549}
{"step": 690040, "time": 79081.4905397892, "eval_episode/length": 54.0, "eval_episode/score": 0.831250011920929, "eval_episode/reward_rate": 0.01818181818181818}
{"step": 690040, "time": 79081.88970780373, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 690040, "time": 79081.99927926064, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 690040, "time": 79082.2970404625, "eval_episode/length": 100.0, "eval_episode/score": 0.6875, "eval_episode/reward_rate": 0.009900990099009901}
{"step": 690040, "time": 79082.4048666954, "eval_episode/length": 106.0, "eval_episode/score": 0.668749988079071, "eval_episode/reward_rate": 0.009345794392523364}
{"step": 690040, "time": 79082.88751721382, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 690040, "time": 79082.94623708725, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 690528, "time": 79138.46510314941, "episode/length": 207.0, "episode/score": 0.3531250059604645, "episode/reward_rate": 0.004807692307692308, "episode/intrinsic_return": 0.0}
{"step": 690728, "time": 79161.20873999596, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 690800, "time": 79169.31330895424, "episode/length": 211.0, "episode/score": 0.34062498807907104, "episode/reward_rate": 0.0047169811320754715, "episode/intrinsic_return": 0.0}
{"step": 691104, "time": 79203.6504688263, "episode/length": 213.0, "episode/score": 0.3343749940395355, "episode/reward_rate": 0.004672897196261682, "episode/intrinsic_return": 0.0}
{"step": 691320, "time": 79228.14868044853, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 691360, "time": 79232.65921354294, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 691384, "time": 79235.35890769958, "episode/length": 222.0, "episode/score": 0.3062500059604645, "episode/reward_rate": 0.004484304932735426, "episode/intrinsic_return": 0.0}
{"step": 691533, "time": 79253.23253703117, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.8930945548837044, "train/action_min": 0.0, "train/action_std": 1.5688871177908492, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.006734278425149042, "train/actor_opt_grad_steps": 171400.0, "train/actor_opt_loss": -30.334415993189705, "train/adv_mag": 0.4533319812114925, "train/adv_max": 0.21110205672102977, "train/adv_mean": -0.0004972510032613467, "train/adv_min": -0.42562226549675475, "train/adv_std": 0.023045984824022203, "train/cont_avg": 0.9953178510273972, "train/cont_loss_mean": 0.01599982690244709, "train/cont_loss_std": 0.22163378918909182, "train/cont_neg_acc": 0.27447575904907434, "train/cont_neg_loss": 2.757827053550917, "train/cont_pos_acc": 0.9999238192762958, "train/cont_pos_loss": 0.003321340051373322, "train/cont_pred": 0.995388846147006, "train/cont_rate": 0.9953178510273972, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.11447209023687666, "train/extr_critic_critic_opt_grad_steps": 171400.0, "train/extr_critic_critic_opt_loss": 12247.29306685217, "train/extr_critic_mag": 0.8766945616839683, "train/extr_critic_max": 0.8766945616839683, "train/extr_critic_mean": 0.7341279349370634, "train/extr_critic_min": 0.6133221861434309, "train/extr_critic_std": 0.04753738000444625, "train/extr_return_normed_mag": 0.4678960371779525, "train/extr_return_normed_max": 0.2925033406035541, "train/extr_return_normed_mean": 0.06343702279609632, "train/extr_return_normed_min": -0.35864148265150586, "train/extr_return_normed_std": 0.05359763919150448, "train/extr_return_rate": 0.9993133163887616, "train/extr_return_raw_mag": 0.9626969689647901, "train/extr_return_raw_max": 0.9626969689647901, "train/extr_return_raw_mean": 0.7336306893117895, "train/extr_return_raw_min": 0.31155214570973017, "train/extr_return_raw_std": 0.0535976392255254, "train/extr_reward_mag": 0.3069986480556122, "train/extr_reward_max": 0.3069986480556122, "train/extr_reward_mean": 0.0012297456311678608, "train/extr_reward_min": -2.5365994945508707e-07, "train/extr_reward_std": 0.0076443879146418075, "train/image_loss_mean": 0.07378778691705504, "train/image_loss_std": 0.09846477370420004, "train/model_loss_mean": 0.7006274812842068, "train/model_loss_std": 0.39975771678773236, "train/model_opt_grad_norm": 10.36007373626918, "train/model_opt_grad_steps": 171251.69406392693, "train/model_opt_loss": 4609.038942101884, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 6575.342465753424, "train/policy_entropy_mag": 1.2739902968820371, "train/policy_entropy_max": 1.2739902968820371, "train/policy_entropy_mean": 0.08472000480922934, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.09725124929865746, "train/policy_logprob_mag": 6.551080276976982, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.08469782426068771, "train/policy_logprob_min": -6.551080276976982, "train/policy_logprob_std": 0.6226717018645648, "train/policy_randomness_mag": 0.6547015420922405, "train/policy_randomness_max": 0.6547015420922405, "train/policy_randomness_mean": 0.04353747671665666, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.049977258290057856, "train/post_ent_mag": 43.258347219528126, "train/post_ent_max": 43.258347219528126, "train/post_ent_mean": 42.29825405660829, "train/post_ent_min": 41.198399722303975, "train/post_ent_std": 0.45357854453396035, "train/prior_ent_mag": 42.879353806308416, "train/prior_ent_max": 42.879353806308416, "train/prior_ent_mean": 41.7375610560587, "train/prior_ent_min": 40.64879773632032, "train/prior_ent_std": 0.39469406621096886, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0013573354787350586, "train/reward_loss_mean": 0.01083984638704625, "train/reward_loss_std": 0.18381934394405042, "train/reward_max_data": 0.6534531964286822, "train/reward_max_pred": 0.21486628164439442, "train/reward_neg_acc": 0.9998122804785428, "train/reward_neg_loss": 0.0018754290011775208, "train/reward_pos_acc": 0.16901328013493463, "train/reward_pos_loss": 3.804455349365106, "train/reward_pred": 0.00106469539821267, "train/reward_rate": 0.002367829623287671, "train_stats/mean_log_entropy": 0.0781199996444312, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.019748730584979057, "report/cont_loss_std": 0.255998820066452, "report/cont_neg_acc": 0.1666666716337204, "report/cont_neg_loss": 2.6135177612304688, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.004461289849132299, "report/cont_pred": 0.9941496849060059, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07850392907857895, "report/image_loss_std": 0.10045632719993591, "report/model_loss_mean": 0.7134071588516235, "report/model_loss_std": 0.4424087107181549, "report/post_ent_mag": 43.446327209472656, "report/post_ent_max": 43.446327209472656, "report/post_ent_mean": 42.702186584472656, "report/post_ent_min": 41.72893142700195, "report/post_ent_std": 0.4018108546733856, "report/prior_ent_mag": 43.00599670410156, "report/prior_ent_max": 43.00599670410156, "report/prior_ent_mean": 41.86985778808594, "report/prior_ent_min": 40.862693786621094, "report/prior_ent_std": 0.3787365257740021, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0017700196476653218, "report/reward_loss_mean": 0.015154464170336723, "report/reward_loss_std": 0.21075816452503204, "report/reward_max_data": 0.643750011920929, "report/reward_max_pred": 0.4550663232803345, "report/reward_neg_acc": 0.9999999403953552, "report/reward_neg_loss": 0.0032217304687947035, "report/reward_pos_acc": 0.25, "report/reward_pos_loss": 3.0580015182495117, "report/reward_pred": 0.0019339307909831405, "report/reward_rate": 0.00390625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.02817721478641033, "eval/cont_loss_std": 0.42914366722106934, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.972723960876465, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.004865266848355532, "eval/cont_pred": 0.9952593445777893, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.10497256368398666, "eval/image_loss_std": 0.11465875804424286, "eval/model_loss_mean": 0.7577440738677979, "eval/model_loss_std": 0.8646987080574036, "eval/post_ent_mag": 43.44967269897461, "eval/post_ent_max": 43.44967269897461, "eval/post_ent_mean": 42.683860778808594, "eval/post_ent_min": 41.49534225463867, "eval/post_ent_std": 0.4197501242160797, "eval/prior_ent_mag": 42.75424575805664, "eval/prior_ent_max": 42.75424575805664, "eval/prior_ent_mean": 41.85190963745117, "eval/prior_ent_min": 40.73921203613281, "eval/prior_ent_std": 0.37281158566474915, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0020294189453125, "eval/reward_loss_mean": 0.02459433488547802, "eval/reward_loss_std": 0.4268859326839447, "eval/reward_max_data": 0.7437499761581421, "eval/reward_max_pred": 0.19967198371887207, "eval/reward_neg_acc": 0.999020516872406, "eval/reward_neg_loss": 0.004305594600737095, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 6.929528713226318, "eval/reward_pred": 0.0018417927203699946, "eval/reward_rate": 0.0029296875, "replay/size": 691029.0, "replay/inserts": 8776.0, "replay/samples": 35104.0, "replay/insert_wait_avg": 1.5282044110780645e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.180879087804552e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 1104.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 9.929788285407468e-07, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.897615432739258e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2113425731659, "timer/env.step_count": 1097.0, "timer/env.step_total": 10.757829666137695, "timer/env.step_frac": 0.010755556559138655, "timer/env.step_avg": 0.009806590397573103, "timer/env.step_min": 0.008679628372192383, "timer/env.step_max": 0.03490471839904785, "timer/replay._sample_count": 35104.0, "timer/replay._sample_total": 18.22235655784607, "timer/replay._sample_frac": 0.018218506211864015, "timer/replay._sample_avg": 0.0005190963012148493, "timer/replay._sample_min": 0.0003495216369628906, "timer/replay._sample_max": 0.026303768157958984, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1235.0, "timer/agent.policy_total": 12.541391134262085, "timer/agent.policy_frac": 0.01253874116444013, "timer/agent.policy_avg": 0.010154972578349866, "timer/agent.policy_min": 0.008636474609375, "timer/agent.policy_max": 0.035878658294677734, "timer/dataset_train_count": 2194.0, "timer/dataset_train_total": 0.38254451751708984, "timer/dataset_train_frac": 0.00038246368665740914, "timer/dataset_train_avg": 0.00017435939722747941, "timer/dataset_train_min": 9.298324584960938e-05, "timer/dataset_train_max": 0.0010933876037597656, "timer/agent.train_count": 2194.0, "timer/agent.train_total": 972.6680047512054, "timer/agent.train_frac": 0.9724624820279464, "timer/agent.train_avg": 0.44333090462680286, "timer/agent.train_min": 0.4325723648071289, "timer/agent.train_max": 0.8894844055175781, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47769808769226074, "timer/agent.report_frac": 0.0004775971510814145, "timer/agent.report_avg": 0.23884904384613037, "timer/agent.report_min": 0.23192238807678223, "timer/agent.report_max": 0.24577569961547852, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 7.510185241699219e-05, "timer/dataset_eval_frac": 7.508598355201961e-08, "timer/dataset_eval_avg": 7.510185241699219e-05, "timer/dataset_eval_min": 7.510185241699219e-05, "timer/dataset_eval_max": 7.510185241699219e-05, "fps": 8.77398426569356}
{"step": 691584, "time": 79258.80172109604, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 691872, "time": 79291.3153758049, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 691920, "time": 79296.74577093124, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 691984, "time": 79304.01926970482, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 692144, "time": 79322.09399962425, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 692256, "time": 79334.85877108574, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 692352, "time": 79345.65765500069, "episode/length": 227.0, "episode/score": 0.2906250059604645, "episode/reward_rate": 0.0043859649122807015, "episode/intrinsic_return": 0.0}
{"step": 692472, "time": 79359.17752218246, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 692648, "time": 79379.10597896576, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 692712, "time": 79386.29406929016, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 692992, "time": 79417.95527625084, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 693384, "time": 79462.51413941383, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 693400, "time": 79464.33723568916, "episode/length": 286.0, "episode/score": 0.10625000298023224, "episode/reward_rate": 0.003484320557491289, "episode/intrinsic_return": 0.0}
{"step": 693696, "time": 79497.72891807556, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 694000, "time": 79532.12392640114, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 694256, "time": 79561.13698887825, "episode/length": 237.0, "episode/score": 0.2593750059604645, "episode/reward_rate": 0.004201680672268907, "episode/intrinsic_return": 0.0}
{"step": 694456, "time": 79583.73561096191, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 694568, "time": 79596.3917119503, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 694704, "time": 79611.82484531403, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 694784, "time": 79620.8370540142, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 694800, "time": 79622.65604496002, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 694928, "time": 79637.14551758766, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 695008, "time": 79646.1675517559, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 695096, "time": 79656.08480405807, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 695096, "time": 79656.10652947426, "episode/length": 20.0, "episode/score": 0.9375, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.0}
{"step": 695176, "time": 79665.19836592674, "episode/length": 20.0, "episode/score": 0.9375, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.0}
{"step": 695192, "time": 79667.00051188469, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 695448, "time": 79695.95113396645, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 695528, "time": 79704.98697662354, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 695552, "time": 79707.69047522545, "episode/length": 268.0, "episode/score": 0.16249999403953552, "episode/reward_rate": 0.0037174721189591076, "episode/intrinsic_return": 0.0}
{"step": 696240, "time": 79787.1507768631, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 696664, "time": 79835.2753777504, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 696768, "time": 79847.1384627819, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 697096, "time": 79884.23478841782, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 697280, "time": 79905.11131215096, "episode/length": 228.0, "episode/score": 0.2874999940395355, "episode/reward_rate": 0.004366812227074236, "episode/intrinsic_return": 0.0}
{"step": 697280, "time": 79905.15987467766, "episode/length": 262.0, "episode/score": 0.18125000596046448, "episode/reward_rate": 0.0038022813688212928, "episode/intrinsic_return": 0.0}
{"step": 697408, "time": 79919.58316612244, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 697408, "time": 79919.67954587936, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 697536, "time": 79934.16532802582, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 697840, "time": 79968.52977824211, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 697872, "time": 79972.12768101692, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 697968, "time": 79982.93639349937, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 698232, "time": 80012.71436262131, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 698376, "time": 80029.00459933281, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 698808, "time": 80077.79280638695, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 698888, "time": 80086.85740852356, "episode/length": 223.0, "episode/score": 0.3031249940395355, "episode/reward_rate": 0.004464285714285714, "episode/intrinsic_return": 0.0}
{"step": 698976, "time": 80096.78139209747, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 699128, "time": 80113.98622441292, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 699144, "time": 80115.78960132599, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 699152, "time": 80116.6976454258, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 699296, "time": 80132.95847725868, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 699400, "time": 80144.86639475822, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 699464, "time": 80152.12674355507, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 699800, "time": 80190.3317565918, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 699968, "time": 80209.40303969383, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 700024, "time": 80217.98197484016, "eval_episode/length": 95.0, "eval_episode/score": 0.703125, "eval_episode/reward_rate": 0.010416666666666666}
{"step": 700024, "time": 80218.3138871193, "eval_episode/length": 114.0, "eval_episode/score": 0.643750011920929, "eval_episode/reward_rate": 0.008695652173913044}
{"step": 700024, "time": 80218.56660580635, "eval_episode/length": 128.0, "eval_episode/score": 0.6000000238418579, "eval_episode/reward_rate": 0.007751937984496124}
{"step": 700024, "time": 80219.09721279144, "eval_episode/length": 159.0, "eval_episode/score": 0.503125011920929, "eval_episode/reward_rate": 0.00625}
{"step": 700024, "time": 80219.30058073997, "eval_episode/length": 171.0, "eval_episode/score": 0.46562498807907104, "eval_episode/reward_rate": 0.005813953488372093}
{"step": 700024, "time": 80219.43973779678, "eval_episode/length": 179.0, "eval_episode/score": 0.44062501192092896, "eval_episode/reward_rate": 0.005555555555555556}
{"step": 700024, "time": 80219.64238739014, "eval_episode/length": 95.0, "eval_episode/score": 0.703125, "eval_episode/reward_rate": 0.010416666666666666}
{"step": 700024, "time": 80220.14403629303, "eval_episode/length": 221.0, "eval_episode/score": 0.30937498807907104, "eval_episode/reward_rate": 0.0045045045045045045}
{"step": 700096, "time": 80228.30298423767, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 700104, "time": 80229.21199560165, "episode/length": 266.0, "episode/score": 0.16875000298023224, "episode/reward_rate": 0.003745318352059925, "episode/intrinsic_return": 0.0}
{"step": 700112, "time": 80230.12483787537, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 700309, "time": 80253.4381802082, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.8798198264483448, "train/action_min": 0.0, "train/action_std": 1.5893901123848135, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.006807956217307614, "train/actor_opt_grad_steps": 173590.0, "train/actor_opt_loss": -32.058204276376664, "train/adv_mag": 0.44608963257101575, "train/adv_max": 0.24769238059379195, "train/adv_mean": 0.00013653504962539997, "train/adv_min": -0.40691880412297704, "train/adv_std": 0.023533898473772557, "train/cont_avg": 0.9950146261415526, "train/cont_loss_mean": 0.01692560363505631, "train/cont_loss_std": 0.2303709762817308, "train/cont_neg_acc": 0.29643486587142726, "train/cont_neg_loss": 2.7067929985222765, "train/cont_pos_acc": 0.9999058826328957, "train/cont_pos_loss": 0.003430681630063241, "train/cont_pred": 0.9951861707587221, "train/cont_rate": 0.9950146261415526, "train/dyn_loss_mean": 1.00000018942846, "train/dyn_loss_std": 6.060040907798224e-06, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.11300215644753414, "train/extr_critic_critic_opt_grad_steps": 173590.0, "train/extr_critic_critic_opt_loss": 12102.694581192922, "train/extr_critic_mag": 0.8790609564411042, "train/extr_critic_max": 0.8790609564411042, "train/extr_critic_mean": 0.7268638303290763, "train/extr_critic_min": 0.5919022924823848, "train/extr_critic_std": 0.049996691428499135, "train/extr_return_normed_mag": 0.46819245679193433, "train/extr_return_normed_max": 0.33935640364477077, "train/extr_return_normed_mean": 0.06753435252940274, "train/extr_return_normed_min": -0.3256217761126827, "train/extr_return_normed_std": 0.05561844846361304, "train/extr_return_rate": 0.9993662300719518, "train/extr_return_raw_mag": 0.9988224073632123, "train/extr_return_raw_max": 0.9988224073632123, "train/extr_return_raw_mean": 0.7270003856589261, "train/extr_return_raw_min": 0.3338442276057587, "train/extr_return_raw_std": 0.05561844858268625, "train/extr_reward_mag": 0.3694025359741629, "train/extr_reward_max": 0.3694025359741629, "train/extr_reward_mean": 0.001302397777762298, "train/extr_reward_min": 0.0, "train/extr_reward_std": 0.00835992407891474, "train/image_loss_mean": 0.07347031441181218, "train/image_loss_std": 0.0987905553758961, "train/model_loss_mean": 0.7014230772784856, "train/model_loss_std": 0.4058563322781428, "train/model_opt_grad_norm": 10.452585777735601, "train/model_opt_grad_steps": 173440.34246575343, "train/model_opt_loss": 4611.35251788135, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 6575.342465753424, "train/policy_entropy_mag": 1.2832924905977292, "train/policy_entropy_max": 1.2832924905977292, "train/policy_entropy_mean": 0.08470084188191314, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.0973521290712705, "train/policy_logprob_mag": 6.551080287863675, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.08487298189913302, "train/policy_logprob_min": -6.551080287863675, "train/policy_logprob_std": 0.6238577967365039, "train/policy_randomness_mag": 0.6594819233297757, "train/policy_randomness_max": 0.6594819233297757, "train/policy_randomness_mean": 0.043527628443965086, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.050029100654604225, "train/post_ent_mag": 43.20686511035379, "train/post_ent_max": 43.20686511035379, "train/post_ent_mean": 42.24763006271293, "train/post_ent_min": 41.13467551801847, "train/post_ent_std": 0.4577432170033999, "train/prior_ent_mag": 43.41036217397751, "train/prior_ent_max": 43.41036217397751, "train/prior_ent_mean": 42.16558548740056, "train/prior_ent_min": 41.04581710954779, "train/prior_ent_std": 0.41186240261003854, "train/rep_loss_mean": 1.00000018942846, "train/rep_loss_std": 6.060040907798224e-06, "train/reward_avg": 0.0014767442087958605, "train/reward_loss_mean": 0.011027024001027692, "train/reward_loss_std": 0.1826906499376342, "train/reward_max_data": 0.681720891159419, "train/reward_max_pred": 0.23814178166324146, "train/reward_neg_acc": 0.9997988060184809, "train/reward_neg_loss": 0.0019446325886539571, "train/reward_pos_acc": 0.19911003380435185, "train/reward_pos_loss": 3.685754732310193, "train/reward_pred": 0.001119919218543968, "train/reward_rate": 0.0024257990867579907, "train_stats/mean_log_entropy": 0.07084219221924913, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.007634915877133608, "report/cont_loss_std": 0.11645328998565674, "report/cont_neg_acc": 0.800000011920929, "report/cont_neg_loss": 0.7322487831115723, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.00407940149307251, "report/cont_pred": 0.992253839969635, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.08257898688316345, "report/image_loss_std": 0.10173064470291138, "report/model_loss_mean": 0.692844033241272, "report/model_loss_std": 0.15989287197589874, "report/post_ent_mag": 42.94017791748047, "report/post_ent_max": 42.94017791748047, "report/post_ent_mean": 41.87778091430664, "report/post_ent_min": 40.58808517456055, "report/post_ent_std": 0.4673774838447571, "report/prior_ent_mag": 43.715518951416016, "report/prior_ent_max": 43.715518951416016, "report/prior_ent_mean": 42.187713623046875, "report/prior_ent_min": 40.971763610839844, "report/prior_ent_std": 0.4357459545135498, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0005706787342205644, "report/reward_loss_mean": 0.0026301294565200806, "report/reward_loss_std": 0.02428736723959446, "report/reward_max_data": 0.5843750238418579, "report/reward_max_pred": 0.5836114883422852, "report/reward_neg_acc": 0.9990224838256836, "report/reward_neg_loss": 0.0023599539417773485, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.27901968359947205, "report/reward_pred": 0.0015301727689802647, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.027607377618551254, "eval/cont_loss_std": 0.4170621335506439, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.850035667419434, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.004774324130266905, "eval/cont_pred": 0.9952200651168823, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.13292589783668518, "eval/image_loss_std": 0.13895639777183533, "eval/model_loss_mean": 0.7760747671127319, "eval/model_loss_std": 0.6332865357398987, "eval/post_ent_mag": 42.96269989013672, "eval/post_ent_max": 42.96269989013672, "eval/post_ent_mean": 42.10071563720703, "eval/post_ent_min": 40.988670349121094, "eval/post_ent_std": 0.4383417069911957, "eval/prior_ent_mag": 43.416351318359375, "eval/prior_ent_max": 43.416351318359375, "eval/prior_ent_mean": 42.34950256347656, "eval/prior_ent_min": 41.21998596191406, "eval/prior_ent_std": 0.41341692209243774, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0020324706565588713, "eval/reward_loss_mean": 0.015541409142315388, "eval/reward_loss_std": 0.25218525528907776, "eval/reward_max_data": 0.746874988079071, "eval/reward_max_pred": 0.03442645072937012, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0022300616838037968, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 4.545836448669434, "eval/reward_pred": 0.0010554203763604164, "eval/reward_rate": 0.0029296875, "replay/size": 699805.0, "replay/inserts": 8776.0, "replay/samples": 35104.0, "replay/insert_wait_avg": 1.5127734911909077e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.202205271099303e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 1776.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 9.76898648717382e-07, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.08970832824707e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1901643276215, "timer/env.step_count": 1097.0, "timer/env.step_total": 10.703034400939941, "timer/env.step_frac": 0.010700999452574165, "timer/env.step_avg": 0.009756640292561477, "timer/env.step_min": 0.008548498153686523, "timer/env.step_max": 0.035141706466674805, "timer/replay._sample_count": 35104.0, "timer/replay._sample_total": 18.160283088684082, "timer/replay._sample_frac": 0.018156830307256965, "timer/replay._sample_avg": 0.0005173280278225866, "timer/replay._sample_min": 0.00041294097900390625, "timer/replay._sample_max": 0.033828020095825195, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1319.0, "timer/agent.policy_total": 13.707720279693604, "timer/agent.policy_frac": 0.01370511405589419, "timer/agent.policy_avg": 0.010392509688926159, "timer/agent.policy_min": 0.008707046508789062, "timer/agent.policy_max": 0.08168649673461914, "timer/dataset_train_count": 2194.0, "timer/dataset_train_total": 0.37482309341430664, "timer/dataset_train_frac": 0.00037475182898472287, "timer/dataset_train_avg": 0.00017084006080870858, "timer/dataset_train_min": 8.916854858398438e-05, "timer/dataset_train_max": 0.0006041526794433594, "timer/agent.train_count": 2194.0, "timer/agent.train_total": 970.7761540412903, "timer/agent.train_frac": 0.9705915821456765, "timer/agent.train_avg": 0.4424686208027759, "timer/agent.train_min": 0.42960596084594727, "timer/agent.train_max": 2.1106960773468018, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4741535186767578, "timer/agent.report_frac": 0.00047406336873499235, "timer/agent.report_avg": 0.2370767593383789, "timer/agent.report_min": 0.23142194747924805, "timer/agent.report_max": 0.24273157119750977, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0040740966796875e-05, "timer/dataset_eval_frac": 3.003502937563057e-08, "timer/dataset_eval_avg": 3.0040740966796875e-05, "timer/dataset_eval_min": 3.0040740966796875e-05, "timer/dataset_eval_max": 3.0040740966796875e-05, "fps": 8.774213022757356}
{"step": 700328, "time": 80255.42630171776, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 700936, "time": 80324.40118169785, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 701032, "time": 80335.22972559929, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 701200, "time": 80354.19862890244, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 701440, "time": 80381.31764626503, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 701536, "time": 80392.13528895378, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 701632, "time": 80402.95978999138, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.0}
{"step": 701784, "time": 80420.22769618034, "episode/length": 209.0, "episode/score": 0.34687501192092896, "episode/reward_rate": 0.004761904761904762, "episode/intrinsic_return": 0.0}
{"step": 701856, "time": 80428.3602142334, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 701952, "time": 80439.18539404869, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 702112, "time": 80457.33137440681, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 702384, "time": 80488.12096786499, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 702488, "time": 80499.85406255722, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 702648, "time": 80517.99970173836, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 702648, "time": 80518.0267663002, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 703328, "time": 80594.99008846283, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 703488, "time": 80613.04851961136, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 703512, "time": 80615.74708914757, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 703848, "time": 80653.7612888813, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 703872, "time": 80656.4647974968, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 703912, "time": 80660.98069024086, "episode/length": 224.0, "episode/score": 0.30000001192092896, "episode/reward_rate": 0.0044444444444444444, "episode/intrinsic_return": 0.0}
{"step": 704088, "time": 80680.82482409477, "episode/length": 287.0, "episode/score": 0.10312499850988388, "episode/reward_rate": 0.003472222222222222, "episode/intrinsic_return": 0.0}
{"step": 704128, "time": 80685.39414310455, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 704408, "time": 80717.02996706963, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 704520, "time": 80730.02839398384, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 704600, "time": 80739.0660135746, "episode/length": 263.0, "episode/score": 0.17812499403953552, "episode/reward_rate": 0.003787878787878788, "episode/intrinsic_return": 0.0}
{"step": 704896, "time": 80772.6073884964, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 704904, "time": 80773.51488423347, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 704968, "time": 80780.76530575752, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 705552, "time": 80846.73428606987, "episode/length": 212.0, "episode/score": 0.3375000059604645, "episode/reward_rate": 0.004694835680751174, "episode/intrinsic_return": 0.0}
{"step": 705592, "time": 80851.2442035675, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 705784, "time": 80873.00879740715, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 705784, "time": 80873.02996778488, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 705952, "time": 80892.04286789894, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 706112, "time": 80910.08640170097, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 706152, "time": 80914.59975409508, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 706304, "time": 80931.77449250221, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 706344, "time": 80936.28107833862, "episode/length": 4.0, "episode/score": 0.987500011920929, "episode/reward_rate": 0.2, "episode/intrinsic_return": 0.0}
{"step": 706440, "time": 80947.10469603539, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 706528, "time": 80957.1269621849, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 706544, "time": 80958.93087720871, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 706784, "time": 80986.23257684708, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 707120, "time": 81024.30911374092, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 707208, "time": 81034.2351436615, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 707296, "time": 81044.20664811134, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 707488, "time": 81065.88310956955, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 707640, "time": 81083.16316127777, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 707880, "time": 81110.38393545151, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 708072, "time": 81132.11135840416, "episode/length": 203.0, "episode/score": 0.3656249940395355, "episode/reward_rate": 0.004901960784313725, "episode/intrinsic_return": 0.0}
{"step": 708184, "time": 81144.74000954628, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 708472, "time": 81177.24004149437, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 708840, "time": 81218.84078741074, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 709008, "time": 81237.84892392159, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 709056, "time": 81243.26366591454, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 709141, "time": 81253.78994894028, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.886698589066035, "train/action_min": 0.0, "train/action_std": 1.5917705421534059, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.006583678115757679, "train/actor_opt_grad_steps": 175790.0, "train/actor_opt_loss": -25.039896965026855, "train/adv_mag": 0.45674043489257676, "train/adv_max": 0.23782080007354597, "train/adv_mean": 0.0014828360272839307, "train/adv_min": -0.4217720470007728, "train/adv_std": 0.021446160601275, "train/cont_avg": 0.9954574377828054, "train/cont_loss_mean": 0.01575061604296325, "train/cont_loss_std": 0.21438099212556808, "train/cont_neg_acc": 0.26884380026974464, "train/cont_neg_loss": 2.667801403245407, "train/cont_pos_acc": 0.9999067794143884, "train/cont_pos_loss": 0.0035262224506755354, "train/cont_pred": 0.9952969427022459, "train/cont_rate": 0.9954574377828054, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.10359704216343785, "train/extr_critic_critic_opt_grad_steps": 175790.0, "train/extr_critic_critic_opt_loss": 12347.167213129242, "train/extr_critic_mag": 0.9162129179924322, "train/extr_critic_max": 0.9162129179924322, "train/extr_critic_mean": 0.752192332464106, "train/extr_critic_min": 0.6298763611737419, "train/extr_critic_std": 0.03956566713076102, "train/extr_return_normed_mag": 0.4820756785470436, "train/extr_return_normed_max": 0.32747535144581513, "train/extr_return_normed_mean": 0.059944680070175844, "train/extr_return_normed_min": -0.3504143953323364, "train/extr_return_normed_std": 0.04493557524391159, "train/extr_return_rate": 0.9993861074900735, "train/extr_return_raw_mag": 1.0212058139063114, "train/extr_return_raw_max": 1.0212058139063114, "train/extr_return_raw_mean": 0.7536751827503222, "train/extr_return_raw_min": 0.3433160671281599, "train/extr_return_raw_std": 0.044935575176485526, "train/extr_reward_mag": 0.38990425632010756, "train/extr_reward_max": 0.38990425632010756, "train/extr_reward_mean": 0.0013386065870464455, "train/extr_reward_min": -1.4564030850095446e-08, "train/extr_reward_std": 0.008345315841814646, "train/image_loss_mean": 0.07300963480345804, "train/image_loss_std": 0.0976690981385395, "train/model_loss_mean": 0.6997768442015843, "train/model_loss_std": 0.391331163635351, "train/model_opt_grad_norm": 10.398318648877726, "train/model_opt_grad_steps": 175638.39366515836, "train/model_opt_loss": 4096.766303291148, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5859.72850678733, "train/policy_entropy_mag": 1.2711545274807856, "train/policy_entropy_max": 1.2711545274807856, "train/policy_entropy_mean": 0.08257622254919682, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.09190602654515348, "train/policy_logprob_mag": 6.551080280839049, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.08229346721690164, "train/policy_logprob_min": -6.551080280839049, "train/policy_logprob_std": 0.6191697846171004, "train/policy_randomness_mag": 0.6532442437577571, "train/policy_randomness_max": 0.6532442437577571, "train/policy_randomness_mean": 0.04243579046691165, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.04723035743063931, "train/post_ent_mag": 42.86720527890581, "train/post_ent_max": 42.86720527890581, "train/post_ent_mean": 41.793265623204846, "train/post_ent_min": 40.55308572415313, "train/post_ent_std": 0.5065927804864909, "train/prior_ent_mag": 43.34083056557772, "train/prior_ent_max": 43.34083056557772, "train/prior_ent_mean": 42.025329866020925, "train/prior_ent_min": 40.64175466822283, "train/prior_ent_std": 0.46940168455175685, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0014339119034747665, "train/reward_loss_mean": 0.011016571796309558, "train/reward_loss_std": 0.1795524595478103, "train/reward_max_data": 0.6811368767492372, "train/reward_max_pred": 0.23915722197536968, "train/reward_neg_acc": 0.9998095280983869, "train/reward_neg_loss": 0.002045011182096513, "train/reward_pos_acc": 0.18767170522075433, "train/reward_pos_loss": 3.606937582676227, "train/reward_pred": 0.0011846486666572714, "train/reward_rate": 0.0024612910067873302, "train_stats/mean_log_entropy": 0.07178676942432369, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.008160416968166828, "report/cont_loss_std": 0.15339121222496033, "report/cont_neg_acc": 0.3333333432674408, "report/cont_neg_loss": 1.9856719970703125, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.00234990194439888, "report/cont_pred": 0.9964544773101807, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.051156848669052124, "report/image_loss_std": 0.08531035482883453, "report/model_loss_mean": 0.6604531407356262, "report/model_loss_std": 0.17607776820659637, "report/post_ent_mag": 42.42543029785156, "report/post_ent_max": 42.42543029785156, "report/post_ent_mean": 41.17662811279297, "report/post_ent_min": 40.030967712402344, "report/post_ent_std": 0.5058858394622803, "report/prior_ent_mag": 43.30543899536133, "report/prior_ent_max": 43.30543899536133, "report/prior_ent_mean": 41.78642272949219, "report/prior_ent_min": 40.57545852661133, "report/prior_ent_std": 0.4705636203289032, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.0011358677875250578, "report/reward_loss_std": 0.007706792559474707, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.05395698547363281, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0011358677875250578, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0004848235985264182, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.022494569420814514, "eval/cont_loss_std": 0.37478742003440857, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.514615058898926, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.003418797394260764, "eval/cont_pred": 0.9966973066329956, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.11724619567394257, "eval/image_loss_std": 0.14189375936985016, "eval/model_loss_mean": 0.7566491365432739, "eval/model_loss_std": 0.7219592928886414, "eval/post_ent_mag": 42.46416091918945, "eval/post_ent_max": 42.46416091918945, "eval/post_ent_mean": 41.32514572143555, "eval/post_ent_min": 39.959815979003906, "eval/post_ent_std": 0.5603578686714172, "eval/prior_ent_mag": 43.165191650390625, "eval/prior_ent_max": 43.165191650390625, "eval/prior_ent_mean": 41.910614013671875, "eval/prior_ent_min": 40.468284606933594, "eval/prior_ent_std": 0.5056170225143433, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0010711669456213713, "eval/reward_loss_mean": 0.016908403486013412, "eval/reward_loss_std": 0.3393973410129547, "eval/reward_max_data": 0.578125, "eval/reward_max_pred": 0.15760409832000732, "eval/reward_neg_acc": 0.9990215301513672, "eval/reward_neg_loss": 0.002371627138927579, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 7.4452009201049805, "eval/reward_pred": 0.0009759924141690135, "eval/reward_rate": 0.001953125, "replay/size": 708637.0, "replay/inserts": 8832.0, "replay/samples": 35328.0, "replay/insert_wait_avg": 1.501264995422916e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.2356340461883e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 9.238719940185547e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3374400138855, "timer/env.step_count": 1104.0, "timer/env.step_total": 10.831365823745728, "timer/env.step_frac": 0.010827712120417466, "timer/env.step_avg": 0.009811019767885622, "timer/env.step_min": 0.008561372756958008, "timer/env.step_max": 0.049272775650024414, "timer/replay._sample_count": 35328.0, "timer/replay._sample_total": 18.282546997070312, "timer/replay._sample_frac": 0.018276379815211692, "timer/replay._sample_avg": 0.0005175086899080138, "timer/replay._sample_min": 0.0003662109375, "timer/replay._sample_max": 0.02271270751953125, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1104.0, "timer/agent.policy_total": 11.301721096038818, "timer/agent.policy_frac": 0.01129790872956024, "timer/agent.policy_avg": 0.01023706621018009, "timer/agent.policy_min": 0.00945591926574707, "timer/agent.policy_max": 0.035250186920166016, "timer/dataset_train_count": 2208.0, "timer/dataset_train_total": 0.37659764289855957, "timer/dataset_train_frac": 0.0003764706066518235, "timer/dataset_train_avg": 0.00017056052667507228, "timer/dataset_train_min": 8.988380432128906e-05, "timer/dataset_train_max": 0.0011925697326660156, "timer/agent.train_count": 2208.0, "timer/agent.train_total": 975.2357637882233, "timer/agent.train_frac": 0.9749067912270546, "timer/agent.train_avg": 0.4416828640345214, "timer/agent.train_min": 0.4314846992492676, "timer/agent.train_max": 0.5765988826751709, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4775960445404053, "timer/agent.report_frac": 0.0004774349388879975, "timer/agent.report_avg": 0.23879802227020264, "timer/agent.report_min": 0.2315666675567627, "timer/agent.report_max": 0.24602937698364258, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0040740966796875e-05, "timer/dataset_eval_frac": 3.0030607438205934e-08, "timer/dataset_eval_avg": 3.0040740966796875e-05, "timer/dataset_eval_min": 3.0040740966796875e-05, "timer/dataset_eval_max": 3.0040740966796875e-05, "fps": 8.828902557530958}
{"step": 709424, "time": 81285.67487764359, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 709432, "time": 81286.5850558281, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 709440, "time": 81287.51957917213, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 709608, "time": 81306.58007335663, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 709664, "time": 81313.0480902195, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 709664, "time": 81313.05691075325, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 709736, "time": 81321.22265958786, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 709864, "time": 81335.71327877045, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 709952, "time": 81345.79660606384, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 709968, "time": 81347.62818098068, "episode/length": 222.0, "episode/score": 0.3062500059604645, "episode/reward_rate": 0.004484304932735426, "episode/intrinsic_return": 0.0}
{"step": 710008, "time": 81353.12089371681, "eval_episode/length": 56.0, "eval_episode/score": 0.824999988079071, "eval_episode/reward_rate": 0.017543859649122806}
{"step": 710008, "time": 81353.12533092499, "eval_episode/length": 56.0, "eval_episode/score": 0.824999988079071, "eval_episode/reward_rate": 0.017543859649122806}
{"step": 710008, "time": 81354.56897163391, "eval_episode/length": 142.0, "eval_episode/score": 0.5562499761581421, "eval_episode/reward_rate": 0.006993006993006993}
{"step": 710008, "time": 81354.61036252975, "eval_episode/length": 144.0, "eval_episode/score": 0.550000011920929, "eval_episode/reward_rate": 0.006896551724137931}
{"step": 710008, "time": 81354.63216471672, "eval_episode/length": 145.0, "eval_episode/score": 0.546875, "eval_episode/reward_rate": 0.00684931506849315}
{"step": 710008, "time": 81354.67053437233, "eval_episode/length": 90.0, "eval_episode/score": 0.71875, "eval_episode/reward_rate": 0.01098901098901099}
{"step": 710008, "time": 81355.27667737007, "eval_episode/length": 181.0, "eval_episode/score": 0.43437498807907104, "eval_episode/reward_rate": 0.005494505494505495}
{"step": 710008, "time": 81355.85480237007, "eval_episode/length": 214.0, "eval_episode/score": 0.33125001192092896, "eval_episode/reward_rate": 0.004651162790697674}
{"step": 710272, "time": 81385.76916456223, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 710640, "time": 81427.56357979774, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 710808, "time": 81446.6284339428, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 710840, "time": 81450.26906657219, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 710920, "time": 81459.35461425781, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 711112, "time": 81481.19523835182, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 711888, "time": 81569.3366920948, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 711920, "time": 81572.97095227242, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 711976, "time": 81579.3309545517, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 712048, "time": 81587.63467168808, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 712176, "time": 81602.1211297512, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 712200, "time": 81604.85170221329, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 712352, "time": 81622.11602258682, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 712592, "time": 81649.41800093651, "episode/length": 218.0, "episode/score": 0.3187499940395355, "episode/reward_rate": 0.0045662100456621, "episode/intrinsic_return": 0.0}
{"step": 712840, "time": 81677.93212485313, "episode/length": 274.0, "episode/score": 0.14374999701976776, "episode/reward_rate": 0.0036363636363636364, "episode/intrinsic_return": 0.0}
{"step": 713120, "time": 81709.71355104446, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 713160, "time": 81714.24343442917, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 713400, "time": 81741.41850852966, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 713560, "time": 81759.49681687355, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 713672, "time": 81772.18338418007, "episode/length": 222.0, "episode/score": 0.3062500059604645, "episode/reward_rate": 0.004484304932735426, "episode/intrinsic_return": 0.0}
{"step": 714152, "time": 81826.71174669266, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 714200, "time": 81832.17510581017, "episode/length": 284.0, "episode/score": 0.11249999701976776, "episode/reward_rate": 0.0035087719298245615, "episode/intrinsic_return": 0.0}
{"step": 714488, "time": 81864.86848640442, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 714656, "time": 81884.01991391182, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 714904, "time": 81912.19304442406, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 715152, "time": 81940.3233602047, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 715224, "time": 81948.5542383194, "episode/length": 227.0, "episode/score": 0.2906250059604645, "episode/reward_rate": 0.0043859649122807015, "episode/intrinsic_return": 0.0}
{"step": 715592, "time": 81990.24777817726, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 715928, "time": 82028.30804896355, "episode/length": 215.0, "episode/score": 0.328125, "episode/reward_rate": 0.004629629629629629, "episode/intrinsic_return": 0.0}
{"step": 715984, "time": 82034.70570373535, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 716104, "time": 82048.2696697712, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 716192, "time": 82058.24144601822, "episode/length": 191.0, "episode/score": 0.40312498807907104, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.0}
{"step": 716352, "time": 82076.40935921669, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 716400, "time": 82081.86615180969, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 716464, "time": 82089.11942267418, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 716488, "time": 82091.92978715897, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 716656, "time": 82111.00691127777, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 716816, "time": 82129.20294165611, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 716856, "time": 82133.73989701271, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 717312, "time": 82185.32296490669, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 717312, "time": 82185.33124232292, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 717496, "time": 82206.14417982101, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 717776, "time": 82237.96066045761, "episode/length": 208.0, "episode/score": 0.3499999940395355, "episode/reward_rate": 0.004784688995215311, "episode/intrinsic_return": 0.0}
{"step": 717904, "time": 82252.53854894638, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 717909, "time": 82253.97972655296, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.856873394691781, "train/action_min": 0.0, "train/action_std": 1.5938500209486104, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.007166669246863965, "train/actor_opt_grad_steps": 177990.0, "train/actor_opt_loss": -26.219287968117353, "train/adv_mag": 0.4520853812291742, "train/adv_max": 0.23988434631530553, "train/adv_mean": 0.00014731440824439503, "train/adv_min": -0.408805317530349, "train/adv_std": 0.022082463098205114, "train/cont_avg": 0.9950770547945206, "train/cont_loss_mean": 0.01676082486269749, "train/cont_loss_std": 0.22472729855408408, "train/cont_neg_acc": 0.2925520900482406, "train/cont_neg_loss": 2.647093196658628, "train/cont_pos_acc": 0.9998969710580835, "train/cont_pos_loss": 0.003450460916440339, "train/cont_pred": 0.9952350231610476, "train/cont_rate": 0.9950770547945206, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.10553645695555428, "train/extr_critic_critic_opt_grad_steps": 177990.0, "train/extr_critic_critic_opt_loss": 10615.584555151256, "train/extr_critic_mag": 0.9801820140995391, "train/extr_critic_max": 0.9801820140995391, "train/extr_critic_mean": 0.7974892925454057, "train/extr_critic_min": 0.6720180397164331, "train/extr_critic_std": 0.041437803686821845, "train/extr_return_normed_mag": 0.4865278136240293, "train/extr_return_normed_max": 0.3458663007440088, "train/extr_return_normed_mean": 0.05587809628139348, "train/extr_return_normed_min": -0.32495510142687795, "train/extr_return_normed_std": 0.047658689702822735, "train/extr_return_rate": 0.9994221155501936, "train/extr_return_raw_mag": 1.0876247744037681, "train/extr_return_raw_max": 1.0876247744037681, "train/extr_return_raw_mean": 0.797636609099227, "train/extr_return_raw_min": 0.41680337223288133, "train/extr_return_raw_std": 0.04765868958374953, "train/extr_reward_mag": 0.37387002276503334, "train/extr_reward_max": 0.37387002276503334, "train/extr_reward_mean": 0.0012994303124038223, "train/extr_reward_min": 0.0, "train/extr_reward_std": 0.008701034998053421, "train/image_loss_mean": 0.07360684296720105, "train/image_loss_std": 0.09831365749035796, "train/model_loss_mean": 0.7014052911436177, "train/model_loss_std": 0.3970468519893411, "train/model_opt_grad_norm": 10.326125453051912, "train/model_opt_grad_steps": 177836.97716894976, "train/model_opt_loss": 4570.01125610909, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 6506.8493150684935, "train/policy_entropy_mag": 1.2370599002054292, "train/policy_entropy_max": 1.2370599002054292, "train/policy_entropy_mean": 0.08087885675773229, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.08776389722410402, "train/policy_logprob_mag": 6.551080276976982, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.08064430843205213, "train/policy_logprob_min": -6.551080276976982, "train/policy_logprob_std": 0.617129056693212, "train/policy_randomness_mag": 0.6357230682895608, "train/policy_randomness_max": 0.6357230682895608, "train/policy_randomness_mean": 0.04156351686544614, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.04510172410574678, "train/post_ent_mag": 42.9315348585991, "train/post_ent_max": 42.9315348585991, "train/post_ent_mean": 41.90155879329873, "train/post_ent_min": 40.675113364441756, "train/post_ent_std": 0.494997276699162, "train/prior_ent_mag": 43.21653141387522, "train/prior_ent_max": 43.21653141387522, "train/prior_ent_mean": 41.89068580871303, "train/prior_ent_min": 40.38501567056734, "train/prior_ent_std": 0.5015616059031116, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.00143270971562892, "train/reward_loss_mean": 0.01103760050099394, "train/reward_loss_std": 0.17927453761546103, "train/reward_max_data": 0.6495433802201868, "train/reward_max_pred": 0.23985213993891188, "train/reward_neg_acc": 0.9997854728132622, "train/reward_neg_loss": 0.002022066830548981, "train/reward_pos_acc": 0.1818599735598753, "train/reward_pos_loss": 3.6192688617375817, "train/reward_pred": 0.001143698711862541, "train/reward_rate": 0.002461472602739726, "train_stats/mean_log_entropy": 0.06909584281621156, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.025097988545894623, "report/cont_loss_std": 0.34268996119499207, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.337961196899414, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0042632268741726875, "report/cont_pred": 0.9958346486091614, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.0626278668642044, "report/image_loss_std": 0.08550133556127548, "report/model_loss_mean": 0.6944534778594971, "report/model_loss_std": 0.41653329133987427, "report/post_ent_mag": 43.15789031982422, "report/post_ent_max": 43.15789031982422, "report/post_ent_mean": 42.24848175048828, "report/post_ent_min": 40.84812927246094, "report/post_ent_std": 0.47059008479118347, "report/prior_ent_mag": 43.25867462158203, "report/prior_ent_max": 43.25867462158203, "report/prior_ent_mean": 41.97560501098633, "report/prior_ent_min": 40.13457489013672, "report/prior_ent_std": 0.5174020528793335, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0007568359142169356, "report/reward_loss_mean": 0.006727553904056549, "report/reward_loss_std": 0.13142119348049164, "report/reward_max_data": 0.7749999761581421, "report/reward_max_pred": 0.07717311382293701, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0026376775931566954, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.190670967102051, "report/reward_pred": 0.0012307938886806369, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.024391941726207733, "eval/cont_loss_std": 0.4280824065208435, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.188851356506348, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.004139159340411425, "eval/cont_pred": 0.9957413673400879, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.12016107141971588, "eval/image_loss_std": 0.11982768028974533, "eval/model_loss_mean": 0.758245050907135, "eval/model_loss_std": 0.5659356713294983, "eval/post_ent_mag": 43.14825439453125, "eval/post_ent_max": 43.14825439453125, "eval/post_ent_mean": 42.29378890991211, "eval/post_ent_min": 41.09454345703125, "eval/post_ent_std": 0.4368992745876312, "eval/prior_ent_mag": 43.18153381347656, "eval/prior_ent_max": 43.18153381347656, "eval/prior_ent_mean": 42.031185150146484, "eval/prior_ent_min": 40.52299499511719, "eval/prior_ent_std": 0.4473053514957428, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0019378662109375, "eval/reward_loss_mean": 0.013691989704966545, "eval/reward_loss_std": 0.2046036571264267, "eval/reward_max_data": 0.8687499761581421, "eval/reward_max_pred": 0.043024301528930664, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0026949048042297363, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 3.756366729736328, "eval/reward_pred": 0.0013112463057041168, "eval/reward_rate": 0.0029296875, "replay/size": 717405.0, "replay/inserts": 8768.0, "replay/samples": 35072.0, "replay/insert_wait_avg": 1.5206526230721578e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.28287455374307e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 1720.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 9.890212569125863e-07, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.5367431640625e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1768233776093, "timer/env.step_count": 1096.0, "timer/env.step_total": 10.708846092224121, "timer/env.step_frac": 0.010706952852656812, "timer/env.step_avg": 0.009770844974657045, "timer/env.step_min": 0.008545637130737305, "timer/env.step_max": 0.03436088562011719, "timer/replay._sample_count": 35072.0, "timer/replay._sample_total": 18.32350778579712, "timer/replay._sample_frac": 0.01832026833407158, "timer/replay._sample_avg": 0.0005224540313012409, "timer/replay._sample_min": 0.00041413307189941406, "timer/replay._sample_max": 0.024708032608032227, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1311.0, "timer/agent.policy_total": 13.226773738861084, "timer/agent.policy_frac": 0.013224435349535603, "timer/agent.policy_avg": 0.010089072264577486, "timer/agent.policy_min": 0.008767366409301758, "timer/agent.policy_max": 0.03612112998962402, "timer/dataset_train_count": 2192.0, "timer/dataset_train_total": 0.38046765327453613, "timer/dataset_train_frac": 0.00038040038959280445, "timer/dataset_train_avg": 0.00017357100970553655, "timer/dataset_train_min": 9.298324584960938e-05, "timer/dataset_train_max": 0.0005962848663330078, "timer/agent.train_count": 2192.0, "timer/agent.train_total": 971.5597901344299, "timer/agent.train_frac": 0.9713880260226994, "timer/agent.train_avg": 0.4432298312657071, "timer/agent.train_min": 0.4329984188079834, "timer/agent.train_max": 0.5819108486175537, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4783477783203125, "timer/agent.report_frac": 0.000478263210204098, "timer/agent.report_avg": 0.23917388916015625, "timer/agent.report_min": 0.2324376106262207, "timer/agent.report_max": 0.2459101676940918, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.218650817871094e-05, "timer/dataset_eval_frac": 3.218081785780309e-08, "timer/dataset_eval_avg": 3.218650817871094e-05, "timer/dataset_eval_min": 3.218650817871094e-05, "timer/dataset_eval_max": 3.218650817871094e-05, "fps": 8.766310356580952}
{"step": 717952, "time": 82258.65532326698, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 717968, "time": 82260.48213982582, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 718192, "time": 82285.8488805294, "episode/length": 191.0, "episode/score": 0.40312498807907104, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.0}
{"step": 718240, "time": 82291.3271496296, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 718568, "time": 82328.73328375816, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 718592, "time": 82331.50208950043, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 718728, "time": 82346.93995261192, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 719168, "time": 82396.78307151794, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 719864, "time": 82475.90661048889, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 720032, "time": 82494.94835090637, "episode/length": 223.0, "episode/score": 0.3031249940395355, "episode/reward_rate": 0.004464285714285714, "episode/intrinsic_return": 0.0}
{"step": 720088, "time": 82501.30830407143, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 720096, "time": 82502.77699303627, "eval_episode/length": 32.0, "eval_episode/score": 0.8999999761581421, "eval_episode/reward_rate": 0.030303030303030304}
{"step": 720096, "time": 82503.10250997543, "eval_episode/length": 51.0, "eval_episode/score": 0.840624988079071, "eval_episode/reward_rate": 0.019230769230769232}
{"step": 720096, "time": 82503.63714408875, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 720096, "time": 82504.1523296833, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 720096, "time": 82504.25915527344, "eval_episode/length": 118.0, "eval_episode/score": 0.6312500238418579, "eval_episode/reward_rate": 0.008403361344537815}
{"step": 720096, "time": 82504.68621850014, "eval_episode/length": 60.0, "eval_episode/score": 0.8125, "eval_episode/reward_rate": 0.01639344262295082}
{"step": 720096, "time": 82505.36361646652, "eval_episode/length": 183.0, "eval_episode/score": 0.4281249940395355, "eval_episode/reward_rate": 0.005434782608695652}
{"step": 720096, "time": 82506.25356817245, "eval_episode/length": 51.0, "eval_episode/score": 0.840624988079071, "eval_episode/reward_rate": 0.019230769230769232}
{"step": 720216, "time": 82519.89800477028, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 720280, "time": 82527.13967752457, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 720304, "time": 82529.8444712162, "episode/length": 213.0, "episode/score": 0.3343749940395355, "episode/reward_rate": 0.004672897196261682, "episode/intrinsic_return": 0.0}
{"step": 720664, "time": 82570.67645931244, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 720720, "time": 82577.14111876488, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 720760, "time": 82581.67356133461, "episode/length": 198.0, "episode/score": 0.3812499940395355, "episode/reward_rate": 0.005025125628140704, "episode/intrinsic_return": 0.0}
{"step": 720800, "time": 82586.20084667206, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 720856, "time": 82592.51680374146, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 720880, "time": 82595.24561214447, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 720904, "time": 82598.32834506035, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 720984, "time": 82607.45596432686, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 721064, "time": 82616.5310075283, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 721472, "time": 82662.84691047668, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 721480, "time": 82663.77540016174, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 721520, "time": 82668.31595897675, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 721992, "time": 82722.11870360374, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 722048, "time": 82728.51722955704, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 722376, "time": 82765.83332395554, "episode/length": 285.0, "episode/score": 0.109375, "episode/reward_rate": 0.0034965034965034965, "episode/intrinsic_return": 0.0}
{"step": 722464, "time": 82775.80350232124, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 722512, "time": 82781.31669306755, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 722680, "time": 82800.31625676155, "episode/length": 234.0, "episode/score": 0.26875001192092896, "episode/reward_rate": 0.00425531914893617, "episode/intrinsic_return": 0.0}
{"step": 723072, "time": 82844.8802921772, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 723424, "time": 82884.67071580887, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 723456, "time": 82888.28816509247, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 723488, "time": 82891.91250371933, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 723568, "time": 82900.9983394146, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 723792, "time": 82926.33477568626, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 723832, "time": 82930.88846111298, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 724072, "time": 82958.04179739952, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 724144, "time": 82966.24344277382, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 724208, "time": 82973.46364974976, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 724320, "time": 82986.10801124573, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 724472, "time": 83003.33326148987, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 724552, "time": 83012.38260889053, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 724776, "time": 83037.79807949066, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 725160, "time": 83081.46858811378, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 725160, "time": 83081.47515583038, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 725288, "time": 83095.97676444054, "episode/length": 228.0, "episode/score": 0.2874999940395355, "episode/reward_rate": 0.004366812227074236, "episode/intrinsic_return": 0.0}
{"step": 725304, "time": 83097.77778458595, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 725384, "time": 83106.87741303444, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 725872, "time": 83162.29360175133, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 725944, "time": 83170.47331500053, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 726384, "time": 83220.40831542015, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 726624, "time": 83247.5790758133, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 726632, "time": 83248.49008369446, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 726673, "time": 83253.9988746643, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.8362644143300515, "train/action_min": 0.0, "train/action_std": 1.5914240269900457, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.007288921411791349, "train/actor_opt_grad_steps": 180180.0, "train/actor_opt_loss": -29.28064089387519, "train/adv_mag": 0.4696492000257588, "train/adv_max": 0.23793783824737758, "train/adv_mean": 0.00044710418836627747, "train/adv_min": -0.43124977557082156, "train/adv_std": 0.023465893529015316, "train/cont_avg": 0.9951350242579908, "train/cont_loss_mean": 0.01664964531837499, "train/cont_loss_std": 0.22327612830351476, "train/cont_neg_acc": 0.28489889510690347, "train/cont_neg_loss": 2.6854842354556263, "train/cont_pos_acc": 0.9999103894516758, "train/cont_pos_loss": 0.003508772192837577, "train/cont_pred": 0.9951842465357149, "train/cont_rate": 0.9951350242579908, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.09977344870907531, "train/extr_critic_critic_opt_grad_steps": 180180.0, "train/extr_critic_critic_opt_loss": 10581.242655714897, "train/extr_critic_mag": 0.9796324347796506, "train/extr_critic_max": 0.9796324347796506, "train/extr_critic_mean": 0.7950462562852798, "train/extr_critic_min": 0.6613096488665228, "train/extr_critic_std": 0.04509607425223203, "train/extr_return_normed_mag": 0.5050874412331952, "train/extr_return_normed_max": 0.3454516883854452, "train/extr_return_normed_mean": 0.06382547916002469, "train/extr_return_normed_min": -0.35598918754760533, "train/extr_return_normed_std": 0.051573135656172824, "train/extr_return_rate": 0.9993486869825076, "train/extr_return_raw_mag": 1.0771195363236346, "train/extr_return_raw_max": 1.0771195363236346, "train/extr_return_raw_mean": 0.7954933670557798, "train/extr_return_raw_min": 0.37567866066275124, "train/extr_return_raw_std": 0.05157313563916237, "train/extr_reward_mag": 0.352331347117141, "train/extr_reward_max": 0.352331347117141, "train/extr_reward_mean": 0.0013794359967929043, "train/extr_reward_min": -1.5241370353524543e-08, "train/extr_reward_std": 0.008604416718332258, "train/image_loss_mean": 0.07326853219164561, "train/image_loss_std": 0.09775916248832119, "train/model_loss_mean": 0.7016367185605715, "train/model_loss_std": 0.4085852225485458, "train/model_opt_grad_norm": 9.88567331392471, "train/model_opt_grad_steps": 180025.54337899544, "train/model_opt_loss": 4657.766599332906, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 6643.835616438356, "train/policy_entropy_mag": 1.2847485378996966, "train/policy_entropy_max": 1.2847485378996966, "train/policy_entropy_mean": 0.08356534720283665, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.09463399498974352, "train/policy_logprob_mag": 6.55108026391295, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.08322093098267028, "train/policy_logprob_min": -6.55108026391295, "train/policy_logprob_std": 0.6202635250679435, "train/policy_randomness_mag": 0.6602301831659116, "train/policy_randomness_max": 0.6602301831659116, "train/policy_randomness_mean": 0.04294409934584409, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.048632256142352816, "train/post_ent_mag": 42.933915978697335, "train/post_ent_max": 42.933915978697335, "train/post_ent_mean": 41.78459869454441, "train/post_ent_min": 40.399638763845786, "train/post_ent_std": 0.5598866976287267, "train/prior_ent_mag": 43.23627149677712, "train/prior_ent_max": 43.23627149677712, "train/prior_ent_mean": 41.892101113654704, "train/prior_ent_min": 40.413743807300584, "train/prior_ent_std": 0.502504338548608, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0015364555476156817, "train/reward_loss_mean": 0.011718515588446908, "train/reward_loss_std": 0.18981284993279673, "train/reward_max_data": 0.6836615293265478, "train/reward_max_pred": 0.20672668387356413, "train/reward_neg_acc": 0.999803349307683, "train/reward_neg_loss": 0.0020731842258549615, "train/reward_pos_acc": 0.16217948883198774, "train/reward_pos_loss": 3.7267375768950353, "train/reward_pred": 0.001175069101324909, "train/reward_rate": 0.002586329908675799, "train_stats/mean_log_entropy": 0.07095698480095182, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.017431756481528282, "report/cont_loss_std": 0.19866132736206055, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 3.10713529586792, "report/cont_pos_acc": 0.9990195631980896, "report/cont_pos_loss": 0.0053152707405388355, "report/cont_pred": 0.9950392246246338, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.0760803371667862, "report/image_loss_std": 0.09412044286727905, "report/model_loss_mean": 0.7129734754562378, "report/model_loss_std": 0.5010251402854919, "report/post_ent_mag": 42.92560958862305, "report/post_ent_max": 42.92560958862305, "report/post_ent_mean": 41.66319274902344, "report/post_ent_min": 40.152435302734375, "report/post_ent_std": 0.6110397577285767, "report/prior_ent_mag": 43.124820709228516, "report/prior_ent_max": 43.124820709228516, "report/prior_ent_mean": 41.93330764770508, "report/prior_ent_min": 40.560359954833984, "report/prior_ent_std": 0.47369176149368286, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0023010254371911287, "report/reward_loss_mean": 0.019461344927549362, "report/reward_loss_std": 0.2711695730686188, "report/reward_max_data": 0.934374988079071, "report/reward_max_pred": 0.05710446834564209, "report/reward_neg_acc": 0.9999999403953552, "report/reward_neg_loss": 0.0025809509679675102, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.32396125793457, "report/reward_pred": 0.0012910397490486503, "report/reward_rate": 0.00390625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.028144773095846176, "eval/cont_loss_std": 0.46050605177879333, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.100600719451904, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.004331221338361502, "eval/cont_pred": 0.9956814050674438, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.14379484951496124, "eval/image_loss_std": 0.13433633744716644, "eval/model_loss_mean": 0.7847815752029419, "eval/model_loss_std": 0.6111499071121216, "eval/post_ent_mag": 42.940086364746094, "eval/post_ent_max": 42.940086364746094, "eval/post_ent_mean": 41.88618469238281, "eval/post_ent_min": 40.33058547973633, "eval/post_ent_std": 0.6609618663787842, "eval/prior_ent_mag": 43.141143798828125, "eval/prior_ent_max": 43.141143798828125, "eval/prior_ent_mean": 42.04460906982422, "eval/prior_ent_min": 40.72397994995117, "eval/prior_ent_std": 0.5017371773719788, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0014007568825036287, "eval/reward_loss_mean": 0.012841980904340744, "eval/reward_loss_std": 0.22503463923931122, "eval/reward_max_data": 0.737500011920929, "eval/reward_max_pred": 0.050284385681152344, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0029087981674820185, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.088697910308838, "eval/reward_pred": 0.001332770218141377, "eval/reward_rate": 0.001953125, "replay/size": 726169.0, "replay/inserts": 8764.0, "replay/samples": 35056.0, "replay/insert_wait_avg": 1.5309769940778906e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.178265446672043e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 1888.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 9.819612664691472e-07, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.450580596923828e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0043804645538, "timer/env.step_count": 1096.0, "timer/env.step_total": 10.733329772949219, "timer/env.step_frac": 0.01073328275618456, "timer/env.step_avg": 0.009793184099406221, "timer/env.step_min": 0.008594751358032227, "timer/env.step_max": 0.035750627517700195, "timer/replay._sample_count": 35056.0, "timer/replay._sample_total": 18.291130781173706, "timer/replay._sample_frac": 0.018291050657874647, "timer/replay._sample_avg": 0.0005217689063547954, "timer/replay._sample_min": 0.0003814697265625, "timer/replay._sample_max": 0.01192617416381836, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1332.0, "timer/agent.policy_total": 13.43571949005127, "timer/agent.policy_frac": 0.013435660635616098, "timer/agent.policy_avg": 0.010086876494032485, "timer/agent.policy_min": 0.00887441635131836, "timer/agent.policy_max": 0.039333343505859375, "timer/dataset_train_count": 2191.0, "timer/dataset_train_total": 0.3862190246582031, "timer/dataset_train_frac": 0.0003862173328468665, "timer/dataset_train_avg": 0.0001762752280502981, "timer/dataset_train_min": 9.489059448242188e-05, "timer/dataset_train_max": 0.0009403228759765625, "timer/agent.train_count": 2191.0, "timer/agent.train_total": 970.992936372757, "timer/agent.train_frac": 0.970988682991249, "timer/agent.train_avg": 0.4431734077465801, "timer/agent.train_min": 0.4333186149597168, "timer/agent.train_max": 0.5851314067840576, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47972965240478516, "timer/agent.report_frac": 0.0004797275509752526, "timer/agent.report_avg": 0.23986482620239258, "timer/agent.report_min": 0.23366498947143555, "timer/agent.report_max": 0.2460646629333496, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.123283386230469e-05, "timer/dataset_eval_frac": 3.123269704858235e-08, "timer/dataset_eval_avg": 3.123283386230469e-05, "timer/dataset_eval_min": 3.123283386230469e-05, "timer/dataset_eval_max": 3.123283386230469e-05, "fps": 8.763836347114035}
{"step": 726768, "time": 83264.71543693542, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 726824, "time": 83271.0959789753, "episode/length": 191.0, "episode/score": 0.40312498807907104, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.0}
{"step": 727016, "time": 83292.94532704353, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 727264, "time": 83321.24500012398, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 727472, "time": 83344.89458465576, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 727504, "time": 83348.54076743126, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 727712, "time": 83372.27380800247, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 727992, "time": 83404.18726706505, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 728184, "time": 83425.92874884605, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 728248, "time": 83433.21841812134, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 728432, "time": 83454.16789150238, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 728904, "time": 83508.0901582241, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 728904, "time": 83508.10009241104, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 728936, "time": 83511.74943637848, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 729032, "time": 83522.58567285538, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 729048, "time": 83524.41316390038, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 729136, "time": 83534.86551141739, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 729320, "time": 83555.71547603607, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 729384, "time": 83563.08213758469, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 729496, "time": 83575.73682999611, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 729672, "time": 83595.67758250237, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 729960, "time": 83628.33723568916, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 730080, "time": 83642.69422793388, "eval_episode/length": 43.0, "eval_episode/score": 0.8656250238418579, "eval_episode/reward_rate": 0.022727272727272728}
{"step": 730080, "time": 83643.91196537018, "eval_episode/length": 113.0, "eval_episode/score": 0.6468750238418579, "eval_episode/reward_rate": 0.008771929824561403}
{"step": 730080, "time": 83644.6116759777, "eval_episode/length": 151.0, "eval_episode/score": 0.528124988079071, "eval_episode/reward_rate": 0.006578947368421052}
{"step": 730080, "time": 83644.75532031059, "eval_episode/length": 44.0, "eval_episode/score": 0.862500011920929, "eval_episode/reward_rate": 0.022222222222222223}
{"step": 730080, "time": 83645.14449357986, "eval_episode/length": 178.0, "eval_episode/score": 0.4437499940395355, "eval_episode/reward_rate": 0.00558659217877095}
{"step": 730080, "time": 83645.19109392166, "eval_episode/length": 180.0, "eval_episode/score": 0.4375, "eval_episode/reward_rate": 0.0055248618784530384}
{"step": 730080, "time": 83646.24406933784, "eval_episode/length": 58.0, "eval_episode/score": 0.8187500238418579, "eval_episode/reward_rate": 0.01694915254237288}
{"step": 730080, "time": 83647.11061263084, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 730080, "time": 83647.11882376671, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 730080, "time": 83647.12494039536, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 730136, "time": 83653.56326985359, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 730144, "time": 83654.47204780579, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 730272, "time": 83668.93102431297, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 730464, "time": 83690.78865385056, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 730744, "time": 83722.60208320618, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 731176, "time": 83771.52219772339, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 731248, "time": 83779.66651296616, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 731344, "time": 83790.4783911705, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 731416, "time": 83798.60221505165, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 731984, "time": 83862.83757638931, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 732104, "time": 83876.38174819946, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 732200, "time": 83887.19773554802, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 732208, "time": 83888.10121250153, "episode/length": 258.0, "episode/score": 0.19374999403953552, "episode/reward_rate": 0.003861003861003861, "episode/intrinsic_return": 0.0}
{"step": 732272, "time": 83895.35576272011, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 733056, "time": 83984.01217103004, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 733080, "time": 83986.74421906471, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 733200, "time": 84000.28416109085, "episode/length": 231.0, "episode/score": 0.27812498807907104, "episode/reward_rate": 0.004310344827586207, "episode/intrinsic_return": 0.0}
{"step": 733256, "time": 84006.58216285706, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 733400, "time": 84022.90162801743, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 733408, "time": 84023.81012511253, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 733488, "time": 84032.84875226021, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 733912, "time": 84080.7485089302, "episode/length": 240.0, "episode/score": 0.25, "episode/reward_rate": 0.004149377593360996, "episode/intrinsic_return": 0.0}
{"step": 734096, "time": 84101.63846755028, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 734128, "time": 84105.24309372902, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 734512, "time": 84148.42877197266, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 734600, "time": 84158.3415620327, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 734704, "time": 84170.12006855011, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 734752, "time": 84175.52276992798, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 734920, "time": 84194.54060745239, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 735040, "time": 84208.0265724659, "episode/length": 222.0, "episode/score": 0.3062500059604645, "episode/reward_rate": 0.004484304932735426, "episode/intrinsic_return": 0.0}
{"step": 735168, "time": 84222.449010849, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 735264, "time": 84233.23373889923, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 735296, "time": 84236.82938551903, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 735440, "time": 84253.08793258667, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 735441, "time": 84254.07947516441, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.835362382368608, "train/action_min": 0.0, "train/action_std": 1.6358327063647184, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.008117018117230724, "train/actor_opt_grad_steps": 182375.0, "train/actor_opt_loss": -39.72561388882724, "train/adv_mag": 0.50091024921699, "train/adv_max": 0.25473901466889814, "train/adv_mean": 0.0024092378040884133, "train/adv_min": -0.47172201587395235, "train/adv_std": 0.03076496320691976, "train/cont_avg": 0.9950905539772728, "train/cont_loss_mean": 0.016266298782482574, "train/cont_loss_std": 0.2166480170943859, "train/cont_neg_acc": 0.3044247720051895, "train/cont_neg_loss": 2.5456197275973285, "train/cont_pos_acc": 0.9999062706123699, "train/cont_pos_loss": 0.0035749142439189282, "train/cont_pred": 0.9950266244736585, "train/cont_rate": 0.9950905539772728, "train/dyn_loss_mean": 1.0000011460347609, "train/dyn_loss_std": 3.511257660151883e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.12767400503666562, "train/extr_critic_critic_opt_grad_steps": 182375.0, "train/extr_critic_critic_opt_loss": 10047.564564098011, "train/extr_critic_mag": 1.0706859919157896, "train/extr_critic_max": 1.0706859919157896, "train/extr_critic_mean": 0.8336516499519349, "train/extr_critic_min": 0.6690469931472431, "train/extr_critic_std": 0.0684832338751717, "train/extr_return_normed_mag": 0.5549994531002912, "train/extr_return_normed_max": 0.4188405467705293, "train/extr_return_normed_mean": 0.08937363228337332, "train/extr_return_normed_min": -0.3699871708046306, "train/extr_return_normed_std": 0.07644067752090368, "train/extr_return_rate": 0.9995087856596166, "train/extr_return_raw_mag": 1.1655277295546098, "train/extr_return_raw_max": 1.1655277295546098, "train/extr_return_raw_mean": 0.8360608561472459, "train/extr_return_raw_min": 0.37670001197944986, "train/extr_return_raw_std": 0.07644067782570016, "train/extr_reward_mag": 0.40399241068146446, "train/extr_reward_max": 0.40399241068146446, "train/extr_reward_mean": 0.0013945079522355544, "train/extr_reward_min": 8.66976651278409e-09, "train/extr_reward_std": 0.01064590722618794, "train/image_loss_mean": 0.0729448387060653, "train/image_loss_std": 0.09685154154219411, "train/model_loss_mean": 0.7004952967166901, "train/model_loss_std": 0.3932270857759497, "train/model_opt_grad_norm": 10.285142665584338, "train/model_opt_grad_steps": 182219.57272727272, "train/model_opt_loss": 5521.6138017134235, "train/model_opt_model_opt_grad_overflow": 0.004545454545454545, "train/model_opt_model_opt_grad_scale": 7863.636363636364, "train/policy_entropy_mag": 1.3157534068281, "train/policy_entropy_max": 1.3157534068281, "train/policy_entropy_mean": 0.08350710526786068, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.09475540493360975, "train/policy_logprob_mag": 6.5510802854191175, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.08344810632142154, "train/policy_logprob_min": -6.5510802854191175, "train/policy_logprob_std": 0.6206485788930546, "train/policy_randomness_mag": 0.6761635341427543, "train/policy_randomness_max": 0.6761635341427543, "train/policy_randomness_mean": 0.042914168841459537, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.04869464884766123, "train/post_ent_mag": 43.14079210107977, "train/post_ent_max": 43.14079210107977, "train/post_ent_mean": 41.99528756575151, "train/post_ent_min": 40.601849816062234, "train/post_ent_std": 0.5615540119734678, "train/prior_ent_mag": 43.112430693886495, "train/prior_ent_max": 43.112430693886495, "train/prior_ent_mean": 41.674499268965285, "train/prior_ent_min": 40.24877201427113, "train/prior_ent_std": 0.5100261280482465, "train/rep_loss_mean": 1.0000011460347609, "train/rep_loss_std": 3.511257660151883e-05, "train/reward_avg": 0.0014852627898190721, "train/reward_loss_mean": 0.011283448035299608, "train/reward_loss_std": 0.17872329838573933, "train/reward_max_data": 0.65643465959213, "train/reward_max_pred": 0.2360500460321253, "train/reward_neg_acc": 0.9997017849575389, "train/reward_neg_loss": 0.002169414112788879, "train/reward_pos_acc": 0.19559233624760697, "train/reward_pos_loss": 3.5494013015089965, "train/reward_pred": 0.0012249033331913366, "train/reward_rate": 0.0025124289772727273, "train_stats/mean_log_entropy": 0.07107098613466535, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.006255968473851681, "report/cont_loss_std": 0.08285035938024521, "report/cont_neg_acc": 0.5, "report/cont_neg_loss": 1.3021762371063232, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.003719920990988612, "report/cont_pred": 0.9953852891921997, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.052416615188121796, "report/image_loss_std": 0.08551996201276779, "report/model_loss_mean": 0.664196252822876, "report/model_loss_std": 0.22124414145946503, "report/post_ent_mag": 43.38556671142578, "report/post_ent_max": 43.38556671142578, "report/post_ent_mean": 42.19390869140625, "report/post_ent_min": 41.0548210144043, "report/post_ent_std": 0.5386103391647339, "report/prior_ent_mag": 42.85762405395508, "report/prior_ent_max": 42.85762405395508, "report/prior_ent_mean": 41.33171463012695, "report/prior_ent_min": 40.14710998535156, "report/prior_ent_std": 0.5116025805473328, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0006530761602334678, "report/reward_loss_mean": 0.005523684434592724, "report/reward_loss_std": 0.10834448039531708, "report/reward_max_data": 0.668749988079071, "report/reward_max_pred": 0.03776276111602783, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.002152681350708008, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 3.4540598392486572, "report/reward_pred": 0.0009614047594368458, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.02181433141231537, "eval/cont_loss_std": 0.31138259172439575, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 2.9092462062835693, "eval/cont_pos_acc": 0.999020516872406, "eval/cont_pos_loss": 0.01333020068705082, "eval/cont_pred": 0.9940876960754395, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.11406329274177551, "eval/image_loss_std": 0.12209653854370117, "eval/model_loss_mean": 0.7515221238136292, "eval/model_loss_std": 0.5031850337982178, "eval/post_ent_mag": 43.356544494628906, "eval/post_ent_max": 43.356544494628906, "eval/post_ent_mean": 42.362064361572266, "eval/post_ent_min": 40.99144744873047, "eval/post_ent_std": 0.5444031357765198, "eval/prior_ent_mag": 42.79542541503906, "eval/prior_ent_max": 42.79542541503906, "eval/prior_ent_mean": 41.514015197753906, "eval/prior_ent_min": 40.08478927612305, "eval/prior_ent_std": 0.48022744059562683, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0014526366721838713, "eval/reward_loss_mean": 0.015644496306777, "eval/reward_loss_std": 0.23515814542770386, "eval/reward_max_data": 0.628125011920929, "eval/reward_max_pred": 0.04331004619598389, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.003026098944246769, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 4.310105800628662, "eval/reward_pred": 0.001464305678382516, "eval/reward_rate": 0.0029296875, "replay/size": 734937.0, "replay/inserts": 8768.0, "replay/samples": 35072.0, "replay/insert_wait_avg": 1.559210737256238e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.087142975661007e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.046587439144359e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.068704366684, "timer/env.step_count": 1096.0, "timer/env.step_total": 10.815097093582153, "timer/env.step_frac": 0.0108143541002326, "timer/env.step_avg": 0.009867789318961819, "timer/env.step_min": 0.008642196655273438, "timer/env.step_max": 0.03322291374206543, "timer/replay._sample_count": 35072.0, "timer/replay._sample_total": 18.300905227661133, "timer/replay._sample_frac": 0.01829964796193737, "timer/replay._sample_avg": 0.000521809569675557, "timer/replay._sample_min": 0.0003998279571533203, "timer/replay._sample_max": 0.020392656326293945, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1385.0, "timer/agent.policy_total": 14.056082725524902, "timer/agent.policy_frac": 0.014055117077607416, "timer/agent.policy_avg": 0.01014879619171473, "timer/agent.policy_min": 0.008934736251831055, "timer/agent.policy_max": 0.03659391403198242, "timer/dataset_train_count": 2192.0, "timer/dataset_train_total": 0.3915059566497803, "timer/dataset_train_frac": 0.00039147906032887034, "timer/dataset_train_avg": 0.00017860673204825743, "timer/dataset_train_min": 9.560585021972656e-05, "timer/dataset_train_max": 0.000873565673828125, "timer/agent.train_count": 2192.0, "timer/agent.train_total": 969.7670729160309, "timer/agent.train_frac": 0.9697004502607226, "timer/agent.train_avg": 0.44241198581935715, "timer/agent.train_min": 0.4323995113372803, "timer/agent.train_max": 0.5909321308135986, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4810178279876709, "timer/agent.report_frac": 0.00048098478223282295, "timer/agent.report_avg": 0.24050891399383545, "timer/agent.report_min": 0.23431992530822754, "timer/agent.report_max": 0.24669790267944336, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.5987625122070312e-05, "timer/dataset_eval_frac": 2.598583978140538e-08, "timer/dataset_eval_avg": 2.5987625122070312e-05, "timer/dataset_eval_min": 2.5987625122070312e-05, "timer/dataset_eval_max": 2.5987625122070312e-05, "fps": 8.767286772087385}
{"step": 735512, "time": 84261.86327719688, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 735800, "time": 84294.31482410431, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 736136, "time": 84332.16532492638, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 736408, "time": 84362.92317438126, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 736520, "time": 84375.5855448246, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 736536, "time": 84377.39152288437, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 736696, "time": 84395.3824801445, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 736912, "time": 84419.75820207596, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 736976, "time": 84426.97883439064, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 737000, "time": 84429.69732928276, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 737200, "time": 84452.32277750969, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 737328, "time": 84467.18320846558, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 737424, "time": 84477.98630475998, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 737440, "time": 84479.80236768723, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 737480, "time": 84484.30823397636, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 737608, "time": 84498.80603671074, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 738368, "time": 84584.65047979355, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 738400, "time": 84588.26037454605, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 738568, "time": 84607.17489743233, "episode/length": 269.0, "episode/score": 0.15937499701976776, "episode/reward_rate": 0.003703703703703704, "episode/intrinsic_return": 0.0}
{"step": 738688, "time": 84620.74309372902, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 738848, "time": 84638.7456395626, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 739096, "time": 84666.71987700462, "episode/length": 208.0, "episode/score": 0.3499999940395355, "episode/reward_rate": 0.004784688995215311, "episode/intrinsic_return": 0.0}
{"step": 739120, "time": 84669.4403784275, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 739120, "time": 84669.44796228409, "episode/length": 239.0, "episode/score": 0.25312501192092896, "episode/reward_rate": 0.004166666666666667, "episode/intrinsic_return": 0.0}
{"step": 739232, "time": 84682.12182927132, "episode/length": 237.0, "episode/score": 0.2593750059604645, "episode/reward_rate": 0.004201680672268907, "episode/intrinsic_return": 0.0}
{"step": 739272, "time": 84686.62951111794, "episode/length": 286.0, "episode/score": 0.10625000298023224, "episode/reward_rate": 0.003484320557491289, "episode/intrinsic_return": 0.0}
{"step": 739280, "time": 84687.5522184372, "episode/length": 208.0, "episode/score": 0.3499999940395355, "episode/reward_rate": 0.004784688995215311, "episode/intrinsic_return": 0.0}
{"step": 739744, "time": 84739.8543548584, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 739936, "time": 84761.48668909073, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 739952, "time": 84763.284512043, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 740064, "time": 84776.82187318802, "eval_episode/length": 54.0, "eval_episode/score": 0.831250011920929, "eval_episode/reward_rate": 0.01818181818181818}
{"step": 740064, "time": 84776.95115947723, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 740064, "time": 84777.9265127182, "eval_episode/length": 96.0, "eval_episode/score": 0.699999988079071, "eval_episode/reward_rate": 0.010309278350515464}
{"step": 740064, "time": 84778.58713293076, "eval_episode/length": 60.0, "eval_episode/score": 0.8125, "eval_episode/reward_rate": 0.01639344262295082}
{"step": 740064, "time": 84779.0100722313, "eval_episode/length": 147.0, "eval_episode/score": 0.5406249761581421, "eval_episode/reward_rate": 0.006756756756756757}
{"step": 740064, "time": 84779.16599369049, "eval_episode/length": 156.0, "eval_episode/score": 0.512499988079071, "eval_episode/reward_rate": 0.006369426751592357}
{"step": 740064, "time": 84779.22297024727, "eval_episode/length": 159.0, "eval_episode/score": 0.503125011920929, "eval_episode/reward_rate": 0.00625}
{"step": 740064, "time": 84779.43015933037, "eval_episode/length": 171.0, "eval_episode/score": 0.46562498807907104, "eval_episode/reward_rate": 0.005813953488372093}
{"step": 740352, "time": 84811.88995313644, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 740688, "time": 84849.82483911514, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 740896, "time": 84873.33376026154, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.0}
{"step": 741000, "time": 84885.13093781471, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 741120, "time": 84898.68976688385, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 741160, "time": 84903.22626543045, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 741400, "time": 84930.29033708572, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 741432, "time": 84933.88235855103, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 741448, "time": 84935.70789837837, "episode/length": 212.0, "episode/score": 0.3375000059604645, "episode/reward_rate": 0.004694835680751174, "episode/intrinsic_return": 0.0}
{"step": 741800, "time": 84975.53153967857, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 742032, "time": 85001.68700480461, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 742528, "time": 85057.5124847889, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 742648, "time": 85071.10051608086, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 742664, "time": 85072.90209889412, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 742784, "time": 85086.41464042664, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 742968, "time": 85107.20063638687, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 743208, "time": 85134.27675104141, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 743312, "time": 85145.97728991508, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 743744, "time": 85194.75751328468, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 743912, "time": 85213.69724416733, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 743944, "time": 85217.31482028961, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 744048, "time": 85228.99072098732, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 744088, "time": 85233.48476076126, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 744265, "time": 85254.33021736145, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.822467041015625, "train/action_min": 0.0, "train/action_std": 1.6221860625527122, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00693529670719396, "train/actor_opt_grad_steps": 184575.0, "train/actor_opt_loss": -28.382671551270917, "train/adv_mag": 0.4540200696750121, "train/adv_max": 0.19495608779517087, "train/adv_mean": -0.0009381940552223321, "train/adv_min": -0.41813442436131565, "train/adv_std": 0.021001000384884803, "train/cont_avg": 0.9950062144886364, "train/cont_loss_mean": 0.017132227710151875, "train/cont_loss_std": 0.2293161911551248, "train/cont_neg_acc": 0.286044732212476, "train/cont_neg_loss": 2.674839079794931, "train/cont_pos_acc": 0.9998661008748141, "train/cont_pos_loss": 0.0036821950777349145, "train/cont_pred": 0.9949646827849474, "train/cont_rate": 0.9950062144886364, "train/dyn_loss_mean": 1.0000000552697614, "train/dyn_loss_std": 1.7653483982113274e-06, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.08461466937071897, "train/extr_critic_critic_opt_grad_steps": 184575.0, "train/extr_critic_critic_opt_loss": 7279.858556019176, "train/extr_critic_mag": 1.005237745696848, "train/extr_critic_max": 1.005237745696848, "train/extr_critic_mean": 0.8772090974179181, "train/extr_critic_min": 0.7444049488414418, "train/extr_critic_std": 0.04031836946748874, "train/extr_return_normed_mag": 0.48626956939697263, "train/extr_return_normed_max": 0.2703996766697277, "train/extr_return_normed_mean": 0.057679945467547934, "train/extr_return_normed_min": -0.3584448844194412, "train/extr_return_normed_std": 0.04540628247301687, "train/extr_return_rate": 0.9996025938879359, "train/extr_return_raw_mag": 1.0889906189658425, "train/extr_return_raw_max": 1.0889906189658425, "train/extr_return_raw_mean": 0.8762709241021763, "train/extr_return_raw_min": 0.4601460578766736, "train/extr_return_raw_std": 0.045406282727013934, "train/extr_reward_mag": 0.2679802959615534, "train/extr_reward_max": 0.2679802959615534, "train/extr_reward_mean": 0.0012917621865529906, "train/extr_reward_min": 1.246278936212713e-08, "train/extr_reward_std": 0.007344049560329454, "train/image_loss_mean": 0.07339956750246611, "train/image_loss_std": 0.09793592430651188, "train/model_loss_mean": 0.7020313601602207, "train/model_loss_std": 0.4049999005415223, "train/model_opt_grad_norm": 10.242119661244478, "train/model_opt_grad_steps": 184417.7409090909, "train/model_opt_loss": 4276.057596102628, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 6090.909090909091, "train/policy_entropy_mag": 1.2748387390916998, "train/policy_entropy_max": 1.2748387390916998, "train/policy_entropy_mean": 0.08235411227426746, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.09177528045732866, "train/policy_logprob_mag": 6.551080265912143, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.08266302858563987, "train/policy_logprob_min": -6.551080265912143, "train/policy_logprob_std": 0.6222926557064057, "train/policy_randomness_mag": 0.655137550830841, "train/policy_randomness_max": 0.655137550830841, "train/policy_randomness_mean": 0.04232164797457782, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.04716316720640117, "train/post_ent_mag": 43.70602040724321, "train/post_ent_max": 43.70602040724321, "train/post_ent_mean": 42.56349289634011, "train/post_ent_min": 41.194373564286664, "train/post_ent_std": 0.5586980738423087, "train/prior_ent_mag": 43.43870114413175, "train/prior_ent_max": 43.43870114413175, "train/prior_ent_mean": 42.22084213603627, "train/prior_ent_min": 40.896651510758836, "train/prior_ent_std": 0.46792489249597896, "train/rep_loss_mean": 1.0000000552697614, "train/rep_loss_std": 1.7653483982113274e-06, "train/reward_avg": 0.0014988431065417402, "train/reward_loss_mean": 0.011499511284372684, "train/reward_loss_std": 0.18484189386945218, "train/reward_max_data": 0.6843039787628434, "train/reward_max_pred": 0.22303334095261312, "train/reward_neg_acc": 0.999768649448048, "train/reward_neg_loss": 0.0022013389923482797, "train/reward_pos_acc": 0.15279676597654535, "train/reward_pos_loss": 3.7069883541912554, "train/reward_pred": 0.0012235412427054888, "train/reward_rate": 0.0025168678977272726, "train_stats/mean_log_entropy": 0.07167288056522045, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.01518218033015728, "report/cont_loss_std": 0.17946282029151917, "report/cont_neg_acc": 0.20000000298023224, "report/cont_neg_loss": 2.2574174404144287, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.004180042538791895, "report/cont_pred": 0.9946770071983337, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.0725763589143753, "report/image_loss_std": 0.1030515730381012, "report/model_loss_mean": 0.7067540884017944, "report/model_loss_std": 0.4728374779224396, "report/post_ent_mag": 43.485591888427734, "report/post_ent_max": 43.485591888427734, "report/post_ent_mean": 42.222232818603516, "report/post_ent_min": 40.68205261230469, "report/post_ent_std": 0.6254704594612122, "report/prior_ent_mag": 43.568111419677734, "report/prior_ent_max": 43.568111419677734, "report/prior_ent_mean": 42.3315544128418, "report/prior_ent_min": 40.676334381103516, "report/prior_ent_std": 0.5165767073631287, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.003488159039989114, "report/reward_loss_mean": 0.018995555117726326, "report/reward_loss_std": 0.2540586590766907, "report/reward_max_data": 0.965624988079071, "report/reward_max_pred": 0.484643816947937, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.002887559588998556, "report/reward_pos_acc": 0.20000000298023224, "report/reward_pos_loss": 3.3018054962158203, "report/reward_pred": 0.0019316230900585651, "report/reward_rate": 0.0048828125, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.036272503435611725, "eval/cont_loss_std": 0.535251796245575, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.339141368865967, "eval/cont_pos_acc": 0.999018669128418, "eval/cont_pos_loss": 0.005345769226551056, "eval/cont_pred": 0.9949315190315247, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.10062557458877563, "eval/image_loss_std": 0.11925794929265976, "eval/model_loss_mean": 0.7488947510719299, "eval/model_loss_std": 0.6359233856201172, "eval/post_ent_mag": 43.466182708740234, "eval/post_ent_max": 43.466182708740234, "eval/post_ent_mean": 42.24859619140625, "eval/post_ent_min": 40.74932861328125, "eval/post_ent_std": 0.6316282749176025, "eval/prior_ent_mag": 43.54022216796875, "eval/prior_ent_max": 43.54022216796875, "eval/prior_ent_mean": 42.40125274658203, "eval/prior_ent_min": 41.01333236694336, "eval/prior_ent_std": 0.47354742884635925, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0011779784690588713, "eval/reward_loss_mean": 0.011996657587587833, "eval/reward_loss_std": 0.17879441380500793, "eval/reward_max_data": 0.6937500238418579, "eval/reward_max_pred": 0.3607218265533447, "eval/reward_neg_acc": 0.9990215301513672, "eval/reward_neg_loss": 0.0042344387620687485, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 3.978489875793457, "eval/reward_pred": 0.0018669682322070003, "eval/reward_rate": 0.001953125, "replay/size": 743761.0, "replay/inserts": 8824.0, "replay/samples": 35296.0, "replay/insert_wait_avg": 1.496438642901285e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 6.969366307055421e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 1376.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.026447429213413e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.897615432739258e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2357141971588, "timer/env.step_count": 1103.0, "timer/env.step_total": 10.8135347366333, "timer/env.step_frac": 0.010810986433645598, "timer/env.step_avg": 0.009803748627954035, "timer/env.step_min": 0.008674860000610352, "timer/env.step_max": 0.034330129623413086, "timer/replay._sample_count": 35296.0, "timer/replay._sample_total": 18.141714096069336, "timer/replay._sample_frac": 0.01813743884423365, "timer/replay._sample_avg": 0.0005139878200382292, "timer/replay._sample_min": 0.0003719329833984375, "timer/replay._sample_max": 0.029430389404296875, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1275.0, "timer/agent.policy_total": 13.266342639923096, "timer/agent.policy_frac": 0.013263216311538479, "timer/agent.policy_avg": 0.010404974619547525, "timer/agent.policy_min": 0.008780241012573242, "timer/agent.policy_max": 0.07819032669067383, "timer/dataset_train_count": 2206.0, "timer/dataset_train_total": 0.45528197288513184, "timer/dataset_train_frac": 0.00045517468175045603, "timer/dataset_train_avg": 0.0002063834872552728, "timer/dataset_train_min": 9.441375732421875e-05, "timer/dataset_train_max": 0.06468367576599121, "timer/agent.train_count": 2206.0, "timer/agent.train_total": 971.5534839630127, "timer/agent.train_frac": 0.9713245289814831, "timer/agent.train_avg": 0.4404140906450647, "timer/agent.train_min": 0.4289841651916504, "timer/agent.train_max": 0.6148743629455566, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.481687068939209, "timer/agent.report_frac": 0.0004815735552152685, "timer/agent.report_avg": 0.2408435344696045, "timer/agent.report_min": 0.23454856872558594, "timer/agent.report_max": 0.24713850021362305, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.1219253540039062e-05, "timer/dataset_eval_frac": 2.1214253039415552e-08, "timer/dataset_eval_avg": 2.1219253540039062e-05, "timer/dataset_eval_min": 2.1219253540039062e-05, "timer/dataset_eval_max": 2.1219253540039062e-05, "fps": 8.821806900853886}
{"step": 744520, "time": 85283.04663801193, "episode/length": 233.0, "episode/score": 0.2718749940395355, "episode/reward_rate": 0.004273504273504274, "episode/intrinsic_return": 0.0}
{"step": 744720, "time": 85305.6765601635, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 744840, "time": 85319.25714159012, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 745024, "time": 85340.10428094864, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 745048, "time": 85342.8415119648, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 745192, "time": 85359.15088272095, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 745280, "time": 85369.19990301132, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 745488, "time": 85393.26169109344, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 745504, "time": 85395.07746911049, "episode/length": 198.0, "episode/score": 0.3812499940395355, "episode/reward_rate": 0.005025125628140704, "episode/intrinsic_return": 0.0}
{"step": 745520, "time": 85396.91128373146, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 745712, "time": 85418.621799469, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 745904, "time": 85440.31207489967, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 746136, "time": 85466.63397097588, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 746512, "time": 85509.30448579788, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 746688, "time": 85529.26757836342, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 747136, "time": 85579.96163105965, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.0}
{"step": 747224, "time": 85589.89885306358, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 747288, "time": 85597.11255121231, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 747336, "time": 85602.63624382019, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 747360, "time": 85605.37352013588, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 747800, "time": 85655.30638074875, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 747936, "time": 85670.76974272728, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 748208, "time": 85701.64658427238, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 748272, "time": 85708.89140415192, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 748368, "time": 85719.75289845467, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 748448, "time": 85728.92710590363, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 748672, "time": 85754.3644258976, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 748704, "time": 85757.99585032463, "episode/length": 251.0, "episode/score": 0.21562500298023224, "episode/reward_rate": 0.003968253968253968, "episode/intrinsic_return": 0.0}
{"step": 748768, "time": 85765.24141001701, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 748768, "time": 85765.24893307686, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 748856, "time": 85775.15792131424, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 748976, "time": 85788.75229334831, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 749184, "time": 85812.2828719616, "episode/length": 227.0, "episode/score": 0.2906250059604645, "episode/reward_rate": 0.0043859649122807015, "episode/intrinsic_return": 0.0}
{"step": 749568, "time": 85855.72768449783, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 749888, "time": 85891.79462647438, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 749952, "time": 85899.05312657356, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 749968, "time": 85900.91896653175, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 750016, "time": 85906.40590286255, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 750048, "time": 85910.59566640854, "eval_episode/length": 31.0, "eval_episode/score": 0.903124988079071, "eval_episode/reward_rate": 0.03125}
{"step": 750048, "time": 85910.60028338432, "eval_episode/length": 31.0, "eval_episode/score": 0.903124988079071, "eval_episode/reward_rate": 0.03125}
{"step": 750048, "time": 85911.24109530449, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 750048, "time": 85911.48019576073, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 750048, "time": 85911.63604593277, "eval_episode/length": 22.0, "eval_episode/score": 0.9312499761581421, "eval_episode/reward_rate": 0.043478260869565216}
{"step": 750048, "time": 85912.18520998955, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 750048, "time": 85912.33003878593, "eval_episode/length": 132.0, "eval_episode/score": 0.5874999761581421, "eval_episode/reward_rate": 0.007518796992481203}
{"step": 750048, "time": 85912.6040687561, "eval_episode/length": 116.0, "eval_episode/score": 0.637499988079071, "eval_episode/reward_rate": 0.008547008547008548}
{"step": 750224, "time": 85932.65362048149, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 750544, "time": 85969.01337838173, "episode/length": 283.0, "episode/score": 0.11562500149011612, "episode/reward_rate": 0.0035211267605633804, "episode/intrinsic_return": 0.0}
{"step": 750760, "time": 85993.59937500954, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 750800, "time": 85998.13727426529, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 750840, "time": 86002.6613073349, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 750992, "time": 86019.79654431343, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 751168, "time": 86039.76951575279, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 751168, "time": 86039.77682352066, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 751400, "time": 86066.12673544884, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 751496, "time": 86076.99469995499, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 751616, "time": 86090.66794586182, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 751656, "time": 86095.19380521774, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 751680, "time": 86097.92194962502, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 751688, "time": 86098.82481050491, "episode/length": 8.0, "episode/score": 0.9750000238418579, "episode/reward_rate": 0.1111111111111111, "episode/intrinsic_return": 0.0}
{"step": 751880, "time": 86120.64682388306, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 752024, "time": 86136.97167515755, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 752784, "time": 86223.29131174088, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 752888, "time": 86235.0486330986, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 753032, "time": 86251.29582571983, "episode/length": 203.0, "episode/score": 0.3656249940395355, "episode/reward_rate": 0.004901960784313725, "episode/intrinsic_return": 0.0}
{"step": 753053, "time": 86254.54884433746, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.797022871537642, "train/action_min": 0.0, "train/action_std": 1.659885975447568, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.007253372277641161, "train/actor_opt_grad_steps": 186775.0, "train/actor_opt_loss": -32.73862439935858, "train/adv_mag": 0.447955306280743, "train/adv_max": 0.21501737914302133, "train/adv_mean": -0.00011987007049108136, "train/adv_min": -0.41785691380500795, "train/adv_std": 0.024179950987242838, "train/cont_avg": 0.9951837713068182, "train/cont_loss_mean": 0.01691076402256096, "train/cont_loss_std": 0.2215145550033247, "train/cont_neg_acc": 0.26092810551189394, "train/cont_neg_loss": 2.668558374198247, "train/cont_pos_acc": 0.9998929432847283, "train/cont_pos_loss": 0.0037470534920099785, "train/cont_pred": 0.9951020040295341, "train/cont_rate": 0.9951837713068182, "train/dyn_loss_mean": 1.0000009217045525, "train/dyn_loss_std": 2.9478903690522368e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.09905748396942561, "train/extr_critic_critic_opt_grad_steps": 186775.0, "train/extr_critic_critic_opt_loss": 8071.976473721591, "train/extr_critic_mag": 1.0078659843314777, "train/extr_critic_max": 1.0078659843314777, "train/extr_critic_mean": 0.8456119000911713, "train/extr_critic_min": 0.7067358802665363, "train/extr_critic_std": 0.04759953873740001, "train/extr_return_normed_mag": 0.4704382758248936, "train/extr_return_normed_max": 0.3188749251040545, "train/extr_return_normed_mean": 0.07047566669908437, "train/extr_return_normed_min": -0.3188603853637522, "train/extr_return_normed_std": 0.053856667927043, "train/extr_return_rate": 0.9994780058210546, "train/extr_return_raw_mag": 1.0938912697813727, "train/extr_return_raw_max": 1.0938912697813727, "train/extr_return_raw_mean": 0.8454920549284328, "train/extr_return_raw_min": 0.45615595931356606, "train/extr_return_raw_std": 0.05385666804557497, "train/extr_reward_mag": 0.31980906779115853, "train/extr_reward_max": 0.31980906779115853, "train/extr_reward_mean": 0.001417805421674116, "train/extr_reward_min": 2.1674416281960226e-09, "train/extr_reward_std": 0.008572514187967912, "train/image_loss_mean": 0.07313537411391735, "train/image_loss_std": 0.09710105334154584, "train/model_loss_mean": 0.7020051517269829, "train/model_loss_std": 0.4094022499905391, "train/model_opt_grad_norm": 10.233341243050315, "train/model_opt_grad_steps": 186616.4909090909, "train/model_opt_loss": 4802.46142578125, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 6863.636363636364, "train/policy_entropy_mag": 1.3270933064547452, "train/policy_entropy_max": 1.3270933064547452, "train/policy_entropy_mean": 0.09025475264272907, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.11027439524504272, "train/policy_logprob_mag": 6.551080250740052, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09004102704877204, "train/policy_logprob_min": -6.551080250740052, "train/policy_logprob_std": 0.6274901563471014, "train/policy_randomness_mag": 0.6819910908287222, "train/policy_randomness_max": 0.6819910908287222, "train/policy_randomness_mean": 0.04638177403672175, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.05666983244432645, "train/post_ent_mag": 43.25556534853848, "train/post_ent_max": 43.25556534853848, "train/post_ent_mean": 41.96095138896595, "train/post_ent_min": 40.4023905320601, "train/post_ent_std": 0.6307858743450858, "train/prior_ent_mag": 43.117059395530006, "train/prior_ent_max": 43.117059395530006, "train/prior_ent_mean": 41.843401822176844, "train/prior_ent_min": 40.48728531924161, "train/prior_ent_std": 0.4881071459163319, "train/rep_loss_mean": 1.0000009217045525, "train/rep_loss_std": 2.9478903690522368e-05, "train/reward_avg": 0.0015655656331959604, "train/reward_loss_mean": 0.01195843549424105, "train/reward_loss_std": 0.1927112128373913, "train/reward_max_data": 0.7084801146929914, "train/reward_max_pred": 0.2342685260555961, "train/reward_neg_acc": 0.9998041824861006, "train/reward_neg_loss": 0.002189591725949537, "train/reward_pos_acc": 0.1670579044891635, "train/reward_pos_loss": 3.7631483359236113, "train/reward_pred": 0.0012397839428475972, "train/reward_rate": 0.0026100852272727274, "train_stats/mean_log_entropy": 0.07309955998993757, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.014249584637582302, "report/cont_loss_std": 0.23024430871009827, "report/cont_neg_acc": 0.4000000059604645, "report/cont_neg_loss": 2.252948760986328, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0032648006454110146, "report/cont_pred": 0.9946099519729614, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07110808789730072, "report/image_loss_std": 0.09512855857610703, "report/model_loss_mean": 0.6926524639129639, "report/model_loss_std": 0.36036914587020874, "report/post_ent_mag": 43.537750244140625, "report/post_ent_max": 43.537750244140625, "report/post_ent_mean": 42.270328521728516, "report/post_ent_min": 40.43943786621094, "report/post_ent_std": 0.6728668212890625, "report/prior_ent_mag": 42.96225357055664, "report/prior_ent_max": 42.96225357055664, "report/prior_ent_mean": 41.71812438964844, "report/prior_ent_min": 39.85787582397461, "report/prior_ent_std": 0.5164177417755127, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0009063720935955644, "report/reward_loss_mean": 0.007294833194464445, "report/reward_loss_std": 0.15686486661434174, "report/reward_max_data": 0.4781250059604645, "report/reward_max_pred": 0.45199155807495117, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0018019065028056502, "report/reward_pos_acc": 0.5, "report/reward_pos_loss": 2.814180374145508, "report/reward_pred": 0.0012584542855620384, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.013188503682613373, "eval/cont_loss_std": 0.2217492312192917, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 4.828514099121094, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.003765163477510214, "eval/cont_pred": 0.9962833523750305, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.09548953175544739, "eval/image_loss_std": 0.10679853707551956, "eval/model_loss_mean": 0.7246639132499695, "eval/model_loss_std": 0.5547661185264587, "eval/post_ent_mag": 43.51857376098633, "eval/post_ent_max": 43.51857376098633, "eval/post_ent_mean": 42.29643249511719, "eval/post_ent_min": 40.546775817871094, "eval/post_ent_std": 0.6141942143440247, "eval/prior_ent_mag": 42.90568923950195, "eval/prior_ent_max": 42.90568923950195, "eval/prior_ent_mean": 41.76531219482422, "eval/prior_ent_min": 40.34681701660156, "eval/prior_ent_std": 0.49353930354118347, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0010772704845294356, "eval/reward_loss_mean": 0.015985850244760513, "eval/reward_loss_std": 0.30822327733039856, "eval/reward_max_data": 0.7281249761581421, "eval/reward_max_pred": 0.05489969253540039, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.002401222474873066, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 6.957731246948242, "eval/reward_pred": 0.0010723917512223125, "eval/reward_rate": 0.001953125, "replay/size": 752549.0, "replay/inserts": 8788.0, "replay/samples": 35152.0, "replay/insert_wait_avg": 1.4967629732627677e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 6.969226291085245e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 1192.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 9.86676888177859e-07, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.195638656616211e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2058145999908, "timer/env.step_count": 1098.0, "timer/env.step_total": 10.766830205917358, "timer/env.step_frac": 0.010764614691050665, "timer/env.step_avg": 0.00980585628954222, "timer/env.step_min": 0.008554220199584961, "timer/env.step_max": 0.04538536071777344, "timer/replay._sample_count": 35152.0, "timer/replay._sample_total": 17.95021414756775, "timer/replay._sample_frac": 0.017946520491631538, "timer/replay._sample_avg": 0.0005106456004656279, "timer/replay._sample_min": 0.0003707408905029297, "timer/replay._sample_max": 0.025445222854614258, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1247.0, "timer/agent.policy_total": 12.653002500534058, "timer/agent.policy_frac": 0.01265039886375219, "timer/agent.policy_avg": 0.010146754210532525, "timer/agent.policy_min": 0.008779287338256836, "timer/agent.policy_max": 0.03748679161071777, "timer/dataset_train_count": 2197.0, "timer/dataset_train_total": 0.42177891731262207, "timer/dataset_train_frac": 0.00042169212691620155, "timer/dataset_train_avg": 0.00019197947988740195, "timer/dataset_train_min": 9.322166442871094e-05, "timer/dataset_train_max": 0.03588223457336426, "timer/agent.train_count": 2197.0, "timer/agent.train_total": 972.6108658313751, "timer/agent.train_frac": 0.972410729506055, "timer/agent.train_avg": 0.4426995292814634, "timer/agent.train_min": 0.42978882789611816, "timer/agent.train_max": 0.6915898323059082, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4770498275756836, "timer/agent.report_frac": 0.00047695166395975077, "timer/agent.report_avg": 0.2385249137878418, "timer/agent.report_min": 0.23343110084533691, "timer/agent.report_max": 0.24361872673034668, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 7.152557373046875e-05, "timer/dataset_eval_frac": 7.151085575229709e-08, "timer/dataset_eval_avg": 7.152557373046875e-05, "timer/dataset_eval_min": 7.152557373046875e-05, "timer/dataset_eval_max": 7.152557373046875e-05, "fps": 8.786074330130088}
{"step": 753112, "time": 86261.07924747467, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 753232, "time": 86274.67328333855, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 753352, "time": 86288.29207348824, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 753480, "time": 86302.87164711952, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
