{"step": 1560, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 1560, "eval_episode/length": 209.0, "eval_episode/score": 0.34687501192092896, "eval_episode/reward_rate": 0.004761904761904762}
{"step": 1560, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1561, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.86944580078125, "train/action_min": 0.0, "train/action_std": 1.8495298624038696, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0009697465575300157, "train/actor_opt_grad_steps": 1.0, "train/actor_opt_loss": -1.850915551185608, "train/adv_mag": 0.0, "train/adv_max": 0.0, "train/adv_mean": 0.0, "train/adv_min": 0.0, "train/adv_std": 0.0, "train/cont_avg": 1.0, "train/cont_loss_mean": 0.6016687750816345, "train/cont_loss_std": 0.24879752099514008, "train/cont_neg_acc": NaN, "train/cont_neg_loss": NaN, "train/cont_pos_acc": 0.6962890625, "train/cont_pos_loss": 0.6016687750816345, "train/cont_pred": 0.5639342069625854, "train/cont_rate": 1.0, "train/dyn_loss_mean": 10.965954780578613, "train/dyn_loss_std": 0.3692508935928345, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 10.468391418457031, "train/extr_critic_critic_opt_grad_steps": 1.0, "train/extr_critic_critic_opt_loss": 41517.85546875, "train/extr_critic_mag": 0.0, "train/extr_critic_max": 0.0, "train/extr_critic_mean": 0.0, "train/extr_critic_min": 0.0, "train/extr_critic_std": 0.0, "train/extr_return_normed_mag": 0.0, "train/extr_return_normed_max": 0.0, "train/extr_return_normed_mean": 0.0, "train/extr_return_normed_min": 0.0, "train/extr_return_normed_std": 0.0, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.0, "train/extr_return_raw_max": 0.0, "train/extr_return_raw_mean": 0.0, "train/extr_return_raw_min": 0.0, "train/extr_return_raw_std": 0.0, "train/extr_reward_mag": 0.0, "train/extr_reward_max": 0.0, "train/extr_reward_mean": 0.0, "train/extr_reward_min": 0.0, "train/extr_reward_std": 0.0, "train/image_loss_mean": 5008.1357421875, "train/image_loss_std": 41.07746505737305, "train/model_loss_mean": 5020.8583984375, "train/model_loss_std": 41.04701232910156, "train/model_opt_grad_norm": NaN, "train/model_opt_grad_steps": 0.0, "train/model_opt_loss": 50208584.0, "train/model_opt_model_opt_grad_overflow": 1.0, "train/model_opt_model_opt_grad_scale": 5000.0, "train/policy_entropy_mag": 1.9365105628967285, "train/policy_entropy_max": 1.9365105628967285, "train/policy_entropy_mean": 1.6417206525802612, "train/policy_entropy_min": 0.7053414583206177, "train/policy_entropy_std": 0.13991625607013702, "train/policy_logprob_mag": 4.575332164764404, "train/policy_logprob_max": -0.18079763650894165, "train/policy_logprob_mean": -1.6553319692611694, "train/policy_logprob_min": -4.575332164764404, "train/policy_logprob_std": 0.7242045402526855, "train/policy_randomness_mag": 0.9951696395874023, "train/policy_randomness_max": 0.9951696395874023, "train/policy_randomness_mean": 0.8436775803565979, "train/policy_randomness_min": 0.36247381567955017, "train/policy_randomness_std": 0.07190273702144623, "train/post_ent_mag": 105.60275268554688, "train/post_ent_max": 105.60275268554688, "train/post_ent_mean": 105.30221557617188, "train/post_ent_min": 104.96006774902344, "train/post_ent_std": 0.10813795030117035, "train/prior_ent_mag": 106.33799743652344, "train/prior_ent_max": 106.33799743652344, "train/prior_ent_mean": 105.59782409667969, "train/prior_ent_min": 104.8521728515625, "train/prior_ent_std": 0.2587502598762512, "train/rep_loss_mean": 10.965954780578613, "train/rep_loss_std": 0.3692508935928345, "train/reward_avg": 0.0, "train/reward_loss_mean": 5.541262626647949, "train/reward_loss_std": 9.5367431640625e-07, "train/reward_max_data": 0.0, "train/reward_max_pred": 0.0, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 5.541262626647949, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0, "train/reward_rate": 0.0, "train/params_agent/wm/model_opt": 181559683.0, "train/params_agent/task_behavior/critic/critic_opt": 9708799.0, "train/params_agent/task_behavior/ac/actor_opt": 9454599.0, "report/cont_avg": 1.0, "report/cont_loss_mean": 0.6201251745223999, "report/cont_loss_std": 0.26019302010536194, "report/cont_neg_acc": NaN, "report/cont_neg_loss": NaN, "report/cont_pos_acc": 0.65625, "report/cont_pos_loss": 0.6201251745223999, "report/cont_pred": 0.5552015900611877, "report/cont_rate": 1.0, "report/dyn_loss_mean": 10.995914459228516, "report/dyn_loss_std": 0.371224582195282, "report/image_loss_mean": 5009.283203125, "report/image_loss_std": 39.07275390625, "report/model_loss_mean": 5022.04248046875, "report/model_loss_std": 39.08145523071289, "report/post_ent_mag": 105.62808990478516, "report/post_ent_max": 105.62808990478516, "report/post_ent_mean": 105.30646514892578, "report/post_ent_min": 104.96400451660156, "report/post_ent_std": 0.10455156862735748, "report/prior_ent_mag": 106.31985473632812, "report/prior_ent_max": 106.31985473632812, "report/prior_ent_mean": 105.5582046508789, "report/prior_ent_min": 104.41403198242188, "report/prior_ent_std": 0.2984074354171753, "report/rep_loss_mean": 10.995914459228516, "report/rep_loss_std": 0.371224582195282, "report/reward_avg": 0.0, "report/reward_loss_mean": 5.541262626647949, "report/reward_loss_std": 9.5367431640625e-07, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.0, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 5.541262626647949, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.6484378576278687, "eval/cont_loss_std": 0.27522939443588257, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 0.609375, "eval/cont_pos_loss": 0.6484378576278687, "eval/cont_pred": 0.5417146682739258, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 11.02171516418457, "eval/dyn_loss_std": 0.3529345393180847, "eval/image_loss_mean": 4999.99609375, "eval/image_loss_std": 40.9888916015625, "eval/model_loss_mean": 5012.79931640625, "eval/model_loss_std": 40.99501419067383, "eval/post_ent_mag": 105.6063232421875, "eval/post_ent_max": 105.6063232421875, "eval/post_ent_mean": 105.28933715820312, "eval/post_ent_min": 104.93293762207031, "eval/post_ent_std": 0.11109544336795807, "eval/prior_ent_mag": 106.40953063964844, "eval/prior_ent_max": 106.40953063964844, "eval/prior_ent_mean": 105.56182861328125, "eval/prior_ent_min": 104.79472351074219, "eval/prior_ent_std": 0.26635807752609253, "eval/rep_loss_mean": 11.02171516418457, "eval/rep_loss_std": 0.3529345393180847, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 5.541262626647949, "eval/reward_loss_std": 9.5367431640625e-07, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 5.541262626647949, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0, "eval/reward_rate": 0.0, "replay/size": 1057.0, "replay/inserts": 1057.0, "replay/samples": 112.0, "replay/insert_wait_avg": 7.842775776122354e-07, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.08920179094587e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 3368.0, "eval_replay/inserts": 3368.0, "eval_replay/samples": 112.0, "eval_replay/insert_wait_avg": 1.6517282381759969e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.940190179007394e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 63.715928077697754, "timer/env.step_count": 196.0, "timer/env.step_total": 0.18962979316711426, "timer/env.step_frac": 0.002976175642233008, "timer/env.step_avg": 0.0009674989447301747, "timer/env.step_min": 0.0008068084716796875, "timer/env.step_max": 0.008779287338256836, "timer/replay._sample_count": 112.0, "timer/replay._sample_total": 46.53210473060608, "timer/replay._sample_frac": 0.7303056886162431, "timer/replay._sample_avg": 0.41546522080898285, "timer/replay._sample_min": 0.09188103675842285, "timer/replay._sample_max": 2.516263008117676, "timer/agent.save_count": 1.0, "timer/agent.save_total": 1.3616788387298584, "timer/agent.save_frac": 0.021371090083932745, "timer/agent.save_avg": 1.3616788387298584, "timer/agent.save_min": 1.3616788387298584, "timer/agent.save_max": 1.3616788387298584, "timer/agent.policy_count": 290.0, "timer/agent.policy_total": 9.622919797897339, "timer/agent.policy_frac": 0.1510284804478209, "timer/agent.policy_avg": 0.03318248206171496, "timer/agent.policy_min": 0.0049211978912353516, "timer/agent.policy_max": 6.801283597946167, "timer/dataset_train_count": 1.0, "timer/dataset_train_total": 3.266334533691406e-05, "timer/dataset_train_frac": 5.126401878205881e-07, "timer/dataset_train_avg": 3.266334533691406e-05, "timer/dataset_train_min": 3.266334533691406e-05, "timer/dataset_train_max": 3.266334533691406e-05, "timer/agent.train_count": 1.0, "timer/agent.train_total": 43.2104389667511, "timer/agent.train_frac": 0.6781732648398147, "timer/agent.train_avg": 43.2104389667511, "timer/agent.train_min": 43.2104389667511, "timer/agent.train_max": 43.2104389667511, "timer/agent.report_count": 2.0, "timer/agent.report_total": 9.297666549682617, "timer/agent.report_frac": 0.14592374042397485, "timer/agent.report_avg": 4.648833274841309, "timer/agent.report_min": 0.20876717567443848, "timer/agent.report_max": 9.088899374008179, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.9577484130859375e-05, "timer/dataset_eval_frac": 6.211552640745813e-07, "timer/dataset_eval_avg": 3.9577484130859375e-05, "timer/dataset_eval_min": 3.9577484130859375e-05, "timer/dataset_eval_max": 3.9577484130859375e-05}
{"step": 2312, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 2312, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 2312, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 2312, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 2312, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 2312, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 2312, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 2312, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 4624, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 4624, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 4624, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 4624, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 4624, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 4624, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 4624, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 4624, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 6936, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 6936, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 6936, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 6936, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 6936, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 6936, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 6936, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 6936, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 9008, "episode/length": 258.0, "episode/score": 0.19374999403953552, "episode/reward_rate": 0.003861003861003861}
{"step": 9248, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 9248, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 9248, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 9248, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 9248, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 9248, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 9248, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 10088, "eval_episode/length": 227.0, "eval_episode/score": 0.2906250059604645, "eval_episode/reward_rate": 0.0043859649122807015}
{"step": 10088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 11320, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 11560, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 11560, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 11560, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 11560, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 11560, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 11560, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 11560, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 13632, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 13872, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 13872, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 13872, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 13872, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 13872, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 13872, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 13872, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 15944, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 16184, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 16184, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 16184, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 16184, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 16184, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 16184, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 16184, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 18256, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 18496, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 18496, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 18496, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 18496, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 18496, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 18496, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 18496, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 20072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20568, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 20808, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 20808, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 20808, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 20808, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 20808, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 20808, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 20808, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 21225, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.002575882082063, "train/action_min": 0.0, "train/action_std": 2.000878125671449, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 6.65938906917941e-05, "train/actor_opt_grad_steps": 620.0, "train/actor_opt_loss": -5.173167900341313, "train/adv_mag": 4.247191803961283e-05, "train/adv_max": 4.23843571908804e-05, "train/adv_mean": 2.5363406138171946e-05, "train/adv_min": 3.839939393651456e-06, "train/adv_std": 1.1796867050024602e-05, "train/cont_avg": 0.9971258892276422, "train/cont_loss_mean": 0.02462117834537187, "train/cont_loss_std": 0.2942466682846918, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.836171266307002, "train/cont_pos_acc": 0.9972132148781443, "train/cont_pos_loss": 0.007874955020416635, "train/cont_pred": 0.9935212367918433, "train/cont_rate": 0.9971258892276422, "train/dyn_loss_mean": 1.1097175280253093, "train/dyn_loss_std": 0.007582473202750023, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 6.742523270409282, "train/extr_critic_critic_opt_grad_steps": 620.0, "train/extr_critic_critic_opt_loss": 7919.453293715066, "train/extr_critic_mag": 5.283006807652916e-06, "train/extr_critic_max": 5.279130082789475e-06, "train/extr_critic_mean": 5.124800362946865e-06, "train/extr_critic_min": 5.086263020833333e-06, "train/extr_critic_std": 2.0208131211756784e-08, "train/extr_return_normed_mag": 4.0260218364498756e-05, "train/extr_return_normed_max": 4.024557573149202e-05, "train/extr_return_normed_mean": 2.325219654384153e-05, "train/extr_return_normed_min": 1.8549837785620958e-06, "train/extr_return_normed_std": 1.1790702131574882e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 4.75040676270227e-05, "train/extr_return_raw_max": 4.748158485395938e-05, "train/extr_return_raw_mean": 3.048820556907616e-05, "train/extr_return_raw_min": 9.090992841220022e-06, "train/extr_return_raw_std": 1.179070204891342e-05, "train/extr_reward_mag": 4.038578126488662e-06, "train/extr_reward_max": 4.034701401625222e-06, "train/extr_reward_mean": 4.024331354017479e-06, "train/extr_reward_min": 4.017256139739742e-06, "train/extr_reward_std": 3.817098110943395e-09, "train/image_loss_mean": 42.44559159293407, "train/image_loss_std": 0.5751601393084701, "train/model_loss_mean": 43.30458619487964, "train/model_loss_std": 0.8214597998838115, "train/model_opt_grad_norm": 107.87070057040356, "train/model_opt_grad_steps": 610.0, "train/model_opt_loss": 822.8471060341935, "train/model_opt_model_opt_grad_overflow": 0.008130081300813009, "train/model_opt_model_opt_grad_scale": 11.512322154471544, "train/policy_entropy_mag": 1.9457889960064152, "train/policy_entropy_max": 1.9457889960064152, "train/policy_entropy_mean": 1.9401269695623133, "train/policy_entropy_min": 1.8637809065299304, "train/policy_entropy_std": 0.0036995223660885195, "train/policy_logprob_mag": 2.4609954337763593, "train/policy_logprob_max": -1.454999882515853, "train/policy_logprob_mean": -1.940087052864757, "train/policy_logprob_min": -2.4609954337763593, "train/policy_logprob_std": 0.09417927889077644, "train/policy_randomness_mag": 0.9999377998879285, "train/policy_randomness_max": 0.9999377998879285, "train/policy_randomness_mean": 0.9970280944816465, "train/policy_randomness_min": 0.9577939721142373, "train/policy_randomness_std": 0.0019011785516636522, "train/post_ent_mag": 85.1716876766546, "train/post_ent_max": 85.1716876766546, "train/post_ent_mean": 85.14190041146627, "train/post_ent_min": 84.98154697573283, "train/post_ent_std": 0.03141366230036185, "train/prior_ent_mag": 89.25620511683022, "train/prior_ent_max": 89.25620511683022, "train/prior_ent_mean": 89.1430633668977, "train/prior_ent_min": 88.82578531901042, "train/prior_ent_std": 0.06314571837826473, "train/rep_loss_mean": 1.1097175280253093, "train/rep_loss_std": 0.007582473202750023, "train/reward_avg": 1.5382843784897065e-05, "train/reward_loss_mean": 0.16854113895006903, "train/reward_loss_std": 0.024518860929800376, "train/reward_max_data": 0.014176828832161136, "train/reward_max_pred": 4.038578126488662e-06, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.16772932079772093, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 10.235526296827528, "train/reward_pred": 4.026181314413141e-06, "train/reward_rate": 7.939532520325203e-05, "train_stats/mean_log_entropy": 1.9240828421380785, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.014625849202275276, "report/cont_loss_std": 0.24731457233428955, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.605247974395752, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.003685291390866041, "report/cont_pred": 0.9963216185569763, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.2649836242198944, "report/image_loss_std": 0.09441512078046799, "report/model_loss_mean": 0.8807522058486938, "report/model_loss_std": 0.26121124625205994, "report/post_ent_mag": 75.83168029785156, "report/post_ent_max": 75.83168029785156, "report/post_ent_mean": 75.74687194824219, "report/post_ent_min": 75.72358703613281, "report/post_ent_std": 0.012311219237744808, "report/prior_ent_mag": 81.33360290527344, "report/prior_ent_max": 81.33360290527344, "report/prior_ent_mean": 81.27330017089844, "report/prior_ent_min": 80.67036437988281, "report/prior_ent_std": 0.09194175153970718, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.0011426876299083233, "report/reward_loss_std": 1.47073251355323e-06, "report/reward_max_data": 0.0, "report/reward_max_pred": 7.033348083496094e-06, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0011426876299083233, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 6.922520697116852e-06, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.003685291623696685, "eval/cont_loss_std": 4.656612873077393e-10, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.003685291623696685, "eval/cont_pred": 0.9963216185569763, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2558453381061554, "eval/image_loss_std": 0.09523336589336395, "eval/model_loss_mean": 0.8606734275817871, "eval/model_loss_std": 0.09523330628871918, "eval/post_ent_mag": 75.8294677734375, "eval/post_ent_max": 75.8294677734375, "eval/post_ent_mean": 75.74644470214844, "eval/post_ent_min": 75.7119140625, "eval/post_ent_std": 0.011638258583843708, "eval/prior_ent_mag": 81.33638000488281, "eval/prior_ent_max": 81.33638000488281, "eval/prior_ent_mean": 81.27725219726562, "eval/prior_ent_min": 80.67036437988281, "eval/prior_ent_std": 0.08664556592702866, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0011427351273596287, "eval/reward_loss_std": 1.4651625406258972e-06, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 7.033348083496094e-06, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0011427351273596287, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 6.9231027737259865e-06, "eval/reward_rate": 0.0, "replay/size": 20721.0, "replay/inserts": 19664.0, "replay/samples": 19664.0, "replay/insert_wait_avg": 1.3376611146236262e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 6.790394895536517e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 7992.0, "eval_replay/inserts": 4624.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1446566730222076e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 6.556510925292969e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 491.18377447128296, "timer/env.step_count": 2458.0, "timer/env.step_total": 5.092322587966919, "timer/env.step_frac": 0.01036744870786574, "timer/env.step_avg": 0.0020717341692298285, "timer/env.step_min": 0.001130819320678711, "timer/env.step_max": 0.012462377548217773, "timer/replay._sample_count": 19664.0, "timer/replay._sample_total": 1339.6646673679352, "timer/replay._sample_frac": 2.7274204421959354, "timer/replay._sample_avg": 0.0681277800736338, "timer/replay._sample_min": 0.0003540515899658203, "timer/replay._sample_max": 0.09656572341918945, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3036.0, "timer/agent.policy_total": 19.575418710708618, "timer/agent.policy_frac": 0.039853553248536906, "timer/agent.policy_avg": 0.006447766373751192, "timer/agent.policy_min": 0.0048961639404296875, "timer/agent.policy_max": 0.010805368423461914, "timer/dataset_train_count": 1229.0, "timer/dataset_train_total": 0.1002197265625, "timer/dataset_train_frac": 0.0002040371277947402, "timer/dataset_train_avg": 8.154574984743694e-05, "timer/dataset_train_min": 5.14984130859375e-05, "timer/dataset_train_max": 0.0001881122589111328, "timer/agent.train_count": 1229.0, "timer/agent.train_total": 459.7138411998749, "timer/agent.train_frac": 0.935930429898091, "timer/agent.train_avg": 0.37405520032536604, "timer/agent.train_min": 0.347506046295166, "timer/agent.train_max": 0.4600551128387451, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.39702630043029785, "timer/agent.report_frac": 0.0008083049991984415, "timer/agent.report_avg": 0.19851315021514893, "timer/agent.report_min": 0.19163131713867188, "timer/agent.report_max": 0.20539498329162598, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.814697265625e-05, "timer/dataset_eval_frac": 7.76633403603609e-08, "timer/dataset_eval_avg": 3.814697265625e-05, "timer/dataset_eval_min": 3.814697265625e-05, "timer/dataset_eval_max": 3.814697265625e-05, "fps": 40.0334200876579}
{"step": 22880, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 23120, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 23120, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 23120, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 23120, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 23120, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 23120, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 23120, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 25192, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 25432, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 25432, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 25432, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 25432, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 25432, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 25432, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 25432, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 27504, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 27744, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 27744, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 27744, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 27744, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 27744, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 27744, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 27744, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 29816, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 30056, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 30056, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 30056, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 30056, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 30056, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 30056, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 30056, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 30056, "eval_episode/length": 31.0, "eval_episode/score": 0.903124988079071, "eval_episode/reward_rate": 0.03125}
{"step": 30056, "eval_episode/length": 219.0, "eval_episode/score": 0.31562501192092896, "eval_episode/reward_rate": 0.004545454545454545}
{"step": 30056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30848, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102}
{"step": 31816, "episode/length": 219.0, "episode/score": 0.31562501192092896, "episode/reward_rate": 0.004545454545454545}
{"step": 32128, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 32368, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 32368, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 32368, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 32368, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 32368, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 33160, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 34128, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 34440, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 34680, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 34680, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 34680, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 34680, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 34680, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 35472, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 36440, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 36752, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 36992, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 36992, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 36992, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 36992, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 36992, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 37784, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 38752, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 38776, "episode/length": 252.0, "episode/score": 0.21250000596046448, "episode/reward_rate": 0.003952569169960474}
{"step": 39304, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 39304, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 39304, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 39304, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 39304, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 40040, "eval_episode/length": 75.0, "eval_episode/score": 0.765625, "eval_episode/reward_rate": 0.013157894736842105}
{"step": 40040, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40096, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 41064, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 41088, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 41193, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.000211654170867, "train/action_min": 0.0, "train/action_std": 2.000312101456427, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 2.5154346311014266e-05, "train/actor_opt_grad_steps": 1855.0, "train/actor_opt_loss": -4.808664864109408, "train/adv_mag": 7.736435582633168e-05, "train/adv_max": 7.736435582633168e-05, "train/adv_mean": 4.628222313840524e-05, "train/adv_min": 7.079948582325033e-06, "train/adv_std": 2.149153959679449e-05, "train/cont_avg": 0.9965190272177419, "train/cont_loss_mean": 0.023302935337978264, "train/cont_loss_std": 0.3198317232073871, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.728839465550014, "train/cont_pos_acc": 0.9999999855795214, "train/cont_pos_loss": 0.0033573287233124457, "train/cont_pred": 0.9966486793371939, "train/cont_rate": 0.9965190272177419, "train/dyn_loss_mean": 1.0000000192273049, "train/dyn_loss_std": 5.768965820607264e-07, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.21013665367518702, "train/extr_critic_critic_opt_grad_steps": 1855.0, "train/extr_critic_critic_opt_loss": 202.04280680994833, "train/extr_critic_mag": 0.00010077703383661086, "train/extr_critic_max": 0.00010077703383661086, "train/extr_critic_mean": 0.00010047023915244461, "train/extr_critic_min": 0.0001002982739479311, "train/extr_critic_std": 5.2573757290271914e-08, "train/extr_return_normed_mag": 9.281159090014333e-05, "train/extr_return_normed_max": 9.281159090014333e-05, "train/extr_return_normed_mean": 6.182358256703611e-05, "train/extr_return_normed_min": 2.2714759251680186e-05, "train/extr_return_normed_std": 2.1491423489527322e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.00017774046594446014, "train/extr_return_raw_max": 0.00017774046594446014, "train/extr_return_raw_mean": 0.00014675246007579018, "train/extr_return_raw_min": 0.000107643634295997, "train/extr_return_raw_std": 2.1491423489527322e-05, "train/extr_reward_mag": 7.643815009824692e-06, "train/extr_reward_max": 7.643815009824692e-06, "train/extr_reward_mean": 7.616726505940248e-06, "train/extr_reward_min": 7.548639851231729e-06, "train/extr_reward_std": 1.315908790087927e-08, "train/image_loss_mean": 0.28432545402357656, "train/image_loss_std": 0.0828987592831254, "train/model_loss_mean": 0.9083748704964115, "train/model_loss_std": 0.338752347915884, "train/model_opt_grad_norm": 93.20554960927656, "train/model_opt_grad_steps": 1845.0, "train/model_opt_loss": 24.29765413653466, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 26.77671370967742, "train/policy_entropy_mag": 1.94587696463831, "train/policy_entropy_max": 1.94587696463831, "train/policy_entropy_mean": 1.9443038634715542, "train/policy_entropy_min": 1.920664333528088, "train/policy_entropy_std": 0.0010720973068307485, "train/policy_logprob_mag": 2.239699577131579, "train/policy_logprob_max": -1.6413979780289434, "train/policy_logprob_mean": -1.9443045114317248, "train/policy_logprob_min": -2.239699577131579, "train/policy_logprob_std": 0.05649348919189746, "train/policy_randomness_mag": 0.9999830049853171, "train/policy_randomness_max": 0.9999830049853171, "train/policy_randomness_mean": 0.9991745910336894, "train/policy_randomness_min": 0.987026275646302, "train/policy_randomness_std": 0.000550949068471504, "train/post_ent_mag": 66.71986019995904, "train/post_ent_max": 66.71986019995904, "train/post_ent_mean": 66.58237205013153, "train/post_ent_min": 66.55644930562666, "train/post_ent_std": 0.02003130852995861, "train/prior_ent_mag": 74.68849428238407, "train/prior_ent_max": 74.68849428238407, "train/prior_ent_mean": 74.6105715843939, "train/prior_ent_min": 74.22827037688225, "train/prior_ent_std": 0.060777537434572176, "train/rep_loss_mean": 1.0000000192273049, "train/rep_loss_std": 5.768965820607264e-07, "train/reward_avg": 4.011584913373113e-06, "train/reward_loss_mean": 0.0007464504094734307, "train/reward_loss_std": 0.005353074561946021, "train/reward_max_data": 0.004107862951294068, "train/reward_max_pred": 7.651505931731194e-06, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.0005791100242453056, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 10.624787330627441, "train/reward_pred": 7.6166207661792154e-06, "train/reward_rate": 1.575100806451613e-05, "train_stats/mean_log_entropy": 1.9374204251303602, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.02001912146806717, "report/cont_loss_std": 0.31837204098701477, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.893386363983154, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.002761431271210313, "report/cont_pred": 0.9972422122955322, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.2716870903968811, "report/image_loss_std": 0.07114196568727493, "report/model_loss_mean": 0.8920099139213562, "report/model_loss_std": 0.33068493008613586, "report/post_ent_mag": 58.66609573364258, "report/post_ent_max": 58.66609573364258, "report/post_ent_mean": 58.51734161376953, "report/post_ent_min": 58.48417663574219, "report/post_ent_std": 0.021266402676701546, "report/prior_ent_mag": 66.3648452758789, "report/prior_ent_max": 66.3648452758789, "report/prior_ent_mean": 66.28022003173828, "report/prior_ent_min": 66.06465911865234, "report/prior_ent_std": 0.03712957724928856, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.00030370429158210754, "report/reward_loss_std": 2.140988755172657e-07, "report/reward_max_data": 0.0, "report/reward_max_pred": 1.6689300537109375e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00030370429158210754, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 1.6683130525052547e-05, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.002761431271210313, "eval/cont_loss_std": 2.3283064365386963e-10, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.002761431271210313, "eval/cont_pred": 0.9972422122955322, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2764802575111389, "eval/image_loss_std": 0.07347074151039124, "eval/model_loss_mean": 0.8795454502105713, "eval/model_loss_std": 0.07347074896097183, "eval/post_ent_mag": 58.664955139160156, "eval/post_ent_max": 58.664955139160156, "eval/post_ent_mean": 58.51689910888672, "eval/post_ent_min": 58.48991394042969, "eval/post_ent_std": 0.019542142748832703, "eval/prior_ent_mag": 66.36797332763672, "eval/prior_ent_max": 66.36797332763672, "eval/prior_ent_mean": 66.2824478149414, "eval/prior_ent_min": 66.06465911865234, "eval/prior_ent_std": 0.03484946861863136, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00030371639877557755, "eval/reward_loss_std": 1.55033731630283e-07, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 1.6689300537109375e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00030371639877557755, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 1.6685226000845432e-05, "eval/reward_rate": 0.0, "replay/size": 40689.0, "replay/inserts": 19968.0, "replay/samples": 19968.0, "replay/insert_wait_avg": 1.3542863038870005e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 6.901577879221012e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 12616.0, "eval_replay/inserts": 4624.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.292121451618762e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 500.2248737812042, "timer/env.step_count": 2496.0, "timer/env.step_total": 5.143575191497803, "timer/env.step_frac": 0.010282525842062736, "timer/env.step_avg": 0.0020607272401834144, "timer/env.step_min": 0.0011317729949951172, "timer/env.step_max": 0.009536504745483398, "timer/replay._sample_count": 19968.0, "timer/replay._sample_total": 1363.9627463817596, "timer/replay._sample_frac": 2.7266991664599827, "timer/replay._sample_avg": 0.0683074292058173, "timer/replay._sample_min": 0.00033974647521972656, "timer/replay._sample_max": 0.10234594345092773, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3074.0, "timer/agent.policy_total": 20.213926315307617, "timer/agent.policy_frac": 0.04040967847622284, "timer/agent.policy_avg": 0.0065757730368599925, "timer/agent.policy_min": 0.00493621826171875, "timer/agent.policy_max": 0.31942272186279297, "timer/dataset_train_count": 1248.0, "timer/dataset_train_total": 0.1047677993774414, "timer/dataset_train_frac": 0.00020944140299441867, "timer/dataset_train_avg": 8.394855719346266e-05, "timer/dataset_train_min": 6.270408630371094e-05, "timer/dataset_train_max": 0.0005409717559814453, "timer/agent.train_count": 1248.0, "timer/agent.train_total": 467.8293299674988, "timer/agent.train_frac": 0.9352380389067276, "timer/agent.train_avg": 0.37486324516626507, "timer/agent.train_min": 0.34874725341796875, "timer/agent.train_max": 0.5070812702178955, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.420332670211792, "timer/agent.report_frac": 0.0008402874232032758, "timer/agent.report_avg": 0.210166335105896, "timer/agent.report_min": 0.20428228378295898, "timer/agent.report_max": 0.216050386428833, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.4809112548828125e-05, "timer/dataset_eval_frac": 6.958692854616713e-08, "timer/dataset_eval_avg": 3.4809112548828125e-05, "timer/dataset_eval_min": 3.4809112548828125e-05, "timer/dataset_eval_max": 3.4809112548828125e-05, "fps": 39.91758535582062}
{"step": 41616, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 41616, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 41616, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 41616, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 41616, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 42408, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 43376, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 43400, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 43928, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 43928, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 43928, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 43928, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 43928, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 44720, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 45136, "episode/length": 219.0, "episode/score": 0.31562501192092896, "episode/reward_rate": 0.004545454545454545}
{"step": 45712, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 46240, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 46240, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 46240, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 46240, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 46240, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 46520, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857}
{"step": 47032, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 47448, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 48024, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 48552, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 48552, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 48552, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 48552, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 48832, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 49344, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 49760, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 50024, "eval_episode/length": 16.0, "eval_episode/score": 0.949999988079071, "eval_episode/reward_rate": 0.058823529411764705}
{"step": 50024, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50336, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 50800, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827}
{"step": 50864, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 50864, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 50864, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 50864, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 51144, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 51656, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 52072, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 53112, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 53176, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 53176, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 53176, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 53176, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 53456, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 53968, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 54384, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 55424, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 55488, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 55488, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 55488, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 55488, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 55768, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 56280, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 56696, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 57736, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 57800, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 57800, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 57800, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 57800, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 58080, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 58256, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806}
{"step": 58592, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 59008, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 60008, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60048, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 60112, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 60112, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 60112, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 60392, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 60393, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.0030471801757814, "train/action_min": 0.0, "train/action_std": 1.9995839228232701, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 8.679053574572511e-05, "train/actor_opt_grad_steps": 3075.0, "train/actor_opt_loss": -2.327404174829523, "train/adv_mag": 0.00029885044787079094, "train/adv_max": 0.00029885044787079094, "train/adv_mean": 0.00017632433203592276, "train/adv_min": 2.232298138551414e-05, "train/adv_std": 8.19002960876484e-05, "train/cont_avg": 0.9966715494791667, "train/cont_loss_mean": 0.022467849258100615, "train/cont_loss_std": 0.3164792275674756, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.699594094203069, "train/cont_pos_acc": 0.9999999900658926, "train/cont_pos_loss": 0.0034442401656027263, "train/cont_pred": 0.9965619524319966, "train/cont_rate": 0.9966715494791667, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.06834429881225029, "train/extr_critic_critic_opt_grad_steps": 3075.0, "train/extr_critic_critic_opt_loss": 1355.90488764445, "train/extr_critic_mag": 0.002076368530591329, "train/extr_critic_max": 0.002076368530591329, "train/extr_critic_mean": 0.0020699270865103853, "train/extr_critic_min": 0.002065086364746094, "train/extr_critic_std": 1.5026874163955503e-06, "train/extr_return_normed_mag": 0.0005663072680666422, "train/extr_return_normed_max": 0.0005663072680666422, "train/extr_return_normed_mean": 0.0004467042483156547, "train/extr_return_normed_min": 0.0002951251650908186, "train/extr_return_normed_std": 8.187932738413413e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.002365854346620229, "train/extr_return_raw_max": 0.002365854346620229, "train/extr_return_raw_mean": 0.0022462514374637977, "train/extr_return_raw_min": 0.002094672243644406, "train/extr_return_raw_std": 8.187932771761553e-05, "train/extr_reward_mag": 3.4143527348836265e-05, "train/extr_reward_max": 3.4143527348836265e-05, "train/extr_reward_mean": 3.408286732640893e-05, "train/extr_reward_min": 3.3943851788838705e-05, "train/extr_reward_std": 2.9830664294294705e-08, "train/image_loss_mean": 0.27201453323165575, "train/image_loss_std": 0.08474050797522067, "train/model_loss_mean": 0.8955279797315597, "train/model_loss_std": 0.3481437766303619, "train/model_opt_grad_norm": 78.3463522275289, "train/model_opt_grad_steps": 3065.0, "train/model_opt_loss": 54.19428981145223, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 60.546875, "train/policy_entropy_mag": 1.9458906014760335, "train/policy_entropy_max": 1.9458906014760335, "train/policy_entropy_mean": 1.9449361522992452, "train/policy_entropy_min": 1.929493851463, "train/policy_entropy_std": 0.0006767873283630858, "train/policy_logprob_mag": 2.1886297007401785, "train/policy_logprob_max": -1.7052087366580964, "train/policy_logprob_mean": -1.9450049151976903, "train/policy_logprob_min": -2.1886297007401785, "train/policy_logprob_std": 0.04408798919369777, "train/policy_randomness_mag": 0.9999900137384733, "train/policy_randomness_max": 0.9999900137384733, "train/policy_randomness_mean": 0.9994995166858037, "train/policy_randomness_min": 0.9915637513001759, "train/policy_randomness_std": 0.00034779989776628404, "train/post_ent_mag": 52.1236065864563, "train/post_ent_max": 52.1236065864563, "train/post_ent_mean": 51.97102133433024, "train/post_ent_min": 51.93667510350545, "train/post_ent_std": 0.022138024509573976, "train/prior_ent_mag": 61.38270483016968, "train/prior_ent_max": 61.38270483016968, "train/prior_ent_mean": 61.28388395309448, "train/prior_ent_min": 61.16077496210734, "train/prior_ent_std": 0.028492345459138355, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 3.1458537705475464e-05, "train/reward_loss_mean": 0.0010455749230459332, "train/reward_loss_std": 0.02508235656131189, "train/reward_max_data": 0.032213542610406876, "train/reward_max_pred": 3.417134284973144e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.0002613759770611068, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 10.707189665900337, "train/reward_pred": 3.4119067519592744e-05, "train/reward_rate": 7.32421875e-05, "train_stats/mean_log_entropy": 1.9368085021704016, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.0202444139868021, "report/cont_loss_std": 0.29493749141693115, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.4612884521484375, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.004257014952600002, "report/cont_pred": 0.995752215385437, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.24781957268714905, "report/image_loss_std": 0.08285651355981827, "report/model_loss_mean": 0.868314802646637, "report/model_loss_std": 0.30703458189964294, "report/post_ent_mag": 46.49822998046875, "report/post_ent_max": 46.49822998046875, "report/post_ent_mean": 46.37150573730469, "report/post_ent_min": 46.326412200927734, "report/post_ent_std": 0.0196259543299675, "report/prior_ent_mag": 57.25182342529297, "report/prior_ent_max": 57.25182342529297, "report/prior_ent_mean": 57.152503967285156, "report/prior_ent_min": 57.10765838623047, "report/prior_ent_std": 0.022297445684671402, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.0002507967874407768, "report/reward_loss_std": 1.301421264088276e-07, "report/reward_max_data": 0.0, "report/reward_max_pred": 5.6862831115722656e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0002507967874407768, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 5.685992073267698e-05, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.004256999120116234, "eval/cont_loss_std": 1.4581737559637986e-06, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.004256999120116234, "eval/cont_pred": 0.995752215385437, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2535446882247925, "eval/image_loss_std": 0.08011042326688766, "eval/model_loss_mean": 0.8580524921417236, "eval/model_loss_std": 0.08011039346456528, "eval/post_ent_mag": 46.49763488769531, "eval/post_ent_max": 46.49763488769531, "eval/post_ent_mean": 46.37248611450195, "eval/post_ent_min": 46.332889556884766, "eval/post_ent_std": 0.018118565902113914, "eval/prior_ent_mag": 57.24662399291992, "eval/prior_ent_max": 57.24662399291992, "eval/prior_ent_mean": 57.1502571105957, "eval/prior_ent_min": 57.104148864746094, "eval/prior_ent_std": 0.020933708176016808, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00025079958140850067, "eval/reward_loss_std": 1.1420004852880083e-07, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 5.6862831115722656e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00025079958140850067, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 5.686073563992977e-05, "eval/reward_rate": 0.0, "replay/size": 59889.0, "replay/inserts": 19200.0, "replay/samples": 19200.0, "replay/insert_wait_avg": 1.3729681571324667e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.261335849761962e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 17240.0, "eval_replay/inserts": 4624.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3567275241997003e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.493661880493164e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 500.1597537994385, "timer/env.step_count": 2400.0, "timer/env.step_total": 5.156869411468506, "timer/env.step_frac": 0.010310444557553073, "timer/env.step_avg": 0.0021486955881118773, "timer/env.step_min": 0.0010833740234375, "timer/env.step_max": 0.009948015213012695, "timer/replay._sample_count": 19200.0, "timer/replay._sample_total": 1326.6712386608124, "timer/replay._sample_frac": 2.6524949850179285, "timer/replay._sample_avg": 0.06909746034691731, "timer/replay._sample_min": 0.0003380775451660156, "timer/replay._sample_max": 0.09833025932312012, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2978.0, "timer/agent.policy_total": 19.814276456832886, "timer/agent.policy_frac": 0.03961589533407022, "timer/agent.policy_avg": 0.006653551530165509, "timer/agent.policy_min": 0.004849672317504883, "timer/agent.policy_max": 0.011627197265625, "timer/dataset_train_count": 1200.0, "timer/dataset_train_total": 0.1037759780883789, "timer/dataset_train_frac": 0.00020748566293079341, "timer/dataset_train_avg": 8.647998174031576e-05, "timer/dataset_train_min": 6.794929504394531e-05, "timer/dataset_train_max": 0.00022649765014648438, "timer/agent.train_count": 1200.0, "timer/agent.train_total": 468.187885761261, "timer/agent.train_frac": 0.9360766879076039, "timer/agent.train_avg": 0.3901565714677175, "timer/agent.train_min": 0.3494586944580078, "timer/agent.train_max": 0.53900146484375, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4003894329071045, "timer/agent.report_frac": 0.0008005230926030458, "timer/agent.report_avg": 0.20019471645355225, "timer/agent.report_min": 0.19278907775878906, "timer/agent.report_max": 0.20760035514831543, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 4.8160552978515625e-05, "timer/dataset_eval_frac": 9.629034046155533e-08, "timer/dataset_eval_avg": 4.8160552978515625e-05, "timer/dataset_eval_min": 4.8160552978515625e-05, "timer/dataset_eval_max": 4.8160552978515625e-05, "fps": 38.38725712313969}
{"step": 60568, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 60904, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 61320, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 62360, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 62424, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 62424, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 62424, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 62704, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 62880, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 63160, "episode/length": 281.0, "episode/score": 0.12187500298023224, "episode/reward_rate": 0.0035460992907801418}
{"step": 63632, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 64672, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 64736, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 64736, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 64736, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 65016, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 65192, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 65472, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 65944, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 66984, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 67048, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 67048, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 67048, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 67328, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 67504, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 67784, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 68256, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 69296, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 69360, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 69360, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 69360, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 69640, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 69816, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 70096, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 70096, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70568, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 71608, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 71672, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 71672, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 71672, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 71952, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 72128, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 72408, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 72880, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 73856, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541}
{"step": 73920, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 73984, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 73984, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 73984, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 74264, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 74440, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 74720, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 76168, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 76232, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 76296, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 76296, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 76296, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 76576, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 76752, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 77032, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 78480, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 78544, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 78608, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 78608, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 78608, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 78864, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125}
{"step": 78888, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 79064, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 79344, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 79785, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.0007089083311986, "train/action_min": 0.0, "train/action_std": 1.9986917190864437, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 9.522517644117975e-05, "train/actor_opt_grad_steps": 4285.0, "train/actor_opt_loss": -1.7547724045752013, "train/adv_mag": 0.00036116872654586544, "train/adv_max": 0.00036116872654586544, "train/adv_mean": 0.00020631047330231818, "train/adv_min": 1.3600752429395425e-05, "train/adv_std": 9.61823293959033e-05, "train/cont_avg": 0.9963819159836066, "train/cont_loss_mean": 0.02401554245562827, "train/cont_loss_std": 0.3303553084613847, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.680608358539518, "train/cont_pos_acc": 0.9999999853431202, "train/cont_pos_loss": 0.003467394684090233, "train/cont_pred": 0.9965387817289009, "train/cont_rate": 0.9963819159836066, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.029896500222690282, "train/extr_critic_critic_opt_grad_steps": 4285.0, "train/extr_critic_critic_opt_loss": 3631.577798812116, "train/extr_critic_mag": 0.007282893188664171, "train/extr_critic_max": 0.007282893188664171, "train/extr_critic_mean": 0.007261047628326494, "train/extr_critic_min": 0.00724593635465278, "train/extr_critic_std": 5.2973355186399295e-06, "train/extr_return_normed_mag": 0.0007262243545751591, "train/extr_return_normed_max": 0.0007262243545751591, "train/extr_return_normed_mean": 0.0005816444589996894, "train/extr_return_normed_min": 0.00039694373129454795, "train/extr_return_normed_std": 9.596030682945131e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.00761193766441868, "train/extr_return_raw_max": 0.00761193766441868, "train/extr_return_raw_mean": 0.007467358128824195, "train/extr_return_raw_min": 0.007282657041138068, "train/extr_return_raw_std": 9.596030690400007e-05, "train/extr_reward_mag": 5.4467896946140976e-05, "train/extr_reward_max": 5.4467896946140976e-05, "train/extr_reward_mean": 5.4419014244946296e-05, "train/extr_reward_min": 5.432914515010646e-05, "train/extr_reward_std": 2.0661887397742863e-08, "train/image_loss_mean": 0.26250330273245204, "train/image_loss_std": 0.08431247066034646, "train/model_loss_mean": 0.8880332043913545, "train/model_loss_std": 0.37062957919523365, "train/model_opt_grad_norm": 67.67756426138956, "train/model_opt_grad_steps": 4275.0, "train/model_opt_loss": 119.3744797628434, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 134.47745901639345, "train/policy_entropy_mag": 1.9458956571876025, "train/policy_entropy_max": 1.9458956571876025, "train/policy_entropy_mean": 1.945213460531391, "train/policy_entropy_min": 1.9319010621211568, "train/policy_entropy_std": 0.0005064373232374639, "train/policy_logprob_mag": 2.1588055638016246, "train/policy_logprob_max": -1.734507354556537, "train/policy_logprob_mean": -1.9452291492555962, "train/policy_logprob_min": -2.1588055638016246, "train/policy_logprob_std": 0.03724805238183405, "train/policy_randomness_mag": 0.9999926143982372, "train/policy_randomness_max": 0.9999926143982372, "train/policy_randomness_mean": 0.9996420355116735, "train/policy_randomness_min": 0.9928008132293576, "train/policy_randomness_std": 0.0002602573136367728, "train/post_ent_mag": 43.49283787461578, "train/post_ent_max": 43.49283787461578, "train/post_ent_mean": 43.420638193849655, "train/post_ent_min": 43.35152751109639, "train/post_ent_std": 0.01942436500895219, "train/prior_ent_mag": 52.638486017946335, "train/prior_ent_max": 52.638486017946335, "train/prior_ent_mean": 52.571036323172144, "train/prior_ent_min": 52.47557455594422, "train/prior_ent_std": 0.019346334322615236, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 6.336149650809095e-05, "train/reward_loss_mean": 0.0015143383538625279, "train/reward_loss_std": 0.040313972637981, "train/reward_max_data": 0.06329405796332438, "train/reward_max_pred": 5.44805995753554e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00020343040583223928, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 10.200797017415365, "train/reward_pred": 5.442428509475755e-05, "train/reward_rate": 0.00012807377049180329, "train_stats/mean_log_entropy": 1.937631978708155, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.042103320360183716, "report/cont_loss_std": 0.464768648147583, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.644169807434082, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0035443599335849285, "report/cont_pred": 0.9964619278907776, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.2683238387107849, "report/image_loss_std": 0.08669281750917435, "report/model_loss_mean": 0.910578727722168, "report/model_loss_std": 0.4679863750934601, "report/post_ent_mag": 43.132606506347656, "report/post_ent_max": 43.132606506347656, "report/post_ent_mean": 43.10063171386719, "report/post_ent_min": 42.95502471923828, "report/post_ent_std": 0.0377027727663517, "report/prior_ent_mag": 42.424224853515625, "report/prior_ent_max": 42.424224853515625, "report/prior_ent_mean": 42.290252685546875, "report/prior_ent_min": 42.23540496826172, "report/prior_ent_std": 0.024098282679915428, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.00015163421630859375, "report/reward_loss_std": 0.0, "report/reward_max_data": 0.0, "report/reward_max_pred": 4.661083221435547e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00015163421630859375, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 4.661083221435547e-05, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.003544360166415572, "eval/cont_loss_std": 2.3283064365386963e-10, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.003544360166415572, "eval/cont_pred": 0.9964619278907776, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.25462543964385986, "eval/image_loss_std": 0.08414128422737122, "eval/model_loss_mean": 0.8583214282989502, "eval/model_loss_std": 0.08414128422737122, "eval/post_ent_mag": 43.13433074951172, "eval/post_ent_max": 43.13433074951172, "eval/post_ent_mean": 43.106449127197266, "eval/post_ent_min": 42.95477294921875, "eval/post_ent_std": 0.03276204317808151, "eval/prior_ent_mag": 42.424224853515625, "eval/prior_ent_max": 42.424224853515625, "eval/prior_ent_mean": 42.29186248779297, "eval/prior_ent_min": 42.241859436035156, "eval/prior_ent_std": 0.020350534468889236, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00015163421630859375, "eval/reward_loss_std": 0.0, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 4.661083221435547e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00015163421630859375, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 4.661083221435547e-05, "eval/reward_rate": 0.0, "replay/size": 79281.0, "replay/inserts": 19392.0, "replay/samples": 19392.0, "replay/insert_wait_avg": 1.4529492792123222e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.479719006189025e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 19552.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3262549073638389e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0132789611816406e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 500.2579503059387, "timer/env.step_count": 2424.0, "timer/env.step_total": 5.316834926605225, "timer/env.step_frac": 0.010628186765155158, "timer/env.step_avg": 0.0021934137485995152, "timer/env.step_min": 0.001153707504272461, "timer/env.step_max": 0.010742902755737305, "timer/replay._sample_count": 19392.0, "timer/replay._sample_total": 1349.841667175293, "timer/replay._sample_frac": 2.69829128422603, "timer/replay._sample_avg": 0.06960817178090413, "timer/replay._sample_min": 0.0003190040588378906, "timer/replay._sample_max": 0.1031179428100586, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2713.0, "timer/agent.policy_total": 18.292569160461426, "timer/agent.policy_frac": 0.036566273757917066, "timer/agent.policy_avg": 0.006742561430321203, "timer/agent.policy_min": 0.005075931549072266, "timer/agent.policy_max": 0.016437768936157227, "timer/dataset_train_count": 1212.0, "timer/dataset_train_total": 0.10710620880126953, "timer/dataset_train_frac": 0.0002141019622692002, "timer/dataset_train_avg": 8.837145940698806e-05, "timer/dataset_train_min": 7.2479248046875e-05, "timer/dataset_train_max": 0.00019407272338867188, "timer/agent.train_count": 1212.0, "timer/agent.train_total": 470.55551981925964, "timer/agent.train_frac": 0.9406257702281109, "timer/agent.train_avg": 0.3882471285637456, "timer/agent.train_min": 0.350527286529541, "timer/agent.train_max": 0.6341605186462402, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.44954347610473633, "timer/agent.report_frac": 0.0008986233518723944, "timer/agent.report_avg": 0.22477173805236816, "timer/agent.report_min": 0.2233107089996338, "timer/agent.report_max": 0.22623276710510254, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 5.91278076171875e-05, "timer/dataset_eval_frac": 1.1819463854802744e-07, "timer/dataset_eval_avg": 5.91278076171875e-05, "timer/dataset_eval_min": 5.91278076171875e-05, "timer/dataset_eval_max": 5.91278076171875e-05, "fps": 38.763350686758436}
{"step": 80080, "eval_episode/length": 228.0, "eval_episode/score": 0.2874999940395355, "eval_episode/reward_rate": 0.004366812227074236}
{"step": 80080, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80792, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 80856, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 80920, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 80920, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 81176, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 81200, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 81376, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 81656, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 81792, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505}
{"step": 83104, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 83168, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 83232, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 83488, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 83512, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 83688, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 83968, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 84104, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 85416, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 85480, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 85544, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 85800, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 85824, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 86000, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 86280, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 86416, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 87728, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 87792, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 87856, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 88112, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 88136, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 88312, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 88592, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 88728, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 90040, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 90064, "eval_episode/length": 160.0, "eval_episode/score": 0.5, "eval_episode/reward_rate": 0.006211180124223602}
{"step": 90064, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90104, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 90168, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 90424, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 90448, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 90624, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 90904, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 91040, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 92352, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 92416, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 92480, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 92736, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 92760, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 92776, "episode/length": 216.0, "episode/score": 0.32499998807907104, "episode/reward_rate": 0.004608294930875576}
{"step": 92936, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 93216, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 94664, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 94728, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 94792, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 95048, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 95072, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 95088, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 95248, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 95528, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 96976, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 97040, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 97104, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 97360, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 97384, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 97400, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 97560, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 97840, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 98665, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.9998986195709745, "train/action_min": 0.0, "train/action_std": 1.9999428644018657, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 6.135956470905635e-05, "train/actor_opt_grad_steps": 5485.0, "train/actor_opt_loss": -3.329669559406022, "train/adv_mag": 0.00023457709447307102, "train/adv_max": 0.00023457709447307102, "train/adv_mean": 0.00012382336877882322, "train/adv_min": -1.3527002627566709e-05, "train/adv_std": 5.923887561886844e-05, "train/cont_avg": 0.9962840969279662, "train/cont_loss_mean": 0.024599818301671263, "train/cont_loss_std": 0.3286946032105519, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.681949864446589, "train/cont_pos_acc": 0.9999999828257803, "train/cont_pos_loss": 0.003480878498768276, "train/cont_pred": 0.99652530682289, "train/cont_rate": 0.9962840969279662, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.01585967272867338, "train/extr_critic_critic_opt_grad_steps": 5485.0, "train/extr_critic_critic_opt_loss": 4772.619703389831, "train/extr_critic_mag": 0.010565827458591784, "train/extr_critic_max": 0.010565827458591784, "train/extr_critic_mean": 0.010532286649538298, "train/extr_critic_min": 0.01051215196059922, "train/extr_critic_std": 9.061126661676854e-06, "train/extr_return_normed_mag": 0.0004459721888652292, "train/extr_return_normed_max": 0.0004459721888652292, "train/extr_return_normed_mean": 0.0003519141950380152, "train/extr_return_normed_min": 0.00023076560948107202, "train/extr_return_normed_std": 5.8176200913664415e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.010750167434877259, "train/extr_return_raw_max": 0.010750167434877259, "train/extr_return_raw_mean": 0.010656110082074241, "train/extr_return_raw_min": 0.010534960855493101, "train/extr_return_raw_std": 5.817620072097486e-05, "train/extr_reward_mag": 5.126807649256819e-05, "train/extr_reward_max": 5.126807649256819e-05, "train/extr_reward_mean": 5.120938451801845e-05, "train/extr_reward_min": 5.113573397620249e-05, "train/extr_reward_std": 1.95298828850939e-08, "train/image_loss_mean": 0.2615680418024629, "train/image_loss_std": 0.08268116768133843, "train/model_loss_mean": 0.888205265089617, "train/model_loss_std": 0.38523432719758, "train/model_opt_grad_norm": 63.260847770561604, "train/model_opt_grad_steps": 5475.0, "train/model_opt_loss": 277.46519327971896, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 312.5, "train/policy_entropy_mag": 1.9459012585171198, "train/policy_entropy_max": 1.9459012585171198, "train/policy_entropy_mean": 1.9454225736149287, "train/policy_entropy_min": 1.9351824663453183, "train/policy_entropy_std": 0.0003757848169050827, "train/policy_logprob_mag": 2.137089262574406, "train/policy_logprob_max": -1.7623184666795246, "train/policy_logprob_mean": -1.9454144441475303, "train/policy_logprob_min": -2.137089262574406, "train/policy_logprob_std": 0.031208917293381894, "train/policy_randomness_mag": 0.9999954917673337, "train/policy_randomness_max": 0.9999954917673337, "train/policy_randomness_mean": 0.9997494821831331, "train/policy_randomness_min": 0.9944871204384302, "train/policy_randomness_std": 0.00019311522204188187, "train/post_ent_mag": 40.44500554618189, "train/post_ent_max": 40.44500554618189, "train/post_ent_mean": 40.41134944204557, "train/post_ent_min": 40.22940735897775, "train/post_ent_std": 0.045720040640335975, "train/prior_ent_mag": 42.46215939925889, "train/prior_ent_max": 42.46215939925889, "train/prior_ent_mean": 42.35558823407707, "train/prior_ent_min": 42.30914497375488, "train/prior_ent_std": 0.01910001713529987, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 8.95354716734708e-05, "train/reward_loss_mean": 0.0020373793658247943, "train/reward_loss_std": 0.056824640431439484, "train/reward_max_data": 0.08339512828042951, "train/reward_max_pred": 5.1251912521103684e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.0001590059029571791, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 10.29954981803894, "train/reward_pred": 5.1185158199741175e-05, "train/reward_rate": 0.0001820709745762712, "eval_stats/mean_log_entropy": 0.0, "train_stats/mean_log_entropy": 1.9384796912853535, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.020056329667568207, "report/cont_loss_std": 0.3061269223690033, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.667525291442871, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0034623967949301004, "report/cont_pred": 0.9965437054634094, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.24707376956939697, "report/image_loss_std": 0.09863701462745667, "report/model_loss_mean": 0.8877180814743042, "report/model_loss_std": 0.7495537400245667, "report/post_ent_mag": 39.13458251953125, "report/post_ent_max": 39.13458251953125, "report/post_ent_mean": 39.09889221191406, "report/post_ent_min": 38.85157012939453, "report/post_ent_std": 0.06093861162662506, "report/prior_ent_mag": 42.519901275634766, "report/prior_ent_max": 42.519901275634766, "report/prior_ent_mean": 42.43329620361328, "report/prior_ent_min": 42.380157470703125, "report/prior_ent_std": 0.01637864299118519, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00091552734375, "report/reward_loss_mean": 0.020588014274835587, "report/reward_loss_std": 0.46221229434013367, "report/reward_max_data": 0.621874988079071, "report/reward_max_pred": 5.9485435485839844e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00015621409693267196, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 10.461236000061035, "report/reward_pred": 5.938997492194176e-05, "report/reward_rate": 0.001953125, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.0034623967949301004, "eval/cont_loss_std": 2.3283064365386963e-10, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0034623967949301004, "eval/cont_pred": 0.9965437054634094, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2599928379058838, "eval/image_loss_std": 0.097489133477211, "eval/model_loss_mean": 0.8636114001274109, "eval/model_loss_std": 0.09748914837837219, "eval/post_ent_mag": 39.13733673095703, "eval/post_ent_max": 39.13733673095703, "eval/post_ent_mean": 39.10205078125, "eval/post_ent_min": 38.849754333496094, "eval/post_ent_std": 0.057034894824028015, "eval/prior_ent_mag": 42.519901275634766, "eval/prior_ent_max": 42.519901275634766, "eval/prior_ent_mean": 42.43433380126953, "eval/prior_ent_min": 42.35472106933594, "eval/prior_ent_std": 0.015768639743328094, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00015622470527887344, "eval/reward_loss_std": 2.3252310654697794e-07, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 5.9604644775390625e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00015622470527887344, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 5.9394980780780315e-05, "eval/reward_rate": 0.0, "replay/size": 98161.0, "replay/inserts": 18880.0, "replay/samples": 18880.0, "replay/insert_wait_avg": 1.4636981285224527e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.538093348680916e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 20000.0, "eval_replay/inserts": 4624.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.4906317304987396e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.387731552124023e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 500.1327815055847, "timer/env.step_count": 2360.0, "timer/env.step_total": 5.321796894073486, "timer/env.step_frac": 0.010640767993757395, "timer/env.step_avg": 0.0022549986839294433, "timer/env.step_min": 0.0011467933654785156, "timer/env.step_max": 0.014496088027954102, "timer/replay._sample_count": 18880.0, "timer/replay._sample_total": 1318.5795741081238, "timer/replay._sample_frac": 2.636459002224792, "timer/replay._sample_avg": 0.06984001981504893, "timer/replay._sample_min": 0.0004253387451171875, "timer/replay._sample_max": 0.10128903388977051, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2938.0, "timer/agent.policy_total": 20.188655853271484, "timer/agent.policy_frac": 0.04036659183286519, "timer/agent.policy_avg": 0.0068715642795342015, "timer/agent.policy_min": 0.005010128021240234, "timer/agent.policy_max": 0.01090383529663086, "timer/dataset_train_count": 1180.0, "timer/dataset_train_total": 0.10648822784423828, "timer/dataset_train_frac": 0.00021291991203549847, "timer/dataset_train_avg": 9.024426088494769e-05, "timer/dataset_train_min": 6.771087646484375e-05, "timer/dataset_train_max": 0.0002522468566894531, "timer/agent.train_count": 1180.0, "timer/agent.train_total": 467.32752418518066, "timer/agent.train_frac": 0.9344069044591556, "timer/agent.train_avg": 0.39604027473320397, "timer/agent.train_min": 0.35756826400756836, "timer/agent.train_max": 0.8958053588867188, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.41914868354797363, "timer/agent.report_frac": 0.0008380748054270329, "timer/agent.report_avg": 0.20957434177398682, "timer/agent.report_min": 0.20940208435058594, "timer/agent.report_max": 0.2097465991973877, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.8623809814453125e-05, "timer/dataset_eval_frac": 7.722711096477453e-08, "timer/dataset_eval_avg": 3.8623809814453125e-05, "timer/dataset_eval_min": 3.8623809814453125e-05, "timer/dataset_eval_max": 3.8623809814453125e-05, "fps": 37.74946382085934}
{"step": 99288, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 99352, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 99416, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 99672, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 99696, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 99712, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 99872, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 100048, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100152, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 101600, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 101664, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 101728, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 101984, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 102008, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 102024, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 102184, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 102464, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 103912, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 103976, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 104040, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 104296, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 104320, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 104336, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 104496, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 104776, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 106224, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 106288, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 106352, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 106608, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 106632, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 106648, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 106808, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 107088, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 108536, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 108600, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 108664, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 108920, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 108944, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 108960, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 109120, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 109400, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 110032, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110848, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 110912, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 110976, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 111232, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 111256, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 111272, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 111432, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 111712, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 113160, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 113224, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 113288, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 113544, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 113568, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 113584, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 113744, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 114024, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 115472, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 115536, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 115600, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 115856, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 115880, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 115896, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 116056, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 116336, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 117784, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 117848, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 117912, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 118168, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 118192, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 118208, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 118368, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 118409, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.9986259646532014, "train/action_min": 0.0, "train/action_std": 2.000955824929524, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 6.372057354812155e-05, "train/actor_opt_grad_steps": 6690.0, "train/actor_opt_loss": -4.110287961330477, "train/adv_mag": 0.0001977175716462174, "train/adv_max": 0.000184765486879562, "train/adv_mean": 8.296341518548449e-05, "train/adv_min": -3.8186868092393484e-05, "train/adv_std": 4.8432180695575276e-05, "train/cont_avg": 0.9964669080284553, "train/cont_loss_mean": 0.023515489048937837, "train/cont_loss_std": 0.3227477738826831, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.673117637634277, "train/cont_pos_acc": 0.9999999869160536, "train/cont_pos_loss": 0.0034954923534447828, "train/cont_pred": 0.996510725195815, "train/cont_rate": 0.9964669080284553, "train/dyn_loss_mean": 1.0200878914778795, "train/dyn_loss_std": 0.0013847549207417703, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.01128242675184719, "train/extr_critic_critic_opt_grad_steps": 6690.0, "train/extr_critic_critic_opt_loss": 5728.117814723069, "train/extr_critic_mag": 0.013697224903882034, "train/extr_critic_max": 0.013697224903882034, "train/extr_critic_mean": 0.013651071381338729, "train/extr_critic_min": 0.013628006950626529, "train/extr_critic_std": 9.604855348442936e-06, "train/extr_return_normed_mag": 0.00034250478010352067, "train/extr_return_normed_max": 0.00033121166856792887, "train/extr_return_normed_mean": 0.00025088516056756614, "train/extr_return_normed_min": 0.00015445223941308695, "train/extr_return_normed_std": 4.6125856226531255e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.013814360562075929, "train/extr_return_raw_max": 0.013814360562075929, "train/extr_return_raw_mean": 0.01373403473961644, "train/extr_return_raw_min": 0.013637601132921087, "train/extr_return_raw_std": 4.612585668774858e-05, "train/extr_reward_mag": 5.4176260785358705e-05, "train/extr_reward_max": 5.4176260785358705e-05, "train/extr_reward_mean": 5.411684833234176e-05, "train/extr_reward_min": 5.406674330796653e-05, "train/extr_reward_std": 1.5958316187924733e-08, "train/image_loss_mean": 0.2579085268383104, "train/image_loss_std": 0.08481939591285659, "train/model_loss_mean": 0.8946611503275429, "train/model_loss_std": 0.36048729505723087, "train/model_opt_grad_norm": 55.744639326886436, "train/model_opt_grad_steps": 6680.0, "train/model_opt_loss": 696.716874285442, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 772.3577235772358, "train/policy_entropy_mag": 1.945896914334801, "train/policy_entropy_max": 1.945896914334801, "train/policy_entropy_mean": 1.945298114443213, "train/policy_entropy_min": 1.9330983316995265, "train/policy_entropy_std": 0.0004737578122781938, "train/policy_logprob_mag": 2.1604633234380706, "train/policy_logprob_max": -1.7428230153835886, "train/policy_logprob_mean": -1.9452754462637551, "train/policy_logprob_min": -2.1604633234380706, "train/policy_logprob_std": 0.03390733225316536, "train/policy_randomness_mag": 0.9999932574062813, "train/policy_randomness_max": 0.9999932574062813, "train/policy_randomness_mean": 0.9996855317092523, "train/policy_randomness_min": 0.9934160883833723, "train/policy_randomness_std": 0.00024346336123734198, "train/post_ent_mag": 40.807802991169254, "train/post_ent_max": 40.807802991169254, "train/post_ent_mean": 40.757347913292364, "train/post_ent_min": 40.316971135333304, "train/post_ent_std": 0.0950497953274204, "train/prior_ent_mag": 42.379053999738, "train/prior_ent_max": 42.379053999738, "train/prior_ent_mean": 42.316410653959444, "train/prior_ent_min": 42.21875319442129, "train/prior_ent_std": 0.020930155892137106, "train/rep_loss_mean": 1.0200878914778795, "train/rep_loss_std": 0.0013847549207417703, "train/reward_avg": 5.639549103429223e-05, "train/reward_loss_mean": 0.0011843768046881126, "train/reward_loss_std": 0.03172016751169335, "train/reward_max_data": 0.05510670697785974, "train/reward_max_pred": 5.425573364505923e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00014296474303894988, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 10.040533900260925, "train/reward_pred": 5.420981111322961e-05, "train/reward_rate": 0.00010321392276422765, "train_stats/mean_log_entropy": 1.9386032299256661, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.014573667198419571, "report/cont_loss_std": 0.24869424104690552, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.6363844871521, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.00357208214700222, "report/cont_pred": 0.996434211730957, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.2823166847229004, "report/image_loss_std": 0.07187037914991379, "report/model_loss_mean": 0.8970066905021667, "report/model_loss_std": 0.26130548119544983, "report/post_ent_mag": 41.38563537597656, "report/post_ent_max": 41.38563537597656, "report/post_ent_mean": 41.37440872192383, "report/post_ent_min": 41.366607666015625, "report/post_ent_std": 0.002799034584313631, "report/prior_ent_mag": 38.87818908691406, "report/prior_ent_max": 38.87818908691406, "report/prior_ent_mean": 38.85606384277344, "report/prior_ent_min": 38.73198699951172, "report/prior_ent_std": 0.022398239001631737, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.0001163482666015625, "report/reward_loss_std": 0.0, "report/reward_max_data": 0.0, "report/reward_max_pred": 4.112720489501953e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0001163482666015625, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 4.112720489501953e-05, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.003572095651179552, "eval/cont_loss_std": 4.342062709383754e-07, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.003572095651179552, "eval/cont_pred": 0.996434211730957, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2629655599594116, "eval/image_loss_std": 0.06851916760206223, "eval/model_loss_mean": 0.8666539788246155, "eval/model_loss_std": 0.06851917505264282, "eval/post_ent_mag": 41.384727478027344, "eval/post_ent_max": 41.384727478027344, "eval/post_ent_mean": 41.37460708618164, "eval/post_ent_min": 41.36690139770508, "eval/post_ent_std": 0.0028846231289207935, "eval/prior_ent_mag": 38.87732696533203, "eval/prior_ent_max": 38.87732696533203, "eval/prior_ent_mean": 38.85576248168945, "eval/prior_ent_min": 38.73198699951172, "eval/prior_ent_std": 0.023621562868356705, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0001163482666015625, "eval/reward_loss_std": 0.0, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 4.112720489501953e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0001163482666015625, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 4.112720489501953e-05, "eval/reward_rate": 0.0, "replay/size": 117905.0, "replay/inserts": 19744.0, "replay/samples": 19744.0, "replay/insert_wait_avg": 1.4283499609515965e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.555275141130197e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 20000.0, "eval_replay/inserts": 4624.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.4402049635520856e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.003545761108398e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 500.0436463356018, "timer/env.step_count": 2468.0, "timer/env.step_total": 5.634764671325684, "timer/env.step_frac": 0.011268545681198276, "timer/env.step_avg": 0.0022831299316554633, "timer/env.step_min": 0.0011746883392333984, "timer/env.step_max": 0.01758599281311035, "timer/replay._sample_count": 19744.0, "timer/replay._sample_total": 1353.9822432994843, "timer/replay._sample_frac": 2.707728121778325, "timer/replay._sample_avg": 0.06857689643939852, "timer/replay._sample_min": 0.00031948089599609375, "timer/replay._sample_max": 0.10696077346801758, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3046.0, "timer/agent.policy_total": 20.154921770095825, "timer/agent.policy_frac": 0.04030632509340785, "timer/agent.policy_avg": 0.006616848906794428, "timer/agent.policy_min": 0.005007028579711914, "timer/agent.policy_max": 0.023800134658813477, "timer/dataset_train_count": 1234.0, "timer/dataset_train_total": 0.10864973068237305, "timer/dataset_train_frac": 0.0002172804943699921, "timer/dataset_train_avg": 8.804678337307378e-05, "timer/dataset_train_min": 7.271766662597656e-05, "timer/dataset_train_max": 0.00020313262939453125, "timer/agent.train_count": 1234.0, "timer/agent.train_total": 466.94030928611755, "timer/agent.train_frac": 0.9337991047540136, "timer/agent.train_avg": 0.378395712549528, "timer/agent.train_min": 0.34952831268310547, "timer/agent.train_max": 0.5025811195373535, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4130227565765381, "timer/agent.report_frac": 0.0008259734117276233, "timer/agent.report_avg": 0.20651137828826904, "timer/agent.report_min": 0.20520710945129395, "timer/agent.report_max": 0.20781564712524414, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.6716461181640625e-05, "timer/dataset_eval_frac": 7.342651276684467e-08, "timer/dataset_eval_avg": 3.6716461181640625e-05, "timer/dataset_eval_min": 3.6716461181640625e-05, "timer/dataset_eval_max": 3.6716461181640625e-05, "fps": 39.48407289034855}
{"step": 118648, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 120016, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120096, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 120160, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 120224, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 120480, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 120504, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 120520, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 120680, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 120960, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 122408, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 122472, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 122536, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 122792, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 122816, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 122832, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 122992, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 123272, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 124720, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 124784, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 124848, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 125104, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 125128, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 125144, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 125304, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 125584, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 127032, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 127096, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 127160, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 127416, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 127440, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 127456, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 127616, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 127896, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 128040, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936}
{"step": 129408, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 129472, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 129728, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 129752, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 129768, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 129928, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 130000, "eval_episode/length": 197.0, "eval_episode/score": 0.3843750059604645, "eval_episode/reward_rate": 0.005050505050505051}
{"step": 130000, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130208, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 130352, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 131720, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 131784, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 132040, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 132064, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 132080, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 132240, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 132520, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 132664, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 134032, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 134096, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 134352, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 134376, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 134392, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 134552, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 134832, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 134976, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 136344, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 136408, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 136664, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 136688, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 136704, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 136864, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 137144, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 137288, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 138537, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.0009358723958335, "train/action_min": 0.0, "train/action_std": 1.9987670306175473, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 2.449854176279226e-05, "train/actor_opt_grad_steps": 7935.0, "train/actor_opt_loss": -5.713688191913423, "train/adv_mag": 0.00012844727773751532, "train/adv_max": 7.84773054340529e-05, "train/adv_mean": -9.984960622695947e-07, "train/adv_min": -8.96774572394197e-05, "train/adv_std": 2.7974699291700656e-05, "train/cont_avg": 0.9965277777777778, "train/cont_loss_mean": 0.023194082456433937, "train/cont_loss_std": 0.32264820461337906, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.658095247377225, "train/cont_pos_acc": 0.9999999796587323, "train/cont_pos_loss": 0.003529287640020133, "train/cont_pred": 0.9964770329377007, "train/cont_rate": 0.9965277777777778, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.0073906292913422465, "train/extr_critic_critic_opt_grad_steps": 7935.0, "train/extr_critic_critic_opt_loss": 5860.803575303819, "train/extr_critic_mag": 0.014159450455317421, "train/extr_critic_max": 0.014159450455317421, "train/extr_critic_mean": 0.014112190387788274, "train/extr_critic_min": 0.01408112332934425, "train/extr_critic_std": 1.1096823568451212e-05, "train/extr_return_normed_mag": 0.00013734928760973235, "train/extr_return_normed_max": 7.970438205770083e-05, "train/extr_return_normed_mean": 2.651411111873896e-05, "train/extr_return_normed_min": -2.804207837297803e-05, "train/extr_return_normed_std": 2.4122811659423412e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.014164381423994662, "train/extr_return_raw_max": 0.014164381423994662, "train/extr_return_raw_mean": 0.01411119189911655, "train/extr_return_raw_min": 0.014056634963563984, "train/extr_return_raw_std": 2.412281170047699e-05, "train/extr_reward_mag": 4.2292806837293836e-05, "train/extr_reward_max": 4.2292806837293836e-05, "train/extr_reward_mean": 4.225165878504788e-05, "train/extr_reward_min": 4.2231309981573195e-05, "train/extr_reward_std": 1.1170010428071486e-08, "train/image_loss_mean": 0.25153653512871454, "train/image_loss_std": 0.08453273796845996, "train/model_loss_mean": 0.8763769675814916, "train/model_loss_std": 0.37204601385054137, "train/model_opt_grad_norm": 50.50329539889381, "train/model_opt_grad_steps": 7925.0, "train/model_opt_loss": 1574.0198751782614, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1795.6349206349207, "train/policy_entropy_mag": 1.9458956084554158, "train/policy_entropy_max": 1.9458956084554158, "train/policy_entropy_mean": 1.9451688736204118, "train/policy_entropy_min": 1.9277169988268898, "train/policy_entropy_std": 0.0006326187992401953, "train/policy_logprob_mag": 2.1883461759203957, "train/policy_logprob_max": -1.6936645820027305, "train/policy_logprob_mean": -1.9452125089509147, "train/policy_logprob_min": -2.1883461759203957, "train/policy_logprob_std": 0.038432729829634936, "train/policy_randomness_mag": 0.9999925886827802, "train/policy_randomness_max": 0.9999925886827802, "train/policy_randomness_mean": 0.9996191173318832, "train/policy_randomness_min": 0.9906506306595273, "train/policy_randomness_std": 0.00032510178321639875, "train/post_ent_mag": 41.45072146824428, "train/post_ent_max": 41.45072146824428, "train/post_ent_mean": 41.44110964214991, "train/post_ent_min": 41.42850824386355, "train/post_ent_std": 0.003357923977697889, "train/prior_ent_mag": 38.92879213605608, "train/prior_ent_max": 38.92879213605608, "train/prior_ent_mean": 38.908576178172275, "train/prior_ent_min": 38.79044396536691, "train/prior_ent_std": 0.022536799947302493, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 8.130754715585638e-05, "train/reward_loss_mean": 0.0016463321397110584, "train/reward_loss_std": 0.047834018087212646, "train/reward_max_data": 0.08229166647744557, "train/reward_max_pred": 4.2242663247244696e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00011014320429355379, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 10.496403482225206, "train/reward_pred": 4.221472264607511e-05, "train/reward_rate": 0.0001472594246031746, "train_stats/mean_log_entropy": 1.9382220940156416, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.02564448118209839, "report/cont_loss_std": 0.35915979743003845, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.760965347290039, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.003153035882860422, "report/cont_pred": 0.9968519806861877, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.25471436977386475, "report/image_loss_std": 0.0776953175663948, "report/model_loss_mean": 0.8906921148300171, "report/model_loss_std": 0.605126142501831, "report/post_ent_mag": 41.671966552734375, "report/post_ent_max": 41.671966552734375, "report/post_ent_mean": 41.664405822753906, "report/post_ent_min": 41.64881134033203, "report/post_ent_std": 0.0033788722939789295, "report/prior_ent_mag": 38.97607421875, "report/prior_ent_max": 38.97607421875, "report/prior_ent_mean": 38.95612716674805, "report/prior_ent_min": 38.83654022216797, "report/prior_ent_std": 0.02345038577914238, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0003082275507040322, "report/reward_loss_mean": 0.010333211161196232, "report/reward_loss_std": 0.3272069990634918, "report/reward_max_data": 0.31562501192092896, "report/reward_max_pred": 3.5881996154785156e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.000102996826171875, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 10.475842475891113, "report/reward_pred": 3.5881996154785156e-05, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.020021621137857437, "eval/cont_loss_std": 0.31119397282600403, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.760965347290039, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0031530363485217094, "eval/cont_pred": 0.9968519806861877, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2553531527519226, "eval/image_loss_std": 0.07784400880336761, "eval/model_loss_mean": 0.8856995105743408, "eval/model_loss_std": 0.5756680369377136, "eval/post_ent_mag": 41.669857025146484, "eval/post_ent_max": 41.669857025146484, "eval/post_ent_mean": 41.6642951965332, "eval/post_ent_min": 41.647220611572266, "eval/post_ent_std": 0.0033294735476374626, "eval/prior_ent_mag": 38.976951599121094, "eval/prior_ent_max": 38.976951599121094, "eval/prior_ent_mean": 38.95625305175781, "eval/prior_ent_min": 38.83654022216797, "eval/prior_ent_std": 0.02312929555773735, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0002838134823832661, "eval/reward_loss_mean": 0.010324730537831783, "eval/reward_loss_std": 0.3269357681274414, "eval/reward_max_data": 0.2906250059604645, "eval/reward_max_pred": 3.5881996154785156e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.000102996826171875, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 10.467158317565918, "eval/reward_pred": 3.5881996154785156e-05, "eval/reward_rate": 0.0009765625, "replay/size": 138033.0, "replay/inserts": 20128.0, "replay/samples": 20128.0, "replay/insert_wait_avg": 1.3478325357118736e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 6.896228972224249e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 20000.0, "eval_replay/inserts": 4624.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.4076699022603283e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.387731552124023e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 500.07724046707153, "timer/env.step_count": 2516.0, "timer/env.step_total": 5.507615089416504, "timer/env.step_frac": 0.011013528798615986, "timer/env.step_avg": 0.0021890362040606136, "timer/env.step_min": 0.0011272430419921875, "timer/env.step_max": 0.0469052791595459, "timer/replay._sample_count": 20128.0, "timer/replay._sample_total": 1372.496208190918, "timer/replay._sample_frac": 2.744568432886504, "timer/replay._sample_avg": 0.06818840461997804, "timer/replay._sample_min": 0.0003428459167480469, "timer/replay._sample_max": 0.09887838363647461, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3094.0, "timer/agent.policy_total": 19.88091802597046, "timer/agent.policy_frac": 0.03975569455510854, "timer/agent.policy_avg": 0.006425636078206354, "timer/agent.policy_min": 0.004914522171020508, "timer/agent.policy_max": 0.00983881950378418, "timer/dataset_train_count": 1258.0, "timer/dataset_train_total": 0.1070559024810791, "timer/dataset_train_frac": 0.00021407873387936836, "timer/dataset_train_avg": 8.51000814634969e-05, "timer/dataset_train_min": 6.961822509765625e-05, "timer/dataset_train_max": 0.0002079010009765625, "timer/agent.train_count": 1258.0, "timer/agent.train_total": 467.6808099746704, "timer/agent.train_frac": 0.9352171467308872, "timer/agent.train_avg": 0.3717653497413914, "timer/agent.train_min": 0.3494536876678467, "timer/agent.train_max": 0.45559239387512207, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4142911434173584, "timer/agent.report_frac": 0.0008284543064395631, "timer/agent.report_avg": 0.2071455717086792, "timer/agent.report_min": 0.20350074768066406, "timer/agent.report_max": 0.21079039573669434, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 4.0531158447265625e-05, "timer/dataset_eval_frac": 8.104979624629501e-08, "timer/dataset_eval_avg": 4.0531158447265625e-05, "timer/dataset_eval_min": 4.0531158447265625e-05, "timer/dataset_eval_max": 4.0531158447265625e-05, "fps": 40.24911953074931}
{"step": 138656, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 138720, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 138976, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 139000, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 139016, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 139176, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 139456, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 139600, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 140088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140968, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 141032, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 141288, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 141312, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 141328, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 141488, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 141768, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 141912, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 143280, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 143344, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 143600, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 143624, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 143640, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 143800, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 144080, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 144224, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 145592, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 145656, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 145912, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 145928, "episode/length": 212.0, "episode/score": 0.3375000059604645, "episode/reward_rate": 0.004694835680751174}
{"step": 145936, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 145952, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 146112, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 146392, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 147904, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 147968, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 148224, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 148240, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 148248, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 148264, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 148424, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 148704, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 150072, "eval_episode/length": 96.0, "eval_episode/score": 0.699999988079071, "eval_episode/reward_rate": 0.010309278350515464}
{"step": 150072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150216, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 150280, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 150536, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 150552, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 150560, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 150576, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 150736, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 151016, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 152528, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 152592, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 152848, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 152864, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 152872, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 152888, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 153048, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 153328, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 153736, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259}
{"step": 154840, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 154904, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 155160, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 155176, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 155200, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 155360, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 155640, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 156048, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 157152, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 157216, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 157472, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 157488, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 157512, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 157672, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 157952, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 158360, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 158681, "train_stats/mean_log_entropy": 1.9383446778336617, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.9985535636780756, "train/action_min": 0.0, "train/action_std": 1.999319897757636, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 2.8120478227431287e-05, "train/actor_opt_grad_steps": 9195.0, "train/actor_opt_loss": -6.1415319584664845, "train/adv_mag": 0.00014587481402688555, "train/adv_max": 6.794268708853495e-05, "train/adv_mean": -2.336555059973782e-05, "train/adv_min": -0.00011673554896362244, "train/adv_std": 3.2966911524071625e-05, "train/cont_avg": 0.9965975322420635, "train/cont_loss_mean": 0.022749654168913527, "train/cont_loss_std": 0.32109534385658445, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.665334644317627, "train/cont_pos_acc": 0.9999999824970488, "train/cont_pos_loss": 0.003506596078209224, "train/cont_pred": 0.9964996500620766, "train/cont_rate": 0.9965975322420635, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 3.636592910403297e-09, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.006502318552636084, "train/extr_critic_critic_opt_grad_steps": 9195.0, "train/extr_critic_critic_opt_loss": 5737.40925719246, "train/extr_critic_mag": 0.013730699107760475, "train/extr_critic_max": 0.013730699107760475, "train/extr_critic_mean": 0.013684971147172507, "train/extr_critic_min": 0.013655368297819107, "train/extr_critic_std": 1.2698725928629077e-05, "train/extr_return_normed_mag": 0.00015729157963678952, "train/extr_return_normed_max": 6.0098615312387074e-05, "train/extr_return_normed_mean": -6.081943724884767e-06, "train/extr_return_normed_min": -6.162653130198282e-05, "train/extr_return_normed_std": 2.887155586930383e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.013727785502043035, "train/extr_return_raw_max": 0.013727785502043035, "train/extr_return_raw_mean": 0.013661605719890859, "train/extr_return_raw_min": 0.013606060355428665, "train/extr_return_raw_std": 2.887155584006443e-05, "train/extr_reward_mag": 3.747523777068607e-05, "train/extr_reward_max": 3.747523777068607e-05, "train/extr_reward_mean": 3.7447367070680705e-05, "train/extr_reward_min": 3.742414807516431e-05, "train/extr_reward_std": 1.5348557458504088e-08, "train/image_loss_mean": 0.2520625748568111, "train/image_loss_std": 0.0848760363010187, "train/model_loss_mean": 0.87622169890101, "train/model_loss_std": 0.3628713980553642, "train/model_opt_grad_norm": 48.64055980197967, "train/model_opt_grad_steps": 9184.373015873016, "train/model_opt_loss": 2224.8527250744046, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2539.6825396825398, "train/policy_entropy_mag": 1.945898569765545, "train/policy_entropy_max": 1.945898569765545, "train/policy_entropy_mean": 1.9453228362022885, "train/policy_entropy_min": 1.9343479862288824, "train/policy_entropy_std": 0.0004423578927618644, "train/policy_logprob_mag": 2.140316789112394, "train/policy_logprob_max": -1.7443993905233959, "train/policy_logprob_mean": -1.9453019717383007, "train/policy_logprob_min": -2.140316789112394, "train/policy_logprob_std": 0.034249332896064195, "train/policy_randomness_mag": 0.9999941090742747, "train/policy_randomness_max": 0.9999941090742747, "train/policy_randomness_mean": 0.9996982443900335, "train/policy_randomness_min": 0.9940582821293483, "train/policy_randomness_std": 0.0002273269887414894, "train/post_ent_mag": 42.288778698633585, "train/post_ent_max": 42.288778698633585, "train/post_ent_mean": 42.279004899282306, "train/post_ent_min": 42.25979199485173, "train/post_ent_std": 0.004287091689923453, "train/prior_ent_mag": 39.050402111477325, "train/prior_ent_max": 39.050402111477325, "train/prior_ent_mean": 39.028609018477184, "train/prior_ent_min": 38.90246182396298, "train/prior_ent_std": 0.024050398345386224, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 3.636592910403297e-09, "train/reward_avg": 6.554013227633688e-05, "train/reward_loss_mean": 0.0014094505385155716, "train/reward_loss_std": 0.03882801104842639, "train/reward_max_data": 0.056770833830038704, "train/reward_max_pred": 3.742225586421906e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 9.80723978298354e-05, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 10.554863146373204, "train/reward_pred": 3.740073750830359e-05, "train/reward_rate": 0.0001240079365079365, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.02556207962334156, "report/cont_loss_std": 0.3479512631893158, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.581897735595703, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.003772520227357745, "report/cont_pred": 0.996234655380249, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.2662077248096466, "report/image_loss_std": 0.07078927010297775, "report/model_loss_mean": 0.8918622136116028, "report/model_loss_std": 0.35033661127090454, "report/post_ent_mag": 43.03630065917969, "report/post_ent_max": 43.03630065917969, "report/post_ent_mean": 43.02070999145508, "report/post_ent_min": 43.00291061401367, "report/post_ent_std": 0.00628939364105463, "report/prior_ent_mag": 39.3713493347168, "report/prior_ent_max": 39.3713493347168, "report/prior_ent_mean": 39.342960357666016, "report/prior_ent_min": 39.21019744873047, "report/prior_ent_std": 0.025586223229765892, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 9.239464998245239e-05, "report/reward_loss_std": 3.067432032821671e-07, "report/reward_max_data": 0.0, "report/reward_max_pred": 3.2782554626464844e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 9.239464998245239e-05, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 3.2782554626464844e-05, "report/reward_rate": 0.0, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.014667298644781113, "eval/cont_loss_std": 0.2462797611951828, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.581897735595703, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.003772520460188389, "eval/cont_pred": 0.996234655380249, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.24994409084320068, "eval/image_loss_std": 0.06610777974128723, "eval/model_loss_mean": 0.8647037148475647, "eval/model_loss_std": 0.25467434525489807, "eval/post_ent_mag": 43.03455352783203, "eval/post_ent_max": 43.03455352783203, "eval/post_ent_mean": 43.02033615112305, "eval/post_ent_min": 43.0006103515625, "eval/post_ent_std": 0.006447147112339735, "eval/prior_ent_mag": 39.376068115234375, "eval/prior_ent_max": 39.376068115234375, "eval/prior_ent_mean": 39.344242095947266, "eval/prior_ent_min": 39.21019744873047, "eval/prior_ent_std": 0.025052977725863457, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 9.238719940185547e-05, "eval/reward_loss_std": 3.1539812539449485e-07, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 3.2782554626464844e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 9.238719940185547e-05, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 3.2782554626464844e-05, "eval/reward_rate": 0.0, "replay/size": 158177.0, "replay/inserts": 20144.0, "replay/samples": 20144.0, "replay/insert_wait_avg": 1.3425603000013672e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 6.959990341574356e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 20000.0, "eval_replay/inserts": 4624.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2929464294011206e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.791685104370117e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 500.0382080078125, "timer/env.step_count": 2518.0, "timer/env.step_total": 5.450299978256226, "timer/env.step_frac": 0.010899767039744034, "timer/env.step_avg": 0.002164535336876976, "timer/env.step_min": 0.0011124610900878906, "timer/env.step_max": 0.013031721115112305, "timer/replay._sample_count": 20144.0, "timer/replay._sample_total": 1373.217674255371, "timer/replay._sample_frac": 2.746225492900567, "timer/replay._sample_avg": 0.06817005928591001, "timer/replay._sample_min": 0.0003256797790527344, "timer/replay._sample_max": 0.09708738327026367, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3096.0, "timer/agent.policy_total": 19.91223692893982, "timer/agent.policy_frac": 0.03982143086279662, "timer/agent.policy_avg": 0.0064316010752389595, "timer/agent.policy_min": 0.004799604415893555, "timer/agent.policy_max": 0.014639854431152344, "timer/dataset_train_count": 1259.0, "timer/dataset_train_total": 0.10757160186767578, "timer/dataset_train_frac": 0.00021512676460514615, "timer/dataset_train_avg": 8.544209838576313e-05, "timer/dataset_train_min": 6.175041198730469e-05, "timer/dataset_train_max": 0.0002703666687011719, "timer/agent.train_count": 1259.0, "timer/agent.train_total": 467.67482471466064, "timer/agent.train_frac": 0.935278179197366, "timer/agent.train_avg": 0.37146530954301876, "timer/agent.train_min": 0.3487863540649414, "timer/agent.train_max": 0.8977291584014893, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.41648030281066895, "timer/agent.report_frac": 0.0008328969589543084, "timer/agent.report_avg": 0.20824015140533447, "timer/agent.report_min": 0.20743536949157715, "timer/agent.report_max": 0.2090449333190918, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.719329833984375e-05, "timer/dataset_eval_frac": 7.43809127866938e-08, "timer/dataset_eval_avg": 3.719329833984375e-05, "timer/dataset_eval_min": 3.719329833984375e-05, "timer/dataset_eval_max": 3.719329833984375e-05, "fps": 40.28440568896747}
{"step": 159464, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 159528, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 159784, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 159800, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 159824, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 159984, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 160056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160264, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 160672, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 161776, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 161840, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 162096, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 162112, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 162136, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 162296, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 162576, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 162984, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 164088, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 164152, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 164408, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 164424, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 164448, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 164608, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 164784, "episode/length": 275.0, "episode/score": 0.140625, "episode/reward_rate": 0.0036231884057971015}
{"step": 165296, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 166400, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 166464, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 166720, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 166736, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 166760, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 166920, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 167096, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 167608, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 168712, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 168776, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 169032, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 169048, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 169072, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 169232, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 169408, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 169920, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 170040, "eval_episode/length": 49.0, "eval_episode/score": 0.846875011920929, "eval_episode/reward_rate": 0.02}
{"step": 170040, "eval_episode/length": 199.0, "eval_episode/score": 0.37812501192092896, "eval_episode/reward_rate": 0.005}
{"step": 170040, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 171024, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 171088, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 171344, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 171360, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 171384, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 171544, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 171720, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 172232, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 173336, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 173400, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 173656, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 173672, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 173696, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 173856, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 174032, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 174544, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 175648, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 175712, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 175968, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 175984, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 176008, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 176168, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 176344, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 176856, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 177960, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 178024, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 178280, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 178296, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 178320, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 178480, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 178656, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 178761, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.00086376953125, "train/action_min": 0.0, "train/action_std": 1.9999928789138794, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 5.5415450478903946e-05, "train/actor_opt_grad_steps": 10450.0, "train/actor_opt_loss": -5.975437721095979, "train/adv_mag": 0.00018221867829561233, "train/adv_max": 0.00010891415923833847, "train/adv_mean": -1.4825819443785804e-05, "train/adv_min": -0.0001422552317380905, "train/adv_std": 4.0555899462560776e-05, "train/cont_avg": 0.9963359375, "train/cont_loss_mean": 0.02424832495301962, "train/cont_loss_std": 0.3294453300274909, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.651934332963897, "train/cont_pos_acc": 0.9999999842643738, "train/cont_pos_loss": 0.0035441322848200796, "train/cont_pred": 0.9964622430801392, "train/cont_rate": 0.9963359375, "train/dyn_loss_mean": 1.0000000200271606, "train/dyn_loss_std": 4.14206499044667e-07, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.007286458348389715, "train/extr_critic_critic_opt_grad_steps": 10450.0, "train/extr_critic_critic_opt_loss": 5604.19974609375, "train/extr_critic_mag": 0.013299901962280274, "train/extr_critic_max": 0.013299901962280274, "train/extr_critic_mean": 0.013232564277946949, "train/extr_critic_min": 0.013183677673339844, "train/extr_critic_std": 1.8372035249285546e-05, "train/extr_return_normed_mag": 0.00018788278847932816, "train/extr_return_normed_max": 0.00011433275789022446, "train/extr_return_normed_mean": 2.328315981412743e-05, "train/extr_return_normed_min": -5.027493834495544e-05, "train/extr_return_normed_std": 3.456495641694346e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.013308787405490876, "train/extr_return_raw_max": 0.013308787405490876, "train/extr_return_raw_mean": 0.013217738449573517, "train/extr_return_raw_min": 0.013144179709255695, "train/extr_return_raw_std": 3.456495632781298e-05, "train/extr_reward_mag": 3.743743896484375e-05, "train/extr_reward_max": 3.743743896484375e-05, "train/extr_reward_mean": 3.740380931412801e-05, "train/extr_reward_min": 3.737068176269531e-05, "train/extr_reward_std": 1.6361418455623778e-08, "train/image_loss_mean": 0.24588219785690307, "train/image_loss_std": 0.08377988356351852, "train/model_loss_mean": 0.8711145157814026, "train/model_loss_std": 0.36135809403657915, "train/model_opt_grad_norm": 45.00737342834473, "train/model_opt_grad_steps": 10438.208, "train/model_opt_loss": 2265.370681640625, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2600.0, "train/policy_entropy_mag": 1.9458885068893432, "train/policy_entropy_max": 1.9458885068893432, "train/policy_entropy_mean": 1.9447614812850953, "train/policy_entropy_min": 1.929604245185852, "train/policy_entropy_std": 0.0008301375813316553, "train/policy_logprob_mag": 2.2074164905548095, "train/policy_logprob_max": -1.71556298828125, "train/policy_logprob_mean": -1.9447896823883057, "train/policy_logprob_min": -2.2074164905548095, "train/policy_logprob_std": 0.04718430054187775, "train/policy_randomness_mag": 0.9999889359474182, "train/policy_randomness_max": 0.9999889359474182, "train/policy_randomness_mean": 0.9994097628593445, "train/policy_randomness_min": 0.9916204800605773, "train/policy_randomness_std": 0.00042660635104402897, "train/post_ent_mag": 44.71508639526367, "train/post_ent_max": 44.71508639526367, "train/post_ent_mean": 44.67964453125, "train/post_ent_min": 44.65697775268555, "train/post_ent_std": 0.011420836741104721, "train/prior_ent_mag": 40.066212371826175, "train/prior_ent_max": 40.066212371826175, "train/prior_ent_mean": 39.74466262817383, "train/prior_ent_min": 39.63013162231445, "train/prior_ent_std": 0.06466955514252186, "train/rep_loss_mean": 1.0000000200271606, "train/rep_loss_std": 4.14206499044667e-07, "train/reward_avg": 3.4985352191142736e-05, "train/reward_loss_mean": 0.000983955591917038, "train/reward_loss_std": 0.026913490353611024, "train/reward_max_data": 0.0342750004529953, "train/reward_max_pred": 3.7493705749511717e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 9.273735893657431e-05, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 10.321610832214356, "train/reward_pred": 3.746036253869534e-05, "train/reward_rate": 8.59375e-05, "train_stats/mean_log_entropy": 1.937952760239722, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.014342055656015873, "report/cont_loss_std": 0.2564552128314972, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.811590671539307, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0029971525073051453, "report/cont_pred": 0.9970073103904724, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.25385797023773193, "report/image_loss_std": 0.08777633309364319, "report/model_loss_mean": 0.868279218673706, "report/model_loss_std": 0.266245037317276, "report/post_ent_mag": 45.89952087402344, "report/post_ent_max": 45.89952087402344, "report/post_ent_mean": 45.78867721557617, "report/post_ent_min": 45.741294860839844, "report/post_ent_std": 0.03566066175699234, "report/prior_ent_mag": 41.91614532470703, "report/prior_ent_max": 41.91614532470703, "report/prior_ent_mean": 40.34379577636719, "report/prior_ent_min": 40.142425537109375, "report/prior_ent_std": 0.2513207495212555, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 7.915496826171875e-05, "report/reward_loss_std": 0.0, "report/reward_max_data": 0.0, "report/reward_max_pred": 3.266334533691406e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 7.915496826171875e-05, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 3.266334533691406e-05, "report/reward_rate": 0.0, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.02568696439266205, "eval/cont_loss_std": 0.36232736706733704, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.811590671539307, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.0029971522744745016, "eval/cont_pred": 0.9970073103904724, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.24510322511196136, "eval/image_loss_std": 0.07820462435483932, "eval/model_loss_mean": 0.8708693981170654, "eval/model_loss_std": 0.36839812994003296, "eval/post_ent_mag": 45.88856506347656, "eval/post_ent_max": 45.88856506347656, "eval/post_ent_mean": 45.78898620605469, "eval/post_ent_min": 45.73973083496094, "eval/post_ent_std": 0.035904496908187866, "eval/prior_ent_mag": 41.56907272338867, "eval/prior_ent_max": 41.56907272338867, "eval/prior_ent_mean": 40.348899841308594, "eval/prior_ent_min": 40.13092041015625, "eval/prior_ent_std": 0.23796579241752625, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 7.915496826171875e-05, "eval/reward_loss_std": 0.0, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 3.266334533691406e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 7.915496826171875e-05, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 3.266334533691406e-05, "eval/reward_rate": 0.0, "replay/size": 178257.0, "replay/inserts": 20080.0, "replay/samples": 20080.0, "replay/insert_wait_avg": 1.3582141275899818e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.070986873125175e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 20000.0, "eval_replay/inserts": 4624.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.328884524045106e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.493661880493164e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 500.1794319152832, "timer/env.step_count": 2510.0, "timer/env.step_total": 5.4091761112213135, "timer/env.step_frac": 0.010814471299846414, "timer/env.step_avg": 0.0021550502435144676, "timer/env.step_min": 0.0011250972747802734, "timer/env.step_max": 0.009904623031616211, "timer/replay._sample_count": 20080.0, "timer/replay._sample_total": 1373.361129283905, "timer/replay._sample_frac": 2.745736912901519, "timer/replay._sample_avg": 0.06839447854999527, "timer/replay._sample_min": 0.00032401084899902344, "timer/replay._sample_max": 0.09889650344848633, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3088.0, "timer/agent.policy_total": 19.836962461471558, "timer/agent.policy_frac": 0.03965969249377571, "timer/agent.policy_avg": 0.006423886807471359, "timer/agent.policy_min": 0.004838466644287109, "timer/agent.policy_max": 0.01050257682800293, "timer/dataset_train_count": 1255.0, "timer/dataset_train_total": 0.10821223258972168, "timer/dataset_train_frac": 0.00021634682612868794, "timer/dataset_train_avg": 8.622488652567464e-05, "timer/dataset_train_min": 7.224082946777344e-05, "timer/dataset_train_max": 0.0001819133758544922, "timer/agent.train_count": 1255.0, "timer/agent.train_total": 467.9126875400543, "timer/agent.train_frac": 0.935489661676664, "timer/agent.train_avg": 0.37283879485263294, "timer/agent.train_min": 0.3494253158569336, "timer/agent.train_max": 0.45638418197631836, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.41197681427001953, "timer/agent.report_frac": 0.0008236580474580514, "timer/agent.report_avg": 0.20598840713500977, "timer/agent.report_min": 0.20562219619750977, "timer/agent.report_max": 0.20635461807250977, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.743171691894531e-05, "timer/dataset_eval_frac": 7.483657769695182e-08, "timer/dataset_eval_avg": 3.743171691894531e-05, "timer/dataset_eval_min": 3.743171691894531e-05, "timer/dataset_eval_max": 3.743171691894531e-05, "fps": 40.14504702512602}
{"step": 179168, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 180024, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180272, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 180336, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 180592, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 180608, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 180632, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 180792, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 180968, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 181480, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 182584, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 182648, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 182904, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 182920, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 182944, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 183104, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 183280, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 183328, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571}
{"step": 183792, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 184896, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 184960, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 185216, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 185232, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 185256, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 185592, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 185640, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 186104, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 187208, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 187272, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 187528, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 187544, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 187568, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 187904, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 187952, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 188088, "episode/length": 247.0, "episode/score": 0.22812500596046448, "episode/reward_rate": 0.004032258064516129}
{"step": 189520, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 189584, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 189840, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 189856, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 189880, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 190008, "eval_episode/length": 207.0, "eval_episode/score": 0.3531250059604645, "eval_episode/reward_rate": 0.004807692307692308}
{"step": 190008, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190216, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 190264, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 190400, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 191832, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 191896, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 192152, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 192168, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 192192, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 192528, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 192576, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 192712, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 194144, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 194208, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 194464, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 194480, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 194504, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 194840, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 194888, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 195024, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 196456, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 196520, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 196776, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 196792, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 196816, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 197152, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 197192, "episode/length": 270.0, "episode/score": 0.15625, "episode/reward_rate": 0.0036900369003690036}
{"step": 197200, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 198681, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.99124560546875, "train/action_min": 0.0, "train/action_std": 2.000474987983704, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0001769885742396582, "train/actor_opt_grad_steps": 11700.0, "train/actor_opt_loss": -5.291813330173492, "train/adv_mag": 0.0003765776753425598, "train/adv_max": 0.0003116019070148468, "train/adv_mean": 1.940682211125022e-05, "train/adv_min": -0.0003101300448179245, "train/adv_std": 7.057403912767768e-05, "train/cont_avg": 0.9963671875, "train/cont_loss_mean": 0.02406648149341345, "train/cont_loss_std": 0.32954003573581575, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.6629957648796765, "train/cont_pos_acc": 0.9999999852180481, "train/cont_pos_loss": 0.0035008068513125183, "train/cont_pred": 0.9965053782463074, "train/cont_rate": 0.9963671875, "train/dyn_loss_mean": 1.0000000915527343, "train/dyn_loss_std": 2.9454741161316634e-06, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.00619111809367314, "train/extr_critic_critic_opt_grad_steps": 11700.0, "train/extr_critic_critic_opt_loss": 5593.2403046875, "train/extr_critic_mag": 0.013479486465454101, "train/extr_critic_max": 0.013479486465454101, "train/extr_critic_mean": 0.013191462025046348, "train/extr_critic_min": 0.013022039413452148, "train/extr_critic_std": 4.7424858261365445e-05, "train/extr_return_normed_mag": 0.0003923666924238205, "train/extr_return_normed_max": 0.00035395099967718127, "train/extr_return_normed_mean": 0.00011828021052042459, "train/extr_return_normed_min": -6.151355057954789e-05, "train/extr_return_normed_std": 5.579081723408308e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.013446538992226123, "train/extr_return_raw_max": 0.013446538992226123, "train/extr_return_raw_mean": 0.013210868827998639, "train/extr_return_raw_min": 0.013031074441969395, "train/extr_return_raw_std": 5.579081737960223e-05, "train/extr_reward_mag": 4.261016845703125e-05, "train/extr_reward_max": 4.261016845703125e-05, "train/extr_reward_mean": 4.251111877965741e-05, "train/extr_reward_min": 4.242324829101563e-05, "train/extr_reward_std": 3.978341729471424e-08, "train/image_loss_mean": 0.22419418144226075, "train/image_loss_std": 0.0893594810962677, "train/model_loss_mean": 0.8495271830558777, "train/model_loss_std": 0.3694319878816605, "train/model_opt_grad_norm": 43.54653437805176, "train/model_opt_grad_steps": 11687.128, "train/model_opt_loss": 2536.2481796875, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2980.0, "train/policy_entropy_mag": 1.9456927061080933, "train/policy_entropy_max": 1.9456927061080933, "train/policy_entropy_mean": 1.9328327379226684, "train/policy_entropy_min": 1.807721643447876, "train/policy_entropy_std": 0.010443004131317138, "train/policy_logprob_mag": 2.74292041015625, "train/policy_logprob_max": -1.2068520679473878, "train/policy_logprob_mean": -1.9326215324401856, "train/policy_logprob_min": -2.74292041015625, "train/policy_logprob_std": 0.15438770923018455, "train/policy_randomness_mag": 0.9998883161544799, "train/policy_randomness_max": 0.9998883161544799, "train/policy_randomness_mean": 0.9932795886993409, "train/policy_randomness_min": 0.9289852094650268, "train/policy_randomness_std": 0.005366642798762768, "train/post_ent_mag": 43.94970208740234, "train/post_ent_max": 43.94970208740234, "train/post_ent_mean": 43.719257385253904, "train/post_ent_min": 43.53837014770508, "train/post_ent_std": 0.09331125476956367, "train/prior_ent_mag": 46.50221166992188, "train/prior_ent_max": 46.50221166992188, "train/prior_ent_mean": 44.31895150756836, "train/prior_ent_min": 42.51224356079101, "train/prior_ent_std": 0.6550102725028991, "train/rep_loss_mean": 1.0000000915527343, "train/rep_loss_std": 2.9454741161316634e-06, "train/reward_avg": 4.846191417891532e-05, "train/reward_loss_mean": 0.001266444928944111, "train/reward_loss_std": 0.03718375867443359, "train/reward_max_data": 0.04962500011920929, "train/reward_max_pred": 4.245281219482422e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00010388708123355172, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 10.629189491271973, "train/reward_pred": 4.2375532910227774e-05, "train/reward_rate": 0.000109375, "train_stats/mean_log_entropy": 1.9240965590332493, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.020131723955273628, "report/cont_loss_std": 0.3004266619682312, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.562440395355225, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0038467831909656525, "report/cont_pred": 0.9961605668067932, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.19669795036315918, "report/image_loss_std": 0.09099512547254562, "report/model_loss_mean": 0.8169107437133789, "report/model_loss_std": 0.31204286217689514, "report/post_ent_mag": 44.02980041503906, "report/post_ent_max": 44.02980041503906, "report/post_ent_mean": 43.709136962890625, "report/post_ent_min": 43.45404815673828, "report/post_ent_std": 0.1271943300962448, "report/prior_ent_mag": 47.819854736328125, "report/prior_ent_max": 47.819854736328125, "report/prior_ent_mean": 44.117618560791016, "report/prior_ent_min": 41.597023010253906, "report/prior_ent_std": 1.0228620767593384, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 8.106231689453125e-05, "report/reward_loss_std": 0.0, "report/reward_max_data": 0.0, "report/reward_max_pred": 3.552436828613281e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 8.106231689453125e-05, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 3.552436828613281e-05, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.02013172209262848, "eval/cont_loss_std": 0.3004266619682312, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.562440395355225, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0038467831909656525, "eval/cont_pred": 0.9961605668067932, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.20819944143295288, "eval/image_loss_std": 0.09842205047607422, "eval/model_loss_mean": 0.8284121751785278, "eval/model_loss_std": 0.3131250739097595, "eval/post_ent_mag": 44.05097961425781, "eval/post_ent_max": 44.05097961425781, "eval/post_ent_mean": 43.69745635986328, "eval/post_ent_min": 43.449867248535156, "eval/post_ent_std": 0.13705137372016907, "eval/prior_ent_mag": 47.09348678588867, "eval/prior_ent_max": 47.09348678588867, "eval/prior_ent_mean": 44.16522979736328, "eval/prior_ent_min": 41.715675354003906, "eval/prior_ent_std": 0.7996474504470825, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 8.106231689453125e-05, "eval/reward_loss_std": 0.0, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 3.552436828613281e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 8.106231689453125e-05, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 3.552436828613281e-05, "eval/reward_rate": 0.0, "replay/size": 198177.0, "replay/inserts": 19920.0, "replay/samples": 19920.0, "replay/insert_wait_avg": 1.3943896236189876e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.073204201388072e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 20000.0, "eval_replay/inserts": 4624.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.460159113662878e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1324882507324219e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 500.2406153678894, "timer/env.step_count": 2490.0, "timer/env.step_total": 5.367338418960571, "timer/env.step_frac": 0.010729513466261225, "timer/env.step_avg": 0.0021555575979761332, "timer/env.step_min": 0.0011241436004638672, "timer/env.step_max": 0.009046316146850586, "timer/replay._sample_count": 19920.0, "timer/replay._sample_total": 1368.3007957935333, "timer/replay._sample_frac": 2.7352852882352443, "timer/replay._sample_avg": 0.06868979898561914, "timer/replay._sample_min": 0.000370025634765625, "timer/replay._sample_max": 0.10388946533203125, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3068.0, "timer/agent.policy_total": 19.9291090965271, "timer/agent.policy_frac": 0.03983904641943305, "timer/agent.policy_avg": 0.006495798271358246, "timer/agent.policy_min": 0.004983425140380859, "timer/agent.policy_max": 0.00974130630493164, "timer/dataset_train_count": 1245.0, "timer/dataset_train_total": 0.11025571823120117, "timer/dataset_train_frac": 0.0002204053706237275, "timer/dataset_train_avg": 8.855880982425797e-05, "timer/dataset_train_min": 6.67572021484375e-05, "timer/dataset_train_max": 0.00020456314086914062, "timer/agent.train_count": 1245.0, "timer/agent.train_total": 467.60615968704224, "timer/agent.train_frac": 0.9347624829366424, "timer/agent.train_avg": 0.37558727685706206, "timer/agent.train_min": 0.34888720512390137, "timer/agent.train_max": 0.46024227142333984, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.41945505142211914, "timer/agent.report_frac": 0.000838506587702083, "timer/agent.report_avg": 0.20972752571105957, "timer/agent.report_min": 0.19606566429138184, "timer/agent.report_max": 0.2233893871307373, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 5.936622619628906e-05, "timer/dataset_eval_frac": 1.1867534217034668e-07, "timer/dataset_eval_avg": 5.936622619628906e-05, "timer/dataset_eval_min": 5.936622619628906e-05, "timer/dataset_eval_max": 5.936622619628906e-05, "fps": 39.82027892195051}
{"step": 198768, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 198832, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 199088, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 199104, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 199128, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 199464, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 199504, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 199512, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 200024, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625}
{"step": 200096, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 201080, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 201144, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 201400, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 201416, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 201440, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 201776, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 201816, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 202336, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 203392, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 203456, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 203712, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 203728, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 203752, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 204088, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 204128, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 204648, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 205704, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 205768, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 206024, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 206040, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 206064, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 206400, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 206440, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 206960, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 208016, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 208080, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 208336, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 208352, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 208376, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 208712, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 208752, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 209272, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 210080, "eval_episode/length": 181.0, "eval_episode/score": 0.43437498807907104, "eval_episode/reward_rate": 0.005494505494505495}
{"step": 210080, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210328, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 210392, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 210648, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 210664, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 210688, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 211024, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 211064, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 211584, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 212304, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805}
{"step": 212480, "episode/length": 223.0, "episode/score": 0.3031249940395355, "episode/reward_rate": 0.004464285714285714}
{"step": 212640, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 212704, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 212960, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 213336, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 213376, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 213896, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 214616, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 214792, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 214952, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 215016, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 215272, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 215648, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 215688, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 216208, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 216928, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 217104, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 217264, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 217328, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 217584, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 217960, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 218000, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 218409, "train_stats/mean_log_entropy": 1.9197784927156236, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.0017486820376016, "train/action_min": 0.0, "train/action_std": 1.9866803380531994, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00012631763728847539, "train/actor_opt_grad_steps": 12940.0, "train/actor_opt_loss": -5.585020208988732, "train/adv_mag": 0.0005780884890052361, "train/adv_max": 0.00043736052949254104, "train/adv_mean": 3.884253375902081e-06, "train/adv_min": -0.0005567718630399161, "train/adv_std": 8.741925682066144e-05, "train/cont_avg": 0.9962842987804879, "train/cont_loss_mean": 0.024532364711650018, "train/cont_loss_std": 0.32994358232294446, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.659365117549896, "train/cont_pos_acc": 0.9999999825547381, "train/cont_pos_loss": 0.0035226242143539636, "train/cont_pred": 0.9964836787402145, "train/cont_rate": 0.9962842987804879, "train/dyn_loss_mean": 1.0000028145022508, "train/dyn_loss_std": 9.0012326836586e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.011075478057543619, "train/extr_critic_critic_opt_grad_steps": 12940.0, "train/extr_critic_critic_opt_loss": 5736.264156186484, "train/extr_critic_mag": 0.014296751681382095, "train/extr_critic_max": 0.014296751681382095, "train/extr_critic_mean": 0.013689904443435067, "train/extr_critic_min": 0.01342996543015891, "train/extr_critic_std": 8.721199566668762e-05, "train/extr_return_normed_mag": 0.0005842179771724755, "train/extr_return_normed_max": 0.0005580627972759852, "train/extr_return_normed_mean": 0.00013189099217231893, "train/extr_return_normed_min": -9.392304875986363e-05, "train/extr_return_normed_std": 8.122615057859585e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.014119959814943434, "train/extr_return_raw_max": 0.014119959814943434, "train/extr_return_raw_mean": 0.013693788671881204, "train/extr_return_raw_min": 0.013467973968907586, "train/extr_return_raw_std": 8.122615054901879e-05, "train/extr_reward_mag": 4.1670915557117e-05, "train/extr_reward_max": 4.1670915557117e-05, "train/extr_reward_mean": 3.984569051001047e-05, "train/extr_reward_min": 3.954453196952014e-05, "train/extr_reward_std": 2.482834611076855e-07, "train/image_loss_mean": 0.20025218381145135, "train/image_loss_std": 0.09692671737535213, "train/model_loss_mean": 0.8258259766470126, "train/model_loss_std": 0.3667101466922256, "train/model_opt_grad_norm": 40.37820446975832, "train/model_opt_grad_steps": 12926.048780487805, "train/model_opt_loss": 2452.8356675558944, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2967.479674796748, "train/policy_entropy_mag": 1.9454986525744926, "train/policy_entropy_max": 1.9454986525744926, "train/policy_entropy_mean": 1.9311211370840304, "train/policy_entropy_min": 1.8213172017074213, "train/policy_entropy_std": 0.01070269308529976, "train/policy_logprob_mag": 2.8128957535193218, "train/policy_logprob_max": -1.2055440850374175, "train/policy_logprob_mean": -1.9312212573803538, "train/policy_logprob_min": -2.8128957535193218, "train/policy_logprob_std": 0.1671857881109889, "train/policy_randomness_mag": 0.9997885934705657, "train/policy_randomness_max": 0.9997885934705657, "train/policy_randomness_mean": 0.99240000315798, "train/policy_randomness_min": 0.9359719486740546, "train/policy_randomness_std": 0.005500096608165319, "train/post_ent_mag": 41.061725523413685, "train/post_ent_max": 41.061725523413685, "train/post_ent_mean": 40.805986637022436, "train/post_ent_min": 40.64567665162125, "train/post_ent_std": 0.08378480604993618, "train/prior_ent_mag": 44.52228124354913, "train/prior_ent_max": 44.52228124354913, "train/prior_ent_mean": 41.237263439147455, "train/prior_ent_min": 38.153790512705235, "train/prior_ent_std": 1.1343676883999894, "train/rep_loss_mean": 1.0000028145022508, "train/rep_loss_std": 9.0012326836586e-05, "train/reward_avg": 4.818303852694155e-05, "train/reward_loss_mean": 0.0010397108991032208, "train/reward_loss_std": 0.029613661511881075, "train/reward_max_data": 0.049339431451588145, "train/reward_max_pred": 0.00032687090276702633, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00012000814059889323, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 10.530855959111994, "train/reward_pred": 4.316460931809937e-05, "train/reward_rate": 8.733485772357724e-05, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.042014479637145996, "report/cont_loss_std": 0.46251556277275085, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.616923809051514, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0036424349527806044, "report/cont_pred": 0.9963643550872803, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.2015831172466278, "report/image_loss_std": 0.08876167982816696, "report/model_loss_mean": 0.8437898755073547, "report/model_loss_std": 0.47425130009651184, "report/post_ent_mag": 37.845375061035156, "report/post_ent_max": 37.845375061035156, "report/post_ent_mean": 37.621612548828125, "report/post_ent_min": 37.498477935791016, "report/post_ent_std": 0.069149911403656, "report/prior_ent_mag": 41.58604049682617, "report/prior_ent_max": 41.58604049682617, "report/prior_ent_mean": 38.97300338745117, "report/prior_ent_min": 36.60354995727539, "report/prior_ent_std": 1.1220954656600952, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.0001922454684972763, "report/reward_loss_std": 8.672308808854723e-07, "report/reward_max_data": 0.0, "report/reward_max_pred": 7.939338684082031e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0001922454684972763, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 7.885240484029055e-05, "report/reward_rate": 0.0, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.025569315999746323, "eval/cont_loss_std": 0.3501441776752472, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.616923809051514, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.0036424349527806044, "eval/cont_pred": 0.9963643550872803, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.22113534808158875, "eval/image_loss_std": 0.09614922851324081, "eval/model_loss_mean": 0.8468970060348511, "eval/model_loss_std": 0.35764384269714355, "eval/post_ent_mag": 37.816734313964844, "eval/post_ent_max": 37.816734313964844, "eval/post_ent_mean": 37.631649017333984, "eval/post_ent_min": 37.514259338378906, "eval/post_ent_std": 0.0707806646823883, "eval/prior_ent_mag": 41.39390182495117, "eval/prior_ent_max": 41.39390182495117, "eval/prior_ent_mean": 38.832298278808594, "eval/prior_ent_min": 36.38426208496094, "eval/prior_ent_std": 1.1539874076843262, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0001923535019159317, "eval/reward_loss_std": 9.08923084352864e-07, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 7.939338684082031e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0001923535019159317, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 7.888698019087315e-05, "eval/reward_rate": 0.0, "replay/size": 200000.0, "replay/inserts": 19728.0, "replay/samples": 19728.0, "replay/insert_wait_avg": 1.405120282664303e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.112555066841169e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 20000.0, "eval_replay/inserts": 4624.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3788472409891834e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.087784767150879e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 500.26858496665955, "timer/env.step_count": 2466.0, "timer/env.step_total": 5.540753126144409, "timer/env.step_frac": 0.01107555679618314, "timer/env.step_avg": 0.0022468585264170354, "timer/env.step_min": 0.0011219978332519531, "timer/env.step_max": 0.009964942932128906, "timer/replay._sample_count": 19728.0, "timer/replay._sample_total": 1363.47402882576, "timer/replay._sample_frac": 2.725484009587827, "timer/replay._sample_avg": 0.06911364704104622, "timer/replay._sample_min": 0.00034928321838378906, "timer/replay._sample_max": 0.10842657089233398, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3044.0, "timer/agent.policy_total": 19.898885011672974, "timer/agent.policy_frac": 0.03977640333541859, "timer/agent.policy_avg": 0.006537084432218454, "timer/agent.policy_min": 0.0048770904541015625, "timer/agent.policy_max": 0.013126373291015625, "timer/dataset_train_count": 1233.0, "timer/dataset_train_total": 0.11044764518737793, "timer/dataset_train_frac": 0.00022077669577180972, "timer/dataset_train_avg": 8.957635457208267e-05, "timer/dataset_train_min": 6.914138793945312e-05, "timer/dataset_train_max": 0.00022792816162109375, "timer/agent.train_count": 1233.0, "timer/agent.train_total": 467.3169176578522, "timer/agent.train_frac": 0.9341320476659484, "timer/agent.train_avg": 0.3790080435181283, "timer/agent.train_min": 0.3494696617126465, "timer/agent.train_max": 0.47129273414611816, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.40905117988586426, "timer/agent.report_frac": 0.0008176631357196365, "timer/agent.report_avg": 0.20452558994293213, "timer/agent.report_min": 0.19950532913208008, "timer/agent.report_max": 0.20954585075378418, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.886222839355469e-05, "timer/dataset_eval_frac": 7.768272796131035e-08, "timer/dataset_eval_avg": 3.886222839355469e-05, "timer/dataset_eval_min": 3.886222839355469e-05, "timer/dataset_eval_max": 3.886222839355469e-05, "fps": 39.43432961408436}
{"step": 218520, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 219152, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653}
{"step": 219240, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 219416, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 219576, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 219640, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 220064, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220272, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 220312, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 220832, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 221464, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 221552, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 221728, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 221888, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 221952, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 222584, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 222624, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 223144, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 223776, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 223864, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 224040, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 224200, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 224264, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 224896, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 224936, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 225456, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 226088, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 226176, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 226352, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 226512, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 226576, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 227208, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 227248, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 227768, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 228400, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 228488, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 228664, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 228824, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 228888, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 229520, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 229560, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 230048, "eval_episode/length": 36.0, "eval_episode/score": 0.887499988079071, "eval_episode/reward_rate": 0.02702702702702703}
{"step": 230048, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230080, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 230712, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 230800, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 230976, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 231136, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 231200, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 231832, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266}
{"step": 231832, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 231872, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 232392, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 233024, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 233112, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 233288, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 233448, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 234144, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 234144, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 234184, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 234704, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 235296, "episode/length": 250.0, "episode/score": 0.21875, "episode/reward_rate": 0.00398406374501992}
{"step": 235336, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 235424, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 235760, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 236456, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 236456, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 236496, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 237016, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 237608, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 237648, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 237736, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 237881, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.988646460361168, "train/action_min": 0.0, "train/action_std": 1.9919627543355598, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 9.134985124487162e-05, "train/actor_opt_grad_steps": 14165.0, "train/actor_opt_loss": -5.349088719633759, "train/adv_mag": 0.0006330787341614238, "train/adv_max": 0.0004877288688401707, "train/adv_mean": 1.687157176085569e-05, "train/adv_min": -0.0005984679780534056, "train/adv_std": 9.419558284475972e-05, "train/cont_avg": 0.9964059298155737, "train/cont_loss_mean": 0.0238614787412502, "train/cont_loss_std": 0.3257933059997368, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.638802552223206, "train/cont_pos_acc": 0.9999999848545574, "train/cont_pos_loss": 0.003600151678852615, "train/cont_pred": 0.996406409584108, "train/cont_rate": 0.9964059298155737, "train/dyn_loss_mean": 1.000000653696842, "train/dyn_loss_std": 1.7908761648987954e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.0024137916713743088, "train/extr_critic_critic_opt_grad_steps": 14165.0, "train/extr_critic_critic_opt_loss": 5898.993880475154, "train/extr_critic_mag": 0.014941577051506668, "train/extr_critic_max": 0.014941577051506668, "train/extr_critic_mean": 0.01425601330539975, "train/extr_critic_min": 0.01399528491692465, "train/extr_critic_std": 9.090248550208224e-05, "train/extr_return_normed_mag": 0.0006504469001513036, "train/extr_return_normed_max": 0.0006504469001513036, "train/extr_return_normed_mean": 0.00017187989905466814, "train/extr_return_normed_min": -7.243468960533377e-05, "train/extr_return_normed_std": 8.909975368907431e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.014751451151048551, "train/extr_return_raw_max": 0.014751451151048551, "train/extr_return_raw_mean": 0.014272884794007071, "train/extr_return_raw_min": 0.014028569561291913, "train/extr_return_raw_std": 8.909975380835231e-05, "train/extr_reward_mag": 4.3422472281534165e-05, "train/extr_reward_max": 4.3422472281534165e-05, "train/extr_reward_mean": 4.332098570393711e-05, "train/extr_reward_min": 4.32133674621582e-05, "train/extr_reward_std": 5.5606870832901626e-08, "train/image_loss_mean": 0.19415387144831361, "train/image_loss_std": 0.10082205165116513, "train/model_loss_mean": 0.8189629291901823, "train/model_loss_std": 0.36335536269623725, "train/model_opt_grad_norm": 38.314563672404645, "train/model_opt_grad_steps": 14149.926229508197, "train/model_opt_loss": 2265.8458041832096, "train/model_opt_model_opt_grad_overflow": 0.00819672131147541, "train/model_opt_model_opt_grad_scale": 2745.901639344262, "train/policy_entropy_mag": 1.9457535391948262, "train/policy_entropy_max": 1.9457535391948262, "train/policy_entropy_mean": 1.9355327770358226, "train/policy_entropy_min": 1.8458970706970965, "train/policy_entropy_std": 0.008143663589583069, "train/policy_logprob_mag": 2.6560895442962646, "train/policy_logprob_max": -1.2800925676939918, "train/policy_logprob_mean": -1.9355548854734077, "train/policy_logprob_min": -2.6560895442962646, "train/policy_logprob_std": 0.14354656465718005, "train/policy_randomness_mag": 0.9999195777001928, "train/policy_randomness_max": 0.9999195777001928, "train/policy_randomness_mean": 0.9946671406753728, "train/policy_randomness_min": 0.9486035025510632, "train/policy_randomness_std": 0.004185015476904199, "train/post_ent_mag": 36.14744696069936, "train/post_ent_max": 36.14744696069936, "train/post_ent_mean": 35.883668399247966, "train/post_ent_min": 35.68808777605901, "train/post_ent_std": 0.0817893138308017, "train/prior_ent_mag": 40.327719297565395, "train/prior_ent_max": 40.327719297565395, "train/prior_ent_mean": 37.85059703764368, "train/prior_ent_min": 35.34365600836082, "train/prior_ent_std": 1.0938696577900746, "train/rep_loss_mean": 1.000000653696842, "train/rep_loss_std": 1.7908761648987954e-05, "train/reward_avg": 3.72214400740035e-05, "train/reward_loss_mean": 0.0009471676159711158, "train/reward_loss_std": 0.02516654571389855, "train/reward_max_data": 0.035348360900019034, "train/reward_max_pred": 4.3485985427606303e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00010964900782889092, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 10.42515394422743, "train/reward_pred": 4.335487124006279e-05, "train/reward_rate": 8.004610655737704e-05, "train_stats/mean_log_entropy": 1.925303225931914, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.014812393113970757, "report/cont_loss_std": 0.2430029660463333, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.507968902587891, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.004062575288116932, "report/cont_pred": 0.9959457516670227, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.18332123756408691, "report/image_loss_std": 0.09366850554943085, "report/model_loss_mean": 0.7983015179634094, "report/model_loss_std": 0.258215993642807, "report/post_ent_mag": 33.29429244995117, "report/post_ent_max": 33.29429244995117, "report/post_ent_mean": 33.0556640625, "report/post_ent_min": 32.8099250793457, "report/post_ent_std": 0.08278479427099228, "report/prior_ent_mag": 37.90541458129883, "report/prior_ent_max": 37.90541458129883, "report/prior_ent_mean": 35.490318298339844, "report/prior_ent_min": 33.51944351196289, "report/prior_ent_std": 0.9376863837242126, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.0001678466796875, "report/reward_loss_std": 0.0, "report/reward_max_data": 0.0, "report/reward_max_pred": 7.295608520507812e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0001678466796875, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 7.295608520507812e-05, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.02018730156123638, "eval/cont_loss_std": 0.29747092723846436, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.507968902587891, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.004062574822455645, "eval/cont_pred": 0.9959457516670227, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.19464951753616333, "eval/image_loss_std": 0.10976438224315643, "eval/model_loss_mean": 0.8150047063827515, "eval/model_loss_std": 0.3114466369152069, "eval/post_ent_mag": 33.309471130371094, "eval/post_ent_max": 33.309471130371094, "eval/post_ent_mean": 33.04399108886719, "eval/post_ent_min": 32.79460144042969, "eval/post_ent_std": 0.08704733848571777, "eval/prior_ent_mag": 37.593292236328125, "eval/prior_ent_max": 37.593292236328125, "eval/prior_ent_mean": 35.539939880371094, "eval/prior_ent_min": 33.776580810546875, "eval/prior_ent_std": 0.9606481194496155, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0001678466796875, "eval/reward_loss_std": 0.0, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 7.295608520507812e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0001678466796875, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 7.295608520507812e-05, "eval/reward_rate": 0.0, "replay/size": 200000.0, "replay/inserts": 19472.0, "replay/samples": 19472.0, "replay/insert_wait_avg": 1.4011621867033332e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.142884474654812e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 20000.0, "eval_replay/inserts": 4624.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3175926406490761e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.940696716308594e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 500.04556155204773, "timer/env.step_count": 2434.0, "timer/env.step_total": 5.44527530670166, "timer/env.step_frac": 0.010889558323046696, "timer/env.step_avg": 0.0022371714489324815, "timer/env.step_min": 0.0011584758758544922, "timer/env.step_max": 0.010214567184448242, "timer/replay._sample_count": 19472.0, "timer/replay._sample_total": 1346.182020187378, "timer/replay._sample_frac": 2.6921187261598347, "timer/replay._sample_avg": 0.06913424507946682, "timer/replay._sample_min": 0.00035190582275390625, "timer/replay._sample_max": 0.09490227699279785, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3012.0, "timer/agent.policy_total": 19.72840714454651, "timer/agent.policy_frac": 0.03945321918929393, "timer/agent.policy_avg": 0.006549935970964977, "timer/agent.policy_min": 0.0047228336334228516, "timer/agent.policy_max": 0.01797032356262207, "timer/dataset_train_count": 1217.0, "timer/dataset_train_total": 0.108856201171875, "timer/dataset_train_frac": 0.0002176925655214412, "timer/dataset_train_avg": 8.944634443046426e-05, "timer/dataset_train_min": 6.508827209472656e-05, "timer/dataset_train_max": 0.00021457672119140625, "timer/agent.train_count": 1217.0, "timer/agent.train_total": 467.4256627559662, "timer/agent.train_frac": 0.93476614671904, "timer/agent.train_avg": 0.38408024877236335, "timer/agent.train_min": 0.35285186767578125, "timer/agent.train_max": 0.48036718368530273, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.40874314308166504, "timer/agent.report_frac": 0.0008174118010626929, "timer/agent.report_avg": 0.20437157154083252, "timer/agent.report_min": 0.19505739212036133, "timer/agent.report_max": 0.2136857509613037, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.6716461181640625e-05, "timer/dataset_eval_frac": 7.342623153714155e-08, "timer/dataset_eval_avg": 3.6716461181640625e-05, "timer/dataset_eval_min": 3.6716461181640625e-05, "timer/dataset_eval_max": 3.6716461181640625e-05, "fps": 38.93995956178638}
{"step": 238072, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 238768, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 238768, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 238808, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 239328, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 239920, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 239960, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 240032, "eval_episode/length": 223.0, "eval_episode/score": 0.3031249940395355, "eval_episode/reward_rate": 0.004464285714285714}
{"step": 240032, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240048, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 240384, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 241080, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 241080, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 241120, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 241640, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 242232, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 242272, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 242328, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186}
{"step": 242360, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 242696, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 243392, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 243392, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 243432, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 244544, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 244584, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 244640, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 244672, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 245008, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 245704, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 245704, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 245744, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 246856, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 246896, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 246952, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 246984, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 247320, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 248008, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125}
{"step": 248016, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 248016, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 248056, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 249168, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 249208, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 249264, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 249632, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 250016, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250320, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 250328, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 250328, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 250368, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 250792, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827}
{"step": 251480, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 251520, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 251576, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 251944, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 252632, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 252640, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 252680, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 253104, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 253792, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 253832, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 253888, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 254256, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 254944, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 254952, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 254992, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 255416, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 256104, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 256144, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 256200, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 256568, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 257001, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.992477801667542, "train/action_min": 0.0, "train/action_std": 1.992518584267432, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 8.462536171471951e-05, "train/actor_opt_grad_steps": 15370.0, "train/actor_opt_loss": -5.95932535714462, "train/adv_mag": 0.0006825391500562179, "train/adv_max": 0.0004804186413393301, "train/adv_mean": -1.5132369754656265e-05, "train/adv_min": -0.0006492075455539367, "train/adv_std": 9.69333471578718e-05, "train/cont_avg": 0.9965697216386554, "train/cont_loss_mean": 0.022909686693279932, "train/cont_loss_std": 0.31785296201183705, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.653575905438127, "train/cont_pos_acc": 0.9999999859753776, "train/cont_pos_loss": 0.003544776381517784, "train/cont_pred": 0.9964616068271028, "train/cont_rate": 0.9965697216386554, "train/dyn_loss_mean": 1.0000033017967929, "train/dyn_loss_std": 6.850636080863686e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.001635404520725808, "train/extr_critic_critic_opt_grad_steps": 15370.0, "train/extr_critic_critic_opt_loss": 5905.5118828781515, "train/extr_critic_mag": 0.014954192297799247, "train/extr_critic_max": 0.014954192297799247, "train/extr_critic_mean": 0.01427723715441818, "train/extr_critic_min": 0.014006608674506179, "train/extr_critic_std": 8.007867046301214e-05, "train/extr_return_normed_mag": 0.0005887703766592411, "train/extr_return_normed_max": 0.0005781314954036424, "train/extr_return_normed_mean": 9.390232837383238e-05, "train/extr_return_normed_min": -0.00014166699080657557, "train/extr_return_normed_std": 8.049565755044102e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.014746333175033582, "train/extr_return_raw_max": 0.014746333175033582, "train/extr_return_raw_mean": 0.014262104633913822, "train/extr_return_raw_min": 0.014026534688823363, "train/extr_return_raw_std": 8.049565748929853e-05, "train/extr_reward_mag": 3.93480813803793e-05, "train/extr_reward_max": 3.93480813803793e-05, "train/extr_reward_mean": 3.92305499939111e-05, "train/extr_reward_min": 3.9101648731391974e-05, "train/extr_reward_std": 5.028087584199755e-08, "train/image_loss_mean": 0.18772780594705535, "train/image_loss_std": 0.1009522197502, "train/model_loss_mean": 0.811383237357901, "train/model_loss_std": 0.35163921361961287, "train/model_opt_grad_norm": 38.16589337036389, "train/model_opt_grad_steps": 15353.848739495797, "train/model_opt_loss": 2197.3764576631434, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2710.084033613445, "train/policy_entropy_mag": 1.945782859786218, "train/policy_entropy_max": 1.945782859786218, "train/policy_entropy_mean": 1.9366142880015011, "train/policy_entropy_min": 1.8603422761965198, "train/policy_entropy_std": 0.007153919729709374, "train/policy_logprob_mag": 2.616246185382875, "train/policy_logprob_max": -1.3083456394051303, "train/policy_logprob_mean": -1.9366232918090178, "train/policy_logprob_min": -2.616246185382875, "train/policy_logprob_std": 0.13595187263328487, "train/policy_randomness_mag": 0.9999346442583228, "train/policy_randomness_max": 0.9999346442583228, "train/policy_randomness_mean": 0.995222928143349, "train/policy_randomness_min": 0.9560268661555122, "train/policy_randomness_std": 0.0036763877553098344, "train/post_ent_mag": 33.58208635474453, "train/post_ent_max": 33.58208635474453, "train/post_ent_mean": 33.33729343254025, "train/post_ent_min": 33.1378105708531, "train/post_ent_std": 0.08399437039214022, "train/prior_ent_mag": 35.656163255707554, "train/prior_ent_max": 35.656163255707554, "train/prior_ent_mean": 33.59683945599724, "train/prior_ent_min": 32.18029770730924, "train/prior_ent_std": 0.6280313008973578, "train/rep_loss_mean": 1.0000033017967929, "train/rep_loss_std": 6.850636080863686e-05, "train/reward_avg": 3.3800141199124084e-05, "train/reward_loss_mean": 0.000743737694721262, "train/reward_loss_std": 0.02076505644597386, "train/reward_max_data": 0.03461134458790306, "train/reward_max_pred": 3.947430298108013e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 9.451618898922123e-05, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.88903260231018, "train/reward_pred": 3.936314395777568e-05, "train/reward_rate": 6.565126050420168e-05, "train_stats/mean_log_entropy": 1.927046635257664, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.03087446838617325, "report/cont_loss_std": 0.3760871887207031, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.399840354919434, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.004530185367912054, "report/cont_pred": 0.9954802393913269, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.1679268330335617, "report/image_loss_std": 0.09527474641799927, "report/model_loss_mean": 0.7988623380661011, "report/model_loss_std": 0.389088898897171, "report/post_ent_mag": 32.015907287597656, "report/post_ent_max": 32.015907287597656, "report/post_ent_mean": 31.82107925415039, "report/post_ent_min": 31.632213592529297, "report/post_ent_std": 0.07129417359828949, "report/prior_ent_mag": 34.97600173950195, "report/prior_ent_max": 34.97600173950195, "report/prior_ent_mean": 33.03827667236328, "report/prior_ent_min": 31.621055603027344, "report/prior_ent_std": 0.5509039759635925, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 6.103515625e-05, "report/reward_loss_std": 0.0, "report/reward_max_data": 0.0, "report/reward_max_pred": 2.2649765014648438e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 6.103515625e-05, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 2.2558262571692467e-05, "report/reward_rate": 0.0, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.009798371233046055, "eval/cont_loss_std": 0.16849680244922638, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.399062156677246, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.004530274774879217, "eval/cont_pred": 0.9954800605773926, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.22252683341503143, "eval/image_loss_std": 0.1126587986946106, "eval/model_loss_mean": 0.832386314868927, "eval/model_loss_std": 0.19940213859081268, "eval/post_ent_mag": 32.037109375, "eval/post_ent_max": 32.037109375, "eval/post_ent_mean": 31.81565284729004, "eval/post_ent_min": 31.625492095947266, "eval/post_ent_std": 0.07699552923440933, "eval/prior_ent_mag": 34.64982604980469, "eval/prior_ent_max": 34.64982604980469, "eval/prior_ent_mean": 33.00979232788086, "eval/prior_ent_min": 31.627939224243164, "eval/prior_ent_std": 0.529236912727356, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 6.103515625e-05, "eval/reward_loss_std": 0.0, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 2.2649765014648438e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 6.103515625e-05, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 2.2557447664439678e-05, "eval/reward_rate": 0.0, "replay/size": 200000.0, "replay/inserts": 19120.0, "replay/samples": 19120.0, "replay/insert_wait_avg": 1.3811069552369697e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.284485645373995e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 20000.0, "eval_replay/inserts": 4624.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3338343907392561e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.195638656616211e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 500.32604122161865, "timer/env.step_count": 2390.0, "timer/env.step_total": 5.3783860206604, "timer/env.step_frac": 0.010749762310049444, "timer/env.step_avg": 0.00225037071994159, "timer/env.step_min": 0.0010859966278076172, "timer/env.step_max": 0.0697929859161377, "timer/replay._sample_count": 19120.0, "timer/replay._sample_total": 1326.2344994544983, "timer/replay._sample_frac": 2.650740497568954, "timer/replay._sample_avg": 0.06936372905096748, "timer/replay._sample_min": 0.0026955604553222656, "timer/replay._sample_max": 0.09181451797485352, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2968.0, "timer/agent.policy_total": 19.429978370666504, "timer/agent.policy_frac": 0.03883463335873022, "timer/agent.policy_avg": 0.00654648866936203, "timer/agent.policy_min": 0.0049479007720947266, "timer/agent.policy_max": 0.010773897171020508, "timer/dataset_train_count": 1195.0, "timer/dataset_train_total": 0.10865020751953125, "timer/dataset_train_frac": 0.0002171588095919333, "timer/dataset_train_avg": 9.092067574856171e-05, "timer/dataset_train_min": 6.866455078125e-05, "timer/dataset_train_max": 0.00028896331787109375, "timer/agent.train_count": 1195.0, "timer/agent.train_total": 466.27325916290283, "timer/agent.train_frac": 0.9319388173848177, "timer/agent.train_avg": 0.39018682775138314, "timer/agent.train_min": 0.3553657531738281, "timer/agent.train_max": 0.5345408916473389, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4516315460205078, "timer/agent.report_frac": 0.00090267447386465, "timer/agent.report_avg": 0.2258157730102539, "timer/agent.report_min": 0.21836256980895996, "timer/agent.report_max": 0.23326897621154785, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.457069396972656e-05, "timer/dataset_eval_frac": 6.909633143483237e-08, "timer/dataset_eval_avg": 3.457069396972656e-05, "timer/dataset_eval_min": 3.457069396972656e-05, "timer/dataset_eval_max": 3.457069396972656e-05, "fps": 38.21460434549418}
{"step": 257256, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 257264, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 257304, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 257728, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 258416, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 258456, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 258512, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 258880, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 259568, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 259576, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 259616, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 260000, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260040, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 260728, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 260768, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 260824, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 261192, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 261880, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 261888, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 261928, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 262352, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 263032, "episode/length": 275.0, "episode/score": 0.140625, "episode/reward_rate": 0.0036231884057971015}
{"step": 263040, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 263080, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 263504, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 264192, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 264200, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 264240, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 264664, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 265344, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 265352, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 265392, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 265816, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 266504, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 266512, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 266552, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 266976, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 267656, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 267664, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 267704, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 268128, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 268816, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 268824, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 268864, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 269288, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 269968, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 269976, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 270016, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 270088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270440, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 270776, "episode/length": 244.0, "episode/score": 0.23749999701976776, "episode/reward_rate": 0.004081632653061225}
{"step": 271136, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 271176, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 271600, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 272280, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 272288, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 272328, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 272752, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 273088, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 273448, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 273488, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 273912, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 274592, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 274600, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 274640, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 275064, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 275400, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 275760, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 275800, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 276224, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 276425, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.9896345294889857, "train/action_min": 0.0, "train/action_std": 1.994691125682143, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 7.354038417197146e-05, "train/actor_opt_grad_steps": 16575.0, "train/actor_opt_loss": -6.014764068312332, "train/adv_mag": 0.0005571856774145462, "train/adv_max": 0.00039371926734437705, "train/adv_mean": -1.7938327325699917e-05, "train/adv_min": -0.0005351361497992374, "train/adv_std": 8.525678405006699e-05, "train/cont_avg": 0.9964859759221312, "train/cont_loss_mean": 0.023371139062247925, "train/cont_loss_std": 0.3242791015368535, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.6690058469772335, "train/cont_pos_acc": 0.9999999892516215, "train/cont_pos_loss": 0.003486998776187662, "train/cont_pred": 0.9965191512811379, "train/cont_rate": 0.9964859759221312, "train/dyn_loss_mean": 1.0006729149427571, "train/dyn_loss_std": 0.0011883567308732233, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.0024407003691551644, "train/extr_critic_critic_opt_grad_steps": 16575.0, "train/extr_critic_critic_opt_loss": 5729.6769259093235, "train/extr_critic_mag": 0.014182546099678416, "train/extr_critic_max": 0.014182546099678416, "train/extr_critic_mean": 0.013661919955591687, "train/extr_critic_min": 0.013418698897127245, "train/extr_critic_std": 6.63370759210637e-05, "train/extr_return_normed_mag": 0.0004478660335794824, "train/extr_return_normed_max": 0.00044342959452359405, "train/extr_return_normed_mean": 6.244600600443026e-05, "train/extr_return_normed_min": -0.0001400147610511936, "train/extr_return_normed_std": 6.377985688440738e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.014024964587182784, "train/extr_return_raw_max": 0.014024964587182784, "train/extr_return_raw_mean": 0.013643981789650976, "train/extr_return_raw_min": 0.013441520231607997, "train/extr_return_raw_std": 6.377985712296337e-05, "train/extr_reward_mag": 4.1642149940865935e-05, "train/extr_reward_max": 4.1642149940865935e-05, "train/extr_reward_mean": 3.770037950684515e-05, "train/extr_reward_min": 3.6286526038998464e-05, "train/extr_reward_std": 5.859731030672835e-07, "train/image_loss_mean": 0.18221694377602124, "train/image_loss_std": 0.10376786831461016, "train/model_loss_mean": 0.8070716032239257, "train/model_loss_std": 0.36477027131152934, "train/model_opt_grad_norm": 35.498876274609174, "train/model_opt_grad_steps": 16557.909836065573, "train/model_opt_loss": 2495.206820128394, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3094.2622950819673, "train/policy_entropy_mag": 1.9457741301567828, "train/policy_entropy_max": 1.9457741301567828, "train/policy_entropy_mean": 1.9379609266265494, "train/policy_entropy_min": 1.8760928120769438, "train/policy_entropy_std": 0.005785208846228655, "train/policy_logprob_mag": 2.5385404199850363, "train/policy_logprob_max": -1.3832667509063346, "train/policy_logprob_mean": -1.9379750890809981, "train/policy_logprob_min": -2.5385404199850363, "train/policy_logprob_std": 0.125474285761841, "train/policy_randomness_mag": 0.9999301575246404, "train/policy_randomness_max": 0.9999301575246404, "train/policy_randomness_mean": 0.9959149717307482, "train/policy_randomness_min": 0.9641210407507225, "train/policy_randomness_std": 0.0029730094094821786, "train/post_ent_mag": 30.97276176390101, "train/post_ent_max": 30.97276176390101, "train/post_ent_mean": 30.822835937875215, "train/post_ent_min": 30.689017545981486, "train/post_ent_std": 0.05437948337954576, "train/prior_ent_mag": 33.53028764881071, "train/prior_ent_max": 33.53028764881071, "train/prior_ent_mean": 31.537240137819385, "train/prior_ent_min": 30.575355232739057, "train/prior_ent_std": 0.4146734102339041, "train/rep_loss_mean": 1.0006729149427571, "train/rep_loss_std": 0.0011883567308732233, "train/reward_avg": 3.48200566625818e-05, "train/reward_loss_mean": 0.001079748514428979, "train/reward_loss_std": 0.03140082993048458, "train/reward_max_data": 0.035655738022483764, "train/reward_max_pred": 3.9730892806756694e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 9.803388430092857e-05, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 10.22039826711019, "train/reward_pred": 3.7599361661943744e-05, "train/reward_rate": 9.605532786885246e-05, "train_stats/mean_log_entropy": 1.9301675943767322, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.03666914999485016, "report/cont_loss_std": 0.4328886568546295, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.675311088562012, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.003435499267652631, "report/cont_pred": 0.9965705275535583, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.2147187739610672, "report/image_loss_std": 0.10817462205886841, "report/model_loss_mean": 0.8514856100082397, "report/model_loss_std": 0.44791850447654724, "report/post_ent_mag": 30.212860107421875, "report/post_ent_max": 30.212860107421875, "report/post_ent_mean": 30.09894371032715, "report/post_ent_min": 29.990331649780273, "report/post_ent_std": 0.04185313731431961, "report/prior_ent_mag": 32.69003677368164, "report/prior_ent_max": 32.69003677368164, "report/prior_ent_mean": 31.164989471435547, "report/prior_ent_min": 30.36513900756836, "report/prior_ent_std": 0.38333043456077576, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 9.770411998033524e-05, "report/reward_loss_std": 1.150176444753015e-06, "report/reward_max_data": 0.0, "report/reward_max_pred": 4.5299530029296875e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 9.770411998033524e-05, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 4.3101957999169827e-05, "report/reward_rate": 0.0, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.008974440395832062, "eval/cont_loss_std": 0.17715951800346375, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.6753106117248535, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.003435499034821987, "eval/cont_pred": 0.9965705275535583, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.20642106235027313, "eval/image_loss_std": 0.11997952312231064, "eval/model_loss_mean": 0.8260565400123596, "eval/model_loss_std": 0.5419001579284668, "eval/post_ent_mag": 30.218782424926758, "eval/post_ent_max": 30.218782424926758, "eval/post_ent_mean": 30.104578018188477, "eval/post_ent_min": 30.000595092773438, "eval/post_ent_std": 0.04239713028073311, "eval/prior_ent_mag": 33.138694763183594, "eval/prior_ent_max": 33.138694763183594, "eval/prior_ent_mean": 31.230939865112305, "eval/prior_ent_min": 30.380964279174805, "eval/prior_ent_std": 0.40326380729675293, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0002807617129292339, "eval/reward_loss_mean": 0.010661059990525246, "eval/reward_loss_std": 0.3378589451313019, "eval/reward_max_data": 0.2874999940395355, "eval/reward_max_pred": 4.5299530029296875e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 9.7809883300215e-05, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 10.816865921020508, "eval/reward_pred": 4.315841943025589e-05, "eval/reward_rate": 0.0009765625, "replay/size": 200000.0, "replay/inserts": 19424.0, "replay/samples": 19424.0, "replay/insert_wait_avg": 1.4217598041553278e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.539815722030313e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 20000.0, "eval_replay/inserts": 4624.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3484261852647195e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.791685104370117e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 500.1770284175873, "timer/env.step_count": 2428.0, "timer/env.step_total": 5.803949594497681, "timer/env.step_frac": 0.011603790787553093, "timer/env.step_avg": 0.0023904240504520925, "timer/env.step_min": 0.0011589527130126953, "timer/env.step_max": 0.07004809379577637, "timer/replay._sample_count": 19424.0, "timer/replay._sample_total": 1350.9928395748138, "timer/replay._sample_frac": 2.7010293612422727, "timer/replay._sample_avg": 0.06955276151023547, "timer/replay._sample_min": 0.0003097057342529297, "timer/replay._sample_max": 0.12191009521484375, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3006.0, "timer/agent.policy_total": 19.849138259887695, "timer/agent.policy_frac": 0.03968422604829438, "timer/agent.policy_avg": 0.0066031730738149354, "timer/agent.policy_min": 0.004795074462890625, "timer/agent.policy_max": 0.012062311172485352, "timer/dataset_train_count": 1214.0, "timer/dataset_train_total": 0.11290287971496582, "timer/dataset_train_frac": 0.0002257258396535268, "timer/dataset_train_avg": 9.300072464165224e-05, "timer/dataset_train_min": 7.367134094238281e-05, "timer/dataset_train_max": 0.0002727508544921875, "timer/agent.train_count": 1214.0, "timer/agent.train_total": 466.84393548965454, "timer/agent.train_frac": 0.933357409408847, "timer/agent.train_avg": 0.38455019397829865, "timer/agent.train_min": 0.3531150817871094, "timer/agent.train_max": 0.4809279441833496, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.42142176628112793, "timer/agent.report_frac": 0.0008425452236668729, "timer/agent.report_avg": 0.21071088314056396, "timer/agent.report_min": 0.209975004196167, "timer/agent.report_max": 0.21144676208496094, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.62396240234375e-05, "timer/dataset_eval_frac": 7.245359535620616e-08, "timer/dataset_eval_avg": 3.62396240234375e-05, "timer/dataset_eval_min": 3.62396240234375e-05, "timer/dataset_eval_max": 3.62396240234375e-05, "fps": 38.833671117680595}
{"step": 276904, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 276912, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 276952, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 277376, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 277712, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 278072, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 278112, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 278536, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 279216, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 279224, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 279264, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 279688, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 280024, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 280072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280384, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 280424, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 280848, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 281528, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 281536, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 281576, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 282000, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 282336, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 282696, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 282736, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 283160, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 283840, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 283848, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 283888, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 284312, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 284648, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 285008, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 285048, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 285472, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 286152, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 286160, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 286200, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 286624, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 286960, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 287320, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 287360, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 287784, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 288464, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 288472, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 288512, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 288936, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 289272, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 289632, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 289672, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 290056, "eval_episode/length": 280.0, "eval_episode/score": 0.125, "eval_episode/reward_rate": 0.0035587188612099642}
{"step": 290056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290096, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 290776, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 290784, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 290824, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 291248, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 291584, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 291944, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 291984, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 292408, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 293088, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 293096, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 293136, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 293560, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 293896, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 294256, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 294296, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 294720, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 295400, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 295408, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 295448, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 295817, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.1805369479597108, "train/action_min": 0.0, "train/action_std": 1.808324425673682, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0008286952873855956, "train/actor_opt_grad_steps": 17790.0, "train/actor_opt_loss": -2.1701391031080473, "train/adv_mag": 0.0031934942480576923, "train/adv_max": 0.0030002055289454696, "train/adv_mean": 0.00024640245100148275, "train/adv_min": -0.0012038123124271385, "train/adv_std": 0.0004868479082981425, "train/cont_avg": 0.9963197314049587, "train/cont_loss_mean": 0.024341792522444707, "train/cont_loss_std": 0.33387100425633515, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.668936134369905, "train/cont_pos_acc": 0.9999999876849908, "train/cont_pos_loss": 0.003478866634305474, "train/cont_pred": 0.9965272388182396, "train/cont_rate": 0.9963197314049587, "train/dyn_loss_mean": 1.0000179759727037, "train/dyn_loss_std": 0.00045149970207024705, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.02097673101332866, "train/extr_critic_critic_opt_grad_steps": 17790.0, "train/extr_critic_critic_opt_loss": 6182.58743866219, "train/extr_critic_mag": 0.01655898803521779, "train/extr_critic_max": 0.01655898803521779, "train/extr_critic_mean": 0.015362569115563366, "train/extr_critic_min": 0.014602135035617293, "train/extr_critic_std": 0.00023774433426928423, "train/extr_return_normed_mag": 0.004088981161740693, "train/extr_return_normed_max": 0.004079587757587433, "train/extr_return_normed_mean": 0.001030577026299886, "train/extr_return_normed_min": 3.4856132793525036e-05, "train/extr_return_normed_std": 0.0005386569177032417, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.01865798143346694, "train/extr_return_raw_max": 0.01865798143346694, "train/extr_return_raw_mean": 0.015608971484374902, "train/extr_return_raw_min": 0.014613249816369913, "train/extr_return_raw_std": 0.000538656916019549, "train/extr_reward_mag": 0.0012222262453441778, "train/extr_reward_max": 0.0012222262453441778, "train/extr_reward_mean": 8.048285048257527e-05, "train/extr_reward_min": 1.7685338485339456e-05, "train/extr_reward_std": 0.00013822938104668115, "train/image_loss_mean": 0.17089700785057604, "train/image_loss_std": 0.10516049448123649, "train/model_loss_mean": 0.7964837664415029, "train/model_loss_std": 0.3748405897174, "train/model_opt_grad_norm": 33.70939980656647, "train/model_opt_grad_steps": 17771.785123966944, "train/model_opt_loss": 2088.277535430656, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2623.96694214876, "train/policy_entropy_mag": 1.8601072750800898, "train/policy_entropy_max": 1.8601072750800898, "train/policy_entropy_mean": 1.7755870405307486, "train/policy_entropy_min": 1.5543942855409354, "train/policy_entropy_std": 0.03397498259798062, "train/policy_logprob_mag": 3.688531574138925, "train/policy_logprob_max": -0.9423998653396102, "train/policy_logprob_mean": -1.7753307755328407, "train/policy_logprob_min": -3.688531574138925, "train/policy_logprob_std": 0.37804156652659426, "train/policy_randomness_mag": 0.9559061029725824, "train/policy_randomness_max": 0.9559061029725824, "train/policy_randomness_mean": 0.9124712909548736, "train/policy_randomness_min": 0.7988006933168932, "train/policy_randomness_std": 0.017459688271388166, "train/post_ent_mag": 29.90299295787969, "train/post_ent_max": 29.90299295787969, "train/post_ent_mean": 29.791730013760652, "train/post_ent_min": 29.687659838968074, "train/post_ent_std": 0.0402313583830664, "train/prior_ent_mag": 32.92021352594549, "train/prior_ent_max": 32.92021352594549, "train/prior_ent_mean": 30.746886245475327, "train/prior_ent_min": 29.93618520626352, "train/prior_ent_std": 0.3661298370065768, "train/rep_loss_mean": 1.0000179759727037, "train/rep_loss_std": 0.00045149970207024705, "train/reward_avg": 4.665910681009231e-05, "train/reward_loss_mean": 0.0012341546441220548, "train/reward_loss_std": 0.03365174100773084, "train/reward_max_data": 0.04532541297684031, "train/reward_max_pred": 0.0008539296378774091, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 9.092903345551972e-05, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.321372178884653, "train/reward_pred": 3.4513649499921266e-05, "train/reward_rate": 0.00012106146694214876, "train_stats/mean_log_entropy": 1.7890312529321928, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.025624938309192657, "report/cont_loss_std": 0.3574540615081787, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.73370885848999, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.003240299178287387, "report/cont_pred": 0.9967650771141052, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.18046295642852783, "report/image_loss_std": 0.10543284565210342, "report/model_loss_mean": 0.8061916828155518, "report/model_loss_std": 0.3752829432487488, "report/post_ent_mag": 29.613407135009766, "report/post_ent_max": 29.613407135009766, "report/post_ent_mean": 29.514921188354492, "report/post_ent_min": 29.420408248901367, "report/post_ent_std": 0.03560356795787811, "report/prior_ent_mag": 32.51991653442383, "report/prior_ent_max": 32.51991653442383, "report/prior_ent_mean": 30.316265106201172, "report/prior_ent_min": 29.528091430664062, "report/prior_ent_std": 0.42770880460739136, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.00010376842692494392, "report/reward_loss_std": 0.0007688779733143747, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.006204843521118164, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00010376842692494392, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 4.0370156057178974e-05, "report/reward_rate": 0.0, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.03681725263595581, "eval/cont_loss_std": 0.4373607337474823, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.73370885848999, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.003240299643948674, "eval/cont_pred": 0.9967650771141052, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.23123610019683838, "eval/image_loss_std": 0.15158826112747192, "eval/model_loss_mean": 0.8681837916374207, "eval/model_loss_std": 0.4689607620239258, "eval/post_ent_mag": 29.618854522705078, "eval/post_ent_max": 29.618854522705078, "eval/post_ent_mean": 29.51201629638672, "eval/post_ent_min": 29.419658660888672, "eval/post_ent_std": 0.03565835952758789, "eval/prior_ent_mag": 32.24980926513672, "eval/prior_ent_max": 32.24980926513672, "eval/prior_ent_mean": 30.317054748535156, "eval/prior_ent_min": 29.16944122314453, "eval/prior_ent_std": 0.4212595820426941, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00013037072494626045, "eval/reward_loss_std": 0.000912538671400398, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.005222320556640625, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00013037072494626045, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 5.090364720672369e-05, "eval/reward_rate": 0.0, "replay/size": 200000.0, "replay/inserts": 19392.0, "replay/samples": 19392.0, "replay/insert_wait_avg": 1.4143439606077995e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.33550232235748e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 20000.0, "eval_replay/inserts": 4624.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3127974572891183e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.301568984985352e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 500.2590272426605, "timer/env.step_count": 2424.0, "timer/env.step_total": 5.458049058914185, "timer/env.step_frac": 0.010910445912386605, "timer/env.step_avg": 0.0022516704038424854, "timer/env.step_min": 0.0011878013610839844, "timer/env.step_max": 0.010083436965942383, "timer/replay._sample_count": 19392.0, "timer/replay._sample_total": 1343.790934562683, "timer/replay._sample_frac": 2.6861902762043526, "timer/replay._sample_avg": 0.06929614967835618, "timer/replay._sample_min": 0.0002994537353515625, "timer/replay._sample_max": 0.0975806713104248, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3002.0, "timer/agent.policy_total": 19.703842163085938, "timer/agent.policy_frac": 0.03938727956932639, "timer/agent.policy_avg": 0.006563571673246482, "timer/agent.policy_min": 0.004923343658447266, "timer/agent.policy_max": 0.010487079620361328, "timer/dataset_train_count": 1212.0, "timer/dataset_train_total": 0.11124324798583984, "timer/dataset_train_frac": 0.00022237129552462651, "timer/dataset_train_avg": 9.178485807412528e-05, "timer/dataset_train_min": 7.939338684082031e-05, "timer/dataset_train_max": 0.00021719932556152344, "timer/agent.train_count": 1212.0, "timer/agent.train_total": 467.53533387184143, "timer/agent.train_frac": 0.9345865010149116, "timer/agent.train_avg": 0.38575522596686584, "timer/agent.train_min": 0.35646748542785645, "timer/agent.train_max": 0.4631063938140869, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.41252970695495605, "timer/agent.report_frac": 0.000824632209495043, "timer/agent.report_avg": 0.20626485347747803, "timer/agent.report_min": 0.19968056678771973, "timer/agent.report_max": 0.21284914016723633, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.504753112792969e-05, "timer/dataset_eval_frac": 7.005876799686253e-08, "timer/dataset_eval_avg": 3.504753112792969e-05, "timer/dataset_eval_min": 3.504753112792969e-05, "timer/dataset_eval_max": 3.504753112792969e-05, "fps": 38.76320912128267}
{"step": 295872, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 295968, "episode/length": 213.0, "episode/score": 0.3343749940395355, "episode/reward_rate": 0.004672897196261682}
{"step": 296208, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 296608, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 296808, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705}
{"step": 297032, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 297384, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374}
{"step": 297712, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 297720, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 297920, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547}
{"step": 298184, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 298280, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 298808, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875}
{"step": 298920, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 299344, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 300024, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 300032, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 300040, "eval_episode/length": 199.0, "eval_episode/score": 0.37812501192092896, "eval_episode/reward_rate": 0.005}
{"step": 300040, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300040, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300040, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300040, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300040, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300040, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300040, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300072, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444}
{"step": 300232, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 300496, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 300592, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 301120, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 301656, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 302336, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 302344, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 302384, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 302544, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 302808, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 302904, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 303432, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 303968, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 304648, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 304656, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 304696, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 304856, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 305120, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 305216, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 305744, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 305816, "episode/length": 8.0, "episode/score": 0.9750000238418579, "episode/reward_rate": 0.1111111111111111}
{"step": 306280, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 306960, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 306968, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 307008, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 307168, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 307360, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02}
{"step": 307432, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 307528, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 308128, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 308352, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044}
{"step": 308592, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 308760, "episode/length": 218.0, "episode/score": 0.3187499940395355, "episode/reward_rate": 0.0045662100456621}
{"step": 308856, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169}
{"step": 309280, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 309480, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 309672, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 309872, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496}
{"step": 309936, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304}
{"step": 310024, "eval_episode/length": 155.0, "eval_episode/score": 0.515625, "eval_episode/reward_rate": 0.00641025641025641}
{"step": 310024, "eval_episode/length": 195.0, "eval_episode/score": 0.390625, "eval_episode/reward_rate": 0.00510204081632653}
{"step": 310024, "eval_episode/length": 210.0, "eval_episode/score": 0.34375, "eval_episode/reward_rate": 0.004739336492890996}
{"step": 310024, "eval_episode/length": 275.0, "eval_episode/score": 0.140625, "eval_episode/reward_rate": 0.0036231884057971015}
{"step": 310024, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310440, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 310664, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 310824, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952}
{"step": 310904, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 311048, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374}
{"step": 311072, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 311592, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 311832, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609}
{"step": 311840, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548}
{"step": 311952, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835}
{"step": 312072, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655}
{"step": 312248, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 312368, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358}
{"step": 312536, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506}
{"step": 312976, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 313384, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 313736, "episode/length": 222.0, "episode/score": 0.3062500059604645, "episode/reward_rate": 0.004484304932735426}
{"step": 313904, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 314024, "episode/length": 206.0, "episode/score": 0.35624998807907104, "episode/reward_rate": 0.004830917874396135}
{"step": 314384, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 314560, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 314848, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 315288, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 315401, "train_stats/mean_log_entropy": 0.9774730909615755, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.0664612816982584, "train/action_min": 0.0, "train/action_std": 1.8309571078566254, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0029337367555317393, "train/actor_opt_grad_steps": 19005.0, "train/actor_opt_loss": 16.05389539323381, "train/adv_mag": 0.02559855055125033, "train/adv_max": 0.02515350295933055, "train/adv_mean": 0.003235837550432809, "train/adv_min": -0.006027319224276503, "train/adv_std": 0.0038420935731560573, "train/cont_avg": 0.9965259989754098, "train/cont_loss_mean": 0.023139719994448613, "train/cont_loss_std": 0.3182608790668949, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.6667949652471465, "train/cont_pos_acc": 0.9999999809460561, "train/cont_pos_loss": 0.0034800526079126312, "train/cont_pred": 0.996526058091492, "train/cont_rate": 0.9965259989754098, "train/dyn_loss_mean": 1.0000310051636618, "train/dyn_loss_std": 0.0009916339973404052, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.5160860661016472, "train/extr_critic_critic_opt_grad_steps": 19005.0, "train/extr_critic_critic_opt_loss": 11341.842337186219, "train/extr_critic_mag": 0.05920855823110362, "train/extr_critic_max": 0.05920855823110362, "train/extr_critic_mean": 0.052399095163115715, "train/extr_critic_min": 0.047337140216202035, "train/extr_critic_std": 0.0023192730868239046, "train/extr_return_normed_mag": 0.0368690783402226, "train/extr_return_normed_max": 0.03681141228155523, "train/extr_return_normed_mean": 0.011602035422091846, "train/extr_return_normed_min": 0.0036384395980199827, "train/extr_return_normed_std": 0.004733546598114028, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.08084430719618915, "train/extr_return_raw_max": 0.08084430719618915, "train/extr_return_raw_mean": 0.05563493253144085, "train/extr_return_raw_min": 0.047671334451583565, "train/extr_return_raw_std": 0.004733546596682692, "train/extr_reward_mag": 0.01832635676274534, "train/extr_reward_max": 0.01832635676274534, "train/extr_reward_mean": 0.0007371781104040088, "train/extr_reward_min": 2.5971991116883326e-06, "train/extr_reward_std": 0.0020386060301074184, "train/image_loss_mean": 0.15175622878748862, "train/image_loss_std": 0.10714111800809376, "train/model_loss_mean": 0.776158263448809, "train/model_loss_std": 0.36340296512744463, "train/model_opt_grad_norm": 32.730951825126276, "train/model_opt_grad_steps": 18985.745901639344, "train/model_opt_loss": 2209.7468181672643, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2848.3606557377047, "train/policy_entropy_mag": 1.777836471307473, "train/policy_entropy_max": 1.777836471307473, "train/policy_entropy_mean": 0.9039641203450375, "train/policy_entropy_min": 0.1657883967654627, "train/policy_entropy_std": 0.36640611150469937, "train/policy_logprob_mag": 6.304749172241961, "train/policy_logprob_max": -0.036353228422889454, "train/policy_logprob_mean": -0.9036201331459108, "train/policy_logprob_min": -6.304749172241961, "train/policy_logprob_std": 0.926049920867701, "train/policy_randomness_mag": 0.9136272683495381, "train/policy_randomness_max": 0.9136272683495381, "train/policy_randomness_mean": 0.46454569245459604, "train/policy_randomness_min": 0.0851983869234558, "train/policy_randomness_std": 0.1882955037423822, "train/post_ent_mag": 29.263871880828358, "train/post_ent_max": 29.263871880828358, "train/post_ent_mean": 29.16030164624824, "train/post_ent_min": 29.06837128811195, "train/post_ent_std": 0.03790734241121128, "train/prior_ent_mag": 32.12967405162874, "train/prior_ent_max": 32.12967405162874, "train/prior_ent_mean": 29.74174666795574, "train/prior_ent_min": 28.935614648412486, "train/prior_ent_std": 0.35169063630651254, "train/rep_loss_mean": 1.0000310051636618, "train/rep_loss_std": 0.0009916339973404052, "train/reward_avg": 7.006535797998248e-05, "train/reward_loss_mean": 0.0012436937540769577, "train/reward_loss_std": 0.03355176852824488, "train/reward_max_data": 0.0624743858810331, "train/reward_max_pred": 0.00713595796803959, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.0001379282959056045, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 6.59096524450514, "train/reward_pred": 5.585630138053513e-05, "train/reward_rate": 0.0001680968237704918, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.03668823093175888, "report/cont_loss_std": 0.4334849715232849, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.683096885681152, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.003408808493986726, "report/cont_pred": 0.9965971112251282, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.12079315632581711, "report/image_loss_std": 0.09436791390180588, "report/model_loss_mean": 0.75753253698349, "report/model_loss_std": 0.4434257447719574, "report/post_ent_mag": 29.34050178527832, "report/post_ent_max": 29.34050178527832, "report/post_ent_mean": 29.22943687438965, "report/post_ent_min": 29.104843139648438, "report/post_ent_std": 0.04194872826337814, "report/prior_ent_mag": 30.580230712890625, "report/prior_ent_max": 30.580230712890625, "report/prior_ent_mean": 29.093597412109375, "report/prior_ent_min": 28.30999755859375, "report/prior_ent_std": 0.26851633191108704, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 5.1119364798069e-05, "report/reward_loss_std": 0.00035732993273995817, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.002766132354736328, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 5.1119364798069e-05, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 2.1683750674128532e-05, "report/reward_rate": 0.0, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.03114166110754013, "eval/cont_loss_std": 0.3959100842475891, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.683096408843994, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.003408808493986726, "eval/cont_pred": 0.9965971112251282, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.22228285670280457, "eval/image_loss_std": 0.1283167451620102, "eval/model_loss_mean": 0.8534537553787231, "eval/model_loss_std": 0.41457653045654297, "eval/post_ent_mag": 29.330707550048828, "eval/post_ent_max": 29.330707550048828, "eval/post_ent_mean": 29.219640731811523, "eval/post_ent_min": 29.136829376220703, "eval/post_ent_std": 0.03994680196046829, "eval/prior_ent_mag": 30.437164306640625, "eval/prior_ent_max": 30.437164306640625, "eval/prior_ent_mean": 29.045503616333008, "eval/prior_ent_min": 28.277835845947266, "eval/prior_ent_std": 0.2836754024028778, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 2.924026921391487e-05, "eval/reward_loss_std": 0.00026805425295606256, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.002918243408203125, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 2.924026921391487e-05, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 1.2225937098264694e-05, "eval/reward_rate": 0.0, "replay/size": 200000.0, "replay/inserts": 19584.0, "replay/samples": 19584.0, "replay/insert_wait_avg": 1.429829722136454e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.367187660504011e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 20000.0, "eval_replay/inserts": 4624.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3163036128641413e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1920928955078125e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 500.19413685798645, "timer/env.step_count": 2448.0, "timer/env.step_total": 5.576555013656616, "timer/env.step_frac": 0.011148781248589274, "timer/env.step_avg": 0.0022780044990427352, "timer/env.step_min": 0.001119375228881836, "timer/env.step_max": 0.009934425354003906, "timer/replay._sample_count": 19584.0, "timer/replay._sample_total": 1355.936759710312, "timer/replay._sample_frac": 2.7108209788858146, "timer/replay._sample_avg": 0.06923696689697262, "timer/replay._sample_min": 0.0003819465637207031, "timer/replay._sample_max": 0.0944371223449707, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3026.0, "timer/agent.policy_total": 19.831884145736694, "timer/agent.policy_frac": 0.03964837387001859, "timer/agent.policy_avg": 0.006553828204142992, "timer/agent.policy_min": 0.004790306091308594, "timer/agent.policy_max": 0.011696815490722656, "timer/dataset_train_count": 1224.0, "timer/dataset_train_total": 0.11291098594665527, "timer/dataset_train_frac": 0.00022573432518804715, "timer/dataset_train_avg": 9.224753753811706e-05, "timer/dataset_train_min": 7.128715515136719e-05, "timer/dataset_train_max": 0.00022077560424804688, "timer/agent.train_count": 1224.0, "timer/agent.train_total": 467.02566289901733, "timer/agent.train_frac": 0.933688798978493, "timer/agent.train_avg": 0.3815569141331841, "timer/agent.train_min": 0.3558964729309082, "timer/agent.train_max": 0.49116945266723633, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.42207837104797363, "timer/agent.report_frac": 0.0008438291054335344, "timer/agent.report_avg": 0.21103918552398682, "timer/agent.report_min": 0.20056509971618652, "timer/agent.report_max": 0.2215132713317871, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 4.00543212890625e-05, "timer/dataset_eval_frac": 8.007755056999918e-08, "timer/dataset_eval_avg": 4.00543212890625e-05, "timer/dataset_eval_min": 4.00543212890625e-05, "timer/dataset_eval_max": 4.00543212890625e-05, "fps": 39.15218028647558}
{"step": 315672, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547}
{"step": 315696, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 315776, "episode/length": 218.0, "episode/score": 0.3187499940395355, "episode/reward_rate": 0.0045662100456621}
{"step": 315856, "episode/length": 243.0, "episode/score": 0.24062499403953552, "episode/reward_rate": 0.004098360655737705}
{"step": 316048, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 316696, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 316912, "episode/length": 202.0, "episode/score": 0.3687500059604645, "episode/reward_rate": 0.0049261083743842365}
{"step": 316960, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602}
{"step": 317008, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494}
{"step": 317048, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609}
{"step": 317160, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 317368, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904}
{"step": 317456, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856}
{"step": 318000, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266}
{"step": 318168, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 318184, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099}
{"step": 318360, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 318704, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676}
{"step": 318856, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904}
{"step": 319224, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 319272, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 319360, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 320008, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320008, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320008, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320008, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320008, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320008, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320008, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320008, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320312, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 320480, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 320672, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 321016, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 321168, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 321536, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 321584, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 321672, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 322216, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941}
{"step": 322624, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 322792, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 322984, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 323328, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 323336, "episode/length": 218.0, "episode/score": 0.3187499940395355, "episode/reward_rate": 0.0045662100456621}
{"step": 323480, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 323984, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 324048, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112}
{"step": 324336, "episode/length": 264.0, "episode/score": 0.17499999701976776, "episode/reward_rate": 0.0037735849056603774}
{"step": 324576, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333}
{"step": 324936, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 325104, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 325296, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 325648, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 325792, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 325848, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629}
{"step": 325856, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044}
{"step": 326056, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684}
{"step": 326296, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 326360, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 327416, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 327920, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872}
{"step": 327960, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 328104, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 328160, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 328168, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 328368, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 328608, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 328672, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 328880, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464}
{"step": 329752, "episode/length": 197.0, "episode/score": 0.3843750059604645, "episode/reward_rate": 0.005050505050505051}
{"step": 330096, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 330096, "eval_episode/length": 184.0, "eval_episode/score": 0.42500001192092896, "eval_episode/reward_rate": 0.005405405405405406}
{"step": 330096, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330096, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330096, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330096, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330096, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330096, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330232, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 330272, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 330416, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 330472, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 330680, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 330920, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 331000, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641}
{"step": 331192, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 331264, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372}
{"step": 331360, "episode/length": 20.0, "episode/score": 0.9375, "episode/reward_rate": 0.047619047619047616}
{"step": 331824, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827}
{"step": 331832, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444}
{"step": 331888, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282}
{"step": 331904, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894}
{"step": 332160, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353}
{"step": 332232, "episode/length": 244.0, "episode/score": 0.23749999701976776, "episode/reward_rate": 0.004081632653061225}
{"step": 332336, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517}
{"step": 332440, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988}
{"step": 332544, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 332728, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 332784, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 332856, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385}
{"step": 333432, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364}
{"step": 334144, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 334472, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 334544, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 334745, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.0131462664643593, "train/action_min": 0.0, "train/action_std": 1.3998683513688648, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.005017961305662343, "train/actor_opt_grad_steps": 20220.0, "train/actor_opt_loss": 12.047804684432085, "train/adv_mag": 0.09093823856558682, "train/adv_max": 0.09065431861345433, "train/adv_mean": 0.009892891292411676, "train/adv_min": -0.013799959224117688, "train/adv_std": 0.01291242389062281, "train/cont_avg": 0.9963197314049587, "train/cont_loss_mean": 0.024308892675052006, "train/cont_loss_std": 0.33233975921180253, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.648397469520569, "train/cont_pos_acc": 0.999999982758987, "train/cont_pos_loss": 0.0035495619570513155, "train/cont_pred": 0.996456803369128, "train/cont_rate": 0.9963197314049587, "train/dyn_loss_mean": 1.0000197089408054, "train/dyn_loss_std": 0.0006303751539565961, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.4223973663323675, "train/extr_critic_critic_opt_grad_steps": 20220.0, "train/extr_critic_critic_opt_loss": 6972.591820078448, "train/extr_critic_mag": 0.18852228763674903, "train/extr_critic_max": 0.18852228763674903, "train/extr_critic_mean": 0.18159636879755445, "train/extr_critic_min": 0.16618315838585215, "train/extr_critic_std": 0.004737279220091656, "train/extr_return_normed_mag": 0.11329873909881293, "train/extr_return_normed_max": 0.11318383525964643, "train/extr_return_normed_mean": 0.027869122860037284, "train/extr_return_normed_min": 0.004203513141505974, "train/extr_return_normed_std": 0.014310305651415847, "train/extr_return_rate": 0.0002953900043056, "train/extr_return_raw_mag": 0.27680396417940945, "train/extr_return_raw_max": 0.27680396417940945, "train/extr_return_raw_mean": 0.19148926030505786, "train/extr_return_raw_min": 0.1678236418149688, "train/extr_return_raw_std": 0.014310305703369794, "train/extr_reward_mag": 0.08560266573567035, "train/extr_reward_max": 0.08560266573567035, "train/extr_reward_mean": 0.0018848577557706028, "train/extr_reward_min": 3.180227989007619e-06, "train/extr_reward_std": 0.007605480658797709, "train/image_loss_mean": 0.12852241031148218, "train/image_loss_std": 0.10414295655883048, "train/model_loss_mean": 0.7548345933275774, "train/model_loss_std": 0.38373153792186215, "train/model_opt_grad_norm": 31.173720359802246, "train/model_opt_grad_steps": 20200.0, "train/model_opt_loss": 2680.529488555656, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3574.380165289256, "train/policy_entropy_mag": 1.6300309985137182, "train/policy_entropy_max": 1.6300309985137182, "train/policy_entropy_mean": 0.2277985422079228, "train/policy_entropy_min": 0.06470390612428839, "train/policy_entropy_std": 0.2590907690199939, "train/policy_logprob_mag": 6.550906244388297, "train/policy_logprob_max": -0.008611018969561936, "train/policy_logprob_mean": -0.22854886197846783, "train/policy_logprob_min": -6.550906244388297, "train/policy_logprob_std": 0.7651365931369056, "train/policy_randomness_mag": 0.8376702764802728, "train/policy_randomness_max": 0.8376702764802728, "train/policy_randomness_mean": 0.11706529920997698, "train/policy_randomness_min": 0.03325123195190075, "train/policy_randomness_std": 0.13314632511089655, "train/post_ent_mag": 28.672008829668535, "train/post_ent_max": 28.672008829668535, "train/post_ent_mean": 28.56929843681903, "train/post_ent_min": 28.465748857860724, "train/post_ent_std": 0.03992900483248647, "train/prior_ent_mag": 30.926952440876605, "train/prior_ent_max": 30.926952440876605, "train/prior_ent_mean": 28.74924087524414, "train/prior_ent_min": 27.80753381587257, "train/prior_ent_std": 0.35455096888640697, "train/rep_loss_mean": 1.0000197089408054, "train/rep_loss_std": 0.0006303751539565961, "train/reward_avg": 0.0001676953527576113, "train/reward_loss_mean": 0.0019914407594791377, "train/reward_loss_std": 0.049363332591668994, "train/reward_max_data": 0.1391012407531423, "train/reward_max_pred": 0.025150992653586647, "train/reward_neg_acc": 0.9999596141586619, "train/reward_neg_loss": 0.0002742607871631895, "train/reward_pos_acc": 0.06896551724137931, "train/reward_pos_loss": 5.722745763844457, "train/reward_pred": 0.00012228178622370416, "train/reward_rate": 0.00029054752066115703, "train_stats/mean_log_entropy": 0.22016262059861963, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.020234355702996254, "report/cont_loss_std": 0.29535973072052, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.4690680503845215, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.004224068485200405, "report/cont_pred": 0.9957848191261292, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.10606783628463745, "report/image_loss_std": 0.09246689081192017, "report/model_loss_mean": 0.7264294624328613, "report/model_loss_std": 0.3115918040275574, "report/post_ent_mag": 28.387996673583984, "report/post_ent_max": 28.387996673583984, "report/post_ent_mean": 28.28978729248047, "report/post_ent_min": 28.163066864013672, "report/post_ent_std": 0.03986956179141998, "report/prior_ent_mag": 29.44610595703125, "report/prior_ent_max": 29.44610595703125, "report/prior_ent_mean": 28.17780303955078, "report/prior_ent_min": 27.08788299560547, "report/prior_ent_std": 0.29991671442985535, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.00012723589316010475, "report/reward_loss_std": 0.0011715737637132406, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.011489510536193848, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00012723589316010475, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 5.689461249858141e-05, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.0202343612909317, "eval/cont_loss_std": 0.29535970091819763, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.4690680503845215, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.004224068485200405, "eval/cont_pred": 0.9957848191261292, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.22106298804283142, "eval/image_loss_std": 0.12966591119766235, "eval/model_loss_mean": 0.8413591384887695, "eval/model_loss_std": 0.325960248708725, "eval/post_ent_mag": 28.391345977783203, "eval/post_ent_max": 28.391345977783203, "eval/post_ent_mean": 28.278921127319336, "eval/post_ent_min": 28.174015045166016, "eval/post_ent_std": 0.03755902871489525, "eval/prior_ent_mag": 29.738689422607422, "eval/prior_ent_max": 29.738689422607422, "eval/prior_ent_mean": 28.17346954345703, "eval/prior_ent_min": 27.312774658203125, "eval/prior_ent_std": 0.34665989875793457, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 6.179185584187508e-05, "eval/reward_loss_std": 0.0005548095796257257, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0039414167404174805, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 6.179185584187508e-05, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 2.7538160793483257e-05, "eval/reward_rate": 0.0, "replay/size": 200000.0, "replay/inserts": 19344.0, "replay/samples": 19344.0, "replay/insert_wait_avg": 1.4187162626469993e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.437639141792695e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 20000.0, "eval_replay/inserts": 4624.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3517776575055502e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.08970832824707e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 500.2191650867462, "timer/env.step_count": 2418.0, "timer/env.step_total": 5.627057075500488, "timer/env.step_frac": 0.011249183294535834, "timer/env.step_avg": 0.0023271534638132706, "timer/env.step_min": 0.0011539459228515625, "timer/env.step_max": 0.009037017822265625, "timer/replay._sample_count": 19344.0, "timer/replay._sample_total": 1344.876924753189, "timer/replay._sample_frac": 2.6885753657998395, "timer/replay._sample_avg": 0.06952424135407305, "timer/replay._sample_min": 0.0003654956817626953, "timer/replay._sample_max": 0.09793281555175781, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2996.0, "timer/agent.policy_total": 19.861788034439087, "timer/agent.policy_frac": 0.03970617165576758, "timer/agent.policy_avg": 0.006629435258491017, "timer/agent.policy_min": 0.005010843276977539, "timer/agent.policy_max": 0.010761022567749023, "timer/dataset_train_count": 1209.0, "timer/dataset_train_total": 0.11226606369018555, "timer/dataset_train_frac": 0.0002244337512952283, "timer/dataset_train_avg": 9.285861347409888e-05, "timer/dataset_train_min": 6.866455078125e-05, "timer/dataset_train_max": 0.0003192424774169922, "timer/agent.train_count": 1209.0, "timer/agent.train_total": 466.92996740341187, "timer/agent.train_frac": 0.9334507751665984, "timer/agent.train_avg": 0.3862117182823919, "timer/agent.train_min": 0.3567044734954834, "timer/agent.train_max": 0.45835065841674805, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4154188632965088, "timer/agent.report_frac": 0.0008304737049098635, "timer/agent.report_avg": 0.2077094316482544, "timer/agent.report_min": 0.1974492073059082, "timer/agent.report_max": 0.21796965599060059, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 4.410743713378906e-05, "timer/dataset_eval_frac": 8.817622396802832e-08, "timer/dataset_eval_avg": 4.410743713378906e-05, "timer/dataset_eval_min": 4.410743713378906e-05, "timer/dataset_eval_max": 4.410743713378906e-05, "fps": 38.67032956720705}
{"step": 334752, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 334856, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 335096, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 335168, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 335368, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988}
{"step": 335400, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176}
{"step": 335640, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176}
{"step": 335720, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025}
{"step": 335744, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 336456, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 336784, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 336856, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 337480, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 337680, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 337952, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 338032, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 338056, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 338552, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334}
{"step": 338768, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 339096, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 339168, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 339376, "episode/length": 236.0, "episode/score": 0.26249998807907104, "episode/reward_rate": 0.004219409282700422}
{"step": 339992, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 340080, "eval_episode/length": 151.0, "eval_episode/score": 0.528124988079071, "eval_episode/reward_rate": 0.006578947368421052}
{"step": 340080, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 340080, "eval_episode/length": 40.0, "eval_episode/score": 0.875, "eval_episode/reward_rate": 0.024390243902439025}
{"step": 340080, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340344, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 340368, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 340656, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338}
{"step": 340776, "episode/length": 14.0, "episode/score": 0.956250011920929, "episode/reward_rate": 0.06666666666666667}
{"step": 340864, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 341080, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 341408, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 341408, "episode/length": 253.0, "episode/score": 0.20937499403953552, "episode/reward_rate": 0.003937007874015748}
{"step": 341480, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 341864, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588}
{"step": 342656, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 342680, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 343176, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 343392, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 343720, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 343720, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 343792, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 344176, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 344640, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827}
{"step": 344968, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 344992, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 345024, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494}
{"step": 345488, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 345704, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 346032, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 346032, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 346928, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428}
{"step": 346952, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 347280, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 347304, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 347336, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 347560, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838}
{"step": 347800, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 348016, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 349232, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052}
{"step": 349240, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 349264, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 349592, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 349616, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 349648, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 349840, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105}
{"step": 349848, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105}
{"step": 349872, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 350064, "eval_episode/length": 30.0, "eval_episode/score": 0.90625, "eval_episode/reward_rate": 0.03225806451612903}
{"step": 350064, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 350064, "eval_episode/length": 262.0, "eval_episode/score": 0.18125000596046448, "eval_episode/reward_rate": 0.0038022813688212928}
{"step": 350064, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350064, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350064, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350064, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350064, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350112, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 350184, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808}
{"step": 350592, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549}
{"step": 351520, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414}
{"step": 351576, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 351904, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 351928, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 351960, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 351984, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827}
{"step": 352152, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 352184, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 352336, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517}
{"step": 352368, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102}
{"step": 352424, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 352768, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863}
{"step": 352776, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102}
{"step": 353136, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374}
{"step": 354057, "train_stats/mean_log_entropy": 0.16201826947999287, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.450229613248967, "train/action_min": 0.0, "train/action_std": 1.7148322029547258, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.008325754151071521, "train/actor_opt_grad_steps": 21430.0, "train/actor_opt_loss": 9.648744750121407, "train/adv_mag": 0.21088449435293183, "train/adv_max": 0.2086990212113404, "train/adv_mean": 0.014148275761538924, "train/adv_min": -0.025089789766910647, "train/adv_std": 0.02642290406544839, "train/cont_avg": 0.9961018207644629, "train/cont_loss_mean": 0.02554600543250168, "train/cont_loss_std": 0.3378241700101028, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.597929125072575, "train/cont_pos_acc": 0.9999999832515875, "train/cont_pos_loss": 0.003739177047328885, "train/cont_pred": 0.9962679083682289, "train/cont_rate": 0.9961018207644629, "train/dyn_loss_mean": 1.0000051112214396, "train/dyn_loss_std": 0.00016311228508370245, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.9095629427797538, "train/extr_critic_critic_opt_grad_steps": 21430.0, "train/extr_critic_critic_opt_loss": 10517.867921939565, "train/extr_critic_mag": 0.36235374064484904, "train/extr_critic_max": 0.36235374064484904, "train/extr_critic_mean": 0.3501888938432883, "train/extr_critic_min": 0.3303312092773185, "train/extr_critic_std": 0.007270620879909593, "train/extr_return_normed_mag": 0.24447341817469637, "train/extr_return_normed_max": 0.24447322569110178, "train/extr_return_normed_mean": 0.04210073934206046, "train/extr_return_normed_min": 0.005927951991065474, "train/extr_return_normed_std": 0.028105407589584713, "train/extr_return_rate": 0.050764573458185296, "train/extr_return_raw_mag": 0.5667096424447603, "train/extr_return_raw_max": 0.5667096424447603, "train/extr_return_raw_mean": 0.3643371712816648, "train/extr_return_raw_min": 0.3281643683752738, "train/extr_return_raw_std": 0.028105407639614437, "train/extr_reward_mag": 0.1905591576552588, "train/extr_reward_max": 0.1905591576552588, "train/extr_reward_mean": 0.00282894052776281, "train/extr_reward_min": 1.098498825199348e-06, "train/extr_reward_std": 0.01333951289103605, "train/image_loss_mean": 0.11341306339364407, "train/image_loss_std": 0.10155006134805601, "train/model_loss_mean": 0.7417256354300443, "train/model_loss_std": 0.4039202906376074, "train/model_opt_grad_norm": 30.571876297312336, "train/model_opt_grad_steps": 21409.02479338843, "train/model_opt_loss": 3025.034962551653, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 4070.2479338842977, "train/policy_entropy_mag": 1.5453608380861519, "train/policy_entropy_max": 1.5453608380861519, "train/policy_entropy_mean": 0.1875770452840269, "train/policy_entropy_min": 0.06468977945402635, "train/policy_entropy_std": 0.22397362878007337, "train/policy_logprob_mag": 6.551054126960187, "train/policy_logprob_max": -0.008608777253034194, "train/policy_logprob_mean": -0.18671214746788514, "train/policy_logprob_min": -6.551054126960187, "train/policy_logprob_std": 0.7219739950392857, "train/policy_randomness_mag": 0.7941584197942876, "train/policy_randomness_max": 0.7941584197942876, "train/policy_randomness_mean": 0.096395539227596, "train/policy_randomness_min": 0.0332439725002474, "train/policy_randomness_std": 0.11509968260349321, "train/post_ent_mag": 28.236877141905225, "train/post_ent_max": 28.236877141905225, "train/post_ent_mean": 28.13129168108475, "train/post_ent_min": 28.015515760941938, "train/post_ent_std": 0.042140284014388546, "train/prior_ent_mag": 29.65854810289115, "train/prior_ent_max": 29.65854810289115, "train/prior_ent_mean": 27.78667974866126, "train/prior_ent_min": 26.590288036125752, "train/prior_ent_std": 0.3844745787214642, "train/rep_loss_mean": 1.0000051112214396, "train/rep_loss_std": 0.00016311228508370245, "train/reward_avg": 0.0003090093958851581, "train/reward_loss_mean": 0.00276347233679084, "train/reward_loss_std": 0.06858319741799324, "train/reward_max_data": 0.24726239647254472, "train/reward_max_pred": 0.0455539019639827, "train/reward_neg_acc": 0.9999272759295692, "train/reward_neg_loss": 0.0003547769963555134, "train/reward_pos_acc": 0.2, "train/reward_pos_loss": 5.025839665200976, "train/reward_pred": 0.00019479697581750057, "train/reward_rate": 0.00048424586776859505, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.0256415493786335, "report/cont_loss_std": 0.3589159846305847, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.757071495056152, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0031653570476919413, "report/cont_pred": 0.9968395829200745, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.08810935169458389, "report/image_loss_std": 0.08419480919837952, "report/model_loss_mean": 0.7139879465103149, "report/model_loss_std": 0.36654168367385864, "report/post_ent_mag": 27.951663970947266, "report/post_ent_max": 27.951663970947266, "report/post_ent_mean": 27.84348487854004, "report/post_ent_min": 27.72464370727539, "report/post_ent_std": 0.04454004764556885, "report/prior_ent_mag": 28.828590393066406, "report/prior_ent_max": 28.828590393066406, "report/prior_ent_mean": 27.466102600097656, "report/prior_ent_min": 26.264137268066406, "report/prior_ent_std": 0.3525010347366333, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.00023706024512648582, "report/reward_loss_std": 0.0015855435049161315, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.009541511535644531, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00023706024512648582, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00010751874651759863, "report/reward_rate": 0.0, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.03687964379787445, "eval/cont_loss_std": 0.4391494691371918, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.757071495056152, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.003165357280522585, "eval/cont_pred": 0.9968395829200745, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.24854792654514313, "eval/image_loss_std": 0.143188938498497, "eval/model_loss_mean": 0.9065384268760681, "eval/model_loss_std": 0.8353358507156372, "eval/post_ent_mag": 27.946182250976562, "eval/post_ent_max": 27.946182250976562, "eval/post_ent_mean": 27.82442855834961, "eval/post_ent_min": 27.726451873779297, "eval/post_ent_std": 0.04069148749113083, "eval/prior_ent_mag": 29.438323974609375, "eval/prior_ent_max": 29.438323974609375, "eval/prior_ent_mean": 27.432353973388672, "eval/prior_ent_min": 26.391319274902344, "eval/prior_ent_std": 0.37120047211647034, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0015106201171875, "eval/reward_loss_mean": 0.021110838279128075, "eval/reward_loss_std": 0.48795998096466064, "eval/reward_max_data": 0.846875011920929, "eval/reward_max_pred": 0.0021954774856567383, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 3.299647869425826e-05, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 10.791889190673828, "eval/reward_pred": 1.48421386256814e-05, "eval/reward_rate": 0.001953125, "replay/size": 200000.0, "replay/inserts": 19312.0, "replay/samples": 19312.0, "replay/insert_wait_avg": 1.4503138462373216e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.42514862338669e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 20000.0, "eval_replay/inserts": 4624.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.422467941231381e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 500.3289384841919, "timer/env.step_count": 2414.0, "timer/env.step_total": 5.603342056274414, "timer/env.step_frac": 0.011199316340266923, "timer/env.step_avg": 0.00232118560740448, "timer/env.step_min": 0.0011525154113769531, "timer/env.step_max": 0.030786752700805664, "timer/replay._sample_count": 19312.0, "timer/replay._sample_total": 1341.9896547794342, "timer/replay._sample_frac": 2.682214742255679, "timer/replay._sample_avg": 0.06948993655651585, "timer/replay._sample_min": 0.005851030349731445, "timer/replay._sample_max": 0.09820294380187988, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2992.0, "timer/agent.policy_total": 19.7464861869812, "timer/agent.policy_frac": 0.03946700793842869, "timer/agent.policy_avg": 0.006599761426130081, "timer/agent.policy_min": 0.0049555301666259766, "timer/agent.policy_max": 0.01163339614868164, "timer/dataset_train_count": 1207.0, "timer/dataset_train_total": 0.11167788505554199, "timer/dataset_train_frac": 0.00022320892609946547, "timer/dataset_train_avg": 9.252517403110356e-05, "timer/dataset_train_min": 8.034706115722656e-05, "timer/dataset_train_max": 0.00021147727966308594, "timer/agent.train_count": 1207.0, "timer/agent.train_total": 465.838684797287, "timer/agent.train_frac": 0.9310648434779779, "timer/agent.train_avg": 0.3859475433283239, "timer/agent.train_min": 0.35610532760620117, "timer/agent.train_max": 0.46822190284729004, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.44601988792419434, "timer/agent.report_frac": 0.0008914533092478451, "timer/agent.report_avg": 0.22300994396209717, "timer/agent.report_min": 0.22264862060546875, "timer/agent.report_max": 0.22337126731872559, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.719329833984375e-05, "timer/dataset_eval_frac": 7.433769162448493e-08, "timer/dataset_eval_avg": 3.719329833984375e-05, "timer/dataset_eval_min": 3.719329833984375e-05, "timer/dataset_eval_max": 3.719329833984375e-05, "fps": 38.598093445983466}
{"step": 354240, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 354464, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 354648, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 354680, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 354736, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 355040, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01}
{"step": 355080, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 355088, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 355152, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872}
{"step": 355448, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 355504, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693}
{"step": 355568, "episode/length": 7.0, "episode/score": 0.9781249761581421, "episode/reward_rate": 0.125}
{"step": 355664, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414}
{"step": 356576, "episode/length": 191.0, "episode/score": 0.40312498807907104, "episode/reward_rate": 0.005208333333333333}
{"step": 356696, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835}
{"step": 356992, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 357392, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 357400, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 357464, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 357520, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644}
{"step": 357760, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 357952, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517}
{"step": 357976, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 358320, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608}
{"step": 358464, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203}
{"step": 358520, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835}
{"step": 358704, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099}
{"step": 358864, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714}
{"step": 359008, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 359296, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541}
{"step": 359304, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 359512, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035}
{"step": 360048, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693}
{"step": 360048, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 360048, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 360048, "eval_episode/length": 90.0, "eval_episode/score": 0.71875, "eval_episode/reward_rate": 0.01098901098901099}
{"step": 360048, "eval_episode/length": 140.0, "eval_episode/score": 0.5625, "eval_episode/reward_rate": 0.0070921985815602835}
{"step": 360048, "eval_episode/length": 14.0, "eval_episode/score": 0.956250011920929, "eval_episode/reward_rate": 0.06666666666666667}
{"step": 360048, "eval_episode/length": 109.0, "eval_episode/score": 0.659375011920929, "eval_episode/reward_rate": 0.00909090909090909}
{"step": 360048, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 360048, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 360048, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 360048, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 360072, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 360088, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888}
{"step": 360184, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909}
{"step": 360616, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517}
{"step": 360632, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863}
{"step": 360776, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 360824, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425}
{"step": 360832, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 361016, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 361176, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 361728, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005}
{"step": 362288, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285}
{"step": 362400, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 362928, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125}
{"step": 362928, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 363088, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 363136, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 363144, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 363328, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 363408, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666}
{"step": 363488, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 363904, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888}
{"step": 364176, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693}
{"step": 364320, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403}
{"step": 364712, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 365240, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 365400, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 365456, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 365800, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 366000, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176}
{"step": 366216, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 366488, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 366632, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 366672, "episode/length": 244.0, "episode/score": 0.23749999701976776, "episode/reward_rate": 0.004081632653061225}
{"step": 366744, "episode/length": 8.0, "episode/score": 0.9750000238418579, "episode/reward_rate": 0.1111111111111111}
{"step": 366832, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095}
{"step": 366992, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464}
{"step": 367552, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 367736, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216}
{"step": 368112, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 368312, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 368800, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 368944, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 369056, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 369144, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 369304, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 369744, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818}
{"step": 370032, "eval_episode/length": 60.0, "eval_episode/score": 0.8125, "eval_episode/reward_rate": 0.01639344262295082}
{"step": 370032, "eval_episode/length": 44.0, "eval_episode/score": 0.862500011920929, "eval_episode/reward_rate": 0.022222222222222223}
{"step": 370032, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370032, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370032, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370032, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370032, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370032, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370032, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370048, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 370424, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 370624, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 370704, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857}
{"step": 371112, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 371256, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 371368, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 371456, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 372056, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 372232, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453}
{"step": 372360, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 372688, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025}
{"step": 373016, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 373289, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.486670430501302, "train/action_min": 0.0, "train/action_std": 1.7419291943311692, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.007182006556346702, "train/actor_opt_grad_steps": 22635.0, "train/actor_opt_loss": 2.1264877232412496, "train/adv_mag": 0.2571817482511202, "train/adv_max": 0.25623636692762375, "train/adv_mean": 0.009044337572049699, "train/adv_min": -0.035077788929144545, "train/adv_std": 0.025712127222989996, "train/cont_avg": 0.9964436848958333, "train/cont_loss_mean": 0.023636695948274184, "train/cont_loss_std": 0.31720825223989474, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.566522402641101, "train/cont_pos_acc": 0.9999999870856603, "train/cont_pos_loss": 0.0038474762948074686, "train/cont_pred": 0.9961599950989087, "train/cont_rate": 0.9964436848958333, "train/dyn_loss_mean": 1.000011260310809, "train/dyn_loss_std": 0.00034900577887431915, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1303815560104946, "train/extr_critic_critic_opt_grad_steps": 22635.0, "train/extr_critic_critic_opt_loss": 12289.622737630209, "train/extr_critic_mag": 0.49602656861146294, "train/extr_critic_max": 0.49602656861146294, "train/extr_critic_mean": 0.47186229154467585, "train/extr_critic_min": 0.449623696009318, "train/extr_critic_std": 0.009542561772589882, "train/extr_return_normed_mag": 0.2955624784032504, "train/extr_return_normed_max": 0.2955624784032504, "train/extr_return_normed_mean": 0.03440574938977079, "train/extr_return_normed_min": -0.0015558769305547078, "train/extr_return_normed_std": 0.028331921878270806, "train/extr_return_rate": 0.31596897520309236, "train/extr_return_raw_mag": 0.7420633365710576, "train/extr_return_raw_max": 0.7420633365710576, "train/extr_return_raw_mean": 0.48090663105249404, "train/extr_return_raw_min": 0.44494498123725257, "train/extr_return_raw_std": 0.028331922200353195, "train/extr_reward_mag": 0.26673477788766226, "train/extr_reward_max": 0.26673477788766226, "train/extr_reward_mean": 0.002344814777704111, "train/extr_reward_min": 6.099541982014973e-07, "train/extr_reward_std": 0.012984078971203416, "train/image_loss_mean": 0.10013338619222244, "train/image_loss_std": 0.09854493041833241, "train/model_loss_mean": 0.7273605873187383, "train/model_loss_std": 0.3956511513640483, "train/model_opt_grad_norm": 29.456083313624063, "train/model_opt_grad_steps": 22612.475, "train/model_opt_loss": 1878.2154123942057, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2583.3333333333335, "train/policy_entropy_mag": 1.505280496676763, "train/policy_entropy_max": 1.505280496676763, "train/policy_entropy_mean": 0.15615801146874825, "train/policy_entropy_min": 0.06468790862709284, "train/policy_entropy_std": 0.20023047650853792, "train/policy_logprob_mag": 6.551075299580892, "train/policy_logprob_max": -0.008608471283999582, "train/policy_logprob_mean": -0.15672763548791407, "train/policy_logprob_min": -6.551075299580892, "train/policy_logprob_std": 0.6988326753179233, "train/policy_randomness_mag": 0.7735611940423648, "train/policy_randomness_max": 0.7735611940423648, "train/policy_randomness_mean": 0.08024934809654952, "train/policy_randomness_min": 0.03324301068981488, "train/policy_randomness_std": 0.10289811696857214, "train/post_ent_mag": 27.8996422290802, "train/post_ent_max": 27.8996422290802, "train/post_ent_mean": 27.787648232777915, "train/post_ent_min": 27.661974668502808, "train/post_ent_std": 0.046909338080634674, "train/prior_ent_mag": 28.825333960851033, "train/prior_ent_max": 28.825333960851033, "train/prior_ent_mean": 26.9896368821462, "train/prior_ent_min": 25.781231594085693, "train/prior_ent_std": 0.41632211456696194, "train/rep_loss_mean": 1.000011260310809, "train/rep_loss_std": 0.00034900577887431915, "train/reward_avg": 0.00038454691615091483, "train/reward_loss_mean": 0.0035837299462097385, "train/reward_loss_std": 0.08164228987540506, "train/reward_max_data": 0.30721354397634665, "train/reward_max_pred": 0.06739696164925893, "train/reward_neg_acc": 0.9999429856737455, "train/reward_neg_loss": 0.0005298527221990905, "train/reward_pos_acc": 0.17857142857142858, "train/reward_pos_loss": 4.534017550093787, "train/reward_pred": 0.00029491388510602217, "train/reward_rate": 0.000634765625, "train_stats/mean_log_entropy": 0.11827782934070916, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.014710811898112297, "report/cont_loss_std": 0.24524499475955963, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.558549404144287, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.003861811012029648, "report/cont_pred": 0.996145486831665, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.09366466104984283, "report/image_loss_std": 0.09600744396448135, "report/model_loss_mean": 0.7087132334709167, "report/model_loss_std": 0.26078498363494873, "report/post_ent_mag": 27.684223175048828, "report/post_ent_max": 27.684223175048828, "report/post_ent_mean": 27.567678451538086, "report/post_ent_min": 27.45931053161621, "report/post_ent_std": 0.04650527611374855, "report/prior_ent_mag": 27.846031188964844, "report/prior_ent_max": 27.846031188964844, "report/prior_ent_mean": 26.685482025146484, "report/prior_ent_min": 25.518199920654297, "report/prior_ent_std": 0.3990953266620636, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.00033775437623262405, "report/reward_loss_std": 0.004863709211349487, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.06809556484222412, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00033775437623262405, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00015940272714942694, "report/reward_rate": 0.0, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.030984314158558846, "eval/cont_loss_std": 0.3871968388557434, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.558549404144287, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.003861811012029648, "eval/cont_pred": 0.996145486831665, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2629967927932739, "eval/image_loss_std": 0.1520979255437851, "eval/model_loss_mean": 0.9064191579818726, "eval/model_loss_std": 0.6869038343429565, "eval/post_ent_mag": 27.677566528320312, "eval/post_ent_max": 27.677566528320312, "eval/post_ent_mean": 27.552104949951172, "eval/post_ent_min": 27.455812454223633, "eval/post_ent_std": 0.0423235259950161, "eval/prior_ent_mag": 27.866817474365234, "eval/prior_ent_max": 27.866817474365234, "eval/prior_ent_mean": 26.544424057006836, "eval/prior_ent_min": 25.298603057861328, "eval/prior_ent_std": 0.4174487888813019, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0008270263788290322, "eval/reward_loss_mean": 0.012438040226697922, "eval/reward_loss_std": 0.3969935178756714, "eval/reward_max_data": 0.846875011920929, "eval/reward_max_pred": 0.0021647214889526367, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 2.593238968984224e-05, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 12.7100248336792, "eval/reward_pred": 1.1600670404732227e-05, "eval/reward_rate": 0.0009765625, "replay/size": 200000.0, "replay/inserts": 19232.0, "replay/samples": 19232.0, "replay/insert_wait_avg": 1.4581691207187545e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.493598092217215e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 20000.0, "eval_replay/inserts": 4624.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3806518798880925e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.2516975402832031e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 500.085679769516, "timer/env.step_count": 2404.0, "timer/env.step_total": 5.620140075683594, "timer/env.step_frac": 0.011238354352145926, "timer/env.step_avg": 0.0023378286504507463, "timer/env.step_min": 0.0011951923370361328, "timer/env.step_max": 0.010003805160522461, "timer/replay._sample_count": 19232.0, "timer/replay._sample_total": 1339.8042378425598, "timer/replay._sample_frac": 2.679149377882728, "timer/replay._sample_avg": 0.06966536178465889, "timer/replay._sample_min": 0.0003085136413574219, "timer/replay._sample_max": 0.09821796417236328, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2982.0, "timer/agent.policy_total": 19.817445755004883, "timer/agent.policy_frac": 0.03962810085691421, "timer/agent.policy_avg": 0.006645689387996272, "timer/agent.policy_min": 0.0049746036529541016, "timer/agent.policy_max": 0.011437177658081055, "timer/dataset_train_count": 1202.0, "timer/dataset_train_total": 0.11181402206420898, "timer/dataset_train_frac": 0.00022358972989537082, "timer/dataset_train_avg": 9.302331286539849e-05, "timer/dataset_train_min": 6.771087646484375e-05, "timer/dataset_train_max": 0.00019216537475585938, "timer/agent.train_count": 1202.0, "timer/agent.train_total": 466.51758003234863, "timer/agent.train_frac": 0.9328753029828039, "timer/agent.train_avg": 0.38811778704854294, "timer/agent.train_min": 0.35872721672058105, "timer/agent.train_max": 0.4578852653503418, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.5208730697631836, "timer/agent.report_frac": 0.0010415676569727977, "timer/agent.report_avg": 0.2604365348815918, "timer/agent.report_min": 0.23639631271362305, "timer/agent.report_max": 0.28447675704956055, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.910064697265625e-05, "timer/dataset_eval_frac": 7.818789570354686e-08, "timer/dataset_eval_avg": 3.910064697265625e-05, "timer/dataset_eval_min": 3.910064697265625e-05, "timer/dataset_eval_max": 3.910064697265625e-05, "fps": 38.456891510366134}
{"step": 373376, "episode/length": 282.0, "episode/score": 0.11874999850988388, "episode/reward_rate": 0.0035335689045936395}
{"step": 373376, "episode/length": 239.0, "episode/score": 0.25312501192092896, "episode/reward_rate": 0.004166666666666667}
{"step": 373552, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259}
{"step": 373568, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 373680, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 374368, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 374472, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894}
{"step": 374544, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 375328, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 375688, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 375688, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 375864, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 375992, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 376680, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 376784, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 376856, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 377120, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095}
{"step": 377200, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391}
{"step": 377624, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644}
{"step": 377640, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 377872, "episode/length": 272.0, "episode/score": 0.15000000596046448, "episode/reward_rate": 0.003663003663003663}
{"step": 377944, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025}
{"step": 378176, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 378712, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291}
{"step": 378848, "episode/length": 215.0, "episode/score": 0.328125, "episode/reward_rate": 0.004629629629629629}
{"step": 378856, "episode/length": 17.0, "episode/score": 0.9468749761581421, "episode/reward_rate": 0.05555555555555555}
{"step": 379096, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 379136, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333}
{"step": 379168, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 379728, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266}
{"step": 379952, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 380016, "episode/length": 267.0, "episode/score": 0.16562500596046448, "episode/reward_rate": 0.0037313432835820895}
{"step": 380016, "eval_episode/length": 192.0, "eval_episode/score": 0.4000000059604645, "eval_episode/reward_rate": 0.0051813471502590676}
{"step": 380016, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380016, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380016, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380016, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380016, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380016, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380016, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380256, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 380416, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625}
{"step": 381160, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 381168, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 381480, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 382040, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 382264, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 382328, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 382568, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 382728, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 383472, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 383480, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 383792, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 384352, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 384576, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 384640, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 384880, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 385040, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 385784, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 385792, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 386104, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 386664, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 386888, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 386952, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 387192, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 387352, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 387472, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901}
{"step": 388096, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 388104, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 388416, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 388712, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064}
{"step": 389200, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 389264, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 389504, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 389664, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 389856, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514}
{"step": 390000, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 390000, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 390000, "eval_episode/length": 149.0, "eval_episode/score": 0.534375011920929, "eval_episode/reward_rate": 0.006666666666666667}
{"step": 390000, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390000, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390000, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390000, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390000, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390136, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548}
{"step": 390192, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406}
{"step": 390408, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 390416, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 390728, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 390880, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827}
{"step": 391024, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703}
{"step": 391816, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 391976, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 392168, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
